{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "2  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   \n",
       "3  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275   \n",
       "4  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "2   8.2675  14.7222   0.3965  \n",
       "3  10.2922  17.9697  -8.9996  \n",
       "4   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', sep = ',')\n",
    "X = df.loc[:,'var_0':'var_199']\n",
    "Y = df.loc[:,'target']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_index = np.where(Y==1)\n",
    "honest_index = np.where(Y==0)\n",
    "fraud = X.loc[fraud_index]\n",
    "honest = X.loc[honest_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yh = Y.loc[honest_index]\n",
    "yf = Y.loc[fraud_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_train, h_test, hy_train, hy_test = train_test_split(honest, yh,test_size=0.4,random_state=30)\n",
    "h_train, h_test, hy_train, hy_test = train_test_split(h_test, hy_test,test_size=0.3,random_state=30)\n",
    "h_test, h_val, hy_test, hy_val = train_test_split(h_test, hy_test,test_size=0.5,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train, f_test, fy_train, fy_test = train_test_split(fraud, yf,test_size=0.3,random_state=30)\n",
    "f_test, f_val, fy_test, fy_val = train_test_split(f_test, fy_test,test_size=0.5,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.580608473130509"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_train)/len(f_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.concat([h_train,f_train],ignore_index = True)\n",
    "x_test = pd.concat([h_test,f_test],ignore_index = True)\n",
    "x_val = pd.concat([h_val,f_val],ignore_index = True)\n",
    "\n",
    "y_train = pd.concat([hy_train,fy_train],ignore_index = True)\n",
    "y_test = pd.concat([hy_test,fy_test],ignore_index = True)\n",
    "y_val = pd.concat([hy_val,fy_val],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanx = x_train.mean(axis = 0)\n",
    "stdx = x_train.std(axis = 0)\n",
    "x_train_norm = (x_train - meanx)/stdx\n",
    "x_val_norm = (x_val - meanx)/stdx\n",
    "x_test_norm = (x_test - meanx)/stdx\n",
    "x_train_norm=np.asarray(x_train_norm)\n",
    "x_test_norm=np.asarray(x_test_norm)\n",
    "x_val_norm=np.asarray(x_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from keras.backend import binary_crossentropy\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "from keras.backend import mean\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class new_rna:\n",
    "    def build_model(self,data_shape,units_list,activation_list,dropout_list):\n",
    "        self.model = models.Sequential()\n",
    "        if len(dropout_list)<0:\n",
    "            my_init = keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=1)\n",
    "            for i in range(len(units_list)):\n",
    "                if i == 0:\n",
    "                    self.model.add(layers.Dense(units=units_list[i], \n",
    "                                                activation=activation_list[i], \n",
    "                                                kernel_initializer = my_init,\n",
    "                                                input_shape=data_shape))\n",
    "                else:\n",
    "                    self.model.add(layers.Dense(units=units_list[i], \n",
    "                                                activation=activation_list[i]))\n",
    "        else:\n",
    "            my_init = keras.initializers.RandomUniform(minval=-0.05, \n",
    "                                                       maxval=0.05, \n",
    "                                                       seed=1)\n",
    "            for i in range(len(units_list)):\n",
    "                if i == 0:\n",
    "                    self.model.add(layers.Dense(units=units_list[i], \n",
    "                                                activation=activation_list[i],\n",
    "                                                kernel_initializer = my_init,\n",
    "                                                input_shape=data_shape))\n",
    "                else:\n",
    "                    self.model.add(layers.Dropout(dropout_list[i-1]))\n",
    "                    self.model.add(layers.Dense(units=units_list[i], \n",
    "                                                activation=activation_list[i]))\n",
    "        self.model.summary()\n",
    "           \n",
    "    def train(self,x_train,y_train,x_val,y_val,batch_size,epochs,loss,metric):\n",
    "        mom = optimizers.SGD(lr=0.001, decay=0, momentum=0.9, nesterov=True)\n",
    "        self.model.compile(loss = [loss],metrics = [metric], optimizer = mom)\n",
    "        history = self.model.fit(x_train,y_train,batch_size = batch_size,epochs = epochs,validation_data = (x_val,y_val))\n",
    "        self.history_dict = history.history\n",
    "        self.aux_train = 1\n",
    "        \n",
    "    def plot(self):\n",
    "        if (self.aux_train == 1):\n",
    "            self.aux_plt = 1\n",
    "            cost = self.history_dict['loss']\n",
    "            metric = self.history_dict['f1']\n",
    "            val_cost = self.history_dict['val_loss']\n",
    "            val_metric = self.history_dict['val_f1']\n",
    "            aux_epocas = range(1,len(cost)+1)\n",
    "            plt.plot(aux_epocas,cost,'b',label = 'Custo - treinamento', color = 'red')\n",
    "            plt.plot(aux_epocas,val_cost,'b',label = 'Custo - validacao', color = 'blue')\n",
    "            plt.title(' Valor da Funcao Custo = Treinamento e Validacao')\n",
    "            plt.xlabel('Épocas')\n",
    "            plt.ylabel('Custo')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            plt.plot(aux_epocas, metric,'b',label = 'metrica - treinamento',color = 'red')\n",
    "            plt.plot(aux_epocas, val_metric,'b',label = 'metrica - validacao', color = 'blue')\n",
    "            plt.title('Valor da métrica – treinamento e validação')\n",
    "            plt.xlabel('Épocas')\n",
    "            plt.ylabel('Acertividade')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('Train before plot')\n",
    "\n",
    "    def predict(self,x_data,y_data):\n",
    "        if (self.aux_plt == 1):\n",
    "            class_names = np.array([['Honest'],['Fraud']])\n",
    "            subtitle = ['Test', 'Val', 'Train']\n",
    "            for i in range(len(x_data)):\n",
    "                y_hat = self.model.predict(x_data[i])\n",
    "                yy_hat = np.round(y_hat)\n",
    "                yy_hat = yy_hat.astype(int)\n",
    "                yy_hat = np.ravel(yy_hat)\n",
    "                f1 = f1_score(y_data[i],yy_hat)\n",
    "                plot_confusion_matrix(np.int_(y_data[i]), np.int_(yy_hat), classes=class_names,\n",
    "                                      title='F1_Score = {0}: {1} Data'.format(f1, subtitle[i]))\n",
    "                plt.show()\n",
    "            K.clear_session()\n",
    "        else:\n",
    "            print('Train before predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = (200,)\n",
    "\n",
    "loss = 'binary_crossentropy'\n",
    "metric = f1\n",
    "batch_size = 32\n",
    "epochs = 2000\n",
    "\n",
    "x_data = [x_test_norm,x_val_norm,x_train_norm]\n",
    "y_data = [y_test,y_val,y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list0 = [50,1]\n",
    "activation_list0 = ['tanh','sigmoid']\n",
    "dropout_list0 = [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Elvemage\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Elvemage\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,101\n",
      "Trainable params: 10,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna0 = new_rna()\n",
    "rna0.build_model(data_shape,n_list0,activation_list0,dropout_list0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Elvemage\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 64440 samples, validate on 13810 samples\n",
      "Epoch 1/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.4001 - f1: 0.5105 - val_loss: 0.3695 - val_f1: 0.1395\n",
      "Epoch 2/2000\n",
      "64440/64440 [==============================] - 2s 30us/step - loss: 0.3693 - f1: 0.5425 - val_loss: 0.3681 - val_f1: 0.1427\n",
      "Epoch 3/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3681 - f1: 0.5455 - val_loss: 0.3680 - val_f1: 0.1421\n",
      "Epoch 4/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3658 - f1: 0.5482 - val_loss: 0.3671 - val_f1: 0.1413\n",
      "Epoch 5/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3655 - f1: 0.5461 - val_loss: 0.3664 - val_f1: 0.1425\n",
      "Epoch 6/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3645 - f1: 0.5471 - val_loss: 0.3670 - val_f1: 0.1405\n",
      "Epoch 7/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3632 - f1: 0.5455 - val_loss: 0.3668 - val_f1: 0.1425\n",
      "Epoch 8/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3636 - f1: 0.5452 - val_loss: 0.3665 - val_f1: 0.1436\n",
      "Epoch 9/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3633 - f1: 0.5535 - val_loss: 0.3670 - val_f1: 0.1409\n",
      "Epoch 10/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3624 - f1: 0.5518 - val_loss: 0.3666 - val_f1: 0.1409\n",
      "Epoch 11/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3624 - f1: 0.5467 - val_loss: 0.3666 - val_f1: 0.1423\n",
      "Epoch 12/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3617 - f1: 0.5503 - val_loss: 0.3665 - val_f1: 0.1434\n",
      "Epoch 13/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3622 - f1: 0.5493 - val_loss: 0.3665 - val_f1: 0.1442\n",
      "Epoch 14/2000\n",
      "64440/64440 [==============================] - 2s 32us/step - loss: 0.3610 - f1: 0.5512 - val_loss: 0.3667 - val_f1: 0.1429\n",
      "Epoch 15/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3612 - f1: 0.5540 - val_loss: 0.3663 - val_f1: 0.1432\n",
      "Epoch 16/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3610 - f1: 0.5530 - val_loss: 0.3663 - val_f1: 0.1429\n",
      "Epoch 17/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3607 - f1: 0.5473 - val_loss: 0.3663 - val_f1: 0.1428\n",
      "Epoch 18/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3609 - f1: 0.5545 - val_loss: 0.3665 - val_f1: 0.1417\n",
      "Epoch 19/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3605 - f1: 0.5508 - val_loss: 0.3665 - val_f1: 0.1429\n",
      "Epoch 20/2000\n",
      "64440/64440 [==============================] - 2s 30us/step - loss: 0.3605 - f1: 0.5540 - val_loss: 0.3667 - val_f1: 0.1430\n",
      "Epoch 21/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3598 - f1: 0.5532 - val_loss: 0.3665 - val_f1: 0.1429\n",
      "Epoch 22/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3602 - f1: 0.5537 - val_loss: 0.3661 - val_f1: 0.1417\n",
      "Epoch 23/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3597 - f1: 0.5531 - val_loss: 0.3664 - val_f1: 0.1440\n",
      "Epoch 24/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3600 - f1: 0.5589 - val_loss: 0.3663 - val_f1: 0.1433\n",
      "Epoch 25/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3598 - f1: 0.5533 - val_loss: 0.3667 - val_f1: 0.1436\n",
      "Epoch 26/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3601 - f1: 0.5508 - val_loss: 0.3664 - val_f1: 0.1424\n",
      "Epoch 27/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3598 - f1: 0.5573 - val_loss: 0.3667 - val_f1: 0.1446\n",
      "Epoch 28/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3595 - f1: 0.5581 - val_loss: 0.3665 - val_f1: 0.1436\n",
      "Epoch 29/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3594 - f1: 0.5553 - val_loss: 0.3664 - val_f1: 0.1413\n",
      "Epoch 30/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3591 - f1: 0.5561 - val_loss: 0.3666 - val_f1: 0.1439\n",
      "Epoch 31/2000\n",
      "64440/64440 [==============================] - 2s 30us/step - loss: 0.3591 - f1: 0.5549 - val_loss: 0.3665 - val_f1: 0.1425\n",
      "Epoch 32/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3594 - f1: 0.5557 - val_loss: 0.3664 - val_f1: 0.1408\n",
      "Epoch 33/2000\n",
      "64440/64440 [==============================] - 2s 30us/step - loss: 0.3587 - f1: 0.5538 - val_loss: 0.3671 - val_f1: 0.1438\n",
      "Epoch 34/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3588 - f1: 0.5584 - val_loss: 0.3667 - val_f1: 0.1431\n",
      "Epoch 35/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3588 - f1: 0.5547 - val_loss: 0.3667 - val_f1: 0.1447\n",
      "Epoch 36/2000\n",
      "64440/64440 [==============================] - 2s 32us/step - loss: 0.3589 - f1: 0.5597 - val_loss: 0.3666 - val_f1: 0.1434\n",
      "Epoch 37/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3579 - f1: 0.5599 - val_loss: 0.3666 - val_f1: 0.1428\n",
      "Epoch 38/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3578 - f1: 0.5585 - val_loss: 0.3669 - val_f1: 0.1430\n",
      "Epoch 39/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3580 - f1: 0.5598 - val_loss: 0.3666 - val_f1: 0.1414\n",
      "Epoch 40/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3578 - f1: 0.5613 - val_loss: 0.3671 - val_f1: 0.1439\n",
      "Epoch 41/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3577 - f1: 0.5574 - val_loss: 0.3670 - val_f1: 0.1442\n",
      "Epoch 42/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3579 - f1: 0.5609 - val_loss: 0.3667 - val_f1: 0.1415\n",
      "Epoch 43/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3574 - f1: 0.5594 - val_loss: 0.3667 - val_f1: 0.1435\n",
      "Epoch 44/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3576 - f1: 0.5579 - val_loss: 0.3667 - val_f1: 0.1428\n",
      "Epoch 45/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3571 - f1: 0.5596 - val_loss: 0.3667 - val_f1: 0.1433\n",
      "Epoch 46/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3569 - f1: 0.5583 - val_loss: 0.3668 - val_f1: 0.1424\n",
      "Epoch 47/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3566 - f1: 0.5599 - val_loss: 0.3668 - val_f1: 0.1434\n",
      "Epoch 48/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3564 - f1: 0.5597 - val_loss: 0.3667 - val_f1: 0.1424\n",
      "Epoch 49/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3562 - f1: 0.5608 - val_loss: 0.3666 - val_f1: 0.1427\n",
      "Epoch 50/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3564 - f1: 0.5599 - val_loss: 0.3669 - val_f1: 0.1427\n",
      "Epoch 51/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3565 - f1: 0.5633 - val_loss: 0.3668 - val_f1: 0.1427\n",
      "Epoch 52/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3559 - f1: 0.5596 - val_loss: 0.3672 - val_f1: 0.1440\n",
      "Epoch 53/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3552 - f1: 0.5631 - val_loss: 0.3670 - val_f1: 0.1426\n",
      "Epoch 54/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3562 - f1: 0.5572 - val_loss: 0.3667 - val_f1: 0.1418\n",
      "Epoch 55/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3554 - f1: 0.5592 - val_loss: 0.3674 - val_f1: 0.1444\n",
      "Epoch 56/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3549 - f1: 0.5641 - val_loss: 0.3670 - val_f1: 0.1410\n",
      "Epoch 57/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3546 - f1: 0.5632 - val_loss: 0.3671 - val_f1: 0.1428\n",
      "Epoch 58/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3549 - f1: 0.5640 - val_loss: 0.3672 - val_f1: 0.1427\n",
      "Epoch 59/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3546 - f1: 0.5604 - val_loss: 0.3674 - val_f1: 0.1428\n",
      "Epoch 60/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3537 - f1: 0.5598 - val_loss: 0.3675 - val_f1: 0.1427\n",
      "Epoch 61/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3538 - f1: 0.5648 - val_loss: 0.3675 - val_f1: 0.1444\n",
      "Epoch 62/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3547 - f1: 0.5620 - val_loss: 0.3672 - val_f1: 0.1434\n",
      "Epoch 63/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3546 - f1: 0.5639 - val_loss: 0.3672 - val_f1: 0.1417\n",
      "Epoch 64/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3538 - f1: 0.5635 - val_loss: 0.3673 - val_f1: 0.1424\n",
      "Epoch 65/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3530 - f1: 0.5621 - val_loss: 0.3674 - val_f1: 0.1428\n",
      "Epoch 66/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3540 - f1: 0.5646 - val_loss: 0.3676 - val_f1: 0.1427\n",
      "Epoch 67/2000\n",
      "64440/64440 [==============================] - 2s 32us/step - loss: 0.3534 - f1: 0.5625 - val_loss: 0.3672 - val_f1: 0.1421\n",
      "Epoch 68/2000\n",
      "64440/64440 [==============================] - 2s 30us/step - loss: 0.3527 - f1: 0.5627 - val_loss: 0.3676 - val_f1: 0.1423\n",
      "Epoch 69/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3529 - f1: 0.5670 - val_loss: 0.3677 - val_f1: 0.1424\n",
      "Epoch 70/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3530 - f1: 0.5627 - val_loss: 0.3672 - val_f1: 0.1421\n",
      "Epoch 71/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3530 - f1: 0.5652 - val_loss: 0.3674 - val_f1: 0.1421\n",
      "Epoch 72/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3518 - f1: 0.5671 - val_loss: 0.3677 - val_f1: 0.1430\n",
      "Epoch 73/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3527 - f1: 0.5664 - val_loss: 0.3673 - val_f1: 0.1430\n",
      "Epoch 74/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3517 - f1: 0.5652 - val_loss: 0.3676 - val_f1: 0.1431\n",
      "Epoch 75/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3513 - f1: 0.5680 - val_loss: 0.3680 - val_f1: 0.1417\n",
      "Epoch 76/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3518 - f1: 0.5643 - val_loss: 0.3675 - val_f1: 0.1417\n",
      "Epoch 77/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3510 - f1: 0.5696 - val_loss: 0.3682 - val_f1: 0.1414\n",
      "Epoch 78/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3511 - f1: 0.5683 - val_loss: 0.3680 - val_f1: 0.1424\n",
      "Epoch 79/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3509 - f1: 0.5646 - val_loss: 0.3679 - val_f1: 0.1419\n",
      "Epoch 80/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3504 - f1: 0.5684 - val_loss: 0.3680 - val_f1: 0.1427\n",
      "Epoch 81/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3507 - f1: 0.5664 - val_loss: 0.3682 - val_f1: 0.1420\n",
      "Epoch 82/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3501 - f1: 0.5690 - val_loss: 0.3679 - val_f1: 0.1419\n",
      "Epoch 83/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3501 - f1: 0.5694 - val_loss: 0.3681 - val_f1: 0.1428\n",
      "Epoch 84/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3492 - f1: 0.5723 - val_loss: 0.3677 - val_f1: 0.1422\n",
      "Epoch 85/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3481 - f1: 0.5728 - val_loss: 0.3680 - val_f1: 0.1420\n",
      "Epoch 86/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3496 - f1: 0.5741 - val_loss: 0.3680 - val_f1: 0.1424\n",
      "Epoch 87/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3488 - f1: 0.5669 - val_loss: 0.3682 - val_f1: 0.1434\n",
      "Epoch 88/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3484 - f1: 0.5706 - val_loss: 0.3681 - val_f1: 0.1433\n",
      "Epoch 89/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3492 - f1: 0.5713 - val_loss: 0.3682 - val_f1: 0.1416\n",
      "Epoch 90/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3478 - f1: 0.5705 - val_loss: 0.3678 - val_f1: 0.1408\n",
      "Epoch 91/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3472 - f1: 0.5732 - val_loss: 0.3688 - val_f1: 0.1429\n",
      "Epoch 92/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3474 - f1: 0.5744 - val_loss: 0.3684 - val_f1: 0.1420\n",
      "Epoch 93/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3462 - f1: 0.5769 - val_loss: 0.3687 - val_f1: 0.1411\n",
      "Epoch 94/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3483 - f1: 0.5706 - val_loss: 0.3688 - val_f1: 0.1419\n",
      "Epoch 95/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3458 - f1: 0.5762 - val_loss: 0.3685 - val_f1: 0.1412\n",
      "Epoch 96/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3462 - f1: 0.5730 - val_loss: 0.3689 - val_f1: 0.1429\n",
      "Epoch 97/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3455 - f1: 0.5752 - val_loss: 0.3691 - val_f1: 0.1418\n",
      "Epoch 98/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3462 - f1: 0.5738 - val_loss: 0.3687 - val_f1: 0.1424\n",
      "Epoch 99/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3461 - f1: 0.5746 - val_loss: 0.3689 - val_f1: 0.1418\n",
      "Epoch 100/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3463 - f1: 0.5749 - val_loss: 0.3694 - val_f1: 0.1432\n",
      "Epoch 101/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3448 - f1: 0.5787 - val_loss: 0.3690 - val_f1: 0.1426\n",
      "Epoch 102/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3454 - f1: 0.5758 - val_loss: 0.3690 - val_f1: 0.1418\n",
      "Epoch 103/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3447 - f1: 0.5762 - val_loss: 0.3690 - val_f1: 0.1429\n",
      "Epoch 104/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3447 - f1: 0.5760 - val_loss: 0.3692 - val_f1: 0.1413\n",
      "Epoch 105/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3445 - f1: 0.5780 - val_loss: 0.3691 - val_f1: 0.1423\n",
      "Epoch 106/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3434 - f1: 0.5793 - val_loss: 0.3693 - val_f1: 0.1421\n",
      "Epoch 107/2000\n",
      "64440/64440 [==============================] - 2s 30us/step - loss: 0.3435 - f1: 0.5781 - val_loss: 0.3694 - val_f1: 0.1414\n",
      "Epoch 108/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3437 - f1: 0.5805 - val_loss: 0.3691 - val_f1: 0.1404\n",
      "Epoch 109/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3422 - f1: 0.5811 - val_loss: 0.3699 - val_f1: 0.1417\n",
      "Epoch 110/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3432 - f1: 0.5810 - val_loss: 0.3697 - val_f1: 0.1422\n",
      "Epoch 111/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3419 - f1: 0.5819 - val_loss: 0.3698 - val_f1: 0.1425\n",
      "Epoch 112/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3409 - f1: 0.5794 - val_loss: 0.3703 - val_f1: 0.1430\n",
      "Epoch 113/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3414 - f1: 0.5824 - val_loss: 0.3701 - val_f1: 0.1425\n",
      "Epoch 114/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3416 - f1: 0.5829 - val_loss: 0.3700 - val_f1: 0.1421\n",
      "Epoch 115/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3431 - f1: 0.5812 - val_loss: 0.3696 - val_f1: 0.1427\n",
      "Epoch 116/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3412 - f1: 0.5854 - val_loss: 0.3705 - val_f1: 0.1414\n",
      "Epoch 117/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3398 - f1: 0.5832 - val_loss: 0.3702 - val_f1: 0.1417\n",
      "Epoch 118/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3404 - f1: 0.5823 - val_loss: 0.3713 - val_f1: 0.1419\n",
      "Epoch 119/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3412 - f1: 0.5822 - val_loss: 0.3703 - val_f1: 0.1425\n",
      "Epoch 120/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3411 - f1: 0.5820 - val_loss: 0.3705 - val_f1: 0.1424\n",
      "Epoch 121/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3395 - f1: 0.5907 - val_loss: 0.3710 - val_f1: 0.1414\n",
      "Epoch 122/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3398 - f1: 0.5871 - val_loss: 0.3705 - val_f1: 0.1419\n",
      "Epoch 123/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3394 - f1: 0.5845 - val_loss: 0.3709 - val_f1: 0.1408\n",
      "Epoch 124/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3381 - f1: 0.5897 - val_loss: 0.3709 - val_f1: 0.1409\n",
      "Epoch 125/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3401 - f1: 0.5838 - val_loss: 0.3709 - val_f1: 0.1419\n",
      "Epoch 126/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3368 - f1: 0.5877 - val_loss: 0.3715 - val_f1: 0.1417\n",
      "Epoch 127/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3388 - f1: 0.5890 - val_loss: 0.3714 - val_f1: 0.1421\n",
      "Epoch 128/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3364 - f1: 0.5906 - val_loss: 0.3719 - val_f1: 0.1412\n",
      "Epoch 129/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3365 - f1: 0.5882 - val_loss: 0.3719 - val_f1: 0.1407\n",
      "Epoch 130/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3377 - f1: 0.5873 - val_loss: 0.3718 - val_f1: 0.1413\n",
      "Epoch 131/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3368 - f1: 0.5912 - val_loss: 0.3719 - val_f1: 0.1422\n",
      "Epoch 132/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3357 - f1: 0.5943 - val_loss: 0.3718 - val_f1: 0.1423\n",
      "Epoch 133/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3358 - f1: 0.5957 - val_loss: 0.3722 - val_f1: 0.1420\n",
      "Epoch 134/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3371 - f1: 0.5896 - val_loss: 0.3721 - val_f1: 0.1411\n",
      "Epoch 135/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3354 - f1: 0.5953 - val_loss: 0.3721 - val_f1: 0.1417\n",
      "Epoch 136/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3353 - f1: 0.5948 - val_loss: 0.3723 - val_f1: 0.1426\n",
      "Epoch 137/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3351 - f1: 0.5962 - val_loss: 0.3724 - val_f1: 0.1408\n",
      "Epoch 138/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3349 - f1: 0.5928 - val_loss: 0.3727 - val_f1: 0.1418\n",
      "Epoch 139/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3345 - f1: 0.5964 - val_loss: 0.3724 - val_f1: 0.1433\n",
      "Epoch 140/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3348 - f1: 0.5915 - val_loss: 0.3723 - val_f1: 0.1427\n",
      "Epoch 141/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3353 - f1: 0.5925 - val_loss: 0.3727 - val_f1: 0.1414\n",
      "Epoch 142/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3346 - f1: 0.5923 - val_loss: 0.3727 - val_f1: 0.1428\n",
      "Epoch 143/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3325 - f1: 0.5989 - val_loss: 0.3729 - val_f1: 0.1420\n",
      "Epoch 144/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3325 - f1: 0.5932 - val_loss: 0.3734 - val_f1: 0.1429\n",
      "Epoch 145/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3326 - f1: 0.5969 - val_loss: 0.3733 - val_f1: 0.1412\n",
      "Epoch 146/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3321 - f1: 0.5985 - val_loss: 0.3740 - val_f1: 0.1431\n",
      "Epoch 147/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3325 - f1: 0.5970 - val_loss: 0.3736 - val_f1: 0.1417\n",
      "Epoch 148/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3311 - f1: 0.6011 - val_loss: 0.3740 - val_f1: 0.1414\n",
      "Epoch 149/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3323 - f1: 0.6013 - val_loss: 0.3742 - val_f1: 0.1412\n",
      "Epoch 150/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3311 - f1: 0.5933 - val_loss: 0.3740 - val_f1: 0.1428\n",
      "Epoch 151/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3314 - f1: 0.6023 - val_loss: 0.3737 - val_f1: 0.1417\n",
      "Epoch 152/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3317 - f1: 0.6024 - val_loss: 0.3742 - val_f1: 0.1419\n",
      "Epoch 153/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3290 - f1: 0.6040 - val_loss: 0.3751 - val_f1: 0.1429\n",
      "Epoch 154/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3309 - f1: 0.6027 - val_loss: 0.3739 - val_f1: 0.1418\n",
      "Epoch 155/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3286 - f1: 0.6044 - val_loss: 0.3743 - val_f1: 0.1428\n",
      "Epoch 156/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3294 - f1: 0.6047 - val_loss: 0.3748 - val_f1: 0.1417\n",
      "Epoch 157/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3318 - f1: 0.5979 - val_loss: 0.3742 - val_f1: 0.1420\n",
      "Epoch 158/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3291 - f1: 0.5997 - val_loss: 0.3746 - val_f1: 0.1421\n",
      "Epoch 159/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3286 - f1: 0.6004 - val_loss: 0.3756 - val_f1: 0.1434\n",
      "Epoch 160/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3284 - f1: 0.6103 - val_loss: 0.3747 - val_f1: 0.1425\n",
      "Epoch 161/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3271 - f1: 0.6081 - val_loss: 0.3747 - val_f1: 0.1413\n",
      "Epoch 162/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3285 - f1: 0.6074 - val_loss: 0.3754 - val_f1: 0.1417\n",
      "Epoch 163/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3282 - f1: 0.6047 - val_loss: 0.3758 - val_f1: 0.1414\n",
      "Epoch 164/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3274 - f1: 0.6041 - val_loss: 0.3758 - val_f1: 0.1414\n",
      "Epoch 165/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3276 - f1: 0.6061 - val_loss: 0.3763 - val_f1: 0.1417\n",
      "Epoch 166/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3268 - f1: 0.6073 - val_loss: 0.3756 - val_f1: 0.1414\n",
      "Epoch 167/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3274 - f1: 0.6061 - val_loss: 0.3759 - val_f1: 0.1415\n",
      "Epoch 168/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3262 - f1: 0.6067 - val_loss: 0.3767 - val_f1: 0.1426\n",
      "Epoch 169/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3256 - f1: 0.6087 - val_loss: 0.3765 - val_f1: 0.1416\n",
      "Epoch 170/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3260 - f1: 0.6082 - val_loss: 0.3763 - val_f1: 0.1414\n",
      "Epoch 171/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3249 - f1: 0.6100 - val_loss: 0.3767 - val_f1: 0.1424\n",
      "Epoch 172/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.3266 - f1: 0.6099 - val_loss: 0.3765 - val_f1: 0.1416\n",
      "Epoch 173/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3273 - f1: 0.6101 - val_loss: 0.3765 - val_f1: 0.1413\n",
      "Epoch 174/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3245 - f1: 0.6152 - val_loss: 0.3765 - val_f1: 0.1417\n",
      "Epoch 175/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3250 - f1: 0.6094 - val_loss: 0.3767 - val_f1: 0.1418\n",
      "Epoch 176/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3255 - f1: 0.6117 - val_loss: 0.3769 - val_f1: 0.1427\n",
      "Epoch 177/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3253 - f1: 0.6091 - val_loss: 0.3765 - val_f1: 0.1410\n",
      "Epoch 178/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3237 - f1: 0.6138 - val_loss: 0.3765 - val_f1: 0.1416\n",
      "Epoch 179/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3227 - f1: 0.6156 - val_loss: 0.3772 - val_f1: 0.1425\n",
      "Epoch 180/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3253 - f1: 0.6153 - val_loss: 0.3774 - val_f1: 0.1416\n",
      "Epoch 181/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3237 - f1: 0.6110 - val_loss: 0.3766 - val_f1: 0.1409\n",
      "Epoch 182/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3217 - f1: 0.6150 - val_loss: 0.3784 - val_f1: 0.1413\n",
      "Epoch 183/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3229 - f1: 0.6091 - val_loss: 0.3777 - val_f1: 0.1430\n",
      "Epoch 184/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3216 - f1: 0.6179 - val_loss: 0.3780 - val_f1: 0.1414\n",
      "Epoch 185/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3238 - f1: 0.6130 - val_loss: 0.3776 - val_f1: 0.1403\n",
      "Epoch 186/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3227 - f1: 0.6166 - val_loss: 0.3777 - val_f1: 0.1416\n",
      "Epoch 187/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3214 - f1: 0.6147 - val_loss: 0.3777 - val_f1: 0.1405\n",
      "Epoch 188/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3220 - f1: 0.6146 - val_loss: 0.3778 - val_f1: 0.1414\n",
      "Epoch 189/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3229 - f1: 0.6090 - val_loss: 0.3778 - val_f1: 0.1414\n",
      "Epoch 190/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3204 - f1: 0.6184 - val_loss: 0.3783 - val_f1: 0.1413\n",
      "Epoch 191/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3204 - f1: 0.6142 - val_loss: 0.3778 - val_f1: 0.1422\n",
      "Epoch 192/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3211 - f1: 0.6184 - val_loss: 0.3785 - val_f1: 0.1408\n",
      "Epoch 193/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3214 - f1: 0.6205 - val_loss: 0.3784 - val_f1: 0.1411\n",
      "Epoch 194/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3209 - f1: 0.6204 - val_loss: 0.3788 - val_f1: 0.1418\n",
      "Epoch 195/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3218 - f1: 0.6165 - val_loss: 0.3784 - val_f1: 0.1406\n",
      "Epoch 196/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3191 - f1: 0.6199 - val_loss: 0.3790 - val_f1: 0.1407\n",
      "Epoch 197/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3187 - f1: 0.6241 - val_loss: 0.3785 - val_f1: 0.1412\n",
      "Epoch 198/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3190 - f1: 0.6207 - val_loss: 0.3795 - val_f1: 0.1417\n",
      "Epoch 199/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3198 - f1: 0.6212 - val_loss: 0.3787 - val_f1: 0.1429\n",
      "Epoch 200/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3180 - f1: 0.6222 - val_loss: 0.3795 - val_f1: 0.1415\n",
      "Epoch 201/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3180 - f1: 0.6255 - val_loss: 0.3797 - val_f1: 0.1411\n",
      "Epoch 202/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3194 - f1: 0.6177 - val_loss: 0.3795 - val_f1: 0.1412\n",
      "Epoch 203/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3191 - f1: 0.6187 - val_loss: 0.3794 - val_f1: 0.1417\n",
      "Epoch 204/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3180 - f1: 0.6236 - val_loss: 0.3800 - val_f1: 0.1411\n",
      "Epoch 205/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3171 - f1: 0.6291 - val_loss: 0.3798 - val_f1: 0.1419\n",
      "Epoch 206/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3176 - f1: 0.6252 - val_loss: 0.3794 - val_f1: 0.1421\n",
      "Epoch 207/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3173 - f1: 0.6271 - val_loss: 0.3795 - val_f1: 0.1408\n",
      "Epoch 208/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3169 - f1: 0.6258 - val_loss: 0.3797 - val_f1: 0.1415\n",
      "Epoch 209/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3168 - f1: 0.6219 - val_loss: 0.3804 - val_f1: 0.1411\n",
      "Epoch 210/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3195 - f1: 0.6244 - val_loss: 0.3792 - val_f1: 0.1407\n",
      "Epoch 211/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3172 - f1: 0.6194 - val_loss: 0.3805 - val_f1: 0.1418\n",
      "Epoch 212/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3170 - f1: 0.6257 - val_loss: 0.3800 - val_f1: 0.1401\n",
      "Epoch 213/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3171 - f1: 0.6235 - val_loss: 0.3804 - val_f1: 0.1417\n",
      "Epoch 214/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3159 - f1: 0.6265 - val_loss: 0.3815 - val_f1: 0.1422\n",
      "Epoch 215/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3167 - f1: 0.6212 - val_loss: 0.3805 - val_f1: 0.1406\n",
      "Epoch 216/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3160 - f1: 0.6236 - val_loss: 0.3808 - val_f1: 0.1420\n",
      "Epoch 217/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3160 - f1: 0.6262 - val_loss: 0.3808 - val_f1: 0.1407\n",
      "Epoch 218/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3152 - f1: 0.6270 - val_loss: 0.3811 - val_f1: 0.1410\n",
      "Epoch 219/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3157 - f1: 0.6257 - val_loss: 0.3809 - val_f1: 0.1410\n",
      "Epoch 220/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3136 - f1: 0.6272 - val_loss: 0.3818 - val_f1: 0.1414\n",
      "Epoch 221/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3137 - f1: 0.6295 - val_loss: 0.3823 - val_f1: 0.1425\n",
      "Epoch 222/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3160 - f1: 0.6276 - val_loss: 0.3817 - val_f1: 0.1409\n",
      "Epoch 223/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3129 - f1: 0.6320 - val_loss: 0.3820 - val_f1: 0.1411\n",
      "Epoch 224/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3145 - f1: 0.6262 - val_loss: 0.3814 - val_f1: 0.1413\n",
      "Epoch 225/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3137 - f1: 0.6269 - val_loss: 0.3814 - val_f1: 0.1410\n",
      "Epoch 226/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3118 - f1: 0.6293 - val_loss: 0.3826 - val_f1: 0.1405\n",
      "Epoch 227/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3129 - f1: 0.6311 - val_loss: 0.3829 - val_f1: 0.1412\n",
      "Epoch 228/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3135 - f1: 0.6305 - val_loss: 0.3825 - val_f1: 0.1411\n",
      "Epoch 229/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3133 - f1: 0.6294 - val_loss: 0.3821 - val_f1: 0.1407\n",
      "Epoch 230/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3139 - f1: 0.6292 - val_loss: 0.3822 - val_f1: 0.1418\n",
      "Epoch 231/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3132 - f1: 0.6325 - val_loss: 0.3825 - val_f1: 0.1415\n",
      "Epoch 232/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3121 - f1: 0.6348 - val_loss: 0.3828 - val_f1: 0.1421\n",
      "Epoch 233/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3124 - f1: 0.6303 - val_loss: 0.3819 - val_f1: 0.1415\n",
      "Epoch 234/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3134 - f1: 0.6265 - val_loss: 0.3826 - val_f1: 0.1406\n",
      "Epoch 235/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3112 - f1: 0.6310 - val_loss: 0.3830 - val_f1: 0.1415\n",
      "Epoch 236/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3125 - f1: 0.6318 - val_loss: 0.3829 - val_f1: 0.1416\n",
      "Epoch 237/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3121 - f1: 0.6295 - val_loss: 0.3827 - val_f1: 0.1417\n",
      "Epoch 238/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3113 - f1: 0.6328 - val_loss: 0.3829 - val_f1: 0.1415\n",
      "Epoch 239/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3093 - f1: 0.6347 - val_loss: 0.3833 - val_f1: 0.1424\n",
      "Epoch 240/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3118 - f1: 0.6348 - val_loss: 0.3832 - val_f1: 0.1416\n",
      "Epoch 241/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3102 - f1: 0.6344 - val_loss: 0.3838 - val_f1: 0.1409\n",
      "Epoch 242/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3105 - f1: 0.6347 - val_loss: 0.3831 - val_f1: 0.1437\n",
      "Epoch 243/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3112 - f1: 0.6334 - val_loss: 0.3835 - val_f1: 0.1419\n",
      "Epoch 244/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3117 - f1: 0.6314 - val_loss: 0.3835 - val_f1: 0.1415\n",
      "Epoch 245/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3104 - f1: 0.6387 - val_loss: 0.3833 - val_f1: 0.1424\n",
      "Epoch 246/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3103 - f1: 0.6321 - val_loss: 0.3842 - val_f1: 0.1421\n",
      "Epoch 247/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3097 - f1: 0.6374 - val_loss: 0.3847 - val_f1: 0.1422\n",
      "Epoch 248/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3083 - f1: 0.6380 - val_loss: 0.3849 - val_f1: 0.1403\n",
      "Epoch 249/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3102 - f1: 0.6345 - val_loss: 0.3849 - val_f1: 0.1417\n",
      "Epoch 250/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3075 - f1: 0.6433 - val_loss: 0.3844 - val_f1: 0.1408\n",
      "Epoch 251/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3093 - f1: 0.6410 - val_loss: 0.3848 - val_f1: 0.1418\n",
      "Epoch 252/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3098 - f1: 0.6386 - val_loss: 0.3841 - val_f1: 0.1411\n",
      "Epoch 253/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3093 - f1: 0.6336 - val_loss: 0.3844 - val_f1: 0.1432\n",
      "Epoch 254/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3085 - f1: 0.6378 - val_loss: 0.3847 - val_f1: 0.1403\n",
      "Epoch 255/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3082 - f1: 0.6365 - val_loss: 0.3839 - val_f1: 0.1416\n",
      "Epoch 256/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3083 - f1: 0.6366 - val_loss: 0.3849 - val_f1: 0.1413\n",
      "Epoch 257/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3082 - f1: 0.6370 - val_loss: 0.3858 - val_f1: 0.1413\n",
      "Epoch 258/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3081 - f1: 0.6367 - val_loss: 0.3857 - val_f1: 0.1412\n",
      "Epoch 259/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3063 - f1: 0.6461 - val_loss: 0.3854 - val_f1: 0.1409\n",
      "Epoch 260/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3077 - f1: 0.6395 - val_loss: 0.3863 - val_f1: 0.1411\n",
      "Epoch 261/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3071 - f1: 0.6386 - val_loss: 0.3857 - val_f1: 0.1413\n",
      "Epoch 262/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3088 - f1: 0.6375 - val_loss: 0.3851 - val_f1: 0.1408\n",
      "Epoch 263/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3091 - f1: 0.6347 - val_loss: 0.3850 - val_f1: 0.1411\n",
      "Epoch 264/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3068 - f1: 0.6391 - val_loss: 0.3857 - val_f1: 0.1416\n",
      "Epoch 265/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3066 - f1: 0.6443 - val_loss: 0.3856 - val_f1: 0.1404\n",
      "Epoch 266/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3061 - f1: 0.6384 - val_loss: 0.3865 - val_f1: 0.1409\n",
      "Epoch 267/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3090 - f1: 0.6394 - val_loss: 0.3848 - val_f1: 0.1399\n",
      "Epoch 268/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3050 - f1: 0.6430 - val_loss: 0.3862 - val_f1: 0.1411\n",
      "Epoch 269/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3054 - f1: 0.6419 - val_loss: 0.3863 - val_f1: 0.1407\n",
      "Epoch 270/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3066 - f1: 0.6455 - val_loss: 0.3861 - val_f1: 0.1417\n",
      "Epoch 271/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3036 - f1: 0.6451 - val_loss: 0.3871 - val_f1: 0.1413\n",
      "Epoch 272/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3067 - f1: 0.6395 - val_loss: 0.3863 - val_f1: 0.1417\n",
      "Epoch 273/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3064 - f1: 0.6390 - val_loss: 0.3857 - val_f1: 0.1415\n",
      "Epoch 274/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3065 - f1: 0.6400 - val_loss: 0.3861 - val_f1: 0.1413\n",
      "Epoch 275/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3059 - f1: 0.6408 - val_loss: 0.3868 - val_f1: 0.1410\n",
      "Epoch 276/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3063 - f1: 0.6416 - val_loss: 0.3859 - val_f1: 0.1414\n",
      "Epoch 277/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3072 - f1: 0.6411 - val_loss: 0.3866 - val_f1: 0.1409\n",
      "Epoch 278/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3051 - f1: 0.6436 - val_loss: 0.3869 - val_f1: 0.1404\n",
      "Epoch 279/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3066 - f1: 0.6384 - val_loss: 0.3855 - val_f1: 0.1421\n",
      "Epoch 280/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3054 - f1: 0.6425 - val_loss: 0.3872 - val_f1: 0.1405\n",
      "Epoch 281/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3052 - f1: 0.6431 - val_loss: 0.3865 - val_f1: 0.1414\n",
      "Epoch 282/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3066 - f1: 0.6402 - val_loss: 0.3863 - val_f1: 0.1411\n",
      "Epoch 283/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3050 - f1: 0.6433 - val_loss: 0.3870 - val_f1: 0.1402\n",
      "Epoch 284/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3049 - f1: 0.6441 - val_loss: 0.3870 - val_f1: 0.1410\n",
      "Epoch 285/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3039 - f1: 0.6454 - val_loss: 0.3865 - val_f1: 0.1410\n",
      "Epoch 286/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3053 - f1: 0.6438 - val_loss: 0.3863 - val_f1: 0.1410\n",
      "Epoch 287/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3046 - f1: 0.6433 - val_loss: 0.3878 - val_f1: 0.1415\n",
      "Epoch 288/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3037 - f1: 0.6406 - val_loss: 0.3880 - val_f1: 0.1413\n",
      "Epoch 289/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3036 - f1: 0.6450 - val_loss: 0.3877 - val_f1: 0.1416\n",
      "Epoch 290/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3043 - f1: 0.6488 - val_loss: 0.3880 - val_f1: 0.1417\n",
      "Epoch 291/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3037 - f1: 0.6446 - val_loss: 0.3881 - val_f1: 0.1414\n",
      "Epoch 292/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3036 - f1: 0.6454 - val_loss: 0.3880 - val_f1: 0.1397\n",
      "Epoch 293/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3038 - f1: 0.6441 - val_loss: 0.3878 - val_f1: 0.1419\n",
      "Epoch 294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3031 - f1: 0.6415 - val_loss: 0.3887 - val_f1: 0.1421\n",
      "Epoch 295/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3023 - f1: 0.6504 - val_loss: 0.3883 - val_f1: 0.1406\n",
      "Epoch 296/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3035 - f1: 0.6442 - val_loss: 0.3877 - val_f1: 0.1416\n",
      "Epoch 297/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3024 - f1: 0.6439 - val_loss: 0.3876 - val_f1: 0.1422\n",
      "Epoch 298/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3030 - f1: 0.6458 - val_loss: 0.3883 - val_f1: 0.1409\n",
      "Epoch 299/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3031 - f1: 0.6476 - val_loss: 0.3877 - val_f1: 0.1415\n",
      "Epoch 300/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3019 - f1: 0.6492 - val_loss: 0.3884 - val_f1: 0.1415\n",
      "Epoch 301/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3013 - f1: 0.6519 - val_loss: 0.3886 - val_f1: 0.1419\n",
      "Epoch 302/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3012 - f1: 0.6474 - val_loss: 0.3893 - val_f1: 0.1407\n",
      "Epoch 303/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3025 - f1: 0.6449 - val_loss: 0.3887 - val_f1: 0.1415\n",
      "Epoch 304/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3006 - f1: 0.6492 - val_loss: 0.3890 - val_f1: 0.1417\n",
      "Epoch 305/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3025 - f1: 0.6479 - val_loss: 0.3879 - val_f1: 0.1411\n",
      "Epoch 306/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3024 - f1: 0.6479 - val_loss: 0.3881 - val_f1: 0.1413\n",
      "Epoch 307/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3021 - f1: 0.6472 - val_loss: 0.3878 - val_f1: 0.1415\n",
      "Epoch 308/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3028 - f1: 0.6488 - val_loss: 0.3875 - val_f1: 0.1407\n",
      "Epoch 309/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3017 - f1: 0.6433 - val_loss: 0.3893 - val_f1: 0.1406\n",
      "Epoch 310/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3011 - f1: 0.6480 - val_loss: 0.3890 - val_f1: 0.1412\n",
      "Epoch 311/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3020 - f1: 0.6485 - val_loss: 0.3886 - val_f1: 0.1410\n",
      "Epoch 312/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3003 - f1: 0.6491 - val_loss: 0.3885 - val_f1: 0.1412\n",
      "Epoch 313/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2989 - f1: 0.6526 - val_loss: 0.3904 - val_f1: 0.1398\n",
      "Epoch 314/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3014 - f1: 0.6462 - val_loss: 0.3883 - val_f1: 0.1409\n",
      "Epoch 315/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2995 - f1: 0.6510 - val_loss: 0.3900 - val_f1: 0.1394\n",
      "Epoch 316/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2996 - f1: 0.6483 - val_loss: 0.3895 - val_f1: 0.1398\n",
      "Epoch 317/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3000 - f1: 0.6490 - val_loss: 0.3899 - val_f1: 0.1408\n",
      "Epoch 318/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2995 - f1: 0.6529 - val_loss: 0.3900 - val_f1: 0.1399\n",
      "Epoch 319/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3009 - f1: 0.6494 - val_loss: 0.3896 - val_f1: 0.1416\n",
      "Epoch 320/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2998 - f1: 0.6507 - val_loss: 0.3900 - val_f1: 0.1394\n",
      "Epoch 321/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2983 - f1: 0.6512 - val_loss: 0.3912 - val_f1: 0.1401\n",
      "Epoch 322/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2993 - f1: 0.6493 - val_loss: 0.3904 - val_f1: 0.1413\n",
      "Epoch 323/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3010 - f1: 0.6492 - val_loss: 0.3903 - val_f1: 0.1417\n",
      "Epoch 324/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2993 - f1: 0.6527 - val_loss: 0.3898 - val_f1: 0.1409\n",
      "Epoch 325/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3002 - f1: 0.6530 - val_loss: 0.3892 - val_f1: 0.1407\n",
      "Epoch 326/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2999 - f1: 0.6498 - val_loss: 0.3897 - val_f1: 0.1410\n",
      "Epoch 327/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2979 - f1: 0.6581 - val_loss: 0.3903 - val_f1: 0.1414\n",
      "Epoch 328/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2994 - f1: 0.6515 - val_loss: 0.3907 - val_f1: 0.1408\n",
      "Epoch 329/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2995 - f1: 0.6547 - val_loss: 0.3907 - val_f1: 0.1412\n",
      "Epoch 330/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2983 - f1: 0.6549 - val_loss: 0.3910 - val_f1: 0.1409\n",
      "Epoch 331/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2973 - f1: 0.6542 - val_loss: 0.3914 - val_f1: 0.1411\n",
      "Epoch 332/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2983 - f1: 0.6520 - val_loss: 0.3916 - val_f1: 0.1396\n",
      "Epoch 333/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2991 - f1: 0.6533 - val_loss: 0.3898 - val_f1: 0.1404\n",
      "Epoch 334/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2981 - f1: 0.6570 - val_loss: 0.3907 - val_f1: 0.1408\n",
      "Epoch 335/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2979 - f1: 0.6568 - val_loss: 0.3907 - val_f1: 0.1403\n",
      "Epoch 336/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2988 - f1: 0.6554 - val_loss: 0.3902 - val_f1: 0.1400\n",
      "Epoch 337/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2971 - f1: 0.6553 - val_loss: 0.3908 - val_f1: 0.1394\n",
      "Epoch 338/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2991 - f1: 0.6515 - val_loss: 0.3898 - val_f1: 0.1409\n",
      "Epoch 339/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2975 - f1: 0.6596 - val_loss: 0.3906 - val_f1: 0.1400\n",
      "Epoch 340/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2970 - f1: 0.6539 - val_loss: 0.3911 - val_f1: 0.1400\n",
      "Epoch 341/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2972 - f1: 0.6555 - val_loss: 0.3909 - val_f1: 0.1410\n",
      "Epoch 342/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2963 - f1: 0.6559 - val_loss: 0.3916 - val_f1: 0.1405\n",
      "Epoch 343/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2968 - f1: 0.6505 - val_loss: 0.3910 - val_f1: 0.1413\n",
      "Epoch 344/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2984 - f1: 0.6496 - val_loss: 0.3906 - val_f1: 0.1402\n",
      "Epoch 345/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2970 - f1: 0.6556 - val_loss: 0.3916 - val_f1: 0.1400\n",
      "Epoch 346/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2984 - f1: 0.6548 - val_loss: 0.3913 - val_f1: 0.1406\n",
      "Epoch 347/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2987 - f1: 0.6507 - val_loss: 0.3913 - val_f1: 0.1401\n",
      "Epoch 348/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2959 - f1: 0.6568 - val_loss: 0.3920 - val_f1: 0.1402\n",
      "Epoch 349/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2977 - f1: 0.6604 - val_loss: 0.3916 - val_f1: 0.1404\n",
      "Epoch 350/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2972 - f1: 0.6550 - val_loss: 0.3914 - val_f1: 0.1397\n",
      "Epoch 351/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2979 - f1: 0.6532 - val_loss: 0.3911 - val_f1: 0.1402\n",
      "Epoch 352/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2965 - f1: 0.6609 - val_loss: 0.3918 - val_f1: 0.1390\n",
      "Epoch 353/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2966 - f1: 0.6554 - val_loss: 0.3922 - val_f1: 0.1394\n",
      "Epoch 354/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2965 - f1: 0.6600 - val_loss: 0.3916 - val_f1: 0.1402\n",
      "Epoch 355/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2962 - f1: 0.6590 - val_loss: 0.3916 - val_f1: 0.1405\n",
      "Epoch 356/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2948 - f1: 0.6544 - val_loss: 0.3921 - val_f1: 0.1411\n",
      "Epoch 357/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2962 - f1: 0.6562 - val_loss: 0.3932 - val_f1: 0.1400\n",
      "Epoch 358/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2963 - f1: 0.6581 - val_loss: 0.3920 - val_f1: 0.1412\n",
      "Epoch 359/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2968 - f1: 0.6592 - val_loss: 0.3923 - val_f1: 0.1406\n",
      "Epoch 360/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2937 - f1: 0.6571 - val_loss: 0.3925 - val_f1: 0.1407\n",
      "Epoch 361/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2958 - f1: 0.6597 - val_loss: 0.3924 - val_f1: 0.1397\n",
      "Epoch 362/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2964 - f1: 0.6584 - val_loss: 0.3925 - val_f1: 0.1401\n",
      "Epoch 363/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2955 - f1: 0.6585 - val_loss: 0.3921 - val_f1: 0.1409\n",
      "Epoch 364/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2942 - f1: 0.6609 - val_loss: 0.3934 - val_f1: 0.1403\n",
      "Epoch 365/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2945 - f1: 0.6567 - val_loss: 0.3932 - val_f1: 0.1403\n",
      "Epoch 366/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2961 - f1: 0.6558 - val_loss: 0.3925 - val_f1: 0.1405\n",
      "Epoch 367/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2944 - f1: 0.6573 - val_loss: 0.3936 - val_f1: 0.1405\n",
      "Epoch 368/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2957 - f1: 0.6604 - val_loss: 0.3935 - val_f1: 0.1394\n",
      "Epoch 369/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2962 - f1: 0.6580 - val_loss: 0.3932 - val_f1: 0.1408\n",
      "Epoch 370/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2933 - f1: 0.6611 - val_loss: 0.3927 - val_f1: 0.1410\n",
      "Epoch 371/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2951 - f1: 0.6604 - val_loss: 0.3927 - val_f1: 0.1407\n",
      "Epoch 372/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2954 - f1: 0.6602 - val_loss: 0.3927 - val_f1: 0.1407\n",
      "Epoch 373/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2952 - f1: 0.6636 - val_loss: 0.3925 - val_f1: 0.1400\n",
      "Epoch 374/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2946 - f1: 0.6578 - val_loss: 0.3924 - val_f1: 0.1409\n",
      "Epoch 375/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2946 - f1: 0.6591 - val_loss: 0.3932 - val_f1: 0.1414\n",
      "Epoch 376/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2932 - f1: 0.6623 - val_loss: 0.3942 - val_f1: 0.1415\n",
      "Epoch 377/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2967 - f1: 0.6559 - val_loss: 0.3928 - val_f1: 0.1413\n",
      "Epoch 378/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2935 - f1: 0.6604 - val_loss: 0.3938 - val_f1: 0.1398\n",
      "Epoch 379/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2918 - f1: 0.6668 - val_loss: 0.3942 - val_f1: 0.1396\n",
      "Epoch 380/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2930 - f1: 0.6637 - val_loss: 0.3932 - val_f1: 0.1393\n",
      "Epoch 381/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2962 - f1: 0.6544 - val_loss: 0.3931 - val_f1: 0.1411\n",
      "Epoch 382/2000\n",
      "64440/64440 [==============================] - 2s 32us/step - loss: 0.2912 - f1: 0.6618 - val_loss: 0.3947 - val_f1: 0.1409\n",
      "Epoch 383/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2944 - f1: 0.6607 - val_loss: 0.3938 - val_f1: 0.1398\n",
      "Epoch 384/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2923 - f1: 0.6641 - val_loss: 0.3951 - val_f1: 0.1405\n",
      "Epoch 385/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2926 - f1: 0.6645 - val_loss: 0.3946 - val_f1: 0.1398\n",
      "Epoch 386/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2940 - f1: 0.6610 - val_loss: 0.3945 - val_f1: 0.1397\n",
      "Epoch 387/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2925 - f1: 0.6611 - val_loss: 0.3950 - val_f1: 0.1403\n",
      "Epoch 388/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2959 - f1: 0.6592 - val_loss: 0.3939 - val_f1: 0.1401\n",
      "Epoch 389/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2928 - f1: 0.6624 - val_loss: 0.3938 - val_f1: 0.1408\n",
      "Epoch 390/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2923 - f1: 0.6637 - val_loss: 0.3945 - val_f1: 0.1405\n",
      "Epoch 391/2000\n",
      "64440/64440 [==============================] - 2s 32us/step - loss: 0.2913 - f1: 0.6635 - val_loss: 0.3948 - val_f1: 0.1418\n",
      "Epoch 392/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2921 - f1: 0.6584 - val_loss: 0.3955 - val_f1: 0.1390\n",
      "Epoch 393/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2922 - f1: 0.6664 - val_loss: 0.3952 - val_f1: 0.1401\n",
      "Epoch 394/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2925 - f1: 0.6626 - val_loss: 0.3949 - val_f1: 0.1417\n",
      "Epoch 395/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2924 - f1: 0.6607 - val_loss: 0.3951 - val_f1: 0.1404\n",
      "Epoch 396/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2923 - f1: 0.6594 - val_loss: 0.3942 - val_f1: 0.1411\n",
      "Epoch 397/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2939 - f1: 0.6592 - val_loss: 0.3941 - val_f1: 0.1403\n",
      "Epoch 398/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2934 - f1: 0.6631 - val_loss: 0.3946 - val_f1: 0.1407\n",
      "Epoch 399/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2924 - f1: 0.6634 - val_loss: 0.3956 - val_f1: 0.1402\n",
      "Epoch 400/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2931 - f1: 0.6633 - val_loss: 0.3947 - val_f1: 0.1394\n",
      "Epoch 401/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2924 - f1: 0.6571 - val_loss: 0.3951 - val_f1: 0.1404\n",
      "Epoch 402/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2933 - f1: 0.6613 - val_loss: 0.3946 - val_f1: 0.1404\n",
      "Epoch 403/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2953 - f1: 0.6606 - val_loss: 0.3933 - val_f1: 0.1405\n",
      "Epoch 404/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2910 - f1: 0.6643 - val_loss: 0.3948 - val_f1: 0.1399\n",
      "Epoch 405/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2932 - f1: 0.6599 - val_loss: 0.3951 - val_f1: 0.1396\n",
      "Epoch 406/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2933 - f1: 0.6617 - val_loss: 0.3956 - val_f1: 0.1392\n",
      "Epoch 407/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2922 - f1: 0.6646 - val_loss: 0.3951 - val_f1: 0.1399\n",
      "Epoch 408/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2933 - f1: 0.6591 - val_loss: 0.3945 - val_f1: 0.1414\n",
      "Epoch 409/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2920 - f1: 0.6599 - val_loss: 0.3964 - val_f1: 0.1399\n",
      "Epoch 410/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2912 - f1: 0.6623 - val_loss: 0.3951 - val_f1: 0.1407\n",
      "Epoch 411/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2921 - f1: 0.6600 - val_loss: 0.3956 - val_f1: 0.1403\n",
      "Epoch 412/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2924 - f1: 0.6624 - val_loss: 0.3961 - val_f1: 0.1404\n",
      "Epoch 413/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2917 - f1: 0.6624 - val_loss: 0.3962 - val_f1: 0.1400\n",
      "Epoch 414/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2893 - f1: 0.6677 - val_loss: 0.3969 - val_f1: 0.1404\n",
      "Epoch 415/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2902 - f1: 0.6636 - val_loss: 0.3973 - val_f1: 0.1392\n",
      "Epoch 416/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2909 - f1: 0.6665 - val_loss: 0.3959 - val_f1: 0.1392\n",
      "Epoch 417/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2908 - f1: 0.6680 - val_loss: 0.3962 - val_f1: 0.1403\n",
      "Epoch 418/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2906 - f1: 0.6659 - val_loss: 0.3960 - val_f1: 0.1401\n",
      "Epoch 419/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2895 - f1: 0.6680 - val_loss: 0.3972 - val_f1: 0.1396\n",
      "Epoch 420/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2889 - f1: 0.6683 - val_loss: 0.3972 - val_f1: 0.1413\n",
      "Epoch 421/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2896 - f1: 0.6699 - val_loss: 0.3969 - val_f1: 0.1404\n",
      "Epoch 422/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2912 - f1: 0.6674 - val_loss: 0.3970 - val_f1: 0.1399\n",
      "Epoch 423/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2911 - f1: 0.6644 - val_loss: 0.3967 - val_f1: 0.1400\n",
      "Epoch 424/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2899 - f1: 0.6644 - val_loss: 0.3968 - val_f1: 0.1401\n",
      "Epoch 425/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2902 - f1: 0.6647 - val_loss: 0.3968 - val_f1: 0.1395\n",
      "Epoch 426/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2895 - f1: 0.6620 - val_loss: 0.3982 - val_f1: 0.1405\n",
      "Epoch 427/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2884 - f1: 0.6669 - val_loss: 0.3980 - val_f1: 0.1404\n",
      "Epoch 428/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2903 - f1: 0.6646 - val_loss: 0.3969 - val_f1: 0.1404\n",
      "Epoch 429/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2905 - f1: 0.6649 - val_loss: 0.3965 - val_f1: 0.1404\n",
      "Epoch 430/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2890 - f1: 0.6704 - val_loss: 0.3969 - val_f1: 0.1403\n",
      "Epoch 431/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2895 - f1: 0.6686 - val_loss: 0.3965 - val_f1: 0.1402\n",
      "Epoch 432/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2901 - f1: 0.6683 - val_loss: 0.3967 - val_f1: 0.1402\n",
      "Epoch 433/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2915 - f1: 0.6612 - val_loss: 0.3967 - val_f1: 0.1392\n",
      "Epoch 434/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2869 - f1: 0.6714 - val_loss: 0.3973 - val_f1: 0.1395\n",
      "Epoch 435/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2904 - f1: 0.6680 - val_loss: 0.3967 - val_f1: 0.1401\n",
      "Epoch 436/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2894 - f1: 0.6724 - val_loss: 0.3982 - val_f1: 0.1398\n",
      "Epoch 437/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2904 - f1: 0.6607 - val_loss: 0.3968 - val_f1: 0.1400\n",
      "Epoch 438/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2887 - f1: 0.6696 - val_loss: 0.3969 - val_f1: 0.1401\n",
      "Epoch 439/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2880 - f1: 0.6660 - val_loss: 0.3982 - val_f1: 0.1403\n",
      "Epoch 440/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2905 - f1: 0.6666 - val_loss: 0.3970 - val_f1: 0.1405\n",
      "Epoch 441/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2880 - f1: 0.6727 - val_loss: 0.3974 - val_f1: 0.1395\n",
      "Epoch 442/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2896 - f1: 0.6655 - val_loss: 0.3970 - val_f1: 0.1399\n",
      "Epoch 443/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2888 - f1: 0.6667 - val_loss: 0.3976 - val_f1: 0.1409\n",
      "Epoch 444/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2883 - f1: 0.6632 - val_loss: 0.3978 - val_f1: 0.1410\n",
      "Epoch 445/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2891 - f1: 0.6692 - val_loss: 0.3981 - val_f1: 0.1407\n",
      "Epoch 446/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2868 - f1: 0.6670 - val_loss: 0.3981 - val_f1: 0.1404\n",
      "Epoch 447/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2870 - f1: 0.6710 - val_loss: 0.3991 - val_f1: 0.1404\n",
      "Epoch 448/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2882 - f1: 0.6686 - val_loss: 0.3984 - val_f1: 0.1401\n",
      "Epoch 449/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2865 - f1: 0.6698 - val_loss: 0.3986 - val_f1: 0.1412\n",
      "Epoch 450/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2880 - f1: 0.6719 - val_loss: 0.3978 - val_f1: 0.1414\n",
      "Epoch 451/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2870 - f1: 0.6758 - val_loss: 0.3987 - val_f1: 0.1397\n",
      "Epoch 452/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2866 - f1: 0.6720 - val_loss: 0.3989 - val_f1: 0.1395\n",
      "Epoch 453/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2878 - f1: 0.6709 - val_loss: 0.3997 - val_f1: 0.1398\n",
      "Epoch 454/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2857 - f1: 0.6717 - val_loss: 0.3997 - val_f1: 0.1401\n",
      "Epoch 455/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2883 - f1: 0.6684 - val_loss: 0.3976 - val_f1: 0.1407\n",
      "Epoch 456/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2866 - f1: 0.6707 - val_loss: 0.3982 - val_f1: 0.1409\n",
      "Epoch 457/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2878 - f1: 0.6687 - val_loss: 0.3988 - val_f1: 0.1402\n",
      "Epoch 458/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2855 - f1: 0.6691 - val_loss: 0.3996 - val_f1: 0.1397\n",
      "Epoch 459/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2868 - f1: 0.6705 - val_loss: 0.3988 - val_f1: 0.1404\n",
      "Epoch 460/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2876 - f1: 0.6677 - val_loss: 0.3986 - val_f1: 0.1405\n",
      "Epoch 461/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2894 - f1: 0.6681 - val_loss: 0.3981 - val_f1: 0.1400\n",
      "Epoch 462/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2899 - f1: 0.6671 - val_loss: 0.3968 - val_f1: 0.1406\n",
      "Epoch 463/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2899 - f1: 0.6622 - val_loss: 0.3981 - val_f1: 0.1405\n",
      "Epoch 464/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2847 - f1: 0.6738 - val_loss: 0.3984 - val_f1: 0.1403\n",
      "Epoch 465/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2877 - f1: 0.6708 - val_loss: 0.3981 - val_f1: 0.1409\n",
      "Epoch 466/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2873 - f1: 0.6697 - val_loss: 0.3976 - val_f1: 0.1400\n",
      "Epoch 467/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2882 - f1: 0.6684 - val_loss: 0.3977 - val_f1: 0.1409\n",
      "Epoch 468/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2863 - f1: 0.6684 - val_loss: 0.3990 - val_f1: 0.1404\n",
      "Epoch 469/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2842 - f1: 0.6689 - val_loss: 0.4000 - val_f1: 0.1410\n",
      "Epoch 470/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2880 - f1: 0.6702 - val_loss: 0.3988 - val_f1: 0.1407\n",
      "Epoch 471/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2863 - f1: 0.6682 - val_loss: 0.3984 - val_f1: 0.1399\n",
      "Epoch 472/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2878 - f1: 0.6700 - val_loss: 0.3987 - val_f1: 0.1408\n",
      "Epoch 473/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2867 - f1: 0.6719 - val_loss: 0.3986 - val_f1: 0.1406\n",
      "Epoch 474/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2870 - f1: 0.6728 - val_loss: 0.3992 - val_f1: 0.1399\n",
      "Epoch 475/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2886 - f1: 0.6690 - val_loss: 0.3996 - val_f1: 0.1399\n",
      "Epoch 476/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2882 - f1: 0.6693 - val_loss: 0.3978 - val_f1: 0.1406\n",
      "Epoch 477/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2868 - f1: 0.6709 - val_loss: 0.3984 - val_f1: 0.1406\n",
      "Epoch 478/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2865 - f1: 0.6678 - val_loss: 0.3983 - val_f1: 0.1403\n",
      "Epoch 479/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2855 - f1: 0.6743 - val_loss: 0.3996 - val_f1: 0.1396\n",
      "Epoch 480/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2854 - f1: 0.6720 - val_loss: 0.3996 - val_f1: 0.1405\n",
      "Epoch 481/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2855 - f1: 0.6739 - val_loss: 0.3994 - val_f1: 0.1395\n",
      "Epoch 482/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2837 - f1: 0.6702 - val_loss: 0.4002 - val_f1: 0.1394\n",
      "Epoch 483/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2854 - f1: 0.6686 - val_loss: 0.4003 - val_f1: 0.1409\n",
      "Epoch 484/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2851 - f1: 0.6720 - val_loss: 0.3998 - val_f1: 0.1407\n",
      "Epoch 485/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2848 - f1: 0.6740 - val_loss: 0.4003 - val_f1: 0.1398\n",
      "Epoch 486/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2837 - f1: 0.6755 - val_loss: 0.4010 - val_f1: 0.1401\n",
      "Epoch 487/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2851 - f1: 0.6752 - val_loss: 0.3996 - val_f1: 0.1404\n",
      "Epoch 488/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2854 - f1: 0.6687 - val_loss: 0.4007 - val_f1: 0.1409\n",
      "Epoch 489/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2854 - f1: 0.6744 - val_loss: 0.3998 - val_f1: 0.1397\n",
      "Epoch 490/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2849 - f1: 0.6760 - val_loss: 0.4001 - val_f1: 0.1395\n",
      "Epoch 491/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2849 - f1: 0.6729 - val_loss: 0.3995 - val_f1: 0.1411\n",
      "Epoch 492/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2841 - f1: 0.6711 - val_loss: 0.4005 - val_f1: 0.1405\n",
      "Epoch 493/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2849 - f1: 0.6738 - val_loss: 0.4003 - val_f1: 0.1411\n",
      "Epoch 494/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2853 - f1: 0.6745 - val_loss: 0.3992 - val_f1: 0.1411\n",
      "Epoch 495/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2844 - f1: 0.6730 - val_loss: 0.3999 - val_f1: 0.1412\n",
      "Epoch 496/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2852 - f1: 0.6745 - val_loss: 0.4008 - val_f1: 0.1397\n",
      "Epoch 497/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2823 - f1: 0.6776 - val_loss: 0.4010 - val_f1: 0.1410\n",
      "Epoch 498/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2842 - f1: 0.6739 - val_loss: 0.4006 - val_f1: 0.1407\n",
      "Epoch 499/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2834 - f1: 0.6792 - val_loss: 0.4007 - val_f1: 0.1410\n",
      "Epoch 500/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2841 - f1: 0.6771 - val_loss: 0.4007 - val_f1: 0.1405\n",
      "Epoch 501/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2846 - f1: 0.6734 - val_loss: 0.4006 - val_f1: 0.1409\n",
      "Epoch 502/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2865 - f1: 0.6662 - val_loss: 0.3996 - val_f1: 0.1414\n",
      "Epoch 503/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2838 - f1: 0.6759 - val_loss: 0.4000 - val_f1: 0.1415\n",
      "Epoch 504/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2842 - f1: 0.6733 - val_loss: 0.4005 - val_f1: 0.1407\n",
      "Epoch 505/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2832 - f1: 0.6805 - val_loss: 0.4009 - val_f1: 0.1413\n",
      "Epoch 506/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2847 - f1: 0.6780 - val_loss: 0.4013 - val_f1: 0.1410\n",
      "Epoch 507/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2839 - f1: 0.6754 - val_loss: 0.4011 - val_f1: 0.1407\n",
      "Epoch 508/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2834 - f1: 0.6760 - val_loss: 0.4007 - val_f1: 0.1409\n",
      "Epoch 509/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2839 - f1: 0.6732 - val_loss: 0.4006 - val_f1: 0.1404\n",
      "Epoch 510/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2862 - f1: 0.6706 - val_loss: 0.3997 - val_f1: 0.1420\n",
      "Epoch 511/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2847 - f1: 0.6745 - val_loss: 0.4005 - val_f1: 0.1407\n",
      "Epoch 512/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2839 - f1: 0.6754 - val_loss: 0.4014 - val_f1: 0.1400\n",
      "Epoch 513/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2860 - f1: 0.6746 - val_loss: 0.4009 - val_f1: 0.1403\n",
      "Epoch 514/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2832 - f1: 0.6764 - val_loss: 0.4010 - val_f1: 0.1411\n",
      "Epoch 515/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2842 - f1: 0.6745 - val_loss: 0.4013 - val_f1: 0.1396\n",
      "Epoch 516/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2836 - f1: 0.6760 - val_loss: 0.4014 - val_f1: 0.1412\n",
      "Epoch 517/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2845 - f1: 0.6791 - val_loss: 0.4007 - val_f1: 0.1405\n",
      "Epoch 518/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2846 - f1: 0.6733 - val_loss: 0.4005 - val_f1: 0.1414\n",
      "Epoch 519/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2835 - f1: 0.6738 - val_loss: 0.4003 - val_f1: 0.1413\n",
      "Epoch 520/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2837 - f1: 0.6736 - val_loss: 0.4016 - val_f1: 0.1404\n",
      "Epoch 521/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2830 - f1: 0.6784 - val_loss: 0.4018 - val_f1: 0.1395\n",
      "Epoch 522/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2832 - f1: 0.6787 - val_loss: 0.4020 - val_f1: 0.1404\n",
      "Epoch 523/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2849 - f1: 0.6746 - val_loss: 0.4011 - val_f1: 0.1401\n",
      "Epoch 524/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2832 - f1: 0.6774 - val_loss: 0.4009 - val_f1: 0.1419\n",
      "Epoch 525/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2808 - f1: 0.6790 - val_loss: 0.4030 - val_f1: 0.1402\n",
      "Epoch 526/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2833 - f1: 0.6770 - val_loss: 0.4022 - val_f1: 0.1406\n",
      "Epoch 527/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2830 - f1: 0.6783 - val_loss: 0.4019 - val_f1: 0.1411\n",
      "Epoch 528/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2830 - f1: 0.6746 - val_loss: 0.4019 - val_f1: 0.1404\n",
      "Epoch 529/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2808 - f1: 0.6776 - val_loss: 0.4027 - val_f1: 0.1416\n",
      "Epoch 530/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2804 - f1: 0.6803 - val_loss: 0.4029 - val_f1: 0.1415\n",
      "Epoch 531/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2827 - f1: 0.6770 - val_loss: 0.4029 - val_f1: 0.1407\n",
      "Epoch 532/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2827 - f1: 0.6725 - val_loss: 0.4023 - val_f1: 0.1388\n",
      "Epoch 533/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2824 - f1: 0.6726 - val_loss: 0.4021 - val_f1: 0.1404\n",
      "Epoch 534/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2830 - f1: 0.6754 - val_loss: 0.4023 - val_f1: 0.1414\n",
      "Epoch 535/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2823 - f1: 0.6772 - val_loss: 0.4016 - val_f1: 0.1408\n",
      "Epoch 536/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2799 - f1: 0.6819 - val_loss: 0.4024 - val_f1: 0.1412\n",
      "Epoch 537/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2827 - f1: 0.6784 - val_loss: 0.4026 - val_f1: 0.1405\n",
      "Epoch 538/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2827 - f1: 0.6791 - val_loss: 0.4026 - val_f1: 0.1402\n",
      "Epoch 539/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2838 - f1: 0.6740 - val_loss: 0.4032 - val_f1: 0.1394\n",
      "Epoch 540/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2829 - f1: 0.6744 - val_loss: 0.4026 - val_f1: 0.1406\n",
      "Epoch 541/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2821 - f1: 0.6788 - val_loss: 0.4021 - val_f1: 0.1414\n",
      "Epoch 542/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2823 - f1: 0.6795 - val_loss: 0.4026 - val_f1: 0.1403\n",
      "Epoch 543/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2827 - f1: 0.6733 - val_loss: 0.4028 - val_f1: 0.1405\n",
      "Epoch 544/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2820 - f1: 0.6776 - val_loss: 0.4030 - val_f1: 0.1407\n",
      "Epoch 545/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2815 - f1: 0.6789 - val_loss: 0.4034 - val_f1: 0.1407\n",
      "Epoch 546/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2818 - f1: 0.6791 - val_loss: 0.4034 - val_f1: 0.1410\n",
      "Epoch 547/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2830 - f1: 0.6747 - val_loss: 0.4032 - val_f1: 0.1410\n",
      "Epoch 548/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2800 - f1: 0.6790 - val_loss: 0.4047 - val_f1: 0.1401\n",
      "Epoch 549/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2794 - f1: 0.6829 - val_loss: 0.4044 - val_f1: 0.1395\n",
      "Epoch 550/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2817 - f1: 0.6782 - val_loss: 0.4040 - val_f1: 0.1399\n",
      "Epoch 551/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2809 - f1: 0.6775 - val_loss: 0.4029 - val_f1: 0.1407\n",
      "Epoch 552/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2808 - f1: 0.6754 - val_loss: 0.4029 - val_f1: 0.1408\n",
      "Epoch 553/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2816 - f1: 0.6812 - val_loss: 0.4031 - val_f1: 0.1411\n",
      "Epoch 554/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2821 - f1: 0.6783 - val_loss: 0.4033 - val_f1: 0.1401\n",
      "Epoch 555/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2818 - f1: 0.6787 - val_loss: 0.4027 - val_f1: 0.1404\n",
      "Epoch 556/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2798 - f1: 0.6811 - val_loss: 0.4037 - val_f1: 0.1405\n",
      "Epoch 557/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2814 - f1: 0.6778 - val_loss: 0.4048 - val_f1: 0.1402\n",
      "Epoch 558/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2810 - f1: 0.6800 - val_loss: 0.4040 - val_f1: 0.1404\n",
      "Epoch 559/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2823 - f1: 0.6758 - val_loss: 0.4037 - val_f1: 0.1404\n",
      "Epoch 560/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2814 - f1: 0.6781 - val_loss: 0.4028 - val_f1: 0.1398\n",
      "Epoch 561/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2801 - f1: 0.6758 - val_loss: 0.4040 - val_f1: 0.1401\n",
      "Epoch 562/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2810 - f1: 0.6758 - val_loss: 0.4040 - val_f1: 0.1408\n",
      "Epoch 563/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2824 - f1: 0.6802 - val_loss: 0.4042 - val_f1: 0.1408\n",
      "Epoch 564/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2794 - f1: 0.6785 - val_loss: 0.4044 - val_f1: 0.1404\n",
      "Epoch 565/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2824 - f1: 0.6787 - val_loss: 0.4040 - val_f1: 0.1398\n",
      "Epoch 566/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2798 - f1: 0.6830 - val_loss: 0.4048 - val_f1: 0.1398\n",
      "Epoch 567/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2793 - f1: 0.6839 - val_loss: 0.4054 - val_f1: 0.1406\n",
      "Epoch 568/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2807 - f1: 0.6826 - val_loss: 0.4034 - val_f1: 0.1403\n",
      "Epoch 569/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2798 - f1: 0.6825 - val_loss: 0.4049 - val_f1: 0.1405\n",
      "Epoch 570/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2792 - f1: 0.6812 - val_loss: 0.4048 - val_f1: 0.1403\n",
      "Epoch 571/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2807 - f1: 0.6790 - val_loss: 0.4043 - val_f1: 0.1400\n",
      "Epoch 572/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2821 - f1: 0.6741 - val_loss: 0.4044 - val_f1: 0.1404\n",
      "Epoch 573/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2788 - f1: 0.6882 - val_loss: 0.4043 - val_f1: 0.1407\n",
      "Epoch 574/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2815 - f1: 0.6795 - val_loss: 0.4042 - val_f1: 0.1417\n",
      "Epoch 575/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2796 - f1: 0.6807 - val_loss: 0.4042 - val_f1: 0.1407\n",
      "Epoch 576/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2809 - f1: 0.6792 - val_loss: 0.4029 - val_f1: 0.1407\n",
      "Epoch 577/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2788 - f1: 0.6815 - val_loss: 0.4057 - val_f1: 0.1405\n",
      "Epoch 578/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2808 - f1: 0.6770 - val_loss: 0.4040 - val_f1: 0.1413\n",
      "Epoch 579/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2787 - f1: 0.6829 - val_loss: 0.4043 - val_f1: 0.1419\n",
      "Epoch 580/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2808 - f1: 0.6852 - val_loss: 0.4043 - val_f1: 0.1403\n",
      "Epoch 581/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2787 - f1: 0.6773 - val_loss: 0.4052 - val_f1: 0.1400\n",
      "Epoch 582/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2800 - f1: 0.6819 - val_loss: 0.4050 - val_f1: 0.1403\n",
      "Epoch 583/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2811 - f1: 0.6836 - val_loss: 0.4038 - val_f1: 0.1405\n",
      "Epoch 584/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2796 - f1: 0.6857 - val_loss: 0.4042 - val_f1: 0.1407\n",
      "Epoch 585/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2796 - f1: 0.6779 - val_loss: 0.4050 - val_f1: 0.1394\n",
      "Epoch 586/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2828 - f1: 0.6741 - val_loss: 0.4053 - val_f1: 0.1403\n",
      "Epoch 587/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2782 - f1: 0.6832 - val_loss: 0.4059 - val_f1: 0.1415\n",
      "Epoch 588/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2792 - f1: 0.6840 - val_loss: 0.4051 - val_f1: 0.1415\n",
      "Epoch 589/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2788 - f1: 0.6826 - val_loss: 0.4055 - val_f1: 0.1415\n",
      "Epoch 590/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2796 - f1: 0.6832 - val_loss: 0.4049 - val_f1: 0.1411\n",
      "Epoch 591/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2798 - f1: 0.6844 - val_loss: 0.4042 - val_f1: 0.1406\n",
      "Epoch 592/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2813 - f1: 0.6809 - val_loss: 0.4040 - val_f1: 0.1404\n",
      "Epoch 593/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2787 - f1: 0.6841 - val_loss: 0.4055 - val_f1: 0.1409\n",
      "Epoch 594/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2801 - f1: 0.6812 - val_loss: 0.4047 - val_f1: 0.1404\n",
      "Epoch 595/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2796 - f1: 0.6808 - val_loss: 0.4046 - val_f1: 0.1412\n",
      "Epoch 596/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2789 - f1: 0.6869 - val_loss: 0.4043 - val_f1: 0.1409\n",
      "Epoch 597/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2797 - f1: 0.6815 - val_loss: 0.4051 - val_f1: 0.1404\n",
      "Epoch 598/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2799 - f1: 0.6828 - val_loss: 0.4053 - val_f1: 0.1403\n",
      "Epoch 599/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2801 - f1: 0.6798 - val_loss: 0.4055 - val_f1: 0.1407\n",
      "Epoch 600/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2772 - f1: 0.6868 - val_loss: 0.4062 - val_f1: 0.1398\n",
      "Epoch 601/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2800 - f1: 0.6835 - val_loss: 0.4061 - val_f1: 0.1409\n",
      "Epoch 602/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2777 - f1: 0.6836 - val_loss: 0.4053 - val_f1: 0.1407\n",
      "Epoch 603/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2790 - f1: 0.6826 - val_loss: 0.4065 - val_f1: 0.1404\n",
      "Epoch 604/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2791 - f1: 0.6812 - val_loss: 0.4057 - val_f1: 0.1414\n",
      "Epoch 605/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2787 - f1: 0.6813 - val_loss: 0.4053 - val_f1: 0.1406\n",
      "Epoch 606/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2788 - f1: 0.6809 - val_loss: 0.4043 - val_f1: 0.1409\n",
      "Epoch 607/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2796 - f1: 0.6802 - val_loss: 0.4049 - val_f1: 0.1410\n",
      "Epoch 608/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2815 - f1: 0.6762 - val_loss: 0.4041 - val_f1: 0.1412\n",
      "Epoch 609/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2798 - f1: 0.6784 - val_loss: 0.4046 - val_f1: 0.1410\n",
      "Epoch 610/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2774 - f1: 0.6866 - val_loss: 0.4058 - val_f1: 0.1401\n",
      "Epoch 611/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2785 - f1: 0.6821 - val_loss: 0.4061 - val_f1: 0.1409\n",
      "Epoch 612/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2773 - f1: 0.6911 - val_loss: 0.4060 - val_f1: 0.1411\n",
      "Epoch 613/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2779 - f1: 0.6801 - val_loss: 0.4065 - val_f1: 0.1410\n",
      "Epoch 614/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2787 - f1: 0.6815 - val_loss: 0.4056 - val_f1: 0.1392\n",
      "Epoch 615/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2773 - f1: 0.6863 - val_loss: 0.4062 - val_f1: 0.1401\n",
      "Epoch 616/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2774 - f1: 0.6801 - val_loss: 0.4059 - val_f1: 0.1418\n",
      "Epoch 617/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2779 - f1: 0.6844 - val_loss: 0.4065 - val_f1: 0.1408\n",
      "Epoch 618/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2778 - f1: 0.6856 - val_loss: 0.4058 - val_f1: 0.1418\n",
      "Epoch 619/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2779 - f1: 0.6849 - val_loss: 0.4057 - val_f1: 0.1413\n",
      "Epoch 620/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2802 - f1: 0.6780 - val_loss: 0.4058 - val_f1: 0.1409\n",
      "Epoch 621/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2791 - f1: 0.6822 - val_loss: 0.4064 - val_f1: 0.1398\n",
      "Epoch 622/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2801 - f1: 0.6803 - val_loss: 0.4048 - val_f1: 0.1405\n",
      "Epoch 623/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2766 - f1: 0.6871 - val_loss: 0.4060 - val_f1: 0.1412\n",
      "Epoch 624/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2757 - f1: 0.6880 - val_loss: 0.4067 - val_f1: 0.1402\n",
      "Epoch 625/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2785 - f1: 0.6830 - val_loss: 0.4064 - val_f1: 0.1398\n",
      "Epoch 626/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2796 - f1: 0.6833 - val_loss: 0.4062 - val_f1: 0.1406\n",
      "Epoch 627/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2796 - f1: 0.6833 - val_loss: 0.4053 - val_f1: 0.1413\n",
      "Epoch 628/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2785 - f1: 0.6857 - val_loss: 0.4054 - val_f1: 0.1406\n",
      "Epoch 629/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2795 - f1: 0.6848 - val_loss: 0.4052 - val_f1: 0.1409\n",
      "Epoch 630/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2777 - f1: 0.6865 - val_loss: 0.4066 - val_f1: 0.1409\n",
      "Epoch 631/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2779 - f1: 0.6891 - val_loss: 0.4060 - val_f1: 0.1405\n",
      "Epoch 632/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2764 - f1: 0.6863 - val_loss: 0.4061 - val_f1: 0.1406\n",
      "Epoch 633/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2775 - f1: 0.6850 - val_loss: 0.4065 - val_f1: 0.1409\n",
      "Epoch 634/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2802 - f1: 0.6814 - val_loss: 0.4057 - val_f1: 0.1412\n",
      "Epoch 635/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2794 - f1: 0.6840 - val_loss: 0.4054 - val_f1: 0.1403\n",
      "Epoch 636/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2790 - f1: 0.6812 - val_loss: 0.4058 - val_f1: 0.1405\n",
      "Epoch 637/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2780 - f1: 0.6798 - val_loss: 0.4055 - val_f1: 0.1411\n",
      "Epoch 638/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2756 - f1: 0.6888 - val_loss: 0.4070 - val_f1: 0.1410\n",
      "Epoch 639/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2754 - f1: 0.6853 - val_loss: 0.4083 - val_f1: 0.1416\n",
      "Epoch 640/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2778 - f1: 0.6842 - val_loss: 0.4068 - val_f1: 0.1411\n",
      "Epoch 641/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2772 - f1: 0.6867 - val_loss: 0.4065 - val_f1: 0.1413\n",
      "Epoch 642/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2773 - f1: 0.6832 - val_loss: 0.4071 - val_f1: 0.1408\n",
      "Epoch 643/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2776 - f1: 0.6820 - val_loss: 0.4065 - val_f1: 0.1410\n",
      "Epoch 644/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2773 - f1: 0.6821 - val_loss: 0.4071 - val_f1: 0.1408\n",
      "Epoch 645/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2790 - f1: 0.6831 - val_loss: 0.4055 - val_f1: 0.1407\n",
      "Epoch 646/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2777 - f1: 0.6860 - val_loss: 0.4060 - val_f1: 0.1408\n",
      "Epoch 647/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2785 - f1: 0.6840 - val_loss: 0.4060 - val_f1: 0.1409\n",
      "Epoch 648/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2763 - f1: 0.6798 - val_loss: 0.4066 - val_f1: 0.1405\n",
      "Epoch 649/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2765 - f1: 0.6816 - val_loss: 0.4065 - val_f1: 0.1415\n",
      "Epoch 650/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2783 - f1: 0.6845 - val_loss: 0.4062 - val_f1: 0.1412\n",
      "Epoch 651/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2733 - f1: 0.6851 - val_loss: 0.4088 - val_f1: 0.1409\n",
      "Epoch 652/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2770 - f1: 0.6835 - val_loss: 0.4058 - val_f1: 0.1405\n",
      "Epoch 653/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2769 - f1: 0.6866 - val_loss: 0.4077 - val_f1: 0.1399\n",
      "Epoch 654/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2758 - f1: 0.6843 - val_loss: 0.4082 - val_f1: 0.1400\n",
      "Epoch 655/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2769 - f1: 0.6867 - val_loss: 0.4072 - val_f1: 0.1397\n",
      "Epoch 656/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2760 - f1: 0.6852 - val_loss: 0.4075 - val_f1: 0.1405\n",
      "Epoch 657/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2771 - f1: 0.6865 - val_loss: 0.4082 - val_f1: 0.1411\n",
      "Epoch 658/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2750 - f1: 0.6875 - val_loss: 0.4083 - val_f1: 0.1404\n",
      "Epoch 659/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2788 - f1: 0.6819 - val_loss: 0.4061 - val_f1: 0.1416\n",
      "Epoch 660/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2763 - f1: 0.6875 - val_loss: 0.4076 - val_f1: 0.1397\n",
      "Epoch 661/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2765 - f1: 0.6848 - val_loss: 0.4067 - val_f1: 0.1415\n",
      "Epoch 662/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2788 - f1: 0.6844 - val_loss: 0.4064 - val_f1: 0.1400\n",
      "Epoch 663/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2762 - f1: 0.6862 - val_loss: 0.4077 - val_f1: 0.1404\n",
      "Epoch 664/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2761 - f1: 0.6834 - val_loss: 0.4083 - val_f1: 0.1411\n",
      "Epoch 665/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2765 - f1: 0.6916 - val_loss: 0.4080 - val_f1: 0.1410\n",
      "Epoch 666/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2771 - f1: 0.6845 - val_loss: 0.4075 - val_f1: 0.1406\n",
      "Epoch 667/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2745 - f1: 0.6901 - val_loss: 0.4085 - val_f1: 0.1412\n",
      "Epoch 668/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2763 - f1: 0.6887 - val_loss: 0.4081 - val_f1: 0.1403\n",
      "Epoch 669/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2755 - f1: 0.6891 - val_loss: 0.4083 - val_f1: 0.1413\n",
      "Epoch 670/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2774 - f1: 0.6874 - val_loss: 0.4071 - val_f1: 0.1405\n",
      "Epoch 671/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2744 - f1: 0.6910 - val_loss: 0.4086 - val_f1: 0.1403\n",
      "Epoch 672/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2757 - f1: 0.6876 - val_loss: 0.4085 - val_f1: 0.1403\n",
      "Epoch 673/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2752 - f1: 0.6827 - val_loss: 0.4076 - val_f1: 0.1410\n",
      "Epoch 674/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2781 - f1: 0.6829 - val_loss: 0.4070 - val_f1: 0.1407\n",
      "Epoch 675/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2756 - f1: 0.6865 - val_loss: 0.4081 - val_f1: 0.1414\n",
      "Epoch 676/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2744 - f1: 0.6921 - val_loss: 0.4083 - val_f1: 0.1409\n",
      "Epoch 677/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2743 - f1: 0.6915 - val_loss: 0.4085 - val_f1: 0.1399\n",
      "Epoch 678/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2747 - f1: 0.6871 - val_loss: 0.4087 - val_f1: 0.1405\n",
      "Epoch 679/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2751 - f1: 0.6854 - val_loss: 0.4083 - val_f1: 0.1412\n",
      "Epoch 680/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2766 - f1: 0.6882 - val_loss: 0.4076 - val_f1: 0.1400\n",
      "Epoch 681/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2780 - f1: 0.6856 - val_loss: 0.4075 - val_f1: 0.1411\n",
      "Epoch 682/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2755 - f1: 0.6908 - val_loss: 0.4084 - val_f1: 0.1400\n",
      "Epoch 683/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2758 - f1: 0.6837 - val_loss: 0.4071 - val_f1: 0.1411\n",
      "Epoch 684/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2763 - f1: 0.6846 - val_loss: 0.4079 - val_f1: 0.1413\n",
      "Epoch 685/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2758 - f1: 0.6848 - val_loss: 0.4080 - val_f1: 0.1417\n",
      "Epoch 686/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2756 - f1: 0.6863 - val_loss: 0.4092 - val_f1: 0.1411\n",
      "Epoch 687/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2753 - f1: 0.6845 - val_loss: 0.4091 - val_f1: 0.1412\n",
      "Epoch 688/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2733 - f1: 0.6938 - val_loss: 0.4093 - val_f1: 0.1412\n",
      "Epoch 689/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2753 - f1: 0.6880 - val_loss: 0.4082 - val_f1: 0.1393\n",
      "Epoch 690/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2748 - f1: 0.6903 - val_loss: 0.4086 - val_f1: 0.1406\n",
      "Epoch 691/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2758 - f1: 0.6892 - val_loss: 0.4069 - val_f1: 0.1410\n",
      "Epoch 692/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2745 - f1: 0.6880 - val_loss: 0.4088 - val_f1: 0.1412\n",
      "Epoch 693/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2745 - f1: 0.6901 - val_loss: 0.4080 - val_f1: 0.1411\n",
      "Epoch 694/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2740 - f1: 0.6896 - val_loss: 0.4086 - val_f1: 0.1416\n",
      "Epoch 695/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2754 - f1: 0.6847 - val_loss: 0.4090 - val_f1: 0.1406\n",
      "Epoch 696/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2749 - f1: 0.6891 - val_loss: 0.4088 - val_f1: 0.1414\n",
      "Epoch 697/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2747 - f1: 0.6890 - val_loss: 0.4090 - val_f1: 0.1409\n",
      "Epoch 698/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2729 - f1: 0.6922 - val_loss: 0.4095 - val_f1: 0.1409\n",
      "Epoch 699/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2740 - f1: 0.6900 - val_loss: 0.4087 - val_f1: 0.1415\n",
      "Epoch 700/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2758 - f1: 0.6880 - val_loss: 0.4088 - val_f1: 0.1406\n",
      "Epoch 701/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2740 - f1: 0.6913 - val_loss: 0.4091 - val_f1: 0.1410\n",
      "Epoch 702/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2774 - f1: 0.6811 - val_loss: 0.4074 - val_f1: 0.1412\n",
      "Epoch 703/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2745 - f1: 0.6878 - val_loss: 0.4090 - val_f1: 0.1413\n",
      "Epoch 704/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2769 - f1: 0.6884 - val_loss: 0.4088 - val_f1: 0.1399\n",
      "Epoch 705/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2752 - f1: 0.6892 - val_loss: 0.4080 - val_f1: 0.1408\n",
      "Epoch 706/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2717 - f1: 0.6918 - val_loss: 0.4104 - val_f1: 0.1402\n",
      "Epoch 707/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2743 - f1: 0.6921 - val_loss: 0.4100 - val_f1: 0.1402\n",
      "Epoch 708/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2748 - f1: 0.6930 - val_loss: 0.4084 - val_f1: 0.1408\n",
      "Epoch 709/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2751 - f1: 0.6916 - val_loss: 0.4084 - val_f1: 0.1409\n",
      "Epoch 710/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2741 - f1: 0.6948 - val_loss: 0.4086 - val_f1: 0.1406\n",
      "Epoch 711/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2720 - f1: 0.6927 - val_loss: 0.4095 - val_f1: 0.1416\n",
      "Epoch 712/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2746 - f1: 0.6861 - val_loss: 0.4092 - val_f1: 0.1406\n",
      "Epoch 713/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2750 - f1: 0.6901 - val_loss: 0.4091 - val_f1: 0.1411\n",
      "Epoch 714/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2746 - f1: 0.6916 - val_loss: 0.4096 - val_f1: 0.1409\n",
      "Epoch 715/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2738 - f1: 0.6882 - val_loss: 0.4088 - val_f1: 0.1418\n",
      "Epoch 716/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2730 - f1: 0.6906 - val_loss: 0.4092 - val_f1: 0.1411\n",
      "Epoch 717/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2729 - f1: 0.6953 - val_loss: 0.4101 - val_f1: 0.1408\n",
      "Epoch 718/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2726 - f1: 0.6954 - val_loss: 0.4105 - val_f1: 0.1408\n",
      "Epoch 719/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2753 - f1: 0.6891 - val_loss: 0.4088 - val_f1: 0.1405\n",
      "Epoch 720/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2724 - f1: 0.6901 - val_loss: 0.4088 - val_f1: 0.1413\n",
      "Epoch 721/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2762 - f1: 0.6846 - val_loss: 0.4076 - val_f1: 0.1416\n",
      "Epoch 722/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2733 - f1: 0.6896 - val_loss: 0.4092 - val_f1: 0.1413\n",
      "Epoch 723/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2730 - f1: 0.6941 - val_loss: 0.4101 - val_f1: 0.1409\n",
      "Epoch 724/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2746 - f1: 0.6889 - val_loss: 0.4099 - val_f1: 0.1412\n",
      "Epoch 725/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2739 - f1: 0.6889 - val_loss: 0.4092 - val_f1: 0.1411\n",
      "Epoch 726/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2732 - f1: 0.6845 - val_loss: 0.4100 - val_f1: 0.1404\n",
      "Epoch 727/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2750 - f1: 0.6860 - val_loss: 0.4095 - val_f1: 0.1406\n",
      "Epoch 728/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2735 - f1: 0.6908 - val_loss: 0.4096 - val_f1: 0.1410\n",
      "Epoch 729/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2729 - f1: 0.6904 - val_loss: 0.4094 - val_f1: 0.1405\n",
      "Epoch 730/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2751 - f1: 0.6911 - val_loss: 0.4099 - val_f1: 0.1408\n",
      "Epoch 731/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2742 - f1: 0.6870 - val_loss: 0.4095 - val_f1: 0.1413\n",
      "Epoch 732/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2735 - f1: 0.6921 - val_loss: 0.4097 - val_f1: 0.1412\n",
      "Epoch 733/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2738 - f1: 0.6894 - val_loss: 0.4091 - val_f1: 0.1406\n",
      "Epoch 734/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2740 - f1: 0.6878 - val_loss: 0.4082 - val_f1: 0.1418\n",
      "Epoch 735/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2737 - f1: 0.6925 - val_loss: 0.4093 - val_f1: 0.1415\n",
      "Epoch 736/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2738 - f1: 0.6896 - val_loss: 0.4097 - val_f1: 0.1411\n",
      "Epoch 737/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2717 - f1: 0.6940 - val_loss: 0.4102 - val_f1: 0.1410\n",
      "Epoch 738/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2737 - f1: 0.6871 - val_loss: 0.4096 - val_f1: 0.1409\n",
      "Epoch 739/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2731 - f1: 0.6923 - val_loss: 0.4088 - val_f1: 0.1410\n",
      "Epoch 740/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2713 - f1: 0.6966 - val_loss: 0.4095 - val_f1: 0.1408\n",
      "Epoch 741/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2731 - f1: 0.6913 - val_loss: 0.4096 - val_f1: 0.1414\n",
      "Epoch 742/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2732 - f1: 0.6888 - val_loss: 0.4102 - val_f1: 0.1414\n",
      "Epoch 743/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2770 - f1: 0.6840 - val_loss: 0.4081 - val_f1: 0.1410\n",
      "Epoch 744/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2729 - f1: 0.6911 - val_loss: 0.4100 - val_f1: 0.1405\n",
      "Epoch 745/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2757 - f1: 0.6850 - val_loss: 0.4095 - val_f1: 0.1409\n",
      "Epoch 746/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2745 - f1: 0.6907 - val_loss: 0.4103 - val_f1: 0.1399\n",
      "Epoch 747/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2735 - f1: 0.6910 - val_loss: 0.4101 - val_f1: 0.1406\n",
      "Epoch 748/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2734 - f1: 0.6954 - val_loss: 0.4097 - val_f1: 0.1413\n",
      "Epoch 749/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2719 - f1: 0.6935 - val_loss: 0.4111 - val_f1: 0.1408\n",
      "Epoch 750/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2727 - f1: 0.6973 - val_loss: 0.4100 - val_f1: 0.1411\n",
      "Epoch 751/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2720 - f1: 0.6936 - val_loss: 0.4096 - val_f1: 0.1418\n",
      "Epoch 752/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2725 - f1: 0.6938 - val_loss: 0.4108 - val_f1: 0.1416\n",
      "Epoch 753/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2726 - f1: 0.6923 - val_loss: 0.4099 - val_f1: 0.1408\n",
      "Epoch 754/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2716 - f1: 0.6949 - val_loss: 0.4113 - val_f1: 0.1405\n",
      "Epoch 755/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2723 - f1: 0.6887 - val_loss: 0.4108 - val_f1: 0.1405\n",
      "Epoch 756/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2722 - f1: 0.6912 - val_loss: 0.4111 - val_f1: 0.1404\n",
      "Epoch 757/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2707 - f1: 0.6951 - val_loss: 0.4111 - val_f1: 0.1405\n",
      "Epoch 758/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2727 - f1: 0.6910 - val_loss: 0.4100 - val_f1: 0.1419\n",
      "Epoch 759/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2726 - f1: 0.6927 - val_loss: 0.4104 - val_f1: 0.1405\n",
      "Epoch 760/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2745 - f1: 0.6878 - val_loss: 0.4097 - val_f1: 0.1419\n",
      "Epoch 761/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2708 - f1: 0.6941 - val_loss: 0.4116 - val_f1: 0.1418\n",
      "Epoch 762/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2717 - f1: 0.6922 - val_loss: 0.4108 - val_f1: 0.1406\n",
      "Epoch 763/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2717 - f1: 0.6931 - val_loss: 0.4102 - val_f1: 0.1416\n",
      "Epoch 764/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2721 - f1: 0.6926 - val_loss: 0.4110 - val_f1: 0.1403\n",
      "Epoch 765/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2725 - f1: 0.6912 - val_loss: 0.4114 - val_f1: 0.1407\n",
      "Epoch 766/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2743 - f1: 0.6914 - val_loss: 0.4096 - val_f1: 0.1415\n",
      "Epoch 767/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2726 - f1: 0.6910 - val_loss: 0.4103 - val_f1: 0.1409\n",
      "Epoch 768/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2725 - f1: 0.6919 - val_loss: 0.4107 - val_f1: 0.1410\n",
      "Epoch 769/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2710 - f1: 0.6940 - val_loss: 0.4109 - val_f1: 0.1412\n",
      "Epoch 770/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2716 - f1: 0.6924 - val_loss: 0.4107 - val_f1: 0.1409\n",
      "Epoch 771/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2733 - f1: 0.6926 - val_loss: 0.4104 - val_f1: 0.1411\n",
      "Epoch 772/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2735 - f1: 0.6923 - val_loss: 0.4114 - val_f1: 0.1406\n",
      "Epoch 773/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2744 - f1: 0.6905 - val_loss: 0.4100 - val_f1: 0.1404\n",
      "Epoch 774/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2708 - f1: 0.6922 - val_loss: 0.4108 - val_f1: 0.1403\n",
      "Epoch 775/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2741 - f1: 0.6873 - val_loss: 0.4102 - val_f1: 0.1410\n",
      "Epoch 776/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2700 - f1: 0.6969 - val_loss: 0.4118 - val_f1: 0.1405\n",
      "Epoch 777/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2726 - f1: 0.6910 - val_loss: 0.4120 - val_f1: 0.1406\n",
      "Epoch 778/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2704 - f1: 0.6955 - val_loss: 0.4111 - val_f1: 0.1420\n",
      "Epoch 779/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2724 - f1: 0.6918 - val_loss: 0.4111 - val_f1: 0.1414\n",
      "Epoch 780/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2717 - f1: 0.6965 - val_loss: 0.4116 - val_f1: 0.1401\n",
      "Epoch 781/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2718 - f1: 0.6932 - val_loss: 0.4111 - val_f1: 0.1408\n",
      "Epoch 782/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2691 - f1: 0.6965 - val_loss: 0.4119 - val_f1: 0.1409\n",
      "Epoch 783/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2730 - f1: 0.6896 - val_loss: 0.4111 - val_f1: 0.1407\n",
      "Epoch 784/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2713 - f1: 0.6941 - val_loss: 0.4123 - val_f1: 0.1407\n",
      "Epoch 785/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2698 - f1: 0.6976 - val_loss: 0.4122 - val_f1: 0.1410\n",
      "Epoch 786/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2723 - f1: 0.6949 - val_loss: 0.4104 - val_f1: 0.1403\n",
      "Epoch 787/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2728 - f1: 0.6912 - val_loss: 0.4112 - val_f1: 0.1413\n",
      "Epoch 788/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2709 - f1: 0.6942 - val_loss: 0.4117 - val_f1: 0.1411\n",
      "Epoch 789/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2703 - f1: 0.6939 - val_loss: 0.4115 - val_f1: 0.1405\n",
      "Epoch 790/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2727 - f1: 0.6957 - val_loss: 0.4102 - val_f1: 0.1410\n",
      "Epoch 791/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2714 - f1: 0.6958 - val_loss: 0.4117 - val_f1: 0.1400\n",
      "Epoch 792/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2687 - f1: 0.6922 - val_loss: 0.4123 - val_f1: 0.1414\n",
      "Epoch 793/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2714 - f1: 0.6980 - val_loss: 0.4126 - val_f1: 0.1405\n",
      "Epoch 794/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2725 - f1: 0.6958 - val_loss: 0.4104 - val_f1: 0.1415\n",
      "Epoch 795/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2701 - f1: 0.6984 - val_loss: 0.4120 - val_f1: 0.1406\n",
      "Epoch 796/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2700 - f1: 0.6983 - val_loss: 0.4121 - val_f1: 0.1411\n",
      "Epoch 797/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2721 - f1: 0.6885 - val_loss: 0.4115 - val_f1: 0.1415\n",
      "Epoch 798/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2717 - f1: 0.6906 - val_loss: 0.4118 - val_f1: 0.1414\n",
      "Epoch 799/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2724 - f1: 0.6883 - val_loss: 0.4110 - val_f1: 0.1410\n",
      "Epoch 800/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2707 - f1: 0.6930 - val_loss: 0.4116 - val_f1: 0.1415\n",
      "Epoch 801/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2711 - f1: 0.6959 - val_loss: 0.4129 - val_f1: 0.1398\n",
      "Epoch 802/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2727 - f1: 0.6906 - val_loss: 0.4118 - val_f1: 0.1398\n",
      "Epoch 803/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2712 - f1: 0.6873 - val_loss: 0.4119 - val_f1: 0.1406\n",
      "Epoch 804/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2687 - f1: 0.6991 - val_loss: 0.4127 - val_f1: 0.1410\n",
      "Epoch 805/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2714 - f1: 0.6907 - val_loss: 0.4120 - val_f1: 0.1409\n",
      "Epoch 806/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2716 - f1: 0.6908 - val_loss: 0.4117 - val_f1: 0.1414\n",
      "Epoch 807/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2718 - f1: 0.6928 - val_loss: 0.4117 - val_f1: 0.1408\n",
      "Epoch 808/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2710 - f1: 0.6949 - val_loss: 0.4124 - val_f1: 0.1416\n",
      "Epoch 809/2000\n",
      "64440/64440 [==============================] - 2s 32us/step - loss: 0.2732 - f1: 0.6921 - val_loss: 0.4115 - val_f1: 0.1404\n",
      "Epoch 810/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2692 - f1: 0.6968 - val_loss: 0.4121 - val_f1: 0.1409\n",
      "Epoch 811/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2716 - f1: 0.6909 - val_loss: 0.4124 - val_f1: 0.1403\n",
      "Epoch 812/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2724 - f1: 0.6890 - val_loss: 0.4113 - val_f1: 0.1412\n",
      "Epoch 813/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2721 - f1: 0.6919 - val_loss: 0.4107 - val_f1: 0.1409\n",
      "Epoch 814/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2707 - f1: 0.6960 - val_loss: 0.4117 - val_f1: 0.1414\n",
      "Epoch 815/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2708 - f1: 0.6933 - val_loss: 0.4126 - val_f1: 0.1412\n",
      "Epoch 816/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2698 - f1: 0.6927 - val_loss: 0.4133 - val_f1: 0.1410\n",
      "Epoch 817/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2718 - f1: 0.6932 - val_loss: 0.4119 - val_f1: 0.1409\n",
      "Epoch 818/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2716 - f1: 0.6944 - val_loss: 0.4119 - val_f1: 0.1413\n",
      "Epoch 819/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2703 - f1: 0.6908 - val_loss: 0.4123 - val_f1: 0.1408\n",
      "Epoch 820/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2722 - f1: 0.6883 - val_loss: 0.4110 - val_f1: 0.1410\n",
      "Epoch 821/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2712 - f1: 0.6929 - val_loss: 0.4124 - val_f1: 0.1403\n",
      "Epoch 822/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2692 - f1: 0.6999 - val_loss: 0.4129 - val_f1: 0.1402\n",
      "Epoch 823/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2695 - f1: 0.6975 - val_loss: 0.4131 - val_f1: 0.1413\n",
      "Epoch 824/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2704 - f1: 0.6921 - val_loss: 0.4133 - val_f1: 0.1401\n",
      "Epoch 825/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2708 - f1: 0.6978 - val_loss: 0.4124 - val_f1: 0.1414\n",
      "Epoch 826/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2721 - f1: 0.6914 - val_loss: 0.4114 - val_f1: 0.1414\n",
      "Epoch 827/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2720 - f1: 0.6913 - val_loss: 0.4127 - val_f1: 0.1394\n",
      "Epoch 828/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2724 - f1: 0.6934 - val_loss: 0.4113 - val_f1: 0.1406\n",
      "Epoch 829/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2717 - f1: 0.6968 - val_loss: 0.4116 - val_f1: 0.1405\n",
      "Epoch 830/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2676 - f1: 0.6995 - val_loss: 0.4129 - val_f1: 0.1416\n",
      "Epoch 831/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2683 - f1: 0.6978 - val_loss: 0.4142 - val_f1: 0.1405\n",
      "Epoch 832/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2708 - f1: 0.6970 - val_loss: 0.4125 - val_f1: 0.1416\n",
      "Epoch 833/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2699 - f1: 0.6990 - val_loss: 0.4127 - val_f1: 0.1410\n",
      "Epoch 834/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2684 - f1: 0.6928 - val_loss: 0.4136 - val_f1: 0.1410\n",
      "Epoch 835/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2706 - f1: 0.6969 - val_loss: 0.4122 - val_f1: 0.1413\n",
      "Epoch 836/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2686 - f1: 0.6976 - val_loss: 0.4129 - val_f1: 0.1411\n",
      "Epoch 837/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2709 - f1: 0.6932 - val_loss: 0.4128 - val_f1: 0.1415\n",
      "Epoch 838/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2711 - f1: 0.6933 - val_loss: 0.4119 - val_f1: 0.1404\n",
      "Epoch 839/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2686 - f1: 0.6990 - val_loss: 0.4126 - val_f1: 0.1418\n",
      "Epoch 840/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2722 - f1: 0.6900 - val_loss: 0.4118 - val_f1: 0.1412\n",
      "Epoch 841/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2706 - f1: 0.6986 - val_loss: 0.4127 - val_f1: 0.1415\n",
      "Epoch 842/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2713 - f1: 0.6948 - val_loss: 0.4119 - val_f1: 0.1409\n",
      "Epoch 843/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2696 - f1: 0.6928 - val_loss: 0.4116 - val_f1: 0.1407\n",
      "Epoch 844/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2684 - f1: 0.6963 - val_loss: 0.4134 - val_f1: 0.1409\n",
      "Epoch 845/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2709 - f1: 0.6951 - val_loss: 0.4135 - val_f1: 0.1410\n",
      "Epoch 846/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2684 - f1: 0.6986 - val_loss: 0.4145 - val_f1: 0.1412\n",
      "Epoch 847/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2714 - f1: 0.6970 - val_loss: 0.4123 - val_f1: 0.1410\n",
      "Epoch 848/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2705 - f1: 0.6993 - val_loss: 0.4126 - val_f1: 0.1414\n",
      "Epoch 849/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2708 - f1: 0.6954 - val_loss: 0.4128 - val_f1: 0.1410\n",
      "Epoch 850/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2699 - f1: 0.6966 - val_loss: 0.4124 - val_f1: 0.1414\n",
      "Epoch 851/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2689 - f1: 0.7013 - val_loss: 0.4129 - val_f1: 0.1414\n",
      "Epoch 852/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2700 - f1: 0.6899 - val_loss: 0.4131 - val_f1: 0.1419\n",
      "Epoch 853/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2694 - f1: 0.6976 - val_loss: 0.4140 - val_f1: 0.1408\n",
      "Epoch 854/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2681 - f1: 0.6984 - val_loss: 0.4133 - val_f1: 0.1408\n",
      "Epoch 855/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2695 - f1: 0.6991 - val_loss: 0.4131 - val_f1: 0.1412\n",
      "Epoch 856/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2712 - f1: 0.6918 - val_loss: 0.4125 - val_f1: 0.1415\n",
      "Epoch 857/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2703 - f1: 0.6944 - val_loss: 0.4126 - val_f1: 0.1416\n",
      "Epoch 858/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2688 - f1: 0.6931 - val_loss: 0.4134 - val_f1: 0.1407\n",
      "Epoch 859/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2679 - f1: 0.6942 - val_loss: 0.4137 - val_f1: 0.1408\n",
      "Epoch 860/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2657 - f1: 0.7011 - val_loss: 0.4154 - val_f1: 0.1411\n",
      "Epoch 861/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2711 - f1: 0.6968 - val_loss: 0.4134 - val_f1: 0.1403\n",
      "Epoch 862/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2683 - f1: 0.6978 - val_loss: 0.4138 - val_f1: 0.1407\n",
      "Epoch 863/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2693 - f1: 0.6985 - val_loss: 0.4135 - val_f1: 0.1412\n",
      "Epoch 864/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2682 - f1: 0.6980 - val_loss: 0.4137 - val_f1: 0.1404\n",
      "Epoch 865/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2695 - f1: 0.7004 - val_loss: 0.4141 - val_f1: 0.1405\n",
      "Epoch 866/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2708 - f1: 0.6963 - val_loss: 0.4135 - val_f1: 0.1410\n",
      "Epoch 867/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2680 - f1: 0.6974 - val_loss: 0.4139 - val_f1: 0.1403\n",
      "Epoch 868/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2690 - f1: 0.6959 - val_loss: 0.4137 - val_f1: 0.1409\n",
      "Epoch 869/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2692 - f1: 0.6943 - val_loss: 0.4135 - val_f1: 0.1419\n",
      "Epoch 870/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2681 - f1: 0.7061 - val_loss: 0.4133 - val_f1: 0.1405\n",
      "Epoch 871/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2693 - f1: 0.6968 - val_loss: 0.4137 - val_f1: 0.1417\n",
      "Epoch 872/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2689 - f1: 0.6979 - val_loss: 0.4139 - val_f1: 0.1404\n",
      "Epoch 873/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2692 - f1: 0.6995 - val_loss: 0.4136 - val_f1: 0.1403\n",
      "Epoch 874/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2697 - f1: 0.6962 - val_loss: 0.4137 - val_f1: 0.1406\n",
      "Epoch 875/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2682 - f1: 0.6974 - val_loss: 0.4144 - val_f1: 0.1406\n",
      "Epoch 876/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2673 - f1: 0.6972 - val_loss: 0.4141 - val_f1: 0.1411\n",
      "Epoch 877/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2691 - f1: 0.6995 - val_loss: 0.4144 - val_f1: 0.1406\n",
      "Epoch 878/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2690 - f1: 0.6975 - val_loss: 0.4134 - val_f1: 0.1406\n",
      "Epoch 879/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2687 - f1: 0.6990 - val_loss: 0.4138 - val_f1: 0.1408\n",
      "Epoch 880/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2688 - f1: 0.6998 - val_loss: 0.4149 - val_f1: 0.1407\n",
      "Epoch 881/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2681 - f1: 0.6957 - val_loss: 0.4144 - val_f1: 0.1416\n",
      "Epoch 882/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2683 - f1: 0.6962 - val_loss: 0.4148 - val_f1: 0.1404\n",
      "Epoch 883/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2679 - f1: 0.6975 - val_loss: 0.4144 - val_f1: 0.1411\n",
      "Epoch 884/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2695 - f1: 0.6955 - val_loss: 0.4145 - val_f1: 0.1405\n",
      "Epoch 885/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2671 - f1: 0.7005 - val_loss: 0.4142 - val_f1: 0.1409\n",
      "Epoch 886/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2691 - f1: 0.7000 - val_loss: 0.4153 - val_f1: 0.1404\n",
      "Epoch 887/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2691 - f1: 0.6914 - val_loss: 0.4143 - val_f1: 0.1410\n",
      "Epoch 888/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2676 - f1: 0.6973 - val_loss: 0.4148 - val_f1: 0.1412\n",
      "Epoch 889/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2671 - f1: 0.6965 - val_loss: 0.4145 - val_f1: 0.1415\n",
      "Epoch 890/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2676 - f1: 0.7024 - val_loss: 0.4139 - val_f1: 0.1412\n",
      "Epoch 891/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2673 - f1: 0.7016 - val_loss: 0.4146 - val_f1: 0.1412\n",
      "Epoch 892/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2713 - f1: 0.6932 - val_loss: 0.4135 - val_f1: 0.1406\n",
      "Epoch 893/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2645 - f1: 0.7013 - val_loss: 0.4160 - val_f1: 0.1410\n",
      "Epoch 894/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2691 - f1: 0.6964 - val_loss: 0.4153 - val_f1: 0.1399\n",
      "Epoch 895/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2700 - f1: 0.6911 - val_loss: 0.4134 - val_f1: 0.1405\n",
      "Epoch 896/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2692 - f1: 0.6979 - val_loss: 0.4131 - val_f1: 0.1410\n",
      "Epoch 897/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2684 - f1: 0.6987 - val_loss: 0.4127 - val_f1: 0.1404\n",
      "Epoch 898/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2665 - f1: 0.7025 - val_loss: 0.4154 - val_f1: 0.1404\n",
      "Epoch 899/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2673 - f1: 0.6979 - val_loss: 0.4152 - val_f1: 0.1403\n",
      "Epoch 900/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2670 - f1: 0.7029 - val_loss: 0.4147 - val_f1: 0.1413\n",
      "Epoch 901/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2673 - f1: 0.6995 - val_loss: 0.4144 - val_f1: 0.1408\n",
      "Epoch 902/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2692 - f1: 0.6970 - val_loss: 0.4140 - val_f1: 0.1406\n",
      "Epoch 903/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2677 - f1: 0.6957 - val_loss: 0.4153 - val_f1: 0.1406\n",
      "Epoch 904/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2680 - f1: 0.6954 - val_loss: 0.4145 - val_f1: 0.1407\n",
      "Epoch 905/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2669 - f1: 0.6993 - val_loss: 0.4149 - val_f1: 0.1408\n",
      "Epoch 906/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2704 - f1: 0.6937 - val_loss: 0.4137 - val_f1: 0.1408\n",
      "Epoch 907/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2680 - f1: 0.6920 - val_loss: 0.4142 - val_f1: 0.1420\n",
      "Epoch 908/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2672 - f1: 0.6989 - val_loss: 0.4153 - val_f1: 0.1411\n",
      "Epoch 909/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2641 - f1: 0.6992 - val_loss: 0.4164 - val_f1: 0.1410\n",
      "Epoch 910/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2652 - f1: 0.7029 - val_loss: 0.4164 - val_f1: 0.1405\n",
      "Epoch 911/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2671 - f1: 0.6968 - val_loss: 0.4158 - val_f1: 0.1414\n",
      "Epoch 912/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2697 - f1: 0.6965 - val_loss: 0.4152 - val_f1: 0.1407\n",
      "Epoch 913/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.2682 - f1: 0.69 - 2s 34us/step - loss: 0.2684 - f1: 0.6976 - val_loss: 0.4144 - val_f1: 0.1409\n",
      "Epoch 914/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2688 - f1: 0.6963 - val_loss: 0.4137 - val_f1: 0.1414\n",
      "Epoch 915/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2697 - f1: 0.6964 - val_loss: 0.4133 - val_f1: 0.1418\n",
      "Epoch 916/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2677 - f1: 0.6968 - val_loss: 0.4149 - val_f1: 0.1406\n",
      "Epoch 917/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2663 - f1: 0.7015 - val_loss: 0.4153 - val_f1: 0.1408\n",
      "Epoch 918/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2669 - f1: 0.7032 - val_loss: 0.4153 - val_f1: 0.1409\n",
      "Epoch 919/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2676 - f1: 0.7007 - val_loss: 0.4145 - val_f1: 0.1406\n",
      "Epoch 920/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2660 - f1: 0.7032 - val_loss: 0.4151 - val_f1: 0.1411\n",
      "Epoch 921/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2662 - f1: 0.6986 - val_loss: 0.4150 - val_f1: 0.1416\n",
      "Epoch 922/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2668 - f1: 0.6996 - val_loss: 0.4157 - val_f1: 0.1411\n",
      "Epoch 923/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2681 - f1: 0.6968 - val_loss: 0.4149 - val_f1: 0.1414\n",
      "Epoch 924/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2681 - f1: 0.6981 - val_loss: 0.4150 - val_f1: 0.1406\n",
      "Epoch 925/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2665 - f1: 0.7011 - val_loss: 0.4154 - val_f1: 0.1407\n",
      "Epoch 926/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2660 - f1: 0.6970 - val_loss: 0.4148 - val_f1: 0.1419\n",
      "Epoch 927/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2668 - f1: 0.7013 - val_loss: 0.4161 - val_f1: 0.1414\n",
      "Epoch 928/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2680 - f1: 0.6969 - val_loss: 0.4142 - val_f1: 0.1423\n",
      "Epoch 929/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2682 - f1: 0.6972 - val_loss: 0.4143 - val_f1: 0.1414\n",
      "Epoch 930/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2688 - f1: 0.6983 - val_loss: 0.4148 - val_f1: 0.1414\n",
      "Epoch 931/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2654 - f1: 0.6981 - val_loss: 0.4154 - val_f1: 0.1414\n",
      "Epoch 932/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2693 - f1: 0.6991 - val_loss: 0.4146 - val_f1: 0.1406\n",
      "Epoch 933/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2670 - f1: 0.6997 - val_loss: 0.4150 - val_f1: 0.1405\n",
      "Epoch 934/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2655 - f1: 0.6996 - val_loss: 0.4145 - val_f1: 0.1423\n",
      "Epoch 935/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2677 - f1: 0.6997 - val_loss: 0.4159 - val_f1: 0.1410\n",
      "Epoch 936/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2656 - f1: 0.7038 - val_loss: 0.4170 - val_f1: 0.1415\n",
      "Epoch 937/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2668 - f1: 0.6987 - val_loss: 0.4160 - val_f1: 0.1405\n",
      "Epoch 938/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2680 - f1: 0.6971 - val_loss: 0.4149 - val_f1: 0.1415\n",
      "Epoch 939/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2657 - f1: 0.7001 - val_loss: 0.4167 - val_f1: 0.1401\n",
      "Epoch 940/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2649 - f1: 0.7017 - val_loss: 0.4170 - val_f1: 0.1401\n",
      "Epoch 941/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2666 - f1: 0.6951 - val_loss: 0.4160 - val_f1: 0.1410\n",
      "Epoch 942/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2662 - f1: 0.7012 - val_loss: 0.4156 - val_f1: 0.1408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 943/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2675 - f1: 0.6977 - val_loss: 0.4156 - val_f1: 0.1412\n",
      "Epoch 944/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2689 - f1: 0.6966 - val_loss: 0.4157 - val_f1: 0.1406\n",
      "Epoch 945/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2688 - f1: 0.6987 - val_loss: 0.4150 - val_f1: 0.1409\n",
      "Epoch 946/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2659 - f1: 0.6993 - val_loss: 0.4153 - val_f1: 0.1409\n",
      "Epoch 947/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2707 - f1: 0.6928 - val_loss: 0.4130 - val_f1: 0.1415\n",
      "Epoch 948/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2671 - f1: 0.6994 - val_loss: 0.4153 - val_f1: 0.1412\n",
      "Epoch 949/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2688 - f1: 0.7014 - val_loss: 0.4142 - val_f1: 0.1408\n",
      "Epoch 950/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2669 - f1: 0.7008 - val_loss: 0.4152 - val_f1: 0.1414\n",
      "Epoch 951/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2654 - f1: 0.7037 - val_loss: 0.4165 - val_f1: 0.1412\n",
      "Epoch 952/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2689 - f1: 0.6970 - val_loss: 0.4154 - val_f1: 0.1413\n",
      "Epoch 953/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2655 - f1: 0.7006 - val_loss: 0.4160 - val_f1: 0.1412\n",
      "Epoch 954/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2672 - f1: 0.6983 - val_loss: 0.4149 - val_f1: 0.1407\n",
      "Epoch 955/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2676 - f1: 0.6994 - val_loss: 0.4149 - val_f1: 0.1412\n",
      "Epoch 956/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2670 - f1: 0.6980 - val_loss: 0.4154 - val_f1: 0.1409\n",
      "Epoch 957/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2687 - f1: 0.6991 - val_loss: 0.4152 - val_f1: 0.1408\n",
      "Epoch 958/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2684 - f1: 0.6974 - val_loss: 0.4146 - val_f1: 0.1407\n",
      "Epoch 959/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2667 - f1: 0.7024 - val_loss: 0.4152 - val_f1: 0.1412\n",
      "Epoch 960/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2675 - f1: 0.7017 - val_loss: 0.4156 - val_f1: 0.1418\n",
      "Epoch 961/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2682 - f1: 0.6921 - val_loss: 0.4142 - val_f1: 0.1416\n",
      "Epoch 962/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2649 - f1: 0.7020 - val_loss: 0.4173 - val_f1: 0.1408\n",
      "Epoch 963/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2648 - f1: 0.7015 - val_loss: 0.4168 - val_f1: 0.1409\n",
      "Epoch 964/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2656 - f1: 0.7022 - val_loss: 0.4164 - val_f1: 0.1414\n",
      "Epoch 965/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2683 - f1: 0.6970 - val_loss: 0.4154 - val_f1: 0.1409\n",
      "Epoch 966/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2680 - f1: 0.6973 - val_loss: 0.4156 - val_f1: 0.1408\n",
      "Epoch 967/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2652 - f1: 0.7034 - val_loss: 0.4166 - val_f1: 0.1400\n",
      "Epoch 968/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2674 - f1: 0.7041 - val_loss: 0.4157 - val_f1: 0.1416\n",
      "Epoch 969/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2656 - f1: 0.7005 - val_loss: 0.4158 - val_f1: 0.1417\n",
      "Epoch 970/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2665 - f1: 0.6981 - val_loss: 0.4166 - val_f1: 0.1409\n",
      "Epoch 971/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2677 - f1: 0.6974 - val_loss: 0.4147 - val_f1: 0.1413\n",
      "Epoch 972/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2649 - f1: 0.7022 - val_loss: 0.4147 - val_f1: 0.1412\n",
      "Epoch 973/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2662 - f1: 0.7021 - val_loss: 0.4156 - val_f1: 0.1411\n",
      "Epoch 974/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2660 - f1: 0.6984 - val_loss: 0.4155 - val_f1: 0.1412\n",
      "Epoch 975/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2674 - f1: 0.7007 - val_loss: 0.4153 - val_f1: 0.1412\n",
      "Epoch 976/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2656 - f1: 0.7075 - val_loss: 0.4163 - val_f1: 0.1396\n",
      "Epoch 977/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2667 - f1: 0.6982 - val_loss: 0.4152 - val_f1: 0.1408\n",
      "Epoch 978/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2669 - f1: 0.7006 - val_loss: 0.4143 - val_f1: 0.1411\n",
      "Epoch 979/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2661 - f1: 0.6993 - val_loss: 0.4155 - val_f1: 0.1410\n",
      "Epoch 980/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2658 - f1: 0.7027 - val_loss: 0.4154 - val_f1: 0.1409\n",
      "Epoch 981/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2646 - f1: 0.6993 - val_loss: 0.4173 - val_f1: 0.1408\n",
      "Epoch 982/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2639 - f1: 0.7009 - val_loss: 0.4176 - val_f1: 0.1405\n",
      "Epoch 983/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2645 - f1: 0.7053 - val_loss: 0.4176 - val_f1: 0.1406\n",
      "Epoch 984/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2661 - f1: 0.7035 - val_loss: 0.4171 - val_f1: 0.1407\n",
      "Epoch 985/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2641 - f1: 0.7070 - val_loss: 0.4167 - val_f1: 0.1409\n",
      "Epoch 986/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2628 - f1: 0.7071 - val_loss: 0.4182 - val_f1: 0.1414\n",
      "Epoch 987/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2638 - f1: 0.7026 - val_loss: 0.4193 - val_f1: 0.1409\n",
      "Epoch 988/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2650 - f1: 0.7014 - val_loss: 0.4174 - val_f1: 0.1409\n",
      "Epoch 989/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2641 - f1: 0.7042 - val_loss: 0.4169 - val_f1: 0.1408\n",
      "Epoch 990/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2656 - f1: 0.7046 - val_loss: 0.4173 - val_f1: 0.1410\n",
      "Epoch 991/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2664 - f1: 0.7021 - val_loss: 0.4165 - val_f1: 0.1411\n",
      "Epoch 992/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2658 - f1: 0.6982 - val_loss: 0.4166 - val_f1: 0.1420\n",
      "Epoch 993/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2628 - f1: 0.7040 - val_loss: 0.4180 - val_f1: 0.1413\n",
      "Epoch 994/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2656 - f1: 0.7033 - val_loss: 0.4168 - val_f1: 0.1416\n",
      "Epoch 995/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2644 - f1: 0.7039 - val_loss: 0.4176 - val_f1: 0.1412\n",
      "Epoch 996/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2629 - f1: 0.7077 - val_loss: 0.4183 - val_f1: 0.1409\n",
      "Epoch 997/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2665 - f1: 0.6995 - val_loss: 0.4173 - val_f1: 0.1411\n",
      "Epoch 998/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2653 - f1: 0.7016 - val_loss: 0.4171 - val_f1: 0.1412\n",
      "Epoch 999/2000\n",
      "64440/64440 [==============================] - 2s 32us/step - loss: 0.2656 - f1: 0.7037 - val_loss: 0.4170 - val_f1: 0.1416\n",
      "Epoch 1000/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2656 - f1: 0.7021 - val_loss: 0.4167 - val_f1: 0.1401\n",
      "Epoch 1001/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2662 - f1: 0.7009 - val_loss: 0.4162 - val_f1: 0.1411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1002/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2659 - f1: 0.7011 - val_loss: 0.4173 - val_f1: 0.1405\n",
      "Epoch 1003/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2654 - f1: 0.6996 - val_loss: 0.4162 - val_f1: 0.1413\n",
      "Epoch 1004/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2662 - f1: 0.7040 - val_loss: 0.4159 - val_f1: 0.1405\n",
      "Epoch 1005/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2657 - f1: 0.6983 - val_loss: 0.4156 - val_f1: 0.1413\n",
      "Epoch 1006/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2637 - f1: 0.7070 - val_loss: 0.4174 - val_f1: 0.1410\n",
      "Epoch 1007/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2662 - f1: 0.7057 - val_loss: 0.4166 - val_f1: 0.1415\n",
      "Epoch 1008/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2651 - f1: 0.7030 - val_loss: 0.4159 - val_f1: 0.1414\n",
      "Epoch 1009/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2641 - f1: 0.7051 - val_loss: 0.4170 - val_f1: 0.1410\n",
      "Epoch 1010/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2650 - f1: 0.7012 - val_loss: 0.4179 - val_f1: 0.1408\n",
      "Epoch 1011/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2644 - f1: 0.7057 - val_loss: 0.4180 - val_f1: 0.1407\n",
      "Epoch 1012/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2667 - f1: 0.6972 - val_loss: 0.4168 - val_f1: 0.1415\n",
      "Epoch 1013/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2647 - f1: 0.6991 - val_loss: 0.4173 - val_f1: 0.1417\n",
      "Epoch 1014/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2628 - f1: 0.7092 - val_loss: 0.4189 - val_f1: 0.1407\n",
      "Epoch 1015/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2653 - f1: 0.7001 - val_loss: 0.4195 - val_f1: 0.1405\n",
      "Epoch 1016/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2654 - f1: 0.7060 - val_loss: 0.4172 - val_f1: 0.1404\n",
      "Epoch 1017/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2663 - f1: 0.7019 - val_loss: 0.4166 - val_f1: 0.1404\n",
      "Epoch 1018/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2649 - f1: 0.7010 - val_loss: 0.4171 - val_f1: 0.1403\n",
      "Epoch 1019/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2643 - f1: 0.7006 - val_loss: 0.4172 - val_f1: 0.1410\n",
      "Epoch 1020/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2648 - f1: 0.7015 - val_loss: 0.4168 - val_f1: 0.1416\n",
      "Epoch 1021/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2633 - f1: 0.7049 - val_loss: 0.4180 - val_f1: 0.1404\n",
      "Epoch 1022/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2653 - f1: 0.7062 - val_loss: 0.4168 - val_f1: 0.1413\n",
      "Epoch 1023/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2627 - f1: 0.7113 - val_loss: 0.4189 - val_f1: 0.1408\n",
      "Epoch 1024/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2663 - f1: 0.6959 - val_loss: 0.4170 - val_f1: 0.1418\n",
      "Epoch 1025/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2638 - f1: 0.7031 - val_loss: 0.4173 - val_f1: 0.1416\n",
      "Epoch 1026/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2624 - f1: 0.7069 - val_loss: 0.4186 - val_f1: 0.1411\n",
      "Epoch 1027/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2662 - f1: 0.6964 - val_loss: 0.4176 - val_f1: 0.1415\n",
      "Epoch 1028/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2669 - f1: 0.7050 - val_loss: 0.4161 - val_f1: 0.1416\n",
      "Epoch 1029/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2659 - f1: 0.7049 - val_loss: 0.4169 - val_f1: 0.1411\n",
      "Epoch 1030/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2628 - f1: 0.7031 - val_loss: 0.4177 - val_f1: 0.1412\n",
      "Epoch 1031/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2643 - f1: 0.7041 - val_loss: 0.4169 - val_f1: 0.1415\n",
      "Epoch 1032/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2637 - f1: 0.7082 - val_loss: 0.4177 - val_f1: 0.1409\n",
      "Epoch 1033/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2646 - f1: 0.7018 - val_loss: 0.4186 - val_f1: 0.1413\n",
      "Epoch 1034/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2642 - f1: 0.7031 - val_loss: 0.4176 - val_f1: 0.1418\n",
      "Epoch 1035/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2670 - f1: 0.6997 - val_loss: 0.4167 - val_f1: 0.1406\n",
      "Epoch 1036/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2656 - f1: 0.7045 - val_loss: 0.4171 - val_f1: 0.1411\n",
      "Epoch 1037/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2654 - f1: 0.6995 - val_loss: 0.4167 - val_f1: 0.1404\n",
      "Epoch 1038/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2624 - f1: 0.7096 - val_loss: 0.4186 - val_f1: 0.1402\n",
      "Epoch 1039/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2648 - f1: 0.7020 - val_loss: 0.4182 - val_f1: 0.1410\n",
      "Epoch 1040/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2657 - f1: 0.7003 - val_loss: 0.4174 - val_f1: 0.1404\n",
      "Epoch 1041/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2639 - f1: 0.7021 - val_loss: 0.4180 - val_f1: 0.1418\n",
      "Epoch 1042/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2649 - f1: 0.6991 - val_loss: 0.4169 - val_f1: 0.1416\n",
      "Epoch 1043/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2650 - f1: 0.7011 - val_loss: 0.4180 - val_f1: 0.1414\n",
      "Epoch 1044/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2645 - f1: 0.7036 - val_loss: 0.4182 - val_f1: 0.1411\n",
      "Epoch 1045/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2645 - f1: 0.6995 - val_loss: 0.4176 - val_f1: 0.1413\n",
      "Epoch 1046/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2641 - f1: 0.7033 - val_loss: 0.4175 - val_f1: 0.1413\n",
      "Epoch 1047/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2659 - f1: 0.7021 - val_loss: 0.4176 - val_f1: 0.1422\n",
      "Epoch 1048/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2630 - f1: 0.7041 - val_loss: 0.4177 - val_f1: 0.1411\n",
      "Epoch 1049/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2645 - f1: 0.7043 - val_loss: 0.4178 - val_f1: 0.1414\n",
      "Epoch 1050/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2642 - f1: 0.7043 - val_loss: 0.4185 - val_f1: 0.1403\n",
      "Epoch 1051/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2642 - f1: 0.7076 - val_loss: 0.4182 - val_f1: 0.1406\n",
      "Epoch 1052/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2646 - f1: 0.7023 - val_loss: 0.4186 - val_f1: 0.1406\n",
      "Epoch 1053/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2632 - f1: 0.7052 - val_loss: 0.4193 - val_f1: 0.1406\n",
      "Epoch 1054/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2656 - f1: 0.7008 - val_loss: 0.4181 - val_f1: 0.1408\n",
      "Epoch 1055/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2635 - f1: 0.7029 - val_loss: 0.4181 - val_f1: 0.1419\n",
      "Epoch 1056/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2621 - f1: 0.7058 - val_loss: 0.4188 - val_f1: 0.1413\n",
      "Epoch 1057/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2635 - f1: 0.7079 - val_loss: 0.4183 - val_f1: 0.1410\n",
      "Epoch 1058/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2639 - f1: 0.7061 - val_loss: 0.4188 - val_f1: 0.1417\n",
      "Epoch 1059/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2637 - f1: 0.7039 - val_loss: 0.4186 - val_f1: 0.1417\n",
      "Epoch 1060/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2637 - f1: 0.7055 - val_loss: 0.4191 - val_f1: 0.1410\n",
      "Epoch 1061/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2628 - f1: 0.7036 - val_loss: 0.4184 - val_f1: 0.1411\n",
      "Epoch 1062/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2637 - f1: 0.7054 - val_loss: 0.4188 - val_f1: 0.1409\n",
      "Epoch 1063/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2640 - f1: 0.7065 - val_loss: 0.4190 - val_f1: 0.1409\n",
      "Epoch 1064/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2624 - f1: 0.7067 - val_loss: 0.4195 - val_f1: 0.1414\n",
      "Epoch 1065/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2627 - f1: 0.7061 - val_loss: 0.4200 - val_f1: 0.1407\n",
      "Epoch 1066/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2630 - f1: 0.7021 - val_loss: 0.4191 - val_f1: 0.1415\n",
      "Epoch 1067/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2643 - f1: 0.7090 - val_loss: 0.4188 - val_f1: 0.1423\n",
      "Epoch 1068/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2617 - f1: 0.7066 - val_loss: 0.4199 - val_f1: 0.1407\n",
      "Epoch 1069/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2655 - f1: 0.7029 - val_loss: 0.4180 - val_f1: 0.1410\n",
      "Epoch 1070/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2608 - f1: 0.7117 - val_loss: 0.4195 - val_f1: 0.1410\n",
      "Epoch 1071/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2651 - f1: 0.7037 - val_loss: 0.4186 - val_f1: 0.1405\n",
      "Epoch 1072/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2621 - f1: 0.7026 - val_loss: 0.4192 - val_f1: 0.1414\n",
      "Epoch 1073/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2629 - f1: 0.7086 - val_loss: 0.4187 - val_f1: 0.1409\n",
      "Epoch 1074/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2650 - f1: 0.7064 - val_loss: 0.4176 - val_f1: 0.1416\n",
      "Epoch 1075/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2653 - f1: 0.7009 - val_loss: 0.4179 - val_f1: 0.1411\n",
      "Epoch 1076/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2615 - f1: 0.7050 - val_loss: 0.4184 - val_f1: 0.1415\n",
      "Epoch 1077/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2632 - f1: 0.7034 - val_loss: 0.4185 - val_f1: 0.1416\n",
      "Epoch 1078/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2645 - f1: 0.7068 - val_loss: 0.4189 - val_f1: 0.1412\n",
      "Epoch 1079/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2639 - f1: 0.7040 - val_loss: 0.4176 - val_f1: 0.1407\n",
      "Epoch 1080/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2625 - f1: 0.7051 - val_loss: 0.4184 - val_f1: 0.1410\n",
      "Epoch 1081/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2651 - f1: 0.7046 - val_loss: 0.4178 - val_f1: 0.1407\n",
      "Epoch 1082/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2647 - f1: 0.7025 - val_loss: 0.4172 - val_f1: 0.1410\n",
      "Epoch 1083/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2651 - f1: 0.7013 - val_loss: 0.4179 - val_f1: 0.1411\n",
      "Epoch 1084/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2649 - f1: 0.7076 - val_loss: 0.4180 - val_f1: 0.1411\n",
      "Epoch 1085/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2640 - f1: 0.7026 - val_loss: 0.4189 - val_f1: 0.1410\n",
      "Epoch 1086/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2635 - f1: 0.7082 - val_loss: 0.4173 - val_f1: 0.1414\n",
      "Epoch 1087/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2619 - f1: 0.7077 - val_loss: 0.4196 - val_f1: 0.1410\n",
      "Epoch 1088/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2631 - f1: 0.7004 - val_loss: 0.4186 - val_f1: 0.1423\n",
      "Epoch 1089/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2617 - f1: 0.7094 - val_loss: 0.4189 - val_f1: 0.1415\n",
      "Epoch 1090/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2626 - f1: 0.7017 - val_loss: 0.4184 - val_f1: 0.1414\n",
      "Epoch 1091/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2629 - f1: 0.7060 - val_loss: 0.4191 - val_f1: 0.1409\n",
      "Epoch 1092/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2640 - f1: 0.7032 - val_loss: 0.4192 - val_f1: 0.1417\n",
      "Epoch 1093/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2621 - f1: 0.7072 - val_loss: 0.4193 - val_f1: 0.1415\n",
      "Epoch 1094/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2643 - f1: 0.7064 - val_loss: 0.4185 - val_f1: 0.1417\n",
      "Epoch 1095/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2651 - f1: 0.7009 - val_loss: 0.4181 - val_f1: 0.1412\n",
      "Epoch 1096/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2623 - f1: 0.7055 - val_loss: 0.4189 - val_f1: 0.1406\n",
      "Epoch 1097/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2616 - f1: 0.7045 - val_loss: 0.4199 - val_f1: 0.1411\n",
      "Epoch 1098/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2637 - f1: 0.7053 - val_loss: 0.4192 - val_f1: 0.1418\n",
      "Epoch 1099/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2628 - f1: 0.7059 - val_loss: 0.4191 - val_f1: 0.1417\n",
      "Epoch 1100/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2648 - f1: 0.7038 - val_loss: 0.4192 - val_f1: 0.1410\n",
      "Epoch 1101/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2630 - f1: 0.7067 - val_loss: 0.4186 - val_f1: 0.1418\n",
      "Epoch 1102/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2645 - f1: 0.7031 - val_loss: 0.4190 - val_f1: 0.1409\n",
      "Epoch 1103/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2641 - f1: 0.7044 - val_loss: 0.4176 - val_f1: 0.1412\n",
      "Epoch 1104/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2639 - f1: 0.7041 - val_loss: 0.4180 - val_f1: 0.1411\n",
      "Epoch 1105/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2632 - f1: 0.7044 - val_loss: 0.4182 - val_f1: 0.1411\n",
      "Epoch 1106/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2637 - f1: 0.7087 - val_loss: 0.4184 - val_f1: 0.1414\n",
      "Epoch 1107/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2619 - f1: 0.7066 - val_loss: 0.4186 - val_f1: 0.1417\n",
      "Epoch 1108/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2640 - f1: 0.7052 - val_loss: 0.4182 - val_f1: 0.1411\n",
      "Epoch 1109/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2628 - f1: 0.7035 - val_loss: 0.4194 - val_f1: 0.1415\n",
      "Epoch 1110/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2639 - f1: 0.7020 - val_loss: 0.4189 - val_f1: 0.1410\n",
      "Epoch 1111/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2619 - f1: 0.7074 - val_loss: 0.4184 - val_f1: 0.1412\n",
      "Epoch 1112/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2642 - f1: 0.7056 - val_loss: 0.4180 - val_f1: 0.1413\n",
      "Epoch 1113/2000\n",
      "64440/64440 [==============================] - 2s 32us/step - loss: 0.2644 - f1: 0.7056 - val_loss: 0.4178 - val_f1: 0.1414\n",
      "Epoch 1114/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2645 - f1: 0.7002 - val_loss: 0.4177 - val_f1: 0.1411\n",
      "Epoch 1115/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2630 - f1: 0.7059 - val_loss: 0.4190 - val_f1: 0.1409\n",
      "Epoch 1116/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2633 - f1: 0.7003 - val_loss: 0.4180 - val_f1: 0.1410\n",
      "Epoch 1117/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2653 - f1: 0.7034 - val_loss: 0.4176 - val_f1: 0.1411\n",
      "Epoch 1118/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2627 - f1: 0.7054 - val_loss: 0.4199 - val_f1: 0.1409\n",
      "Epoch 1119/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2627 - f1: 0.7067 - val_loss: 0.4185 - val_f1: 0.1412\n",
      "Epoch 1120/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2628 - f1: 0.7076 - val_loss: 0.4185 - val_f1: 0.1402\n",
      "Epoch 1121/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2621 - f1: 0.7042 - val_loss: 0.4187 - val_f1: 0.1410\n",
      "Epoch 1122/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2635 - f1: 0.7051 - val_loss: 0.4185 - val_f1: 0.1413\n",
      "Epoch 1123/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2633 - f1: 0.7038 - val_loss: 0.4192 - val_f1: 0.1404\n",
      "Epoch 1124/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2628 - f1: 0.7096 - val_loss: 0.4182 - val_f1: 0.1406\n",
      "Epoch 1125/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2631 - f1: 0.7066 - val_loss: 0.4193 - val_f1: 0.1405\n",
      "Epoch 1126/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2622 - f1: 0.7032 - val_loss: 0.4201 - val_f1: 0.1407\n",
      "Epoch 1127/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2619 - f1: 0.7028 - val_loss: 0.4197 - val_f1: 0.1417\n",
      "Epoch 1128/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2610 - f1: 0.7078 - val_loss: 0.4199 - val_f1: 0.1410\n",
      "Epoch 1129/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2622 - f1: 0.7071 - val_loss: 0.4203 - val_f1: 0.1410\n",
      "Epoch 1130/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2631 - f1: 0.7062 - val_loss: 0.4200 - val_f1: 0.1405\n",
      "Epoch 1131/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2631 - f1: 0.7063 - val_loss: 0.4186 - val_f1: 0.1409\n",
      "Epoch 1132/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2610 - f1: 0.7095 - val_loss: 0.4212 - val_f1: 0.1404\n",
      "Epoch 1133/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2621 - f1: 0.7124 - val_loss: 0.4197 - val_f1: 0.1401\n",
      "Epoch 1134/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2632 - f1: 0.7031 - val_loss: 0.4204 - val_f1: 0.1403\n",
      "Epoch 1135/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2620 - f1: 0.7067 - val_loss: 0.4199 - val_f1: 0.1414\n",
      "Epoch 1136/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2622 - f1: 0.7051 - val_loss: 0.4208 - val_f1: 0.1409\n",
      "Epoch 1137/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2626 - f1: 0.7090 - val_loss: 0.4195 - val_f1: 0.1409\n",
      "Epoch 1138/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2619 - f1: 0.7060 - val_loss: 0.4197 - val_f1: 0.1409\n",
      "Epoch 1139/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2638 - f1: 0.7027 - val_loss: 0.4183 - val_f1: 0.1416\n",
      "Epoch 1140/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2610 - f1: 0.7085 - val_loss: 0.4200 - val_f1: 0.1414\n",
      "Epoch 1141/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2628 - f1: 0.7042 - val_loss: 0.4198 - val_f1: 0.1412\n",
      "Epoch 1142/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2626 - f1: 0.7067 - val_loss: 0.4187 - val_f1: 0.1409\n",
      "Epoch 1143/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2624 - f1: 0.7080 - val_loss: 0.4181 - val_f1: 0.1405\n",
      "Epoch 1144/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2625 - f1: 0.7037 - val_loss: 0.4194 - val_f1: 0.1403\n",
      "Epoch 1145/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2627 - f1: 0.7058 - val_loss: 0.4184 - val_f1: 0.1408\n",
      "Epoch 1146/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2630 - f1: 0.7093 - val_loss: 0.4182 - val_f1: 0.1414\n",
      "Epoch 1147/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2616 - f1: 0.7054 - val_loss: 0.4196 - val_f1: 0.1410\n",
      "Epoch 1148/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2640 - f1: 0.7054 - val_loss: 0.4185 - val_f1: 0.1413\n",
      "Epoch 1149/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2610 - f1: 0.7078 - val_loss: 0.4203 - val_f1: 0.1406\n",
      "Epoch 1150/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2615 - f1: 0.7067 - val_loss: 0.4204 - val_f1: 0.1415\n",
      "Epoch 1151/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2615 - f1: 0.7055 - val_loss: 0.4202 - val_f1: 0.1412\n",
      "Epoch 1152/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2628 - f1: 0.7068 - val_loss: 0.4197 - val_f1: 0.1404\n",
      "Epoch 1153/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2628 - f1: 0.7058 - val_loss: 0.4187 - val_f1: 0.1417\n",
      "Epoch 1154/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2628 - f1: 0.7061 - val_loss: 0.4194 - val_f1: 0.1415\n",
      "Epoch 1155/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2612 - f1: 0.7072 - val_loss: 0.4202 - val_f1: 0.1413\n",
      "Epoch 1156/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2604 - f1: 0.7083 - val_loss: 0.4203 - val_f1: 0.1416\n",
      "Epoch 1157/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2620 - f1: 0.7070 - val_loss: 0.4205 - val_f1: 0.1415\n",
      "Epoch 1158/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2612 - f1: 0.7089 - val_loss: 0.4202 - val_f1: 0.1412\n",
      "Epoch 1159/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2606 - f1: 0.7079 - val_loss: 0.4206 - val_f1: 0.1411\n",
      "Epoch 1160/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2640 - f1: 0.7061 - val_loss: 0.4190 - val_f1: 0.1416\n",
      "Epoch 1161/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2628 - f1: 0.7037 - val_loss: 0.4200 - val_f1: 0.1412\n",
      "Epoch 1162/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2615 - f1: 0.7078 - val_loss: 0.4211 - val_f1: 0.1421\n",
      "Epoch 1163/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2639 - f1: 0.7018 - val_loss: 0.4192 - val_f1: 0.1412\n",
      "Epoch 1164/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2627 - f1: 0.7085 - val_loss: 0.4190 - val_f1: 0.1410\n",
      "Epoch 1165/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2622 - f1: 0.7082 - val_loss: 0.4201 - val_f1: 0.1412\n",
      "Epoch 1166/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2593 - f1: 0.7107 - val_loss: 0.4200 - val_f1: 0.1418\n",
      "Epoch 1167/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2610 - f1: 0.7082 - val_loss: 0.4201 - val_f1: 0.1411\n",
      "Epoch 1168/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2602 - f1: 0.7083 - val_loss: 0.4215 - val_f1: 0.1419\n",
      "Epoch 1169/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2595 - f1: 0.7109 - val_loss: 0.4215 - val_f1: 0.1411\n",
      "Epoch 1170/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2609 - f1: 0.7106 - val_loss: 0.4208 - val_f1: 0.1408\n",
      "Epoch 1171/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2632 - f1: 0.7041 - val_loss: 0.4196 - val_f1: 0.1413\n",
      "Epoch 1172/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2625 - f1: 0.7046 - val_loss: 0.4187 - val_f1: 0.1411\n",
      "Epoch 1173/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2613 - f1: 0.7071 - val_loss: 0.4192 - val_f1: 0.1415\n",
      "Epoch 1174/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2628 - f1: 0.7092 - val_loss: 0.4197 - val_f1: 0.1409\n",
      "Epoch 1175/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2621 - f1: 0.7067 - val_loss: 0.4199 - val_f1: 0.1415\n",
      "Epoch 1176/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2625 - f1: 0.7044 - val_loss: 0.4188 - val_f1: 0.1413\n",
      "Epoch 1177/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2616 - f1: 0.7085 - val_loss: 0.4196 - val_f1: 0.1409\n",
      "Epoch 1178/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2624 - f1: 0.7055 - val_loss: 0.4188 - val_f1: 0.1407\n",
      "Epoch 1179/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2625 - f1: 0.7073 - val_loss: 0.4188 - val_f1: 0.1414\n",
      "Epoch 1180/2000\n",
      "64440/64440 [==============================] - 2s 32us/step - loss: 0.2630 - f1: 0.7048 - val_loss: 0.4189 - val_f1: 0.1420\n",
      "Epoch 1181/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2586 - f1: 0.7132 - val_loss: 0.4211 - val_f1: 0.1414\n",
      "Epoch 1182/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2588 - f1: 0.7121 - val_loss: 0.4214 - val_f1: 0.1412\n",
      "Epoch 1183/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2609 - f1: 0.7106 - val_loss: 0.4204 - val_f1: 0.1407\n",
      "Epoch 1184/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2613 - f1: 0.7048 - val_loss: 0.4205 - val_f1: 0.1405\n",
      "Epoch 1185/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2615 - f1: 0.7075 - val_loss: 0.4196 - val_f1: 0.1410\n",
      "Epoch 1186/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2628 - f1: 0.7054 - val_loss: 0.4191 - val_f1: 0.1409\n",
      "Epoch 1187/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2627 - f1: 0.7138 - val_loss: 0.4202 - val_f1: 0.1408\n",
      "Epoch 1188/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2628 - f1: 0.7081 - val_loss: 0.4194 - val_f1: 0.1405\n",
      "Epoch 1189/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2592 - f1: 0.7116 - val_loss: 0.4205 - val_f1: 0.1411\n",
      "Epoch 1190/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2602 - f1: 0.7073 - val_loss: 0.4211 - val_f1: 0.1414\n",
      "Epoch 1191/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2611 - f1: 0.7096 - val_loss: 0.4206 - val_f1: 0.1404\n",
      "Epoch 1192/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2629 - f1: 0.7065 - val_loss: 0.4201 - val_f1: 0.1414\n",
      "Epoch 1193/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2600 - f1: 0.7112 - val_loss: 0.4201 - val_f1: 0.1413\n",
      "Epoch 1194/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2618 - f1: 0.7073 - val_loss: 0.4202 - val_f1: 0.1406\n",
      "Epoch 1195/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2615 - f1: 0.7048 - val_loss: 0.4191 - val_f1: 0.1419\n",
      "Epoch 1196/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2631 - f1: 0.7055 - val_loss: 0.4189 - val_f1: 0.1415\n",
      "Epoch 1197/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2623 - f1: 0.7031 - val_loss: 0.4204 - val_f1: 0.1411\n",
      "Epoch 1198/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2597 - f1: 0.7081 - val_loss: 0.4206 - val_f1: 0.1411\n",
      "Epoch 1199/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2610 - f1: 0.7122 - val_loss: 0.4199 - val_f1: 0.1412\n",
      "Epoch 1200/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2611 - f1: 0.7074 - val_loss: 0.4202 - val_f1: 0.1408\n",
      "Epoch 1201/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2607 - f1: 0.7081 - val_loss: 0.4210 - val_f1: 0.1409\n",
      "Epoch 1202/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2624 - f1: 0.7029 - val_loss: 0.4202 - val_f1: 0.1410\n",
      "Epoch 1203/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2593 - f1: 0.7090 - val_loss: 0.4209 - val_f1: 0.1411\n",
      "Epoch 1204/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2621 - f1: 0.7081 - val_loss: 0.4202 - val_f1: 0.1415\n",
      "Epoch 1205/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2640 - f1: 0.7030 - val_loss: 0.4189 - val_f1: 0.1417\n",
      "Epoch 1206/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2619 - f1: 0.7077 - val_loss: 0.4191 - val_f1: 0.1411\n",
      "Epoch 1207/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2610 - f1: 0.7081 - val_loss: 0.4207 - val_f1: 0.1403\n",
      "Epoch 1208/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2592 - f1: 0.7103 - val_loss: 0.4212 - val_f1: 0.1416\n",
      "Epoch 1209/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2624 - f1: 0.7044 - val_loss: 0.4204 - val_f1: 0.1406\n",
      "Epoch 1210/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2602 - f1: 0.7090 - val_loss: 0.4208 - val_f1: 0.1415\n",
      "Epoch 1211/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2623 - f1: 0.7046 - val_loss: 0.4204 - val_f1: 0.1405\n",
      "Epoch 1212/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2601 - f1: 0.7089 - val_loss: 0.4203 - val_f1: 0.1409\n",
      "Epoch 1213/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2601 - f1: 0.7097 - val_loss: 0.4211 - val_f1: 0.1408\n",
      "Epoch 1214/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2614 - f1: 0.7069 - val_loss: 0.4209 - val_f1: 0.1421\n",
      "Epoch 1215/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2611 - f1: 0.7068 - val_loss: 0.4204 - val_f1: 0.1411\n",
      "Epoch 1216/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2577 - f1: 0.7134 - val_loss: 0.4215 - val_f1: 0.1411\n",
      "Epoch 1217/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2608 - f1: 0.7090 - val_loss: 0.4218 - val_f1: 0.1418\n",
      "Epoch 1218/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2612 - f1: 0.7117 - val_loss: 0.4216 - val_f1: 0.1413\n",
      "Epoch 1219/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2622 - f1: 0.7076 - val_loss: 0.4208 - val_f1: 0.1416\n",
      "Epoch 1220/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2612 - f1: 0.7064 - val_loss: 0.4212 - val_f1: 0.1413\n",
      "Epoch 1221/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2602 - f1: 0.7091 - val_loss: 0.4216 - val_f1: 0.1414\n",
      "Epoch 1222/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2597 - f1: 0.7103 - val_loss: 0.4211 - val_f1: 0.1413\n",
      "Epoch 1223/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2623 - f1: 0.7044 - val_loss: 0.4193 - val_f1: 0.1412\n",
      "Epoch 1224/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2583 - f1: 0.7119 - val_loss: 0.4221 - val_f1: 0.1405\n",
      "Epoch 1225/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2594 - f1: 0.7109 - val_loss: 0.4214 - val_f1: 0.1413\n",
      "Epoch 1226/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2595 - f1: 0.7110 - val_loss: 0.4214 - val_f1: 0.1416\n",
      "Epoch 1227/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2595 - f1: 0.7108 - val_loss: 0.4223 - val_f1: 0.1412\n",
      "Epoch 1228/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2603 - f1: 0.7119 - val_loss: 0.4205 - val_f1: 0.1422\n",
      "Epoch 1229/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2641 - f1: 0.7067 - val_loss: 0.4200 - val_f1: 0.1407\n",
      "Epoch 1230/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2592 - f1: 0.7078 - val_loss: 0.4216 - val_f1: 0.1405\n",
      "Epoch 1231/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2619 - f1: 0.7061 - val_loss: 0.4206 - val_f1: 0.1415\n",
      "Epoch 1232/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2604 - f1: 0.7102 - val_loss: 0.4209 - val_f1: 0.1419\n",
      "Epoch 1233/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2611 - f1: 0.7061 - val_loss: 0.4214 - val_f1: 0.1409\n",
      "Epoch 1234/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2627 - f1: 0.7047 - val_loss: 0.4207 - val_f1: 0.1412\n",
      "Epoch 1235/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2608 - f1: 0.7092 - val_loss: 0.4210 - val_f1: 0.1419\n",
      "Epoch 1236/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2612 - f1: 0.7100 - val_loss: 0.4195 - val_f1: 0.1415\n",
      "Epoch 1237/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2606 - f1: 0.7093 - val_loss: 0.4197 - val_f1: 0.1421\n",
      "Epoch 1238/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2610 - f1: 0.7077 - val_loss: 0.4204 - val_f1: 0.1416\n",
      "Epoch 1239/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2622 - f1: 0.7051 - val_loss: 0.4191 - val_f1: 0.1414\n",
      "Epoch 1240/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2620 - f1: 0.7073 - val_loss: 0.4193 - val_f1: 0.1411\n",
      "Epoch 1241/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2604 - f1: 0.7083 - val_loss: 0.4202 - val_f1: 0.1410\n",
      "Epoch 1242/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2621 - f1: 0.7043 - val_loss: 0.4197 - val_f1: 0.1413\n",
      "Epoch 1243/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2600 - f1: 0.7083 - val_loss: 0.4211 - val_f1: 0.1409\n",
      "Epoch 1244/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2613 - f1: 0.7063 - val_loss: 0.4202 - val_f1: 0.1408\n",
      "Epoch 1245/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2602 - f1: 0.7098 - val_loss: 0.4216 - val_f1: 0.1415\n",
      "Epoch 1246/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2600 - f1: 0.7080 - val_loss: 0.4209 - val_f1: 0.1418\n",
      "Epoch 1247/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2597 - f1: 0.7098 - val_loss: 0.4213 - val_f1: 0.1423\n",
      "Epoch 1248/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2607 - f1: 0.7082 - val_loss: 0.4207 - val_f1: 0.1419\n",
      "Epoch 1249/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2620 - f1: 0.7059 - val_loss: 0.4203 - val_f1: 0.1419\n",
      "Epoch 1250/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2613 - f1: 0.7063 - val_loss: 0.4210 - val_f1: 0.1413\n",
      "Epoch 1251/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2603 - f1: 0.7121 - val_loss: 0.4216 - val_f1: 0.1410\n",
      "Epoch 1252/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2592 - f1: 0.7076 - val_loss: 0.4219 - val_f1: 0.1415\n",
      "Epoch 1253/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2614 - f1: 0.7068 - val_loss: 0.4218 - val_f1: 0.1413\n",
      "Epoch 1254/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2606 - f1: 0.7043 - val_loss: 0.4214 - val_f1: 0.1422\n",
      "Epoch 1255/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2625 - f1: 0.7044 - val_loss: 0.4190 - val_f1: 0.1409\n",
      "Epoch 1256/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2610 - f1: 0.7064 - val_loss: 0.4201 - val_f1: 0.1417\n",
      "Epoch 1257/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2597 - f1: 0.7106 - val_loss: 0.4213 - val_f1: 0.1408\n",
      "Epoch 1258/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2628 - f1: 0.7091 - val_loss: 0.4197 - val_f1: 0.1416\n",
      "Epoch 1259/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2611 - f1: 0.7076 - val_loss: 0.4195 - val_f1: 0.1406\n",
      "Epoch 1260/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2595 - f1: 0.7113 - val_loss: 0.4205 - val_f1: 0.1407\n",
      "Epoch 1261/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2592 - f1: 0.7088 - val_loss: 0.4216 - val_f1: 0.1412\n",
      "Epoch 1262/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2580 - f1: 0.7096 - val_loss: 0.4226 - val_f1: 0.1413\n",
      "Epoch 1263/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2601 - f1: 0.7115 - val_loss: 0.4213 - val_f1: 0.1415\n",
      "Epoch 1264/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2609 - f1: 0.7091 - val_loss: 0.4214 - val_f1: 0.1409\n",
      "Epoch 1265/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2607 - f1: 0.7059 - val_loss: 0.4208 - val_f1: 0.1413\n",
      "Epoch 1266/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2593 - f1: 0.7104 - val_loss: 0.4204 - val_f1: 0.1423\n",
      "Epoch 1267/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2607 - f1: 0.7078 - val_loss: 0.4210 - val_f1: 0.1415\n",
      "Epoch 1268/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2601 - f1: 0.7103 - val_loss: 0.4206 - val_f1: 0.1418\n",
      "Epoch 1269/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2587 - f1: 0.7053 - val_loss: 0.4215 - val_f1: 0.1411\n",
      "Epoch 1270/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2618 - f1: 0.7037 - val_loss: 0.4210 - val_f1: 0.1400\n",
      "Epoch 1271/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2598 - f1: 0.7075 - val_loss: 0.4203 - val_f1: 0.1411\n",
      "Epoch 1272/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2579 - f1: 0.7101 - val_loss: 0.4215 - val_f1: 0.1418\n",
      "Epoch 1273/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2615 - f1: 0.7108 - val_loss: 0.4214 - val_f1: 0.1403\n",
      "Epoch 1274/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2596 - f1: 0.7078 - val_loss: 0.4219 - val_f1: 0.1412\n",
      "Epoch 1275/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2592 - f1: 0.7132 - val_loss: 0.4210 - val_f1: 0.1419\n",
      "Epoch 1276/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2588 - f1: 0.7075 - val_loss: 0.4213 - val_f1: 0.1417\n",
      "Epoch 1277/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2605 - f1: 0.7084 - val_loss: 0.4220 - val_f1: 0.1409\n",
      "Epoch 1278/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2591 - f1: 0.7096 - val_loss: 0.4221 - val_f1: 0.1409\n",
      "Epoch 1279/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2587 - f1: 0.7104 - val_loss: 0.4218 - val_f1: 0.1413\n",
      "Epoch 1280/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2584 - f1: 0.7123 - val_loss: 0.4224 - val_f1: 0.1407\n",
      "Epoch 1281/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2579 - f1: 0.7162 - val_loss: 0.4227 - val_f1: 0.1420\n",
      "Epoch 1282/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2601 - f1: 0.7098 - val_loss: 0.4211 - val_f1: 0.1420\n",
      "Epoch 1283/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2588 - f1: 0.7133 - val_loss: 0.4229 - val_f1: 0.1412\n",
      "Epoch 1284/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2566 - f1: 0.7141 - val_loss: 0.4227 - val_f1: 0.1419\n",
      "Epoch 1285/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2611 - f1: 0.7115 - val_loss: 0.4215 - val_f1: 0.1415\n",
      "Epoch 1286/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2601 - f1: 0.7073 - val_loss: 0.4213 - val_f1: 0.1411\n",
      "Epoch 1287/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2617 - f1: 0.7086 - val_loss: 0.4205 - val_f1: 0.1409\n",
      "Epoch 1288/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2593 - f1: 0.7072 - val_loss: 0.4219 - val_f1: 0.1415\n",
      "Epoch 1289/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2593 - f1: 0.7096 - val_loss: 0.4221 - val_f1: 0.1415\n",
      "Epoch 1290/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2585 - f1: 0.7133 - val_loss: 0.4232 - val_f1: 0.1410\n",
      "Epoch 1291/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2602 - f1: 0.7057 - val_loss: 0.4219 - val_f1: 0.1420\n",
      "Epoch 1292/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2591 - f1: 0.7081 - val_loss: 0.4229 - val_f1: 0.1415\n",
      "Epoch 1293/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2589 - f1: 0.7116 - val_loss: 0.4225 - val_f1: 0.1419\n",
      "Epoch 1294/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2594 - f1: 0.7106 - val_loss: 0.4213 - val_f1: 0.1420\n",
      "Epoch 1295/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2594 - f1: 0.7121 - val_loss: 0.4211 - val_f1: 0.1412\n",
      "Epoch 1296/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2587 - f1: 0.7146 - val_loss: 0.4230 - val_f1: 0.1410\n",
      "Epoch 1297/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2586 - f1: 0.7086 - val_loss: 0.4221 - val_f1: 0.1421\n",
      "Epoch 1298/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2602 - f1: 0.7076 - val_loss: 0.4216 - val_f1: 0.1407\n",
      "Epoch 1299/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2591 - f1: 0.7141 - val_loss: 0.4219 - val_f1: 0.1410\n",
      "Epoch 1300/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2595 - f1: 0.7066 - val_loss: 0.4212 - val_f1: 0.1420\n",
      "Epoch 1301/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2601 - f1: 0.7104 - val_loss: 0.4210 - val_f1: 0.1421\n",
      "Epoch 1302/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2595 - f1: 0.7097 - val_loss: 0.4216 - val_f1: 0.1411\n",
      "Epoch 1303/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2608 - f1: 0.7128 - val_loss: 0.4204 - val_f1: 0.1415\n",
      "Epoch 1304/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2589 - f1: 0.7125 - val_loss: 0.4221 - val_f1: 0.1421\n",
      "Epoch 1305/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2611 - f1: 0.7053 - val_loss: 0.4214 - val_f1: 0.1413\n",
      "Epoch 1306/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2583 - f1: 0.7089 - val_loss: 0.4219 - val_f1: 0.1422\n",
      "Epoch 1307/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2583 - f1: 0.7128 - val_loss: 0.4220 - val_f1: 0.1414\n",
      "Epoch 1308/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2592 - f1: 0.7139 - val_loss: 0.4223 - val_f1: 0.1398\n",
      "Epoch 1309/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2595 - f1: 0.7066 - val_loss: 0.4219 - val_f1: 0.1411\n",
      "Epoch 1310/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2591 - f1: 0.7081 - val_loss: 0.4220 - val_f1: 0.1417\n",
      "Epoch 1311/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2598 - f1: 0.7118 - val_loss: 0.4219 - val_f1: 0.1413\n",
      "Epoch 1312/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2599 - f1: 0.7134 - val_loss: 0.4207 - val_f1: 0.1425\n",
      "Epoch 1313/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2584 - f1: 0.7148 - val_loss: 0.4221 - val_f1: 0.1414\n",
      "Epoch 1314/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2584 - f1: 0.7129 - val_loss: 0.4231 - val_f1: 0.1414\n",
      "Epoch 1315/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2570 - f1: 0.7166 - val_loss: 0.4236 - val_f1: 0.1409\n",
      "Epoch 1316/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2593 - f1: 0.7125 - val_loss: 0.4223 - val_f1: 0.1414\n",
      "Epoch 1317/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2576 - f1: 0.7132 - val_loss: 0.4217 - val_f1: 0.1404\n",
      "Epoch 1318/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2590 - f1: 0.7120 - val_loss: 0.4227 - val_f1: 0.1411\n",
      "Epoch 1319/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2592 - f1: 0.7081 - val_loss: 0.4221 - val_f1: 0.1419\n",
      "Epoch 1320/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2584 - f1: 0.7103 - val_loss: 0.4226 - val_f1: 0.1423\n",
      "Epoch 1321/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2589 - f1: 0.7111 - val_loss: 0.4228 - val_f1: 0.1420\n",
      "Epoch 1322/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2607 - f1: 0.7095 - val_loss: 0.4216 - val_f1: 0.1403\n",
      "Epoch 1323/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2598 - f1: 0.7090 - val_loss: 0.4223 - val_f1: 0.1411\n",
      "Epoch 1324/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2597 - f1: 0.7107 - val_loss: 0.4213 - val_f1: 0.1409\n",
      "Epoch 1325/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2584 - f1: 0.7161 - val_loss: 0.4220 - val_f1: 0.1408\n",
      "Epoch 1326/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2595 - f1: 0.7152 - val_loss: 0.4226 - val_f1: 0.1413\n",
      "Epoch 1327/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2587 - f1: 0.7115 - val_loss: 0.4221 - val_f1: 0.1419\n",
      "Epoch 1328/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2602 - f1: 0.7109 - val_loss: 0.4228 - val_f1: 0.1415\n",
      "Epoch 1329/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2601 - f1: 0.7112 - val_loss: 0.4222 - val_f1: 0.1414\n",
      "Epoch 1330/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2591 - f1: 0.7120 - val_loss: 0.4216 - val_f1: 0.1416\n",
      "Epoch 1331/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2606 - f1: 0.7128 - val_loss: 0.4212 - val_f1: 0.1420\n",
      "Epoch 1332/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2580 - f1: 0.7155 - val_loss: 0.4218 - val_f1: 0.1425\n",
      "Epoch 1333/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2588 - f1: 0.7108 - val_loss: 0.4223 - val_f1: 0.1408\n",
      "Epoch 1334/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2578 - f1: 0.7120 - val_loss: 0.4235 - val_f1: 0.1408\n",
      "Epoch 1335/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2589 - f1: 0.7122 - val_loss: 0.4227 - val_f1: 0.1419\n",
      "Epoch 1336/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2611 - f1: 0.7081 - val_loss: 0.4219 - val_f1: 0.1408\n",
      "Epoch 1337/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2582 - f1: 0.7105 - val_loss: 0.4237 - val_f1: 0.1408\n",
      "Epoch 1338/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2621 - f1: 0.7096 - val_loss: 0.4210 - val_f1: 0.1408\n",
      "Epoch 1339/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2590 - f1: 0.7133 - val_loss: 0.4229 - val_f1: 0.1412\n",
      "Epoch 1340/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2574 - f1: 0.7134 - val_loss: 0.4231 - val_f1: 0.1414\n",
      "Epoch 1341/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2599 - f1: 0.7113 - val_loss: 0.4216 - val_f1: 0.1410\n",
      "Epoch 1342/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2570 - f1: 0.7094 - val_loss: 0.4220 - val_f1: 0.1420\n",
      "Epoch 1343/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2561 - f1: 0.7135 - val_loss: 0.4242 - val_f1: 0.1417\n",
      "Epoch 1344/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2578 - f1: 0.7152 - val_loss: 0.4238 - val_f1: 0.1420\n",
      "Epoch 1345/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2567 - f1: 0.7081 - val_loss: 0.4239 - val_f1: 0.1414\n",
      "Epoch 1346/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2613 - f1: 0.7100 - val_loss: 0.4221 - val_f1: 0.1412\n",
      "Epoch 1347/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2591 - f1: 0.7087 - val_loss: 0.4221 - val_f1: 0.1412\n",
      "Epoch 1348/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2578 - f1: 0.7118 - val_loss: 0.4220 - val_f1: 0.1418\n",
      "Epoch 1349/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2574 - f1: 0.7122 - val_loss: 0.4226 - val_f1: 0.1407\n",
      "Epoch 1350/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2597 - f1: 0.7093 - val_loss: 0.4229 - val_f1: 0.1412\n",
      "Epoch 1351/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2586 - f1: 0.7087 - val_loss: 0.4227 - val_f1: 0.1408\n",
      "Epoch 1352/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2589 - f1: 0.7132 - val_loss: 0.4229 - val_f1: 0.1413\n",
      "Epoch 1353/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2590 - f1: 0.7115 - val_loss: 0.4221 - val_f1: 0.1408\n",
      "Epoch 1354/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2582 - f1: 0.7126 - val_loss: 0.4222 - val_f1: 0.1424\n",
      "Epoch 1355/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2587 - f1: 0.7168 - val_loss: 0.4228 - val_f1: 0.1420\n",
      "Epoch 1356/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2577 - f1: 0.7180 - val_loss: 0.4227 - val_f1: 0.1421\n",
      "Epoch 1357/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2585 - f1: 0.7124 - val_loss: 0.4225 - val_f1: 0.1411\n",
      "Epoch 1358/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2576 - f1: 0.7098 - val_loss: 0.4232 - val_f1: 0.1425\n",
      "Epoch 1359/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2576 - f1: 0.7165 - val_loss: 0.4231 - val_f1: 0.1408\n",
      "Epoch 1360/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.2593 - f1: 0.70 - 2s 34us/step - loss: 0.2588 - f1: 0.7054 - val_loss: 0.4234 - val_f1: 0.1416\n",
      "Epoch 1361/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2583 - f1: 0.7111 - val_loss: 0.4238 - val_f1: 0.1413\n",
      "Epoch 1362/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2566 - f1: 0.7147 - val_loss: 0.4236 - val_f1: 0.1411\n",
      "Epoch 1363/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2572 - f1: 0.7100 - val_loss: 0.4241 - val_f1: 0.1414\n",
      "Epoch 1364/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2598 - f1: 0.7127 - val_loss: 0.4229 - val_f1: 0.1414\n",
      "Epoch 1365/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2590 - f1: 0.7130 - val_loss: 0.4218 - val_f1: 0.1410\n",
      "Epoch 1366/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2579 - f1: 0.7076 - val_loss: 0.4232 - val_f1: 0.1414\n",
      "Epoch 1367/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2583 - f1: 0.7142 - val_loss: 0.4227 - val_f1: 0.1419\n",
      "Epoch 1368/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2599 - f1: 0.7109 - val_loss: 0.4222 - val_f1: 0.1412\n",
      "Epoch 1369/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2600 - f1: 0.7079 - val_loss: 0.4224 - val_f1: 0.1407\n",
      "Epoch 1370/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2578 - f1: 0.7132 - val_loss: 0.4225 - val_f1: 0.1415\n",
      "Epoch 1371/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2598 - f1: 0.7095 - val_loss: 0.4228 - val_f1: 0.1408\n",
      "Epoch 1372/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2586 - f1: 0.7061 - val_loss: 0.4225 - val_f1: 0.1403\n",
      "Epoch 1373/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2601 - f1: 0.7108 - val_loss: 0.4223 - val_f1: 0.1399\n",
      "Epoch 1374/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2589 - f1: 0.7121 - val_loss: 0.4217 - val_f1: 0.1411\n",
      "Epoch 1375/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2556 - f1: 0.7188 - val_loss: 0.4251 - val_f1: 0.1405\n",
      "Epoch 1376/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2593 - f1: 0.7116 - val_loss: 0.4229 - val_f1: 0.1413\n",
      "Epoch 1377/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2578 - f1: 0.7112 - val_loss: 0.4232 - val_f1: 0.1410\n",
      "Epoch 1378/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2589 - f1: 0.7104 - val_loss: 0.4231 - val_f1: 0.1409\n",
      "Epoch 1379/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2578 - f1: 0.7100 - val_loss: 0.4233 - val_f1: 0.1416\n",
      "Epoch 1380/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2583 - f1: 0.7116 - val_loss: 0.4239 - val_f1: 0.1413\n",
      "Epoch 1381/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2572 - f1: 0.7114 - val_loss: 0.4238 - val_f1: 0.1414\n",
      "Epoch 1382/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2590 - f1: 0.7088 - val_loss: 0.4234 - val_f1: 0.1406\n",
      "Epoch 1383/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2556 - f1: 0.7156 - val_loss: 0.4249 - val_f1: 0.1409\n",
      "Epoch 1384/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2567 - f1: 0.7122 - val_loss: 0.4239 - val_f1: 0.1413\n",
      "Epoch 1385/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2599 - f1: 0.7087 - val_loss: 0.4235 - val_f1: 0.1408\n",
      "Epoch 1386/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2585 - f1: 0.7095 - val_loss: 0.4231 - val_f1: 0.1406\n",
      "Epoch 1387/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2576 - f1: 0.7161 - val_loss: 0.4230 - val_f1: 0.1412\n",
      "Epoch 1388/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2579 - f1: 0.7139 - val_loss: 0.4232 - val_f1: 0.1407\n",
      "Epoch 1389/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2578 - f1: 0.7112 - val_loss: 0.4232 - val_f1: 0.1412\n",
      "Epoch 1390/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2575 - f1: 0.7090 - val_loss: 0.4239 - val_f1: 0.1408\n",
      "Epoch 1391/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2588 - f1: 0.7107 - val_loss: 0.4225 - val_f1: 0.1410\n",
      "Epoch 1392/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2588 - f1: 0.7146 - val_loss: 0.4228 - val_f1: 0.1415\n",
      "Epoch 1393/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2590 - f1: 0.7125 - val_loss: 0.4236 - val_f1: 0.1409\n",
      "Epoch 1394/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2565 - f1: 0.7106 - val_loss: 0.4240 - val_f1: 0.1410\n",
      "Epoch 1395/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2594 - f1: 0.7105 - val_loss: 0.4235 - val_f1: 0.1409\n",
      "Epoch 1396/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2562 - f1: 0.7196 - val_loss: 0.4238 - val_f1: 0.1417\n",
      "Epoch 1397/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2571 - f1: 0.7134 - val_loss: 0.4230 - val_f1: 0.1421\n",
      "Epoch 1398/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2576 - f1: 0.7093 - val_loss: 0.4232 - val_f1: 0.1413\n",
      "Epoch 1399/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2569 - f1: 0.7145 - val_loss: 0.4243 - val_f1: 0.1408\n",
      "Epoch 1400/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2578 - f1: 0.7100 - val_loss: 0.4238 - val_f1: 0.1414\n",
      "Epoch 1401/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2559 - f1: 0.7147 - val_loss: 0.4236 - val_f1: 0.1419\n",
      "Epoch 1402/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2583 - f1: 0.7154 - val_loss: 0.4242 - val_f1: 0.1412\n",
      "Epoch 1403/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2583 - f1: 0.7108 - val_loss: 0.4227 - val_f1: 0.1424\n",
      "Epoch 1404/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2588 - f1: 0.7130 - val_loss: 0.4235 - val_f1: 0.1414\n",
      "Epoch 1405/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2573 - f1: 0.7150 - val_loss: 0.4239 - val_f1: 0.1408\n",
      "Epoch 1406/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2572 - f1: 0.7165 - val_loss: 0.4228 - val_f1: 0.1423\n",
      "Epoch 1407/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2570 - f1: 0.7168 - val_loss: 0.4236 - val_f1: 0.1406\n",
      "Epoch 1408/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2578 - f1: 0.7074 - val_loss: 0.4240 - val_f1: 0.1417\n",
      "Epoch 1409/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2565 - f1: 0.7086 - val_loss: 0.4239 - val_f1: 0.1417\n",
      "Epoch 1410/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2559 - f1: 0.7197 - val_loss: 0.4234 - val_f1: 0.1409\n",
      "Epoch 1411/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2552 - f1: 0.7176 - val_loss: 0.4249 - val_f1: 0.1416\n",
      "Epoch 1412/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2592 - f1: 0.7161 - val_loss: 0.4235 - val_f1: 0.1413\n",
      "Epoch 1413/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2575 - f1: 0.7123 - val_loss: 0.4239 - val_f1: 0.1412\n",
      "Epoch 1414/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2583 - f1: 0.7130 - val_loss: 0.4229 - val_f1: 0.1407\n",
      "Epoch 1415/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2556 - f1: 0.7134 - val_loss: 0.4234 - val_f1: 0.1412\n",
      "Epoch 1416/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2573 - f1: 0.7159 - val_loss: 0.4233 - val_f1: 0.1407\n",
      "Epoch 1417/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2548 - f1: 0.7139 - val_loss: 0.4244 - val_f1: 0.1417\n",
      "Epoch 1418/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2597 - f1: 0.7088 - val_loss: 0.4231 - val_f1: 0.1422\n",
      "Epoch 1419/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2558 - f1: 0.7154 - val_loss: 0.4247 - val_f1: 0.1416\n",
      "Epoch 1420/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2575 - f1: 0.7099 - val_loss: 0.4246 - val_f1: 0.1411\n",
      "Epoch 1421/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2579 - f1: 0.7157 - val_loss: 0.4244 - val_f1: 0.1403\n",
      "Epoch 1422/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2553 - f1: 0.7156 - val_loss: 0.4248 - val_f1: 0.1409\n",
      "Epoch 1423/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2581 - f1: 0.7137 - val_loss: 0.4224 - val_f1: 0.1421\n",
      "Epoch 1424/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2595 - f1: 0.7155 - val_loss: 0.4215 - val_f1: 0.1417\n",
      "Epoch 1425/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2552 - f1: 0.7183 - val_loss: 0.4248 - val_f1: 0.1411\n",
      "Epoch 1426/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2568 - f1: 0.7093 - val_loss: 0.4258 - val_f1: 0.1411\n",
      "Epoch 1427/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2553 - f1: 0.7123 - val_loss: 0.4243 - val_f1: 0.1413\n",
      "Epoch 1428/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2566 - f1: 0.7127 - val_loss: 0.4238 - val_f1: 0.1415\n",
      "Epoch 1429/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2564 - f1: 0.7125 - val_loss: 0.4242 - val_f1: 0.1411\n",
      "Epoch 1430/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2564 - f1: 0.7175 - val_loss: 0.4246 - val_f1: 0.1415\n",
      "Epoch 1431/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2580 - f1: 0.7118 - val_loss: 0.4235 - val_f1: 0.1419\n",
      "Epoch 1432/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2570 - f1: 0.7166 - val_loss: 0.4250 - val_f1: 0.1410\n",
      "Epoch 1433/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2565 - f1: 0.7116 - val_loss: 0.4240 - val_f1: 0.1414\n",
      "Epoch 1434/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2559 - f1: 0.7139 - val_loss: 0.4237 - val_f1: 0.1414\n",
      "Epoch 1435/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2544 - f1: 0.7168 - val_loss: 0.4253 - val_f1: 0.1412\n",
      "Epoch 1436/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2570 - f1: 0.7149 - val_loss: 0.4249 - val_f1: 0.1416\n",
      "Epoch 1437/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2581 - f1: 0.7103 - val_loss: 0.4227 - val_f1: 0.1411\n",
      "Epoch 1438/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2574 - f1: 0.7148 - val_loss: 0.4230 - val_f1: 0.1423\n",
      "Epoch 1439/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2583 - f1: 0.7165 - val_loss: 0.4240 - val_f1: 0.1400\n",
      "Epoch 1440/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2566 - f1: 0.7174 - val_loss: 0.4238 - val_f1: 0.1413\n",
      "Epoch 1441/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2576 - f1: 0.7134 - val_loss: 0.4231 - val_f1: 0.1414\n",
      "Epoch 1442/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2551 - f1: 0.7154 - val_loss: 0.4251 - val_f1: 0.1410\n",
      "Epoch 1443/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2570 - f1: 0.7134 - val_loss: 0.4250 - val_f1: 0.1408\n",
      "Epoch 1444/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2586 - f1: 0.7079 - val_loss: 0.4235 - val_f1: 0.1412\n",
      "Epoch 1445/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2564 - f1: 0.7117 - val_loss: 0.4250 - val_f1: 0.1410\n",
      "Epoch 1446/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2571 - f1: 0.7145 - val_loss: 0.4239 - val_f1: 0.1419\n",
      "Epoch 1447/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2582 - f1: 0.7110 - val_loss: 0.4239 - val_f1: 0.1410\n",
      "Epoch 1448/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2567 - f1: 0.7143 - val_loss: 0.4235 - val_f1: 0.1404\n",
      "Epoch 1449/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2572 - f1: 0.7119 - val_loss: 0.4233 - val_f1: 0.1408\n",
      "Epoch 1450/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2565 - f1: 0.7116 - val_loss: 0.4238 - val_f1: 0.1419\n",
      "Epoch 1451/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2552 - f1: 0.7137 - val_loss: 0.4259 - val_f1: 0.1412\n",
      "Epoch 1452/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2563 - f1: 0.7179 - val_loss: 0.4250 - val_f1: 0.1412\n",
      "Epoch 1453/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2580 - f1: 0.7145 - val_loss: 0.4247 - val_f1: 0.1409\n",
      "Epoch 1454/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2572 - f1: 0.7187 - val_loss: 0.4251 - val_f1: 0.1404\n",
      "Epoch 1455/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2565 - f1: 0.7115 - val_loss: 0.4239 - val_f1: 0.1414\n",
      "Epoch 1456/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2545 - f1: 0.7174 - val_loss: 0.4250 - val_f1: 0.1418\n",
      "Epoch 1457/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2562 - f1: 0.7159 - val_loss: 0.4246 - val_f1: 0.1406\n",
      "Epoch 1458/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2577 - f1: 0.7106 - val_loss: 0.4236 - val_f1: 0.1405\n",
      "Epoch 1459/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2569 - f1: 0.7104 - val_loss: 0.4245 - val_f1: 0.1406\n",
      "Epoch 1460/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2568 - f1: 0.7117 - val_loss: 0.4246 - val_f1: 0.1411\n",
      "Epoch 1461/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2558 - f1: 0.7144 - val_loss: 0.4247 - val_f1: 0.1420\n",
      "Epoch 1462/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2560 - f1: 0.7147 - val_loss: 0.4257 - val_f1: 0.1418\n",
      "Epoch 1463/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2565 - f1: 0.7150 - val_loss: 0.4252 - val_f1: 0.1408\n",
      "Epoch 1464/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2558 - f1: 0.7151 - val_loss: 0.4255 - val_f1: 0.1410\n",
      "Epoch 1465/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2586 - f1: 0.7084 - val_loss: 0.4240 - val_f1: 0.1411\n",
      "Epoch 1466/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2576 - f1: 0.7130 - val_loss: 0.4238 - val_f1: 0.1410\n",
      "Epoch 1467/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2585 - f1: 0.7120 - val_loss: 0.4239 - val_f1: 0.1409\n",
      "Epoch 1468/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2585 - f1: 0.7131 - val_loss: 0.4237 - val_f1: 0.1414\n",
      "Epoch 1469/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2566 - f1: 0.7168 - val_loss: 0.4238 - val_f1: 0.1417\n",
      "Epoch 1470/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2580 - f1: 0.7138 - val_loss: 0.4236 - val_f1: 0.1416\n",
      "Epoch 1471/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2560 - f1: 0.7108 - val_loss: 0.4243 - val_f1: 0.1413\n",
      "Epoch 1472/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7160 - val_loss: 0.4249 - val_f1: 0.1410\n",
      "Epoch 1473/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2566 - f1: 0.7122 - val_loss: 0.4239 - val_f1: 0.1410\n",
      "Epoch 1474/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2586 - f1: 0.7134 - val_loss: 0.4236 - val_f1: 0.1410\n",
      "Epoch 1475/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2564 - f1: 0.7175 - val_loss: 0.4255 - val_f1: 0.1402\n",
      "Epoch 1476/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2576 - f1: 0.7136 - val_loss: 0.4238 - val_f1: 0.1418\n",
      "Epoch 1477/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2580 - f1: 0.7103 - val_loss: 0.4241 - val_f1: 0.1416\n",
      "Epoch 1478/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2580 - f1: 0.7132 - val_loss: 0.4242 - val_f1: 0.1411\n",
      "Epoch 1479/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2577 - f1: 0.7091 - val_loss: 0.4224 - val_f1: 0.1424\n",
      "Epoch 1480/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2582 - f1: 0.7093 - val_loss: 0.4242 - val_f1: 0.1412\n",
      "Epoch 1481/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2558 - f1: 0.7171 - val_loss: 0.4255 - val_f1: 0.1413\n",
      "Epoch 1482/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2572 - f1: 0.7132 - val_loss: 0.4241 - val_f1: 0.1414\n",
      "Epoch 1483/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2574 - f1: 0.7162 - val_loss: 0.4250 - val_f1: 0.1406\n",
      "Epoch 1484/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2569 - f1: 0.7193 - val_loss: 0.4242 - val_f1: 0.1416\n",
      "Epoch 1485/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2555 - f1: 0.7150 - val_loss: 0.4255 - val_f1: 0.1410\n",
      "Epoch 1486/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2577 - f1: 0.7117 - val_loss: 0.4236 - val_f1: 0.1415\n",
      "Epoch 1487/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2559 - f1: 0.7111 - val_loss: 0.4247 - val_f1: 0.1409\n",
      "Epoch 1488/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2576 - f1: 0.7176 - val_loss: 0.4235 - val_f1: 0.1409\n",
      "Epoch 1489/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2562 - f1: 0.7158 - val_loss: 0.4244 - val_f1: 0.1415\n",
      "Epoch 1490/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2575 - f1: 0.7134 - val_loss: 0.4240 - val_f1: 0.1407\n",
      "Epoch 1491/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2548 - f1: 0.7188 - val_loss: 0.4255 - val_f1: 0.1412\n",
      "Epoch 1492/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2548 - f1: 0.7174 - val_loss: 0.4255 - val_f1: 0.1416\n",
      "Epoch 1493/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2545 - f1: 0.7161 - val_loss: 0.4247 - val_f1: 0.1419\n",
      "Epoch 1494/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2559 - f1: 0.7131 - val_loss: 0.4249 - val_f1: 0.1410\n",
      "Epoch 1495/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2562 - f1: 0.7174 - val_loss: 0.4238 - val_f1: 0.1411\n",
      "Epoch 1496/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2555 - f1: 0.7170 - val_loss: 0.4243 - val_f1: 0.1413\n",
      "Epoch 1497/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2579 - f1: 0.7131 - val_loss: 0.4238 - val_f1: 0.1407\n",
      "Epoch 1498/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2564 - f1: 0.7163 - val_loss: 0.4237 - val_f1: 0.1404\n",
      "Epoch 1499/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2580 - f1: 0.7125 - val_loss: 0.4230 - val_f1: 0.1411\n",
      "Epoch 1500/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2562 - f1: 0.7129 - val_loss: 0.4243 - val_f1: 0.1410\n",
      "Epoch 1501/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2562 - f1: 0.7092 - val_loss: 0.4234 - val_f1: 0.1411\n",
      "Epoch 1502/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2566 - f1: 0.7140 - val_loss: 0.4248 - val_f1: 0.1420\n",
      "Epoch 1503/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2567 - f1: 0.7146 - val_loss: 0.4243 - val_f1: 0.1411\n",
      "Epoch 1504/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2573 - f1: 0.7107 - val_loss: 0.4239 - val_f1: 0.1410\n",
      "Epoch 1505/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2565 - f1: 0.7104 - val_loss: 0.4234 - val_f1: 0.1413\n",
      "Epoch 1506/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2547 - f1: 0.7172 - val_loss: 0.4248 - val_f1: 0.1409\n",
      "Epoch 1507/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2551 - f1: 0.7179 - val_loss: 0.4250 - val_f1: 0.1403\n",
      "Epoch 1508/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2563 - f1: 0.7121 - val_loss: 0.4244 - val_f1: 0.1415\n",
      "Epoch 1509/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7199 - val_loss: 0.4253 - val_f1: 0.1400\n",
      "Epoch 1510/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2559 - f1: 0.7146 - val_loss: 0.4248 - val_f1: 0.1413\n",
      "Epoch 1511/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2541 - f1: 0.7164 - val_loss: 0.4250 - val_f1: 0.1406\n",
      "Epoch 1512/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2558 - f1: 0.7153 - val_loss: 0.4250 - val_f1: 0.1419\n",
      "Epoch 1513/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2573 - f1: 0.7148 - val_loss: 0.4242 - val_f1: 0.1412\n",
      "Epoch 1514/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2550 - f1: 0.7148 - val_loss: 0.4253 - val_f1: 0.1405\n",
      "Epoch 1515/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2542 - f1: 0.7128 - val_loss: 0.4245 - val_f1: 0.1420\n",
      "Epoch 1516/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2563 - f1: 0.7148 - val_loss: 0.4240 - val_f1: 0.1416\n",
      "Epoch 1517/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2575 - f1: 0.7133 - val_loss: 0.4239 - val_f1: 0.1411\n",
      "Epoch 1518/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2539 - f1: 0.7186 - val_loss: 0.4258 - val_f1: 0.1421\n",
      "Epoch 1519/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2571 - f1: 0.7173 - val_loss: 0.4247 - val_f1: 0.1420\n",
      "Epoch 1520/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2551 - f1: 0.7182 - val_loss: 0.4244 - val_f1: 0.1413\n",
      "Epoch 1521/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2551 - f1: 0.7181 - val_loss: 0.4257 - val_f1: 0.1407\n",
      "Epoch 1522/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2541 - f1: 0.7183 - val_loss: 0.4258 - val_f1: 0.1411\n",
      "Epoch 1523/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2579 - f1: 0.7137 - val_loss: 0.4245 - val_f1: 0.1409\n",
      "Epoch 1524/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2558 - f1: 0.7154 - val_loss: 0.4256 - val_f1: 0.1409\n",
      "Epoch 1525/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2551 - f1: 0.7185 - val_loss: 0.4256 - val_f1: 0.1414\n",
      "Epoch 1526/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7160 - val_loss: 0.4246 - val_f1: 0.1417\n",
      "Epoch 1527/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2556 - f1: 0.7200 - val_loss: 0.4250 - val_f1: 0.1416\n",
      "Epoch 1528/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2562 - f1: 0.7171 - val_loss: 0.4256 - val_f1: 0.1409\n",
      "Epoch 1529/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2539 - f1: 0.7163 - val_loss: 0.4257 - val_f1: 0.1409\n",
      "Epoch 1530/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2545 - f1: 0.7146 - val_loss: 0.4268 - val_f1: 0.1416\n",
      "Epoch 1531/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2553 - f1: 0.7164 - val_loss: 0.4271 - val_f1: 0.1407\n",
      "Epoch 1532/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2564 - f1: 0.7124 - val_loss: 0.4242 - val_f1: 0.1414\n",
      "Epoch 1533/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2566 - f1: 0.7158 - val_loss: 0.4257 - val_f1: 0.1411\n",
      "Epoch 1534/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2550 - f1: 0.7118 - val_loss: 0.4246 - val_f1: 0.1418\n",
      "Epoch 1535/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2571 - f1: 0.7156 - val_loss: 0.4236 - val_f1: 0.1416\n",
      "Epoch 1536/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2527 - f1: 0.7149 - val_loss: 0.4256 - val_f1: 0.1412\n",
      "Epoch 1537/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2576 - f1: 0.7151 - val_loss: 0.4251 - val_f1: 0.1407\n",
      "Epoch 1538/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2569 - f1: 0.7155 - val_loss: 0.4237 - val_f1: 0.1415\n",
      "Epoch 1539/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2551 - f1: 0.7168 - val_loss: 0.4251 - val_f1: 0.1410\n",
      "Epoch 1540/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2553 - f1: 0.7159 - val_loss: 0.4242 - val_f1: 0.1415\n",
      "Epoch 1541/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2537 - f1: 0.7196 - val_loss: 0.4252 - val_f1: 0.1407\n",
      "Epoch 1542/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2564 - f1: 0.7097 - val_loss: 0.4247 - val_f1: 0.1411\n",
      "Epoch 1543/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2554 - f1: 0.7156 - val_loss: 0.4256 - val_f1: 0.1408\n",
      "Epoch 1544/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2551 - f1: 0.7156 - val_loss: 0.4245 - val_f1: 0.1415\n",
      "Epoch 1545/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2557 - f1: 0.7153 - val_loss: 0.4262 - val_f1: 0.1409\n",
      "Epoch 1546/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2549 - f1: 0.7133 - val_loss: 0.4253 - val_f1: 0.1429\n",
      "Epoch 1547/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2552 - f1: 0.7142 - val_loss: 0.4258 - val_f1: 0.1415\n",
      "Epoch 1548/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2565 - f1: 0.7148 - val_loss: 0.4251 - val_f1: 0.1413\n",
      "Epoch 1549/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2552 - f1: 0.7167 - val_loss: 0.4262 - val_f1: 0.1409\n",
      "Epoch 1550/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2564 - f1: 0.7126 - val_loss: 0.4241 - val_f1: 0.1412\n",
      "Epoch 1551/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2549 - f1: 0.7175 - val_loss: 0.4250 - val_f1: 0.1415\n",
      "Epoch 1552/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2547 - f1: 0.7161 - val_loss: 0.4249 - val_f1: 0.1421\n",
      "Epoch 1553/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2533 - f1: 0.7154 - val_loss: 0.4275 - val_f1: 0.1411\n",
      "Epoch 1554/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2533 - f1: 0.7209 - val_loss: 0.4258 - val_f1: 0.1421\n",
      "Epoch 1555/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2557 - f1: 0.7142 - val_loss: 0.4252 - val_f1: 0.1417\n",
      "Epoch 1556/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2538 - f1: 0.7194 - val_loss: 0.4263 - val_f1: 0.1413\n",
      "Epoch 1557/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2559 - f1: 0.7126 - val_loss: 0.4254 - val_f1: 0.1409\n",
      "Epoch 1558/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7205 - val_loss: 0.4260 - val_f1: 0.1414\n",
      "Epoch 1559/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7187 - val_loss: 0.4263 - val_f1: 0.1411\n",
      "Epoch 1560/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2563 - f1: 0.7128 - val_loss: 0.4240 - val_f1: 0.1411\n",
      "Epoch 1561/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2577 - f1: 0.7114 - val_loss: 0.4231 - val_f1: 0.1407\n",
      "Epoch 1562/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2570 - f1: 0.7138 - val_loss: 0.4246 - val_f1: 0.1415\n",
      "Epoch 1563/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2550 - f1: 0.7161 - val_loss: 0.4258 - val_f1: 0.1407\n",
      "Epoch 1564/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2547 - f1: 0.7139 - val_loss: 0.4251 - val_f1: 0.1416\n",
      "Epoch 1565/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2578 - f1: 0.7128 - val_loss: 0.4238 - val_f1: 0.1412\n",
      "Epoch 1566/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7156 - val_loss: 0.4253 - val_f1: 0.1411\n",
      "Epoch 1567/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2563 - f1: 0.7154 - val_loss: 0.4250 - val_f1: 0.1408\n",
      "Epoch 1568/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2547 - f1: 0.7176 - val_loss: 0.4253 - val_f1: 0.1418\n",
      "Epoch 1569/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2549 - f1: 0.7196 - val_loss: 0.4257 - val_f1: 0.1412\n",
      "Epoch 1570/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2551 - f1: 0.7197 - val_loss: 0.4260 - val_f1: 0.1409\n",
      "Epoch 1571/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2558 - f1: 0.7157 - val_loss: 0.4241 - val_f1: 0.1402\n",
      "Epoch 1572/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2542 - f1: 0.7183 - val_loss: 0.4261 - val_f1: 0.1412\n",
      "Epoch 1573/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2545 - f1: 0.7152 - val_loss: 0.4257 - val_f1: 0.1409\n",
      "Epoch 1574/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2552 - f1: 0.7173 - val_loss: 0.4265 - val_f1: 0.1409\n",
      "Epoch 1575/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2548 - f1: 0.7129 - val_loss: 0.4255 - val_f1: 0.1414\n",
      "Epoch 1576/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2556 - f1: 0.7119 - val_loss: 0.4249 - val_f1: 0.1414\n",
      "Epoch 1577/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7206 - val_loss: 0.4250 - val_f1: 0.1415\n",
      "Epoch 1578/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2566 - f1: 0.7118 - val_loss: 0.4263 - val_f1: 0.1407\n",
      "Epoch 1579/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2542 - f1: 0.7190 - val_loss: 0.4258 - val_f1: 0.1412\n",
      "Epoch 1580/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2560 - f1: 0.7161 - val_loss: 0.4254 - val_f1: 0.1414\n",
      "Epoch 1581/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2563 - f1: 0.7160 - val_loss: 0.4237 - val_f1: 0.1404\n",
      "Epoch 1582/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2549 - f1: 0.7133 - val_loss: 0.4250 - val_f1: 0.1406\n",
      "Epoch 1583/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7193 - val_loss: 0.4242 - val_f1: 0.1411\n",
      "Epoch 1584/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2526 - f1: 0.7201 - val_loss: 0.4270 - val_f1: 0.1405\n",
      "Epoch 1585/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2545 - f1: 0.7195 - val_loss: 0.4256 - val_f1: 0.1408\n",
      "Epoch 1586/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7163 - val_loss: 0.4256 - val_f1: 0.1411\n",
      "Epoch 1587/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2544 - f1: 0.7168 - val_loss: 0.4261 - val_f1: 0.1418\n",
      "Epoch 1588/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2528 - f1: 0.7245 - val_loss: 0.4264 - val_f1: 0.1412\n",
      "Epoch 1589/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2527 - f1: 0.7168 - val_loss: 0.4265 - val_f1: 0.1410\n",
      "Epoch 1590/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2570 - f1: 0.7128 - val_loss: 0.4248 - val_f1: 0.1415\n",
      "Epoch 1591/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2556 - f1: 0.7183 - val_loss: 0.4255 - val_f1: 0.1404\n",
      "Epoch 1592/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7213 - val_loss: 0.4253 - val_f1: 0.1413\n",
      "Epoch 1593/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2567 - f1: 0.7157 - val_loss: 0.4251 - val_f1: 0.1401\n",
      "Epoch 1594/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2564 - f1: 0.7155 - val_loss: 0.4246 - val_f1: 0.1419\n",
      "Epoch 1595/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2575 - f1: 0.7123 - val_loss: 0.4233 - val_f1: 0.1412\n",
      "Epoch 1596/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2543 - f1: 0.7161 - val_loss: 0.4254 - val_f1: 0.1407\n",
      "Epoch 1597/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2545 - f1: 0.7197 - val_loss: 0.4257 - val_f1: 0.1416\n",
      "Epoch 1598/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2567 - f1: 0.7140 - val_loss: 0.4249 - val_f1: 0.1422\n",
      "Epoch 1599/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7124 - val_loss: 0.4262 - val_f1: 0.1414\n",
      "Epoch 1600/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2552 - f1: 0.7165 - val_loss: 0.4254 - val_f1: 0.1416\n",
      "Epoch 1601/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2548 - f1: 0.7149 - val_loss: 0.4254 - val_f1: 0.1408\n",
      "Epoch 1602/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2543 - f1: 0.7158 - val_loss: 0.4257 - val_f1: 0.1411\n",
      "Epoch 1603/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2536 - f1: 0.7206 - val_loss: 0.4255 - val_f1: 0.1413\n",
      "Epoch 1604/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2511 - f1: 0.7230 - val_loss: 0.4269 - val_f1: 0.1419\n",
      "Epoch 1605/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2543 - f1: 0.7189 - val_loss: 0.4270 - val_f1: 0.1416\n",
      "Epoch 1606/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2551 - f1: 0.7199 - val_loss: 0.4257 - val_f1: 0.1408\n",
      "Epoch 1607/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2532 - f1: 0.7161 - val_loss: 0.4271 - val_f1: 0.1419\n",
      "Epoch 1608/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2552 - f1: 0.7146 - val_loss: 0.4256 - val_f1: 0.1411\n",
      "Epoch 1609/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2556 - f1: 0.7154 - val_loss: 0.4268 - val_f1: 0.1413\n",
      "Epoch 1610/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2570 - f1: 0.7160 - val_loss: 0.4247 - val_f1: 0.1405\n",
      "Epoch 1611/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2535 - f1: 0.7223 - val_loss: 0.4250 - val_f1: 0.1411\n",
      "Epoch 1612/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2528 - f1: 0.7179 - val_loss: 0.4270 - val_f1: 0.1413\n",
      "Epoch 1613/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2551 - f1: 0.7187 - val_loss: 0.4260 - val_f1: 0.1419\n",
      "Epoch 1614/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2559 - f1: 0.7121 - val_loss: 0.4257 - val_f1: 0.1405\n",
      "Epoch 1615/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2562 - f1: 0.7147 - val_loss: 0.4250 - val_f1: 0.1407\n",
      "Epoch 1616/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2541 - f1: 0.7162 - val_loss: 0.4257 - val_f1: 0.1413\n",
      "Epoch 1617/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2552 - f1: 0.7202 - val_loss: 0.4252 - val_f1: 0.1407\n",
      "Epoch 1618/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2544 - f1: 0.7149 - val_loss: 0.4246 - val_f1: 0.1406\n",
      "Epoch 1619/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2537 - f1: 0.7154 - val_loss: 0.4262 - val_f1: 0.1405\n",
      "Epoch 1620/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2564 - f1: 0.7169 - val_loss: 0.4257 - val_f1: 0.1411\n",
      "Epoch 1621/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2560 - f1: 0.7114 - val_loss: 0.4251 - val_f1: 0.1417\n",
      "Epoch 1622/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2547 - f1: 0.7179 - val_loss: 0.4257 - val_f1: 0.1408\n",
      "Epoch 1623/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2505 - f1: 0.7211 - val_loss: 0.4267 - val_f1: 0.1410\n",
      "Epoch 1624/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2536 - f1: 0.7219 - val_loss: 0.4263 - val_f1: 0.1413\n",
      "Epoch 1625/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2549 - f1: 0.7168 - val_loss: 0.4256 - val_f1: 0.1410\n",
      "Epoch 1626/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2538 - f1: 0.7188 - val_loss: 0.4256 - val_f1: 0.1419\n",
      "Epoch 1627/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2526 - f1: 0.7221 - val_loss: 0.4261 - val_f1: 0.1418\n",
      "Epoch 1628/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2553 - f1: 0.7167 - val_loss: 0.4256 - val_f1: 0.1412\n",
      "Epoch 1629/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2525 - f1: 0.7211 - val_loss: 0.4264 - val_f1: 0.1410\n",
      "Epoch 1630/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2537 - f1: 0.7200 - val_loss: 0.4258 - val_f1: 0.1409\n",
      "Epoch 1631/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7154 - val_loss: 0.4249 - val_f1: 0.1425\n",
      "Epoch 1632/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2550 - f1: 0.7181 - val_loss: 0.4265 - val_f1: 0.1412\n",
      "Epoch 1633/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2538 - f1: 0.7183 - val_loss: 0.4268 - val_f1: 0.1424\n",
      "Epoch 1634/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2542 - f1: 0.7176 - val_loss: 0.4262 - val_f1: 0.1416\n",
      "Epoch 1635/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2536 - f1: 0.7202 - val_loss: 0.4257 - val_f1: 0.1411\n",
      "Epoch 1636/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2569 - f1: 0.7109 - val_loss: 0.4254 - val_f1: 0.1412\n",
      "Epoch 1637/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2548 - f1: 0.7162 - val_loss: 0.4254 - val_f1: 0.1410\n",
      "Epoch 1638/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2529 - f1: 0.7216 - val_loss: 0.4254 - val_f1: 0.1406\n",
      "Epoch 1639/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2548 - f1: 0.7140 - val_loss: 0.4259 - val_f1: 0.1409\n",
      "Epoch 1640/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2551 - f1: 0.7144 - val_loss: 0.4257 - val_f1: 0.1416\n",
      "Epoch 1641/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2567 - f1: 0.7161 - val_loss: 0.4257 - val_f1: 0.1408\n",
      "Epoch 1642/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2555 - f1: 0.7190 - val_loss: 0.4249 - val_f1: 0.1416\n",
      "Epoch 1643/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2551 - f1: 0.7148 - val_loss: 0.4248 - val_f1: 0.1417\n",
      "Epoch 1644/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2527 - f1: 0.7174 - val_loss: 0.4270 - val_f1: 0.1405\n",
      "Epoch 1645/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2556 - f1: 0.7173 - val_loss: 0.4261 - val_f1: 0.1417\n",
      "Epoch 1646/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2520 - f1: 0.7212 - val_loss: 0.4272 - val_f1: 0.1413\n",
      "Epoch 1647/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2541 - f1: 0.7203 - val_loss: 0.4256 - val_f1: 0.1411\n",
      "Epoch 1648/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2550 - f1: 0.7143 - val_loss: 0.4259 - val_f1: 0.1408\n",
      "Epoch 1649/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2553 - f1: 0.7168 - val_loss: 0.4243 - val_f1: 0.1416\n",
      "Epoch 1650/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2539 - f1: 0.7158 - val_loss: 0.4252 - val_f1: 0.1417\n",
      "Epoch 1651/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2513 - f1: 0.7223 - val_loss: 0.4269 - val_f1: 0.1420\n",
      "Epoch 1652/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2566 - f1: 0.7166 - val_loss: 0.4250 - val_f1: 0.1420\n",
      "Epoch 1653/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2540 - f1: 0.7176 - val_loss: 0.4259 - val_f1: 0.1409\n",
      "Epoch 1654/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2537 - f1: 0.7153 - val_loss: 0.4261 - val_f1: 0.1400\n",
      "Epoch 1655/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2539 - f1: 0.7163 - val_loss: 0.4256 - val_f1: 0.1410\n",
      "Epoch 1656/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2545 - f1: 0.7164 - val_loss: 0.4254 - val_f1: 0.1420\n",
      "Epoch 1657/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2542 - f1: 0.7145 - val_loss: 0.4263 - val_f1: 0.1412\n",
      "Epoch 1658/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2498 - f1: 0.7247 - val_loss: 0.4272 - val_f1: 0.1411\n",
      "Epoch 1659/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2530 - f1: 0.7202 - val_loss: 0.4273 - val_f1: 0.1414\n",
      "Epoch 1660/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2548 - f1: 0.7164 - val_loss: 0.4253 - val_f1: 0.1412\n",
      "Epoch 1661/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2576 - f1: 0.7105 - val_loss: 0.4247 - val_f1: 0.1411\n",
      "Epoch 1662/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2544 - f1: 0.7186 - val_loss: 0.4250 - val_f1: 0.1416\n",
      "Epoch 1663/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2560 - f1: 0.7135 - val_loss: 0.4249 - val_f1: 0.1407\n",
      "Epoch 1664/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2529 - f1: 0.7185 - val_loss: 0.4248 - val_f1: 0.1421\n",
      "Epoch 1665/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2537 - f1: 0.7170 - val_loss: 0.4262 - val_f1: 0.1410\n",
      "Epoch 1666/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2524 - f1: 0.7203 - val_loss: 0.4265 - val_f1: 0.1406\n",
      "Epoch 1667/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2534 - f1: 0.7189 - val_loss: 0.4262 - val_f1: 0.1413\n",
      "Epoch 1668/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2538 - f1: 0.7189 - val_loss: 0.4261 - val_f1: 0.1410\n",
      "Epoch 1669/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2544 - f1: 0.7198 - val_loss: 0.4267 - val_f1: 0.1414\n",
      "Epoch 1670/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2529 - f1: 0.7198 - val_loss: 0.4268 - val_f1: 0.1413\n",
      "Epoch 1671/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2531 - f1: 0.7190 - val_loss: 0.4268 - val_f1: 0.1411\n",
      "Epoch 1672/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2528 - f1: 0.7191 - val_loss: 0.4265 - val_f1: 0.1413\n",
      "Epoch 1673/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2546 - f1: 0.7233 - val_loss: 0.4246 - val_f1: 0.1415\n",
      "Epoch 1674/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2533 - f1: 0.7189 - val_loss: 0.4255 - val_f1: 0.1415\n",
      "Epoch 1675/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2548 - f1: 0.7185 - val_loss: 0.4249 - val_f1: 0.1412\n",
      "Epoch 1676/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2536 - f1: 0.7180 - val_loss: 0.4263 - val_f1: 0.1404\n",
      "Epoch 1677/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2540 - f1: 0.7149 - val_loss: 0.4256 - val_f1: 0.1418\n",
      "Epoch 1678/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2502 - f1: 0.7238 - val_loss: 0.4275 - val_f1: 0.1405\n",
      "Epoch 1679/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2556 - f1: 0.7148 - val_loss: 0.4265 - val_f1: 0.1409\n",
      "Epoch 1680/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2533 - f1: 0.7166 - val_loss: 0.4264 - val_f1: 0.1413\n",
      "Epoch 1681/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2547 - f1: 0.7206 - val_loss: 0.4260 - val_f1: 0.1407\n",
      "Epoch 1682/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2537 - f1: 0.7208 - val_loss: 0.4260 - val_f1: 0.1406\n",
      "Epoch 1683/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2548 - f1: 0.7160 - val_loss: 0.4260 - val_f1: 0.1411\n",
      "Epoch 1684/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2538 - f1: 0.7169 - val_loss: 0.4256 - val_f1: 0.1413\n",
      "Epoch 1685/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2552 - f1: 0.7109 - val_loss: 0.4255 - val_f1: 0.1406\n",
      "Epoch 1686/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2522 - f1: 0.7258 - val_loss: 0.4280 - val_f1: 0.1411\n",
      "Epoch 1687/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2534 - f1: 0.7191 - val_loss: 0.4275 - val_f1: 0.1410\n",
      "Epoch 1688/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2534 - f1: 0.7215 - val_loss: 0.4268 - val_f1: 0.1416\n",
      "Epoch 1689/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2554 - f1: 0.7142 - val_loss: 0.4253 - val_f1: 0.1416\n",
      "Epoch 1690/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2518 - f1: 0.7214 - val_loss: 0.4282 - val_f1: 0.1414\n",
      "Epoch 1691/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2560 - f1: 0.7150 - val_loss: 0.4263 - val_f1: 0.1417\n",
      "Epoch 1692/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2553 - f1: 0.7137 - val_loss: 0.4254 - val_f1: 0.1411\n",
      "Epoch 1693/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2525 - f1: 0.7196 - val_loss: 0.4265 - val_f1: 0.1424\n",
      "Epoch 1694/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2512 - f1: 0.7198 - val_loss: 0.4282 - val_f1: 0.1411\n",
      "Epoch 1695/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2556 - f1: 0.7154 - val_loss: 0.4253 - val_f1: 0.1413\n",
      "Epoch 1696/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2543 - f1: 0.7207 - val_loss: 0.4251 - val_f1: 0.1423\n",
      "Epoch 1697/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2548 - f1: 0.7149 - val_loss: 0.4251 - val_f1: 0.1417\n",
      "Epoch 1698/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2534 - f1: 0.7148 - val_loss: 0.4259 - val_f1: 0.1408\n",
      "Epoch 1699/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2541 - f1: 0.7201 - val_loss: 0.4269 - val_f1: 0.1417\n",
      "Epoch 1700/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2529 - f1: 0.7205 - val_loss: 0.4269 - val_f1: 0.1417\n",
      "Epoch 1701/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2542 - f1: 0.7188 - val_loss: 0.4261 - val_f1: 0.1423\n",
      "Epoch 1702/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2532 - f1: 0.7187 - val_loss: 0.4261 - val_f1: 0.1425\n",
      "Epoch 1703/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2550 - f1: 0.7182 - val_loss: 0.4255 - val_f1: 0.1422\n",
      "Epoch 1704/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2542 - f1: 0.7165 - val_loss: 0.4252 - val_f1: 0.1422\n",
      "Epoch 1705/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2519 - f1: 0.7212 - val_loss: 0.4270 - val_f1: 0.1421\n",
      "Epoch 1706/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2535 - f1: 0.7205 - val_loss: 0.4264 - val_f1: 0.1424\n",
      "Epoch 1707/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2542 - f1: 0.7204 - val_loss: 0.4259 - val_f1: 0.1422\n",
      "Epoch 1708/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2533 - f1: 0.7204 - val_loss: 0.4259 - val_f1: 0.1419\n",
      "Epoch 1709/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2534 - f1: 0.7167 - val_loss: 0.4265 - val_f1: 0.1416\n",
      "Epoch 1710/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2539 - f1: 0.7198 - val_loss: 0.4258 - val_f1: 0.1422\n",
      "Epoch 1711/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2520 - f1: 0.7204 - val_loss: 0.4275 - val_f1: 0.1418\n",
      "Epoch 1712/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2542 - f1: 0.7190 - val_loss: 0.4262 - val_f1: 0.1415\n",
      "Epoch 1713/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2548 - f1: 0.7200 - val_loss: 0.4249 - val_f1: 0.1420\n",
      "Epoch 1714/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2551 - f1: 0.7120 - val_loss: 0.4251 - val_f1: 0.1410\n",
      "Epoch 1715/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2533 - f1: 0.7219 - val_loss: 0.4260 - val_f1: 0.1413\n",
      "Epoch 1716/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2542 - f1: 0.7171 - val_loss: 0.4269 - val_f1: 0.1409\n",
      "Epoch 1717/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2518 - f1: 0.7211 - val_loss: 0.4271 - val_f1: 0.1407\n",
      "Epoch 1718/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2520 - f1: 0.7214 - val_loss: 0.4280 - val_f1: 0.1419\n",
      "Epoch 1719/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2522 - f1: 0.7184 - val_loss: 0.4271 - val_f1: 0.1418\n",
      "Epoch 1720/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2522 - f1: 0.7208 - val_loss: 0.4287 - val_f1: 0.1403\n",
      "Epoch 1721/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2532 - f1: 0.7186 - val_loss: 0.4270 - val_f1: 0.1413\n",
      "Epoch 1722/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2520 - f1: 0.7221 - val_loss: 0.4271 - val_f1: 0.1411\n",
      "Epoch 1723/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2513 - f1: 0.7212 - val_loss: 0.4273 - val_f1: 0.1419\n",
      "Epoch 1724/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2513 - f1: 0.7185 - val_loss: 0.4273 - val_f1: 0.1424\n",
      "Epoch 1725/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2517 - f1: 0.7228 - val_loss: 0.4273 - val_f1: 0.1416\n",
      "Epoch 1726/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2527 - f1: 0.7208 - val_loss: 0.4259 - val_f1: 0.1413\n",
      "Epoch 1727/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2542 - f1: 0.7160 - val_loss: 0.4267 - val_f1: 0.1417\n",
      "Epoch 1728/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2546 - f1: 0.7227 - val_loss: 0.4255 - val_f1: 0.1417\n",
      "Epoch 1729/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2513 - f1: 0.7253 - val_loss: 0.4271 - val_f1: 0.1410\n",
      "Epoch 1730/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2528 - f1: 0.7180 - val_loss: 0.4270 - val_f1: 0.1411\n",
      "Epoch 1731/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2522 - f1: 0.7200 - val_loss: 0.4274 - val_f1: 0.1416\n",
      "Epoch 1732/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2517 - f1: 0.7179 - val_loss: 0.4277 - val_f1: 0.1413\n",
      "Epoch 1733/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2528 - f1: 0.7228 - val_loss: 0.4272 - val_f1: 0.1414\n",
      "Epoch 1734/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2510 - f1: 0.7169 - val_loss: 0.4286 - val_f1: 0.1408\n",
      "Epoch 1735/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2524 - f1: 0.7199 - val_loss: 0.4275 - val_f1: 0.1417\n",
      "Epoch 1736/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2552 - f1: 0.7119 - val_loss: 0.4259 - val_f1: 0.1408\n",
      "Epoch 1737/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2519 - f1: 0.7231 - val_loss: 0.4281 - val_f1: 0.1402\n",
      "Epoch 1738/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2524 - f1: 0.7184 - val_loss: 0.4269 - val_f1: 0.1407\n",
      "Epoch 1739/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2526 - f1: 0.7219 - val_loss: 0.4267 - val_f1: 0.1417\n",
      "Epoch 1740/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2556 - f1: 0.7183 - val_loss: 0.4259 - val_f1: 0.1413\n",
      "Epoch 1741/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2539 - f1: 0.7228 - val_loss: 0.4260 - val_f1: 0.1417\n",
      "Epoch 1742/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2534 - f1: 0.7178 - val_loss: 0.4267 - val_f1: 0.1404\n",
      "Epoch 1743/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2523 - f1: 0.7225 - val_loss: 0.4279 - val_f1: 0.1408\n",
      "Epoch 1744/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2532 - f1: 0.7204 - val_loss: 0.4271 - val_f1: 0.1416\n",
      "Epoch 1745/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2531 - f1: 0.7210 - val_loss: 0.4265 - val_f1: 0.1417\n",
      "Epoch 1746/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2526 - f1: 0.7206 - val_loss: 0.4272 - val_f1: 0.1414\n",
      "Epoch 1747/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2526 - f1: 0.7235 - val_loss: 0.4284 - val_f1: 0.1416\n",
      "Epoch 1748/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2545 - f1: 0.7156 - val_loss: 0.4270 - val_f1: 0.1417\n",
      "Epoch 1749/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2551 - f1: 0.7172 - val_loss: 0.4257 - val_f1: 0.1411\n",
      "Epoch 1750/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2536 - f1: 0.7186 - val_loss: 0.4260 - val_f1: 0.1416\n",
      "Epoch 1751/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2552 - f1: 0.7162 - val_loss: 0.4255 - val_f1: 0.1415\n",
      "Epoch 1752/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2534 - f1: 0.7185 - val_loss: 0.4260 - val_f1: 0.1418\n",
      "Epoch 1753/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2541 - f1: 0.7253 - val_loss: 0.4262 - val_f1: 0.1416\n",
      "Epoch 1754/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2543 - f1: 0.7162 - val_loss: 0.4258 - val_f1: 0.1415\n",
      "Epoch 1755/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2542 - f1: 0.7179 - val_loss: 0.4265 - val_f1: 0.1406\n",
      "Epoch 1756/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2512 - f1: 0.7246 - val_loss: 0.4274 - val_f1: 0.1413\n",
      "Epoch 1757/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2557 - f1: 0.7151 - val_loss: 0.4257 - val_f1: 0.1411\n",
      "Epoch 1758/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2528 - f1: 0.7155 - val_loss: 0.4259 - val_f1: 0.1412\n",
      "Epoch 1759/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2532 - f1: 0.7203 - val_loss: 0.4269 - val_f1: 0.1411\n",
      "Epoch 1760/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2514 - f1: 0.7202 - val_loss: 0.4274 - val_f1: 0.1409\n",
      "Epoch 1761/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2534 - f1: 0.7189 - val_loss: 0.4265 - val_f1: 0.1416\n",
      "Epoch 1762/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2519 - f1: 0.7228 - val_loss: 0.4278 - val_f1: 0.1408\n",
      "Epoch 1763/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2532 - f1: 0.7158 - val_loss: 0.4273 - val_f1: 0.1422\n",
      "Epoch 1764/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2533 - f1: 0.7185 - val_loss: 0.4274 - val_f1: 0.1413\n",
      "Epoch 1765/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2519 - f1: 0.7196 - val_loss: 0.4280 - val_f1: 0.1419\n",
      "Epoch 1766/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2517 - f1: 0.7227 - val_loss: 0.4278 - val_f1: 0.1412\n",
      "Epoch 1767/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2517 - f1: 0.7264 - val_loss: 0.4271 - val_f1: 0.1413\n",
      "Epoch 1768/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2504 - f1: 0.7237 - val_loss: 0.4279 - val_f1: 0.1413\n",
      "Epoch 1769/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2520 - f1: 0.7202 - val_loss: 0.4283 - val_f1: 0.1410\n",
      "Epoch 1770/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2497 - f1: 0.7249 - val_loss: 0.4292 - val_f1: 0.1408\n",
      "Epoch 1771/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2529 - f1: 0.7214 - val_loss: 0.4281 - val_f1: 0.1409\n",
      "Epoch 1772/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2530 - f1: 0.7159 - val_loss: 0.4268 - val_f1: 0.1425\n",
      "Epoch 1773/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2505 - f1: 0.7245 - val_loss: 0.4283 - val_f1: 0.1413\n",
      "Epoch 1774/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2517 - f1: 0.7200 - val_loss: 0.4277 - val_f1: 0.1413\n",
      "Epoch 1775/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2537 - f1: 0.7209 - val_loss: 0.4264 - val_f1: 0.1422\n",
      "Epoch 1776/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2552 - f1: 0.7205 - val_loss: 0.4255 - val_f1: 0.1409\n",
      "Epoch 1777/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2534 - f1: 0.7201 - val_loss: 0.4254 - val_f1: 0.1406\n",
      "Epoch 1778/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2513 - f1: 0.7218 - val_loss: 0.4271 - val_f1: 0.1412\n",
      "Epoch 1779/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2514 - f1: 0.7231 - val_loss: 0.4273 - val_f1: 0.1408\n",
      "Epoch 1780/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2521 - f1: 0.7231 - val_loss: 0.4267 - val_f1: 0.1425\n",
      "Epoch 1781/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2531 - f1: 0.7215 - val_loss: 0.4271 - val_f1: 0.1408\n",
      "Epoch 1782/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2534 - f1: 0.7164 - val_loss: 0.4265 - val_f1: 0.1414\n",
      "Epoch 1783/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2532 - f1: 0.7157 - val_loss: 0.4261 - val_f1: 0.1419\n",
      "Epoch 1784/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2530 - f1: 0.7209 - val_loss: 0.4269 - val_f1: 0.1409\n",
      "Epoch 1785/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2539 - f1: 0.7206 - val_loss: 0.4261 - val_f1: 0.1408\n",
      "Epoch 1786/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2535 - f1: 0.7158 - val_loss: 0.4263 - val_f1: 0.1420\n",
      "Epoch 1787/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2535 - f1: 0.7200 - val_loss: 0.4272 - val_f1: 0.1405\n",
      "Epoch 1788/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2524 - f1: 0.7209 - val_loss: 0.4272 - val_f1: 0.1405\n",
      "Epoch 1789/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2526 - f1: 0.7181 - val_loss: 0.4267 - val_f1: 0.1428\n",
      "Epoch 1790/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2536 - f1: 0.7189 - val_loss: 0.4276 - val_f1: 0.1425\n",
      "Epoch 1791/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2523 - f1: 0.7203 - val_loss: 0.4268 - val_f1: 0.1416\n",
      "Epoch 1792/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2529 - f1: 0.7183 - val_loss: 0.4277 - val_f1: 0.1413\n",
      "Epoch 1793/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2503 - f1: 0.7193 - val_loss: 0.4284 - val_f1: 0.1419\n",
      "Epoch 1794/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2539 - f1: 0.7196 - val_loss: 0.4274 - val_f1: 0.1420\n",
      "Epoch 1795/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2570 - f1: 0.7132 - val_loss: 0.4242 - val_f1: 0.1418\n",
      "Epoch 1796/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2509 - f1: 0.7213 - val_loss: 0.4278 - val_f1: 0.1408\n",
      "Epoch 1797/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2511 - f1: 0.7203 - val_loss: 0.4267 - val_f1: 0.1416\n",
      "Epoch 1798/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2526 - f1: 0.7182 - val_loss: 0.4275 - val_f1: 0.1425\n",
      "Epoch 1799/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2529 - f1: 0.7163 - val_loss: 0.4270 - val_f1: 0.1418\n",
      "Epoch 1800/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2524 - f1: 0.7230 - val_loss: 0.4268 - val_f1: 0.1414\n",
      "Epoch 1801/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2544 - f1: 0.7194 - val_loss: 0.4261 - val_f1: 0.1410\n",
      "Epoch 1802/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2522 - f1: 0.7231 - val_loss: 0.4274 - val_f1: 0.1406\n",
      "Epoch 1803/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2542 - f1: 0.7187 - val_loss: 0.4280 - val_f1: 0.1409\n",
      "Epoch 1804/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2533 - f1: 0.7192 - val_loss: 0.4274 - val_f1: 0.1413\n",
      "Epoch 1805/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2530 - f1: 0.7183 - val_loss: 0.4263 - val_f1: 0.1416\n",
      "Epoch 1806/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2517 - f1: 0.7213 - val_loss: 0.4269 - val_f1: 0.1416\n",
      "Epoch 1807/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2489 - f1: 0.7259 - val_loss: 0.4286 - val_f1: 0.1414\n",
      "Epoch 1808/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2522 - f1: 0.7174 - val_loss: 0.4282 - val_f1: 0.1417\n",
      "Epoch 1809/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2535 - f1: 0.7167 - val_loss: 0.4272 - val_f1: 0.1416\n",
      "Epoch 1810/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2504 - f1: 0.7195 - val_loss: 0.4279 - val_f1: 0.1416\n",
      "Epoch 1811/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2535 - f1: 0.7193 - val_loss: 0.4264 - val_f1: 0.1425\n",
      "Epoch 1812/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2534 - f1: 0.7181 - val_loss: 0.4266 - val_f1: 0.1414\n",
      "Epoch 1813/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2534 - f1: 0.7196 - val_loss: 0.4259 - val_f1: 0.1414\n",
      "Epoch 1814/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2519 - f1: 0.7202 - val_loss: 0.4273 - val_f1: 0.1416\n",
      "Epoch 1815/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2526 - f1: 0.7233 - val_loss: 0.4284 - val_f1: 0.1412\n",
      "Epoch 1816/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2517 - f1: 0.7246 - val_loss: 0.4277 - val_f1: 0.1416\n",
      "Epoch 1817/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2506 - f1: 0.7231 - val_loss: 0.4279 - val_f1: 0.1411\n",
      "Epoch 1818/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2535 - f1: 0.7210 - val_loss: 0.4271 - val_f1: 0.1420\n",
      "Epoch 1819/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2528 - f1: 0.7231 - val_loss: 0.4274 - val_f1: 0.1415\n",
      "Epoch 1820/2000\n",
      "64440/64440 [==============================] - 2s 32us/step - loss: 0.2521 - f1: 0.7155 - val_loss: 0.4274 - val_f1: 0.1416\n",
      "Epoch 1821/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2518 - f1: 0.7217 - val_loss: 0.4276 - val_f1: 0.1409\n",
      "Epoch 1822/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2529 - f1: 0.7213 - val_loss: 0.4266 - val_f1: 0.1418\n",
      "Epoch 1823/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2529 - f1: 0.7202 - val_loss: 0.4266 - val_f1: 0.1419\n",
      "Epoch 1824/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2507 - f1: 0.7248 - val_loss: 0.4281 - val_f1: 0.1423\n",
      "Epoch 1825/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2522 - f1: 0.7175 - val_loss: 0.4277 - val_f1: 0.1420\n",
      "Epoch 1826/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2526 - f1: 0.7199 - val_loss: 0.4269 - val_f1: 0.1422\n",
      "Epoch 1827/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2504 - f1: 0.7209 - val_loss: 0.4281 - val_f1: 0.1417\n",
      "Epoch 1828/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2520 - f1: 0.7195 - val_loss: 0.4266 - val_f1: 0.1412\n",
      "Epoch 1829/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2528 - f1: 0.7200 - val_loss: 0.4263 - val_f1: 0.1424\n",
      "Epoch 1830/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2529 - f1: 0.7180 - val_loss: 0.4262 - val_f1: 0.1424\n",
      "Epoch 1831/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2507 - f1: 0.7230 - val_loss: 0.4287 - val_f1: 0.1407\n",
      "Epoch 1832/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2531 - f1: 0.7193 - val_loss: 0.4277 - val_f1: 0.1415\n",
      "Epoch 1833/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2522 - f1: 0.7244 - val_loss: 0.4277 - val_f1: 0.1418\n",
      "Epoch 1834/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2530 - f1: 0.7180 - val_loss: 0.4263 - val_f1: 0.1415\n",
      "Epoch 1835/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2522 - f1: 0.7186 - val_loss: 0.4271 - val_f1: 0.1419\n",
      "Epoch 1836/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2507 - f1: 0.7217 - val_loss: 0.4287 - val_f1: 0.1414\n",
      "Epoch 1837/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2515 - f1: 0.7226 - val_loss: 0.4273 - val_f1: 0.1423\n",
      "Epoch 1838/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2506 - f1: 0.7169 - val_loss: 0.4283 - val_f1: 0.1419\n",
      "Epoch 1839/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2510 - f1: 0.7219 - val_loss: 0.4287 - val_f1: 0.1412\n",
      "Epoch 1840/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2530 - f1: 0.7195 - val_loss: 0.4276 - val_f1: 0.1415\n",
      "Epoch 1841/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2529 - f1: 0.7225 - val_loss: 0.4272 - val_f1: 0.1416\n",
      "Epoch 1842/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2515 - f1: 0.7221 - val_loss: 0.4276 - val_f1: 0.1415\n",
      "Epoch 1843/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2510 - f1: 0.7226 - val_loss: 0.4273 - val_f1: 0.1411\n",
      "Epoch 1844/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2516 - f1: 0.7161 - val_loss: 0.4284 - val_f1: 0.1414\n",
      "Epoch 1845/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2521 - f1: 0.7177 - val_loss: 0.4275 - val_f1: 0.1416\n",
      "Epoch 1846/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2514 - f1: 0.7201 - val_loss: 0.4294 - val_f1: 0.1408\n",
      "Epoch 1847/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2517 - f1: 0.7203 - val_loss: 0.4273 - val_f1: 0.1417\n",
      "Epoch 1848/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2516 - f1: 0.7230 - val_loss: 0.4275 - val_f1: 0.1412\n",
      "Epoch 1849/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2523 - f1: 0.7243 - val_loss: 0.4272 - val_f1: 0.1417\n",
      "Epoch 1850/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2497 - f1: 0.7209 - val_loss: 0.4283 - val_f1: 0.1415\n",
      "Epoch 1851/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2513 - f1: 0.7204 - val_loss: 0.4289 - val_f1: 0.1413\n",
      "Epoch 1852/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2523 - f1: 0.7216 - val_loss: 0.4260 - val_f1: 0.1431\n",
      "Epoch 1853/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2529 - f1: 0.7214 - val_loss: 0.4275 - val_f1: 0.1418\n",
      "Epoch 1854/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2525 - f1: 0.7250 - val_loss: 0.4281 - val_f1: 0.1413\n",
      "Epoch 1855/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2524 - f1: 0.7186 - val_loss: 0.4270 - val_f1: 0.1417\n",
      "Epoch 1856/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2500 - f1: 0.7210 - val_loss: 0.4288 - val_f1: 0.1412\n",
      "Epoch 1857/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2519 - f1: 0.7216 - val_loss: 0.4278 - val_f1: 0.1418\n",
      "Epoch 1858/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2501 - f1: 0.7227 - val_loss: 0.4294 - val_f1: 0.1411\n",
      "Epoch 1859/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2515 - f1: 0.7205 - val_loss: 0.4286 - val_f1: 0.1415\n",
      "Epoch 1860/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2513 - f1: 0.7206 - val_loss: 0.4268 - val_f1: 0.1416\n",
      "Epoch 1861/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2541 - f1: 0.7172 - val_loss: 0.4278 - val_f1: 0.1409\n",
      "Epoch 1862/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2534 - f1: 0.7167 - val_loss: 0.4269 - val_f1: 0.1418\n",
      "Epoch 1863/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2520 - f1: 0.7193 - val_loss: 0.4280 - val_f1: 0.1412\n",
      "Epoch 1864/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2496 - f1: 0.7220 - val_loss: 0.4288 - val_f1: 0.1417\n",
      "Epoch 1865/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2513 - f1: 0.7228 - val_loss: 0.4295 - val_f1: 0.1412\n",
      "Epoch 1866/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2524 - f1: 0.7167 - val_loss: 0.4285 - val_f1: 0.1412\n",
      "Epoch 1867/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2500 - f1: 0.7178 - val_loss: 0.4275 - val_f1: 0.1420\n",
      "Epoch 1868/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2522 - f1: 0.7208 - val_loss: 0.4282 - val_f1: 0.1421\n",
      "Epoch 1869/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2510 - f1: 0.7203 - val_loss: 0.4293 - val_f1: 0.1423\n",
      "Epoch 1870/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2516 - f1: 0.7223 - val_loss: 0.4275 - val_f1: 0.1428\n",
      "Epoch 1871/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2509 - f1: 0.7233 - val_loss: 0.4280 - val_f1: 0.1417\n",
      "Epoch 1872/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2516 - f1: 0.7239 - val_loss: 0.4270 - val_f1: 0.1420\n",
      "Epoch 1873/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2518 - f1: 0.7215 - val_loss: 0.4271 - val_f1: 0.1414\n",
      "Epoch 1874/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2534 - f1: 0.7194 - val_loss: 0.4270 - val_f1: 0.1414\n",
      "Epoch 1875/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2507 - f1: 0.7236 - val_loss: 0.4283 - val_f1: 0.1416\n",
      "Epoch 1876/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2510 - f1: 0.7218 - val_loss: 0.4285 - val_f1: 0.1415\n",
      "Epoch 1877/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2502 - f1: 0.7220 - val_loss: 0.4289 - val_f1: 0.1430\n",
      "Epoch 1878/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2523 - f1: 0.7224 - val_loss: 0.4276 - val_f1: 0.1425\n",
      "Epoch 1879/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2523 - f1: 0.7209 - val_loss: 0.4283 - val_f1: 0.1414\n",
      "Epoch 1880/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2511 - f1: 0.7206 - val_loss: 0.4280 - val_f1: 0.1416\n",
      "Epoch 1881/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2538 - f1: 0.7205 - val_loss: 0.4268 - val_f1: 0.1413\n",
      "Epoch 1882/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2526 - f1: 0.7227 - val_loss: 0.4265 - val_f1: 0.1417\n",
      "Epoch 1883/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2509 - f1: 0.7247 - val_loss: 0.4273 - val_f1: 0.1423\n",
      "Epoch 1884/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2514 - f1: 0.7208 - val_loss: 0.4276 - val_f1: 0.1413\n",
      "Epoch 1885/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2508 - f1: 0.7212 - val_loss: 0.4291 - val_f1: 0.1417\n",
      "Epoch 1886/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2516 - f1: 0.7186 - val_loss: 0.4290 - val_f1: 0.1416\n",
      "Epoch 1887/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2504 - f1: 0.7231 - val_loss: 0.4296 - val_f1: 0.1417\n",
      "Epoch 1888/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2503 - f1: 0.7224 - val_loss: 0.4282 - val_f1: 0.1422\n",
      "Epoch 1889/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2508 - f1: 0.7248 - val_loss: 0.4290 - val_f1: 0.1415\n",
      "Epoch 1890/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2490 - f1: 0.7248 - val_loss: 0.4301 - val_f1: 0.1419\n",
      "Epoch 1891/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2520 - f1: 0.7175 - val_loss: 0.4293 - val_f1: 0.1412\n",
      "Epoch 1892/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2522 - f1: 0.7181 - val_loss: 0.4287 - val_f1: 0.1417\n",
      "Epoch 1893/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2528 - f1: 0.7207 - val_loss: 0.4273 - val_f1: 0.1419\n",
      "Epoch 1894/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2507 - f1: 0.7235 - val_loss: 0.4282 - val_f1: 0.1415\n",
      "Epoch 1895/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2509 - f1: 0.7200 - val_loss: 0.4281 - val_f1: 0.1413\n",
      "Epoch 1896/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2516 - f1: 0.7220 - val_loss: 0.4285 - val_f1: 0.1413\n",
      "Epoch 1897/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2520 - f1: 0.7199 - val_loss: 0.4280 - val_f1: 0.1411\n",
      "Epoch 1898/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2517 - f1: 0.7233 - val_loss: 0.4274 - val_f1: 0.1422\n",
      "Epoch 1899/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2498 - f1: 0.7217 - val_loss: 0.4288 - val_f1: 0.1418\n",
      "Epoch 1900/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2487 - f1: 0.7222 - val_loss: 0.4294 - val_f1: 0.1428\n",
      "Epoch 1901/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2527 - f1: 0.7203 - val_loss: 0.4277 - val_f1: 0.1421\n",
      "Epoch 1902/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2526 - f1: 0.7232 - val_loss: 0.4280 - val_f1: 0.1408\n",
      "Epoch 1903/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2524 - f1: 0.7183 - val_loss: 0.4283 - val_f1: 0.1413\n",
      "Epoch 1904/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2537 - f1: 0.7174 - val_loss: 0.4277 - val_f1: 0.1416\n",
      "Epoch 1905/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2497 - f1: 0.7254 - val_loss: 0.4286 - val_f1: 0.1421\n",
      "Epoch 1906/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2513 - f1: 0.7225 - val_loss: 0.4287 - val_f1: 0.1415\n",
      "Epoch 1907/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2501 - f1: 0.7224 - val_loss: 0.4300 - val_f1: 0.1412\n",
      "Epoch 1908/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2526 - f1: 0.7226 - val_loss: 0.4277 - val_f1: 0.1414\n",
      "Epoch 1909/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2526 - f1: 0.7182 - val_loss: 0.4277 - val_f1: 0.1407\n",
      "Epoch 1910/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2505 - f1: 0.7204 - val_loss: 0.4288 - val_f1: 0.1407\n",
      "Epoch 1911/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2541 - f1: 0.7204 - val_loss: 0.4273 - val_f1: 0.1414\n",
      "Epoch 1912/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2544 - f1: 0.7191 - val_loss: 0.4272 - val_f1: 0.1408\n",
      "Epoch 1913/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2512 - f1: 0.7215 - val_loss: 0.4279 - val_f1: 0.1418\n",
      "Epoch 1914/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2518 - f1: 0.7220 - val_loss: 0.4280 - val_f1: 0.1411\n",
      "Epoch 1915/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2495 - f1: 0.7242 - val_loss: 0.4290 - val_f1: 0.1408\n",
      "Epoch 1916/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2508 - f1: 0.7212 - val_loss: 0.4284 - val_f1: 0.1417\n",
      "Epoch 1917/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2494 - f1: 0.7211 - val_loss: 0.4280 - val_f1: 0.1416\n",
      "Epoch 1918/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2542 - f1: 0.7175 - val_loss: 0.4264 - val_f1: 0.1419\n",
      "Epoch 1919/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2519 - f1: 0.7216 - val_loss: 0.4280 - val_f1: 0.1417\n",
      "Epoch 1920/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2521 - f1: 0.7215 - val_loss: 0.4275 - val_f1: 0.1420\n",
      "Epoch 1921/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2513 - f1: 0.7216 - val_loss: 0.4287 - val_f1: 0.1411\n",
      "Epoch 1922/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2506 - f1: 0.7249 - val_loss: 0.4292 - val_f1: 0.1418\n",
      "Epoch 1923/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2514 - f1: 0.7226 - val_loss: 0.4286 - val_f1: 0.1409\n",
      "Epoch 1924/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2486 - f1: 0.7253 - val_loss: 0.4296 - val_f1: 0.1423\n",
      "Epoch 1925/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2501 - f1: 0.7214 - val_loss: 0.4296 - val_f1: 0.1424\n",
      "Epoch 1926/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2490 - f1: 0.7252 - val_loss: 0.4302 - val_f1: 0.1406\n",
      "Epoch 1927/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2504 - f1: 0.7185 - val_loss: 0.4298 - val_f1: 0.1422\n",
      "Epoch 1928/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2508 - f1: 0.7203 - val_loss: 0.4283 - val_f1: 0.1424\n",
      "Epoch 1929/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2506 - f1: 0.7265 - val_loss: 0.4291 - val_f1: 0.1423\n",
      "Epoch 1930/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2491 - f1: 0.7221 - val_loss: 0.4303 - val_f1: 0.1415\n",
      "Epoch 1931/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2497 - f1: 0.7216 - val_loss: 0.4299 - val_f1: 0.1415\n",
      "Epoch 1932/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2509 - f1: 0.7196 - val_loss: 0.4293 - val_f1: 0.1418\n",
      "Epoch 1933/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2500 - f1: 0.7272 - val_loss: 0.4296 - val_f1: 0.1412\n",
      "Epoch 1934/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2507 - f1: 0.7260 - val_loss: 0.4298 - val_f1: 0.1419\n",
      "Epoch 1935/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2520 - f1: 0.7186 - val_loss: 0.4271 - val_f1: 0.1417\n",
      "Epoch 1936/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2504 - f1: 0.7252 - val_loss: 0.4282 - val_f1: 0.1415\n",
      "Epoch 1937/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2501 - f1: 0.7214 - val_loss: 0.4289 - val_f1: 0.1408\n",
      "Epoch 1938/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2522 - f1: 0.7157 - val_loss: 0.4282 - val_f1: 0.1419\n",
      "Epoch 1939/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2519 - f1: 0.7219 - val_loss: 0.4271 - val_f1: 0.1413\n",
      "Epoch 1940/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2513 - f1: 0.7205 - val_loss: 0.4284 - val_f1: 0.1418\n",
      "Epoch 1941/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2497 - f1: 0.7207 - val_loss: 0.4293 - val_f1: 0.1417\n",
      "Epoch 1942/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2526 - f1: 0.7200 - val_loss: 0.4292 - val_f1: 0.1413\n",
      "Epoch 1943/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2499 - f1: 0.7247 - val_loss: 0.4290 - val_f1: 0.1421\n",
      "Epoch 1944/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2515 - f1: 0.7201 - val_loss: 0.4286 - val_f1: 0.1420\n",
      "Epoch 1945/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2523 - f1: 0.7211 - val_loss: 0.4281 - val_f1: 0.1421\n",
      "Epoch 1946/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2519 - f1: 0.7172 - val_loss: 0.4273 - val_f1: 0.1417\n",
      "Epoch 1947/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2488 - f1: 0.7264 - val_loss: 0.4298 - val_f1: 0.1419\n",
      "Epoch 1948/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2514 - f1: 0.7245 - val_loss: 0.4284 - val_f1: 0.1424\n",
      "Epoch 1949/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2504 - f1: 0.7246 - val_loss: 0.4277 - val_f1: 0.1419\n",
      "Epoch 1950/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2503 - f1: 0.7257 - val_loss: 0.4290 - val_f1: 0.1416\n",
      "Epoch 1951/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2504 - f1: 0.7254 - val_loss: 0.4293 - val_f1: 0.1414\n",
      "Epoch 1952/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2503 - f1: 0.7221 - val_loss: 0.4282 - val_f1: 0.1422\n",
      "Epoch 1953/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2501 - f1: 0.7248 - val_loss: 0.4296 - val_f1: 0.1418\n",
      "Epoch 1954/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2498 - f1: 0.7247 - val_loss: 0.4294 - val_f1: 0.1414\n",
      "Epoch 1955/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2501 - f1: 0.7241 - val_loss: 0.4289 - val_f1: 0.1418\n",
      "Epoch 1956/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2488 - f1: 0.7272 - val_loss: 0.4301 - val_f1: 0.1419\n",
      "Epoch 1957/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2503 - f1: 0.7229 - val_loss: 0.4292 - val_f1: 0.1419\n",
      "Epoch 1958/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2507 - f1: 0.7243 - val_loss: 0.4291 - val_f1: 0.1416\n",
      "Epoch 1959/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2499 - f1: 0.7229 - val_loss: 0.4294 - val_f1: 0.1411\n",
      "Epoch 1960/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2527 - f1: 0.7253 - val_loss: 0.4266 - val_f1: 0.1420\n",
      "Epoch 1961/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2525 - f1: 0.7212 - val_loss: 0.4272 - val_f1: 0.1413\n",
      "Epoch 1962/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2491 - f1: 0.7221 - val_loss: 0.4290 - val_f1: 0.1414\n",
      "Epoch 1963/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2521 - f1: 0.7191 - val_loss: 0.4272 - val_f1: 0.1427\n",
      "Epoch 1964/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2496 - f1: 0.7215 - val_loss: 0.4292 - val_f1: 0.1419\n",
      "Epoch 1965/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2512 - f1: 0.7238 - val_loss: 0.4293 - val_f1: 0.1418\n",
      "Epoch 1966/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2498 - f1: 0.7244 - val_loss: 0.4309 - val_f1: 0.1411\n",
      "Epoch 1967/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2519 - f1: 0.7158 - val_loss: 0.4280 - val_f1: 0.1429\n",
      "Epoch 1968/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2503 - f1: 0.7246 - val_loss: 0.4283 - val_f1: 0.1423\n",
      "Epoch 1969/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2474 - f1: 0.7223 - val_loss: 0.4303 - val_f1: 0.1423\n",
      "Epoch 1970/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2517 - f1: 0.7228 - val_loss: 0.4287 - val_f1: 0.1417\n",
      "Epoch 1971/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2492 - f1: 0.7241 - val_loss: 0.4289 - val_f1: 0.1423\n",
      "Epoch 1972/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2498 - f1: 0.7172 - val_loss: 0.4294 - val_f1: 0.1419\n",
      "Epoch 1973/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2493 - f1: 0.7265 - val_loss: 0.4309 - val_f1: 0.1415\n",
      "Epoch 1974/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2507 - f1: 0.7219 - val_loss: 0.4288 - val_f1: 0.1420\n",
      "Epoch 1975/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2518 - f1: 0.7200 - val_loss: 0.4295 - val_f1: 0.1415\n",
      "Epoch 1976/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2503 - f1: 0.7234 - val_loss: 0.4299 - val_f1: 0.1412\n",
      "Epoch 1977/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2492 - f1: 0.7268 - val_loss: 0.4299 - val_f1: 0.1415\n",
      "Epoch 1978/2000\n",
      "64440/64440 [==============================] - 2s 31us/step - loss: 0.2506 - f1: 0.7211 - val_loss: 0.4301 - val_f1: 0.1414\n",
      "Epoch 1979/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2499 - f1: 0.7230 - val_loss: 0.4299 - val_f1: 0.1415\n",
      "Epoch 1980/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2496 - f1: 0.7231 - val_loss: 0.4293 - val_f1: 0.1423\n",
      "Epoch 1981/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2481 - f1: 0.7231 - val_loss: 0.4300 - val_f1: 0.1412\n",
      "Epoch 1982/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2495 - f1: 0.7218 - val_loss: 0.4301 - val_f1: 0.1411\n",
      "Epoch 1983/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2498 - f1: 0.7258 - val_loss: 0.4291 - val_f1: 0.1413\n",
      "Epoch 1984/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2484 - f1: 0.7281 - val_loss: 0.4303 - val_f1: 0.1416\n",
      "Epoch 1985/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2521 - f1: 0.7222 - val_loss: 0.4289 - val_f1: 0.1422\n",
      "Epoch 1986/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2507 - f1: 0.7255 - val_loss: 0.4279 - val_f1: 0.1417\n",
      "Epoch 1987/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2510 - f1: 0.7199 - val_loss: 0.4297 - val_f1: 0.1415\n",
      "Epoch 1988/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2513 - f1: 0.7202 - val_loss: 0.4291 - val_f1: 0.1415\n",
      "Epoch 1989/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2519 - f1: 0.7206 - val_loss: 0.4286 - val_f1: 0.1422\n",
      "Epoch 1990/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2512 - f1: 0.7229 - val_loss: 0.4287 - val_f1: 0.1421\n",
      "Epoch 1991/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2498 - f1: 0.7185 - val_loss: 0.4301 - val_f1: 0.1416\n",
      "Epoch 1992/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2500 - f1: 0.7217 - val_loss: 0.4303 - val_f1: 0.1411\n",
      "Epoch 1993/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2499 - f1: 0.7220 - val_loss: 0.4297 - val_f1: 0.1416\n",
      "Epoch 1994/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2504 - f1: 0.7241 - val_loss: 0.4297 - val_f1: 0.1415\n",
      "Epoch 1995/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2511 - f1: 0.7190 - val_loss: 0.4284 - val_f1: 0.1423\n",
      "Epoch 1996/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2499 - f1: 0.7246 - val_loss: 0.4289 - val_f1: 0.1418\n",
      "Epoch 1997/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2489 - f1: 0.7233 - val_loss: 0.4312 - val_f1: 0.1413\n",
      "Epoch 1998/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2505 - f1: 0.7195 - val_loss: 0.4310 - val_f1: 0.1422\n",
      "Epoch 1999/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2507 - f1: 0.7222 - val_loss: 0.4297 - val_f1: 0.1411\n",
      "Epoch 2000/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2462 - f1: 0.7274 - val_loss: 0.4313 - val_f1: 0.1411\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEYCAYAAAB2qXBEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnWeYFFXWgN/DEAaQDEqOIgqSEVFAgqgkSUbEgIkFReFzVXAVUdzVNYLZNQGuAoosGFlFFlAUFVAUSRIEGXLOcTjfj1tN18z09PQw3dMTzvs89fTNdaq6uk7fc+89V1QVwzAMwzhVCsRbAMMwDCN3Y4rEMAzDyBKmSAzDMIwsYYrEMAzDyBKmSAzDMIwsYYrEMAzDyBKmSLIJEWkvIkkxbP8REXk3Vu0buRMR+VJE+sVbjryKiLwrIo944fYisiSSsnkNUyQRIiLLReSWEOlDRGRBPGSKFiIyW0QOi8h+33FBvOWKFBFpKSKfi8huEdkpIj+KyM1ZbDOmij+dc77mu/9HReSYLz79VNpU1UtV9b1oyxpLROTvIjIuG87TVkT2iUixEHmLRWRgZtpT1dmq2iB6EuYeTJFEznjgxhDpN3h5MUNEEmLZvsdgVT3Nd8zLhnNmGU/h/Q+YA5wJlAMGAV3iKdepoKoDA/cfeBx43/d9pLkeESmY/VLmHVT1G2AL0MefLiJNgLrA+/GQKzdiiiRy/g20EZEagQQROQdoBEz04jeLyDLvX84aEflLeo2JyDleT2C3iCwRkR6+vHEi8qr3L/sA0CFE/VoiMsc71wygfKr8ySKyWUT2iMjXIpLpf0oiUlNE1P/C8mS+zQv3F5G5IvKMiOwSkT9EpIuvbFkRGSsiG738aV56GRH5VES2eemfikhVX73KIvKx17tYJSK3hxHzaWC8qj6pqtvVsVBVr/bLmOq6VETO9MJdRWSpdx83iMi9IlIcmA5U9vUIKotIEREZ413PRi9cJLP39VQRkTM92W8WkT+BL7301iLyvfcsLRKRi3x15opIfy98m/fMjPbKrhGRS31lb/M9v6sD37OX10lE1orIA973tlFELheR7iKy0vuu7veVLyAif/Pa2S4ik0SkTKrruFFEkrz2hnt53YH7gX7efV/opVf1npOd3vnSWAd8504UkedEZL2IbBGRV0QkMZ3i75D2D+KNwMequsu7jg+939Ju7/k/J53zdhKRtb54c+/72CciE4Eivrxy4n7fgd/AJyJSJVX+OBHZ5OVPibBexPcpqqiqHREewAzgIV/8CWCaL94NqAMI0A44CDTz8toDSV64ELAK+BtQGOgI7APqefnjgD1Aa5yyTwwhyzzgOdzDeZFX/11f/i1ACS9/DLAozHXNBm4LkV4TUKBgqLJAf+AYcDuQgOsJbATEy/8M96+ujHfN7bz0csAVQDFPxsmp7uMc4BUgEWgCbAMuDiFfMSAZ6BDm2voDc1OlKXCmF94EtPXCZUJ9X756o4DvgdOBCsB3wGPpnLcNsDvM0SaDZ+0R//fppZ3pyT7Wu/aiQDVgB3CZ96x0BrYD5bw6c4H+Xvg27/u6xfu+7gLW+9q/HKiNe347AoeARl5eJ+A48KD3XQ4CtgLvAqfh/lAdBqp75e8FvgWqeN/jW8C/U13Ha15eM+AIUNfL/zswLtW1fwu86Cu/PfA8hbh3LwFTve+zJPB5mO+ppndPqnjxBO+Z6O7FC3jPUAnv3C8BC3z13wUe8d2jtV64CJAE3O3dr2u98wTKVgB6e99hSeA/wIe+dr8AJnjXUBi4KMJ6Ed+nqL4bY32CvHQA1wMrfA/Yn0DvMOWnAUO8cHuCiqQtsBko4Cs70feQjQPeCdNude9HXdyXNoFULx5fXmnvh1sqnfzZOKUXeMn95KXXJGNFssqXV8wrXxGoBJwAykRwX5sAu7xwNZxyKOHLf4JULxYvvYp3vrPDtN2f8IrkT+AvQMlUZU5+X7601UBXX/wyvBdHDJ61R1J/nwRfwNV9aQ8CY1OVmwn088KpFclyX7mSXnvl05HhU+BOL9wJ2A8kePEyXt3mvvK/EHwBr8T3AvO+1yO4303gOir68n8CrvTCKRQJUAv3EvY/708Db4aQuQBOodXwpbUFVoa517OB+71wF5y5q2A6Zct7shf34ukpko7Aerw/VV7aj4GyIdptAWzz3avjpPN7DVMv4vsU7cNMW5njP0AlEWmFe9EUw/3rBkBEungmhp0ishvoSiqTk0dl3D/BE760dbgXY4D1YeSojHvxHkhVPyBHgoj80zMr7AXWelmhZAlwt6qW9o5mYcqlZnMgoKoHveBpuB/DTlXdlbqCiBQTkX+JyDpPvq+B0uLGgip79falurYqqdsBduGUVaVMyJuaK3Df0zrP7BNukkFlfPfZC1fOwrlPFf+zUQPo65lddnvPXaswcm32hf3fF56Z6gff83spKZ+Z7aqa7IUPeZ9bfPmHAm3h/ux84pNpMe4FfHqgsKqmluU0QlPZO3fq5z3UM1ER1xv4xXfuT/3nDYF//PMG4D1VPQ4nf0tPeWbAvThLAoT/LQVkTlLvbe6TGa/d4iLypoj86bX7P1+b1bzr3ZO60QzqZeY+RRVTJJnAe1F+iHvobgAmqepRAHG28inAM8AZqloa16WWEE1tBKqJiP/+Vwc2+E8XRpRNQBlxtnx//QDXAT1x/5BK4XoWpCNLOAIPpH9WS8UI664HyopI6RB5fwXqAeerakmcaS4g30avXglf+dT3Bjj5fczDKYP0OOCXX0RSyK+q81W1J+5FMw34IJAVoq2NuBe3X66NoU4qbkbQ/jBH2zAyhyXVy2k9rkdS2ncUV9WnM9OmiBTFPdtPEHx+vyTzz0yAJOCSVHIlplIe6ZH63m8Eyod43tM8EzjFdhRnJg6ct5SqlgpzvslALRFph/vdvOPLuxH3R6Mj7rd0ppee0X3ZBFRNleb/jd6P60G09H4DHX1563HXWzJEu+HqZeY+RRVTJJlnPHAN7uXln61VGPdPaBtwXNyg86VpqwPwA+4Fd7+IFBKR9jj79KRIBFDVdcAC4FERKSwibbz6AUrgzAg7cC/RxyO7tDTn2YZ7CK/3/pndghsDiqTuJtyA9SviBtcLSXAQuATu3+tuESkLjPTVW48be3jCGzRtBNwKpDeF9X6gv4jcJyLlAESksYgE7uUvQAMRaeINuD4SqOjdu34iUkpVjwF7cWY1cC+kciLifwFNBB4SkQoiUh54GGfaCHX932jKWXCpj28yvosR8W+gt4hc4n1HiSLSQUQy21MqgnuGtwHJ4ga9L86CXK8Bj4tIdQAROV18E0oyYAtQU0QEQFX/wD3vj4ub8NAEuJkQz4TXY3oTGON9T+INQKf3W0RV9+OsDeNxptpFvuzUv6V/RHgNc4ECIjJYRAqKyFW4MQt/uweBXd5z+7BPnvXAV8DLIlI6xG8nvXoR36doY4ok83yNGwjfoKrzA4meKeZu3D/aXbhewcehGvB6MT1w9tjtuIHlG1V1eSbkuA44H9iJexH7/0W9g+vSbgCW4gaIT5XbgftwP6QGuJd8pNyAs9kuxw3MDvXSx+AGC7d7sv03Vb2+uF7URtyg6UhVnRHqBKr6He5fWUdgjYjsBF7H9QZR1d9xg+Rf4ez2c1M1cQOw1jMTDMSNg+F9FxO9Nnd7L+a/436ov+JMNT95aXFDVdfiBl9H4JTAn7geX6Z+26q6G/g/3P3eCVyJMwmdKs/hvteZIrIP99ycF2Hd93FKbaeI/OilXYObkrsZ13P6m6rOSqf+X3HP/4+43+qXXt1wjMf1Nt9JlT4W9xxuBJYQ4fOvqkdw38vtuPdBH1yPN8BzuB7ODq/N1OuErvc+f8cp1rsirJeZ+xQ1ArNrDMMwDOOUsB6JYRiGkSVMkRiGYRhZwhSJYRiGkSVMkRiGYRhZIl84fStfvrzWrFkz3mIYhmHkKhYuXLhdVStkVC5fKJKaNWuyYEGu9vRuGIaR7YjIuoxLmWnLMAzDyCKmSAzDMIwsYYrEMAzDyBKmSAzDMIwsYYrEMAzDyBKmSAzDMIwsYYrEMAzDyBKmSAzDMHI5qnDiBBw6FEx75x248krYsiX9etHCFIlhGEYOZOlSOHbMKYijR13ahg3w6KOw2bfP5LJlMGgQJCRAsWLwyivw/vtw000wZQocOBC6/WiSL/YjadGihdrKdsMwYs2JE7B6NdTNaBstj/nzITERfvnFKYSiReHBB+GFF2DoUNejWLYMliyBffughG8D6uuugwkTMj7H/v1QvHjG5UIhIgtVtUWG5UyRGIZhhObQIVi50imGokVd2oMPQrdusGaN6wFUqwbly0OtWvDII67HMHcutG4N33wDZ5wBv/4KSUnQsiWcfTZcfz1MT723YYzIyis+UkWSL3xtGYaRN0lOhgIFQAR273Yv5759M9/O7t1QsiT89BM0b+7MQf/6F9x7r8vv1Ak++gjuu8+Zjh5/PG0btWs75QLQpg0sWgQXXZS2XHby7rvZc56YjpGISGcRWSEiq0RkeJhyV4qIikgLL36JiCwUkcXeZ0df2dlem4u84/RYXoNhGDmXOnWghfd/edAgZ+75+GP3L/y996BPHyhUCDZtggcecApHBMaOdT2LK66ADh2gTBk3xnDeeVCvnjMhBZQIwFdfOfPQK6+kL0tAiQRo0iT61wtuED09jh93PajRo9096NcvNjKkQVVjcgAJwGqgNlAY+AWoH6JcCeBr4HughZfWFKjshc8FNvjKzw6Ui/Ro3ry5GoaR85g0SfXdd1X37XPxkSNVP/tM9cYbVZOSVH/4QfXzz93x66+uzPbtqmPHqrpXZe4+JkwIhhMT3b3o1s3FlyxR3bhR9fhx1bVrXVrz5qrJyapjxqjOmaO6ZYvq9Okub8OG6H8/wAKN4B0bS9NWS2CVqq4BEJFJQE9gaapyjwFPASf1v6r+7MtfAiSKSBFVPRJDeQ3DiDLjx8OQIdC7N4wZA6VKudfm8OFu8PjVV9OvG+qfd7NmzvyUUyhTxvVe/vzTxVescAPgjz4KlSvDxo0u/ZVX3DTc5s2hSxf4z3/ctZx5Jhw+7D7btnVl+/VzJruEhOB5atRw5QoUcMeQIcG8zp2zNg4SDWI22C4iVwKdVfU2L34DcL6qDvaVaQo8pKpXiMhs4F5VXRCinYGq2smLzwbKAcnAFODvGuIiRGQAMACgevXqzdeti8itvmEYEbJrl5sRVK0a7NkDd9zhXqLz5ztT0jXXpFzXkBMYMABef92FP/gAvvwS9u51YXAv6RMnXLhzZ3jiCZg2zZmMzj4bZs6EW25xA+kBMxm46y9VyoWTk90sq0aNoGxZd5/i/aI/VSIdbI+laesq4E1f/AbgRV+8AM5MVVPTMVkBDXDmsTq+tCoaNIl9CdyYkSxm2jKMzLNzp+q2bS78/vuqZ5zhTCj9+7u0ihVd/J//zH6TUEKC6l13qX7wQTDtnXdUBw8Oxh97zH3eeqv7bNDAyZ2crHrkSMprXbZMdfXqYPzEiejcwz//VP3qq+i0FQ+I0LQVS0VyAfCFL/4A8IAvXgrYDqz1jsPARoLjJFWB34HWYc7RH3gpI1lMkRj5mcOH038xrl2rOnCgexO8/bYrt2aNCwdeyGPGZJ+CeOUV1QMH3LjAnj3B9LlzVcePV61WTXX58pTXsGuXUw6qqgcPqt5yi+qmTS5+9Kj7nDjRvdSNzJETFElBYA1Qi+Bge4Mw5Wf7lEhpr/wVIdos74ULAR/izF6mSIx8z5w5qh06uMHoACNHul/5HXeoNmmi2qaN6ksvqd53n2rJkrFTCIEBY1AtWtTJMnOm6v79wZf+zp0u//LLndIIpeyWL3cD7kZ8iFSRxGywXVWPi8hg4AvcDK63VXWJiIzyhPs4TPXBwJnACBEZ4aVdChwAvhCRQl6bXwFvxOoaDCMn8MMPMHs23H9/0Cb/88/OJl+7Nmzd6txpdOjg8sqXd2spJk4MtuGftjp3bvRk69vXqYuNG+Hrr2HyZLcaO8DRo8Exh44dU9YtUwbmzHHTZEuWDN1+vXrRk9WIHbay3TCymRkzYN48ePhhF//xR7j4YreY7oILgrN1vvvOlZk5M1j32Wfhr38Nxi++OGV+LLjgAqfIFi6EqlWdYvjvf6F7d6hUyQ1QG3kTc5HiwxSJkZMI9Cq6dXPTY5s1C04fzW5+/tn5hlq9Gs45B3r0cCu6H3gAdu50M45Kl46PbEb8MRcphhEnVOHbb92q60qVnOlpwgS46y7w/5/57DNnhooWRYrAsGEwapSLv/gi3HknHDzoVnuXL+9cfezb55TZiRPOPOZfgR34X3nrrS5c0N4QRgRYj8QwTpHt253Tvh07nMnp8cfdorFAGGDgQOfZdd68zLdfvjysWuVe9qtWuTUQs2a5vBMnnAuQWrXg6addXteu0bs2wwAzbaXAFImRVT77zHmAPessF58+Pbov7goVYNs2Fy5RAt5+2/mBCpjBDCMemGnLME4RVfj9dzdj6O23oX17N7AMbsZTmzbROYeqG0zfscPNqlJ1XmjLlMl6+4aRndh8C8Pw2LsX1q51LjDOPtu5/Lj1VjfWESArSmTYMPd5443uUwQeeyw4NVfElIiROzHTlpEvOXTIjTtMnQojR2a+/qOPBusVKuTGSvbsgSNH3FGiRNAsdeyYSyte3A18FymS0iGfYeRUzLRlGD62b3drIYoWdftYjx2bufqnn+48uyYkuDYKFoT+/d0iwddfd2n79kHhwu4Aty/E3r2ubGD2U7Fi0bwqw8gZmCIx8gTJyW5joYoV3SrrwIpoVTjtNNcTOFXSW0tRvTpMmhSMly2bMv/MM0/9nIaRm7AxEiNXc/y4M1P94x9uRlXJkm58I+Diu0CByJTIpk1ufOKyy+DNN2HduuCAuC3IM4zwWI/EyBUsWODWTrRsCX/84WY3ffYZjBiRcd1QfPutWyi4Ywdcf70bt9i5M7oyG0Z+wRSJkaN57DF46y3XQ8gK+/Y5E9fx47Za2zCijf2kjByHqtuWNCEh6NgwUr77Di680A2ClyrlZk+VL++UCJgSMYxYYD8rI26sX+9e7EuXurGM1G7GM6JqVTcbq2pVt3CwXj03u2rdOqhSxabYGkZ2YYrEyBZUnR+q9eud36khQ9y6i1Phzz/dPuHpUb36qbVrGMapYYrEyBbGjnWrxDNLgQJunUbdutC8uVvUZxhGzsIUiREzfvnF7ZC3fXtkSqR/fxg3zq04P3zY7Y9hmyYZRs4npj9TEeksIitEZJWIDA9T7koRURFp4Ut7wKu3QkQuy2ybRnxRdftctGwZ2ktu69bus18/N6Pq0CHXa1F1vq0aNDAlYhi5hZj9VEUkAXgZ6ALUB/qKSP0Q5UoAdwM/+NLqA9cCDYDOwCsikhBpm0b2cviwW1m+c6dbn3H11aGVwFdfwd13uzJz58KSJfDOO25GVWJi9sttGEZ0iKVpqyWwSlXXAIjIJKAnsDRVuceAp4B7fWk9gUmqegT4Q0RWee0RYZvR4ddfnW2mRYY+y/Ilqm7APJzH2qJFnRfdUaOcn6mLLw7m1be/AIaRJ4il8aAKsN4XT/LSTiIiTYFqqvpphHUzbDOqDB8OgwbFrPncxuHDcN11zvXI0KGu1xFOibRt61aPP/OMOSs0jLxMLHskofZ2O+mzXkQKAKOB/pmoG0rxhfSDLyIDgAEA1U91PqhIcBPrfMrWrc7X1PLl0LhxMP3550OX79HDreH4+9/TOjE0DCNvEktFkgT4Z/tXBTb64iWAc4HZ4jZuqAh8LCI9Mqgbrs2TqOrrwOvg9iM5pSvIx4rk8GGnRGrUyLjsI4+4leRHjpiDQ8PIj8RSkcwH6opILWADbvD8ukCmqu4BygfiIjIbuFdVF4jIIWCCiDwHVAbqAj/ieirpthl1ChTIl4pk3z7nRTcj+vRxn/ff78ZCihaNrVyGYeRMYqZIVPW4iAwGvgASgLdVdYmIjAIWqOrHYeouEZEPcIPox4E7VTUZIFSbsboGRJzL2XzCr79CUhJ06xY6/+qr4f33ndfd8ePhgw+yVz7DMHImttVuOHr1cj7Lf/kl+kLlIN59F264IXTe9u1uoNx6G4aR/7CtdqNBHh8j2bQJXnwRnngidP6JE8F9xw3DMNLDFEk48qgimT0bLr0Ujh1LmZ6Y6AbZwTlXNCViGEYkmBOKcOQhRbJ/v+thvPACdOiQVolMnuy2pF2/HqZMca7ZDcMwIsF6JOEoUCDXD7b/7W+wYYNzRZKaokWdZ9127YJu2atWNSViGEbmMEUSjlzcI9myBSpWTD9/8WI499zsk8cwjLyLmbbCkQsVSXKy8+ySnhJ5/XV3SaZEDMOIFtYjCUcuUySffx56Dch558Gjj0KtWnD22dkvl2EYeRtTJOHIBYpk+3bYvNmtBXnyybT5X3zhZmgZhmHEClMk4cjBLlKOHYNnn4UHHkib17y5W0Q4YgRcckn2y2YYRv7CFEk4crCLlMTE0KJt3AiVKmW/PIZh5F9ssD0cOdC0tXlzaP1Wp47brtaUiGEY2Y0pknDkMEWyfXtaRdGnD+zeDatW2Xa1hmHEB1Mk4cghiuTbb50oFSoE0/r0cf4kp0yBUqXiJ5thGIaNkYQjzoPtJ064nQZHjkyZvmqVM2UZhmHkBKxHEo44D7YPGZJSiVx8sRsHMSViGEZOwnok4YiTaWvzZrf2Y/HiYNq6dXCqW88bhmHEElMk4YiDItmzJ+2Auu0LYhhGTsZMW+HIRkWyfbs7XenSwbROnWDePFMihmHkbGKqSESks4isEJFVIjI8RP5AEVksIotEZK6I1PfS+3lpgeOEiDTx8mZ7bQbyTo/hBcRckajCzz+nnJEFsHw5zJgBrVrF9PSGYRhZJmaKREQSgJeBLkB9oG9AUfiYoKoNVbUJ8BTwHICqvqeqTbz0G4C1qrrIV69fIF9Vt8bqGrJjP5I2baBZs2B89Gg4fhzq1YvpaQ3DMKJGLMdIWgKrVHUNgIhMAnoCSwMFVHWvr3xxINTf/77AxBjKmT4x7JH88QfUrh2MV6gA994LQ4fG5HSGYRgxI5aKpAqw3hdPAs5PXUhE7gTuAQoDHUO0cw1OAfkZKyLJwBTg76pp3/YiMgAYAFD9VKc7xUiRJCWlVCIjRsCoUVE/jWEYRrYQyzGSUEPEad7KqvqyqtYBhgEPpWhA5HzgoKr+5kvup6oNgbbecUOok6vq66raQlVbVEg9ABHxFcRGkQS2tQVo0cLtFWIYhpFbiaUiSQJ8r0yqAhvDlJ8E9EqVdi2pzFqqusH73AdMwJnQYkOUFckvv0Dx4sH4jBkwf77NyjIMI3cTS0UyH6grIrVEpDBOKXzsLyAidX3RbsBKX14B4CqcggmkFRSR8l64ENAd8PdWokuUXKTMmwfXXANNmsDBgy5t9243vdcwDCO3E7MxElU9LiKDgS+ABOBtVV0iIqOABar6MTBYRDoBx4BdwE2+Ji4CkgKD9R5FgC88JZIAfAW8EatriIaLlEWL4MILg/EXXoC77sqiXIZhGDmImK5sV9XPgc9TpT3sCw8JU3c20CpV2gGgeXSlTJ9Xfm3D3sNlSLMAJgKWLXNK47XXgmlz50Lr1lETzzAMI0dgLlLCMCPpHFYerc9w1YgGMnbvhoQEKFkybd7mzXDGGTEQ0jAMI86Yi5QwVD4jmSXagH3rdobMP3AAPvwQ+vZ1eqZMmbRK5OWX3TCLKRHDMPIq1iMJQ4v6B+BbKFmrHDfeCF98AVu2RFZ3yRKon3odv2EYRh7EeiRhuKz1gZPhd95JX4ncdBNcdhksXep6H6qmRAzDyD9YjyQMlZtXYhV12PrAGL4udTnLlkHPnnDRRc6MperGRAzDMPIzpkjCcc451GENdTZO4YLHL4+3NIZhGDkSM22FI9DdGD8+rlvuGoZh5GRMkWREc2/Zyn33xVcOwzCMHIopkoyY5Hloee45OHQovrIYhmHkQEyRZMSZZwbDxYrBihXxk8UwDCMHYookEpKTg+Gzz4axY+Mni2EYRg7DFEkkFCgAq1dDQW+S2y23OG+MhmEYhimSiKldG44dg4e8vbeaNoVvv42vTIZhGDkAUySZ5dFH4YILXLhNG/jyy/jKYxiGEWdMkWSWAgXgu+/giSdc/LLLYrIdr2EYRm7BFMmpMty3S0mxYnD4cPxkMQzDiCOmSLLCTz+5z8OH4dxz4yuLYRhGnDBfW1mhaVN48kkYNszN6rr3XnjmmXhLZRghOXbsGElJSRy23rORisTERKpWrUqhQoVOqb5oDO37ItIZeB63v/qbqvrPVPkDgTuBZGA/MEBVl4pITWAZEFj9972qDvTqNAfGAUVx2/gO0QwuokWLFrpgwYIoXVUIeveGadNc+NAhSEyM3bkM4xT5448/KFGiBOXKlUMi2PHTyB+oKjt27GDfvn3UqlUrRZ6ILFTVFhm1ETPTlogkAC8DXYD6QF8RSb1LxwRVbaiqTYCngOd8eatVtYl3DPSlvwoMAOp6R+dYXUPETJ0aDNetGz85DCMMhw8fNiVipEFEKFeuXJZ6qrEcI2kJrFLVNap6FJgE9PQXUNW9vmhxIGzPQkQqASVVdZ7XC3kH6BVdsU+RbdvcZ1IS/PxzfGUxjHQwJWKEIqvPRSwVSRVgvS+e5KWlQETuFJHVuB7J3b6sWiLys4jMEZG2vjaTMmrTa3eAiCwQkQXbAi/5WFK+PLz5pgs3awa7d8f+nIaRy9i8eTPXXnstderUoX79+nTt2pXff/890+1MmzaNpUuXRk2uMWPGcPDgwUzXe/jhh/nqq6+iJkc0WLt2LRMmTMjWc0akSESklIiMDryYReRZESmVUbUQaWl6HKr6sqrWAYYB3rJxNgHVVbUpcA8wQURKRtqm1+7rqtpCVVtUqFAhA1GjxPXXB8NlymTPOQ0jl6Cq9O7dm/bt27N69WqWLl3K448/zpb09rAOQ3YqkmS/r71UjBo1ik6dOkVNjmiQYxUJ8DawF7jaO/YCGXkuTAKq+eJVgY1hyk/CM1Op6hFV3eGFFwKrgbO8Nqtmos3spUgRaN8+GLeFioZxklmzZlGoUCEGDgwOeTZp0oS2bdsye/ZsunfvfjLzEgOQAAAgAElEQVR98ODBjBs3DoDhw4dTv359GjVqxL333st3333Hxx9/zH333UeTJk1YvXo1ixYtolWrVjRq1IjevXuza9euiOV64YUX2LhxIx06dKBDhw4AnHbaaTz88MOcf/75zJs3j4ULF9KuXTuaN2/OZZddxqZNmwDo378/H374IQA1a9Zk5MiRNGvWjIYNG7J8+XIAfvzxRy688EKaNm3KhRdeyArPg/i4cePo1asXl19+ObVq1eKll17iueeeo2nTprRq1YqdO3cCsHr1ajp37kzz5s1p27btyXb79+/P3XffzYUXXkjt2rVPyjF8+HC++eYbmjRpwujRozl8+DA333wzDRs2pGnTpsyaNSvT312GqGqGB7AokrRU+QWBNUAtoDDwC9AgVZm6vvDlwAIvXAFI8MK1gQ1AWS8+H2iF651MB7pmJH/z5s012zhxQtWpENW2bbPvvIaRAUuXLg1GhgxRbdcuuseQIWHP//zzz+vQoUND5s2aNUu7det2Mn7nnXfq2LFjdceOHXrWWWfpiRMnVFV1165dqqp600036eTJk0+Wb9iwoc6ePVtVVUeMGKFDMpAlNTVq1NBt27adjAP6/vvvq6rq0aNH9YILLtCtW7eqquqkSZP05ptvTiNHjRo19IUXXlBV1ZdffllvvfVWVVXds2ePHjt2TFVVZ8yYoX369FFV1bFjx2qdOnV07969unXrVi1ZsqS++uqrqqo6dOhQHT16tKqqduzYUX///XdVVf3++++1Q4cOJ8995ZVXanJysi5ZskTr1KkT8l4+88wz2r9/f1VVXbZsmVarVk0PHTqU5h6keD6C92GBRqAjIl1HckhE2qjqXAARaQ2E3eVJVY+LyGDgC9z037dVdYmIjPKE+xgYLCKdgGPALuAmr/pFwCgROY6bGjxQVXd6eYMITv+d7h05BxHnRuXECfjmGzhwAIoXj7dUhpErKVmyJImJidx2221069YtRa8lwJ49e9i9ezft2rUD4KabbuKqq67K0nkTEhK44oorAFixYgW//fYbl1xyCeBMXZUqVQpZr0+fPgA0b96c//znPyflu+mmm1i5ciUiwrFjx06W79ChAyVKlKBEiRKUKlWKyy+/HICGDRvy66+/sn//fr777rsU13PkyJGT4V69elGgQAHq16+frolw7ty53HXXXQCcffbZ1KhRg99//51GjRqd0r0JRaSKZCDwjm9cxP/STxdV/Ry31sOf9rAvPCSdelOAKenkLQBy9jLyw4ehcGEX/r//g9dfj688hpGaMWOy/ZQNGjQ4aX5JTcGCBTlx4sTJeGAqasGCBfnxxx+ZOXMmkyZN4qWXXuJ///tfps+dnJxMc2/b7B49ejBq1Kiw5RMTE0lISACc1aZBgwbMmzcvw/MUKVIEcIro+PHjAIwYMYIOHTowdepU1q5dS3uf+TtQHqBAgQIn4wUKFOD48eOcOHGC0qVLsyidbSv89TUdU3p66dEk0jGSvaraGGgENFI3CL4vdmLlcgoVgn3e7XnjDfMQbBhAx44dOXLkCG+88cbJtPnz5zNnzhxq1KjB0qVLOXLkCHv27GHmzJkA7N+/nz179tC1a1fGjBlz8oVaokQJ9nm/sVKlSlGmTBm++eYbAP7973+f7J0ESEhIYNGiRSxatCikEvG3l5p69eqxbdu2k4rk2LFjLFmyJOLr3rNnD1WquMmlgXGfSClZsiS1atVi8uTJgFMKv/zyS9g6qa/loosu4r333gPg999/588//6RevXqZkiMjIlUkU8Ct+9Dg2o/Qfy0Mx2mnBU1al10W9MtlGPkUEWHq1KnMmDGDOnXq0KBBAx555BEqV65MtWrVuPrqq2nUqBH9+vWjadOmAOzbt4/u3bvTqFEj2rVrx+jRowG49tprefrpp2natCmrV69m/Pjx3HfffTRq1IhFixbx8MMPhxMlDQMGDKBLly4nB9v9FC5cmA8//JBhw4bRuHFjmjRpwnfffRdx2/fffz8PPPAArVu3DjsDLD3ee+893nrrLRo3bkyDBg346KOPwpZv1KgRBQsWpHHjxowePZo77riD5ORkGjZsyDXXXMO4ceNS9GSiQVgXKSJyNtAAt8bjPl9WSeA+VW0QVWliRMxdpKTHzJkQmBr44osweHD2y2AYHsuWLeOcc86JtxhGDiXU8xEtFyn1gO5AadysqsDRDLj9lKTNT1x8cTDsDXYZhmHkNcIOtqvqR8BHInKBqmY80mSkZeJE6NvXhRs0gEzYVg3DMHIDkY6R9BaRkiJSSERmish2Ebk+42oG11wDFSu6cBRX4hqGYeQUIlUkl3qD7N1xq8vPIuWYiZEeIrBuXTB+Cu4gDMMwcjKRKpLAbiddgYm+xYFGJATWlIDrnfgWJBmGYeR2IlUkn4jIcqAFMFNEKgC2zVpm8KYzArB1a/zkMAzDiDIRKRJVHQ5cALRQ1WPAAVLtLWJkwPffB8NVq8LevemXNYw8Sk51I59Z2rdvT2BJQdeuXdkdYtuIRx55hGfyydbbkbqRvxE37befF74SuDSWguU5ChcGn48c5s+PnyyGEQc0B7uRzwqff/45pUuXjrcYcSVS09Z5vqMt8AjQI0Yy5V0KFw7u7b4x53i/N4zsIKe6kZ8+fTpXX331yfjs2bNPOk8cNGgQLVq0oEGDBowcOTJk/Zo1a7J9+3YA/vGPf1CvXj06dep00l08wBtvvMF5551H48aNueKKK07ufbJlyxZ69+5N48aNady48ckV87169aJ58+Y0aNCA132++iZOnEjDhg0599xzGTZsWMTXGGsictqoqilW03nOG/8dE4nyOuef7z5vvBHOOQcaNnT7mBhGNjJ0KKTjB/CUadIkvC/I33777aTjxEjZuXMnU6dOZfny5YgIu3fvpnTp0vTo0YPu3btz5ZVXAs4tyIsvvki7du14+OGHefTRRxkToWPKSy65hL/85S8cOHCA4sWL8/7773PNNdcATjGULVuW5ORkLr74Yn799dd0veYuXLiQSZMm8fPPP3P8+HGaNWt28nr79OnD7be7NdwPPfQQb731FnfddRd333037dq1Y+rUqSQnJ7N//34A3n77bcqWLcuhQ4c477zzuOKKKzhy5AjDhg1j4cKFlClThksvvZRp06bRq1f8dxs/1a12DwJ1oylIviGwpgTgvPPAc1VtGEZa/G7k//Of/1CsWLE0ZUK5kf/6668jPkfBggXp3Lkzn3zyCcePH+ezzz6jZ083BPzBBx/QrFkzmjZtypIlS8Ka07755ht69+5NsWLFKFmyJD16BI02v/32G23btqVhw4a89957J50+/u9//2PQoEGAcyxZqpRzsP7CCy/QuHFjWrVqxfr161m5ciXz58+nffv2VKhQgYIFC9KvX79MXWcsiahHIiKfENzStgBQH/ggVkLleb7/Hlq1cuHPPouvLEa+JA5e5HO0G/lrrrmGl19+mbJly3LeeedRokQJ/vjjD5555hnmz59PmTJl6N+//0m50kMk1G7gbjfDadOm0bhxY8aNG8fs2bPTbWP27Nl89dVXzJs3j2LFitG+fXsOHz6cLe7gT5WwPRIROdPbxOoZ4FnveALoD7wRpqoRjoB5yzDyETnZjXz79u356aefeOONN06atfbu3Uvx4sUpVaoUW7ZsYfr08HvoXXTRRUydOpVDhw6xb98+Pvnkk5N5+/bto1KlShw7duykS3eAiy++mFdffRVwym7v3r3s2bOHMmXKUKxYMZYvX8733ozP888/nzlz5rB9+3aSk5OZOHFimuuMFxn1SMYAf1PVX/2JItLCy7s8VoLlK5KS3JRgw8jDBNzIDx06lH/+858kJiZSs2ZNxowZk8KNfN26dVO4ke/Zs+fJf+R+N/K33347L7zwAh9++CHjx49n4MCBHDx4kNq1azN27NhMyZaQkED37t0ZN24c48ePB6Bx48Y0bdqUBg0aULt2bVq3bh22jWbNmnHNNdfQpEkTatSoQdu2bU/mPfbYY5x//vnUqFGDhg0bnlSCzz//PAMGDOCtt94iISGBV199lc6dO/Paa6/RqFEj6tWrRyvPelGpUiWeeOIJOnTogKrStWvXkya4eJORG/nfVDXkboQislhVG8ZMsigSNzfy4dixA8qXD8a/+iqlt2DDiDLmRt4IRyzdyCeGySuaUeMi0llEVojIKhEZHiJ/oIgsFpFFIjJXROp76ZeIyEIvb6GIdPTVme21ucg7Ts9IjhxJuXLw3HPBeKdOkINtoIZhGOmRkSKZLyJp9h0RkVuBheEqikgC8DLQBTc43zegKHxMUNWGqtoEt3lW4M26Hbjc6/HcRNqpxv1UtYl35F5/I0OHgjdjA3C9EsMwjFxGRmMkQ4GpItKPoOJoARQGemdQtyWwSlXXAIjIJJxblZPz53zb9gIUx5sZpqo/+9KXAIkiUkRVfUvD8wAi8NRT4A22cemlsHs3eFMADcMwcgNheySqukVVLwQeBdZ6x6OqeoGqbs6g7SrAel88yUtLgYjcKSKrcT2Su0O0cwXwcyolMtYza42QdObbicgAEVkgIgu2bduWgahx5LTT4LbbgvFHHombKEbeJydPITXiR1afi0idNs5S1Re9I9JJ3KFe8GmkVdWXVbUOMAx4KEUDIg2AJ4G/+JL7eSavtt5xQzoyv66qLVS1RYUKFSIUOU74pkMyZgz4XCsYRrRITExkx44dpkyMFKgqO3bsIDEx3JB4eCJakHiKJAHVfPGqQDgHU5OAVwMREakKTAVuVNXVgXRV3eB97hORCTgT2jtRlDs+nH02LF8eDO/dCyVKxFcmI09RtWpVkpKSyNE9dCMuJCYmUjULSxBiqUjmA3VFpBawAbgWuM5fQETqqupKL9oNWOmllwY+Ax5Q1W995QsCpVV1u4gUwu3YmDdGqL/+Gk73TUAbMSI+y4+NPEuhQoWoVatWvMUw8iAxUySqelxEBgNfAAnA26q6RERGAQtU9WNgsIh0Ao4Bu3AztAAGA2cCI0RkhJd2KW4flC88JZKAUyJ5Y4V9hQqwf78bMwFYtSq+8hiGYURI2AWJeYUcuSAxPT79FC73OQzo2xcmTIifPIZh5FuitSDRyG66dUsZnzgxPnIYhmFEiCmSnIYI/Nu2ejEMI/dgiiQncv314G3YA0DLlnDoUPzkMQzDCIMpkpzK5MlBX1zz56dctGgYhpGDMEWSk/m//wuGJ0yA5OT4yWIYhpEOpkhyOiNHBsMFC8LBg/GTxTAMIwSmSHI6d9yRMn57GmfMhmEYccUUSU7n9NNTukqZMAHuuSd+8hiGYaTCFEluYMkSt3dJgNGj4Uje8qhvGEbuxRRJbqBaNac8/CQm2o6KhmHkCEyR5CZuvjllvEABt4DR3M4bhhFHTJHkJv71L/jmm7TpL72U/bIYhmF4mCLJTRQqBG3apE1/6SXXM9m5M/tlMgwj32OKJDeyZw+0a5c2vVy57JfFMIx8jymS3EjJkjBtWuj93devz3ZxDMPI35giya2ULg0PPpg2vXp1OHEi++UxDCPfYookN1OwIFSp4sJPPRVMT0iApCQ4fDg+chmGka+IqSIRkc4iskJEVonI8BD5A0VksYgsEpG5IlLfl/eAV2+FiFwWaZv5jl9+cdN/77sPPvssmF6tGhQtGj+5DMPIN8RMkYhIAvAy0AWoD/T1KwqPCaraUFWbAE8Bz3l16wPXAg2AzsArIpIQYZv5i3Ll4KyzXLhrV6hUKWX+00/b/u+GYcSUWPZIWgKrVHWNqh4FJgE9/QVUda8vWhwILNXuCUxS1SOq+gewymsvwzbzPUlJKeP33w9169q4iWEYMSOWiqQK4J9ClOSlpUBE7hSR1bgeyd0Z1I2oTa/dASKyQEQWbNu27ZQvItdRoAD89hs0b54yvWpVWLYsPjIZhpGniaUikRBpaZxDqerLqloHGAY8lEHdiNr02n1dVVuoaosKFSpEKHIeoUGDtDO6Nm2C+vXdwsWvvoqPXIZh5EliqUiSgGq+eFVgY5jyk4BeGdTNbJv5l1694NNPQ+ddcgns35+98hiGkWeJpSKZD9QVkVoiUhg3eP6xv4CI1PVFuwErvfDHwLUiUkREagF1gR8jadPwEIFu3ZyH4J4hhpFKlIB334VZs2DAAHNLbxjGKVMwVg2r6nERGQx8ASQAb6vqEhEZBSxQ1Y+BwSLSCTgG7AJu8uouEZEPgKXAceBOVU0GCNVmrK4hzzBtmnOrUrp0yvQbbgiG33gDbrvN+e3asQMqV85eGQ3DyLWI5oM9LVq0aKELFiyItxjxZ+9e+PBDuPXW9MtccQVMmQLJyW7g3jCMfIuILFTVFhmVszdFfqJkSbjlFnjzzfTLTJniPvftyx6ZDMPI9ZgiyY/ceKNzrxKO0qVtB0bDMCLCFEl+pFAhOHYMdu2CO+9Mv9y//uU+Dx1ypi7DMIwQmCLJz5QuDQ8/nH7+oEHQsSMUKwZ9+9rqeMMwQmKKJL9z+ukwcyZMnAiTJjkHkPV97stmzXKfkye71fHgFjdOnGimL8MwgBhO/zVyER07powvWeLWoaRm0ya3cdaAAfDf/0KrVlCzZuiyhmHkG6xHYoQmvZld1as7JQJQu7abInzsWPbJZRhGjsMUiRGaW2+F48fhgw8yLrtyZcZlDMPIs5giMdInIQGuuirjcsuXu8+5c6F9exg2DFavjqlohmHkHGxlu5ExO3Y4pfLppyndqvhJSEg7RfjQIUhMjL18hmHEBFvZbkSPcuXcVOHrr4dFi0KXCbXOpGhRNyPMMIw8jSkSI3M0bgxHjwb9cFWsGL78P//pXNr37+/GXAzDyHOYIjEyT6FCTikcPgxffw1t2jhFEYqvvoKPPoLx4129+fPhyivd5/Hj8OSTcPXV2Sq+YRjRxcZIjOjw22/QsCG8847zILx6NTRqFHn9LVugVCmncG67zTwPG0YOINIxEluQaESHc8+FgwfduAg4pZIZzjgDHn0URo6E4sXhuuvcQsejR6Fw4ejLaxhG1LC/fUb0CCiRAJdemrn6I0e6z+uvdz0SEShSBBYvjo58hmHEBFMkRuz44gtISoK774bXX3dpqZVNJHTtCs2bw8KFzt9XUlJ05TQMI0vYGImRfWzc6Lbw3bABzjrLmcJOhTJl3B7z557rNuKqWtWZwAoWtLEVw4giOWIdiYh0FpEVIrJKRIaHyL9HRJaKyK8iMlNEanjpHURkke84LCK9vLxxIvKHL69JLK/BiCKBfeCrVIEDB5z34KSkyNyw+Nm1yymhH3+EESNcWpEiUKlS2rKTJ8N772VNbsMwwhKzHomIJAC/A5cAScB8oK+qLvWV6QD8oKoHRWQQ0F5Vr0nVTllgFVDVKzcO+FRVP4xUFuuR5AJWroTZs93eJ3PmwBtvRF73hx/g/PNd+MgR6NDBTStu0ybomTgf9LwNI9rkhFlbLYFVqrrGE2gS0BM4qUhUdZav/PfA9SHauRKYrqqnaAcxcgV167oDoF8/p0jOPddNK86IgBIB1zMBaNs2OC4DQbOaYRhRJ5amrSrAel88yUtLj1uB6SHSrwUmpkr7h2cOGy0iRUI1JiIDRGSBiCzYtm1bZuQ2cgJHjjh3LKtXw+efn1obAwYEw3PmuN5J4AhsI2wYRpaJpSIJtdtRSPuCiFwPtACeTpVeCWgIfOFLfgA4GzgPKAsMC9Wmqr6uqi1UtUWFChUyL70RXwoXdo4ga9eGLl2C6YcPw+23Q58+cO+9kbf30ksp4wMHwoQJsHOna3PKFBg7NjqyG0Y+I5amrSSgmi9eFdiYupCIdAIeBNqp6pFU2VcDU1X15M5JqrrJCx4RkbFAJt4mRq7ltdfczKwiRYImq2PHYPNm54Zl8+bw9b/7Lm1av35p05YsgWefdYP4jRtD06ZOmRmGkS6xHGwviBtsvxjYgBtsv05Vl/jKNAU+BDqraprdkUTke+AB/1iKiFRS1U0iIsBo4LCqppkR5scG2/M4gV7Ku++6eLFisGpV9MZE3n7bjbH06gUNGgTTn3vO9Yxq1ozOeQwjhxH36b+qehwYjDNLLQM+UNUlIjJKRHp4xZ4GTgMme1N5Pw7UF5GauB7NnFRNvycii4HFQHng77G6BiOXkJjotgaePt31Wg4ccFOBFy923omzujL+llvgoYfc4P9TT7m0LVvgr3+F1q3hrbecE8rUXH21Wy9jGHkcW5Bo5A+WLHHK5t573QLGrNC+Pfz5J6xZkzZPFaZNc2axgEksH/zGjLxJ3HskhpGjaNAARo92iyG3bk2/XCQTM2bPDq1EwJnXevdOOa4iAqNGwfbtmRLZMHILpkiM/EeFCrBvX9A8tXix8zx86JAbtD/jjFNvO72tiEeOdOe9555Tb9swcijmRt7In5x2mjueecbFzz03mDdpEjz/vJsSXKAArFsXHFA/5xxYtuzUzzt6tBvT6dbNLbY8/3z4+Wen1GrVgmuvdeWWL4d69U79PIaRjdgYiWFEQsDVyokTbmfHL76Ayy+P7Tlr13Y9pkGD4OOPnTJr2DCtY8qDB11aYmJs5THyHTZGYhjRpFcvNztLxG0Z3L17MC/g2uXOO6O7bfCaNa7N995z52/SxC3S7NPHyVGiBOzf7zYCq1Ureuc1jExiPRLDOFVEnELZswe++catNalUCbZtg7lzXe+lbVsXv/56t67lhx9gx47YyHPokDORTZgA338Pd9wBnTs7891f/5qy7PLl8Pe/uzUyhQs7BXj4sOv5GIZHpD0SUySGcaqcOOGUyaZNMGMG3HRTxnXWro1f76FpUyhbFmbODKbNmQMXXRQ03e3Y4crs3Onc+//lL8E8I99hpi3DiDWB7YArV45MiYAb57jqqmD899/T9/FVsWKWRUzBzz+nVCIA7dqlVBTlyjlFUq6cG5sJLPRUdQ40d+0K3fbBg259TSTemo08h/VIDCOnsGGDM5MdPepmlNWuDX/7mzM5Pf98+vW6d3cv+azMJsuIO++El1+G8uXddOkLL3Tmu+LF3fqYKVNgmOc/dcwYGDIkdrIY2YaZtnyYIjFyPSLQqJEb+zh2DPbudT7FypZ1+QcOOOUDbkpx4cJu3CaWFC7sXMCE6oWowqefupltH3zgZGvSJOUullu3QqlSwT1kjBxHTtjYyjCMaHH4sNuTPiEBihaFkiVT5hcvntYVy/TpzsNxeuaorHL0aPqmrI4dYZbna9U/k61MGZg3z3ljvuUWl/bSS67HY+RabIzEMHIDRYo4JZIZunSBFSvg7LPh66+D6WPHOrf8VVLtM3fZZU4Z/fCDm22WFWbNCp2+a5eTJ6BEAAYPdhMBApuOLVqUchOy/v1dublznWwBkpLcTLXUHDrkZsoZ2Yeq5vmjefPmahj5no8+Ut22LWWaUx2qDz6oeuJEyrxWrYL5gePii1073bqlzcuu4/nng+FOndznVVc5mdetC+YFWLFCtWpV1U8+Ud20STUpKZh34IA7AhQpovroo9G757t2qS5bFr32shlggUbwjo37Sz47DlMkhpEOq1erLl8evsyePaqXXeZeF998E0xv3NilnTihumFD/BSL/2jTJhh+5pn0y3XurLp5s2pCQlARVayYVgkdP55S8WSW+vVTtpfLiFSRmGnLMPIztWtn7NOrZEm3uv4f/3CztQIsWODGbgJToP/1L5e+aJHbWOyVV9xgeoDUprRYMHduMBxuK+b//tdNr05OdvHJk1Pusrl1q/OrVrCg23agc2fYvdutA9q925XZscPtR/P223DddW78Z/t2Z777/HNXZunSqF5eTsVmbRmGER1U4ciRlD6/li93+7Ps3es8IB844KYqt2wZebs9euSsFfc1arhxnfvuS5v34Yfw6qtuvc727W66NMCDDzpPAulx7JjzSB2YhZeaGTNg5Up3L7K6n04miHTWVtzNTtlxmGnLMHIgkyer7typ+umnzvyzeLEbU+jSxZncJk9WnTjRlR0/XrV/f9Xvv4+/+SzcUb++6mmnpZ/fr5/qn3+qbt2qun+/6rFj7voGDXL5q1apDhyoeu65wbx77knZRjZChKYt65EYhpG72LvX/eNPSHBHwIHmyy+7acQffOA2F9uzJ9gjqF8/Z5qZypVzs9i+/TZt3gMPuFlq//tfynRVZ4YbMsQtAlWFZ591TkWLFo2qeDmiRwJ0BlYAq4DhIfLvAZYCvwIzgRq+vGRgkXd87EuvBfwArATeBwpnJIf1SAwjD3PHHapff+3C/hlYqqpvvun+xc+eHfxH/+yzwfCZZ6oWKBD/nkxmjm+/TRm/+upguGjR4CSIL7/M8q0l3rO2gARgNVAbKAz8AtRPVaYDUMwLDwLe9+XtT6fdD4BrvfBrwKCMZDFFYhhGCtOQP3z0aNoXdWD2V+AlXb++6ogRac1M4KYUt26dNv3OO+OvdHr1yuIti/+srZbAKlVdo6pHgUlAT38BVZ2lqge96PdA2FEkERGgI/ChlzQe6BVVqQ3DyJssXRo0E7VsCY0bu3ChQm72WYkSLn7aac71C8Dw4W6Q+7vvYNQoZ0I6eNAt8Bw92s0Sq1gRPvss7SLMcP7Rsotp09xGbDEmloqkCrDeF0/y0tLjVmC6L54oIgtE5HsRCSiLcsBuVQ3cmXTbFJEBXv0F22yVq2EY55wDHTq48A8/uGnKAYoUcUqhb183nvLSS+4l3LQpnHlmymnMRYu6lf9Dh7rpv+Dy27eHjz5y8c2b3fjNypVuj5gAqm7m2p49Lrx1qxvHCXgtqFwZPvkk2E40OHw4em2lQyx9bYXaxCDkyL6IXA+0ANr5kqur6kYRqQ38T0QWA3sjbVNVXwdeBzfYnhnBDcPIhzRq5DYFA7d+pGfP8OVD0aOHUxABzjzTfT75pOvJgHO2GaBChaA7l+Tk4NYEycluY7Lt252jznXr3Lqd885zZZcudTtoXncdlC7t1q7s25dSlurV4c8/nSIJOLr2RuwAAAjSSURBVPSMEbFUJElANV+8KrAxdSER6QQ8CLRT1SOBdFXd6H2uEZHZQFNgClBaRAp6vZKQbRqGYeQo7r8/4zJ+X2oJCW4Wmp8WLZyyKFLEmePOOcf1bMD1gCpVcsqvcGG3eHT2bBgwINf3SOYDdUWkFrABuBa4zl9ARJoC/wI6q+pWX3oZ4KCqHhGR8kBr4ClVVRGZBVyJG3O5CYhiH9AwDCMHk17PomJFZ64799xgjyfg4DIbFEnMxki8HsNg4AtgGfCBqi4RkVEi0sMr9jRwGjBZRBaJSGD56jnAAhH5BZgF/FNVA5PAhwH3iMgq3JjJW7G6BsMwjFxDy5YpzWa1arndOP2eBmKELUg0DMMwQmJ7thuGYRjZgikSwzAMI0uYIjEMwzCyhCkSwzAMI0uYIjEMwzCyhCkSwzAMI0uYIjEMwzCyhCkSwzAMI0vkiwWJIrINWHeK1csD26MoTrQwuTKHyZU5TK7MkVflqqGqFTIqlC8USVYQkQWRrOzMbkyuzGFyZQ6TK3Pkd7nMtGUYhmFkCVMkhmEYRpYwRZIxr8dbgHQwuTKHyZU5TK7Mka/lsjESwzAMI0tYj8QwDMPIEqZIDMMwjCxhiiQdRKSziKwQkVUiMjybz11NRGaJyDIRWSIiQ7z0R0Rkg7eb5CIR6eqr84An6woRuSyGsq0VkcXe+Rd4aWVFZIaIrPQ+y3jpIiIveHL9KiLNYiRTPd89WSQie0VkaLzul4i8LSJbReQ3X1qm75GI3OSVXykiN8VIrqdFZLl37qkiUtpLrykih3z37jVfnebeM7DKk11iIFemv7to/2bTket9n0xrRWSRl56d9yu990P8njFVtSPVASQAq4HaQGHgF6B+Np6/EtDMC5cAfgfqA48A94YoX9+TsQhQy5M9IUayrQXKp0p7ChjuhYcDT3rhrsB0QIBWwA/Z9N1tBmrE634BFwHNgN9O9R4BZYE13mcZL1wmBnJdChT0wk/65KrpL5eqnR+BCzyZpwNdYiBXpr67WPxmQ8mVKv9Z4OE43K/03g9xe8asRxKalsAqVV2jqkeBSUDP7Dq5qm5S1Z+88D7cnvdVwlTpCUxS1SOq+gewCncN2UVPYLwXHg/08qW/o47vgdIiUinGslwMrFbVcJ4MYnq/VPVrYGeIc2bmHl0GzFDVnaq6C5gBdI62XKr6paoe96LfA1XDteHJVlJV56l7G73ju5aoyRWG9L67qP9mw8nl9SquBiaGayNG9yu990PcnjFTJKGpAqz3xZMI/yKPGSJSE2gK/OAlDfa6p28Huq5kr7wKfCkiC0VkgJd2hqpuAveQA6fHQa4A15Lyxx3v+xUgs/coHjLegvvnGqCWiPwsInNEpK2XVsWTJTvkysx3l933qy2wRVVX+tKy/X6lej/E7RkzRRKaUDbMbJ8nLSKnAVOAoaq6F3gVqAM0ATbhutaQvfK2VtVmQBfgThG5KEzZbL2PIlIY6AFM9pJywv3KiPRkye579yBwHHjPS9oEVFfVpsA9wAQRKZmNcmX2u8vu77QvKf+wZPv9CvF+SLdoOjJETTZTJKFJAqr54lWBjdkpgIgUwj0k76nqfwBUdYuqJqvqCeANguaYbJNXVTd6n1uBqZ4MWwImK+9za3bL5dEF+ElVt3gyxv1++cjsPco2Gb1B1u5AP8/8gmc62uGFF+LGH87y5PKbv2Ii1/+3dz8hVpVhHMe/v1Eo+yfliERRaAktAiGGmKJFRFgEBdYiI5jINoWrViUSuKs2EWIQ0R+jTS0EGygyGEiIggxrUilrkmhjoCX9QRCRp8X7HDkOc4WZ9557KH4fOMzhnTv3Pve9557nnPd9532X8NmNsr6WAw8DH7TiHWl9LXR+oMdjzIlkYQeA9ZLW5lXuZmB6VC+e7a9vAd9HxCut8nb/wiagGU0yDWyWdImktcB6SgffsOO6XNKVzT6lo/Zwvn4z4uMJ4MNWXFM5amQS+LO59e7IBVeJfdfXPIuto33ARklXZ7POxiwbKkn3A88BD0XE6Vb5aknLcn8dpY6OZWx/S5rM43Sq9V6GGddiP7tRfmfvBX6IiPNNVqOsr0HnB/o8xmpGD/yfN8pIhx8pVxbbR/zad1FuMb8Dvs3tAeA94FCWTwPXtv5me8Z6lMpRIReJax1lNMwscKSpF2AVMAP8lD+vyXIBr2Vch4CJDuvsMuB3YGWrrJf6oiSz48BZylXfU0upI0qfxVxuT3YU1xylnbw5zl7Pxz6Sn/EscBB4sPU8E5QT+8/ALnKGjCHHtejPbtjf2YXiyvLdwNPzHjvK+hp0fujtGPMUKWZmVsVNW2ZmVsWJxMzMqjiRmJlZFScSMzOr4kRiZmZVnEjMKkkak7RP0g19x2LWBw//Nask6Sbg+ojY33csZn1wIjGrIOkc5Z+8Gu9HxEt9xWPWBycSswqS/omIK/qOw6xP7iMx64DK6nkvS/oqt5uz/EZJMzk9+kzTryJpjcoKhbO53Znle3PK/iPNtP2SlknaLemwysp7z/b3Ts1ged8BmP3HrVAut5pejIhmVti/IuJ2SVPAq5QZdndRFhl6V9IWYCdlAaKdwP6I2JST/zV3OVsi4g9JK4ADkvZQVuO7LiJuBVAuj2vWFzdtmVUY1LQl6Rfgnog4llN+/xYRqySdpExAeDbLj0fEuKQTlA77M/OeZwdl9lsoCeQ+ymSFXwMfAx8Bn0aZbt2sF27aMutODNgf9JgLSLqbMmX5HRGxAfgGuDTKsqgbgM+ArcCbwwjWbKmcSMy682jr55e5/wVlrQyAx4HPc38GeAbO94FcBawETkXEaUm3AJP5+3FgLCL2AC8At3X9Rswuxk1bZhUWGP77SUQ8n01b71DWiRgDHouIuVxj+21gHDhBWQPiV0lrgDcoa76coySVg8BeyjraR4HVwA7gVD53cyG4LSLaa62bjZQTiVkHMpFMRMTJvmMx65qbtszMrIrvSMzMrIrvSMzMrIoTiZmZVXEiMTOzKk4kZmZWxYnEzMyq/AvWQcxL9QrdcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna0.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna0.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[10024   770]\n",
      " [ 1572  1443]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[9966  829]\n",
      " [1566 1449]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[49441   931]\n",
      " [ 3661 10407]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEYCAYAAADh1BXbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XnclXP+x/HX+75L0R6FClmyZEuRLCmEsmVsk2Vkm4yd2RhryAzjN2MdQ0bIWGPQEFlGFKEFKVtFCKU9KVQ+vz++31PXfdz3fU7d5z7nvs/9efa4Hp3r+72W73Wd+3zOd7nOdcnMcM45VzUlhS6Ac84VAw+mzjmXAx5MnXMuBzyYOudcDngwdc65HPBg6pxzOeDB1DnncsCDqXMuI0kfSepe6HLUZDUmmEqaIWmZpCWJqU3MGxzfzJ8knZzl9ppLGiJplqRvJX0s6aJqPYhqJKmTpAmSlsb/O1WybHtJIyQtiMd/m6R6ifwKz6ekBpJulPRVXP92SfUTeXdL+iye07cl9Unbr6W9h5cn8u+V9GNafmnM6ybpBUnzJc2RNEzSxol1m0u6T9I3cRpYwbH3iGUYlJZ+YTwXi+LfRYOY3lrSQ/F4F0l6TdLuifV6xvOULHP/RH5LSU9I+i6el+MTeftKek/SQknz4nJtE/l/lfSFpMVx3UsrOKb+8ZhOLy+/nOWnJMq6UtL3iflLstlGOjPbxsxGr+l6kurFsn8X9z9X0ouSjlmDbfSSNGNN9513ZlYjJmAG0KuCvLOB/YHxwMlZbu8e4FGgBeFLY1vg6ByXuV6ezs06wGfAhUAD4Lw4v04Fy48A7gUaAhsB7wHnZXM+gSuB0UBLoBXwBnBVzGsEDATax3N6KPAt0D7mtwesovMSyzSogrw+wDFAU2A9YAjwXNr7OSzmtQemA6ekbaM+8E4s86BE+kHAbGD7+PcwCrgu5m0B/BbYGCgFBgBzgcYxvycws5L35iHgEaAxsDewCNg+5m0ItImvGwB/BYYn1t0GaBRftwWmAEembb8F8CEwGTh9Lf52RmVarzr/joF68W8i9TeyAXByPMeXZrmNXsCMfHzWqnSshS5A4oTNoIJgmlhmTPqHv5JlJwNHVJK/PfACMD9+0C6J6Q2Am4Cv4nQT0CDm9QRmAhcBs4D7Y/qh8UO8EHgd2CnH5+ZA4EtAibTPgd4VLP8BcHBi/gbgzmzOJyHAHpOYPx74opKyTQKOiq/bs5bBtJxlOwPfJubnArsl5i8BRqetc3EMWGX2AzwI/Dkxvz8wq5J9Lwa6JN/zCpZrBPwIbJ1Iu58YqNOWbQD8BXi/gm21JXzp/TEt/Q7gLLIIihVs92frAacDrwK3xL//gUAH4GVgXjzX9wPNEuvMBHrG14MIXyL/JnyZTgY6V7D/MsE0kd4PWAY0T5Tpg7i96akyA83icj8BS+LUGtiD8KW5EPg6Hkv9XH7u1nSqMc38avAGcK2kUyR1SGZIagK8CDwHtAG2Al6K2ZcC3YBOwM5AV+CyxOobEWptmwEDJHUm1KLOANYH7gSGp5qR6SRNis2+8qbbKziW7YFJFv+6okkxvTw3A/0krReblX3isWZDcUrOt5PUrJxj2RDYmlCjSvpM0kxJ90jaIC3vrNiUnyDpqErKsU85200v1w6JsmwGnApcXc62tgfeTcy/C2woaf1yjqkToSUwLZHcWtJsSZ/GLpBGMX1rYKWZfZy27VXvi6RNJS0kBITfE4J9cn8XS1pCCFaNCIE/ldcV2JUQUNPLebykSeUca7b2JASvVsD1hPM5iFBD70iosV9e4dpwBCHgNgeeJQSzNfEk4Qtmtzg/GziE0DL5NXCrpJ3MbBFwGPC5mTWO0zfACuB8Qk13L6A34TNYOIWM5GnfVDMI3zoL4/RkOcusSc10XULtZQKwnPDh6BPzjgPermC96ZSt1R1EbGIQaik/Ag0T+f8ErknbxkdAjxyem8uBh9PSHgAGVrD8dvG4VxBqBfeSqNVWdj4JH6jXCB+yjYA34zY2TluuPuEL6c5EWmPCh78eoYn7GDAykd+Z8IVTDziYUAvZq5xy7USoMXVPpP0b+A/QhPDlNx34IZH/FPDL+PpeytZMp5Ooxceyl1dbakqoHf4pkbYRIbiUAJsTanR3xrzupNVwCYFgVDnH1JLQoulWTp6AXYCrgCYxrZTQStgjzo8itzXTTzKsdzQwLjGfXjNNdsHsBCypYDvl1kxj3tzUe1ZO3tPA2fF1xmY+4YtqWK4+c2sz1bSa6RFm1jxOR1RlQ2a2zMz+bGZdCB/gR4FhkloCmxA+YOVpQ+iPTPkspqXMMbPvE/ObAb9L1jDj9pPrVNUSwgc9qSkhGJUhqQQYSQg8jQjf3C0ItY9sXAu8Tei2eJ1Qg1gOfJO2j/sJXyznpNLNbImZjTezFWY2O+YdKKlpzJ9oZvNi/gjCF8KRaeXfilDTOd/KDnicR6jdTSUEzocIH3AkHUYIQo9UcEzp5y/1etX5k7Qu8F/gDTP7S+KYZpnZ+2b2k5l9CvyREGjK225q2z97X8xsPnAf8JQSg4Exz8zs7Xh8V8XkswitkbEVHFNVfZGckbSRpEclfSlpMeELKb1VkTQr8Xop4W8ta5IaEr5g5sf5QyW9GVstCwldWxXuX9K2kp6Jg4qLCS2Syspb7WpaMK0WZrYY+DPhDd+c8Ie0ZQWLf0UIkCmbxrRVm0tb/gvg2sSXQHMzW8/MHipv42kjrenTz5pz0RRgJ0nJZu5O/LwZDOEPdBPgNjP7wczmEQZvDq5g22XEL6FzzKytmW1B6EObYGYrY/kF3E2oeR5lZssr21zqsCvJX5UXm+ovEmr696eVa76ZnWBmG5nZ9oS/3bdi9v7ArvGDNQv4JXCBpKdi/hRCl03KzsDseG6IXTJPEvqlMzUVk2X+GKiX1o20M+W/LxBqaa35eQBO5qf+LvcHfpE4pj2Bv0m6LUP5spX+d3w98AOwo5k1JQwSVfS+5cIRcX/j4hfZY4Q+5Q3NrDnwfGL/6WWF0J02GdgqlveKai5vZoWsFqdV02dQ8Wj+OoSR6dcIzaiGQEmG7V1O6I9JrXspsIDQFG1C6LS+gNBv0wTY3VY3YV4nNHM3IDSFB8W8nqQNRhCatV8AuxPezEaEvp8mOTw3qdH882N5z6Hy0fxPCIMx9Qh9Wk8AD2RzPgkDIW3isXSLx3ZgYt07CP3RjcvZ7+6EEeoSQmvgEeDlRP7R8fyXEGoe37K66diW0Fr4QwXHtGXcZimhD3guq0fNmxCa46npEeBGoGXM702oSXUk1NL/x+rR/PqEGumTlDNwFt/zTeP52IQwSHNPIv9hQi25EaHvLjmaf2TifLQitI4mxrwSQuBuEbfdlfA3eV7Mb552TK8TrjpoVt75qeRvZxTlN/NHpaX9J763pfE43yDRtObnzfx7E3lbESrY5e0/fTR/feBXwBzgisSx/hTPX+oqkWXEbixC3/gSEp8pYCKhG0+Ebq2p6ceU76lgOy7npM+g4mA6Kr4hyalnhu1dRvjmWkxoSowC9kzk70AYdFoQP2gXx/SGhM70r1k9Stgw8cH62cgu4cM6jtUji8PIYTCN+9iF0A+6LP4h7ZLIuwR4NjHfKR7vAkLQGQa0zuZ8EgZ+ZhCabh8BJyTW2ywu+z2rR1aXpJYh9EV/CnwXz8NQYKPE+qMJwWYxYaCmXyLvyrjt5HaXJPKPJbQQlhK6IA6q5FzdS9pVA4RANDvu+x5WX6HRI+53adq+uyfW+zLmfwHcStkPdUtCIP6OcIXF8Ym8cxPnYxYh8G4W80oIg4Lz4/4+ju/jz/q2E+/Z6Yn5E4ApWfzdlFkvppUXTHeMf1dLCN08fyC3wfS7uO35hC+zfmnLnU/oSloY379hJMYECF0k82J+a2Bfwt/nEkI/9qD0Y8r3pFhQ55xzVVAn+kydc6661epgKunZCgZy1uonc845t7a8me+cczlQL/MiLp3qrWtap0mhi1Hn7LLdpoUuQp00ceKEuWbWKhfbKm26mdmKZRmXs2VzRppZ71zsM188mK4FrdOEBtscW+hi1DmvvZmrSyzdmli3vj7LvFR2bMWyrD4737/zj4JegL82PJg65/JHgpLSQpeiWngwdc7ll2r1uHeFPJg65/JLhf3VZ3XxYOqcyyNv5jvnXNUJb+Y751zVyZv5zjmXE97Md865qpI3851zrsqE10ydc67qvGbqnHO5UeIDUM45VzXezHfOuVzwZr5zzuWGX2fqnHNV5HeNcs65HPFmvnPO5YA3851zrqq8me+cc1Xnd41yzrlc8Jqpc87lhtdMnXMuB3wAyjnnqsivM3XOudyQ10ydc65qhAdT55yrOgn5Lficc67qvGbqnHM54MHUOeeqSngz3znnqkrIa6bOOZcLJSX+CyjnnKuyYq2ZFudXhHOuZlKWUzabkkolvS3p6Ti/uaQ3JU2V9IikdWJ6gzg/Lea3T2zjTzH9I0kHJdJ7x7Rpki7OpjweTJ1zeSNESUlJxilL5wMfJOavB240sw7AAuC0mH4asMDMtgJujMshqSPQD9ge6A3cHgN0KfAPoA/QETguLlspD6bOubySlHHKYhvtgEOAf8V5AfsBj8VF7gOOiK/7xnli/v5x+b7Aw2b2g5l9CkwDusZpmpl9YmY/Ag/HZSvlwdQ5l1/ZNfM3kDQ+MQ1I28pNwB+Bn+L8+sBCM1sR52cCbePrtsAXADF/UVx+VXraOhWlV8oHoJxz+aOsR/Pnmtmu5W5COhT4xswmSOq5ess/YxnyKkovr4BWTloZHkydc3mVg9H8vYDDJR0MNASaEmqqzSXVi7XPdsBXcfmZwCbATEn1gGbA/ER6SnKditIr5M1851zepC7ar0qfqZn9yczamVl7wgDS/8zsBOBl4Oi4WH/gqfh6eJwn5v/PzCym94uj/ZsDHYC3gHFAh3h1wDpxH8MzHZvXTJ1z+VO9Pye9CHhY0iDgbeDumH43cL+kaYQaaT8AM5si6VHgfWAFcLaZrQSQdA4wEigFhpjZlEw792DqnMurXF60b2ajgFHx9SeEkfj0Zb4Hjqlg/WuBa8tJHwGMWJOyeDO/FispEWMfuojHb/4NAD1225rXH7yI8cMu4a6rf0Vpadm3t0vHTVky/hZ+0atTmfQmjRoyfeQgbrxo9d/bwLMPY+qz1zDntb9V/4EUgdtuuZkunXag887bc+vNNwFw1ZWXs9suO7F7l04c2udAvvoqdLt99OGH9Nh7D5o1asCNf/+/Qha7IFSijFNt5MG0Fjvn+H356NPZQPi2/9fVv+Kki+9h12P+zOdfz+fEw3ZftWxJiRh0fl9eGPvBz7Zz5VmHMHrCtDJpI159j+6/uqF6D6BITJk8mXuG3MXo19/irQnv8uyIp5k2dSoX/u4PjHt7Em9OeIc+Bx/KXwZdDUCLli352423cMFvf1/gkhdGLq4zrYmqLZhKai9pmaR34vyMRPrktGUHSsrLX5akS9LmU+XaUtI7kpbkoxxV1bZ1c3rvvT33PPE6AOs3b8QPP65g2uffAPC/Nz7kiP1X10DP6teDJ196lznzvy2znV2224TW6zflxbQg+9Z7M5g1d3E1H0Vx+PDDD+jatRvrrbce9erVo/s+PXjqqSdo2rTpqmWWLv1uVZBo3bo1u+62G/Xr1y9UkQsmm0DqwbR8082sU+bF8uqS8hLNrCaWtUI3/OEoLr35SX76KVz+NnfBEurXL6Vzx00B+EWvTrTbsAUAbVo14/D9duaux0aX2YYkrvvtkVxy4xP5LXyR2X77HRgz5lXmzZvH0qVLee7ZEcz8IlzzfeXll7LV5pvw8EMPcPnAqwtc0pohhz8nrVHyWeo52SwkqZOkNyRNkvSEpBYxfZSk6yW9JeljSd1jeqmkGySNi+ucEdM3lvRqrG1OltRd0nXAujHtgTUs14DUrzFsxbI1P/oc6tN9B76Z/y1vf/BFmfSTLr6Hv/7uSEbf/3u+/e4HVqxcCYTAe9nNT60KvClnHNudkWOmMHP2wryVvRhtu912/O73F3Fo7wM4/JDe7LTTztSrF8Z2r7rmWqZ9+gX9jjuBO26/rcAlrSFydKOTmiZvo/lmtltidstU8z/aCEj1xA8FzjWzVyRdDVwJXBDz6plZ13ix7pVAL8JNDBaZ2W6SGgCvSXoeOBIYaWbXxhsXrGdmoyWdk6yBppWrsvIPBgYDlKzXOuOvIarTHp224NAeO9J77+1psE59mjZqyJBBJ3HqZUPpdVoY/Ni/27Z02Kw1AJ07bsrQ604BYP3mjTlo7+1ZseIndt9pc/baZUsGHNudRus2YJ36pSxZ9gOX35LxkjqX5uRTT+PkU8N9Na647BLatm1XJv/YfsdzZN9DuPzKqwpRvBqltjbjMynUpVFlmtSSBsb/mwHNzeyVmHUfMCyx3n/i/xOA9vH1gcBOklIX6zYjXHw7DhgiqT7wpJklg3etdsWtw7ni1hDwunfpwAUn7c+plw2lVYvGzFmwhHXq1+N3Jx/A9XePBGC7QweuWnfwVSfy7OjJ/HfUJP47atKq9BMP250uHTf1QLqWvvnmG1q3bs3nn3/OU0/+h1GjxzJt6lS26tABgGf+O5ytt9m2wKUsPCkMhhaj2nad6Q/x/5WsLrsINdmR6QtL2odwZ5n7Jd1gZkPzU8zCuLB/L/p034GSEnHXsNG8Mu7jtd7Wtef35Zd9dmW9hvWZ9tw13PPEWK69c40uu6tTjjv2KObPn0f9evW56ZZ/0KJFC84843SmfvwRJSph080245Z/3AHArFmz2Kvbrny7eDElJSXcdstNvD3p/TIDVsWr9g4wZaLwq6pq2HC4AevTZrZDpvRYM11iZv8n6V3gnNgkHwg0M7MLJY0Cfm9m4yVtAIw3s/bxbjIHA8eY2XJJWwNfAhsAX5rZCkkXAO3N7AJJC4DWZra8gnIvMbPGlR1byXqtrcE2x67xOXFVs2Cc9zkWwrr1NaGim46sqYYbbW2bnnRLxuWm3tAnZ/vMl5pYM+0P3CFpPeAT4JQMy/+L0OSfGO9ROIdwH8OewB8kLQeWACfF5QcDkyRNjL/ndc7lizfzc8fMZgA7pKUNTLx+B+hWzno9E6/nEvtMzewnwuVO6Zc83cfqG8Imt3MR4Te8zrk8E8UbTKvz0qiVQLO0UfsaK3XRPjC70GVxrpiVlCjjVBtVW83UzL6g7D0BazQzmw7Umov2nauVFEb0i1FN7DN1zhUp4deZOudcDtTeZnwmHkydc3nlNVPnnKsq7zN1zrmqK+ZLozyYOufyypv5zjmXA0UaSz2YOufyx+8a5ZxzOVG8d43yYOqcyyuvmTrnXFX5pVHOOVd1/nNS55zLEW/mO+dcDnjN1Dnnqqou9plKqvTpXma2OPfFcc4VMxXxXaMqu9P+FGBy/H9K2vzk6i+ac64YlUgZp8pIaijpLUnvSpoi6aqYvrmkNyVNlfSIpHVieoM4Py3mt09s608x/SNJByXSe8e0aZIuzua4KqyZmlmtuUu+c672yEEz/wdgPzNbIqk+MEbSs8BvgRvN7GFJdwCnAf+M/y8ws60k9QOuB34pqSPQD9geaAO8GJ9uDPAP4ABgJjBO0nAze7+yQmX1DChJ/SRdEl+3k9RlzY7dOedCIC0tUcapMhYsibP142TAfsBjMf0+wlOKAfqy+uGajwH7xycZ9wUeNrMfzOxTYBrQNU7TzOwTM/sReDguW6mMwVTSbcC+wK9i0lLgjkzrOedceSRlnLLYRml8AOY3wAvAdGChma2Ii8wE2sbXbYEvAGL+ImD9ZHraOhWlVyqb0fw9zayzpLdjYean+iKcc25NCDL2iUYbSBqfmB9sZoNTM2a2EugkqTnwBLBdOduwxG7Ly6sovbxKppWTVkY2wXS5pJLUxiStD/yUxXrOOfczWQ7mzzWzXTMtZGYLJY0CugHNJdWLtc92wFdxsZmEJyXPlFQPaAbMT6SnJNepKL1C2fSZ/gN4HGgVR83GEDpwnXNuzWTRxM/UzJfUKtZIkbQu0Av4AHgZODou1h94Kr4eHueJ+f8zM4vp/eJo/+ZAB+AtYBzQIV4dsA5hkGp4pkPLWDM1s6GSJsQCAxxjZn5plHNujQkyDjBlYWPgPkmlhArho2b2tKT3gYclDQLeBu6Oy98N3C9pGqFG2g/AzKZIehR4H1gBnB27D5B0DjASKAWGmNmUTIXK9hdQpcByKu5PcM65rFT10igzmwTsUk76J4SR+PT074FjKtjWtcC15aSPAEasSbmyGc2/FHiIcB1WO+BBSX9ak50451xKLkbza6JsaqYnAl3MbCmApGuBCcBfqrNgzrnik7rOtBhlE0w/S1uuHvBJ9RTHOVfsijOUVn6jkxsJfaRLgSmSRsb5Awkj+s45t8ZqazM+k8pqpqkR+ynAM4n0N6qvOM65YiZl/rlobVXZjU7urijPOefWVpFWTDP3mUraknDpQEegYSrdzLaucCXnnCtHjq4zrZGyuWb0XuAewnnoAzxKuIuKc86tsWK9NCqbYLqemY0EMLPpZnYZ4S5Szjm3xpTFVBtlc2nUD/Hef9Ml/Qb4EmhdvcVyzhWjun6d6YVAY+A8Qt9pM+DU6iyUc6541dZmfCbZ3OjkzfjyW1bfINo559ZKkcbSSi/af4JKbohqZkdWS4mcc0WrTl5nCtyWt1LUMjttuwkvvXpToYtR53z01beFLoLLgTrXzDezl/JZEOdc3VCs9/DM9n6mzjlXZcV80b4HU+dcXhVpLM0+mEpqYGY/VGdhnHPFrZivM83mTvtdJb0HTI3zO0u6tdpL5pwrSlLmqTbKpi/4FuBQYB6Amb2L/5zUObcWBJRIGafaKJtmfomZfZZ2OcPKaiqPc67IldbOWJlRNsH0C0ldAYuPVj0X+Lh6i+WcK0aqxTXPTLIJpmcSmvqbArOBF2Oac86tsSKNpVn9Nv8boF8eyuKcK3IC6hXpaH42d9q/i3J+o29mA6qlRM65olZna6aEZn1KQ+AXwBfVUxznXFFTHb5o38weSc5Luh94odpK5JwrWgJKi7RqujY/J90c2CzXBXHO1Q11tmYqaQGr+0xLgPnAxdVZKOdc8apzt+ADiM9+2pnw3CeAn8yswhtGO+dcZcJv8wtdiupR6WHFwPmEma2MkwdS51yV5OLnpJI2kfSypA8kTZF0fkxvKekFSVPj/y1iuiTdImmapEmSOie21T8uP1VS/0R6F0nvxXVuUYYqdTbfEW8ld+ycc2sr3M8085SFFcDvzGw7oBtwtqSOhC7Il8ysA/ASq7sk+wAd4jQA+CeE4AtcCewOdAWuTAXguMyAxHq9KytQhcWWlOoC2JsQUD+SNFHS25ImZnW4zjlXhijJYsrEzL42s4nx9bfAB0BboC9wX1zsPuCI+LovMNSCN4DmkjYGDgJeMLP5ZraAcKVS75jX1MzGxhb50MS2ylVZn+lbQOdMG3DOuWyJrC/a30DS+MT8YDMbXO42pfbALsCbwIZm9jWEgCupdVysLWWvj58Z0ypLn1lOeoUqC6aKBZpe2Qaccy5ryvrnpHPNbNeMm5MaA48DF5jZ4kq6NcvLsLVIr1BlwbSVpN9WlGlmf69sw845l24NaqaZtyXVJwTSB8zsPzF5tqSNY610Y+CbmD4T2CSxejvgq5jeMy19VExvV87yFaqsq7cUaAw0qWByzrk1lqPRfAF3Ax+kVeyGA6kR+f7AU4n0k+KofjdgUewOGAkcKKlFHHg6EBgZ876V1C3u66TEtspVWc30azO7OuNROedclsLPSXOyqb2AXwHvSXonpl0CXAc8Kuk04HPgmJg3AjgYmAYsBU4BMLP5kq4BxsXlrjaz+fH1mcC9wLrAs3GqUMY+U+ecyxnl5hdQZjaGimPU/uUsb8DZFWxrCDCknPTxwA7ZlqmyYPqzAjnnXFUVay2twmCaqOo651xO+F2jnHMuR4o0lnowdc7lj5DXTJ1zLhfq5C34nHMu14ozlHowdc7lkeQDUM45lxPezHfOuRwozlDqwdQ5l0d+nalzzuVIkcZSD6bOuXwSKtKGvgdT51zeeDPfOedyQd7Md865nMjm5s+1kQdT51zeCMjuEVC1jwdT51xeFesAVGXPgHK1wPfff88BPfegxx6d2Wu3nbnu2qsAMDOuvepyunbqyB5ddmTwP29dtc6Y0a/Qc88u7LXbzhzWe79V6eedeTrbbt6Gvbt2yvtx1AZX/v4s9u28BUcdsPuqtEUL53PGCX05rEcnzjihL4sXLSizzuR3J9B58+a88MyTq9KGP/YAh/XoxGE9OjH8sQcA+G7JtxzbZ69VU89O7fnrVRfl58DyLBfPgKqJvGZayzVo0IAnnn6Bxo0bs3z5cg45sAe9DjiIjz/6kC+//II3Jk6mpKSEOXPCQxoXLVzIHy88l0efeJp2m2y6Kh2g3wn9Oe2Mszh7wKmFOpwa7fBjTqBf/wFc9tszVqUNuf1Gdt+rB6ee9VuG3P53htx+Ixf8KTw6beXKldz8lyvZY5/VD61YtHA+d950PQ8+PQpJHHdID3oecDBNm7Xg0WdfW7XccYfsw/69D8/fweVJMTfz814zldRe0rLUQ7AkzUhPT0zrVMP+e0p6Or4+WdLA+PpCSZ9Lui3X+6xOkmjcuDEAy5cvZ/ny5Ujinrvv5PcXXUZJSXiLW7VqDcDjwx7i0MOPoN0mm5ZJB9hz7+60aNEyz0dQe3TZfS+aNm9RJm3UC89w2FHHA3DYUcfz8vNPr8p76N472L/P4bTcoNWqtNdfeYlu3felWfOWNG3Wgm7d9+W1US+W2eZnn05j/rw5dO66ZzUeTaEoq3+1UaGa+dPNrLy25HQz65SYfkxmSqq2mrSZ3QhcUV3br04rV66k555d2G6LNvTctxdddtudGZ98wpP/Gcb+++zOL488lOnTpgIwfdpUFi5cwOF99me/7l155MH7C1z62m3e3Dm02nAjAFptuBHz584FYPasr3h55NMcc+JpZZb/ZtbXbLRx21XzG27Uhm9mfV1mmeeGP8ZBhx5ZnDcEUaiZZppqo5rQZzqnskxJAyUNlvQ8MDTWYEdLmhinPeNyq2qccf42SSfH170lfShpDHBkYvPLgCXZFFJQkv7SAAASG0lEQVTSAEnjJY2fFz8wNUVpaSmjXp/ApA9nMHHCOD54fzI//vgDDRo05KVX3+RX/U/j/LN+DcCKFSt49+2JPPTYcIY9MYL/++ufmTb14wIfQfG54aqLOf/iqygtLS2THh6SWVZ60Bw5/HF69z26WstXKKGZ732m1cLMdkvMbpl4BvZrZpZ6NGsXYG8zWyZpPeAAM/teUgfgIWDXirYvqSFwF7Af4ZnZjyT2/UhF65VTzsHAYIBOnbv8/BNRAzRr3py9uvfgpReeZ+M27Tis7y8AOOTwIzj3rNMBaNOmHS3X34BGjRrRqFEj9txzb6ZMnsRWHbYuZNFrrfU3aMWc2bNoteFGzJk9i5YbbADA+5Pe5qJzQ9/zwvnzGPPy85TWq8eGG7dh/BtjVq0/e9ZX7Npt71XzH73/HitWrqDjjrvk90DyqHaGysxqQs00KdnMTz7jeriZLYuv6wN3SXoPGAZ0zLDNbYFPzWxqfHb2v3Nf7MKZO2cOixYuBGDZsmW8+vJLdNh6Gw4+9HBGv/IyAK+NeZUtt+oAQJ9DDuON18ewYsUKli5dyoTx49h6m20LVv7arkevg/nv4w8C8N/HH6TnAYcAMOK193j2tck8+9pkeh3cl0uu+Tv7HXQoe/bYn7Gv/o/FixaweNECxr76P/bssXqA6rnhj9H78OKslaZIyjjVRgWvmWbpu8TrC4HZwM6EL4PvY/oKyn45NEy8rpE1yVyYPftrzjnjVFauXMlPPxl9jzyag/ocQrc99uKM007ijn/cTKNGjbnptjsB2Hrb7div10Hs060zJSUlnNj/FLbruAMAvz7lRF4b/Qrz581lx23ac9ElV3Bifx/ZT7n43FMYP3YMCxfM48Ddt+XMCy/h1LMu5I9nncwTjwxl4zabcMM/76t0G82at2TAeX/khMN6AjDg/Ito1nz1oN/zTz/Bbfc+Vp2HUXC1NFZmpPL6cKp1h1J74Gkz2yHL9IHAEjP7vzh/IzDTzP4m6RRgiJlJ0ibAaGAbQiB9B7gKeBj4GNjXzKZLeghoYmaHllO2k4Fdzeycyo6hU+cu9tKrb67hkbuqmjl/WeaFXM512qzpBDOrsCttTWy34y42dPiojMt13aJ5zvaZLzWtmZ+N24H+kt4AtibWWs3sC+BRYBLwAPB2TP8eGAA8EwegPitEoZ1zob+0WC+NqjHNfDObAexQTvrAtPmpwE6JpD8l8v4I/LGcbTxH6Dt1zhVSEd81qhA105VAs8SofY0g6UJCYF5c6LI4V8ykzFNtlPeaaWyOb5Lv/WYSL9q/sdDlcK641d5mfCa1sc/UOVeL5aJmKmmIpG8kTU6ktZT0gqSp8f8WMV2SbpE0TdIkSZ0T6/SPy0+V1D+R3kXSe3GdW5TF9VoeTJ1zeSNy1sy/F+idlnYx8JKZdQBeivMAfYAOcRoA/BNC8AWuBHYHugJXpgJwXGZAYr30ff2MB1PnXF7lYjTfzF4F5qcl9wVSF/reBxyRSB9qwRtAc0kbAwcBL5jZfDNbALwA9I55Tc1sbPyhz9DEtipUY0bznXN1Q5Y1zw0kjU/MD44/6a7Mhmb2NYCZfS0pdUu0tsAXieVmxrTK0meWk14pD6bOufzJvhk/N4cX7Ze3R1uL9Ep5M985l1fVeNH+7NhEJ/6fuvP5TMpeQdQO+CpDerty0ivlwdQ5lzepO+1X0/1MhwOpEfn+wFOJ9JPiqH43YFHsDhgJHCipRRx4OhAYGfO+ldQtjuKflNhWhbyZ75zLrxxcZhrvsdGT0Lc6kzAqfx3wqKTTgM+BY+LiI4CDCbfgXAqcAmBm8yVdA4yLy11tZqlBrTMJVwysCzwbp0p5MHXO5VUuLto3s+MqyNo/PSGOyJ9dzrKY2RBgSDnp4ynn5+2V8WDqnMur2vpYkkw8mDrn8suDqXPOVU3qFnzFyIOpcy5/avHTRzPxYOqcyy8Pps45V1XFews+D6bOubxJXbRfjDyYOufyy4Opc85VXUltfS5JBh5MnXN5VZyh1IOpcy6favED8zLxYOqcy5vw2JLijKYeTJ1zeVWcodSDqXMuz4q0YurB1DmXX97Md865HCjOUOrB1DmXR/LRfOecyw1v5jvnXA4UZyj1YOqcyyv5z0mdc66qwkX7hS5F9SgpdAGcc64YeM3UOZdX3sx3zrmq8kujnHOu6oSP5jvnXE74dabOOZcDRRpLPZg65/KrSGOpB1PnXH4VazNfZlboMtQ6kuYAnxW6HGtpA2BuoQtRB9Xm876ZmbXKxYYkPUc4F5nMNbPeudhnvngwrWMkjTezXQtdjrrGz3vx819AOedcDngwdc65HPBgWvcMLnQB6ig/70XO+0ydcy4HvGbqnHM54MHUOedywIOpc87lgAfTOkaSv+fOVQP/YNUhkhqb2U8eUPNL0nmSDix0OVz18g9VHSHpKWCGpLYeUPNH0iXAWcDRkvoUujyu+vgHqg6QtCnwDvBPYKwH1Lx6EjgAGAsc6QG1ePldo4qcpD3MbCxwZZyvD7wpaXcz+1JSiZn9VNhSFh9JvwSam9mdcf5lYF3gF5Iws2cLWkCXc14zKWKSNgNGSjoxlWZmFwP3EQKq11Crz3JgS0mnAZjZDGA4oYXwC6+hFh+vmRapWOP8TNK+wCOSJgOTzWyFmV0a7yn5pqSuZvaV11BzQ9K5QH0z+7ukH4CVqTwzmylpeJw9UpLMbERBCupyzoNpEZK0k5lNirOLgV3NbGHMKzGzn2JALQXeSgXUghW4SEhqAHwInCVpoZkNSeTJgpmSngGWAEdJ+tbMRheqzC53vHlXnI6TNFzSY8Ax6YE01ayPTf7Hgeck+RdrFUgqNbMfgDHAW8DpqSZ+apHUCzP7LC6zFzAnrwV11cZvdFJEkk11SV8B35vZFnF+HTP7Mb4W4b3/SdJtwJNm9mLBCl4k4pfU88BEoA3QAnjezG5O5Sfen72BJWb2TqHK63LLg2mRiDWjlXG0fmtgR+BsYI6ZHRmXkaW94fFC/iX5L3HxkbQfMMDM+klqBuwMXAw8lmzyu+LkzfwiEGs8KxM1o53M7GEz6w60lvRkXPRWSWUeneGBdO0p8WQ4SQ2BH4Eukpqa2SLgXUKf9QWSehWomC5PPJgWgdhcF+EC8VfN7CFJ9STVN7O9gXUljQWamNn4wpa2eKRq+ZJ+BxxtZmMIfdC3SmoSA+p84ArvRil+PuhQi6U129cDvgHekHQM0BdoLukRMztI0o5m9l4567k1VM5lZPWAvSV9D/wbOAkYJ+lzQjfLk3E9P+9FzPtMa6lUH2l83RT4DvgdcDjwJmFUuSmwpZldkVjPP9A5EFsCvczshTh/DqGvepSZ/UfSTsA6qZaAn/fi5zXTWiitj/R+YCkwBXgauNvM5sXlhhKamav4Bzpn9gGultTKzB40s9skXQlcIWldwqDTD1BuTdYVIe8zrYUSfaQPEGqhQ4FrgKZmNk9SW0n3EloeF0DZwRK35uIPHFYxs1eAvwPHSzohJl9D+GIjFUjjaw+kdYDXTGuvtsDnwDPAjcBAM3tDUgvCr2seSDRBvWZUBYnLzkqAvwALgNFmNix+R50b78zVEfifmT1QwOK6AvGaaS2RXjMi/HKmEaFpP8rM/haXuQ/YIhFI5YG0ahKB9L+EL6qlwLOS9jezYcCfgA7AZ2Z2GXhLoC7ymmktkNZHeiqhH/RJ4DVgW+CdeIeo6wmjx2+n1vU+0rWXVqM/DBgH/I1w7ocBIyT1NbPnJL1pZivKWc/VET6aX8Mlmpgi1EKNcCF4U8IH/BTCb7xbEmpGq/pIPZCuvcR9DEqBQcBdwNfArcBMMxso6d/A8YQfSUyO6/l5r6O8ZlrDJQLpBcC7ZnYJQBxg+i9whJkNkdTCzBbEPK8ZVVHi/F0PLDCzTwAkfQ1Mj3nTgPNSgTSu54G0jvI+0xpKZW/YvD2heb+tpA0AzOxkwkX678Y7PqXuDOV9pFUg6a+SNomvfwPsCbwe5+sRWgU9JE0E2pjZbTHPP0t1nDfza6C0C/Ibm9kSSVsA/wIeAh42s29j/mlmdncBi1s0JN0MdDSzA+L8XsBvCIN9t5vZtHgjmW2Admb2XFzOm/bOg2lNo7L3HH0IKAVWEPrsPiEE1McIlz4tTqznH+gqkPQw4Q75R8X5XoQBvi7AEcBc4HEzm5q2nnepOMCb+TVKqokeA+mDwJfAH4CHCdeSbgacR3h0cJfkuh5I114cZGqemD8duBRoEG9e8jTQCjhZUqvkuh5IXYoPQNUQko4DGkoaGgedFgK3WHgQ26cKj8T4lZmdJuloM/uooAUuEpJOMrOhkg4H7pb0MTAP6GPxCQVmNireYq+lmfmd8V25vGZaA8R+uE0JNxM+NiavA9yWWOwDoImkhqlA6heG58QFkm6x8BSCAYSf5y6x1Y96qQ9gZs+Z2YMxzc+7+xkPpjWAmS0HbiY8F+hwSQcQBj6WSXpW0o7AZcAsM/s+sZ437deSpBGSjgT2ALpKOsTMlhG6UL6S9ETsdllezu/y/by7n/FgWkCSzk19UGOQbE24G9HRwCGEC8KnAf2Br8zsvLie14yqQNL2wAGEPtEfgL3M7BmAeJXEOYRLoEbFtJUVbMq5VbzPtEBiEO0D7Et4hvrJwFHAfkDX+P9yMzs3bT0fPa4iM5siqS8wSFI9M7sfQpPezJab2beSzgX6FbakrjbxYFoAiUGPIwiDHh8Rfm9/iJnNV3iyaBPgGElzzeyNuJ5fkJ8jZjYiVvCvk/SjmT0Sm/Sp59svBgaDX3bmsuPXmRZA/PXMGDM7T+FGwoOBjVIXi8dl1gP2MLOXClXOukDSwcB1wLVm9khM89q/W2PeZ5pH2Q56AJjZ0lQg9T7S6mNmIwiPY75U8SbPtvrZ9n7eXda8ZponcdDjHeAkC08PXfWT0ZjfhHApVHsz61GoctZVsYY6CLgDWN/M/lLgIrlaxvtM88QHPWq22Icqws91+xe6PK728ZppnlXQR/ezAQ4f9CgMSc0sPO/euTXiNdM8SxtFJo4iW/qghwfSwvBA6taWB9MCSAuo9czsgeSghwdS52ofD6YFkgiogyQ1Ig56eCB1rnbyYFpAPujhXPHwAagawAc9nKv9PJg651wO+C+gnHMuBzyYOudcDngwdRWStFLSO5ImSxoWb76yttvqKenp+PpwSRdXsmxzSWetxT4GSvp9tulpy9wr6eg12Fd7SZPXtIyueHkwdZVZZmadzGwH4EfC3f9XUbDGf0NmNtzMrqtkkeaEm784V2t4MHXZGg1sFWtkH0i6HZgIbCLpQEljJU2MNdjGAJJ6S/pQ0hjgyNSGJJ0s6bb4esN4t6x347Qn4ee2W8Za8Q1xuT9IGidpkqSrEtu6VNJHkl4kPM++UpJ+HbfzrqTH02rbvSSNlvSxpEPj8qWSbkjs+4yqnkhXnDyYuowk1SM8FeC9mLQNMNTMdgG+IzyfqpeZdQbGA79VeJrnXcBhQHdgowo2fwvwipntDHQGphBuiTc91or/IOlAoAPhCQSdgC6S9pHUhXBjmF0IwXq3LA7nP2a2W9zfB8Bpibz2QA/CI2PuiMdwGrDIzHaL2/+1pM2z2I+rY/yifVeZdSW9E1+PBu4G2gCfpe7+D3QDOgKvxV90rQOMBbYFPjWzqQCS/k14+me6/YCTYNWzlhZJapG2zIFxejvONyYE1ybAE2a2NO5jeBbHtIOkQYSuhMbAyETeo/FnvVMlfRKP4UBgp0R/arO474+z2JerQzyYusosM7NOyYQYML9LJgEvmNlxact1AnJ1EbOAv5jZnWn7uGAt9nEvcISZvavw3K2eibz0bVnc97lmlgy6SGq/hvt1Rc6b+a6q3gD2krQVhMetSNoa+BDYXNKWcbnjKlj/JeDMuG6ppKbAt4RaZ8pI4NREX2xbSa2BV4FfSFo33lz7sCzK2wT4WlJ94IS0vGMklcQybwF8FPd9ZlweSVvHeyk4V4bXTF2VmNmcWMN7SFKDmHyZmX0saQDwjKS5wBhgh3I2cT4wWNJpwErgTDMbK+m1eOnRs7HfdDtgbKwZLwFONLOJkh4hPMHgM0JXRCaXA2/G5d+jbND+CHgF2BD4jZl9L+lfhL7UifE+CnOAI7I7O64u8Z+TOudcDngz3znncsCDqXPO5YAHU+ecywEPps45lwMeTJ1zLgc8mDrnXA54MHXOuRz4f5ksHs+cRtaaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna0.predict(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list1 = [100,1]\n",
    "activation_list1 = ['tanh','sigmoid']\n",
    "dropout_list1 = [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 20,201\n",
      "Trainable params: 20,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna1 = new_rna()\n",
    "rna1.build_model(data_shape,n_list1,activation_list1,dropout_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64440 samples, validate on 13810 samples\n",
      "Epoch 1/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3983 - f1: 0.5156 - val_loss: 0.3676 - val_f1: 0.1413\n",
      "Epoch 2/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3697 - f1: 0.5404 - val_loss: 0.3688 - val_f1: 0.1426\n",
      "Epoch 3/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3675 - f1: 0.5419 - val_loss: 0.3662 - val_f1: 0.1397\n",
      "Epoch 4/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3659 - f1: 0.5458 - val_loss: 0.3677 - val_f1: 0.1420\n",
      "Epoch 5/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3647 - f1: 0.5467 - val_loss: 0.3666 - val_f1: 0.1418\n",
      "Epoch 6/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3644 - f1: 0.5474 - val_loss: 0.3665 - val_f1: 0.1419\n",
      "Epoch 7/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3630 - f1: 0.5495 - val_loss: 0.3665 - val_f1: 0.1436\n",
      "Epoch 8/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3621 - f1: 0.5513 - val_loss: 0.3662 - val_f1: 0.1408\n",
      "Epoch 9/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3623 - f1: 0.5523 - val_loss: 0.3665 - val_f1: 0.1396\n",
      "Epoch 10/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3620 - f1: 0.5461 - val_loss: 0.3666 - val_f1: 0.1423\n",
      "Epoch 11/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3615 - f1: 0.5514 - val_loss: 0.3660 - val_f1: 0.1424\n",
      "Epoch 12/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3614 - f1: 0.5500 - val_loss: 0.3662 - val_f1: 0.1420\n",
      "Epoch 13/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3605 - f1: 0.5540 - val_loss: 0.3659 - val_f1: 0.1392\n",
      "Epoch 14/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3606 - f1: 0.5516 - val_loss: 0.3664 - val_f1: 0.1417\n",
      "Epoch 15/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3610 - f1: 0.5505 - val_loss: 0.3662 - val_f1: 0.1424\n",
      "Epoch 16/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3606 - f1: 0.5534 - val_loss: 0.3663 - val_f1: 0.1419\n",
      "Epoch 17/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3604 - f1: 0.5539 - val_loss: 0.3661 - val_f1: 0.1418\n",
      "Epoch 18/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3599 - f1: 0.5522 - val_loss: 0.3660 - val_f1: 0.1404\n",
      "Epoch 19/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3597 - f1: 0.5511 - val_loss: 0.3664 - val_f1: 0.1416\n",
      "Epoch 20/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.3601 - f1: 0.5530 - val_loss: 0.3662 - val_f1: 0.1422\n",
      "Epoch 21/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3594 - f1: 0.5593 - val_loss: 0.3665 - val_f1: 0.1424\n",
      "Epoch 22/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3593 - f1: 0.5545 - val_loss: 0.3666 - val_f1: 0.1420\n",
      "Epoch 23/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3597 - f1: 0.5518 - val_loss: 0.3664 - val_f1: 0.1419\n",
      "Epoch 24/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3594 - f1: 0.5549 - val_loss: 0.3662 - val_f1: 0.1399\n",
      "Epoch 25/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3592 - f1: 0.5546 - val_loss: 0.3661 - val_f1: 0.1418\n",
      "Epoch 26/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3596 - f1: 0.5529 - val_loss: 0.3660 - val_f1: 0.1421\n",
      "Epoch 27/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3591 - f1: 0.5535 - val_loss: 0.3660 - val_f1: 0.1401\n",
      "Epoch 28/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3586 - f1: 0.5548 - val_loss: 0.3665 - val_f1: 0.1432\n",
      "Epoch 29/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3590 - f1: 0.5569 - val_loss: 0.3661 - val_f1: 0.1410\n",
      "Epoch 30/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3587 - f1: 0.5548 - val_loss: 0.3664 - val_f1: 0.1441\n",
      "Epoch 31/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3585 - f1: 0.5552 - val_loss: 0.3662 - val_f1: 0.1423\n",
      "Epoch 32/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3586 - f1: 0.5545 - val_loss: 0.3663 - val_f1: 0.1435\n",
      "Epoch 33/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3582 - f1: 0.5543 - val_loss: 0.3662 - val_f1: 0.1423\n",
      "Epoch 34/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3576 - f1: 0.5596 - val_loss: 0.3660 - val_f1: 0.1425\n",
      "Epoch 35/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3580 - f1: 0.5529 - val_loss: 0.3660 - val_f1: 0.1426\n",
      "Epoch 36/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3577 - f1: 0.5549 - val_loss: 0.3664 - val_f1: 0.1427\n",
      "Epoch 37/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3576 - f1: 0.5583 - val_loss: 0.3662 - val_f1: 0.1428\n",
      "Epoch 38/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3576 - f1: 0.5566 - val_loss: 0.3663 - val_f1: 0.1431\n",
      "Epoch 39/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3572 - f1: 0.5601 - val_loss: 0.3662 - val_f1: 0.1425\n",
      "Epoch 40/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3569 - f1: 0.5586 - val_loss: 0.3661 - val_f1: 0.1414\n",
      "Epoch 41/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3572 - f1: 0.5542 - val_loss: 0.3663 - val_f1: 0.1433\n",
      "Epoch 42/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3571 - f1: 0.5583 - val_loss: 0.3664 - val_f1: 0.1422\n",
      "Epoch 43/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3572 - f1: 0.5605 - val_loss: 0.3663 - val_f1: 0.1424\n",
      "Epoch 44/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3567 - f1: 0.5571 - val_loss: 0.3664 - val_f1: 0.1430\n",
      "Epoch 45/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3564 - f1: 0.5618 - val_loss: 0.3661 - val_f1: 0.1415\n",
      "Epoch 46/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3560 - f1: 0.5574 - val_loss: 0.3662 - val_f1: 0.1422\n",
      "Epoch 47/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3559 - f1: 0.5597 - val_loss: 0.3660 - val_f1: 0.1431\n",
      "Epoch 48/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3564 - f1: 0.5581 - val_loss: 0.3662 - val_f1: 0.1427\n",
      "Epoch 49/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3561 - f1: 0.5595 - val_loss: 0.3662 - val_f1: 0.1432\n",
      "Epoch 50/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3559 - f1: 0.5604 - val_loss: 0.3663 - val_f1: 0.1430\n",
      "Epoch 51/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3555 - f1: 0.5585 - val_loss: 0.3664 - val_f1: 0.1424\n",
      "Epoch 52/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3552 - f1: 0.5601 - val_loss: 0.3666 - val_f1: 0.1436\n",
      "Epoch 53/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3553 - f1: 0.5553 - val_loss: 0.3667 - val_f1: 0.1440\n",
      "Epoch 54/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3549 - f1: 0.5624 - val_loss: 0.3670 - val_f1: 0.1439\n",
      "Epoch 55/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3544 - f1: 0.5612 - val_loss: 0.3666 - val_f1: 0.1416\n",
      "Epoch 56/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3549 - f1: 0.5619 - val_loss: 0.3669 - val_f1: 0.1440\n",
      "Epoch 57/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3548 - f1: 0.5614 - val_loss: 0.3665 - val_f1: 0.1433\n",
      "Epoch 58/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3547 - f1: 0.5638 - val_loss: 0.3665 - val_f1: 0.1414\n",
      "Epoch 59/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3542 - f1: 0.5614 - val_loss: 0.3661 - val_f1: 0.1405\n",
      "Epoch 60/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3547 - f1: 0.5595 - val_loss: 0.3663 - val_f1: 0.1417\n",
      "Epoch 61/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3538 - f1: 0.5626 - val_loss: 0.3667 - val_f1: 0.1433\n",
      "Epoch 62/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3534 - f1: 0.5659 - val_loss: 0.3662 - val_f1: 0.1410\n",
      "Epoch 63/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3527 - f1: 0.5615 - val_loss: 0.3666 - val_f1: 0.1429\n",
      "Epoch 64/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3533 - f1: 0.5633 - val_loss: 0.3670 - val_f1: 0.1440\n",
      "Epoch 65/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3529 - f1: 0.5639 - val_loss: 0.3669 - val_f1: 0.1428\n",
      "Epoch 66/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3536 - f1: 0.5630 - val_loss: 0.3665 - val_f1: 0.1421\n",
      "Epoch 67/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3530 - f1: 0.5642 - val_loss: 0.3670 - val_f1: 0.1421\n",
      "Epoch 68/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3529 - f1: 0.5636 - val_loss: 0.3667 - val_f1: 0.1420\n",
      "Epoch 69/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3528 - f1: 0.5654 - val_loss: 0.3664 - val_f1: 0.1419\n",
      "Epoch 70/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3524 - f1: 0.5623 - val_loss: 0.3665 - val_f1: 0.1424\n",
      "Epoch 71/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3524 - f1: 0.5655 - val_loss: 0.3668 - val_f1: 0.1418\n",
      "Epoch 72/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3513 - f1: 0.5659 - val_loss: 0.3665 - val_f1: 0.1426\n",
      "Epoch 73/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3523 - f1: 0.5616 - val_loss: 0.3667 - val_f1: 0.1427\n",
      "Epoch 74/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3514 - f1: 0.5655 - val_loss: 0.3663 - val_f1: 0.1407\n",
      "Epoch 75/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3510 - f1: 0.5620 - val_loss: 0.3669 - val_f1: 0.1419\n",
      "Epoch 76/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3507 - f1: 0.5661 - val_loss: 0.3673 - val_f1: 0.1436\n",
      "Epoch 77/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3501 - f1: 0.5688 - val_loss: 0.3666 - val_f1: 0.1420\n",
      "Epoch 78/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3495 - f1: 0.5666 - val_loss: 0.3673 - val_f1: 0.1425\n",
      "Epoch 79/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3501 - f1: 0.5686 - val_loss: 0.3671 - val_f1: 0.1419\n",
      "Epoch 80/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3496 - f1: 0.5685 - val_loss: 0.3670 - val_f1: 0.1420\n",
      "Epoch 81/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3500 - f1: 0.5683 - val_loss: 0.3670 - val_f1: 0.1424\n",
      "Epoch 82/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3496 - f1: 0.5708 - val_loss: 0.3673 - val_f1: 0.1424\n",
      "Epoch 83/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3487 - f1: 0.5717 - val_loss: 0.3668 - val_f1: 0.1422\n",
      "Epoch 84/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3495 - f1: 0.5651 - val_loss: 0.3673 - val_f1: 0.1428\n",
      "Epoch 85/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3475 - f1: 0.5689 - val_loss: 0.3678 - val_f1: 0.1431\n",
      "Epoch 86/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3478 - f1: 0.5767 - val_loss: 0.3677 - val_f1: 0.1414\n",
      "Epoch 87/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3482 - f1: 0.5702 - val_loss: 0.3670 - val_f1: 0.1406\n",
      "Epoch 88/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3470 - f1: 0.5685 - val_loss: 0.3676 - val_f1: 0.1428\n",
      "Epoch 89/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3463 - f1: 0.5745 - val_loss: 0.3674 - val_f1: 0.1407\n",
      "Epoch 90/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3463 - f1: 0.5748 - val_loss: 0.3677 - val_f1: 0.1420\n",
      "Epoch 91/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3455 - f1: 0.5727 - val_loss: 0.3674 - val_f1: 0.1415\n",
      "Epoch 92/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3457 - f1: 0.5756 - val_loss: 0.3678 - val_f1: 0.1419\n",
      "Epoch 93/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3455 - f1: 0.5756 - val_loss: 0.3676 - val_f1: 0.1425\n",
      "Epoch 94/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3452 - f1: 0.5762 - val_loss: 0.3674 - val_f1: 0.1413\n",
      "Epoch 95/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3448 - f1: 0.5759 - val_loss: 0.3679 - val_f1: 0.1420\n",
      "Epoch 96/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3445 - f1: 0.5718 - val_loss: 0.3674 - val_f1: 0.1420\n",
      "Epoch 97/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3436 - f1: 0.5823 - val_loss: 0.3683 - val_f1: 0.1416\n",
      "Epoch 98/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3434 - f1: 0.5768 - val_loss: 0.3683 - val_f1: 0.1411\n",
      "Epoch 99/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3431 - f1: 0.5825 - val_loss: 0.3678 - val_f1: 0.1422\n",
      "Epoch 100/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3418 - f1: 0.5806 - val_loss: 0.3686 - val_f1: 0.1407\n",
      "Epoch 101/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3424 - f1: 0.5784 - val_loss: 0.3688 - val_f1: 0.1419\n",
      "Epoch 102/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3422 - f1: 0.5845 - val_loss: 0.3685 - val_f1: 0.1420\n",
      "Epoch 103/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3412 - f1: 0.5839 - val_loss: 0.3683 - val_f1: 0.1420\n",
      "Epoch 104/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3418 - f1: 0.5822 - val_loss: 0.3687 - val_f1: 0.1408\n",
      "Epoch 105/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3409 - f1: 0.5876 - val_loss: 0.3684 - val_f1: 0.1402\n",
      "Epoch 106/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3407 - f1: 0.5824 - val_loss: 0.3689 - val_f1: 0.1431\n",
      "Epoch 107/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3399 - f1: 0.5863 - val_loss: 0.3683 - val_f1: 0.1423\n",
      "Epoch 108/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3402 - f1: 0.5837 - val_loss: 0.3689 - val_f1: 0.1426\n",
      "Epoch 109/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3386 - f1: 0.5854 - val_loss: 0.3685 - val_f1: 0.1417\n",
      "Epoch 110/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3392 - f1: 0.5905 - val_loss: 0.3692 - val_f1: 0.1405\n",
      "Epoch 111/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3373 - f1: 0.5855 - val_loss: 0.3689 - val_f1: 0.1427\n",
      "Epoch 112/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3383 - f1: 0.5890 - val_loss: 0.3696 - val_f1: 0.1438\n",
      "Epoch 113/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3377 - f1: 0.5862 - val_loss: 0.3698 - val_f1: 0.1416\n",
      "Epoch 114/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3371 - f1: 0.5903 - val_loss: 0.3688 - val_f1: 0.1413\n",
      "Epoch 115/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3364 - f1: 0.5920 - val_loss: 0.3693 - val_f1: 0.1425\n",
      "Epoch 116/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3374 - f1: 0.5880 - val_loss: 0.3696 - val_f1: 0.1419\n",
      "Epoch 117/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3362 - f1: 0.5910 - val_loss: 0.3697 - val_f1: 0.1416\n",
      "Epoch 118/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3343 - f1: 0.5958 - val_loss: 0.3702 - val_f1: 0.1409\n",
      "Epoch 119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3347 - f1: 0.5947 - val_loss: 0.3697 - val_f1: 0.1409\n",
      "Epoch 120/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3350 - f1: 0.5912 - val_loss: 0.3697 - val_f1: 0.1410\n",
      "Epoch 121/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3348 - f1: 0.5879 - val_loss: 0.3704 - val_f1: 0.1414\n",
      "Epoch 122/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3344 - f1: 0.5927 - val_loss: 0.3704 - val_f1: 0.1428\n",
      "Epoch 123/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.3326 - f1: 0.59 - 2s 36us/step - loss: 0.3333 - f1: 0.5940 - val_loss: 0.3707 - val_f1: 0.1432\n",
      "Epoch 124/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3334 - f1: 0.5975 - val_loss: 0.3710 - val_f1: 0.1422\n",
      "Epoch 125/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3324 - f1: 0.6015 - val_loss: 0.3705 - val_f1: 0.1413\n",
      "Epoch 126/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3305 - f1: 0.5993 - val_loss: 0.3711 - val_f1: 0.1428\n",
      "Epoch 127/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3314 - f1: 0.5998 - val_loss: 0.3713 - val_f1: 0.1418\n",
      "Epoch 128/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3301 - f1: 0.5995 - val_loss: 0.3709 - val_f1: 0.1433\n",
      "Epoch 129/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3310 - f1: 0.5964 - val_loss: 0.3715 - val_f1: 0.1435\n",
      "Epoch 130/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3304 - f1: 0.6000 - val_loss: 0.3712 - val_f1: 0.1424\n",
      "Epoch 131/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3299 - f1: 0.5978 - val_loss: 0.3713 - val_f1: 0.1428\n",
      "Epoch 132/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3297 - f1: 0.6038 - val_loss: 0.3716 - val_f1: 0.1422\n",
      "Epoch 133/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3274 - f1: 0.6059 - val_loss: 0.3711 - val_f1: 0.1414\n",
      "Epoch 134/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3292 - f1: 0.5974 - val_loss: 0.3713 - val_f1: 0.1418\n",
      "Epoch 135/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3273 - f1: 0.6083 - val_loss: 0.3715 - val_f1: 0.1422\n",
      "Epoch 136/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3267 - f1: 0.6047 - val_loss: 0.3722 - val_f1: 0.1416\n",
      "Epoch 137/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3266 - f1: 0.6044 - val_loss: 0.3726 - val_f1: 0.1421\n",
      "Epoch 138/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3270 - f1: 0.6062 - val_loss: 0.3724 - val_f1: 0.1430\n",
      "Epoch 139/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3264 - f1: 0.6091 - val_loss: 0.3729 - val_f1: 0.1422\n",
      "Epoch 140/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3244 - f1: 0.6135 - val_loss: 0.3727 - val_f1: 0.1416\n",
      "Epoch 141/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3242 - f1: 0.6120 - val_loss: 0.3727 - val_f1: 0.1424\n",
      "Epoch 142/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3237 - f1: 0.6122 - val_loss: 0.3745 - val_f1: 0.1416\n",
      "Epoch 143/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3246 - f1: 0.6142 - val_loss: 0.3739 - val_f1: 0.1431\n",
      "Epoch 144/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3227 - f1: 0.6139 - val_loss: 0.3736 - val_f1: 0.1437\n",
      "Epoch 145/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3228 - f1: 0.6132 - val_loss: 0.3736 - val_f1: 0.1417\n",
      "Epoch 146/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3231 - f1: 0.6130 - val_loss: 0.3722 - val_f1: 0.1418\n",
      "Epoch 147/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3231 - f1: 0.6147 - val_loss: 0.3727 - val_f1: 0.1432\n",
      "Epoch 148/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3207 - f1: 0.6152 - val_loss: 0.3738 - val_f1: 0.1433\n",
      "Epoch 149/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3219 - f1: 0.6171 - val_loss: 0.3734 - val_f1: 0.1419\n",
      "Epoch 150/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3216 - f1: 0.6174 - val_loss: 0.3736 - val_f1: 0.1425\n",
      "Epoch 151/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3195 - f1: 0.6152 - val_loss: 0.3741 - val_f1: 0.1422\n",
      "Epoch 152/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.3193 - f1: 0.6202 - val_loss: 0.3746 - val_f1: 0.1420\n",
      "Epoch 153/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.3181 - f1: 0.6217 - val_loss: 0.3741 - val_f1: 0.1414\n",
      "Epoch 154/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3186 - f1: 0.6214 - val_loss: 0.3744 - val_f1: 0.1431\n",
      "Epoch 155/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3173 - f1: 0.6271 - val_loss: 0.3740 - val_f1: 0.1443\n",
      "Epoch 156/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3169 - f1: 0.6262 - val_loss: 0.3756 - val_f1: 0.1427\n",
      "Epoch 157/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3177 - f1: 0.6247 - val_loss: 0.3751 - val_f1: 0.1423\n",
      "Epoch 158/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3166 - f1: 0.6261 - val_loss: 0.3759 - val_f1: 0.1419\n",
      "Epoch 159/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3173 - f1: 0.6180 - val_loss: 0.3762 - val_f1: 0.1435\n",
      "Epoch 160/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3159 - f1: 0.6257 - val_loss: 0.3752 - val_f1: 0.1416\n",
      "Epoch 161/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3166 - f1: 0.6252 - val_loss: 0.3760 - val_f1: 0.1426\n",
      "Epoch 162/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3158 - f1: 0.6233 - val_loss: 0.3760 - val_f1: 0.1420\n",
      "Epoch 163/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3143 - f1: 0.6286 - val_loss: 0.3763 - val_f1: 0.1433\n",
      "Epoch 164/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3139 - f1: 0.6232 - val_loss: 0.3755 - val_f1: 0.1433\n",
      "Epoch 165/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3140 - f1: 0.6268 - val_loss: 0.3760 - val_f1: 0.1411\n",
      "Epoch 166/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3125 - f1: 0.6313 - val_loss: 0.3772 - val_f1: 0.1415\n",
      "Epoch 167/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3124 - f1: 0.6286 - val_loss: 0.3779 - val_f1: 0.1421\n",
      "Epoch 168/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3122 - f1: 0.6291 - val_loss: 0.3768 - val_f1: 0.1437\n",
      "Epoch 169/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3114 - f1: 0.6326 - val_loss: 0.3770 - val_f1: 0.1432\n",
      "Epoch 170/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3118 - f1: 0.6338 - val_loss: 0.3770 - val_f1: 0.1420\n",
      "Epoch 171/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3104 - f1: 0.6323 - val_loss: 0.3781 - val_f1: 0.1408\n",
      "Epoch 172/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3103 - f1: 0.6313 - val_loss: 0.3781 - val_f1: 0.1414\n",
      "Epoch 173/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3097 - f1: 0.6315 - val_loss: 0.3784 - val_f1: 0.1414\n",
      "Epoch 174/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3100 - f1: 0.6313 - val_loss: 0.3794 - val_f1: 0.1416\n",
      "Epoch 175/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3096 - f1: 0.6353 - val_loss: 0.3786 - val_f1: 0.1429\n",
      "Epoch 176/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3086 - f1: 0.6386 - val_loss: 0.3789 - val_f1: 0.1435\n",
      "Epoch 177/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3073 - f1: 0.6385 - val_loss: 0.3786 - val_f1: 0.1422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3079 - f1: 0.6372 - val_loss: 0.3783 - val_f1: 0.1429\n",
      "Epoch 179/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3070 - f1: 0.6416 - val_loss: 0.3785 - val_f1: 0.1422\n",
      "Epoch 180/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3064 - f1: 0.6374 - val_loss: 0.3800 - val_f1: 0.1423\n",
      "Epoch 181/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3042 - f1: 0.6440 - val_loss: 0.3797 - val_f1: 0.1422\n",
      "Epoch 182/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3057 - f1: 0.6410 - val_loss: 0.3803 - val_f1: 0.1414\n",
      "Epoch 183/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3038 - f1: 0.6446 - val_loss: 0.3800 - val_f1: 0.1418\n",
      "Epoch 184/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3031 - f1: 0.6448 - val_loss: 0.3807 - val_f1: 0.1411\n",
      "Epoch 185/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3043 - f1: 0.6407 - val_loss: 0.3805 - val_f1: 0.1420\n",
      "Epoch 186/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3034 - f1: 0.6460 - val_loss: 0.3817 - val_f1: 0.1423\n",
      "Epoch 187/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3025 - f1: 0.6504 - val_loss: 0.3810 - val_f1: 0.1440\n",
      "Epoch 188/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3032 - f1: 0.6411 - val_loss: 0.3816 - val_f1: 0.1411\n",
      "Epoch 189/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3026 - f1: 0.6484 - val_loss: 0.3819 - val_f1: 0.1424\n",
      "Epoch 190/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3041 - f1: 0.6477 - val_loss: 0.3821 - val_f1: 0.1433\n",
      "Epoch 191/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3032 - f1: 0.6499 - val_loss: 0.3812 - val_f1: 0.1409\n",
      "Epoch 192/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3004 - f1: 0.6464 - val_loss: 0.3818 - val_f1: 0.1419\n",
      "Epoch 193/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3000 - f1: 0.6552 - val_loss: 0.3821 - val_f1: 0.1414\n",
      "Epoch 194/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3004 - f1: 0.6548 - val_loss: 0.3816 - val_f1: 0.1413\n",
      "Epoch 195/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3005 - f1: 0.6539 - val_loss: 0.3820 - val_f1: 0.1427\n",
      "Epoch 196/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3007 - f1: 0.6525 - val_loss: 0.3825 - val_f1: 0.1420\n",
      "Epoch 197/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3007 - f1: 0.6468 - val_loss: 0.3825 - val_f1: 0.1404\n",
      "Epoch 198/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2987 - f1: 0.6553 - val_loss: 0.3821 - val_f1: 0.1406\n",
      "Epoch 199/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2988 - f1: 0.6527 - val_loss: 0.3830 - val_f1: 0.1412\n",
      "Epoch 200/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2985 - f1: 0.6511 - val_loss: 0.3831 - val_f1: 0.1426\n",
      "Epoch 201/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2980 - f1: 0.6509 - val_loss: 0.3830 - val_f1: 0.1412\n",
      "Epoch 202/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2989 - f1: 0.6502 - val_loss: 0.3833 - val_f1: 0.1422\n",
      "Epoch 203/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2947 - f1: 0.6613 - val_loss: 0.3836 - val_f1: 0.1407\n",
      "Epoch 204/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2965 - f1: 0.6569 - val_loss: 0.3843 - val_f1: 0.1409\n",
      "Epoch 205/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2950 - f1: 0.6615 - val_loss: 0.3846 - val_f1: 0.1405\n",
      "Epoch 206/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2945 - f1: 0.6609 - val_loss: 0.3849 - val_f1: 0.1407\n",
      "Epoch 207/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2965 - f1: 0.6556 - val_loss: 0.3844 - val_f1: 0.1412\n",
      "Epoch 208/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2954 - f1: 0.6576 - val_loss: 0.3843 - val_f1: 0.1421\n",
      "Epoch 209/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2954 - f1: 0.6562 - val_loss: 0.3853 - val_f1: 0.1420\n",
      "Epoch 210/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2952 - f1: 0.6582 - val_loss: 0.3855 - val_f1: 0.1421\n",
      "Epoch 211/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2952 - f1: 0.6608 - val_loss: 0.3861 - val_f1: 0.1412\n",
      "Epoch 212/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2933 - f1: 0.6569 - val_loss: 0.3868 - val_f1: 0.1403\n",
      "Epoch 213/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2940 - f1: 0.6582 - val_loss: 0.3849 - val_f1: 0.1418\n",
      "Epoch 214/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2920 - f1: 0.6623 - val_loss: 0.3851 - val_f1: 0.1418\n",
      "Epoch 215/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2933 - f1: 0.6641 - val_loss: 0.3855 - val_f1: 0.1416\n",
      "Epoch 216/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2925 - f1: 0.6635 - val_loss: 0.3850 - val_f1: 0.1405\n",
      "Epoch 217/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2891 - f1: 0.6749 - val_loss: 0.3874 - val_f1: 0.1409\n",
      "Epoch 218/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2922 - f1: 0.6640 - val_loss: 0.3869 - val_f1: 0.1410\n",
      "Epoch 219/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2909 - f1: 0.6605 - val_loss: 0.3866 - val_f1: 0.1437\n",
      "Epoch 220/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2913 - f1: 0.6660 - val_loss: 0.3871 - val_f1: 0.1409\n",
      "Epoch 221/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2913 - f1: 0.6662 - val_loss: 0.3877 - val_f1: 0.1413\n",
      "Epoch 222/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2890 - f1: 0.6684 - val_loss: 0.3875 - val_f1: 0.1414\n",
      "Epoch 223/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2904 - f1: 0.6654 - val_loss: 0.3876 - val_f1: 0.1421\n",
      "Epoch 224/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2895 - f1: 0.6673 - val_loss: 0.3876 - val_f1: 0.1414\n",
      "Epoch 225/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2871 - f1: 0.6719 - val_loss: 0.3890 - val_f1: 0.1415\n",
      "Epoch 226/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2886 - f1: 0.6696 - val_loss: 0.3879 - val_f1: 0.1433\n",
      "Epoch 227/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2870 - f1: 0.6731 - val_loss: 0.3882 - val_f1: 0.1414\n",
      "Epoch 228/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2887 - f1: 0.6672 - val_loss: 0.3895 - val_f1: 0.1406\n",
      "Epoch 229/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2876 - f1: 0.6671 - val_loss: 0.3884 - val_f1: 0.1405\n",
      "Epoch 230/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2863 - f1: 0.6744 - val_loss: 0.3879 - val_f1: 0.1428\n",
      "Epoch 231/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2866 - f1: 0.6681 - val_loss: 0.3887 - val_f1: 0.1412\n",
      "Epoch 232/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2866 - f1: 0.6701 - val_loss: 0.3900 - val_f1: 0.1405\n",
      "Epoch 233/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2867 - f1: 0.6705 - val_loss: 0.3896 - val_f1: 0.1411\n",
      "Epoch 234/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2865 - f1: 0.6735 - val_loss: 0.3893 - val_f1: 0.1413\n",
      "Epoch 235/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2828 - f1: 0.6766 - val_loss: 0.3902 - val_f1: 0.1426\n",
      "Epoch 236/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2855 - f1: 0.6744 - val_loss: 0.3907 - val_f1: 0.1413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2856 - f1: 0.6713 - val_loss: 0.3899 - val_f1: 0.1419\n",
      "Epoch 238/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2866 - f1: 0.6739 - val_loss: 0.3896 - val_f1: 0.1418\n",
      "Epoch 239/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2831 - f1: 0.6748 - val_loss: 0.3913 - val_f1: 0.1424\n",
      "Epoch 240/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2848 - f1: 0.6770 - val_loss: 0.3893 - val_f1: 0.1426\n",
      "Epoch 241/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2818 - f1: 0.6791 - val_loss: 0.3916 - val_f1: 0.1401\n",
      "Epoch 242/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2838 - f1: 0.6781 - val_loss: 0.3908 - val_f1: 0.1417\n",
      "Epoch 243/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2804 - f1: 0.6785 - val_loss: 0.3918 - val_f1: 0.1424\n",
      "Epoch 244/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2806 - f1: 0.6784 - val_loss: 0.3922 - val_f1: 0.1428\n",
      "Epoch 245/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2805 - f1: 0.6801 - val_loss: 0.3930 - val_f1: 0.1421\n",
      "Epoch 246/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2833 - f1: 0.6732 - val_loss: 0.3928 - val_f1: 0.1413\n",
      "Epoch 247/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2790 - f1: 0.6786 - val_loss: 0.3931 - val_f1: 0.1417\n",
      "Epoch 248/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2821 - f1: 0.6793 - val_loss: 0.3921 - val_f1: 0.1412\n",
      "Epoch 249/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2792 - f1: 0.6828 - val_loss: 0.3937 - val_f1: 0.1408\n",
      "Epoch 250/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2808 - f1: 0.6838 - val_loss: 0.3927 - val_f1: 0.1414\n",
      "Epoch 251/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2808 - f1: 0.6787 - val_loss: 0.3918 - val_f1: 0.1432\n",
      "Epoch 252/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2785 - f1: 0.6819 - val_loss: 0.3935 - val_f1: 0.1425\n",
      "Epoch 253/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2802 - f1: 0.6826 - val_loss: 0.3939 - val_f1: 0.1432\n",
      "Epoch 254/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2781 - f1: 0.6818 - val_loss: 0.3934 - val_f1: 0.1423\n",
      "Epoch 255/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2770 - f1: 0.6881 - val_loss: 0.3939 - val_f1: 0.1425\n",
      "Epoch 256/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2794 - f1: 0.6810 - val_loss: 0.3948 - val_f1: 0.1414\n",
      "Epoch 257/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2781 - f1: 0.6806 - val_loss: 0.3946 - val_f1: 0.1425\n",
      "Epoch 258/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2784 - f1: 0.6826 - val_loss: 0.3933 - val_f1: 0.1412\n",
      "Epoch 259/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2757 - f1: 0.6887 - val_loss: 0.3954 - val_f1: 0.1410\n",
      "Epoch 260/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2770 - f1: 0.6861 - val_loss: 0.3948 - val_f1: 0.1418\n",
      "Epoch 261/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2781 - f1: 0.6804 - val_loss: 0.3953 - val_f1: 0.1414\n",
      "Epoch 262/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2755 - f1: 0.6868 - val_loss: 0.3953 - val_f1: 0.1411\n",
      "Epoch 263/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2755 - f1: 0.6881 - val_loss: 0.3952 - val_f1: 0.1429\n",
      "Epoch 264/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2748 - f1: 0.6926 - val_loss: 0.3952 - val_f1: 0.1430\n",
      "Epoch 265/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2732 - f1: 0.6922 - val_loss: 0.3958 - val_f1: 0.1420\n",
      "Epoch 266/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2754 - f1: 0.6901 - val_loss: 0.3963 - val_f1: 0.1420\n",
      "Epoch 267/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2732 - f1: 0.6893 - val_loss: 0.3958 - val_f1: 0.1418\n",
      "Epoch 268/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2748 - f1: 0.6887 - val_loss: 0.3965 - val_f1: 0.1414\n",
      "Epoch 269/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2760 - f1: 0.6865 - val_loss: 0.3953 - val_f1: 0.1416\n",
      "Epoch 270/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2709 - f1: 0.6952 - val_loss: 0.3979 - val_f1: 0.1413\n",
      "Epoch 271/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2736 - f1: 0.6914 - val_loss: 0.3969 - val_f1: 0.1422\n",
      "Epoch 272/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2752 - f1: 0.6860 - val_loss: 0.3963 - val_f1: 0.1423\n",
      "Epoch 273/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2714 - f1: 0.6952 - val_loss: 0.3982 - val_f1: 0.1414\n",
      "Epoch 274/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2707 - f1: 0.6913 - val_loss: 0.3974 - val_f1: 0.1413\n",
      "Epoch 275/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2713 - f1: 0.6965 - val_loss: 0.3975 - val_f1: 0.1407\n",
      "Epoch 276/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2701 - f1: 0.6920 - val_loss: 0.3991 - val_f1: 0.1422\n",
      "Epoch 277/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2715 - f1: 0.6895 - val_loss: 0.3981 - val_f1: 0.1417\n",
      "Epoch 278/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2708 - f1: 0.6948 - val_loss: 0.3980 - val_f1: 0.1419\n",
      "Epoch 279/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2702 - f1: 0.6930 - val_loss: 0.3984 - val_f1: 0.1424\n",
      "Epoch 280/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2711 - f1: 0.6979 - val_loss: 0.3994 - val_f1: 0.1422\n",
      "Epoch 281/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2684 - f1: 0.7000 - val_loss: 0.3995 - val_f1: 0.1428\n",
      "Epoch 282/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2705 - f1: 0.6941 - val_loss: 0.4003 - val_f1: 0.1429\n",
      "Epoch 283/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2714 - f1: 0.6951 - val_loss: 0.3989 - val_f1: 0.1435\n",
      "Epoch 284/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2715 - f1: 0.6928 - val_loss: 0.3985 - val_f1: 0.1415\n",
      "Epoch 285/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2674 - f1: 0.6985 - val_loss: 0.3999 - val_f1: 0.1415\n",
      "Epoch 286/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2672 - f1: 0.6946 - val_loss: 0.3993 - val_f1: 0.1431\n",
      "Epoch 287/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2681 - f1: 0.6977 - val_loss: 0.3998 - val_f1: 0.1421\n",
      "Epoch 288/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2691 - f1: 0.6964 - val_loss: 0.4008 - val_f1: 0.1423\n",
      "Epoch 289/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2692 - f1: 0.6944 - val_loss: 0.4007 - val_f1: 0.1421\n",
      "Epoch 290/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2663 - f1: 0.7039 - val_loss: 0.4006 - val_f1: 0.1412\n",
      "Epoch 291/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2663 - f1: 0.7031 - val_loss: 0.4011 - val_f1: 0.1421\n",
      "Epoch 292/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2692 - f1: 0.6972 - val_loss: 0.4011 - val_f1: 0.1431\n",
      "Epoch 293/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2665 - f1: 0.6993 - val_loss: 0.4008 - val_f1: 0.1431\n",
      "Epoch 294/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2649 - f1: 0.7030 - val_loss: 0.4013 - val_f1: 0.1422\n",
      "Epoch 295/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2673 - f1: 0.7013 - val_loss: 0.4009 - val_f1: 0.1420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2663 - f1: 0.7024 - val_loss: 0.4026 - val_f1: 0.1422\n",
      "Epoch 297/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2681 - f1: 0.6963 - val_loss: 0.4012 - val_f1: 0.1422\n",
      "Epoch 298/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2662 - f1: 0.7012 - val_loss: 0.4026 - val_f1: 0.1425\n",
      "Epoch 299/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2628 - f1: 0.7070 - val_loss: 0.4036 - val_f1: 0.1410\n",
      "Epoch 300/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2672 - f1: 0.6973 - val_loss: 0.4018 - val_f1: 0.1416\n",
      "Epoch 301/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2657 - f1: 0.7021 - val_loss: 0.4017 - val_f1: 0.1416\n",
      "Epoch 302/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2613 - f1: 0.7078 - val_loss: 0.4040 - val_f1: 0.1417\n",
      "Epoch 303/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2623 - f1: 0.7078 - val_loss: 0.4027 - val_f1: 0.1418\n",
      "Epoch 304/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2655 - f1: 0.7032 - val_loss: 0.4027 - val_f1: 0.1405\n",
      "Epoch 305/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2643 - f1: 0.7037 - val_loss: 0.4024 - val_f1: 0.1420\n",
      "Epoch 306/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2633 - f1: 0.7032 - val_loss: 0.4040 - val_f1: 0.1421\n",
      "Epoch 307/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2647 - f1: 0.7038 - val_loss: 0.4037 - val_f1: 0.1424\n",
      "Epoch 308/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2650 - f1: 0.7015 - val_loss: 0.4038 - val_f1: 0.1418\n",
      "Epoch 309/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2635 - f1: 0.7001 - val_loss: 0.4033 - val_f1: 0.1431\n",
      "Epoch 310/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2626 - f1: 0.7065 - val_loss: 0.4036 - val_f1: 0.1423\n",
      "Epoch 311/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2637 - f1: 0.7056 - val_loss: 0.4039 - val_f1: 0.1422\n",
      "Epoch 312/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2631 - f1: 0.7076 - val_loss: 0.4038 - val_f1: 0.1425\n",
      "Epoch 313/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2636 - f1: 0.7060 - val_loss: 0.4049 - val_f1: 0.1412\n",
      "Epoch 314/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2626 - f1: 0.7110 - val_loss: 0.4045 - val_f1: 0.1419\n",
      "Epoch 315/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2606 - f1: 0.7101 - val_loss: 0.4049 - val_f1: 0.1416\n",
      "Epoch 316/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2607 - f1: 0.7100 - val_loss: 0.4061 - val_f1: 0.1426\n",
      "Epoch 317/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2611 - f1: 0.7125 - val_loss: 0.4052 - val_f1: 0.1432\n",
      "Epoch 318/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2622 - f1: 0.7053 - val_loss: 0.4064 - val_f1: 0.1419\n",
      "Epoch 319/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2620 - f1: 0.7064 - val_loss: 0.4059 - val_f1: 0.1416\n",
      "Epoch 320/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2601 - f1: 0.7088 - val_loss: 0.4062 - val_f1: 0.1420\n",
      "Epoch 321/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2578 - f1: 0.7118 - val_loss: 0.4072 - val_f1: 0.1416\n",
      "Epoch 322/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2601 - f1: 0.7053 - val_loss: 0.4062 - val_f1: 0.1429\n",
      "Epoch 323/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2594 - f1: 0.7154 - val_loss: 0.4065 - val_f1: 0.1423\n",
      "Epoch 324/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2581 - f1: 0.7144 - val_loss: 0.4071 - val_f1: 0.1414\n",
      "Epoch 325/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2594 - f1: 0.7101 - val_loss: 0.4077 - val_f1: 0.1428\n",
      "Epoch 326/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2580 - f1: 0.7118 - val_loss: 0.4078 - val_f1: 0.1429\n",
      "Epoch 327/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2583 - f1: 0.7118 - val_loss: 0.4079 - val_f1: 0.1423\n",
      "Epoch 328/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2575 - f1: 0.7129 - val_loss: 0.4071 - val_f1: 0.1411\n",
      "Epoch 329/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2588 - f1: 0.7072 - val_loss: 0.4068 - val_f1: 0.1416\n",
      "Epoch 330/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2579 - f1: 0.7111 - val_loss: 0.4078 - val_f1: 0.1421\n",
      "Epoch 331/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2562 - f1: 0.7124 - val_loss: 0.4084 - val_f1: 0.1427\n",
      "Epoch 332/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2616 - f1: 0.7068 - val_loss: 0.4079 - val_f1: 0.1413\n",
      "Epoch 333/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2571 - f1: 0.7131 - val_loss: 0.4083 - val_f1: 0.1422\n",
      "Epoch 334/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2578 - f1: 0.7105 - val_loss: 0.4085 - val_f1: 0.1407\n",
      "Epoch 335/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2574 - f1: 0.7121 - val_loss: 0.4105 - val_f1: 0.1414\n",
      "Epoch 336/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2565 - f1: 0.7123 - val_loss: 0.4096 - val_f1: 0.1420\n",
      "Epoch 337/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2555 - f1: 0.7131 - val_loss: 0.4093 - val_f1: 0.1426\n",
      "Epoch 338/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2571 - f1: 0.7148 - val_loss: 0.4097 - val_f1: 0.1428\n",
      "Epoch 339/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2561 - f1: 0.7144 - val_loss: 0.4102 - val_f1: 0.1406\n",
      "Epoch 340/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2568 - f1: 0.7123 - val_loss: 0.4114 - val_f1: 0.1403\n",
      "Epoch 341/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2572 - f1: 0.7110 - val_loss: 0.4100 - val_f1: 0.1398\n",
      "Epoch 342/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2551 - f1: 0.7133 - val_loss: 0.4100 - val_f1: 0.1410\n",
      "Epoch 343/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2552 - f1: 0.7169 - val_loss: 0.4102 - val_f1: 0.1400\n",
      "Epoch 344/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2568 - f1: 0.7089 - val_loss: 0.4093 - val_f1: 0.1412\n",
      "Epoch 345/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2562 - f1: 0.7141 - val_loss: 0.4101 - val_f1: 0.1418\n",
      "Epoch 346/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2539 - f1: 0.7165 - val_loss: 0.4110 - val_f1: 0.1415\n",
      "Epoch 347/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2567 - f1: 0.7130 - val_loss: 0.4094 - val_f1: 0.1425\n",
      "Epoch 348/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2538 - f1: 0.7152 - val_loss: 0.4119 - val_f1: 0.1420\n",
      "Epoch 349/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2551 - f1: 0.7099 - val_loss: 0.4111 - val_f1: 0.1417\n",
      "Epoch 350/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2528 - f1: 0.7179 - val_loss: 0.4115 - val_f1: 0.1419\n",
      "Epoch 351/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2533 - f1: 0.7182 - val_loss: 0.4122 - val_f1: 0.1416\n",
      "Epoch 352/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2544 - f1: 0.7157 - val_loss: 0.4113 - val_f1: 0.1422\n",
      "Epoch 353/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2532 - f1: 0.7175 - val_loss: 0.4126 - val_f1: 0.1414\n",
      "Epoch 354/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2523 - f1: 0.7208 - val_loss: 0.4131 - val_f1: 0.1412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2505 - f1: 0.7247 - val_loss: 0.4124 - val_f1: 0.1425\n",
      "Epoch 356/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2535 - f1: 0.7153 - val_loss: 0.4127 - val_f1: 0.1421\n",
      "Epoch 357/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2529 - f1: 0.7207 - val_loss: 0.4138 - val_f1: 0.1424\n",
      "Epoch 358/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2520 - f1: 0.7196 - val_loss: 0.4132 - val_f1: 0.1418\n",
      "Epoch 359/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2527 - f1: 0.7206 - val_loss: 0.4123 - val_f1: 0.1421\n",
      "Epoch 360/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2506 - f1: 0.7228 - val_loss: 0.4124 - val_f1: 0.1425\n",
      "Epoch 361/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2536 - f1: 0.7186 - val_loss: 0.4131 - val_f1: 0.1411\n",
      "Epoch 362/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2539 - f1: 0.7147 - val_loss: 0.4121 - val_f1: 0.1418\n",
      "Epoch 363/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2498 - f1: 0.7230 - val_loss: 0.4154 - val_f1: 0.1408\n",
      "Epoch 364/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2520 - f1: 0.7222 - val_loss: 0.4144 - val_f1: 0.1427\n",
      "Epoch 365/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2498 - f1: 0.7218 - val_loss: 0.4153 - val_f1: 0.1409\n",
      "Epoch 366/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2526 - f1: 0.7188 - val_loss: 0.4136 - val_f1: 0.1415\n",
      "Epoch 367/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2509 - f1: 0.7189 - val_loss: 0.4137 - val_f1: 0.1423\n",
      "Epoch 368/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2482 - f1: 0.7239 - val_loss: 0.4137 - val_f1: 0.1407\n",
      "Epoch 369/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2504 - f1: 0.7217 - val_loss: 0.4158 - val_f1: 0.1412\n",
      "Epoch 370/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2511 - f1: 0.7213 - val_loss: 0.4148 - val_f1: 0.1428\n",
      "Epoch 371/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2521 - f1: 0.7231 - val_loss: 0.4132 - val_f1: 0.1414\n",
      "Epoch 372/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2469 - f1: 0.7278 - val_loss: 0.4169 - val_f1: 0.1405\n",
      "Epoch 373/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2491 - f1: 0.7190 - val_loss: 0.4155 - val_f1: 0.1425\n",
      "Epoch 374/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2483 - f1: 0.7243 - val_loss: 0.4164 - val_f1: 0.1405\n",
      "Epoch 375/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2478 - f1: 0.7307 - val_loss: 0.4166 - val_f1: 0.1436\n",
      "Epoch 376/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2493 - f1: 0.7220 - val_loss: 0.4164 - val_f1: 0.1407\n",
      "Epoch 377/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2471 - f1: 0.7264 - val_loss: 0.4179 - val_f1: 0.1413\n",
      "Epoch 378/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2479 - f1: 0.7231 - val_loss: 0.4184 - val_f1: 0.1415\n",
      "Epoch 379/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2490 - f1: 0.7277 - val_loss: 0.4174 - val_f1: 0.1418\n",
      "Epoch 380/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2494 - f1: 0.7230 - val_loss: 0.4166 - val_f1: 0.1406\n",
      "Epoch 381/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2483 - f1: 0.7262 - val_loss: 0.4160 - val_f1: 0.1421\n",
      "Epoch 382/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2472 - f1: 0.7287 - val_loss: 0.4188 - val_f1: 0.1418\n",
      "Epoch 383/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2470 - f1: 0.7237 - val_loss: 0.4172 - val_f1: 0.1413\n",
      "Epoch 384/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2451 - f1: 0.7277 - val_loss: 0.4178 - val_f1: 0.1420\n",
      "Epoch 385/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2480 - f1: 0.7291 - val_loss: 0.4188 - val_f1: 0.1408\n",
      "Epoch 386/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2466 - f1: 0.7273 - val_loss: 0.4190 - val_f1: 0.1406\n",
      "Epoch 387/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2444 - f1: 0.7289 - val_loss: 0.4182 - val_f1: 0.1409\n",
      "Epoch 388/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2477 - f1: 0.7247 - val_loss: 0.4172 - val_f1: 0.1421\n",
      "Epoch 389/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2460 - f1: 0.7221 - val_loss: 0.4188 - val_f1: 0.1412\n",
      "Epoch 390/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2474 - f1: 0.7269 - val_loss: 0.4190 - val_f1: 0.1424\n",
      "Epoch 391/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2473 - f1: 0.7264 - val_loss: 0.4188 - val_f1: 0.1410\n",
      "Epoch 392/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2463 - f1: 0.7277 - val_loss: 0.4181 - val_f1: 0.1423\n",
      "Epoch 393/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2448 - f1: 0.7307 - val_loss: 0.4200 - val_f1: 0.1414\n",
      "Epoch 394/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2446 - f1: 0.7282 - val_loss: 0.4210 - val_f1: 0.1410\n",
      "Epoch 395/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2448 - f1: 0.7271 - val_loss: 0.4211 - val_f1: 0.1409\n",
      "Epoch 396/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2480 - f1: 0.7258 - val_loss: 0.4185 - val_f1: 0.1426\n",
      "Epoch 397/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2468 - f1: 0.7266 - val_loss: 0.4185 - val_f1: 0.1420\n",
      "Epoch 398/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2423 - f1: 0.7291 - val_loss: 0.4207 - val_f1: 0.1414\n",
      "Epoch 399/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2438 - f1: 0.7344 - val_loss: 0.4209 - val_f1: 0.1415\n",
      "Epoch 400/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2452 - f1: 0.7285 - val_loss: 0.4212 - val_f1: 0.1424\n",
      "Epoch 401/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2445 - f1: 0.7333 - val_loss: 0.4202 - val_f1: 0.1423\n",
      "Epoch 402/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2431 - f1: 0.7303 - val_loss: 0.4205 - val_f1: 0.1416\n",
      "Epoch 403/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2426 - f1: 0.7328 - val_loss: 0.4213 - val_f1: 0.1413\n",
      "Epoch 404/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2450 - f1: 0.7292 - val_loss: 0.4214 - val_f1: 0.1431\n",
      "Epoch 405/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2428 - f1: 0.7323 - val_loss: 0.4214 - val_f1: 0.1414\n",
      "Epoch 406/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2426 - f1: 0.7339 - val_loss: 0.4214 - val_f1: 0.1419\n",
      "Epoch 407/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2428 - f1: 0.7289 - val_loss: 0.4197 - val_f1: 0.1418\n",
      "Epoch 408/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2433 - f1: 0.7307 - val_loss: 0.4218 - val_f1: 0.1417\n",
      "Epoch 409/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2416 - f1: 0.7349 - val_loss: 0.4228 - val_f1: 0.1424\n",
      "Epoch 410/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2417 - f1: 0.7293 - val_loss: 0.4230 - val_f1: 0.1423\n",
      "Epoch 411/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2398 - f1: 0.7391 - val_loss: 0.4231 - val_f1: 0.1413\n",
      "Epoch 412/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2421 - f1: 0.7339 - val_loss: 0.4225 - val_f1: 0.1424\n",
      "Epoch 413/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2455 - f1: 0.7294 - val_loss: 0.4200 - val_f1: 0.1427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2436 - f1: 0.7297 - val_loss: 0.4217 - val_f1: 0.1426\n",
      "Epoch 415/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2437 - f1: 0.7293 - val_loss: 0.4222 - val_f1: 0.1411\n",
      "Epoch 416/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2424 - f1: 0.7320 - val_loss: 0.4235 - val_f1: 0.1420\n",
      "Epoch 417/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2413 - f1: 0.7333 - val_loss: 0.4234 - val_f1: 0.1408\n",
      "Epoch 418/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2423 - f1: 0.7378 - val_loss: 0.4238 - val_f1: 0.1425\n",
      "Epoch 419/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2405 - f1: 0.7341 - val_loss: 0.4240 - val_f1: 0.1412\n",
      "Epoch 420/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2421 - f1: 0.7314 - val_loss: 0.4231 - val_f1: 0.1416\n",
      "Epoch 421/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2398 - f1: 0.7364 - val_loss: 0.4245 - val_f1: 0.1418\n",
      "Epoch 422/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2419 - f1: 0.7306 - val_loss: 0.4237 - val_f1: 0.1420\n",
      "Epoch 423/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2404 - f1: 0.7334 - val_loss: 0.4262 - val_f1: 0.1414\n",
      "Epoch 424/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2417 - f1: 0.7380 - val_loss: 0.4238 - val_f1: 0.1416\n",
      "Epoch 425/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2397 - f1: 0.7334 - val_loss: 0.4254 - val_f1: 0.1426\n",
      "Epoch 426/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2397 - f1: 0.7368 - val_loss: 0.4261 - val_f1: 0.1409\n",
      "Epoch 427/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2391 - f1: 0.7402 - val_loss: 0.4258 - val_f1: 0.1413\n",
      "Epoch 428/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2396 - f1: 0.7389 - val_loss: 0.4252 - val_f1: 0.1410\n",
      "Epoch 429/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2382 - f1: 0.7414 - val_loss: 0.4268 - val_f1: 0.1414\n",
      "Epoch 430/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2404 - f1: 0.7335 - val_loss: 0.4249 - val_f1: 0.1423\n",
      "Epoch 431/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2357 - f1: 0.7440 - val_loss: 0.4272 - val_f1: 0.1417\n",
      "Epoch 432/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2371 - f1: 0.7383 - val_loss: 0.4281 - val_f1: 0.1405\n",
      "Epoch 433/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2388 - f1: 0.7355 - val_loss: 0.4294 - val_f1: 0.1418\n",
      "Epoch 434/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2383 - f1: 0.7364 - val_loss: 0.4280 - val_f1: 0.1423\n",
      "Epoch 435/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2405 - f1: 0.7351 - val_loss: 0.4273 - val_f1: 0.1416\n",
      "Epoch 436/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2410 - f1: 0.7356 - val_loss: 0.4259 - val_f1: 0.1415\n",
      "Epoch 437/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2408 - f1: 0.7376 - val_loss: 0.4272 - val_f1: 0.1401\n",
      "Epoch 438/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2403 - f1: 0.7273 - val_loss: 0.4262 - val_f1: 0.1420\n",
      "Epoch 439/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2391 - f1: 0.7377 - val_loss: 0.4269 - val_f1: 0.1408\n",
      "Epoch 440/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2408 - f1: 0.7337 - val_loss: 0.4256 - val_f1: 0.1418\n",
      "Epoch 441/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2406 - f1: 0.7389 - val_loss: 0.4248 - val_f1: 0.1416\n",
      "Epoch 442/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2338 - f1: 0.7453 - val_loss: 0.4289 - val_f1: 0.1415\n",
      "Epoch 443/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2385 - f1: 0.7389 - val_loss: 0.4280 - val_f1: 0.1420\n",
      "Epoch 444/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2373 - f1: 0.7367 - val_loss: 0.4284 - val_f1: 0.1421\n",
      "Epoch 445/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2383 - f1: 0.7360 - val_loss: 0.4271 - val_f1: 0.1416\n",
      "Epoch 446/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2351 - f1: 0.7420 - val_loss: 0.4284 - val_f1: 0.1420\n",
      "Epoch 447/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2361 - f1: 0.7424 - val_loss: 0.4288 - val_f1: 0.1425\n",
      "Epoch 448/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2375 - f1: 0.7367 - val_loss: 0.4285 - val_f1: 0.1410\n",
      "Epoch 449/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2361 - f1: 0.7381 - val_loss: 0.4284 - val_f1: 0.1420\n",
      "Epoch 450/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2367 - f1: 0.7373 - val_loss: 0.4273 - val_f1: 0.1413\n",
      "Epoch 451/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2366 - f1: 0.7407 - val_loss: 0.4294 - val_f1: 0.1421\n",
      "Epoch 452/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2367 - f1: 0.7397 - val_loss: 0.4298 - val_f1: 0.1408\n",
      "Epoch 453/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2365 - f1: 0.7383 - val_loss: 0.4295 - val_f1: 0.1414\n",
      "Epoch 454/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2341 - f1: 0.7426 - val_loss: 0.4302 - val_f1: 0.1421\n",
      "Epoch 455/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2362 - f1: 0.7404 - val_loss: 0.4292 - val_f1: 0.1424\n",
      "Epoch 456/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2355 - f1: 0.7398 - val_loss: 0.4289 - val_f1: 0.1426\n",
      "Epoch 457/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2359 - f1: 0.7404 - val_loss: 0.4315 - val_f1: 0.1410\n",
      "Epoch 458/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2371 - f1: 0.7342 - val_loss: 0.4321 - val_f1: 0.1409\n",
      "Epoch 459/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2304 - f1: 0.7495 - val_loss: 0.4318 - val_f1: 0.1419\n",
      "Epoch 460/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2355 - f1: 0.7420 - val_loss: 0.4316 - val_f1: 0.1424\n",
      "Epoch 461/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2350 - f1: 0.7438 - val_loss: 0.4316 - val_f1: 0.1419\n",
      "Epoch 462/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2338 - f1: 0.7461 - val_loss: 0.4314 - val_f1: 0.1411\n",
      "Epoch 463/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2364 - f1: 0.7409 - val_loss: 0.4310 - val_f1: 0.1418\n",
      "Epoch 464/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2351 - f1: 0.7456 - val_loss: 0.4313 - val_f1: 0.1409\n",
      "Epoch 465/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2353 - f1: 0.7424 - val_loss: 0.4314 - val_f1: 0.1416\n",
      "Epoch 466/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2354 - f1: 0.7407 - val_loss: 0.4312 - val_f1: 0.1416\n",
      "Epoch 467/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2349 - f1: 0.7430 - val_loss: 0.4308 - val_f1: 0.1413\n",
      "Epoch 468/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2334 - f1: 0.7417 - val_loss: 0.4319 - val_f1: 0.1422\n",
      "Epoch 469/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2340 - f1: 0.7409 - val_loss: 0.4304 - val_f1: 0.1439\n",
      "Epoch 470/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2342 - f1: 0.7425 - val_loss: 0.4305 - val_f1: 0.1431\n",
      "Epoch 471/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2366 - f1: 0.7408 - val_loss: 0.4290 - val_f1: 0.1430\n",
      "Epoch 472/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2318 - f1: 0.7486 - val_loss: 0.4320 - val_f1: 0.1431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2338 - f1: 0.7451 - val_loss: 0.4321 - val_f1: 0.1418\n",
      "Epoch 474/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2331 - f1: 0.7431 - val_loss: 0.4321 - val_f1: 0.1414\n",
      "Epoch 475/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2332 - f1: 0.7459 - val_loss: 0.4316 - val_f1: 0.1436\n",
      "Epoch 476/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2329 - f1: 0.7474 - val_loss: 0.4322 - val_f1: 0.1423\n",
      "Epoch 477/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2349 - f1: 0.7423 - val_loss: 0.4323 - val_f1: 0.1429\n",
      "Epoch 478/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2332 - f1: 0.7422 - val_loss: 0.4322 - val_f1: 0.1427\n",
      "Epoch 479/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2322 - f1: 0.7446 - val_loss: 0.4322 - val_f1: 0.1428\n",
      "Epoch 480/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2312 - f1: 0.7493 - val_loss: 0.4336 - val_f1: 0.1419\n",
      "Epoch 481/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2333 - f1: 0.7447 - val_loss: 0.4331 - val_f1: 0.1425\n",
      "Epoch 482/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2316 - f1: 0.7476 - val_loss: 0.4342 - val_f1: 0.1415\n",
      "Epoch 483/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2323 - f1: 0.7455 - val_loss: 0.4339 - val_f1: 0.1437\n",
      "Epoch 484/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2342 - f1: 0.7450 - val_loss: 0.4341 - val_f1: 0.1425\n",
      "Epoch 485/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2310 - f1: 0.7464 - val_loss: 0.4326 - val_f1: 0.1421\n",
      "Epoch 486/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2341 - f1: 0.7460 - val_loss: 0.4333 - val_f1: 0.1427\n",
      "Epoch 487/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2325 - f1: 0.7451 - val_loss: 0.4340 - val_f1: 0.1412\n",
      "Epoch 488/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2335 - f1: 0.7440 - val_loss: 0.4328 - val_f1: 0.1423\n",
      "Epoch 489/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2300 - f1: 0.7477 - val_loss: 0.4342 - val_f1: 0.1413\n",
      "Epoch 490/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2306 - f1: 0.7503 - val_loss: 0.4362 - val_f1: 0.1410\n",
      "Epoch 491/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2321 - f1: 0.7461 - val_loss: 0.4345 - val_f1: 0.1422\n",
      "Epoch 492/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2299 - f1: 0.7486 - val_loss: 0.4362 - val_f1: 0.1417\n",
      "Epoch 493/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2324 - f1: 0.7452 - val_loss: 0.4349 - val_f1: 0.1429\n",
      "Epoch 494/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2307 - f1: 0.7478 - val_loss: 0.4352 - val_f1: 0.1415\n",
      "Epoch 495/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2304 - f1: 0.7454 - val_loss: 0.4351 - val_f1: 0.1418\n",
      "Epoch 496/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2307 - f1: 0.7479 - val_loss: 0.4363 - val_f1: 0.1428\n",
      "Epoch 497/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2305 - f1: 0.7458 - val_loss: 0.4365 - val_f1: 0.1418\n",
      "Epoch 498/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2333 - f1: 0.7429 - val_loss: 0.4355 - val_f1: 0.1417\n",
      "Epoch 499/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2294 - f1: 0.7473 - val_loss: 0.4357 - val_f1: 0.1421\n",
      "Epoch 500/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2309 - f1: 0.7489 - val_loss: 0.4349 - val_f1: 0.1415\n",
      "Epoch 501/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2309 - f1: 0.7506 - val_loss: 0.4371 - val_f1: 0.1409\n",
      "Epoch 502/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2332 - f1: 0.7420 - val_loss: 0.4356 - val_f1: 0.1412\n",
      "Epoch 503/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2295 - f1: 0.7437 - val_loss: 0.4353 - val_f1: 0.1420\n",
      "Epoch 504/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2303 - f1: 0.7543 - val_loss: 0.4358 - val_f1: 0.1412\n",
      "Epoch 505/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2284 - f1: 0.7484 - val_loss: 0.4343 - val_f1: 0.1424\n",
      "Epoch 506/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2272 - f1: 0.7546 - val_loss: 0.4373 - val_f1: 0.1411\n",
      "Epoch 507/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2335 - f1: 0.7424 - val_loss: 0.4365 - val_f1: 0.1415\n",
      "Epoch 508/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2288 - f1: 0.7468 - val_loss: 0.4365 - val_f1: 0.1421\n",
      "Epoch 509/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2273 - f1: 0.7500 - val_loss: 0.4385 - val_f1: 0.1409\n",
      "Epoch 510/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2299 - f1: 0.7466 - val_loss: 0.4378 - val_f1: 0.1417\n",
      "Epoch 511/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2252 - f1: 0.7560 - val_loss: 0.4387 - val_f1: 0.1416\n",
      "Epoch 512/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2285 - f1: 0.7432 - val_loss: 0.4383 - val_f1: 0.1412\n",
      "Epoch 513/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2273 - f1: 0.7500 - val_loss: 0.4383 - val_f1: 0.1422\n",
      "Epoch 514/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2308 - f1: 0.7487 - val_loss: 0.4365 - val_f1: 0.1419\n",
      "Epoch 515/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2268 - f1: 0.7557 - val_loss: 0.4389 - val_f1: 0.1412\n",
      "Epoch 516/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2281 - f1: 0.7508 - val_loss: 0.4387 - val_f1: 0.1427\n",
      "Epoch 517/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2285 - f1: 0.7480 - val_loss: 0.4367 - val_f1: 0.1432\n",
      "Epoch 518/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2292 - f1: 0.7516 - val_loss: 0.4374 - val_f1: 0.1416\n",
      "Epoch 519/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2275 - f1: 0.7512 - val_loss: 0.4395 - val_f1: 0.1420\n",
      "Epoch 520/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2294 - f1: 0.7493 - val_loss: 0.4384 - val_f1: 0.1430\n",
      "Epoch 521/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2279 - f1: 0.7514 - val_loss: 0.4390 - val_f1: 0.1445\n",
      "Epoch 522/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2298 - f1: 0.7484 - val_loss: 0.4374 - val_f1: 0.1436\n",
      "Epoch 523/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2276 - f1: 0.7489 - val_loss: 0.4388 - val_f1: 0.1416\n",
      "Epoch 524/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2292 - f1: 0.7480 - val_loss: 0.4379 - val_f1: 0.1416\n",
      "Epoch 525/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2269 - f1: 0.7522 - val_loss: 0.4386 - val_f1: 0.1426\n",
      "Epoch 526/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2275 - f1: 0.7489 - val_loss: 0.4387 - val_f1: 0.1423\n",
      "Epoch 527/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2255 - f1: 0.7542 - val_loss: 0.4389 - val_f1: 0.1420\n",
      "Epoch 528/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2242 - f1: 0.7506 - val_loss: 0.4402 - val_f1: 0.1418\n",
      "Epoch 529/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2245 - f1: 0.7542 - val_loss: 0.4398 - val_f1: 0.1430\n",
      "Epoch 530/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2236 - f1: 0.7575 - val_loss: 0.4430 - val_f1: 0.1419\n",
      "Epoch 531/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2251 - f1: 0.7522 - val_loss: 0.4418 - val_f1: 0.1416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2257 - f1: 0.7523 - val_loss: 0.4407 - val_f1: 0.1413\n",
      "Epoch 533/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2272 - f1: 0.7574 - val_loss: 0.4407 - val_f1: 0.1414\n",
      "Epoch 534/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2263 - f1: 0.7522 - val_loss: 0.4405 - val_f1: 0.1414\n",
      "Epoch 535/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2282 - f1: 0.7515 - val_loss: 0.4393 - val_f1: 0.1409\n",
      "Epoch 536/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2278 - f1: 0.7504 - val_loss: 0.4398 - val_f1: 0.1411\n",
      "Epoch 537/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2239 - f1: 0.7548 - val_loss: 0.4415 - val_f1: 0.1416\n",
      "Epoch 538/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2256 - f1: 0.7564 - val_loss: 0.4421 - val_f1: 0.1419\n",
      "Epoch 539/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2270 - f1: 0.7498 - val_loss: 0.4397 - val_f1: 0.1425\n",
      "Epoch 540/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2275 - f1: 0.7527 - val_loss: 0.4388 - val_f1: 0.1422\n",
      "Epoch 541/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2261 - f1: 0.7507 - val_loss: 0.4411 - val_f1: 0.1419\n",
      "Epoch 542/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2240 - f1: 0.7561 - val_loss: 0.4412 - val_f1: 0.1421\n",
      "Epoch 543/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2255 - f1: 0.7526 - val_loss: 0.4410 - val_f1: 0.1429\n",
      "Epoch 544/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2246 - f1: 0.7563 - val_loss: 0.4411 - val_f1: 0.1424\n",
      "Epoch 545/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2238 - f1: 0.7546 - val_loss: 0.4409 - val_f1: 0.1424\n",
      "Epoch 546/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2243 - f1: 0.7552 - val_loss: 0.4428 - val_f1: 0.1414\n",
      "Epoch 547/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2250 - f1: 0.7558 - val_loss: 0.4406 - val_f1: 0.1424\n",
      "Epoch 548/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2268 - f1: 0.7516 - val_loss: 0.4405 - val_f1: 0.1423\n",
      "Epoch 549/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2252 - f1: 0.7544 - val_loss: 0.4418 - val_f1: 0.1411\n",
      "Epoch 550/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2263 - f1: 0.7542 - val_loss: 0.4408 - val_f1: 0.1424\n",
      "Epoch 551/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2257 - f1: 0.7553 - val_loss: 0.4432 - val_f1: 0.1414\n",
      "Epoch 552/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2243 - f1: 0.7558 - val_loss: 0.4417 - val_f1: 0.1420\n",
      "Epoch 553/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2216 - f1: 0.7578 - val_loss: 0.4445 - val_f1: 0.1401\n",
      "Epoch 554/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2247 - f1: 0.7567 - val_loss: 0.4423 - val_f1: 0.1419\n",
      "Epoch 555/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2232 - f1: 0.7595 - val_loss: 0.4432 - val_f1: 0.1423\n",
      "Epoch 556/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2216 - f1: 0.7610 - val_loss: 0.4444 - val_f1: 0.1408\n",
      "Epoch 557/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2250 - f1: 0.7585 - val_loss: 0.4425 - val_f1: 0.1421\n",
      "Epoch 558/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2252 - f1: 0.7554 - val_loss: 0.4426 - val_f1: 0.1418\n",
      "Epoch 559/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2243 - f1: 0.7552 - val_loss: 0.4432 - val_f1: 0.1414\n",
      "Epoch 560/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2231 - f1: 0.7552 - val_loss: 0.4422 - val_f1: 0.1429\n",
      "Epoch 561/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2226 - f1: 0.7588 - val_loss: 0.4426 - val_f1: 0.1421\n",
      "Epoch 562/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2261 - f1: 0.7529 - val_loss: 0.4418 - val_f1: 0.1414\n",
      "Epoch 563/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2242 - f1: 0.7516 - val_loss: 0.4422 - val_f1: 0.1424\n",
      "Epoch 564/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2237 - f1: 0.7552 - val_loss: 0.4438 - val_f1: 0.1406\n",
      "Epoch 565/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2213 - f1: 0.7630 - val_loss: 0.4447 - val_f1: 0.1413\n",
      "Epoch 566/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2215 - f1: 0.7608 - val_loss: 0.4441 - val_f1: 0.1421\n",
      "Epoch 567/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2230 - f1: 0.7532 - val_loss: 0.4459 - val_f1: 0.1415\n",
      "Epoch 568/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2229 - f1: 0.7604 - val_loss: 0.4456 - val_f1: 0.1414\n",
      "Epoch 569/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2218 - f1: 0.7596 - val_loss: 0.4466 - val_f1: 0.1415\n",
      "Epoch 570/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2238 - f1: 0.7564 - val_loss: 0.4432 - val_f1: 0.1423\n",
      "Epoch 571/2000\n",
      "64440/64440 [==============================] - 2s 33us/step - loss: 0.2228 - f1: 0.7563 - val_loss: 0.4440 - val_f1: 0.1428\n",
      "Epoch 572/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.2214 - f1: 0.7598 - val_loss: 0.4451 - val_f1: 0.1418\n",
      "Epoch 573/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2235 - f1: 0.7572 - val_loss: 0.4450 - val_f1: 0.1413\n",
      "Epoch 574/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2230 - f1: 0.7559 - val_loss: 0.4447 - val_f1: 0.1416\n",
      "Epoch 575/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2214 - f1: 0.7555 - val_loss: 0.4441 - val_f1: 0.1419\n",
      "Epoch 576/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2209 - f1: 0.7641 - val_loss: 0.4465 - val_f1: 0.1410\n",
      "Epoch 577/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2211 - f1: 0.7566 - val_loss: 0.4460 - val_f1: 0.1411\n",
      "Epoch 578/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2192 - f1: 0.7596 - val_loss: 0.4475 - val_f1: 0.1413\n",
      "Epoch 579/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2215 - f1: 0.7601 - val_loss: 0.4454 - val_f1: 0.1418\n",
      "Epoch 580/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2198 - f1: 0.7564 - val_loss: 0.4486 - val_f1: 0.1399\n",
      "Epoch 581/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2213 - f1: 0.7616 - val_loss: 0.4465 - val_f1: 0.1420\n",
      "Epoch 582/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2229 - f1: 0.7599 - val_loss: 0.4466 - val_f1: 0.1404\n",
      "Epoch 583/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2206 - f1: 0.7623 - val_loss: 0.4464 - val_f1: 0.1414\n",
      "Epoch 584/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2208 - f1: 0.7598 - val_loss: 0.4457 - val_f1: 0.1424\n",
      "Epoch 585/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2220 - f1: 0.7610 - val_loss: 0.4462 - val_f1: 0.1414\n",
      "Epoch 586/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2237 - f1: 0.7512 - val_loss: 0.4445 - val_f1: 0.1419\n",
      "Epoch 587/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2212 - f1: 0.7617 - val_loss: 0.4447 - val_f1: 0.1421\n",
      "Epoch 588/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2221 - f1: 0.7563 - val_loss: 0.4451 - val_f1: 0.1426\n",
      "Epoch 589/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2199 - f1: 0.7658 - val_loss: 0.4457 - val_f1: 0.1416\n",
      "Epoch 590/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2208 - f1: 0.7594 - val_loss: 0.4472 - val_f1: 0.1418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2212 - f1: 0.7615 - val_loss: 0.4471 - val_f1: 0.1403\n",
      "Epoch 592/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2204 - f1: 0.7607 - val_loss: 0.4457 - val_f1: 0.1416\n",
      "Epoch 593/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2229 - f1: 0.7558 - val_loss: 0.4455 - val_f1: 0.1416\n",
      "Epoch 594/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2197 - f1: 0.7633 - val_loss: 0.4463 - val_f1: 0.1419\n",
      "Epoch 595/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2190 - f1: 0.7619 - val_loss: 0.4484 - val_f1: 0.1416\n",
      "Epoch 596/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2209 - f1: 0.7623 - val_loss: 0.4472 - val_f1: 0.1420\n",
      "Epoch 597/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2200 - f1: 0.7630 - val_loss: 0.4462 - val_f1: 0.1411\n",
      "Epoch 598/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2206 - f1: 0.7597 - val_loss: 0.4461 - val_f1: 0.1420\n",
      "Epoch 599/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2188 - f1: 0.7629 - val_loss: 0.4454 - val_f1: 0.1415\n",
      "Epoch 600/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2206 - f1: 0.7571 - val_loss: 0.4457 - val_f1: 0.1421\n",
      "Epoch 601/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2196 - f1: 0.7597 - val_loss: 0.4458 - val_f1: 0.1428\n",
      "Epoch 602/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2194 - f1: 0.7599 - val_loss: 0.4481 - val_f1: 0.1422\n",
      "Epoch 603/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2200 - f1: 0.7607 - val_loss: 0.4480 - val_f1: 0.1417\n",
      "Epoch 604/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2172 - f1: 0.7659 - val_loss: 0.4489 - val_f1: 0.1415\n",
      "Epoch 605/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2197 - f1: 0.7605 - val_loss: 0.4473 - val_f1: 0.1414\n",
      "Epoch 606/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2191 - f1: 0.7644 - val_loss: 0.4467 - val_f1: 0.1418\n",
      "Epoch 607/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2190 - f1: 0.7612 - val_loss: 0.4465 - val_f1: 0.1413\n",
      "Epoch 608/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2187 - f1: 0.7616 - val_loss: 0.4486 - val_f1: 0.1420\n",
      "Epoch 609/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2143 - f1: 0.7728 - val_loss: 0.4524 - val_f1: 0.1415\n",
      "Epoch 610/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2183 - f1: 0.7625 - val_loss: 0.4508 - val_f1: 0.1416\n",
      "Epoch 611/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2170 - f1: 0.7668 - val_loss: 0.4522 - val_f1: 0.1407\n",
      "Epoch 612/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2166 - f1: 0.7614 - val_loss: 0.4491 - val_f1: 0.1415\n",
      "Epoch 613/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2179 - f1: 0.7643 - val_loss: 0.4490 - val_f1: 0.1418\n",
      "Epoch 614/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2183 - f1: 0.7608 - val_loss: 0.4514 - val_f1: 0.1414\n",
      "Epoch 615/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2202 - f1: 0.7616 - val_loss: 0.4490 - val_f1: 0.1415\n",
      "Epoch 616/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2171 - f1: 0.7617 - val_loss: 0.4505 - val_f1: 0.1418\n",
      "Epoch 617/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2182 - f1: 0.7653 - val_loss: 0.4515 - val_f1: 0.1397\n",
      "Epoch 618/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2172 - f1: 0.7610 - val_loss: 0.4500 - val_f1: 0.1409\n",
      "Epoch 619/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2167 - f1: 0.7665 - val_loss: 0.4500 - val_f1: 0.1423\n",
      "Epoch 620/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2186 - f1: 0.7633 - val_loss: 0.4481 - val_f1: 0.1420\n",
      "Epoch 621/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2165 - f1: 0.7651 - val_loss: 0.4513 - val_f1: 0.1409\n",
      "Epoch 622/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2167 - f1: 0.7677 - val_loss: 0.4522 - val_f1: 0.1411\n",
      "Epoch 623/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2198 - f1: 0.7639 - val_loss: 0.4496 - val_f1: 0.1409\n",
      "Epoch 624/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2176 - f1: 0.7640 - val_loss: 0.4506 - val_f1: 0.1412\n",
      "Epoch 625/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2172 - f1: 0.7614 - val_loss: 0.4498 - val_f1: 0.1410\n",
      "Epoch 626/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2169 - f1: 0.7645 - val_loss: 0.4507 - val_f1: 0.1413\n",
      "Epoch 627/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2172 - f1: 0.7628 - val_loss: 0.4496 - val_f1: 0.1423\n",
      "Epoch 628/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2174 - f1: 0.7643 - val_loss: 0.4509 - val_f1: 0.1418\n",
      "Epoch 629/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2166 - f1: 0.7643 - val_loss: 0.4522 - val_f1: 0.1414\n",
      "Epoch 630/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2187 - f1: 0.7610 - val_loss: 0.4495 - val_f1: 0.1411\n",
      "Epoch 631/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2181 - f1: 0.7659 - val_loss: 0.4503 - val_f1: 0.1416\n",
      "Epoch 632/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2178 - f1: 0.7642 - val_loss: 0.4507 - val_f1: 0.1420\n",
      "Epoch 633/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2142 - f1: 0.7705 - val_loss: 0.4515 - val_f1: 0.1419\n",
      "Epoch 634/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2173 - f1: 0.7617 - val_loss: 0.4519 - val_f1: 0.1419\n",
      "Epoch 635/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2130 - f1: 0.7709 - val_loss: 0.4517 - val_f1: 0.1410\n",
      "Epoch 636/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2170 - f1: 0.7650 - val_loss: 0.4515 - val_f1: 0.1415\n",
      "Epoch 637/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2169 - f1: 0.7650 - val_loss: 0.4525 - val_f1: 0.1413\n",
      "Epoch 638/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2173 - f1: 0.7666 - val_loss: 0.4513 - val_f1: 0.1410\n",
      "Epoch 639/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2138 - f1: 0.7674 - val_loss: 0.4511 - val_f1: 0.1417\n",
      "Epoch 640/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2180 - f1: 0.7633 - val_loss: 0.4507 - val_f1: 0.1427\n",
      "Epoch 641/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2151 - f1: 0.7676 - val_loss: 0.4523 - val_f1: 0.1424\n",
      "Epoch 642/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2138 - f1: 0.7697 - val_loss: 0.4518 - val_f1: 0.1409\n",
      "Epoch 643/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2132 - f1: 0.7717 - val_loss: 0.4541 - val_f1: 0.1412\n",
      "Epoch 644/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2169 - f1: 0.7685 - val_loss: 0.4526 - val_f1: 0.1407\n",
      "Epoch 645/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2161 - f1: 0.7691 - val_loss: 0.4525 - val_f1: 0.1423\n",
      "Epoch 646/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2191 - f1: 0.7597 - val_loss: 0.4501 - val_f1: 0.1428\n",
      "Epoch 647/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2140 - f1: 0.7676 - val_loss: 0.4529 - val_f1: 0.1410\n",
      "Epoch 648/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2135 - f1: 0.7680 - val_loss: 0.4530 - val_f1: 0.1403\n",
      "Epoch 649/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2167 - f1: 0.7579 - val_loss: 0.4522 - val_f1: 0.1420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 650/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2163 - f1: 0.7711 - val_loss: 0.4524 - val_f1: 0.1405\n",
      "Epoch 651/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2159 - f1: 0.7677 - val_loss: 0.4530 - val_f1: 0.1408\n",
      "Epoch 652/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2144 - f1: 0.7647 - val_loss: 0.4531 - val_f1: 0.1408\n",
      "Epoch 653/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2137 - f1: 0.7686 - val_loss: 0.4525 - val_f1: 0.1428\n",
      "Epoch 654/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2138 - f1: 0.7703 - val_loss: 0.4529 - val_f1: 0.1409\n",
      "Epoch 655/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2150 - f1: 0.7679 - val_loss: 0.4531 - val_f1: 0.1419\n",
      "Epoch 656/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2159 - f1: 0.7664 - val_loss: 0.4547 - val_f1: 0.1414\n",
      "Epoch 657/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2166 - f1: 0.7674 - val_loss: 0.4526 - val_f1: 0.1418\n",
      "Epoch 658/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2169 - f1: 0.7635 - val_loss: 0.4522 - val_f1: 0.1416\n",
      "Epoch 659/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2141 - f1: 0.7657 - val_loss: 0.4526 - val_f1: 0.1418\n",
      "Epoch 660/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2134 - f1: 0.7666 - val_loss: 0.4538 - val_f1: 0.1407\n",
      "Epoch 661/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2140 - f1: 0.7660 - val_loss: 0.4547 - val_f1: 0.1412\n",
      "Epoch 662/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2157 - f1: 0.7680 - val_loss: 0.4531 - val_f1: 0.1415\n",
      "Epoch 663/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2118 - f1: 0.7726 - val_loss: 0.4543 - val_f1: 0.1416\n",
      "Epoch 664/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2162 - f1: 0.7637 - val_loss: 0.4549 - val_f1: 0.1411\n",
      "Epoch 665/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2131 - f1: 0.7690 - val_loss: 0.4540 - val_f1: 0.1412\n",
      "Epoch 666/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2141 - f1: 0.7667 - val_loss: 0.4541 - val_f1: 0.1416\n",
      "Epoch 667/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2149 - f1: 0.7705 - val_loss: 0.4535 - val_f1: 0.1409\n",
      "Epoch 668/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2141 - f1: 0.7684 - val_loss: 0.4536 - val_f1: 0.1416\n",
      "Epoch 669/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2154 - f1: 0.7686 - val_loss: 0.4544 - val_f1: 0.1419\n",
      "Epoch 670/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2142 - f1: 0.7657 - val_loss: 0.4529 - val_f1: 0.1413\n",
      "Epoch 671/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.2138 - f1: 0.76 - 2s 37us/step - loss: 0.2131 - f1: 0.7695 - val_loss: 0.4556 - val_f1: 0.1419\n",
      "Epoch 672/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2133 - f1: 0.7682 - val_loss: 0.4546 - val_f1: 0.1415\n",
      "Epoch 673/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2137 - f1: 0.7711 - val_loss: 0.4554 - val_f1: 0.1418\n",
      "Epoch 674/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2117 - f1: 0.7723 - val_loss: 0.4560 - val_f1: 0.1412\n",
      "Epoch 675/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2139 - f1: 0.7672 - val_loss: 0.4544 - val_f1: 0.1413\n",
      "Epoch 676/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2133 - f1: 0.7702 - val_loss: 0.4543 - val_f1: 0.1406\n",
      "Epoch 677/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2125 - f1: 0.7720 - val_loss: 0.4556 - val_f1: 0.1408\n",
      "Epoch 678/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2149 - f1: 0.7684 - val_loss: 0.4539 - val_f1: 0.1414\n",
      "Epoch 679/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2141 - f1: 0.7688 - val_loss: 0.4549 - val_f1: 0.1409\n",
      "Epoch 680/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2125 - f1: 0.7718 - val_loss: 0.4547 - val_f1: 0.1417\n",
      "Epoch 681/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2124 - f1: 0.7662 - val_loss: 0.4556 - val_f1: 0.1420\n",
      "Epoch 682/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2137 - f1: 0.7673 - val_loss: 0.4558 - val_f1: 0.1411\n",
      "Epoch 683/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2130 - f1: 0.7708 - val_loss: 0.4552 - val_f1: 0.1411\n",
      "Epoch 684/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2135 - f1: 0.7702 - val_loss: 0.4552 - val_f1: 0.1417\n",
      "Epoch 685/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2147 - f1: 0.7649 - val_loss: 0.4541 - val_f1: 0.1416\n",
      "Epoch 686/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2133 - f1: 0.7697 - val_loss: 0.4549 - val_f1: 0.1407\n",
      "Epoch 687/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2152 - f1: 0.7682 - val_loss: 0.4548 - val_f1: 0.1420\n",
      "Epoch 688/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2141 - f1: 0.7705 - val_loss: 0.4541 - val_f1: 0.1417\n",
      "Epoch 689/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2131 - f1: 0.7698 - val_loss: 0.4553 - val_f1: 0.1402\n",
      "Epoch 690/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2111 - f1: 0.7730 - val_loss: 0.4563 - val_f1: 0.1408\n",
      "Epoch 691/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2139 - f1: 0.7680 - val_loss: 0.4554 - val_f1: 0.1413\n",
      "Epoch 692/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2131 - f1: 0.7737 - val_loss: 0.4557 - val_f1: 0.1401\n",
      "Epoch 693/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2136 - f1: 0.7716 - val_loss: 0.4556 - val_f1: 0.1414\n",
      "Epoch 694/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2119 - f1: 0.7716 - val_loss: 0.4563 - val_f1: 0.1407\n",
      "Epoch 695/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2132 - f1: 0.7712 - val_loss: 0.4554 - val_f1: 0.1408\n",
      "Epoch 696/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2107 - f1: 0.7754 - val_loss: 0.4556 - val_f1: 0.1417\n",
      "Epoch 697/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2121 - f1: 0.7711 - val_loss: 0.4565 - val_f1: 0.1419\n",
      "Epoch 698/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2113 - f1: 0.7724 - val_loss: 0.4559 - val_f1: 0.1425\n",
      "Epoch 699/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2103 - f1: 0.7749 - val_loss: 0.4563 - val_f1: 0.1415\n",
      "Epoch 700/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2117 - f1: 0.7697 - val_loss: 0.4586 - val_f1: 0.1407\n",
      "Epoch 701/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2105 - f1: 0.7715 - val_loss: 0.4571 - val_f1: 0.1414\n",
      "Epoch 702/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2115 - f1: 0.7708 - val_loss: 0.4559 - val_f1: 0.1419\n",
      "Epoch 703/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2102 - f1: 0.7716 - val_loss: 0.4584 - val_f1: 0.1410\n",
      "Epoch 704/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2120 - f1: 0.7728 - val_loss: 0.4577 - val_f1: 0.1416\n",
      "Epoch 705/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2105 - f1: 0.7760 - val_loss: 0.4576 - val_f1: 0.1413\n",
      "Epoch 706/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2124 - f1: 0.7704 - val_loss: 0.4584 - val_f1: 0.1407\n",
      "Epoch 707/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2105 - f1: 0.7759 - val_loss: 0.4577 - val_f1: 0.1417\n",
      "Epoch 708/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2096 - f1: 0.7759 - val_loss: 0.4569 - val_f1: 0.1413\n",
      "Epoch 709/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2082 - f1: 0.7758 - val_loss: 0.4581 - val_f1: 0.1418\n",
      "Epoch 710/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2100 - f1: 0.7731 - val_loss: 0.4591 - val_f1: 0.1399\n",
      "Epoch 711/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2105 - f1: 0.7759 - val_loss: 0.4590 - val_f1: 0.1406\n",
      "Epoch 712/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2112 - f1: 0.7744 - val_loss: 0.4584 - val_f1: 0.1407\n",
      "Epoch 713/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2075 - f1: 0.7741 - val_loss: 0.4597 - val_f1: 0.1417\n",
      "Epoch 714/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2083 - f1: 0.7731 - val_loss: 0.4613 - val_f1: 0.1412\n",
      "Epoch 715/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2126 - f1: 0.7679 - val_loss: 0.4604 - val_f1: 0.1415\n",
      "Epoch 716/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2085 - f1: 0.7743 - val_loss: 0.4587 - val_f1: 0.1416\n",
      "Epoch 717/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2116 - f1: 0.7723 - val_loss: 0.4589 - val_f1: 0.1400\n",
      "Epoch 718/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2090 - f1: 0.7762 - val_loss: 0.4590 - val_f1: 0.1416\n",
      "Epoch 719/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2127 - f1: 0.7721 - val_loss: 0.4570 - val_f1: 0.1424\n",
      "Epoch 720/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2111 - f1: 0.7706 - val_loss: 0.4595 - val_f1: 0.1413\n",
      "Epoch 721/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2085 - f1: 0.7771 - val_loss: 0.4597 - val_f1: 0.1405\n",
      "Epoch 722/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2090 - f1: 0.7767 - val_loss: 0.4584 - val_f1: 0.1419\n",
      "Epoch 723/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2109 - f1: 0.7754 - val_loss: 0.4584 - val_f1: 0.1418\n",
      "Epoch 724/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2118 - f1: 0.7709 - val_loss: 0.4583 - val_f1: 0.1417\n",
      "Epoch 725/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2085 - f1: 0.7741 - val_loss: 0.4599 - val_f1: 0.1415\n",
      "Epoch 726/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2097 - f1: 0.7769 - val_loss: 0.4598 - val_f1: 0.1417\n",
      "Epoch 727/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2111 - f1: 0.7706 - val_loss: 0.4606 - val_f1: 0.1409\n",
      "Epoch 728/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2094 - f1: 0.7736 - val_loss: 0.4600 - val_f1: 0.1406\n",
      "Epoch 729/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2108 - f1: 0.7726 - val_loss: 0.4611 - val_f1: 0.1396\n",
      "Epoch 730/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2097 - f1: 0.7713 - val_loss: 0.4609 - val_f1: 0.1409\n",
      "Epoch 731/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2119 - f1: 0.7706 - val_loss: 0.4604 - val_f1: 0.1403\n",
      "Epoch 732/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2075 - f1: 0.7796 - val_loss: 0.4598 - val_f1: 0.1404\n",
      "Epoch 733/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2103 - f1: 0.7746 - val_loss: 0.4588 - val_f1: 0.1414\n",
      "Epoch 734/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2083 - f1: 0.7761 - val_loss: 0.4599 - val_f1: 0.1410\n",
      "Epoch 735/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2085 - f1: 0.7748 - val_loss: 0.4592 - val_f1: 0.1413\n",
      "Epoch 736/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2098 - f1: 0.7736 - val_loss: 0.4606 - val_f1: 0.1405\n",
      "Epoch 737/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2099 - f1: 0.7733 - val_loss: 0.4624 - val_f1: 0.1410\n",
      "Epoch 738/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2090 - f1: 0.7747 - val_loss: 0.4610 - val_f1: 0.1416\n",
      "Epoch 739/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2092 - f1: 0.7709 - val_loss: 0.4592 - val_f1: 0.1417\n",
      "Epoch 740/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2105 - f1: 0.7732 - val_loss: 0.4586 - val_f1: 0.1414\n",
      "Epoch 741/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2079 - f1: 0.7772 - val_loss: 0.4597 - val_f1: 0.1419\n",
      "Epoch 742/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2088 - f1: 0.7748 - val_loss: 0.4600 - val_f1: 0.1418\n",
      "Epoch 743/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2063 - f1: 0.7766 - val_loss: 0.4621 - val_f1: 0.1420\n",
      "Epoch 744/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2090 - f1: 0.7737 - val_loss: 0.4602 - val_f1: 0.1413\n",
      "Epoch 745/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2072 - f1: 0.7795 - val_loss: 0.4622 - val_f1: 0.1414\n",
      "Epoch 746/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2074 - f1: 0.7780 - val_loss: 0.4620 - val_f1: 0.1416\n",
      "Epoch 747/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2092 - f1: 0.7749 - val_loss: 0.4623 - val_f1: 0.1413\n",
      "Epoch 748/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2075 - f1: 0.7750 - val_loss: 0.4624 - val_f1: 0.1411\n",
      "Epoch 749/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2089 - f1: 0.7726 - val_loss: 0.4630 - val_f1: 0.1414\n",
      "Epoch 750/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2071 - f1: 0.7795 - val_loss: 0.4619 - val_f1: 0.1412\n",
      "Epoch 751/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2098 - f1: 0.7747 - val_loss: 0.4608 - val_f1: 0.1415\n",
      "Epoch 752/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2074 - f1: 0.7751 - val_loss: 0.4619 - val_f1: 0.1415\n",
      "Epoch 753/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2101 - f1: 0.7735 - val_loss: 0.4613 - val_f1: 0.1413\n",
      "Epoch 754/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2072 - f1: 0.7750 - val_loss: 0.4627 - val_f1: 0.1409\n",
      "Epoch 755/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2057 - f1: 0.7790 - val_loss: 0.4622 - val_f1: 0.1415\n",
      "Epoch 756/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2115 - f1: 0.7690 - val_loss: 0.4596 - val_f1: 0.1421\n",
      "Epoch 757/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2074 - f1: 0.7787 - val_loss: 0.4602 - val_f1: 0.1419\n",
      "Epoch 758/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2063 - f1: 0.7769 - val_loss: 0.4621 - val_f1: 0.1405\n",
      "Epoch 759/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2090 - f1: 0.7787 - val_loss: 0.4617 - val_f1: 0.1411\n",
      "Epoch 760/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2084 - f1: 0.7753 - val_loss: 0.4614 - val_f1: 0.1414\n",
      "Epoch 761/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2068 - f1: 0.7795 - val_loss: 0.4622 - val_f1: 0.1411\n",
      "Epoch 762/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2062 - f1: 0.7774 - val_loss: 0.4644 - val_f1: 0.1405\n",
      "Epoch 763/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2056 - f1: 0.7754 - val_loss: 0.4638 - val_f1: 0.1416\n",
      "Epoch 764/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2071 - f1: 0.7793 - val_loss: 0.4628 - val_f1: 0.1423\n",
      "Epoch 765/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2050 - f1: 0.7806 - val_loss: 0.4642 - val_f1: 0.1403\n",
      "Epoch 766/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2075 - f1: 0.7794 - val_loss: 0.4639 - val_f1: 0.1408\n",
      "Epoch 767/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2059 - f1: 0.7749 - val_loss: 0.4645 - val_f1: 0.1407\n",
      "Epoch 768/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2091 - f1: 0.7739 - val_loss: 0.4629 - val_f1: 0.1412\n",
      "Epoch 769/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2046 - f1: 0.7798 - val_loss: 0.4638 - val_f1: 0.1409\n",
      "Epoch 770/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2063 - f1: 0.7801 - val_loss: 0.4647 - val_f1: 0.1412\n",
      "Epoch 771/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2070 - f1: 0.7775 - val_loss: 0.4630 - val_f1: 0.1417\n",
      "Epoch 772/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2085 - f1: 0.7781 - val_loss: 0.4635 - val_f1: 0.1404\n",
      "Epoch 773/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2089 - f1: 0.7726 - val_loss: 0.4632 - val_f1: 0.1403\n",
      "Epoch 774/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2042 - f1: 0.7831 - val_loss: 0.4653 - val_f1: 0.1403\n",
      "Epoch 775/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2067 - f1: 0.7771 - val_loss: 0.4646 - val_f1: 0.1410\n",
      "Epoch 776/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2067 - f1: 0.7803 - val_loss: 0.4632 - val_f1: 0.1414\n",
      "Epoch 777/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2077 - f1: 0.7788 - val_loss: 0.4638 - val_f1: 0.1412\n",
      "Epoch 778/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2082 - f1: 0.7769 - val_loss: 0.4633 - val_f1: 0.1421\n",
      "Epoch 779/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2095 - f1: 0.7784 - val_loss: 0.4616 - val_f1: 0.1415\n",
      "Epoch 780/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2048 - f1: 0.7761 - val_loss: 0.4616 - val_f1: 0.1428\n",
      "Epoch 781/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2047 - f1: 0.7817 - val_loss: 0.4639 - val_f1: 0.1417\n",
      "Epoch 782/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2076 - f1: 0.7737 - val_loss: 0.4643 - val_f1: 0.1417\n",
      "Epoch 783/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2065 - f1: 0.7778 - val_loss: 0.4643 - val_f1: 0.1414\n",
      "Epoch 784/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2052 - f1: 0.7807 - val_loss: 0.4646 - val_f1: 0.1411\n",
      "Epoch 785/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2046 - f1: 0.7818 - val_loss: 0.4651 - val_f1: 0.1410\n",
      "Epoch 786/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2070 - f1: 0.7776 - val_loss: 0.4644 - val_f1: 0.1415\n",
      "Epoch 787/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2071 - f1: 0.7762 - val_loss: 0.4651 - val_f1: 0.1409\n",
      "Epoch 788/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2058 - f1: 0.7788 - val_loss: 0.4647 - val_f1: 0.1414\n",
      "Epoch 789/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2042 - f1: 0.7818 - val_loss: 0.4651 - val_f1: 0.1418\n",
      "Epoch 790/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2078 - f1: 0.7799 - val_loss: 0.4653 - val_f1: 0.1407\n",
      "Epoch 791/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2055 - f1: 0.7778 - val_loss: 0.4652 - val_f1: 0.1412\n",
      "Epoch 792/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2089 - f1: 0.7768 - val_loss: 0.4620 - val_f1: 0.1422\n",
      "Epoch 793/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2083 - f1: 0.7776 - val_loss: 0.4626 - val_f1: 0.1425\n",
      "Epoch 794/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2023 - f1: 0.7864 - val_loss: 0.4644 - val_f1: 0.1407\n",
      "Epoch 795/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2022 - f1: 0.7804 - val_loss: 0.4659 - val_f1: 0.1419\n",
      "Epoch 796/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2050 - f1: 0.7825 - val_loss: 0.4671 - val_f1: 0.1414\n",
      "Epoch 797/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2047 - f1: 0.7806 - val_loss: 0.4656 - val_f1: 0.1411\n",
      "Epoch 798/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2047 - f1: 0.7813 - val_loss: 0.4645 - val_f1: 0.1419\n",
      "Epoch 799/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2078 - f1: 0.7799 - val_loss: 0.4641 - val_f1: 0.1420\n",
      "Epoch 800/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2060 - f1: 0.7794 - val_loss: 0.4648 - val_f1: 0.1418\n",
      "Epoch 801/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2049 - f1: 0.7784 - val_loss: 0.4637 - val_f1: 0.1427\n",
      "Epoch 802/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2023 - f1: 0.7868 - val_loss: 0.4658 - val_f1: 0.1435\n",
      "Epoch 803/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2025 - f1: 0.7846 - val_loss: 0.4687 - val_f1: 0.1407\n",
      "Epoch 804/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2056 - f1: 0.7773 - val_loss: 0.4663 - val_f1: 0.1410\n",
      "Epoch 805/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2055 - f1: 0.7807 - val_loss: 0.4649 - val_f1: 0.1425\n",
      "Epoch 806/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2051 - f1: 0.7773 - val_loss: 0.4648 - val_f1: 0.1414\n",
      "Epoch 807/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2020 - f1: 0.7861 - val_loss: 0.4654 - val_f1: 0.1420\n",
      "Epoch 808/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2051 - f1: 0.7817 - val_loss: 0.4647 - val_f1: 0.1424\n",
      "Epoch 809/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2041 - f1: 0.7832 - val_loss: 0.4673 - val_f1: 0.1415\n",
      "Epoch 810/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2028 - f1: 0.7849 - val_loss: 0.4679 - val_f1: 0.1413\n",
      "Epoch 811/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2033 - f1: 0.7834 - val_loss: 0.4672 - val_f1: 0.1414\n",
      "Epoch 812/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2067 - f1: 0.7803 - val_loss: 0.4653 - val_f1: 0.1420\n",
      "Epoch 813/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2057 - f1: 0.7788 - val_loss: 0.4670 - val_f1: 0.1422\n",
      "Epoch 814/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2021 - f1: 0.7863 - val_loss: 0.4674 - val_f1: 0.1414\n",
      "Epoch 815/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2032 - f1: 0.7796 - val_loss: 0.4682 - val_f1: 0.1415\n",
      "Epoch 816/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2080 - f1: 0.7782 - val_loss: 0.4666 - val_f1: 0.1412\n",
      "Epoch 817/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2044 - f1: 0.7805 - val_loss: 0.4659 - val_f1: 0.1418\n",
      "Epoch 818/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2022 - f1: 0.7845 - val_loss: 0.4685 - val_f1: 0.1417\n",
      "Epoch 819/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2057 - f1: 0.7792 - val_loss: 0.4666 - val_f1: 0.1418\n",
      "Epoch 820/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2026 - f1: 0.7791 - val_loss: 0.4680 - val_f1: 0.1420\n",
      "Epoch 821/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2030 - f1: 0.7817 - val_loss: 0.4671 - val_f1: 0.1424\n",
      "Epoch 822/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2025 - f1: 0.7874 - val_loss: 0.4686 - val_f1: 0.1418\n",
      "Epoch 823/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2019 - f1: 0.7830 - val_loss: 0.4694 - val_f1: 0.1409\n",
      "Epoch 824/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2032 - f1: 0.7822 - val_loss: 0.4679 - val_f1: 0.1419\n",
      "Epoch 825/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2034 - f1: 0.7808 - val_loss: 0.4711 - val_f1: 0.1415\n",
      "Epoch 826/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2039 - f1: 0.7779 - val_loss: 0.4707 - val_f1: 0.1417\n",
      "Epoch 827/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2052 - f1: 0.7777 - val_loss: 0.4684 - val_f1: 0.1414\n",
      "Epoch 828/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2032 - f1: 0.7805 - val_loss: 0.4670 - val_f1: 0.1421\n",
      "Epoch 829/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2020 - f1: 0.7806 - val_loss: 0.4686 - val_f1: 0.1413\n",
      "Epoch 830/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2047 - f1: 0.7818 - val_loss: 0.4672 - val_f1: 0.1418\n",
      "Epoch 831/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2025 - f1: 0.7823 - val_loss: 0.4693 - val_f1: 0.1415\n",
      "Epoch 832/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2055 - f1: 0.7778 - val_loss: 0.4683 - val_f1: 0.1417\n",
      "Epoch 833/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2034 - f1: 0.7818 - val_loss: 0.4679 - val_f1: 0.1415\n",
      "Epoch 834/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2020 - f1: 0.7813 - val_loss: 0.4686 - val_f1: 0.1423\n",
      "Epoch 835/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2046 - f1: 0.7756 - val_loss: 0.4669 - val_f1: 0.1418\n",
      "Epoch 836/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2038 - f1: 0.7779 - val_loss: 0.4682 - val_f1: 0.1423\n",
      "Epoch 837/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2057 - f1: 0.7780 - val_loss: 0.4670 - val_f1: 0.1420\n",
      "Epoch 838/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2033 - f1: 0.7832 - val_loss: 0.4665 - val_f1: 0.1415\n",
      "Epoch 839/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2005 - f1: 0.7827 - val_loss: 0.4682 - val_f1: 0.1424\n",
      "Epoch 840/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2038 - f1: 0.7830 - val_loss: 0.4706 - val_f1: 0.1412\n",
      "Epoch 841/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2020 - f1: 0.7848 - val_loss: 0.4692 - val_f1: 0.1415\n",
      "Epoch 842/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2046 - f1: 0.7790 - val_loss: 0.4677 - val_f1: 0.1420\n",
      "Epoch 843/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2042 - f1: 0.7808 - val_loss: 0.4681 - val_f1: 0.1422\n",
      "Epoch 844/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2018 - f1: 0.7801 - val_loss: 0.4700 - val_f1: 0.1404\n",
      "Epoch 845/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2033 - f1: 0.7851 - val_loss: 0.4696 - val_f1: 0.1412\n",
      "Epoch 846/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2023 - f1: 0.7809 - val_loss: 0.4686 - val_f1: 0.1419\n",
      "Epoch 847/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2052 - f1: 0.7812 - val_loss: 0.4673 - val_f1: 0.1411\n",
      "Epoch 848/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2041 - f1: 0.7810 - val_loss: 0.4651 - val_f1: 0.1412\n",
      "Epoch 849/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2026 - f1: 0.7817 - val_loss: 0.4666 - val_f1: 0.1413\n",
      "Epoch 850/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2034 - f1: 0.7859 - val_loss: 0.4663 - val_f1: 0.1417\n",
      "Epoch 851/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2037 - f1: 0.7837 - val_loss: 0.4676 - val_f1: 0.1422\n",
      "Epoch 852/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2031 - f1: 0.7826 - val_loss: 0.4680 - val_f1: 0.1418\n",
      "Epoch 853/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2021 - f1: 0.7824 - val_loss: 0.4689 - val_f1: 0.1419\n",
      "Epoch 854/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2000 - f1: 0.7870 - val_loss: 0.4683 - val_f1: 0.1427\n",
      "Epoch 855/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1995 - f1: 0.7842 - val_loss: 0.4699 - val_f1: 0.1413\n",
      "Epoch 856/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2009 - f1: 0.7850 - val_loss: 0.4703 - val_f1: 0.1423\n",
      "Epoch 857/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2019 - f1: 0.7850 - val_loss: 0.4701 - val_f1: 0.1417\n",
      "Epoch 858/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.2024 - f1: 0.7826 - val_loss: 0.4691 - val_f1: 0.1422\n",
      "Epoch 859/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.1989 - f1: 0.7859 - val_loss: 0.4708 - val_f1: 0.1409\n",
      "Epoch 860/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2017 - f1: 0.7850 - val_loss: 0.4708 - val_f1: 0.1420\n",
      "Epoch 861/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2014 - f1: 0.7842 - val_loss: 0.4708 - val_f1: 0.1413\n",
      "Epoch 862/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2019 - f1: 0.7835 - val_loss: 0.4715 - val_f1: 0.1409\n",
      "Epoch 863/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2023 - f1: 0.7802 - val_loss: 0.4693 - val_f1: 0.1411\n",
      "Epoch 864/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2003 - f1: 0.7843 - val_loss: 0.4694 - val_f1: 0.1417\n",
      "Epoch 865/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2025 - f1: 0.7793 - val_loss: 0.4688 - val_f1: 0.1414\n",
      "Epoch 866/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1991 - f1: 0.7893 - val_loss: 0.4711 - val_f1: 0.1415\n",
      "Epoch 867/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2002 - f1: 0.7854 - val_loss: 0.4703 - val_f1: 0.1420\n",
      "Epoch 868/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1998 - f1: 0.7860 - val_loss: 0.4727 - val_f1: 0.1406\n",
      "Epoch 869/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2034 - f1: 0.7823 - val_loss: 0.4711 - val_f1: 0.1421\n",
      "Epoch 870/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1998 - f1: 0.7871 - val_loss: 0.4723 - val_f1: 0.1414\n",
      "Epoch 871/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2013 - f1: 0.7805 - val_loss: 0.4718 - val_f1: 0.1415\n",
      "Epoch 872/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2027 - f1: 0.7826 - val_loss: 0.4702 - val_f1: 0.1420\n",
      "Epoch 873/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2031 - f1: 0.7847 - val_loss: 0.4699 - val_f1: 0.1412\n",
      "Epoch 874/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2009 - f1: 0.7818 - val_loss: 0.4700 - val_f1: 0.1416\n",
      "Epoch 875/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2026 - f1: 0.7790 - val_loss: 0.4695 - val_f1: 0.1423\n",
      "Epoch 876/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2025 - f1: 0.7795 - val_loss: 0.4682 - val_f1: 0.1427\n",
      "Epoch 877/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2000 - f1: 0.7861 - val_loss: 0.4715 - val_f1: 0.1421\n",
      "Epoch 878/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2008 - f1: 0.7883 - val_loss: 0.4706 - val_f1: 0.1424\n",
      "Epoch 879/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2009 - f1: 0.7840 - val_loss: 0.4703 - val_f1: 0.1416\n",
      "Epoch 880/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2001 - f1: 0.7825 - val_loss: 0.4711 - val_f1: 0.1419\n",
      "Epoch 881/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1994 - f1: 0.7915 - val_loss: 0.4743 - val_f1: 0.1416\n",
      "Epoch 882/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2012 - f1: 0.7853 - val_loss: 0.4730 - val_f1: 0.1420\n",
      "Epoch 883/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1997 - f1: 0.7914 - val_loss: 0.4729 - val_f1: 0.1404\n",
      "Epoch 884/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2015 - f1: 0.7842 - val_loss: 0.4730 - val_f1: 0.1412\n",
      "Epoch 885/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2008 - f1: 0.7837 - val_loss: 0.4716 - val_f1: 0.1413\n",
      "Epoch 886/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1979 - f1: 0.7889 - val_loss: 0.4715 - val_f1: 0.1421\n",
      "Epoch 887/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2013 - f1: 0.7857 - val_loss: 0.4720 - val_f1: 0.1412\n",
      "Epoch 888/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1985 - f1: 0.7910 - val_loss: 0.4737 - val_f1: 0.1419\n",
      "Epoch 889/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1990 - f1: 0.7926 - val_loss: 0.4744 - val_f1: 0.1419\n",
      "Epoch 890/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1974 - f1: 0.7881 - val_loss: 0.4743 - val_f1: 0.1406\n",
      "Epoch 891/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2014 - f1: 0.7850 - val_loss: 0.4710 - val_f1: 0.1416\n",
      "Epoch 892/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2028 - f1: 0.7834 - val_loss: 0.4698 - val_f1: 0.1424\n",
      "Epoch 893/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2010 - f1: 0.7856 - val_loss: 0.4709 - val_f1: 0.1417\n",
      "Epoch 894/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1978 - f1: 0.7851 - val_loss: 0.4739 - val_f1: 0.1413\n",
      "Epoch 895/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1980 - f1: 0.7883 - val_loss: 0.4739 - val_f1: 0.1422\n",
      "Epoch 896/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.2010 - f1: 0.7873 - val_loss: 0.4727 - val_f1: 0.1420\n",
      "Epoch 897/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1998 - f1: 0.7872 - val_loss: 0.4735 - val_f1: 0.1416\n",
      "Epoch 898/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1987 - f1: 0.7834 - val_loss: 0.4731 - val_f1: 0.1420\n",
      "Epoch 899/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2015 - f1: 0.7854 - val_loss: 0.4723 - val_f1: 0.1428\n",
      "Epoch 900/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2001 - f1: 0.7891 - val_loss: 0.4726 - val_f1: 0.1424\n",
      "Epoch 901/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2014 - f1: 0.7832 - val_loss: 0.4719 - val_f1: 0.1423\n",
      "Epoch 902/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.1997 - f1: 0.7890 - val_loss: 0.4720 - val_f1: 0.1412\n",
      "Epoch 903/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.2017 - f1: 0.7839 - val_loss: 0.4721 - val_f1: 0.1420\n",
      "Epoch 904/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1998 - f1: 0.7858 - val_loss: 0.4727 - val_f1: 0.1416\n",
      "Epoch 905/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2009 - f1: 0.7829 - val_loss: 0.4725 - val_f1: 0.1425\n",
      "Epoch 906/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2003 - f1: 0.7876 - val_loss: 0.4720 - val_f1: 0.1416\n",
      "Epoch 907/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1995 - f1: 0.7881 - val_loss: 0.4711 - val_f1: 0.1417\n",
      "Epoch 908/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2039 - f1: 0.7844 - val_loss: 0.4692 - val_f1: 0.1419\n",
      "Epoch 909/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1970 - f1: 0.7842 - val_loss: 0.4720 - val_f1: 0.1415\n",
      "Epoch 910/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2005 - f1: 0.7892 - val_loss: 0.4728 - val_f1: 0.1419\n",
      "Epoch 911/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1995 - f1: 0.7873 - val_loss: 0.4745 - val_f1: 0.1398\n",
      "Epoch 912/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1994 - f1: 0.7849 - val_loss: 0.4736 - val_f1: 0.1420\n",
      "Epoch 913/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.1981 - f1: 0.78 - 3s 39us/step - loss: 0.1979 - f1: 0.7855 - val_loss: 0.4729 - val_f1: 0.1426\n",
      "Epoch 914/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1982 - f1: 0.7864 - val_loss: 0.4732 - val_f1: 0.1405\n",
      "Epoch 915/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1981 - f1: 0.7836 - val_loss: 0.4736 - val_f1: 0.1416\n",
      "Epoch 916/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2017 - f1: 0.7832 - val_loss: 0.4701 - val_f1: 0.1415\n",
      "Epoch 917/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1948 - f1: 0.7960 - val_loss: 0.4752 - val_f1: 0.1411\n",
      "Epoch 918/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1991 - f1: 0.7839 - val_loss: 0.4724 - val_f1: 0.1410\n",
      "Epoch 919/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1978 - f1: 0.7925 - val_loss: 0.4745 - val_f1: 0.1415\n",
      "Epoch 920/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1972 - f1: 0.7894 - val_loss: 0.4737 - val_f1: 0.1422\n",
      "Epoch 921/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1979 - f1: 0.7842 - val_loss: 0.4750 - val_f1: 0.1421\n",
      "Epoch 922/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2005 - f1: 0.7849 - val_loss: 0.4748 - val_f1: 0.1413\n",
      "Epoch 923/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1994 - f1: 0.7877 - val_loss: 0.4742 - val_f1: 0.1411\n",
      "Epoch 924/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1991 - f1: 0.7855 - val_loss: 0.4739 - val_f1: 0.1414\n",
      "Epoch 925/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1988 - f1: 0.7880 - val_loss: 0.4739 - val_f1: 0.1424\n",
      "Epoch 926/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1996 - f1: 0.7896 - val_loss: 0.4740 - val_f1: 0.1415\n",
      "Epoch 927/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1989 - f1: 0.7892 - val_loss: 0.4734 - val_f1: 0.1419\n",
      "Epoch 928/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1968 - f1: 0.7903 - val_loss: 0.4758 - val_f1: 0.1419\n",
      "Epoch 929/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1984 - f1: 0.7866 - val_loss: 0.4743 - val_f1: 0.1421\n",
      "Epoch 930/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2017 - f1: 0.7793 - val_loss: 0.4731 - val_f1: 0.1422\n",
      "Epoch 931/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1991 - f1: 0.7894 - val_loss: 0.4746 - val_f1: 0.1418\n",
      "Epoch 932/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1992 - f1: 0.7909 - val_loss: 0.4723 - val_f1: 0.1426\n",
      "Epoch 933/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1988 - f1: 0.7854 - val_loss: 0.4742 - val_f1: 0.1418\n",
      "Epoch 934/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.1996 - f1: 0.7858 - val_loss: 0.4735 - val_f1: 0.1419\n",
      "Epoch 935/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.1978 - f1: 0.7880 - val_loss: 0.4737 - val_f1: 0.1423\n",
      "Epoch 936/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1958 - f1: 0.7933 - val_loss: 0.4742 - val_f1: 0.1415\n",
      "Epoch 937/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1998 - f1: 0.7834 - val_loss: 0.4741 - val_f1: 0.1411\n",
      "Epoch 938/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1983 - f1: 0.7898 - val_loss: 0.4734 - val_f1: 0.1416\n",
      "Epoch 939/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2000 - f1: 0.7852 - val_loss: 0.4741 - val_f1: 0.1415\n",
      "Epoch 940/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1979 - f1: 0.7884 - val_loss: 0.4729 - val_f1: 0.1419\n",
      "Epoch 941/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1969 - f1: 0.7915 - val_loss: 0.4748 - val_f1: 0.1415\n",
      "Epoch 942/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1990 - f1: 0.7874 - val_loss: 0.4752 - val_f1: 0.1418\n",
      "Epoch 943/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1962 - f1: 0.7891 - val_loss: 0.4756 - val_f1: 0.1417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1981 - f1: 0.7881 - val_loss: 0.4745 - val_f1: 0.1417\n",
      "Epoch 945/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1997 - f1: 0.7872 - val_loss: 0.4748 - val_f1: 0.1420\n",
      "Epoch 946/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1947 - f1: 0.7926 - val_loss: 0.4762 - val_f1: 0.1410\n",
      "Epoch 947/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1961 - f1: 0.7948 - val_loss: 0.4769 - val_f1: 0.1410\n",
      "Epoch 948/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1975 - f1: 0.7935 - val_loss: 0.4758 - val_f1: 0.1412\n",
      "Epoch 949/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1991 - f1: 0.7897 - val_loss: 0.4757 - val_f1: 0.1418\n",
      "Epoch 950/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1986 - f1: 0.7881 - val_loss: 0.4748 - val_f1: 0.1412\n",
      "Epoch 951/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1948 - f1: 0.7903 - val_loss: 0.4770 - val_f1: 0.1409\n",
      "Epoch 952/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1974 - f1: 0.7895 - val_loss: 0.4776 - val_f1: 0.1400\n",
      "Epoch 953/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1981 - f1: 0.7868 - val_loss: 0.4753 - val_f1: 0.1415\n",
      "Epoch 954/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1975 - f1: 0.7899 - val_loss: 0.4753 - val_f1: 0.1406\n",
      "Epoch 955/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1962 - f1: 0.7901 - val_loss: 0.4782 - val_f1: 0.1405\n",
      "Epoch 956/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1958 - f1: 0.7883 - val_loss: 0.4786 - val_f1: 0.1409\n",
      "Epoch 957/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1965 - f1: 0.7904 - val_loss: 0.4780 - val_f1: 0.1413\n",
      "Epoch 958/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1976 - f1: 0.7884 - val_loss: 0.4773 - val_f1: 0.1420\n",
      "Epoch 959/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1940 - f1: 0.7964 - val_loss: 0.4768 - val_f1: 0.1412\n",
      "Epoch 960/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1994 - f1: 0.7843 - val_loss: 0.4748 - val_f1: 0.1419\n",
      "Epoch 961/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1982 - f1: 0.7827 - val_loss: 0.4745 - val_f1: 0.1426\n",
      "Epoch 962/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1944 - f1: 0.7923 - val_loss: 0.4775 - val_f1: 0.1413\n",
      "Epoch 963/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1965 - f1: 0.7874 - val_loss: 0.4781 - val_f1: 0.1410\n",
      "Epoch 964/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1988 - f1: 0.7877 - val_loss: 0.4765 - val_f1: 0.1421\n",
      "Epoch 965/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1957 - f1: 0.7884 - val_loss: 0.4782 - val_f1: 0.1411\n",
      "Epoch 966/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1972 - f1: 0.7923 - val_loss: 0.4756 - val_f1: 0.1413\n",
      "Epoch 967/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1978 - f1: 0.7882 - val_loss: 0.4757 - val_f1: 0.1421\n",
      "Epoch 968/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1985 - f1: 0.7881 - val_loss: 0.4751 - val_f1: 0.1412\n",
      "Epoch 969/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1970 - f1: 0.7875 - val_loss: 0.4773 - val_f1: 0.1411\n",
      "Epoch 970/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1967 - f1: 0.7902 - val_loss: 0.4764 - val_f1: 0.1406\n",
      "Epoch 971/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1990 - f1: 0.7898 - val_loss: 0.4751 - val_f1: 0.1411\n",
      "Epoch 972/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1931 - f1: 0.7925 - val_loss: 0.4783 - val_f1: 0.1412\n",
      "Epoch 973/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1973 - f1: 0.7884 - val_loss: 0.4777 - val_f1: 0.1408\n",
      "Epoch 974/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1945 - f1: 0.7939 - val_loss: 0.4796 - val_f1: 0.1405\n",
      "Epoch 975/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1957 - f1: 0.7905 - val_loss: 0.4781 - val_f1: 0.1412\n",
      "Epoch 976/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1960 - f1: 0.7931 - val_loss: 0.4779 - val_f1: 0.1413\n",
      "Epoch 977/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1953 - f1: 0.7912 - val_loss: 0.4798 - val_f1: 0.1411\n",
      "Epoch 978/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1972 - f1: 0.7920 - val_loss: 0.4784 - val_f1: 0.1409\n",
      "Epoch 979/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1988 - f1: 0.7909 - val_loss: 0.4760 - val_f1: 0.1425\n",
      "Epoch 980/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1972 - f1: 0.7896 - val_loss: 0.4783 - val_f1: 0.1403\n",
      "Epoch 981/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1943 - f1: 0.7890 - val_loss: 0.4783 - val_f1: 0.1414\n",
      "Epoch 982/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1952 - f1: 0.7946 - val_loss: 0.4765 - val_f1: 0.1413\n",
      "Epoch 983/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1970 - f1: 0.7879 - val_loss: 0.4751 - val_f1: 0.1422\n",
      "Epoch 984/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1957 - f1: 0.7867 - val_loss: 0.4781 - val_f1: 0.1413\n",
      "Epoch 985/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1959 - f1: 0.7920 - val_loss: 0.4765 - val_f1: 0.1419\n",
      "Epoch 986/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1959 - f1: 0.7872 - val_loss: 0.4785 - val_f1: 0.1408\n",
      "Epoch 987/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1945 - f1: 0.7895 - val_loss: 0.4790 - val_f1: 0.1416\n",
      "Epoch 988/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1929 - f1: 0.7967 - val_loss: 0.4798 - val_f1: 0.1418\n",
      "Epoch 989/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1981 - f1: 0.7907 - val_loss: 0.4778 - val_f1: 0.1415\n",
      "Epoch 990/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1975 - f1: 0.7907 - val_loss: 0.4781 - val_f1: 0.1408\n",
      "Epoch 991/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1947 - f1: 0.7924 - val_loss: 0.4791 - val_f1: 0.1410\n",
      "Epoch 992/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1942 - f1: 0.7942 - val_loss: 0.4816 - val_f1: 0.1410\n",
      "Epoch 993/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1993 - f1: 0.7871 - val_loss: 0.4784 - val_f1: 0.1414\n",
      "Epoch 994/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1966 - f1: 0.7886 - val_loss: 0.4780 - val_f1: 0.1419\n",
      "Epoch 995/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1956 - f1: 0.7918 - val_loss: 0.4790 - val_f1: 0.1412\n",
      "Epoch 996/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1936 - f1: 0.7935 - val_loss: 0.4802 - val_f1: 0.1414\n",
      "Epoch 997/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1938 - f1: 0.7921 - val_loss: 0.4801 - val_f1: 0.1412\n",
      "Epoch 998/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1953 - f1: 0.7911 - val_loss: 0.4774 - val_f1: 0.1423\n",
      "Epoch 999/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1972 - f1: 0.7872 - val_loss: 0.4771 - val_f1: 0.1427\n",
      "Epoch 1000/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1944 - f1: 0.7931 - val_loss: 0.4772 - val_f1: 0.1411\n",
      "Epoch 1001/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1958 - f1: 0.7923 - val_loss: 0.4787 - val_f1: 0.1418\n",
      "Epoch 1002/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1938 - f1: 0.7933 - val_loss: 0.4795 - val_f1: 0.1414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1003/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1950 - f1: 0.7915 - val_loss: 0.4775 - val_f1: 0.1417\n",
      "Epoch 1004/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1919 - f1: 0.7959 - val_loss: 0.4809 - val_f1: 0.1412\n",
      "Epoch 1005/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1931 - f1: 0.7917 - val_loss: 0.4801 - val_f1: 0.1419\n",
      "Epoch 1006/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1938 - f1: 0.7927 - val_loss: 0.4804 - val_f1: 0.1429\n",
      "Epoch 1007/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1968 - f1: 0.7915 - val_loss: 0.4792 - val_f1: 0.1420\n",
      "Epoch 1008/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.1949 - f1: 0.7894 - val_loss: 0.4790 - val_f1: 0.1422\n",
      "Epoch 1009/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1961 - f1: 0.7921 - val_loss: 0.4775 - val_f1: 0.1425\n",
      "Epoch 1010/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1940 - f1: 0.7938 - val_loss: 0.4781 - val_f1: 0.1415\n",
      "Epoch 1011/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1961 - f1: 0.7884 - val_loss: 0.4793 - val_f1: 0.1418\n",
      "Epoch 1012/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1952 - f1: 0.7909 - val_loss: 0.4794 - val_f1: 0.1423\n",
      "Epoch 1013/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1982 - f1: 0.7870 - val_loss: 0.4774 - val_f1: 0.1431\n",
      "Epoch 1014/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1966 - f1: 0.7944 - val_loss: 0.4780 - val_f1: 0.1415\n",
      "Epoch 1015/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1967 - f1: 0.7913 - val_loss: 0.4789 - val_f1: 0.1415\n",
      "Epoch 1016/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1934 - f1: 0.7915 - val_loss: 0.4788 - val_f1: 0.1423\n",
      "Epoch 1017/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1948 - f1: 0.7929 - val_loss: 0.4790 - val_f1: 0.1422\n",
      "Epoch 1018/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1948 - f1: 0.7912 - val_loss: 0.4775 - val_f1: 0.1421\n",
      "Epoch 1019/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1966 - f1: 0.7905 - val_loss: 0.4785 - val_f1: 0.1419\n",
      "Epoch 1020/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1943 - f1: 0.7963 - val_loss: 0.4792 - val_f1: 0.1418\n",
      "Epoch 1021/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1954 - f1: 0.7905 - val_loss: 0.4788 - val_f1: 0.1411\n",
      "Epoch 1022/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1919 - f1: 0.7969 - val_loss: 0.4802 - val_f1: 0.1409\n",
      "Epoch 1023/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1951 - f1: 0.7926 - val_loss: 0.4808 - val_f1: 0.1411\n",
      "Epoch 1024/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1955 - f1: 0.7910 - val_loss: 0.4789 - val_f1: 0.1421\n",
      "Epoch 1025/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1960 - f1: 0.7913 - val_loss: 0.4781 - val_f1: 0.1420\n",
      "Epoch 1026/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1938 - f1: 0.7941 - val_loss: 0.4794 - val_f1: 0.1418\n",
      "Epoch 1027/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1923 - f1: 0.7928 - val_loss: 0.4803 - val_f1: 0.1409\n",
      "Epoch 1028/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1969 - f1: 0.7898 - val_loss: 0.4798 - val_f1: 0.1421\n",
      "Epoch 1029/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1971 - f1: 0.7904 - val_loss: 0.4783 - val_f1: 0.1421\n",
      "Epoch 1030/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1919 - f1: 0.7957 - val_loss: 0.4803 - val_f1: 0.1420\n",
      "Epoch 1031/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1939 - f1: 0.7944 - val_loss: 0.4808 - val_f1: 0.1416\n",
      "Epoch 1032/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1946 - f1: 0.7936 - val_loss: 0.4790 - val_f1: 0.1422\n",
      "Epoch 1033/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1938 - f1: 0.7930 - val_loss: 0.4804 - val_f1: 0.1417\n",
      "Epoch 1034/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1943 - f1: 0.7935 - val_loss: 0.4789 - val_f1: 0.1419\n",
      "Epoch 1035/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1916 - f1: 0.7962 - val_loss: 0.4810 - val_f1: 0.1416\n",
      "Epoch 1036/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1976 - f1: 0.7912 - val_loss: 0.4790 - val_f1: 0.1424\n",
      "Epoch 1037/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1928 - f1: 0.7941 - val_loss: 0.4811 - val_f1: 0.1413\n",
      "Epoch 1038/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1967 - f1: 0.7856 - val_loss: 0.4784 - val_f1: 0.1416\n",
      "Epoch 1039/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1926 - f1: 0.7961 - val_loss: 0.4803 - val_f1: 0.1414\n",
      "Epoch 1040/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1933 - f1: 0.7983 - val_loss: 0.4813 - val_f1: 0.1415\n",
      "Epoch 1041/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1937 - f1: 0.7942 - val_loss: 0.4807 - val_f1: 0.1415\n",
      "Epoch 1042/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1936 - f1: 0.7935 - val_loss: 0.4803 - val_f1: 0.1413\n",
      "Epoch 1043/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1929 - f1: 0.7934 - val_loss: 0.4808 - val_f1: 0.1415\n",
      "Epoch 1044/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1939 - f1: 0.7908 - val_loss: 0.4820 - val_f1: 0.1415\n",
      "Epoch 1045/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1916 - f1: 0.7955 - val_loss: 0.4817 - val_f1: 0.1418\n",
      "Epoch 1046/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1957 - f1: 0.7964 - val_loss: 0.4801 - val_f1: 0.1419\n",
      "Epoch 1047/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1913 - f1: 0.7958 - val_loss: 0.4801 - val_f1: 0.1430\n",
      "Epoch 1048/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1913 - f1: 0.7971 - val_loss: 0.4830 - val_f1: 0.1418\n",
      "Epoch 1049/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1948 - f1: 0.7920 - val_loss: 0.4813 - val_f1: 0.1416\n",
      "Epoch 1050/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1923 - f1: 0.7956 - val_loss: 0.4818 - val_f1: 0.1414\n",
      "Epoch 1051/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1947 - f1: 0.7926 - val_loss: 0.4805 - val_f1: 0.1412\n",
      "Epoch 1052/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1954 - f1: 0.7890 - val_loss: 0.4793 - val_f1: 0.1419\n",
      "Epoch 1053/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1919 - f1: 0.7967 - val_loss: 0.4825 - val_f1: 0.1411\n",
      "Epoch 1054/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1937 - f1: 0.7940 - val_loss: 0.4821 - val_f1: 0.1412\n",
      "Epoch 1055/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1917 - f1: 0.7942 - val_loss: 0.4827 - val_f1: 0.1420\n",
      "Epoch 1056/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1961 - f1: 0.7888 - val_loss: 0.4804 - val_f1: 0.1422\n",
      "Epoch 1057/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1919 - f1: 0.7964 - val_loss: 0.4805 - val_f1: 0.1414\n",
      "Epoch 1058/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1932 - f1: 0.7948 - val_loss: 0.4815 - val_f1: 0.1413\n",
      "Epoch 1059/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1931 - f1: 0.7983 - val_loss: 0.4824 - val_f1: 0.1409\n",
      "Epoch 1060/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1925 - f1: 0.7932 - val_loss: 0.4829 - val_f1: 0.1416\n",
      "Epoch 1061/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1925 - f1: 0.7946 - val_loss: 0.4824 - val_f1: 0.1414\n",
      "Epoch 1062/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1920 - f1: 0.7964 - val_loss: 0.4836 - val_f1: 0.1406\n",
      "Epoch 1063/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1961 - f1: 0.7923 - val_loss: 0.4801 - val_f1: 0.1415\n",
      "Epoch 1064/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1924 - f1: 0.7950 - val_loss: 0.4811 - val_f1: 0.1411\n",
      "Epoch 1065/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1929 - f1: 0.7933 - val_loss: 0.4809 - val_f1: 0.1404\n",
      "Epoch 1066/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1913 - f1: 0.7972 - val_loss: 0.4815 - val_f1: 0.1416\n",
      "Epoch 1067/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1925 - f1: 0.7946 - val_loss: 0.4830 - val_f1: 0.1412\n",
      "Epoch 1068/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1937 - f1: 0.7961 - val_loss: 0.4815 - val_f1: 0.1412\n",
      "Epoch 1069/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1921 - f1: 0.7938 - val_loss: 0.4827 - val_f1: 0.1414\n",
      "Epoch 1070/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1914 - f1: 0.7983 - val_loss: 0.4830 - val_f1: 0.1418\n",
      "Epoch 1071/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1941 - f1: 0.7930 - val_loss: 0.4810 - val_f1: 0.1425\n",
      "Epoch 1072/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1947 - f1: 0.7942 - val_loss: 0.4810 - val_f1: 0.1416\n",
      "Epoch 1073/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1947 - f1: 0.7945 - val_loss: 0.4815 - val_f1: 0.1418\n",
      "Epoch 1074/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1927 - f1: 0.7951 - val_loss: 0.4823 - val_f1: 0.1410\n",
      "Epoch 1075/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1943 - f1: 0.7938 - val_loss: 0.4798 - val_f1: 0.1418\n",
      "Epoch 1076/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1924 - f1: 0.7947 - val_loss: 0.4816 - val_f1: 0.1418\n",
      "Epoch 1077/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1897 - f1: 0.7953 - val_loss: 0.4817 - val_f1: 0.1432\n",
      "Epoch 1078/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1937 - f1: 0.7925 - val_loss: 0.4822 - val_f1: 0.1420\n",
      "Epoch 1079/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1932 - f1: 0.7973 - val_loss: 0.4796 - val_f1: 0.1428\n",
      "Epoch 1080/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1910 - f1: 0.7973 - val_loss: 0.4826 - val_f1: 0.1418\n",
      "Epoch 1081/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1918 - f1: 0.7962 - val_loss: 0.4831 - val_f1: 0.1422\n",
      "Epoch 1082/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1942 - f1: 0.7925 - val_loss: 0.4808 - val_f1: 0.1423\n",
      "Epoch 1083/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1903 - f1: 0.7973 - val_loss: 0.4833 - val_f1: 0.1414\n",
      "Epoch 1084/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1879 - f1: 0.7989 - val_loss: 0.4867 - val_f1: 0.1413\n",
      "Epoch 1085/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1924 - f1: 0.7908 - val_loss: 0.4836 - val_f1: 0.1410\n",
      "Epoch 1086/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1934 - f1: 0.7933 - val_loss: 0.4836 - val_f1: 0.1416\n",
      "Epoch 1087/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1911 - f1: 0.7961 - val_loss: 0.4832 - val_f1: 0.1408\n",
      "Epoch 1088/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1923 - f1: 0.7957 - val_loss: 0.4825 - val_f1: 0.1410\n",
      "Epoch 1089/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1931 - f1: 0.7958 - val_loss: 0.4822 - val_f1: 0.1420\n",
      "Epoch 1090/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1914 - f1: 0.7928 - val_loss: 0.4821 - val_f1: 0.1416\n",
      "Epoch 1091/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1900 - f1: 0.7964 - val_loss: 0.4836 - val_f1: 0.1412\n",
      "Epoch 1092/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1916 - f1: 0.7947 - val_loss: 0.4837 - val_f1: 0.1415\n",
      "Epoch 1093/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1936 - f1: 0.7968 - val_loss: 0.4827 - val_f1: 0.1416\n",
      "Epoch 1094/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1924 - f1: 0.7932 - val_loss: 0.4827 - val_f1: 0.1412\n",
      "Epoch 1095/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1922 - f1: 0.7965 - val_loss: 0.4828 - val_f1: 0.1414\n",
      "Epoch 1096/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1922 - f1: 0.7977 - val_loss: 0.4842 - val_f1: 0.1414\n",
      "Epoch 1097/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1914 - f1: 0.7959 - val_loss: 0.4832 - val_f1: 0.1409\n",
      "Epoch 1098/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1919 - f1: 0.7951 - val_loss: 0.4831 - val_f1: 0.1415\n",
      "Epoch 1099/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1923 - f1: 0.7962 - val_loss: 0.4833 - val_f1: 0.1418\n",
      "Epoch 1100/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1910 - f1: 0.7975 - val_loss: 0.4847 - val_f1: 0.1406\n",
      "Epoch 1101/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1903 - f1: 0.8013 - val_loss: 0.4841 - val_f1: 0.1401\n",
      "Epoch 1102/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1930 - f1: 0.7952 - val_loss: 0.4818 - val_f1: 0.1421\n",
      "Epoch 1103/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1909 - f1: 0.7983 - val_loss: 0.4833 - val_f1: 0.1413\n",
      "Epoch 1104/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1937 - f1: 0.7961 - val_loss: 0.4820 - val_f1: 0.1411\n",
      "Epoch 1105/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1919 - f1: 0.7952 - val_loss: 0.4832 - val_f1: 0.1415\n",
      "Epoch 1106/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1899 - f1: 0.8015 - val_loss: 0.4852 - val_f1: 0.1404\n",
      "Epoch 1107/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1897 - f1: 0.8011 - val_loss: 0.4847 - val_f1: 0.1410\n",
      "Epoch 1108/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1915 - f1: 0.7939 - val_loss: 0.4830 - val_f1: 0.1419\n",
      "Epoch 1109/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1911 - f1: 0.7950 - val_loss: 0.4841 - val_f1: 0.1418\n",
      "Epoch 1110/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1923 - f1: 0.7931 - val_loss: 0.4830 - val_f1: 0.1418\n",
      "Epoch 1111/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1893 - f1: 0.7998 - val_loss: 0.4850 - val_f1: 0.1414\n",
      "Epoch 1112/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1901 - f1: 0.8000 - val_loss: 0.4849 - val_f1: 0.1416\n",
      "Epoch 1113/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1905 - f1: 0.7964 - val_loss: 0.4853 - val_f1: 0.1414\n",
      "Epoch 1114/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1932 - f1: 0.7951 - val_loss: 0.4825 - val_f1: 0.1415\n",
      "Epoch 1115/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1885 - f1: 0.8025 - val_loss: 0.4857 - val_f1: 0.1408\n",
      "Epoch 1116/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1915 - f1: 0.7965 - val_loss: 0.4852 - val_f1: 0.1415\n",
      "Epoch 1117/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1919 - f1: 0.7943 - val_loss: 0.4840 - val_f1: 0.1420\n",
      "Epoch 1118/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1901 - f1: 0.7992 - val_loss: 0.4843 - val_f1: 0.1415\n",
      "Epoch 1119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1914 - f1: 0.7969 - val_loss: 0.4835 - val_f1: 0.1409\n",
      "Epoch 1120/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1908 - f1: 0.7916 - val_loss: 0.4831 - val_f1: 0.1404\n",
      "Epoch 1121/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1905 - f1: 0.7953 - val_loss: 0.4854 - val_f1: 0.1417\n",
      "Epoch 1122/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1911 - f1: 0.7974 - val_loss: 0.4843 - val_f1: 0.1410\n",
      "Epoch 1123/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1895 - f1: 0.7973 - val_loss: 0.4831 - val_f1: 0.1421\n",
      "Epoch 1124/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1924 - f1: 0.7946 - val_loss: 0.4842 - val_f1: 0.1411\n",
      "Epoch 1125/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1901 - f1: 0.7973 - val_loss: 0.4840 - val_f1: 0.1415\n",
      "Epoch 1126/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1881 - f1: 0.8010 - val_loss: 0.4840 - val_f1: 0.1418\n",
      "Epoch 1127/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1926 - f1: 0.7984 - val_loss: 0.4843 - val_f1: 0.1407\n",
      "Epoch 1128/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1912 - f1: 0.7993 - val_loss: 0.4842 - val_f1: 0.1407\n",
      "Epoch 1129/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1900 - f1: 0.7969 - val_loss: 0.4845 - val_f1: 0.1416\n",
      "Epoch 1130/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1913 - f1: 0.7932 - val_loss: 0.4832 - val_f1: 0.1425\n",
      "Epoch 1131/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1899 - f1: 0.8023 - val_loss: 0.4851 - val_f1: 0.1420\n",
      "Epoch 1132/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1907 - f1: 0.7980 - val_loss: 0.4860 - val_f1: 0.1418\n",
      "Epoch 1133/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1910 - f1: 0.7985 - val_loss: 0.4837 - val_f1: 0.1418\n",
      "Epoch 1134/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1924 - f1: 0.7930 - val_loss: 0.4844 - val_f1: 0.1413\n",
      "Epoch 1135/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1896 - f1: 0.7997 - val_loss: 0.4843 - val_f1: 0.1409\n",
      "Epoch 1136/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1891 - f1: 0.7996 - val_loss: 0.4849 - val_f1: 0.1419\n",
      "Epoch 1137/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1911 - f1: 0.7954 - val_loss: 0.4860 - val_f1: 0.1411\n",
      "Epoch 1138/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1909 - f1: 0.8008 - val_loss: 0.4857 - val_f1: 0.1412\n",
      "Epoch 1139/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1898 - f1: 0.7986 - val_loss: 0.4859 - val_f1: 0.1409\n",
      "Epoch 1140/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1930 - f1: 0.7947 - val_loss: 0.4840 - val_f1: 0.1405\n",
      "Epoch 1141/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1912 - f1: 0.7957 - val_loss: 0.4842 - val_f1: 0.1413\n",
      "Epoch 1142/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1902 - f1: 0.7962 - val_loss: 0.4843 - val_f1: 0.1412\n",
      "Epoch 1143/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1885 - f1: 0.8013 - val_loss: 0.4856 - val_f1: 0.1415\n",
      "Epoch 1144/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1912 - f1: 0.7963 - val_loss: 0.4838 - val_f1: 0.1422\n",
      "Epoch 1145/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1919 - f1: 0.7958 - val_loss: 0.4839 - val_f1: 0.1415\n",
      "Epoch 1146/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1901 - f1: 0.7996 - val_loss: 0.4846 - val_f1: 0.1419\n",
      "Epoch 1147/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1898 - f1: 0.7979 - val_loss: 0.4838 - val_f1: 0.1420\n",
      "Epoch 1148/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1914 - f1: 0.7984 - val_loss: 0.4827 - val_f1: 0.1415\n",
      "Epoch 1149/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1924 - f1: 0.7974 - val_loss: 0.4825 - val_f1: 0.1408\n",
      "Epoch 1150/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1902 - f1: 0.7981 - val_loss: 0.4846 - val_f1: 0.1411\n",
      "Epoch 1151/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1887 - f1: 0.7999 - val_loss: 0.4851 - val_f1: 0.1421\n",
      "Epoch 1152/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1899 - f1: 0.8011 - val_loss: 0.4861 - val_f1: 0.1409\n",
      "Epoch 1153/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1904 - f1: 0.7977 - val_loss: 0.4864 - val_f1: 0.1413\n",
      "Epoch 1154/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1908 - f1: 0.7978 - val_loss: 0.4837 - val_f1: 0.1408\n",
      "Epoch 1155/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1904 - f1: 0.7959 - val_loss: 0.4867 - val_f1: 0.1412\n",
      "Epoch 1156/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1930 - f1: 0.7899 - val_loss: 0.4831 - val_f1: 0.1419\n",
      "Epoch 1157/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1882 - f1: 0.8023 - val_loss: 0.4847 - val_f1: 0.1411\n",
      "Epoch 1158/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1883 - f1: 0.7994 - val_loss: 0.4866 - val_f1: 0.1405\n",
      "Epoch 1159/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1869 - f1: 0.8036 - val_loss: 0.4880 - val_f1: 0.1409\n",
      "Epoch 1160/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1902 - f1: 0.7990 - val_loss: 0.4854 - val_f1: 0.1418\n",
      "Epoch 1161/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1890 - f1: 0.7996 - val_loss: 0.4853 - val_f1: 0.1421\n",
      "Epoch 1162/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1897 - f1: 0.7978 - val_loss: 0.4854 - val_f1: 0.1415\n",
      "Epoch 1163/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1917 - f1: 0.7973 - val_loss: 0.4841 - val_f1: 0.1409\n",
      "Epoch 1164/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1897 - f1: 0.7978 - val_loss: 0.4854 - val_f1: 0.1414\n",
      "Epoch 1165/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1904 - f1: 0.7978 - val_loss: 0.4846 - val_f1: 0.1424\n",
      "Epoch 1166/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1904 - f1: 0.8003 - val_loss: 0.4839 - val_f1: 0.1415\n",
      "Epoch 1167/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1904 - f1: 0.7932 - val_loss: 0.4858 - val_f1: 0.1415\n",
      "Epoch 1168/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1871 - f1: 0.8017 - val_loss: 0.4855 - val_f1: 0.1414\n",
      "Epoch 1169/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1883 - f1: 0.8010 - val_loss: 0.4879 - val_f1: 0.1419\n",
      "Epoch 1170/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1900 - f1: 0.7994 - val_loss: 0.4876 - val_f1: 0.1412\n",
      "Epoch 1171/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1887 - f1: 0.7997 - val_loss: 0.4880 - val_f1: 0.1411\n",
      "Epoch 1172/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1905 - f1: 0.7966 - val_loss: 0.4861 - val_f1: 0.1424\n",
      "Epoch 1173/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1883 - f1: 0.8008 - val_loss: 0.4876 - val_f1: 0.1420\n",
      "Epoch 1174/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1892 - f1: 0.8006 - val_loss: 0.4878 - val_f1: 0.1408\n",
      "Epoch 1175/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1865 - f1: 0.7998 - val_loss: 0.4889 - val_f1: 0.1409\n",
      "Epoch 1176/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1883 - f1: 0.8013 - val_loss: 0.4889 - val_f1: 0.1407\n",
      "Epoch 1177/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1879 - f1: 0.7997 - val_loss: 0.4879 - val_f1: 0.1411\n",
      "Epoch 1178/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1883 - f1: 0.7994 - val_loss: 0.4888 - val_f1: 0.1408\n",
      "Epoch 1179/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1864 - f1: 0.8004 - val_loss: 0.4902 - val_f1: 0.1407\n",
      "Epoch 1180/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1908 - f1: 0.7954 - val_loss: 0.4881 - val_f1: 0.1418\n",
      "Epoch 1181/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1888 - f1: 0.7996 - val_loss: 0.4872 - val_f1: 0.1428\n",
      "Epoch 1182/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1871 - f1: 0.8017 - val_loss: 0.4892 - val_f1: 0.1413\n",
      "Epoch 1183/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1896 - f1: 0.7992 - val_loss: 0.4885 - val_f1: 0.1411\n",
      "Epoch 1184/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1864 - f1: 0.8001 - val_loss: 0.4877 - val_f1: 0.1420\n",
      "Epoch 1185/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1907 - f1: 0.7967 - val_loss: 0.4863 - val_f1: 0.1421\n",
      "Epoch 1186/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1877 - f1: 0.8000 - val_loss: 0.4878 - val_f1: 0.1421\n",
      "Epoch 1187/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1892 - f1: 0.7981 - val_loss: 0.4890 - val_f1: 0.1412\n",
      "Epoch 1188/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1869 - f1: 0.8012 - val_loss: 0.4891 - val_f1: 0.1415\n",
      "Epoch 1189/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1899 - f1: 0.8001 - val_loss: 0.4886 - val_f1: 0.1413\n",
      "Epoch 1190/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1880 - f1: 0.8017 - val_loss: 0.4889 - val_f1: 0.1407\n",
      "Epoch 1191/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1877 - f1: 0.8035 - val_loss: 0.4883 - val_f1: 0.1418\n",
      "Epoch 1192/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1892 - f1: 0.8014 - val_loss: 0.4874 - val_f1: 0.1411\n",
      "Epoch 1193/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1879 - f1: 0.8009 - val_loss: 0.4870 - val_f1: 0.1417\n",
      "Epoch 1194/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1897 - f1: 0.7980 - val_loss: 0.4865 - val_f1: 0.1420\n",
      "Epoch 1195/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1894 - f1: 0.7981 - val_loss: 0.4868 - val_f1: 0.1416\n",
      "Epoch 1196/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1881 - f1: 0.7997 - val_loss: 0.4872 - val_f1: 0.1421\n",
      "Epoch 1197/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1898 - f1: 0.7976 - val_loss: 0.4877 - val_f1: 0.1410\n",
      "Epoch 1198/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1904 - f1: 0.8009 - val_loss: 0.4877 - val_f1: 0.1407\n",
      "Epoch 1199/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1862 - f1: 0.8000 - val_loss: 0.4868 - val_f1: 0.1427\n",
      "Epoch 1200/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1862 - f1: 0.8065 - val_loss: 0.4891 - val_f1: 0.1421\n",
      "Epoch 1201/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1878 - f1: 0.8033 - val_loss: 0.4881 - val_f1: 0.1409\n",
      "Epoch 1202/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1878 - f1: 0.8021 - val_loss: 0.4888 - val_f1: 0.1418\n",
      "Epoch 1203/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1878 - f1: 0.8001 - val_loss: 0.4873 - val_f1: 0.1420\n",
      "Epoch 1204/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1887 - f1: 0.8041 - val_loss: 0.4897 - val_f1: 0.1417\n",
      "Epoch 1205/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1878 - f1: 0.8008 - val_loss: 0.4888 - val_f1: 0.1423\n",
      "Epoch 1206/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1857 - f1: 0.8019 - val_loss: 0.4876 - val_f1: 0.1420\n",
      "Epoch 1207/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1878 - f1: 0.8006 - val_loss: 0.4893 - val_f1: 0.1423\n",
      "Epoch 1208/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1897 - f1: 0.7946 - val_loss: 0.4871 - val_f1: 0.1427\n",
      "Epoch 1209/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1870 - f1: 0.7996 - val_loss: 0.4894 - val_f1: 0.1418\n",
      "Epoch 1210/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1880 - f1: 0.7999 - val_loss: 0.4892 - val_f1: 0.1410\n",
      "Epoch 1211/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1872 - f1: 0.8029 - val_loss: 0.4864 - val_f1: 0.1419\n",
      "Epoch 1212/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1831 - f1: 0.8076 - val_loss: 0.4895 - val_f1: 0.1408\n",
      "Epoch 1213/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1871 - f1: 0.7989 - val_loss: 0.4896 - val_f1: 0.1416\n",
      "Epoch 1214/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1890 - f1: 0.7967 - val_loss: 0.4891 - val_f1: 0.1412\n",
      "Epoch 1215/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1884 - f1: 0.7988 - val_loss: 0.4907 - val_f1: 0.1413\n",
      "Epoch 1216/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.1874 - f1: 0.79 - 2s 38us/step - loss: 0.1876 - f1: 0.7989 - val_loss: 0.4890 - val_f1: 0.1419\n",
      "Epoch 1217/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1875 - f1: 0.7998 - val_loss: 0.4889 - val_f1: 0.1416\n",
      "Epoch 1218/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1881 - f1: 0.8042 - val_loss: 0.4878 - val_f1: 0.1421\n",
      "Epoch 1219/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1867 - f1: 0.8038 - val_loss: 0.4889 - val_f1: 0.1408\n",
      "Epoch 1220/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1874 - f1: 0.7996 - val_loss: 0.4890 - val_f1: 0.1411\n",
      "Epoch 1221/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1871 - f1: 0.7977 - val_loss: 0.4884 - val_f1: 0.1419\n",
      "Epoch 1222/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1863 - f1: 0.8023 - val_loss: 0.4879 - val_f1: 0.1409\n",
      "Epoch 1223/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1849 - f1: 0.8022 - val_loss: 0.4883 - val_f1: 0.1433\n",
      "Epoch 1224/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1864 - f1: 0.7996 - val_loss: 0.4913 - val_f1: 0.1417\n",
      "Epoch 1225/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1888 - f1: 0.8002 - val_loss: 0.4892 - val_f1: 0.1407\n",
      "Epoch 1226/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1873 - f1: 0.8025 - val_loss: 0.4878 - val_f1: 0.1414\n",
      "Epoch 1227/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1879 - f1: 0.8026 - val_loss: 0.4896 - val_f1: 0.1412\n",
      "Epoch 1228/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1876 - f1: 0.8009 - val_loss: 0.4898 - val_f1: 0.1420\n",
      "Epoch 1229/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1876 - f1: 0.8019 - val_loss: 0.4886 - val_f1: 0.1418\n",
      "Epoch 1230/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1863 - f1: 0.8016 - val_loss: 0.4909 - val_f1: 0.1406\n",
      "Epoch 1231/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.1873 - f1: 0.8013 - val_loss: 0.4895 - val_f1: 0.1419\n",
      "Epoch 1232/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1848 - f1: 0.8036 - val_loss: 0.4917 - val_f1: 0.1418\n",
      "Epoch 1233/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1873 - f1: 0.8003 - val_loss: 0.4933 - val_f1: 0.1414\n",
      "Epoch 1234/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1900 - f1: 0.7960 - val_loss: 0.4902 - val_f1: 0.1409\n",
      "Epoch 1235/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1839 - f1: 0.8030 - val_loss: 0.4915 - val_f1: 0.1418\n",
      "Epoch 1236/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1894 - f1: 0.8005 - val_loss: 0.4896 - val_f1: 0.1415\n",
      "Epoch 1237/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1872 - f1: 0.8045 - val_loss: 0.4890 - val_f1: 0.1409\n",
      "Epoch 1238/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1896 - f1: 0.7983 - val_loss: 0.4887 - val_f1: 0.1415\n",
      "Epoch 1239/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1896 - f1: 0.8002 - val_loss: 0.4892 - val_f1: 0.1406\n",
      "Epoch 1240/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1859 - f1: 0.8019 - val_loss: 0.4895 - val_f1: 0.1409\n",
      "Epoch 1241/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1877 - f1: 0.7999 - val_loss: 0.4893 - val_f1: 0.1411\n",
      "Epoch 1242/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1902 - f1: 0.7970 - val_loss: 0.4888 - val_f1: 0.1416\n",
      "Epoch 1243/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1894 - f1: 0.7991 - val_loss: 0.4890 - val_f1: 0.1407\n",
      "Epoch 1244/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1846 - f1: 0.8041 - val_loss: 0.4897 - val_f1: 0.1407\n",
      "Epoch 1245/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1832 - f1: 0.8066 - val_loss: 0.4896 - val_f1: 0.1408\n",
      "Epoch 1246/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1871 - f1: 0.8002 - val_loss: 0.4887 - val_f1: 0.1411\n",
      "Epoch 1247/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1884 - f1: 0.8011 - val_loss: 0.4901 - val_f1: 0.1399\n",
      "Epoch 1248/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1864 - f1: 0.8035 - val_loss: 0.4918 - val_f1: 0.1402\n",
      "Epoch 1249/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1864 - f1: 0.7973 - val_loss: 0.4885 - val_f1: 0.1416\n",
      "Epoch 1250/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1882 - f1: 0.8019 - val_loss: 0.4896 - val_f1: 0.1406\n",
      "Epoch 1251/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1883 - f1: 0.7994 - val_loss: 0.4893 - val_f1: 0.1415\n",
      "Epoch 1252/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1853 - f1: 0.8029 - val_loss: 0.4907 - val_f1: 0.1411\n",
      "Epoch 1253/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1867 - f1: 0.8035 - val_loss: 0.4913 - val_f1: 0.1406\n",
      "Epoch 1254/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1867 - f1: 0.8033 - val_loss: 0.4909 - val_f1: 0.1415\n",
      "Epoch 1255/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1834 - f1: 0.8052 - val_loss: 0.4923 - val_f1: 0.1405\n",
      "Epoch 1256/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1853 - f1: 0.8043 - val_loss: 0.4924 - val_f1: 0.1402\n",
      "Epoch 1257/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1879 - f1: 0.7989 - val_loss: 0.4931 - val_f1: 0.1403\n",
      "Epoch 1258/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1878 - f1: 0.8021 - val_loss: 0.4914 - val_f1: 0.1415\n",
      "Epoch 1259/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1847 - f1: 0.8036 - val_loss: 0.4918 - val_f1: 0.1411\n",
      "Epoch 1260/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1846 - f1: 0.8035 - val_loss: 0.4930 - val_f1: 0.1408\n",
      "Epoch 1261/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1874 - f1: 0.8026 - val_loss: 0.4906 - val_f1: 0.1403\n",
      "Epoch 1262/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1869 - f1: 0.8000 - val_loss: 0.4901 - val_f1: 0.1417\n",
      "Epoch 1263/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1854 - f1: 0.8064 - val_loss: 0.4912 - val_f1: 0.1410\n",
      "Epoch 1264/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1867 - f1: 0.8006 - val_loss: 0.4908 - val_f1: 0.1410\n",
      "Epoch 1265/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1850 - f1: 0.8062 - val_loss: 0.4926 - val_f1: 0.1406\n",
      "Epoch 1266/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1883 - f1: 0.8003 - val_loss: 0.4904 - val_f1: 0.1416\n",
      "Epoch 1267/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1841 - f1: 0.8101 - val_loss: 0.4913 - val_f1: 0.1403\n",
      "Epoch 1268/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1849 - f1: 0.8057 - val_loss: 0.4924 - val_f1: 0.1401\n",
      "Epoch 1269/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1840 - f1: 0.8050 - val_loss: 0.4931 - val_f1: 0.1410\n",
      "Epoch 1270/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1868 - f1: 0.8000 - val_loss: 0.4915 - val_f1: 0.1410\n",
      "Epoch 1271/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1864 - f1: 0.8001 - val_loss: 0.4916 - val_f1: 0.1421\n",
      "Epoch 1272/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1853 - f1: 0.8046 - val_loss: 0.4920 - val_f1: 0.1409\n",
      "Epoch 1273/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1866 - f1: 0.8031 - val_loss: 0.4927 - val_f1: 0.1408\n",
      "Epoch 1274/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1836 - f1: 0.8101 - val_loss: 0.4927 - val_f1: 0.1404\n",
      "Epoch 1275/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1864 - f1: 0.8023 - val_loss: 0.4902 - val_f1: 0.1414\n",
      "Epoch 1276/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1886 - f1: 0.7978 - val_loss: 0.4901 - val_f1: 0.1412\n",
      "Epoch 1277/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1831 - f1: 0.8058 - val_loss: 0.4917 - val_f1: 0.1409\n",
      "Epoch 1278/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1872 - f1: 0.8054 - val_loss: 0.4919 - val_f1: 0.1412\n",
      "Epoch 1279/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1890 - f1: 0.7990 - val_loss: 0.4890 - val_f1: 0.1412\n",
      "Epoch 1280/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1871 - f1: 0.8029 - val_loss: 0.4910 - val_f1: 0.1403\n",
      "Epoch 1281/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1857 - f1: 0.8045 - val_loss: 0.4910 - val_f1: 0.1411\n",
      "Epoch 1282/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1851 - f1: 0.8026 - val_loss: 0.4912 - val_f1: 0.1412\n",
      "Epoch 1283/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1838 - f1: 0.8054 - val_loss: 0.4919 - val_f1: 0.1414\n",
      "Epoch 1284/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1864 - f1: 0.8033 - val_loss: 0.4919 - val_f1: 0.1408\n",
      "Epoch 1285/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1838 - f1: 0.8060 - val_loss: 0.4927 - val_f1: 0.1407\n",
      "Epoch 1286/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1868 - f1: 0.8039 - val_loss: 0.4910 - val_f1: 0.1414\n",
      "Epoch 1287/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1832 - f1: 0.8074 - val_loss: 0.4929 - val_f1: 0.1409\n",
      "Epoch 1288/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1842 - f1: 0.8066 - val_loss: 0.4927 - val_f1: 0.1414\n",
      "Epoch 1289/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1850 - f1: 0.8021 - val_loss: 0.4941 - val_f1: 0.1415\n",
      "Epoch 1290/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1870 - f1: 0.8037 - val_loss: 0.4912 - val_f1: 0.1415\n",
      "Epoch 1291/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1871 - f1: 0.8012 - val_loss: 0.4904 - val_f1: 0.1412\n",
      "Epoch 1292/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1867 - f1: 0.8034 - val_loss: 0.4916 - val_f1: 0.1401\n",
      "Epoch 1293/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1848 - f1: 0.8083 - val_loss: 0.4931 - val_f1: 0.1398\n",
      "Epoch 1294/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1863 - f1: 0.8034 - val_loss: 0.4921 - val_f1: 0.1412\n",
      "Epoch 1295/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1854 - f1: 0.8030 - val_loss: 0.4919 - val_f1: 0.1409\n",
      "Epoch 1296/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1874 - f1: 0.8047 - val_loss: 0.4902 - val_f1: 0.1410\n",
      "Epoch 1297/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1854 - f1: 0.8035 - val_loss: 0.4895 - val_f1: 0.1417\n",
      "Epoch 1298/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1864 - f1: 0.8007 - val_loss: 0.4915 - val_f1: 0.1421\n",
      "Epoch 1299/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1861 - f1: 0.7990 - val_loss: 0.4926 - val_f1: 0.1413\n",
      "Epoch 1300/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1834 - f1: 0.8046 - val_loss: 0.4935 - val_f1: 0.1407\n",
      "Epoch 1301/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1861 - f1: 0.8038 - val_loss: 0.4917 - val_f1: 0.1417\n",
      "Epoch 1302/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1856 - f1: 0.8053 - val_loss: 0.4921 - val_f1: 0.1415\n",
      "Epoch 1303/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1860 - f1: 0.8036 - val_loss: 0.4921 - val_f1: 0.1413\n",
      "Epoch 1304/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1863 - f1: 0.8047 - val_loss: 0.4919 - val_f1: 0.1407\n",
      "Epoch 1305/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1862 - f1: 0.8028 - val_loss: 0.4923 - val_f1: 0.1408\n",
      "Epoch 1306/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1857 - f1: 0.8050 - val_loss: 0.4919 - val_f1: 0.1403\n",
      "Epoch 1307/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1861 - f1: 0.7993 - val_loss: 0.4917 - val_f1: 0.1416\n",
      "Epoch 1308/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1851 - f1: 0.8015 - val_loss: 0.4922 - val_f1: 0.1406\n",
      "Epoch 1309/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1828 - f1: 0.8067 - val_loss: 0.4918 - val_f1: 0.1415\n",
      "Epoch 1310/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1878 - f1: 0.8016 - val_loss: 0.4924 - val_f1: 0.1406\n",
      "Epoch 1311/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1863 - f1: 0.8047 - val_loss: 0.4907 - val_f1: 0.1414\n",
      "Epoch 1312/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1847 - f1: 0.8031 - val_loss: 0.4914 - val_f1: 0.1415\n",
      "Epoch 1313/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1831 - f1: 0.8050 - val_loss: 0.4941 - val_f1: 0.1409\n",
      "Epoch 1314/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1873 - f1: 0.8019 - val_loss: 0.4934 - val_f1: 0.1408\n",
      "Epoch 1315/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1843 - f1: 0.8021 - val_loss: 0.4932 - val_f1: 0.1423\n",
      "Epoch 1316/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1836 - f1: 0.8066 - val_loss: 0.4935 - val_f1: 0.1419\n",
      "Epoch 1317/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1842 - f1: 0.8050 - val_loss: 0.4921 - val_f1: 0.1415\n",
      "Epoch 1318/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1823 - f1: 0.8079 - val_loss: 0.4945 - val_f1: 0.1415\n",
      "Epoch 1319/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1831 - f1: 0.8060 - val_loss: 0.4963 - val_f1: 0.1415\n",
      "Epoch 1320/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1846 - f1: 0.8050 - val_loss: 0.4936 - val_f1: 0.1416\n",
      "Epoch 1321/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1831 - f1: 0.8054 - val_loss: 0.4944 - val_f1: 0.1415\n",
      "Epoch 1322/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1839 - f1: 0.8105 - val_loss: 0.4952 - val_f1: 0.1410\n",
      "Epoch 1323/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1838 - f1: 0.8055 - val_loss: 0.4932 - val_f1: 0.1400\n",
      "Epoch 1324/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1858 - f1: 0.8059 - val_loss: 0.4944 - val_f1: 0.1408\n",
      "Epoch 1325/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1825 - f1: 0.8074 - val_loss: 0.4963 - val_f1: 0.1409\n",
      "Epoch 1326/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1844 - f1: 0.8046 - val_loss: 0.4948 - val_f1: 0.1408\n",
      "Epoch 1327/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1847 - f1: 0.8053 - val_loss: 0.4939 - val_f1: 0.1418\n",
      "Epoch 1328/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1852 - f1: 0.8039 - val_loss: 0.4940 - val_f1: 0.1404\n",
      "Epoch 1329/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.1835 - f1: 0.8073 - val_loss: 0.4920 - val_f1: 0.1419\n",
      "Epoch 1330/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1826 - f1: 0.8097 - val_loss: 0.4944 - val_f1: 0.1407\n",
      "Epoch 1331/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1822 - f1: 0.8104 - val_loss: 0.4943 - val_f1: 0.1404\n",
      "Epoch 1332/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1840 - f1: 0.8035 - val_loss: 0.4939 - val_f1: 0.1417\n",
      "Epoch 1333/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1841 - f1: 0.8103 - val_loss: 0.4937 - val_f1: 0.1414\n",
      "Epoch 1334/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1875 - f1: 0.8027 - val_loss: 0.4927 - val_f1: 0.1412\n",
      "Epoch 1335/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1851 - f1: 0.8076 - val_loss: 0.4924 - val_f1: 0.1409\n",
      "Epoch 1336/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1824 - f1: 0.8049 - val_loss: 0.4923 - val_f1: 0.1417\n",
      "Epoch 1337/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1841 - f1: 0.8052 - val_loss: 0.4940 - val_f1: 0.1423\n",
      "Epoch 1338/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1854 - f1: 0.8045 - val_loss: 0.4930 - val_f1: 0.1417\n",
      "Epoch 1339/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1848 - f1: 0.8046 - val_loss: 0.4938 - val_f1: 0.1413\n",
      "Epoch 1340/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1857 - f1: 0.8001 - val_loss: 0.4923 - val_f1: 0.1424\n",
      "Epoch 1341/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1846 - f1: 0.8056 - val_loss: 0.4923 - val_f1: 0.1414\n",
      "Epoch 1342/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1823 - f1: 0.8051 - val_loss: 0.4956 - val_f1: 0.1414\n",
      "Epoch 1343/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1852 - f1: 0.8002 - val_loss: 0.4939 - val_f1: 0.1416\n",
      "Epoch 1344/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.1850 - f1: 0.8066 - val_loss: 0.4941 - val_f1: 0.1418\n",
      "Epoch 1345/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.1817 - f1: 0.8052 - val_loss: 0.4952 - val_f1: 0.1420\n",
      "Epoch 1346/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1850 - f1: 0.8055 - val_loss: 0.4936 - val_f1: 0.1418\n",
      "Epoch 1347/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1832 - f1: 0.8059 - val_loss: 0.4945 - val_f1: 0.1412\n",
      "Epoch 1348/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1842 - f1: 0.8060 - val_loss: 0.4947 - val_f1: 0.1408\n",
      "Epoch 1349/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1837 - f1: 0.8033 - val_loss: 0.4938 - val_f1: 0.1403\n",
      "Epoch 1350/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1849 - f1: 0.7985 - val_loss: 0.4920 - val_f1: 0.1411\n",
      "Epoch 1351/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1867 - f1: 0.8024 - val_loss: 0.4927 - val_f1: 0.1410\n",
      "Epoch 1352/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1827 - f1: 0.8060 - val_loss: 0.4943 - val_f1: 0.1412\n",
      "Epoch 1353/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1838 - f1: 0.8073 - val_loss: 0.4945 - val_f1: 0.1411\n",
      "Epoch 1354/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1812 - f1: 0.8061 - val_loss: 0.4964 - val_f1: 0.1407\n",
      "Epoch 1355/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1827 - f1: 0.8033 - val_loss: 0.4951 - val_f1: 0.1415\n",
      "Epoch 1356/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1857 - f1: 0.8029 - val_loss: 0.4937 - val_f1: 0.1410\n",
      "Epoch 1357/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1836 - f1: 0.8060 - val_loss: 0.4935 - val_f1: 0.1419\n",
      "Epoch 1358/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1844 - f1: 0.8027 - val_loss: 0.4941 - val_f1: 0.1424\n",
      "Epoch 1359/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1843 - f1: 0.8038 - val_loss: 0.4941 - val_f1: 0.1406\n",
      "Epoch 1360/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1844 - f1: 0.8051 - val_loss: 0.4945 - val_f1: 0.1417\n",
      "Epoch 1361/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1831 - f1: 0.8067 - val_loss: 0.4951 - val_f1: 0.1415\n",
      "Epoch 1362/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1811 - f1: 0.8068 - val_loss: 0.4953 - val_f1: 0.1418\n",
      "Epoch 1363/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1834 - f1: 0.8068 - val_loss: 0.4953 - val_f1: 0.1415\n",
      "Epoch 1364/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1826 - f1: 0.8070 - val_loss: 0.4965 - val_f1: 0.1416\n",
      "Epoch 1365/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1844 - f1: 0.8064 - val_loss: 0.4949 - val_f1: 0.1408\n",
      "Epoch 1366/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1828 - f1: 0.8071 - val_loss: 0.4934 - val_f1: 0.1418\n",
      "Epoch 1367/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1829 - f1: 0.8063 - val_loss: 0.4949 - val_f1: 0.1421\n",
      "Epoch 1368/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1825 - f1: 0.8041 - val_loss: 0.4966 - val_f1: 0.1417\n",
      "Epoch 1369/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1822 - f1: 0.8100 - val_loss: 0.4962 - val_f1: 0.1412\n",
      "Epoch 1370/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1825 - f1: 0.8078 - val_loss: 0.4959 - val_f1: 0.1407\n",
      "Epoch 1371/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1833 - f1: 0.8072 - val_loss: 0.4957 - val_f1: 0.1415\n",
      "Epoch 1372/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1852 - f1: 0.8041 - val_loss: 0.4944 - val_f1: 0.1417\n",
      "Epoch 1373/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1834 - f1: 0.8059 - val_loss: 0.4950 - val_f1: 0.1406\n",
      "Epoch 1374/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1811 - f1: 0.8082 - val_loss: 0.4964 - val_f1: 0.1414\n",
      "Epoch 1375/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1839 - f1: 0.8027 - val_loss: 0.4930 - val_f1: 0.1413\n",
      "Epoch 1376/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1816 - f1: 0.8063 - val_loss: 0.4954 - val_f1: 0.1421\n",
      "Epoch 1377/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1839 - f1: 0.8033 - val_loss: 0.4958 - val_f1: 0.1410\n",
      "Epoch 1378/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1809 - f1: 0.8070 - val_loss: 0.4968 - val_f1: 0.1409\n",
      "Epoch 1379/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1800 - f1: 0.8144 - val_loss: 0.4956 - val_f1: 0.1411\n",
      "Epoch 1380/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1796 - f1: 0.8077 - val_loss: 0.4980 - val_f1: 0.1415\n",
      "Epoch 1381/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1839 - f1: 0.8049 - val_loss: 0.4954 - val_f1: 0.1414\n",
      "Epoch 1382/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1833 - f1: 0.8078 - val_loss: 0.4958 - val_f1: 0.1409\n",
      "Epoch 1383/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1838 - f1: 0.8039 - val_loss: 0.4965 - val_f1: 0.1409\n",
      "Epoch 1384/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1833 - f1: 0.8078 - val_loss: 0.4959 - val_f1: 0.1413\n",
      "Epoch 1385/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1841 - f1: 0.8067 - val_loss: 0.4951 - val_f1: 0.1412\n",
      "Epoch 1386/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1836 - f1: 0.8090 - val_loss: 0.4940 - val_f1: 0.1415\n",
      "Epoch 1387/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1821 - f1: 0.8080 - val_loss: 0.4981 - val_f1: 0.1411\n",
      "Epoch 1388/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1806 - f1: 0.8074 - val_loss: 0.4971 - val_f1: 0.1408\n",
      "Epoch 1389/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.1857 - f1: 0.8043 - val_loss: 0.4943 - val_f1: 0.1409\n",
      "Epoch 1390/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.1857 - f1: 0.8035 - val_loss: 0.4946 - val_f1: 0.1415\n",
      "Epoch 1391/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.1866 - f1: 0.8043 - val_loss: 0.4943 - val_f1: 0.1414\n",
      "Epoch 1392/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1844 - f1: 0.8059 - val_loss: 0.4930 - val_f1: 0.1409\n",
      "Epoch 1393/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1806 - f1: 0.8073 - val_loss: 0.4924 - val_f1: 0.1418\n",
      "Epoch 1394/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1824 - f1: 0.8082 - val_loss: 0.4942 - val_f1: 0.1418\n",
      "Epoch 1395/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1807 - f1: 0.8085 - val_loss: 0.4951 - val_f1: 0.1413\n",
      "Epoch 1396/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1825 - f1: 0.8080 - val_loss: 0.4959 - val_f1: 0.1411\n",
      "Epoch 1397/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1825 - f1: 0.8092 - val_loss: 0.4961 - val_f1: 0.1408\n",
      "Epoch 1398/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1795 - f1: 0.8113 - val_loss: 0.4980 - val_f1: 0.1412\n",
      "Epoch 1399/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1826 - f1: 0.8099 - val_loss: 0.4981 - val_f1: 0.1400\n",
      "Epoch 1400/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1787 - f1: 0.8126 - val_loss: 0.4995 - val_f1: 0.1402\n",
      "Epoch 1401/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1825 - f1: 0.8085 - val_loss: 0.4978 - val_f1: 0.1407\n",
      "Epoch 1402/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1839 - f1: 0.8059 - val_loss: 0.4967 - val_f1: 0.1419\n",
      "Epoch 1403/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1812 - f1: 0.8075 - val_loss: 0.4964 - val_f1: 0.1413\n",
      "Epoch 1404/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.1815 - f1: 0.8078 - val_loss: 0.4972 - val_f1: 0.1418\n",
      "Epoch 1405/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1834 - f1: 0.8066 - val_loss: 0.4963 - val_f1: 0.1415\n",
      "Epoch 1406/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1831 - f1: 0.8046 - val_loss: 0.4962 - val_f1: 0.1419\n",
      "Epoch 1407/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1818 - f1: 0.8108 - val_loss: 0.4969 - val_f1: 0.1420\n",
      "Epoch 1408/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1796 - f1: 0.8108 - val_loss: 0.4991 - val_f1: 0.1410\n",
      "Epoch 1409/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1807 - f1: 0.8095 - val_loss: 0.4981 - val_f1: 0.1421\n",
      "Epoch 1410/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1827 - f1: 0.8077 - val_loss: 0.4986 - val_f1: 0.1421\n",
      "Epoch 1411/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1847 - f1: 0.8052 - val_loss: 0.4952 - val_f1: 0.1407\n",
      "Epoch 1412/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1835 - f1: 0.8054 - val_loss: 0.4972 - val_f1: 0.1416\n",
      "Epoch 1413/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1823 - f1: 0.8070 - val_loss: 0.4957 - val_f1: 0.1416\n",
      "Epoch 1414/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1824 - f1: 0.8065 - val_loss: 0.4957 - val_f1: 0.1424\n",
      "Epoch 1415/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1844 - f1: 0.8071 - val_loss: 0.4942 - val_f1: 0.1419\n",
      "Epoch 1416/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1811 - f1: 0.8073 - val_loss: 0.4960 - val_f1: 0.1419\n",
      "Epoch 1417/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1830 - f1: 0.8054 - val_loss: 0.4968 - val_f1: 0.1414\n",
      "Epoch 1418/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1811 - f1: 0.8064 - val_loss: 0.4968 - val_f1: 0.1416\n",
      "Epoch 1419/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1841 - f1: 0.8052 - val_loss: 0.4967 - val_f1: 0.1413\n",
      "Epoch 1420/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1822 - f1: 0.8075 - val_loss: 0.4958 - val_f1: 0.1421\n",
      "Epoch 1421/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1794 - f1: 0.8138 - val_loss: 0.4968 - val_f1: 0.1413\n",
      "Epoch 1422/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1838 - f1: 0.8051 - val_loss: 0.4978 - val_f1: 0.1407\n",
      "Epoch 1423/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1801 - f1: 0.8108 - val_loss: 0.4969 - val_f1: 0.1415\n",
      "Epoch 1424/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1804 - f1: 0.8076 - val_loss: 0.4975 - val_f1: 0.1414\n",
      "Epoch 1425/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1804 - f1: 0.8067 - val_loss: 0.4980 - val_f1: 0.1421\n",
      "Epoch 1426/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1841 - f1: 0.8069 - val_loss: 0.4963 - val_f1: 0.1424\n",
      "Epoch 1427/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1813 - f1: 0.8082 - val_loss: 0.4963 - val_f1: 0.1420\n",
      "Epoch 1428/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1820 - f1: 0.8086 - val_loss: 0.4976 - val_f1: 0.1414\n",
      "Epoch 1429/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1831 - f1: 0.8080 - val_loss: 0.4987 - val_f1: 0.1411\n",
      "Epoch 1430/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1793 - f1: 0.8101 - val_loss: 0.4984 - val_f1: 0.1423\n",
      "Epoch 1431/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1813 - f1: 0.8066 - val_loss: 0.4980 - val_f1: 0.1425\n",
      "Epoch 1432/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1819 - f1: 0.8093 - val_loss: 0.4964 - val_f1: 0.1416\n",
      "Epoch 1433/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1829 - f1: 0.8074 - val_loss: 0.4969 - val_f1: 0.1421\n",
      "Epoch 1434/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1814 - f1: 0.8103 - val_loss: 0.4969 - val_f1: 0.1412\n",
      "Epoch 1435/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1824 - f1: 0.8049 - val_loss: 0.4979 - val_f1: 0.1416\n",
      "Epoch 1436/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1823 - f1: 0.8110 - val_loss: 0.4964 - val_f1: 0.1411\n",
      "Epoch 1437/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1845 - f1: 0.8034 - val_loss: 0.4965 - val_f1: 0.1409\n",
      "Epoch 1438/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1844 - f1: 0.8081 - val_loss: 0.4949 - val_f1: 0.1414\n",
      "Epoch 1439/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1831 - f1: 0.8065 - val_loss: 0.4957 - val_f1: 0.1409\n",
      "Epoch 1440/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1828 - f1: 0.8060 - val_loss: 0.4968 - val_f1: 0.1411\n",
      "Epoch 1441/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1813 - f1: 0.8089 - val_loss: 0.4981 - val_f1: 0.1407\n",
      "Epoch 1442/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1815 - f1: 0.8122 - val_loss: 0.4979 - val_f1: 0.1403\n",
      "Epoch 1443/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1830 - f1: 0.8070 - val_loss: 0.4981 - val_f1: 0.1401\n",
      "Epoch 1444/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1809 - f1: 0.8088 - val_loss: 0.4942 - val_f1: 0.1420\n",
      "Epoch 1445/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1811 - f1: 0.8118 - val_loss: 0.4965 - val_f1: 0.1418\n",
      "Epoch 1446/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1777 - f1: 0.8103 - val_loss: 0.4967 - val_f1: 0.1420\n",
      "Epoch 1447/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1818 - f1: 0.8094 - val_loss: 0.4970 - val_f1: 0.1416\n",
      "Epoch 1448/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1808 - f1: 0.8101 - val_loss: 0.4969 - val_f1: 0.1420\n",
      "Epoch 1449/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1817 - f1: 0.8093 - val_loss: 0.4996 - val_f1: 0.1416\n",
      "Epoch 1450/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1806 - f1: 0.8090 - val_loss: 0.4987 - val_f1: 0.1416\n",
      "Epoch 1451/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1817 - f1: 0.8074 - val_loss: 0.4981 - val_f1: 0.1417\n",
      "Epoch 1452/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1799 - f1: 0.8100 - val_loss: 0.4967 - val_f1: 0.1414\n",
      "Epoch 1453/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.1820 - f1: 0.8082 - val_loss: 0.4984 - val_f1: 0.1422\n",
      "Epoch 1454/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1808 - f1: 0.8100 - val_loss: 0.4956 - val_f1: 0.1414\n",
      "Epoch 1455/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1825 - f1: 0.8065 - val_loss: 0.4962 - val_f1: 0.1418\n",
      "Epoch 1456/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1803 - f1: 0.8092 - val_loss: 0.5005 - val_f1: 0.1404\n",
      "Epoch 1457/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1831 - f1: 0.8103 - val_loss: 0.4969 - val_f1: 0.1418\n",
      "Epoch 1458/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1799 - f1: 0.8105 - val_loss: 0.4977 - val_f1: 0.1410\n",
      "Epoch 1459/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1803 - f1: 0.8140 - val_loss: 0.5007 - val_f1: 0.1406\n",
      "Epoch 1460/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1818 - f1: 0.8079 - val_loss: 0.5002 - val_f1: 0.1409\n",
      "Epoch 1461/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1794 - f1: 0.8086 - val_loss: 0.4997 - val_f1: 0.1415\n",
      "Epoch 1462/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1796 - f1: 0.8093 - val_loss: 0.5017 - val_f1: 0.1408\n",
      "Epoch 1463/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1796 - f1: 0.8084 - val_loss: 0.5006 - val_f1: 0.1412\n",
      "Epoch 1464/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1790 - f1: 0.8112 - val_loss: 0.5009 - val_f1: 0.1419\n",
      "Epoch 1465/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1801 - f1: 0.8097 - val_loss: 0.5008 - val_f1: 0.1418\n",
      "Epoch 1466/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1802 - f1: 0.8114 - val_loss: 0.4999 - val_f1: 0.1422\n",
      "Epoch 1467/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1816 - f1: 0.8072 - val_loss: 0.4986 - val_f1: 0.1419\n",
      "Epoch 1468/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1813 - f1: 0.8087 - val_loss: 0.4971 - val_f1: 0.1423\n",
      "Epoch 1469/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1806 - f1: 0.8098 - val_loss: 0.4991 - val_f1: 0.1418\n",
      "Epoch 1470/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1809 - f1: 0.8099 - val_loss: 0.4994 - val_f1: 0.1415\n",
      "Epoch 1471/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1807 - f1: 0.8073 - val_loss: 0.4995 - val_f1: 0.1422\n",
      "Epoch 1472/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1809 - f1: 0.8070 - val_loss: 0.4975 - val_f1: 0.1420\n",
      "Epoch 1473/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1819 - f1: 0.8070 - val_loss: 0.4980 - val_f1: 0.1417\n",
      "Epoch 1474/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1800 - f1: 0.8108 - val_loss: 0.4978 - val_f1: 0.1419\n",
      "Epoch 1475/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1815 - f1: 0.8049 - val_loss: 0.4987 - val_f1: 0.1407\n",
      "Epoch 1476/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1847 - f1: 0.8043 - val_loss: 0.4981 - val_f1: 0.1416\n",
      "Epoch 1477/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1789 - f1: 0.8117 - val_loss: 0.4980 - val_f1: 0.1414\n",
      "Epoch 1478/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1789 - f1: 0.8110 - val_loss: 0.5000 - val_f1: 0.1416\n",
      "Epoch 1479/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1824 - f1: 0.8114 - val_loss: 0.4985 - val_f1: 0.1424\n",
      "Epoch 1480/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1810 - f1: 0.8095 - val_loss: 0.4978 - val_f1: 0.1413\n",
      "Epoch 1481/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1801 - f1: 0.8058 - val_loss: 0.4995 - val_f1: 0.1420\n",
      "Epoch 1482/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1793 - f1: 0.8104 - val_loss: 0.5007 - val_f1: 0.1411\n",
      "Epoch 1483/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1809 - f1: 0.8105 - val_loss: 0.4998 - val_f1: 0.1405\n",
      "Epoch 1484/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1799 - f1: 0.8106 - val_loss: 0.4979 - val_f1: 0.1422\n",
      "Epoch 1485/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1813 - f1: 0.8139 - val_loss: 0.4985 - val_f1: 0.1420\n",
      "Epoch 1486/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1815 - f1: 0.8071 - val_loss: 0.4996 - val_f1: 0.1417\n",
      "Epoch 1487/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1792 - f1: 0.8097 - val_loss: 0.5010 - val_f1: 0.1409\n",
      "Epoch 1488/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1805 - f1: 0.8120 - val_loss: 0.4999 - val_f1: 0.1417\n",
      "Epoch 1489/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1833 - f1: 0.8085 - val_loss: 0.4988 - val_f1: 0.1418\n",
      "Epoch 1490/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1818 - f1: 0.8085 - val_loss: 0.4993 - val_f1: 0.1414\n",
      "Epoch 1491/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1825 - f1: 0.8059 - val_loss: 0.4988 - val_f1: 0.1412\n",
      "Epoch 1492/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1823 - f1: 0.8057 - val_loss: 0.4982 - val_f1: 0.1411\n",
      "Epoch 1493/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1782 - f1: 0.8132 - val_loss: 0.4998 - val_f1: 0.1422\n",
      "Epoch 1494/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1784 - f1: 0.8121 - val_loss: 0.4991 - val_f1: 0.1421\n",
      "Epoch 1495/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1828 - f1: 0.8109 - val_loss: 0.4969 - val_f1: 0.1424\n",
      "Epoch 1496/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1796 - f1: 0.8072 - val_loss: 0.5010 - val_f1: 0.1415\n",
      "Epoch 1497/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1835 - f1: 0.8050 - val_loss: 0.4985 - val_f1: 0.1420\n",
      "Epoch 1498/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1782 - f1: 0.8105 - val_loss: 0.5008 - val_f1: 0.1414\n",
      "Epoch 1499/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1781 - f1: 0.8116 - val_loss: 0.5022 - val_f1: 0.1406\n",
      "Epoch 1500/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1769 - f1: 0.8139 - val_loss: 0.5023 - val_f1: 0.1412\n",
      "Epoch 1501/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1820 - f1: 0.8091 - val_loss: 0.4992 - val_f1: 0.1418\n",
      "Epoch 1502/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1798 - f1: 0.8101 - val_loss: 0.5004 - val_f1: 0.1418\n",
      "Epoch 1503/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1776 - f1: 0.8163 - val_loss: 0.5032 - val_f1: 0.1409\n",
      "Epoch 1504/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1821 - f1: 0.8100 - val_loss: 0.4995 - val_f1: 0.1417\n",
      "Epoch 1505/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1784 - f1: 0.8110 - val_loss: 0.5007 - val_f1: 0.1417\n",
      "Epoch 1506/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1811 - f1: 0.8122 - val_loss: 0.5014 - val_f1: 0.1410\n",
      "Epoch 1507/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1816 - f1: 0.8069 - val_loss: 0.4991 - val_f1: 0.1401\n",
      "Epoch 1508/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1789 - f1: 0.8138 - val_loss: 0.5012 - val_f1: 0.1410\n",
      "Epoch 1509/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1796 - f1: 0.8126 - val_loss: 0.5015 - val_f1: 0.1416\n",
      "Epoch 1510/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1805 - f1: 0.8088 - val_loss: 0.5012 - val_f1: 0.1409\n",
      "Epoch 1511/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1802 - f1: 0.8100 - val_loss: 0.4997 - val_f1: 0.1414\n",
      "Epoch 1512/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1807 - f1: 0.8066 - val_loss: 0.4987 - val_f1: 0.1411\n",
      "Epoch 1513/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1780 - f1: 0.8122 - val_loss: 0.4999 - val_f1: 0.1420\n",
      "Epoch 1514/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1801 - f1: 0.8095 - val_loss: 0.5013 - val_f1: 0.1406\n",
      "Epoch 1515/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1812 - f1: 0.8112 - val_loss: 0.5013 - val_f1: 0.1400\n",
      "Epoch 1516/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1765 - f1: 0.8137 - val_loss: 0.5046 - val_f1: 0.1404\n",
      "Epoch 1517/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1791 - f1: 0.8110 - val_loss: 0.5032 - val_f1: 0.1414\n",
      "Epoch 1518/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1780 - f1: 0.8161 - val_loss: 0.5013 - val_f1: 0.1414\n",
      "Epoch 1519/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1820 - f1: 0.8059 - val_loss: 0.5006 - val_f1: 0.1412\n",
      "Epoch 1520/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1795 - f1: 0.8082 - val_loss: 0.5012 - val_f1: 0.1411\n",
      "Epoch 1521/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1811 - f1: 0.8133 - val_loss: 0.4990 - val_f1: 0.1411\n",
      "Epoch 1522/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1796 - f1: 0.8122 - val_loss: 0.5004 - val_f1: 0.1415\n",
      "Epoch 1523/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1785 - f1: 0.8144 - val_loss: 0.5012 - val_f1: 0.1421\n",
      "Epoch 1524/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1787 - f1: 0.8091 - val_loss: 0.5004 - val_f1: 0.1422\n",
      "Epoch 1525/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1796 - f1: 0.8122 - val_loss: 0.4994 - val_f1: 0.1416\n",
      "Epoch 1526/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1806 - f1: 0.8099 - val_loss: 0.5008 - val_f1: 0.1411\n",
      "Epoch 1527/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1798 - f1: 0.8088 - val_loss: 0.4989 - val_f1: 0.1416\n",
      "Epoch 1528/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1791 - f1: 0.8125 - val_loss: 0.5016 - val_f1: 0.1411\n",
      "Epoch 1529/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1801 - f1: 0.8094 - val_loss: 0.5016 - val_f1: 0.1415\n",
      "Epoch 1530/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1790 - f1: 0.8110 - val_loss: 0.5004 - val_f1: 0.1414\n",
      "Epoch 1531/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1769 - f1: 0.8120 - val_loss: 0.5021 - val_f1: 0.1408\n",
      "Epoch 1532/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1796 - f1: 0.8087 - val_loss: 0.4988 - val_f1: 0.1405\n",
      "Epoch 1533/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1776 - f1: 0.8097 - val_loss: 0.5010 - val_f1: 0.1410\n",
      "Epoch 1534/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1812 - f1: 0.8061 - val_loss: 0.5018 - val_f1: 0.1411\n",
      "Epoch 1535/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1803 - f1: 0.8093 - val_loss: 0.5011 - val_f1: 0.1405\n",
      "Epoch 1536/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1794 - f1: 0.8103 - val_loss: 0.5001 - val_f1: 0.1419\n",
      "Epoch 1537/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1804 - f1: 0.8081 - val_loss: 0.4994 - val_f1: 0.1420\n",
      "Epoch 1538/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1766 - f1: 0.8132 - val_loss: 0.5032 - val_f1: 0.1406\n",
      "Epoch 1539/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1784 - f1: 0.8097 - val_loss: 0.5014 - val_f1: 0.1414\n",
      "Epoch 1540/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1820 - f1: 0.8087 - val_loss: 0.5013 - val_f1: 0.1409\n",
      "Epoch 1541/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1803 - f1: 0.8084 - val_loss: 0.5016 - val_f1: 0.1415\n",
      "Epoch 1542/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1789 - f1: 0.8144 - val_loss: 0.5038 - val_f1: 0.1408\n",
      "Epoch 1543/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1783 - f1: 0.8086 - val_loss: 0.5017 - val_f1: 0.1413\n",
      "Epoch 1544/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1776 - f1: 0.8101 - val_loss: 0.5020 - val_f1: 0.1419\n",
      "Epoch 1545/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1787 - f1: 0.8144 - val_loss: 0.5034 - val_f1: 0.1413\n",
      "Epoch 1546/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1782 - f1: 0.8101 - val_loss: 0.5026 - val_f1: 0.1419\n",
      "Epoch 1547/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1794 - f1: 0.8123 - val_loss: 0.5017 - val_f1: 0.1418\n",
      "Epoch 1548/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1797 - f1: 0.8092 - val_loss: 0.5007 - val_f1: 0.1417\n",
      "Epoch 1549/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1815 - f1: 0.8103 - val_loss: 0.5005 - val_f1: 0.1416\n",
      "Epoch 1550/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1799 - f1: 0.8121 - val_loss: 0.5001 - val_f1: 0.1410\n",
      "Epoch 1551/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.1795 - f1: 0.8111 - val_loss: 0.5002 - val_f1: 0.1411\n",
      "Epoch 1552/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1814 - f1: 0.8072 - val_loss: 0.5001 - val_f1: 0.1414\n",
      "Epoch 1553/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1793 - f1: 0.8124 - val_loss: 0.5009 - val_f1: 0.1407\n",
      "Epoch 1554/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1786 - f1: 0.8108 - val_loss: 0.4999 - val_f1: 0.1411\n",
      "Epoch 1555/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1798 - f1: 0.8103 - val_loss: 0.4986 - val_f1: 0.1418\n",
      "Epoch 1556/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1762 - f1: 0.8159 - val_loss: 0.5018 - val_f1: 0.1419\n",
      "Epoch 1557/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1757 - f1: 0.8144 - val_loss: 0.5030 - val_f1: 0.1410\n",
      "Epoch 1558/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1782 - f1: 0.8123 - val_loss: 0.5014 - val_f1: 0.1416\n",
      "Epoch 1559/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1787 - f1: 0.8134 - val_loss: 0.5025 - val_f1: 0.1416\n",
      "Epoch 1560/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1808 - f1: 0.8108 - val_loss: 0.4997 - val_f1: 0.1419\n",
      "Epoch 1561/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1791 - f1: 0.8117 - val_loss: 0.5013 - val_f1: 0.1421\n",
      "Epoch 1562/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1812 - f1: 0.8114 - val_loss: 0.5009 - val_f1: 0.1419\n",
      "Epoch 1563/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1787 - f1: 0.8125 - val_loss: 0.5018 - val_f1: 0.1425\n",
      "Epoch 1564/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1769 - f1: 0.8137 - val_loss: 0.5029 - val_f1: 0.1417\n",
      "Epoch 1565/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1793 - f1: 0.8081 - val_loss: 0.5034 - val_f1: 0.1410\n",
      "Epoch 1566/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1760 - f1: 0.8143 - val_loss: 0.5032 - val_f1: 0.1416\n",
      "Epoch 1567/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1790 - f1: 0.8123 - val_loss: 0.5005 - val_f1: 0.1424\n",
      "Epoch 1568/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1772 - f1: 0.8169 - val_loss: 0.5022 - val_f1: 0.1418\n",
      "Epoch 1569/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1795 - f1: 0.8106 - val_loss: 0.5022 - val_f1: 0.1417\n",
      "Epoch 1570/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1794 - f1: 0.8144 - val_loss: 0.5039 - val_f1: 0.1409\n",
      "Epoch 1571/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1763 - f1: 0.8131 - val_loss: 0.5045 - val_f1: 0.1408\n",
      "Epoch 1572/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1795 - f1: 0.8125 - val_loss: 0.5032 - val_f1: 0.1419\n",
      "Epoch 1573/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1797 - f1: 0.8088 - val_loss: 0.5026 - val_f1: 0.1417\n",
      "Epoch 1574/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1791 - f1: 0.8097 - val_loss: 0.5012 - val_f1: 0.1403\n",
      "Epoch 1575/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1789 - f1: 0.8111 - val_loss: 0.5031 - val_f1: 0.1409\n",
      "Epoch 1576/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1811 - f1: 0.8078 - val_loss: 0.5009 - val_f1: 0.1417\n",
      "Epoch 1577/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1788 - f1: 0.8127 - val_loss: 0.5018 - val_f1: 0.1412\n",
      "Epoch 1578/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1788 - f1: 0.8129 - val_loss: 0.5009 - val_f1: 0.1417\n",
      "Epoch 1579/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1777 - f1: 0.8113 - val_loss: 0.5028 - val_f1: 0.1410\n",
      "Epoch 1580/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1786 - f1: 0.8142 - val_loss: 0.5019 - val_f1: 0.1421\n",
      "Epoch 1581/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1790 - f1: 0.8089 - val_loss: 0.5020 - val_f1: 0.1415\n",
      "Epoch 1582/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1799 - f1: 0.8086 - val_loss: 0.5027 - val_f1: 0.1414\n",
      "Epoch 1583/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1790 - f1: 0.8122 - val_loss: 0.5015 - val_f1: 0.1402\n",
      "Epoch 1584/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1783 - f1: 0.8122 - val_loss: 0.5026 - val_f1: 0.1420\n",
      "Epoch 1585/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1773 - f1: 0.8151 - val_loss: 0.5041 - val_f1: 0.1409\n",
      "Epoch 1586/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1774 - f1: 0.8154 - val_loss: 0.5023 - val_f1: 0.1422\n",
      "Epoch 1587/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1796 - f1: 0.8092 - val_loss: 0.5024 - val_f1: 0.1418\n",
      "Epoch 1588/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1778 - f1: 0.8088 - val_loss: 0.5024 - val_f1: 0.1410\n",
      "Epoch 1589/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1807 - f1: 0.8100 - val_loss: 0.5017 - val_f1: 0.1416\n",
      "Epoch 1590/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1790 - f1: 0.8097 - val_loss: 0.5011 - val_f1: 0.1406\n",
      "Epoch 1591/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1788 - f1: 0.8107 - val_loss: 0.5004 - val_f1: 0.1408\n",
      "Epoch 1592/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1792 - f1: 0.8113 - val_loss: 0.5024 - val_f1: 0.1409\n",
      "Epoch 1593/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1778 - f1: 0.8138 - val_loss: 0.5025 - val_f1: 0.1418\n",
      "Epoch 1594/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1778 - f1: 0.8177 - val_loss: 0.5014 - val_f1: 0.1410\n",
      "Epoch 1595/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1783 - f1: 0.8141 - val_loss: 0.5036 - val_f1: 0.1416\n",
      "Epoch 1596/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1806 - f1: 0.8124 - val_loss: 0.5021 - val_f1: 0.1416\n",
      "Epoch 1597/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1788 - f1: 0.8101 - val_loss: 0.5025 - val_f1: 0.1418\n",
      "Epoch 1598/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1785 - f1: 0.8124 - val_loss: 0.5022 - val_f1: 0.1416\n",
      "Epoch 1599/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1763 - f1: 0.8143 - val_loss: 0.5018 - val_f1: 0.1414\n",
      "Epoch 1600/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1789 - f1: 0.8083 - val_loss: 0.5028 - val_f1: 0.1413\n",
      "Epoch 1601/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1766 - f1: 0.8157 - val_loss: 0.5037 - val_f1: 0.1415\n",
      "Epoch 1602/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1800 - f1: 0.8107 - val_loss: 0.5024 - val_f1: 0.1417\n",
      "Epoch 1603/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1776 - f1: 0.8142 - val_loss: 0.5040 - val_f1: 0.1415\n",
      "Epoch 1604/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1783 - f1: 0.8127 - val_loss: 0.5048 - val_f1: 0.1417\n",
      "Epoch 1605/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1785 - f1: 0.8096 - val_loss: 0.5034 - val_f1: 0.1411\n",
      "Epoch 1606/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1772 - f1: 0.8102 - val_loss: 0.5034 - val_f1: 0.1413\n",
      "Epoch 1607/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1784 - f1: 0.8124 - val_loss: 0.5028 - val_f1: 0.1414\n",
      "Epoch 1608/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1766 - f1: 0.8127 - val_loss: 0.5054 - val_f1: 0.1407\n",
      "Epoch 1609/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1765 - f1: 0.8115 - val_loss: 0.5045 - val_f1: 0.1414\n",
      "Epoch 1610/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1785 - f1: 0.8080 - val_loss: 0.5056 - val_f1: 0.1411\n",
      "Epoch 1611/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1779 - f1: 0.8109 - val_loss: 0.5033 - val_f1: 0.1415\n",
      "Epoch 1612/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1810 - f1: 0.8067 - val_loss: 0.5020 - val_f1: 0.1426\n",
      "Epoch 1613/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1787 - f1: 0.8107 - val_loss: 0.5028 - val_f1: 0.1413\n",
      "Epoch 1614/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1778 - f1: 0.8129 - val_loss: 0.5027 - val_f1: 0.1414\n",
      "Epoch 1615/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1763 - f1: 0.8116 - val_loss: 0.5033 - val_f1: 0.1421\n",
      "Epoch 1616/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1744 - f1: 0.8163 - val_loss: 0.5049 - val_f1: 0.1415\n",
      "Epoch 1617/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1785 - f1: 0.8120 - val_loss: 0.5026 - val_f1: 0.1420\n",
      "Epoch 1618/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1789 - f1: 0.8121 - val_loss: 0.5023 - val_f1: 0.1418\n",
      "Epoch 1619/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1751 - f1: 0.8172 - val_loss: 0.5062 - val_f1: 0.1404\n",
      "Epoch 1620/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1788 - f1: 0.8097 - val_loss: 0.5027 - val_f1: 0.1415\n",
      "Epoch 1621/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1763 - f1: 0.8157 - val_loss: 0.5033 - val_f1: 0.1415\n",
      "Epoch 1622/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1781 - f1: 0.8127 - val_loss: 0.5040 - val_f1: 0.1411\n",
      "Epoch 1623/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1771 - f1: 0.8168 - val_loss: 0.5030 - val_f1: 0.1419\n",
      "Epoch 1624/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1761 - f1: 0.8135 - val_loss: 0.5042 - val_f1: 0.1413\n",
      "Epoch 1625/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1793 - f1: 0.8097 - val_loss: 0.5063 - val_f1: 0.1406\n",
      "Epoch 1626/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1776 - f1: 0.8114 - val_loss: 0.5049 - val_f1: 0.1411\n",
      "Epoch 1627/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1764 - f1: 0.8129 - val_loss: 0.5042 - val_f1: 0.1400\n",
      "Epoch 1628/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1789 - f1: 0.8106 - val_loss: 0.5048 - val_f1: 0.1407\n",
      "Epoch 1629/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1773 - f1: 0.8130 - val_loss: 0.5029 - val_f1: 0.1417\n",
      "Epoch 1630/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1812 - f1: 0.8073 - val_loss: 0.5018 - val_f1: 0.1420\n",
      "Epoch 1631/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1790 - f1: 0.8098 - val_loss: 0.5016 - val_f1: 0.1415\n",
      "Epoch 1632/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1773 - f1: 0.8149 - val_loss: 0.5036 - val_f1: 0.1416\n",
      "Epoch 1633/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1782 - f1: 0.8156 - val_loss: 0.5043 - val_f1: 0.1406\n",
      "Epoch 1634/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1758 - f1: 0.8159 - val_loss: 0.5048 - val_f1: 0.1402\n",
      "Epoch 1635/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1762 - f1: 0.8145 - val_loss: 0.5058 - val_f1: 0.1398\n",
      "Epoch 1636/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1775 - f1: 0.8107 - val_loss: 0.5037 - val_f1: 0.1419\n",
      "Epoch 1637/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1768 - f1: 0.8154 - val_loss: 0.5033 - val_f1: 0.1415\n",
      "Epoch 1638/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1759 - f1: 0.8161 - val_loss: 0.5042 - val_f1: 0.1410\n",
      "Epoch 1639/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1767 - f1: 0.8168 - val_loss: 0.5046 - val_f1: 0.1412\n",
      "Epoch 1640/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1816 - f1: 0.8074 - val_loss: 0.5031 - val_f1: 0.1415\n",
      "Epoch 1641/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1756 - f1: 0.8127 - val_loss: 0.5037 - val_f1: 0.1412\n",
      "Epoch 1642/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1741 - f1: 0.8181 - val_loss: 0.5062 - val_f1: 0.1414\n",
      "Epoch 1643/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1746 - f1: 0.8138 - val_loss: 0.5065 - val_f1: 0.1411\n",
      "Epoch 1644/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1757 - f1: 0.8177 - val_loss: 0.5057 - val_f1: 0.1407\n",
      "Epoch 1645/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1759 - f1: 0.8160 - val_loss: 0.5076 - val_f1: 0.1399\n",
      "Epoch 1646/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1793 - f1: 0.8088 - val_loss: 0.5045 - val_f1: 0.1412\n",
      "Epoch 1647/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1782 - f1: 0.8139 - val_loss: 0.5038 - val_f1: 0.1404\n",
      "Epoch 1648/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1793 - f1: 0.8117 - val_loss: 0.5039 - val_f1: 0.1409\n",
      "Epoch 1649/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1756 - f1: 0.8141 - val_loss: 0.5033 - val_f1: 0.1416\n",
      "Epoch 1650/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1778 - f1: 0.8120 - val_loss: 0.5038 - val_f1: 0.1410\n",
      "Epoch 1651/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1781 - f1: 0.8117 - val_loss: 0.5027 - val_f1: 0.1409\n",
      "Epoch 1652/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1775 - f1: 0.8152 - val_loss: 0.5053 - val_f1: 0.1418\n",
      "Epoch 1653/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1762 - f1: 0.8157 - val_loss: 0.5057 - val_f1: 0.1403\n",
      "Epoch 1654/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1802 - f1: 0.8092 - val_loss: 0.5021 - val_f1: 0.1411\n",
      "Epoch 1655/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1762 - f1: 0.8172 - val_loss: 0.5054 - val_f1: 0.1419\n",
      "Epoch 1656/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1800 - f1: 0.8108 - val_loss: 0.5030 - val_f1: 0.1413\n",
      "Epoch 1657/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1782 - f1: 0.8132 - val_loss: 0.5034 - val_f1: 0.1408\n",
      "Epoch 1658/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1772 - f1: 0.8107 - val_loss: 0.5039 - val_f1: 0.1413\n",
      "Epoch 1659/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1743 - f1: 0.8185 - val_loss: 0.5053 - val_f1: 0.1403\n",
      "Epoch 1660/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1761 - f1: 0.8103 - val_loss: 0.5053 - val_f1: 0.1407\n",
      "Epoch 1661/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1789 - f1: 0.8135 - val_loss: 0.5038 - val_f1: 0.1410\n",
      "Epoch 1662/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1772 - f1: 0.8132 - val_loss: 0.5034 - val_f1: 0.1404\n",
      "Epoch 1663/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1769 - f1: 0.8134 - val_loss: 0.5026 - val_f1: 0.1414\n",
      "Epoch 1664/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1770 - f1: 0.8158 - val_loss: 0.5036 - val_f1: 0.1410\n",
      "Epoch 1665/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1789 - f1: 0.8104 - val_loss: 0.5030 - val_f1: 0.1420\n",
      "Epoch 1666/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1768 - f1: 0.8146 - val_loss: 0.5055 - val_f1: 0.1404\n",
      "Epoch 1667/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1778 - f1: 0.8127 - val_loss: 0.5039 - val_f1: 0.1415\n",
      "Epoch 1668/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1764 - f1: 0.8153 - val_loss: 0.5045 - val_f1: 0.1419\n",
      "Epoch 1669/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1777 - f1: 0.8130 - val_loss: 0.5047 - val_f1: 0.1411\n",
      "Epoch 1670/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1752 - f1: 0.8174 - val_loss: 0.5050 - val_f1: 0.1408\n",
      "Epoch 1671/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1761 - f1: 0.8121 - val_loss: 0.5056 - val_f1: 0.1417\n",
      "Epoch 1672/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1776 - f1: 0.8110 - val_loss: 0.5043 - val_f1: 0.1422\n",
      "Epoch 1673/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1770 - f1: 0.8151 - val_loss: 0.5047 - val_f1: 0.1418\n",
      "Epoch 1674/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1762 - f1: 0.8145 - val_loss: 0.5050 - val_f1: 0.1409\n",
      "Epoch 1675/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.1797 - f1: 0.8140 - val_loss: 0.5041 - val_f1: 0.1412\n",
      "Epoch 1676/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1780 - f1: 0.8157 - val_loss: 0.5043 - val_f1: 0.1412\n",
      "Epoch 1677/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1774 - f1: 0.8134 - val_loss: 0.5047 - val_f1: 0.1405\n",
      "Epoch 1678/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1776 - f1: 0.8109 - val_loss: 0.5001 - val_f1: 0.1418\n",
      "Epoch 1679/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1776 - f1: 0.8092 - val_loss: 0.5023 - val_f1: 0.1419\n",
      "Epoch 1680/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1766 - f1: 0.8134 - val_loss: 0.5033 - val_f1: 0.1417\n",
      "Epoch 1681/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1762 - f1: 0.8186 - val_loss: 0.5043 - val_f1: 0.1420\n",
      "Epoch 1682/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1768 - f1: 0.8138 - val_loss: 0.5045 - val_f1: 0.1406\n",
      "Epoch 1683/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1771 - f1: 0.8141 - val_loss: 0.5037 - val_f1: 0.1407\n",
      "Epoch 1684/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1766 - f1: 0.8142 - val_loss: 0.5034 - val_f1: 0.1405\n",
      "Epoch 1685/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1773 - f1: 0.8119 - val_loss: 0.5054 - val_f1: 0.1405\n",
      "Epoch 1686/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1759 - f1: 0.8123 - val_loss: 0.5065 - val_f1: 0.1405\n",
      "Epoch 1687/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1764 - f1: 0.8097 - val_loss: 0.5064 - val_f1: 0.1419\n",
      "Epoch 1688/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1758 - f1: 0.8142 - val_loss: 0.5066 - val_f1: 0.1417\n",
      "Epoch 1689/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1729 - f1: 0.8177 - val_loss: 0.5083 - val_f1: 0.1410\n",
      "Epoch 1690/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1773 - f1: 0.8130 - val_loss: 0.5059 - val_f1: 0.1422\n",
      "Epoch 1691/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1784 - f1: 0.8105 - val_loss: 0.5051 - val_f1: 0.1415\n",
      "Epoch 1692/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1745 - f1: 0.8167 - val_loss: 0.5056 - val_f1: 0.1415\n",
      "Epoch 1693/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1728 - f1: 0.8220 - val_loss: 0.5059 - val_f1: 0.1417\n",
      "Epoch 1694/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1730 - f1: 0.8160 - val_loss: 0.5074 - val_f1: 0.1406\n",
      "Epoch 1695/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1785 - f1: 0.8120 - val_loss: 0.5056 - val_f1: 0.1422\n",
      "Epoch 1696/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1779 - f1: 0.8136 - val_loss: 0.5062 - val_f1: 0.1425\n",
      "Epoch 1697/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1776 - f1: 0.8129 - val_loss: 0.5049 - val_f1: 0.1412\n",
      "Epoch 1698/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1745 - f1: 0.8148 - val_loss: 0.5070 - val_f1: 0.1417\n",
      "Epoch 1699/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1780 - f1: 0.8157 - val_loss: 0.5039 - val_f1: 0.1418\n",
      "Epoch 1700/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1780 - f1: 0.8143 - val_loss: 0.5051 - val_f1: 0.1411\n",
      "Epoch 1701/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1751 - f1: 0.8164 - val_loss: 0.5050 - val_f1: 0.1413\n",
      "Epoch 1702/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1773 - f1: 0.8113 - val_loss: 0.5036 - val_f1: 0.1415\n",
      "Epoch 1703/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1751 - f1: 0.8151 - val_loss: 0.5053 - val_f1: 0.1412\n",
      "Epoch 1704/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1767 - f1: 0.8124 - val_loss: 0.5045 - val_f1: 0.1416\n",
      "Epoch 1705/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1773 - f1: 0.8122 - val_loss: 0.5043 - val_f1: 0.1419\n",
      "Epoch 1706/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1760 - f1: 0.8180 - val_loss: 0.5050 - val_f1: 0.1410\n",
      "Epoch 1707/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1783 - f1: 0.8115 - val_loss: 0.5033 - val_f1: 0.1412\n",
      "Epoch 1708/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1766 - f1: 0.8132 - val_loss: 0.5033 - val_f1: 0.1417\n",
      "Epoch 1709/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1765 - f1: 0.8170 - val_loss: 0.5043 - val_f1: 0.1413\n",
      "Epoch 1710/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1783 - f1: 0.8111 - val_loss: 0.5043 - val_f1: 0.1421\n",
      "Epoch 1711/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1753 - f1: 0.8124 - val_loss: 0.5048 - val_f1: 0.1421\n",
      "Epoch 1712/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1763 - f1: 0.8126 - val_loss: 0.5057 - val_f1: 0.1413\n",
      "Epoch 1713/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1763 - f1: 0.8146 - val_loss: 0.5061 - val_f1: 0.1415\n",
      "Epoch 1714/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1736 - f1: 0.8174 - val_loss: 0.5066 - val_f1: 0.1414\n",
      "Epoch 1715/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1744 - f1: 0.8158 - val_loss: 0.5085 - val_f1: 0.1415\n",
      "Epoch 1716/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1745 - f1: 0.8174 - val_loss: 0.5077 - val_f1: 0.1405\n",
      "Epoch 1717/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1779 - f1: 0.8121 - val_loss: 0.5030 - val_f1: 0.1414\n",
      "Epoch 1718/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1725 - f1: 0.8197 - val_loss: 0.5060 - val_f1: 0.1413\n",
      "Epoch 1719/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1747 - f1: 0.8179 - val_loss: 0.5079 - val_f1: 0.1412\n",
      "Epoch 1720/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1780 - f1: 0.8138 - val_loss: 0.5058 - val_f1: 0.1417\n",
      "Epoch 1721/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1749 - f1: 0.8165 - val_loss: 0.5074 - val_f1: 0.1416\n",
      "Epoch 1722/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1752 - f1: 0.8160 - val_loss: 0.5052 - val_f1: 0.1422\n",
      "Epoch 1723/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1752 - f1: 0.8156 - val_loss: 0.5051 - val_f1: 0.1417\n",
      "Epoch 1724/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1749 - f1: 0.8166 - val_loss: 0.5072 - val_f1: 0.1407\n",
      "Epoch 1725/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1781 - f1: 0.8151 - val_loss: 0.5066 - val_f1: 0.1413\n",
      "Epoch 1726/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1777 - f1: 0.8116 - val_loss: 0.5057 - val_f1: 0.1410\n",
      "Epoch 1727/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1755 - f1: 0.8173 - val_loss: 0.5061 - val_f1: 0.1413\n",
      "Epoch 1728/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1740 - f1: 0.8166 - val_loss: 0.5076 - val_f1: 0.1405\n",
      "Epoch 1729/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1761 - f1: 0.8129 - val_loss: 0.5062 - val_f1: 0.1415\n",
      "Epoch 1730/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1725 - f1: 0.8221 - val_loss: 0.5083 - val_f1: 0.1416\n",
      "Epoch 1731/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1724 - f1: 0.8177 - val_loss: 0.5076 - val_f1: 0.1420\n",
      "Epoch 1732/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1754 - f1: 0.8141 - val_loss: 0.5075 - val_f1: 0.1414\n",
      "Epoch 1733/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1754 - f1: 0.8167 - val_loss: 0.5065 - val_f1: 0.1404\n",
      "Epoch 1734/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1770 - f1: 0.8133 - val_loss: 0.5070 - val_f1: 0.1415\n",
      "Epoch 1735/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1746 - f1: 0.8175 - val_loss: 0.5078 - val_f1: 0.1402\n",
      "Epoch 1736/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1746 - f1: 0.8147 - val_loss: 0.5063 - val_f1: 0.1414\n",
      "Epoch 1737/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1746 - f1: 0.8179 - val_loss: 0.5064 - val_f1: 0.1408\n",
      "Epoch 1738/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1742 - f1: 0.8199 - val_loss: 0.5076 - val_f1: 0.1412\n",
      "Epoch 1739/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1783 - f1: 0.8091 - val_loss: 0.5075 - val_f1: 0.1399\n",
      "Epoch 1740/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1751 - f1: 0.8154 - val_loss: 0.5079 - val_f1: 0.1401\n",
      "Epoch 1741/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1755 - f1: 0.8146 - val_loss: 0.5073 - val_f1: 0.1413\n",
      "Epoch 1742/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1753 - f1: 0.8149 - val_loss: 0.5080 - val_f1: 0.1417\n",
      "Epoch 1743/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1763 - f1: 0.8158 - val_loss: 0.5068 - val_f1: 0.1408\n",
      "Epoch 1744/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1741 - f1: 0.8191 - val_loss: 0.5087 - val_f1: 0.1409\n",
      "Epoch 1745/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1742 - f1: 0.8154 - val_loss: 0.5085 - val_f1: 0.1408\n",
      "Epoch 1746/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1758 - f1: 0.8160 - val_loss: 0.5088 - val_f1: 0.1410\n",
      "Epoch 1747/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1775 - f1: 0.8156 - val_loss: 0.5069 - val_f1: 0.1398\n",
      "Epoch 1748/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1747 - f1: 0.8136 - val_loss: 0.5088 - val_f1: 0.1400\n",
      "Epoch 1749/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1712 - f1: 0.8207 - val_loss: 0.5101 - val_f1: 0.1402\n",
      "Epoch 1750/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1769 - f1: 0.8150 - val_loss: 0.5083 - val_f1: 0.1414\n",
      "Epoch 1751/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1784 - f1: 0.8147 - val_loss: 0.5066 - val_f1: 0.1408\n",
      "Epoch 1752/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1752 - f1: 0.8161 - val_loss: 0.5070 - val_f1: 0.1409\n",
      "Epoch 1753/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1739 - f1: 0.8145 - val_loss: 0.5080 - val_f1: 0.1408\n",
      "Epoch 1754/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1744 - f1: 0.8140 - val_loss: 0.5093 - val_f1: 0.1401\n",
      "Epoch 1755/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1753 - f1: 0.8141 - val_loss: 0.5081 - val_f1: 0.1411\n",
      "Epoch 1756/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1771 - f1: 0.8123 - val_loss: 0.5078 - val_f1: 0.1407\n",
      "Epoch 1757/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1770 - f1: 0.8170 - val_loss: 0.5059 - val_f1: 0.1414\n",
      "Epoch 1758/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1735 - f1: 0.8208 - val_loss: 0.5069 - val_f1: 0.1404\n",
      "Epoch 1759/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1764 - f1: 0.8136 - val_loss: 0.5049 - val_f1: 0.1406\n",
      "Epoch 1760/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1747 - f1: 0.8142 - val_loss: 0.5064 - val_f1: 0.1416\n",
      "Epoch 1761/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1756 - f1: 0.8133 - val_loss: 0.5077 - val_f1: 0.1403\n",
      "Epoch 1762/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1756 - f1: 0.8154 - val_loss: 0.5070 - val_f1: 0.1415\n",
      "Epoch 1763/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1742 - f1: 0.8117 - val_loss: 0.5077 - val_f1: 0.1410\n",
      "Epoch 1764/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1722 - f1: 0.8186 - val_loss: 0.5103 - val_f1: 0.1413\n",
      "Epoch 1765/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1756 - f1: 0.8159 - val_loss: 0.5080 - val_f1: 0.1415\n",
      "Epoch 1766/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1740 - f1: 0.8123 - val_loss: 0.5098 - val_f1: 0.1416\n",
      "Epoch 1767/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1733 - f1: 0.8177 - val_loss: 0.5104 - val_f1: 0.1410\n",
      "Epoch 1768/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1762 - f1: 0.8154 - val_loss: 0.5080 - val_f1: 0.1419\n",
      "Epoch 1769/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1723 - f1: 0.8176 - val_loss: 0.5092 - val_f1: 0.1411\n",
      "Epoch 1770/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1771 - f1: 0.8109 - val_loss: 0.5078 - val_f1: 0.1411\n",
      "Epoch 1771/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1741 - f1: 0.8191 - val_loss: 0.5090 - val_f1: 0.1412\n",
      "Epoch 1772/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1728 - f1: 0.8175 - val_loss: 0.5082 - val_f1: 0.1410\n",
      "Epoch 1773/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1747 - f1: 0.8162 - val_loss: 0.5069 - val_f1: 0.1410\n",
      "Epoch 1774/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1767 - f1: 0.8153 - val_loss: 0.5075 - val_f1: 0.1410\n",
      "Epoch 1775/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1757 - f1: 0.8172 - val_loss: 0.5088 - val_f1: 0.1414\n",
      "Epoch 1776/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1729 - f1: 0.8149 - val_loss: 0.5085 - val_f1: 0.1414\n",
      "Epoch 1777/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1771 - f1: 0.8125 - val_loss: 0.5072 - val_f1: 0.1410\n",
      "Epoch 1778/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1746 - f1: 0.8182 - val_loss: 0.5063 - val_f1: 0.1413\n",
      "Epoch 1779/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1739 - f1: 0.8198 - val_loss: 0.5054 - val_f1: 0.1416\n",
      "Epoch 1780/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1750 - f1: 0.8167 - val_loss: 0.5100 - val_f1: 0.1403\n",
      "Epoch 1781/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1761 - f1: 0.8163 - val_loss: 0.5051 - val_f1: 0.1416\n",
      "Epoch 1782/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1771 - f1: 0.8146 - val_loss: 0.5052 - val_f1: 0.1420\n",
      "Epoch 1783/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1757 - f1: 0.8168 - val_loss: 0.5065 - val_f1: 0.1413\n",
      "Epoch 1784/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1747 - f1: 0.8171 - val_loss: 0.5074 - val_f1: 0.1414\n",
      "Epoch 1785/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1743 - f1: 0.8169 - val_loss: 0.5088 - val_f1: 0.1421\n",
      "Epoch 1786/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1726 - f1: 0.8155 - val_loss: 0.5096 - val_f1: 0.1416\n",
      "Epoch 1787/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1771 - f1: 0.8155 - val_loss: 0.5094 - val_f1: 0.1416\n",
      "Epoch 1788/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1735 - f1: 0.8208 - val_loss: 0.5108 - val_f1: 0.1419\n",
      "Epoch 1789/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1739 - f1: 0.8178 - val_loss: 0.5091 - val_f1: 0.1406\n",
      "Epoch 1790/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1742 - f1: 0.8186 - val_loss: 0.5092 - val_f1: 0.1411\n",
      "Epoch 1791/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1734 - f1: 0.8170 - val_loss: 0.5099 - val_f1: 0.1409\n",
      "Epoch 1792/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1762 - f1: 0.8142 - val_loss: 0.5089 - val_f1: 0.1420\n",
      "Epoch 1793/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1740 - f1: 0.8126 - val_loss: 0.5090 - val_f1: 0.1418\n",
      "Epoch 1794/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1724 - f1: 0.8212 - val_loss: 0.5108 - val_f1: 0.1408\n",
      "Epoch 1795/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1723 - f1: 0.8177 - val_loss: 0.5112 - val_f1: 0.1404\n",
      "Epoch 1796/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1750 - f1: 0.8165 - val_loss: 0.5115 - val_f1: 0.1405\n",
      "Epoch 1797/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1757 - f1: 0.8150 - val_loss: 0.5077 - val_f1: 0.1415\n",
      "Epoch 1798/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1742 - f1: 0.8242 - val_loss: 0.5100 - val_f1: 0.1408\n",
      "Epoch 1799/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1748 - f1: 0.8149 - val_loss: 0.5081 - val_f1: 0.1417\n",
      "Epoch 1800/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1740 - f1: 0.8173 - val_loss: 0.5087 - val_f1: 0.1405\n",
      "Epoch 1801/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1753 - f1: 0.8156 - val_loss: 0.5083 - val_f1: 0.1406\n",
      "Epoch 1802/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1762 - f1: 0.8165 - val_loss: 0.5101 - val_f1: 0.1407\n",
      "Epoch 1803/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1731 - f1: 0.8139 - val_loss: 0.5092 - val_f1: 0.1417\n",
      "Epoch 1804/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1748 - f1: 0.8202 - val_loss: 0.5092 - val_f1: 0.1411\n",
      "Epoch 1805/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1737 - f1: 0.8175 - val_loss: 0.5087 - val_f1: 0.1412\n",
      "Epoch 1806/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1718 - f1: 0.8199 - val_loss: 0.5102 - val_f1: 0.1408\n",
      "Epoch 1807/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1716 - f1: 0.8136 - val_loss: 0.5108 - val_f1: 0.1417\n",
      "Epoch 1808/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1735 - f1: 0.8164 - val_loss: 0.5101 - val_f1: 0.1417\n",
      "Epoch 1809/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1746 - f1: 0.8196 - val_loss: 0.5102 - val_f1: 0.1412\n",
      "Epoch 1810/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1760 - f1: 0.8131 - val_loss: 0.5097 - val_f1: 0.1420\n",
      "Epoch 1811/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1760 - f1: 0.8150 - val_loss: 0.5100 - val_f1: 0.1402\n",
      "Epoch 1812/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1732 - f1: 0.8161 - val_loss: 0.5115 - val_f1: 0.1409\n",
      "Epoch 1813/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1744 - f1: 0.8178 - val_loss: 0.5099 - val_f1: 0.1415\n",
      "Epoch 1814/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1737 - f1: 0.8178 - val_loss: 0.5085 - val_f1: 0.1414\n",
      "Epoch 1815/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1744 - f1: 0.8157 - val_loss: 0.5072 - val_f1: 0.1415\n",
      "Epoch 1816/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1750 - f1: 0.8178 - val_loss: 0.5088 - val_f1: 0.1409\n",
      "Epoch 1817/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1760 - f1: 0.8120 - val_loss: 0.5083 - val_f1: 0.1419\n",
      "Epoch 1818/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1716 - f1: 0.8219 - val_loss: 0.5102 - val_f1: 0.1410\n",
      "Epoch 1819/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1724 - f1: 0.8194 - val_loss: 0.5087 - val_f1: 0.1418\n",
      "Epoch 1820/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1712 - f1: 0.8194 - val_loss: 0.5099 - val_f1: 0.1402\n",
      "Epoch 1821/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1728 - f1: 0.8198 - val_loss: 0.5121 - val_f1: 0.1414\n",
      "Epoch 1822/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1749 - f1: 0.8182 - val_loss: 0.5117 - val_f1: 0.1406\n",
      "Epoch 1823/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1742 - f1: 0.8177 - val_loss: 0.5114 - val_f1: 0.1410\n",
      "Epoch 1824/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1720 - f1: 0.8231 - val_loss: 0.5101 - val_f1: 0.1402\n",
      "Epoch 1825/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1699 - f1: 0.8221 - val_loss: 0.5123 - val_f1: 0.1409\n",
      "Epoch 1826/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1740 - f1: 0.8190 - val_loss: 0.5111 - val_f1: 0.1412\n",
      "Epoch 1827/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1749 - f1: 0.8168 - val_loss: 0.5113 - val_f1: 0.1409\n",
      "Epoch 1828/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1730 - f1: 0.8193 - val_loss: 0.5112 - val_f1: 0.1406\n",
      "Epoch 1829/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1732 - f1: 0.8169 - val_loss: 0.5113 - val_f1: 0.1412\n",
      "Epoch 1830/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1739 - f1: 0.8150 - val_loss: 0.5106 - val_f1: 0.1418\n",
      "Epoch 1831/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1738 - f1: 0.8145 - val_loss: 0.5099 - val_f1: 0.1414\n",
      "Epoch 1832/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1720 - f1: 0.8192 - val_loss: 0.5116 - val_f1: 0.1412\n",
      "Epoch 1833/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1721 - f1: 0.8180 - val_loss: 0.5120 - val_f1: 0.1402\n",
      "Epoch 1834/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1741 - f1: 0.8194 - val_loss: 0.5122 - val_f1: 0.1421\n",
      "Epoch 1835/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1747 - f1: 0.8161 - val_loss: 0.5118 - val_f1: 0.1410\n",
      "Epoch 1836/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1740 - f1: 0.8197 - val_loss: 0.5120 - val_f1: 0.1409\n",
      "Epoch 1837/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1742 - f1: 0.8148 - val_loss: 0.5113 - val_f1: 0.1406\n",
      "Epoch 1838/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1732 - f1: 0.8188 - val_loss: 0.5107 - val_f1: 0.1409\n",
      "Epoch 1839/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1772 - f1: 0.8126 - val_loss: 0.5095 - val_f1: 0.1410\n",
      "Epoch 1840/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1737 - f1: 0.8153 - val_loss: 0.5103 - val_f1: 0.1407\n",
      "Epoch 1841/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1723 - f1: 0.8181 - val_loss: 0.5116 - val_f1: 0.1398\n",
      "Epoch 1842/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1740 - f1: 0.8181 - val_loss: 0.5092 - val_f1: 0.1410\n",
      "Epoch 1843/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1720 - f1: 0.8210 - val_loss: 0.5110 - val_f1: 0.1407\n",
      "Epoch 1844/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1743 - f1: 0.8160 - val_loss: 0.5119 - val_f1: 0.1401\n",
      "Epoch 1845/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1748 - f1: 0.8173 - val_loss: 0.5083 - val_f1: 0.1407\n",
      "Epoch 1846/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1747 - f1: 0.8175 - val_loss: 0.5089 - val_f1: 0.1415\n",
      "Epoch 1847/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1737 - f1: 0.8161 - val_loss: 0.5092 - val_f1: 0.1410\n",
      "Epoch 1848/2000\n",
      "64440/64440 [==============================] - 2s 34us/step - loss: 0.1754 - f1: 0.8170 - val_loss: 0.5105 - val_f1: 0.1415\n",
      "Epoch 1849/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.1722 - f1: 0.8171 - val_loss: 0.5098 - val_f1: 0.1416\n",
      "Epoch 1850/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1736 - f1: 0.8152 - val_loss: 0.5099 - val_f1: 0.1416\n",
      "Epoch 1851/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1736 - f1: 0.8177 - val_loss: 0.5113 - val_f1: 0.1411\n",
      "Epoch 1852/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1715 - f1: 0.8215 - val_loss: 0.5099 - val_f1: 0.1408\n",
      "Epoch 1853/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1712 - f1: 0.8211 - val_loss: 0.5114 - val_f1: 0.1417\n",
      "Epoch 1854/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1734 - f1: 0.8170 - val_loss: 0.5105 - val_f1: 0.1417\n",
      "Epoch 1855/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1750 - f1: 0.8156 - val_loss: 0.5115 - val_f1: 0.1414\n",
      "Epoch 1856/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1737 - f1: 0.8201 - val_loss: 0.5118 - val_f1: 0.1411\n",
      "Epoch 1857/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1717 - f1: 0.8196 - val_loss: 0.5128 - val_f1: 0.1408\n",
      "Epoch 1858/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1758 - f1: 0.8136 - val_loss: 0.5118 - val_f1: 0.1413\n",
      "Epoch 1859/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1743 - f1: 0.8169 - val_loss: 0.5095 - val_f1: 0.1414\n",
      "Epoch 1860/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1732 - f1: 0.8192 - val_loss: 0.5104 - val_f1: 0.1413\n",
      "Epoch 1861/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1691 - f1: 0.8224 - val_loss: 0.5140 - val_f1: 0.1410\n",
      "Epoch 1862/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1726 - f1: 0.8173 - val_loss: 0.5119 - val_f1: 0.1410\n",
      "Epoch 1863/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1749 - f1: 0.8152 - val_loss: 0.5107 - val_f1: 0.1398\n",
      "Epoch 1864/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1755 - f1: 0.8202 - val_loss: 0.5083 - val_f1: 0.1410\n",
      "Epoch 1865/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1740 - f1: 0.8199 - val_loss: 0.5107 - val_f1: 0.1405\n",
      "Epoch 1866/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1731 - f1: 0.8169 - val_loss: 0.5110 - val_f1: 0.1407\n",
      "Epoch 1867/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1716 - f1: 0.8214 - val_loss: 0.5127 - val_f1: 0.1408\n",
      "Epoch 1868/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1726 - f1: 0.8173 - val_loss: 0.5125 - val_f1: 0.1409\n",
      "Epoch 1869/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1746 - f1: 0.8152 - val_loss: 0.5092 - val_f1: 0.1421\n",
      "Epoch 1870/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1740 - f1: 0.8147 - val_loss: 0.5097 - val_f1: 0.1418\n",
      "Epoch 1871/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1716 - f1: 0.8205 - val_loss: 0.5113 - val_f1: 0.1419\n",
      "Epoch 1872/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1706 - f1: 0.8214 - val_loss: 0.5129 - val_f1: 0.1407\n",
      "Epoch 1873/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1760 - f1: 0.8141 - val_loss: 0.5105 - val_f1: 0.1414\n",
      "Epoch 1874/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1720 - f1: 0.8197 - val_loss: 0.5111 - val_f1: 0.1412\n",
      "Epoch 1875/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1754 - f1: 0.8129 - val_loss: 0.5100 - val_f1: 0.1421\n",
      "Epoch 1876/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1734 - f1: 0.8148 - val_loss: 0.5117 - val_f1: 0.1416\n",
      "Epoch 1877/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1760 - f1: 0.8157 - val_loss: 0.5088 - val_f1: 0.1408\n",
      "Epoch 1878/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1699 - f1: 0.8223 - val_loss: 0.5125 - val_f1: 0.1406\n",
      "Epoch 1879/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1756 - f1: 0.8152 - val_loss: 0.5121 - val_f1: 0.1401\n",
      "Epoch 1880/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1737 - f1: 0.8190 - val_loss: 0.5113 - val_f1: 0.1413\n",
      "Epoch 1881/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1699 - f1: 0.8222 - val_loss: 0.5110 - val_f1: 0.1413\n",
      "Epoch 1882/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1725 - f1: 0.8176 - val_loss: 0.5127 - val_f1: 0.1407\n",
      "Epoch 1883/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1733 - f1: 0.8221 - val_loss: 0.5136 - val_f1: 0.1405\n",
      "Epoch 1884/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1741 - f1: 0.8172 - val_loss: 0.5114 - val_f1: 0.1411\n",
      "Epoch 1885/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1742 - f1: 0.8211 - val_loss: 0.5109 - val_f1: 0.1408\n",
      "Epoch 1886/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1723 - f1: 0.8213 - val_loss: 0.5121 - val_f1: 0.1412\n",
      "Epoch 1887/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1739 - f1: 0.8175 - val_loss: 0.5111 - val_f1: 0.1410\n",
      "Epoch 1888/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1732 - f1: 0.8189 - val_loss: 0.5129 - val_f1: 0.1408\n",
      "Epoch 1889/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1741 - f1: 0.8174 - val_loss: 0.5108 - val_f1: 0.1408\n",
      "Epoch 1890/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1729 - f1: 0.8160 - val_loss: 0.5105 - val_f1: 0.1410\n",
      "Epoch 1891/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1721 - f1: 0.8216 - val_loss: 0.5121 - val_f1: 0.1401\n",
      "Epoch 1892/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1739 - f1: 0.8173 - val_loss: 0.5130 - val_f1: 0.1415\n",
      "Epoch 1893/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1739 - f1: 0.8165 - val_loss: 0.5109 - val_f1: 0.1420\n",
      "Epoch 1894/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1744 - f1: 0.8159 - val_loss: 0.5113 - val_f1: 0.1414\n",
      "Epoch 1895/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1722 - f1: 0.8200 - val_loss: 0.5102 - val_f1: 0.1411\n",
      "Epoch 1896/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.1732 - f1: 0.8167 - val_loss: 0.5109 - val_f1: 0.1423\n",
      "Epoch 1897/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1725 - f1: 0.8189 - val_loss: 0.5104 - val_f1: 0.1420\n",
      "Epoch 1898/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1729 - f1: 0.8203 - val_loss: 0.5122 - val_f1: 0.1408\n",
      "Epoch 1899/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1751 - f1: 0.8185 - val_loss: 0.5092 - val_f1: 0.1419\n",
      "Epoch 1900/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1734 - f1: 0.8197 - val_loss: 0.5082 - val_f1: 0.1423\n",
      "Epoch 1901/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1739 - f1: 0.8181 - val_loss: 0.5109 - val_f1: 0.1418\n",
      "Epoch 1902/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.1727 - f1: 0.8194 - val_loss: 0.5108 - val_f1: 0.1428\n",
      "Epoch 1903/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1756 - f1: 0.8165 - val_loss: 0.5103 - val_f1: 0.1416\n",
      "Epoch 1904/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1753 - f1: 0.8168 - val_loss: 0.5095 - val_f1: 0.1414\n",
      "Epoch 1905/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1721 - f1: 0.8175 - val_loss: 0.5093 - val_f1: 0.1412\n",
      "Epoch 1906/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1719 - f1: 0.8202 - val_loss: 0.5105 - val_f1: 0.1416\n",
      "Epoch 1907/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1728 - f1: 0.8198 - val_loss: 0.5106 - val_f1: 0.1417\n",
      "Epoch 1908/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1734 - f1: 0.8188 - val_loss: 0.5105 - val_f1: 0.1414\n",
      "Epoch 1909/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1731 - f1: 0.8180 - val_loss: 0.5119 - val_f1: 0.1410\n",
      "Epoch 1910/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1744 - f1: 0.8133 - val_loss: 0.5108 - val_f1: 0.1421\n",
      "Epoch 1911/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1722 - f1: 0.8203 - val_loss: 0.5121 - val_f1: 0.1412\n",
      "Epoch 1912/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1720 - f1: 0.8145 - val_loss: 0.5111 - val_f1: 0.1410\n",
      "Epoch 1913/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1708 - f1: 0.8194 - val_loss: 0.5119 - val_f1: 0.1422\n",
      "Epoch 1914/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1731 - f1: 0.8187 - val_loss: 0.5124 - val_f1: 0.1415\n",
      "Epoch 1915/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1739 - f1: 0.8207 - val_loss: 0.5125 - val_f1: 0.1424\n",
      "Epoch 1916/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1736 - f1: 0.8187 - val_loss: 0.5109 - val_f1: 0.1409\n",
      "Epoch 1917/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.1716 - f1: 0.8222 - val_loss: 0.5126 - val_f1: 0.1408\n",
      "Epoch 1918/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1737 - f1: 0.8169 - val_loss: 0.5131 - val_f1: 0.1424\n",
      "Epoch 1919/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1738 - f1: 0.8188 - val_loss: 0.5108 - val_f1: 0.1413\n",
      "Epoch 1920/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1716 - f1: 0.8199 - val_loss: 0.5120 - val_f1: 0.1412\n",
      "Epoch 1921/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1701 - f1: 0.8248 - val_loss: 0.5124 - val_f1: 0.1412\n",
      "Epoch 1922/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1706 - f1: 0.8220 - val_loss: 0.5126 - val_f1: 0.1417\n",
      "Epoch 1923/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.1719 - f1: 0.8186 - val_loss: 0.5134 - val_f1: 0.1413\n",
      "Epoch 1924/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1722 - f1: 0.8184 - val_loss: 0.5112 - val_f1: 0.1417\n",
      "Epoch 1925/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1706 - f1: 0.8196 - val_loss: 0.5135 - val_f1: 0.1411\n",
      "Epoch 1926/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1740 - f1: 0.8158 - val_loss: 0.5131 - val_f1: 0.1400\n",
      "Epoch 1927/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1734 - f1: 0.8186 - val_loss: 0.5127 - val_f1: 0.1408\n",
      "Epoch 1928/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1710 - f1: 0.8225 - val_loss: 0.5119 - val_f1: 0.1411\n",
      "Epoch 1929/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1723 - f1: 0.8119 - val_loss: 0.5122 - val_f1: 0.1406\n",
      "Epoch 1930/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1747 - f1: 0.8158 - val_loss: 0.5093 - val_f1: 0.1413\n",
      "Epoch 1931/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1723 - f1: 0.8171 - val_loss: 0.5102 - val_f1: 0.1417\n",
      "Epoch 1932/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1726 - f1: 0.8184 - val_loss: 0.5112 - val_f1: 0.1420\n",
      "Epoch 1933/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1715 - f1: 0.8210 - val_loss: 0.5113 - val_f1: 0.1413\n",
      "Epoch 1934/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1731 - f1: 0.8190 - val_loss: 0.5114 - val_f1: 0.1404\n",
      "Epoch 1935/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1711 - f1: 0.8177 - val_loss: 0.5134 - val_f1: 0.1406\n",
      "Epoch 1936/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1743 - f1: 0.8153 - val_loss: 0.5116 - val_f1: 0.1412\n",
      "Epoch 1937/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1700 - f1: 0.8239 - val_loss: 0.5135 - val_f1: 0.1416\n",
      "Epoch 1938/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1723 - f1: 0.8174 - val_loss: 0.5132 - val_f1: 0.1410\n",
      "Epoch 1939/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1684 - f1: 0.8244 - val_loss: 0.5149 - val_f1: 0.1406\n",
      "Epoch 1940/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1745 - f1: 0.8176 - val_loss: 0.5139 - val_f1: 0.1411\n",
      "Epoch 1941/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1717 - f1: 0.8208 - val_loss: 0.5141 - val_f1: 0.1412\n",
      "Epoch 1942/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1724 - f1: 0.8213 - val_loss: 0.5138 - val_f1: 0.1419\n",
      "Epoch 1943/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1727 - f1: 0.8197 - val_loss: 0.5120 - val_f1: 0.1411\n",
      "Epoch 1944/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1696 - f1: 0.8241 - val_loss: 0.5161 - val_f1: 0.1410\n",
      "Epoch 1945/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1719 - f1: 0.8219 - val_loss: 0.5131 - val_f1: 0.1419\n",
      "Epoch 1946/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1736 - f1: 0.8198 - val_loss: 0.5125 - val_f1: 0.1414\n",
      "Epoch 1947/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1701 - f1: 0.8191 - val_loss: 0.5131 - val_f1: 0.1422\n",
      "Epoch 1948/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1714 - f1: 0.8213 - val_loss: 0.5156 - val_f1: 0.1405\n",
      "Epoch 1949/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1683 - f1: 0.8226 - val_loss: 0.5154 - val_f1: 0.1404\n",
      "Epoch 1950/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.1728 - f1: 0.8192 - val_loss: 0.5126 - val_f1: 0.1417\n",
      "Epoch 1951/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1711 - f1: 0.8200 - val_loss: 0.5127 - val_f1: 0.1412\n",
      "Epoch 1952/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1726 - f1: 0.8197 - val_loss: 0.5123 - val_f1: 0.1415\n",
      "Epoch 1953/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1675 - f1: 0.8248 - val_loss: 0.5164 - val_f1: 0.1424\n",
      "Epoch 1954/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1729 - f1: 0.8219 - val_loss: 0.5149 - val_f1: 0.1411\n",
      "Epoch 1955/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1717 - f1: 0.8200 - val_loss: 0.5144 - val_f1: 0.1409\n",
      "Epoch 1956/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1715 - f1: 0.8186 - val_loss: 0.5138 - val_f1: 0.1426\n",
      "Epoch 1957/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1689 - f1: 0.8256 - val_loss: 0.5164 - val_f1: 0.1413\n",
      "Epoch 1958/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1719 - f1: 0.8196 - val_loss: 0.5142 - val_f1: 0.1415\n",
      "Epoch 1959/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1715 - f1: 0.8192 - val_loss: 0.5146 - val_f1: 0.1417\n",
      "Epoch 1960/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1694 - f1: 0.8232 - val_loss: 0.5154 - val_f1: 0.1414\n",
      "Epoch 1961/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1722 - f1: 0.8212 - val_loss: 0.5144 - val_f1: 0.1433\n",
      "Epoch 1962/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1736 - f1: 0.8182 - val_loss: 0.5134 - val_f1: 0.1420\n",
      "Epoch 1963/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1700 - f1: 0.8227 - val_loss: 0.5152 - val_f1: 0.1405\n",
      "Epoch 1964/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1730 - f1: 0.8166 - val_loss: 0.5138 - val_f1: 0.1410\n",
      "Epoch 1965/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1727 - f1: 0.8185 - val_loss: 0.5147 - val_f1: 0.1410\n",
      "Epoch 1966/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1733 - f1: 0.8211 - val_loss: 0.5134 - val_f1: 0.1410\n",
      "Epoch 1967/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1713 - f1: 0.8217 - val_loss: 0.5141 - val_f1: 0.1410\n",
      "Epoch 1968/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1741 - f1: 0.8193 - val_loss: 0.5120 - val_f1: 0.1410\n",
      "Epoch 1969/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.1727 - f1: 0.8184 - val_loss: 0.5147 - val_f1: 0.1409\n",
      "Epoch 1970/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1711 - f1: 0.8199 - val_loss: 0.5145 - val_f1: 0.1418\n",
      "Epoch 1971/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1718 - f1: 0.8205 - val_loss: 0.5140 - val_f1: 0.1411\n",
      "Epoch 1972/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1732 - f1: 0.8195 - val_loss: 0.5113 - val_f1: 0.1420\n",
      "Epoch 1973/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1732 - f1: 0.8198 - val_loss: 0.5121 - val_f1: 0.1418\n",
      "Epoch 1974/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1729 - f1: 0.8159 - val_loss: 0.5124 - val_f1: 0.1410\n",
      "Epoch 1975/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1707 - f1: 0.8171 - val_loss: 0.5120 - val_f1: 0.1409\n",
      "Epoch 1976/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1745 - f1: 0.8168 - val_loss: 0.5132 - val_f1: 0.1398\n",
      "Epoch 1977/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1711 - f1: 0.8189 - val_loss: 0.5131 - val_f1: 0.1423\n",
      "Epoch 1978/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1693 - f1: 0.8251 - val_loss: 0.5141 - val_f1: 0.1411\n",
      "Epoch 1979/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1739 - f1: 0.8193 - val_loss: 0.5149 - val_f1: 0.1405\n",
      "Epoch 1980/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1710 - f1: 0.8200 - val_loss: 0.5140 - val_f1: 0.1410\n",
      "Epoch 1981/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1700 - f1: 0.8267 - val_loss: 0.5150 - val_f1: 0.1413\n",
      "Epoch 1982/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1713 - f1: 0.8209 - val_loss: 0.5135 - val_f1: 0.1406\n",
      "Epoch 1983/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1691 - f1: 0.8262 - val_loss: 0.5119 - val_f1: 0.1419\n",
      "Epoch 1984/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1722 - f1: 0.8195 - val_loss: 0.5137 - val_f1: 0.1418\n",
      "Epoch 1985/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1715 - f1: 0.8204 - val_loss: 0.5135 - val_f1: 0.1411\n",
      "Epoch 1986/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1733 - f1: 0.8182 - val_loss: 0.5127 - val_f1: 0.1415\n",
      "Epoch 1987/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1702 - f1: 0.8215 - val_loss: 0.5149 - val_f1: 0.1405\n",
      "Epoch 1988/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.1693 - f1: 0.8187 - val_loss: 0.5138 - val_f1: 0.1407\n",
      "Epoch 1989/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1719 - f1: 0.8168 - val_loss: 0.5145 - val_f1: 0.1417\n",
      "Epoch 1990/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1699 - f1: 0.8180 - val_loss: 0.5149 - val_f1: 0.1416\n",
      "Epoch 1991/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1720 - f1: 0.8192 - val_loss: 0.5145 - val_f1: 0.1404\n",
      "Epoch 1992/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1734 - f1: 0.8176 - val_loss: 0.5137 - val_f1: 0.1413\n",
      "Epoch 1993/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1688 - f1: 0.8223 - val_loss: 0.5143 - val_f1: 0.1416\n",
      "Epoch 1994/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.1741 - f1: 0.8163 - val_loss: 0.5130 - val_f1: 0.1419\n",
      "Epoch 1995/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1708 - f1: 0.8215 - val_loss: 0.5142 - val_f1: 0.1411\n",
      "Epoch 1996/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.1699 - f1: 0.8222 - val_loss: 0.5146 - val_f1: 0.1411\n",
      "Epoch 1997/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1733 - f1: 0.8166 - val_loss: 0.5130 - val_f1: 0.1415\n",
      "Epoch 1998/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1714 - f1: 0.8210 - val_loss: 0.5130 - val_f1: 0.1420\n",
      "Epoch 1999/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1722 - f1: 0.8176 - val_loss: 0.5128 - val_f1: 0.1414\n",
      "Epoch 2000/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.1715 - f1: 0.8200 - val_loss: 0.5147 - val_f1: 0.1412\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna1.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[10028   766]\n",
      " [ 1558  1457]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[9932  863]\n",
      " [1565 1450]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[50225   147]\n",
      " [ 1108 12960]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna1.predict(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list2 = [50,50,1]\n",
    "activation_list2 = ['tanh','tanh','sigmoid']\n",
    "dropout_list2 = [0.3,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 12,651\n",
      "Trainable params: 12,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna2 = new_rna()\n",
    "rna2.build_model(data_shape,n_list2,activation_list2,dropout_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64440 samples, validate on 13810 samples\n",
      "Epoch 1/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.4074 - f1: 0.4803 - val_loss: 0.3695 - val_f1: 0.1426\n",
      "Epoch 2/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.3761 - f1: 0.5358 - val_loss: 0.3672 - val_f1: 0.1426\n",
      "Epoch 3/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3720 - f1: 0.5389 - val_loss: 0.3676 - val_f1: 0.1450\n",
      "Epoch 4/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3701 - f1: 0.5455 - val_loss: 0.3668 - val_f1: 0.1449\n",
      "Epoch 5/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3683 - f1: 0.5473 - val_loss: 0.3674 - val_f1: 0.1447\n",
      "Epoch 6/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3673 - f1: 0.5475 - val_loss: 0.3677 - val_f1: 0.1447\n",
      "Epoch 7/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3662 - f1: 0.5520 - val_loss: 0.3680 - val_f1: 0.1454\n",
      "Epoch 8/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3661 - f1: 0.5492 - val_loss: 0.3676 - val_f1: 0.1443\n",
      "Epoch 9/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3653 - f1: 0.5530 - val_loss: 0.3676 - val_f1: 0.1455\n",
      "Epoch 10/2000\n",
      "64440/64440 [==============================] - 2s 35us/step - loss: 0.3648 - f1: 0.5506 - val_loss: 0.3676 - val_f1: 0.1456\n",
      "Epoch 11/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3640 - f1: 0.5555 - val_loss: 0.3673 - val_f1: 0.1436\n",
      "Epoch 12/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3649 - f1: 0.5524 - val_loss: 0.3678 - val_f1: 0.1464\n",
      "Epoch 13/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3640 - f1: 0.5551 - val_loss: 0.3682 - val_f1: 0.1459\n",
      "Epoch 14/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3636 - f1: 0.5565 - val_loss: 0.3679 - val_f1: 0.1452\n",
      "Epoch 15/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3642 - f1: 0.5544 - val_loss: 0.3678 - val_f1: 0.1465\n",
      "Epoch 16/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3631 - f1: 0.5590 - val_loss: 0.3684 - val_f1: 0.1470\n",
      "Epoch 17/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3627 - f1: 0.5549 - val_loss: 0.3682 - val_f1: 0.1454\n",
      "Epoch 18/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3632 - f1: 0.5566 - val_loss: 0.3680 - val_f1: 0.1456\n",
      "Epoch 19/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3628 - f1: 0.5543 - val_loss: 0.3680 - val_f1: 0.1464\n",
      "Epoch 20/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3622 - f1: 0.5616 - val_loss: 0.3680 - val_f1: 0.1452\n",
      "Epoch 21/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3621 - f1: 0.5581 - val_loss: 0.3679 - val_f1: 0.1460\n",
      "Epoch 22/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3620 - f1: 0.5559 - val_loss: 0.3677 - val_f1: 0.1450\n",
      "Epoch 23/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3612 - f1: 0.5639 - val_loss: 0.3674 - val_f1: 0.1447\n",
      "Epoch 24/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3610 - f1: 0.5566 - val_loss: 0.3687 - val_f1: 0.1477\n",
      "Epoch 25/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3618 - f1: 0.5591 - val_loss: 0.3678 - val_f1: 0.1434\n",
      "Epoch 26/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3609 - f1: 0.5572 - val_loss: 0.3680 - val_f1: 0.1469\n",
      "Epoch 27/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3611 - f1: 0.5617 - val_loss: 0.3685 - val_f1: 0.1462\n",
      "Epoch 28/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3600 - f1: 0.5590 - val_loss: 0.3681 - val_f1: 0.1450\n",
      "Epoch 29/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3598 - f1: 0.5602 - val_loss: 0.3672 - val_f1: 0.1437\n",
      "Epoch 30/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3603 - f1: 0.5604 - val_loss: 0.3679 - val_f1: 0.1458\n",
      "Epoch 31/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3599 - f1: 0.5639 - val_loss: 0.3684 - val_f1: 0.1450\n",
      "Epoch 32/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3596 - f1: 0.5658 - val_loss: 0.3683 - val_f1: 0.1453\n",
      "Epoch 33/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3600 - f1: 0.5583 - val_loss: 0.3683 - val_f1: 0.1448\n",
      "Epoch 34/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.3594 - f1: 0.5635 - val_loss: 0.3689 - val_f1: 0.1458\n",
      "Epoch 35/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3583 - f1: 0.5645 - val_loss: 0.3689 - val_f1: 0.1467\n",
      "Epoch 36/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3583 - f1: 0.5664 - val_loss: 0.3688 - val_f1: 0.1462\n",
      "Epoch 37/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3594 - f1: 0.5600 - val_loss: 0.3685 - val_f1: 0.1463\n",
      "Epoch 38/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3583 - f1: 0.5615 - val_loss: 0.3689 - val_f1: 0.1442\n",
      "Epoch 39/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3580 - f1: 0.5587 - val_loss: 0.3684 - val_f1: 0.1457\n",
      "Epoch 40/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3579 - f1: 0.5622 - val_loss: 0.3685 - val_f1: 0.1447\n",
      "Epoch 41/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3579 - f1: 0.5586 - val_loss: 0.3686 - val_f1: 0.1458\n",
      "Epoch 42/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3580 - f1: 0.5618 - val_loss: 0.3681 - val_f1: 0.1453\n",
      "Epoch 43/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3585 - f1: 0.5615 - val_loss: 0.3689 - val_f1: 0.1457\n",
      "Epoch 44/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3573 - f1: 0.5627 - val_loss: 0.3696 - val_f1: 0.1466\n",
      "Epoch 45/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3575 - f1: 0.5634 - val_loss: 0.3688 - val_f1: 0.1460\n",
      "Epoch 46/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3568 - f1: 0.5647 - val_loss: 0.3690 - val_f1: 0.1461\n",
      "Epoch 47/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3567 - f1: 0.5618 - val_loss: 0.3692 - val_f1: 0.1465\n",
      "Epoch 48/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3567 - f1: 0.5649 - val_loss: 0.3686 - val_f1: 0.1444\n",
      "Epoch 49/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3563 - f1: 0.5597 - val_loss: 0.3682 - val_f1: 0.1436\n",
      "Epoch 50/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3562 - f1: 0.5642 - val_loss: 0.3686 - val_f1: 0.1457\n",
      "Epoch 51/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3555 - f1: 0.5656 - val_loss: 0.3688 - val_f1: 0.1447\n",
      "Epoch 52/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3556 - f1: 0.5648 - val_loss: 0.3685 - val_f1: 0.1460\n",
      "Epoch 53/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3559 - f1: 0.5643 - val_loss: 0.3692 - val_f1: 0.1452\n",
      "Epoch 54/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3555 - f1: 0.5628 - val_loss: 0.3688 - val_f1: 0.1442\n",
      "Epoch 55/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3551 - f1: 0.5637 - val_loss: 0.3690 - val_f1: 0.1451\n",
      "Epoch 56/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3550 - f1: 0.5641 - val_loss: 0.3697 - val_f1: 0.1439\n",
      "Epoch 57/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3544 - f1: 0.5677 - val_loss: 0.3690 - val_f1: 0.1451\n",
      "Epoch 58/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3542 - f1: 0.5689 - val_loss: 0.3696 - val_f1: 0.1455\n",
      "Epoch 59/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3548 - f1: 0.5685 - val_loss: 0.3700 - val_f1: 0.1448\n",
      "Epoch 60/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3540 - f1: 0.5665 - val_loss: 0.3704 - val_f1: 0.1463\n",
      "Epoch 61/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3537 - f1: 0.5715 - val_loss: 0.3712 - val_f1: 0.1454\n",
      "Epoch 62/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3549 - f1: 0.5627 - val_loss: 0.3689 - val_f1: 0.1448\n",
      "Epoch 63/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3539 - f1: 0.5666 - val_loss: 0.3691 - val_f1: 0.1446\n",
      "Epoch 64/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3542 - f1: 0.5649 - val_loss: 0.3696 - val_f1: 0.1452\n",
      "Epoch 65/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3527 - f1: 0.5673 - val_loss: 0.3694 - val_f1: 0.1441\n",
      "Epoch 66/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3533 - f1: 0.5653 - val_loss: 0.3694 - val_f1: 0.1453\n",
      "Epoch 67/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3527 - f1: 0.5636 - val_loss: 0.3705 - val_f1: 0.1450\n",
      "Epoch 68/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3533 - f1: 0.5677 - val_loss: 0.3701 - val_f1: 0.1455\n",
      "Epoch 69/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3524 - f1: 0.5645 - val_loss: 0.3694 - val_f1: 0.1462\n",
      "Epoch 70/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3527 - f1: 0.5677 - val_loss: 0.3698 - val_f1: 0.1445\n",
      "Epoch 71/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3513 - f1: 0.5706 - val_loss: 0.3700 - val_f1: 0.1445\n",
      "Epoch 72/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3525 - f1: 0.5645 - val_loss: 0.3701 - val_f1: 0.1449\n",
      "Epoch 73/2000\n",
      "64440/64440 [==============================] - 2s 39us/step - loss: 0.3520 - f1: 0.5665 - val_loss: 0.3704 - val_f1: 0.1463\n",
      "Epoch 74/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3514 - f1: 0.5741 - val_loss: 0.3700 - val_f1: 0.1437\n",
      "Epoch 75/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3519 - f1: 0.5693 - val_loss: 0.3709 - val_f1: 0.1447\n",
      "Epoch 76/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3509 - f1: 0.5653 - val_loss: 0.3704 - val_f1: 0.1448\n",
      "Epoch 77/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3514 - f1: 0.5678 - val_loss: 0.3696 - val_f1: 0.1433\n",
      "Epoch 78/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3511 - f1: 0.5698 - val_loss: 0.3702 - val_f1: 0.1437\n",
      "Epoch 79/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3505 - f1: 0.5706 - val_loss: 0.3712 - val_f1: 0.1444\n",
      "Epoch 80/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3504 - f1: 0.5658 - val_loss: 0.3709 - val_f1: 0.1439\n",
      "Epoch 81/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3508 - f1: 0.5719 - val_loss: 0.3698 - val_f1: 0.1439\n",
      "Epoch 82/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3493 - f1: 0.5698 - val_loss: 0.3711 - val_f1: 0.1448\n",
      "Epoch 83/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3496 - f1: 0.5697 - val_loss: 0.3724 - val_f1: 0.1466\n",
      "Epoch 84/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3500 - f1: 0.5729 - val_loss: 0.3696 - val_f1: 0.1440\n",
      "Epoch 85/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3495 - f1: 0.5694 - val_loss: 0.3701 - val_f1: 0.1451\n",
      "Epoch 86/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3491 - f1: 0.5727 - val_loss: 0.3711 - val_f1: 0.1459\n",
      "Epoch 87/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3494 - f1: 0.5689 - val_loss: 0.3698 - val_f1: 0.1451\n",
      "Epoch 88/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3496 - f1: 0.5713 - val_loss: 0.3709 - val_f1: 0.1448\n",
      "Epoch 89/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3486 - f1: 0.5745 - val_loss: 0.3706 - val_f1: 0.1439\n",
      "Epoch 90/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3467 - f1: 0.5749 - val_loss: 0.3709 - val_f1: 0.1451\n",
      "Epoch 91/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3485 - f1: 0.5765 - val_loss: 0.3711 - val_f1: 0.1445\n",
      "Epoch 92/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3482 - f1: 0.5711 - val_loss: 0.3722 - val_f1: 0.1450\n",
      "Epoch 93/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3479 - f1: 0.5714 - val_loss: 0.3706 - val_f1: 0.1444\n",
      "Epoch 94/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3475 - f1: 0.5718 - val_loss: 0.3711 - val_f1: 0.1446\n",
      "Epoch 95/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3469 - f1: 0.5775 - val_loss: 0.3713 - val_f1: 0.1451\n",
      "Epoch 96/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3473 - f1: 0.5755 - val_loss: 0.3714 - val_f1: 0.1455\n",
      "Epoch 97/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3468 - f1: 0.5745 - val_loss: 0.3726 - val_f1: 0.1450\n",
      "Epoch 98/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3468 - f1: 0.5702 - val_loss: 0.3722 - val_f1: 0.1461\n",
      "Epoch 99/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3463 - f1: 0.5784 - val_loss: 0.3714 - val_f1: 0.1442\n",
      "Epoch 100/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3476 - f1: 0.5752 - val_loss: 0.3717 - val_f1: 0.1459\n",
      "Epoch 101/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3455 - f1: 0.5773 - val_loss: 0.3725 - val_f1: 0.1447\n",
      "Epoch 102/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3464 - f1: 0.5729 - val_loss: 0.3715 - val_f1: 0.1448\n",
      "Epoch 103/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3463 - f1: 0.5750 - val_loss: 0.3717 - val_f1: 0.1450\n",
      "Epoch 104/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3459 - f1: 0.5794 - val_loss: 0.3710 - val_f1: 0.1447\n",
      "Epoch 105/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3444 - f1: 0.5755 - val_loss: 0.3719 - val_f1: 0.1443\n",
      "Epoch 106/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3445 - f1: 0.5838 - val_loss: 0.3722 - val_f1: 0.1444\n",
      "Epoch 107/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3446 - f1: 0.5781 - val_loss: 0.3718 - val_f1: 0.1445\n",
      "Epoch 108/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3437 - f1: 0.5824 - val_loss: 0.3724 - val_f1: 0.1442\n",
      "Epoch 109/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3447 - f1: 0.5823 - val_loss: 0.3720 - val_f1: 0.1445\n",
      "Epoch 110/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3446 - f1: 0.5812 - val_loss: 0.3715 - val_f1: 0.1444\n",
      "Epoch 111/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3441 - f1: 0.5761 - val_loss: 0.3724 - val_f1: 0.1457\n",
      "Epoch 112/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3442 - f1: 0.5787 - val_loss: 0.3717 - val_f1: 0.1436\n",
      "Epoch 113/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3436 - f1: 0.5818 - val_loss: 0.3734 - val_f1: 0.1453\n",
      "Epoch 114/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3435 - f1: 0.5819 - val_loss: 0.3725 - val_f1: 0.1451\n",
      "Epoch 115/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3436 - f1: 0.5818 - val_loss: 0.3728 - val_f1: 0.1444\n",
      "Epoch 116/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3437 - f1: 0.5763 - val_loss: 0.3721 - val_f1: 0.1440\n",
      "Epoch 117/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3426 - f1: 0.5823 - val_loss: 0.3734 - val_f1: 0.1452\n",
      "Epoch 118/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3418 - f1: 0.5817 - val_loss: 0.3729 - val_f1: 0.1447\n",
      "Epoch 119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3415 - f1: 0.5844 - val_loss: 0.3731 - val_f1: 0.1450\n",
      "Epoch 120/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3419 - f1: 0.5795 - val_loss: 0.3749 - val_f1: 0.1454\n",
      "Epoch 121/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3423 - f1: 0.5832 - val_loss: 0.3739 - val_f1: 0.1456\n",
      "Epoch 122/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3420 - f1: 0.5802 - val_loss: 0.3726 - val_f1: 0.1455\n",
      "Epoch 123/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3418 - f1: 0.5870 - val_loss: 0.3727 - val_f1: 0.1447\n",
      "Epoch 124/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3416 - f1: 0.5848 - val_loss: 0.3748 - val_f1: 0.1449\n",
      "Epoch 125/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3404 - f1: 0.5822 - val_loss: 0.3740 - val_f1: 0.1440\n",
      "Epoch 126/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3404 - f1: 0.5880 - val_loss: 0.3728 - val_f1: 0.1447\n",
      "Epoch 127/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3413 - f1: 0.5865 - val_loss: 0.3731 - val_f1: 0.1438\n",
      "Epoch 128/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3410 - f1: 0.5829 - val_loss: 0.3732 - val_f1: 0.1447\n",
      "Epoch 129/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3403 - f1: 0.5871 - val_loss: 0.3735 - val_f1: 0.1453\n",
      "Epoch 130/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3410 - f1: 0.5860 - val_loss: 0.3748 - val_f1: 0.1447\n",
      "Epoch 131/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3395 - f1: 0.5916 - val_loss: 0.3727 - val_f1: 0.1451\n",
      "Epoch 132/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3387 - f1: 0.5858 - val_loss: 0.3747 - val_f1: 0.1444\n",
      "Epoch 133/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3388 - f1: 0.5885 - val_loss: 0.3728 - val_f1: 0.1443\n",
      "Epoch 134/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3386 - f1: 0.5913 - val_loss: 0.3747 - val_f1: 0.1446\n",
      "Epoch 135/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3398 - f1: 0.5882 - val_loss: 0.3735 - val_f1: 0.1447\n",
      "Epoch 136/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3379 - f1: 0.5887 - val_loss: 0.3748 - val_f1: 0.1451\n",
      "Epoch 137/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3379 - f1: 0.5842 - val_loss: 0.3733 - val_f1: 0.1450\n",
      "Epoch 138/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3380 - f1: 0.5933 - val_loss: 0.3756 - val_f1: 0.1437\n",
      "Epoch 139/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3379 - f1: 0.5871 - val_loss: 0.3747 - val_f1: 0.1447\n",
      "Epoch 140/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3371 - f1: 0.5923 - val_loss: 0.3746 - val_f1: 0.1449\n",
      "Epoch 141/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3373 - f1: 0.5884 - val_loss: 0.3753 - val_f1: 0.1450\n",
      "Epoch 142/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3376 - f1: 0.5886 - val_loss: 0.3746 - val_f1: 0.1444\n",
      "Epoch 143/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3365 - f1: 0.5898 - val_loss: 0.3763 - val_f1: 0.1452\n",
      "Epoch 144/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3368 - f1: 0.5935 - val_loss: 0.3759 - val_f1: 0.1458\n",
      "Epoch 145/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3365 - f1: 0.5946 - val_loss: 0.3756 - val_f1: 0.1449\n",
      "Epoch 146/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3366 - f1: 0.5922 - val_loss: 0.3758 - val_f1: 0.1459\n",
      "Epoch 147/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3363 - f1: 0.5892 - val_loss: 0.3772 - val_f1: 0.1453\n",
      "Epoch 148/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3355 - f1: 0.5957 - val_loss: 0.3765 - val_f1: 0.1454\n",
      "Epoch 149/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3352 - f1: 0.5991 - val_loss: 0.3760 - val_f1: 0.1447\n",
      "Epoch 150/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3364 - f1: 0.5935 - val_loss: 0.3762 - val_f1: 0.1451\n",
      "Epoch 151/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3355 - f1: 0.5949 - val_loss: 0.3762 - val_f1: 0.1454\n",
      "Epoch 152/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3338 - f1: 0.5975 - val_loss: 0.3762 - val_f1: 0.1451\n",
      "Epoch 153/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3346 - f1: 0.5963 - val_loss: 0.3751 - val_f1: 0.1455\n",
      "Epoch 154/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3345 - f1: 0.5983 - val_loss: 0.3773 - val_f1: 0.1450\n",
      "Epoch 155/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3352 - f1: 0.5964 - val_loss: 0.3756 - val_f1: 0.1448\n",
      "Epoch 156/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.3354 - f1: 0.5942 - val_loss: 0.3761 - val_f1: 0.1436\n",
      "Epoch 157/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3344 - f1: 0.5945 - val_loss: 0.3778 - val_f1: 0.1442\n",
      "Epoch 158/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3343 - f1: 0.5974 - val_loss: 0.3755 - val_f1: 0.1437\n",
      "Epoch 159/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3339 - f1: 0.5984 - val_loss: 0.3756 - val_f1: 0.1450\n",
      "Epoch 160/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3341 - f1: 0.5971 - val_loss: 0.3745 - val_f1: 0.1441\n",
      "Epoch 161/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3326 - f1: 0.6044 - val_loss: 0.3792 - val_f1: 0.1442\n",
      "Epoch 162/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3340 - f1: 0.5935 - val_loss: 0.3765 - val_f1: 0.1439\n",
      "Epoch 163/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3334 - f1: 0.5968 - val_loss: 0.3782 - val_f1: 0.1453\n",
      "Epoch 164/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3338 - f1: 0.6019 - val_loss: 0.3762 - val_f1: 0.1427\n",
      "Epoch 165/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3320 - f1: 0.5940 - val_loss: 0.3805 - val_f1: 0.1451\n",
      "Epoch 166/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3328 - f1: 0.5961 - val_loss: 0.3771 - val_f1: 0.1439\n",
      "Epoch 167/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3317 - f1: 0.5998 - val_loss: 0.3799 - val_f1: 0.1460\n",
      "Epoch 168/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3316 - f1: 0.6039 - val_loss: 0.3802 - val_f1: 0.1460\n",
      "Epoch 169/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3325 - f1: 0.5992 - val_loss: 0.3774 - val_f1: 0.1452\n",
      "Epoch 170/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3321 - f1: 0.5997 - val_loss: 0.3773 - val_f1: 0.1458\n",
      "Epoch 171/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3298 - f1: 0.6074 - val_loss: 0.3782 - val_f1: 0.1445\n",
      "Epoch 172/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3307 - f1: 0.6089 - val_loss: 0.3794 - val_f1: 0.1447\n",
      "Epoch 173/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3312 - f1: 0.6012 - val_loss: 0.3770 - val_f1: 0.1441\n",
      "Epoch 174/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3302 - f1: 0.6020 - val_loss: 0.3792 - val_f1: 0.1445\n",
      "Epoch 175/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3310 - f1: 0.6044 - val_loss: 0.3776 - val_f1: 0.1445\n",
      "Epoch 176/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3320 - f1: 0.5993 - val_loss: 0.3788 - val_f1: 0.1446\n",
      "Epoch 177/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3300 - f1: 0.6047 - val_loss: 0.3788 - val_f1: 0.1451\n",
      "Epoch 178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3309 - f1: 0.6074 - val_loss: 0.3786 - val_f1: 0.1442\n",
      "Epoch 179/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3287 - f1: 0.6107 - val_loss: 0.3790 - val_f1: 0.1442\n",
      "Epoch 180/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3281 - f1: 0.6126 - val_loss: 0.3812 - val_f1: 0.1455\n",
      "Epoch 181/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3302 - f1: 0.6117 - val_loss: 0.3786 - val_f1: 0.1437\n",
      "Epoch 182/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3296 - f1: 0.6059 - val_loss: 0.3790 - val_f1: 0.1439\n",
      "Epoch 183/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3275 - f1: 0.6098 - val_loss: 0.3786 - val_f1: 0.1445\n",
      "Epoch 184/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3285 - f1: 0.6110 - val_loss: 0.3798 - val_f1: 0.1437\n",
      "Epoch 185/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3283 - f1: 0.6106 - val_loss: 0.3787 - val_f1: 0.1443\n",
      "Epoch 186/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3284 - f1: 0.6058 - val_loss: 0.3817 - val_f1: 0.1433\n",
      "Epoch 187/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3275 - f1: 0.6111 - val_loss: 0.3811 - val_f1: 0.1435\n",
      "Epoch 188/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3282 - f1: 0.6091 - val_loss: 0.3797 - val_f1: 0.1436\n",
      "Epoch 189/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3270 - f1: 0.6087 - val_loss: 0.3816 - val_f1: 0.1454\n",
      "Epoch 190/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3265 - f1: 0.6132 - val_loss: 0.3812 - val_f1: 0.1447\n",
      "Epoch 191/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3259 - f1: 0.6180 - val_loss: 0.3816 - val_f1: 0.1432\n",
      "Epoch 192/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3275 - f1: 0.6061 - val_loss: 0.3806 - val_f1: 0.1425\n",
      "Epoch 193/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3275 - f1: 0.6110 - val_loss: 0.3804 - val_f1: 0.1433\n",
      "Epoch 194/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3278 - f1: 0.6077 - val_loss: 0.3814 - val_f1: 0.1458\n",
      "Epoch 195/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3249 - f1: 0.6176 - val_loss: 0.3818 - val_f1: 0.1429\n",
      "Epoch 196/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3269 - f1: 0.6110 - val_loss: 0.3809 - val_f1: 0.1446\n",
      "Epoch 197/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3256 - f1: 0.6167 - val_loss: 0.3832 - val_f1: 0.1439\n",
      "Epoch 198/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3252 - f1: 0.6161 - val_loss: 0.3796 - val_f1: 0.1432\n",
      "Epoch 199/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3241 - f1: 0.6166 - val_loss: 0.3810 - val_f1: 0.1437\n",
      "Epoch 200/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3265 - f1: 0.6146 - val_loss: 0.3830 - val_f1: 0.1445\n",
      "Epoch 201/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3245 - f1: 0.6157 - val_loss: 0.3820 - val_f1: 0.1448\n",
      "Epoch 202/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3255 - f1: 0.6153 - val_loss: 0.3817 - val_f1: 0.1444\n",
      "Epoch 203/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3237 - f1: 0.6168 - val_loss: 0.3825 - val_f1: 0.1447\n",
      "Epoch 204/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3237 - f1: 0.6178 - val_loss: 0.3821 - val_f1: 0.1433\n",
      "Epoch 205/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3251 - f1: 0.6187 - val_loss: 0.3837 - val_f1: 0.1426\n",
      "Epoch 206/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3235 - f1: 0.6174 - val_loss: 0.3808 - val_f1: 0.1432\n",
      "Epoch 207/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3237 - f1: 0.6203 - val_loss: 0.3826 - val_f1: 0.1432\n",
      "Epoch 208/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3236 - f1: 0.6180 - val_loss: 0.3830 - val_f1: 0.1437\n",
      "Epoch 209/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3257 - f1: 0.6125 - val_loss: 0.3833 - val_f1: 0.1439\n",
      "Epoch 210/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3248 - f1: 0.6165 - val_loss: 0.3821 - val_f1: 0.1440\n",
      "Epoch 211/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3221 - f1: 0.6191 - val_loss: 0.3847 - val_f1: 0.1439\n",
      "Epoch 212/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3232 - f1: 0.6182 - val_loss: 0.3818 - val_f1: 0.1431\n",
      "Epoch 213/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3222 - f1: 0.6225 - val_loss: 0.3846 - val_f1: 0.1442\n",
      "Epoch 214/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3220 - f1: 0.6193 - val_loss: 0.3825 - val_f1: 0.1429\n",
      "Epoch 215/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3225 - f1: 0.6213 - val_loss: 0.3816 - val_f1: 0.1430\n",
      "Epoch 216/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3221 - f1: 0.6209 - val_loss: 0.3840 - val_f1: 0.1432\n",
      "Epoch 217/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3223 - f1: 0.6184 - val_loss: 0.3855 - val_f1: 0.1445\n",
      "Epoch 218/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3222 - f1: 0.6206 - val_loss: 0.3830 - val_f1: 0.1438\n",
      "Epoch 219/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3217 - f1: 0.6216 - val_loss: 0.3827 - val_f1: 0.1447\n",
      "Epoch 220/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3218 - f1: 0.6204 - val_loss: 0.3835 - val_f1: 0.1439\n",
      "Epoch 221/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3206 - f1: 0.6209 - val_loss: 0.3824 - val_f1: 0.1440\n",
      "Epoch 222/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3216 - f1: 0.6192 - val_loss: 0.3825 - val_f1: 0.1435\n",
      "Epoch 223/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3203 - f1: 0.6211 - val_loss: 0.3843 - val_f1: 0.1433\n",
      "Epoch 224/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3201 - f1: 0.6224 - val_loss: 0.3852 - val_f1: 0.1439\n",
      "Epoch 225/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3210 - f1: 0.6225 - val_loss: 0.3839 - val_f1: 0.1443\n",
      "Epoch 226/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3212 - f1: 0.6229 - val_loss: 0.3852 - val_f1: 0.1439\n",
      "Epoch 227/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3195 - f1: 0.6236 - val_loss: 0.3839 - val_f1: 0.1440\n",
      "Epoch 228/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3206 - f1: 0.6202 - val_loss: 0.3840 - val_f1: 0.1449\n",
      "Epoch 229/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3191 - f1: 0.6238 - val_loss: 0.3860 - val_f1: 0.1452\n",
      "Epoch 230/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3199 - f1: 0.6230 - val_loss: 0.3828 - val_f1: 0.1437\n",
      "Epoch 231/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3189 - f1: 0.6235 - val_loss: 0.3872 - val_f1: 0.1448\n",
      "Epoch 232/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3178 - f1: 0.6269 - val_loss: 0.3840 - val_f1: 0.1439\n",
      "Epoch 233/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3182 - f1: 0.6297 - val_loss: 0.3852 - val_f1: 0.1435\n",
      "Epoch 234/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3179 - f1: 0.6251 - val_loss: 0.3855 - val_f1: 0.1448\n",
      "Epoch 235/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3187 - f1: 0.6263 - val_loss: 0.3864 - val_f1: 0.1443\n",
      "Epoch 236/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3197 - f1: 0.6218 - val_loss: 0.3854 - val_f1: 0.1457\n",
      "Epoch 237/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3183 - f1: 0.6292 - val_loss: 0.3859 - val_f1: 0.1444\n",
      "Epoch 238/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3197 - f1: 0.6186 - val_loss: 0.3845 - val_f1: 0.1445\n",
      "Epoch 239/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3173 - f1: 0.6341 - val_loss: 0.3867 - val_f1: 0.1443\n",
      "Epoch 240/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3192 - f1: 0.6238 - val_loss: 0.3887 - val_f1: 0.1431\n",
      "Epoch 241/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3172 - f1: 0.6288 - val_loss: 0.3891 - val_f1: 0.1451\n",
      "Epoch 242/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3183 - f1: 0.6258 - val_loss: 0.3884 - val_f1: 0.1450\n",
      "Epoch 243/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3197 - f1: 0.6264 - val_loss: 0.3839 - val_f1: 0.1438\n",
      "Epoch 244/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3181 - f1: 0.6292 - val_loss: 0.3867 - val_f1: 0.1437\n",
      "Epoch 245/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3177 - f1: 0.6309 - val_loss: 0.3873 - val_f1: 0.1445\n",
      "Epoch 246/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3186 - f1: 0.6248 - val_loss: 0.3842 - val_f1: 0.1437\n",
      "Epoch 247/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3161 - f1: 0.6287 - val_loss: 0.3869 - val_f1: 0.1451\n",
      "Epoch 248/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3181 - f1: 0.6285 - val_loss: 0.3863 - val_f1: 0.1444\n",
      "Epoch 249/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3171 - f1: 0.6270 - val_loss: 0.3873 - val_f1: 0.1437\n",
      "Epoch 250/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3182 - f1: 0.6249 - val_loss: 0.3858 - val_f1: 0.1451\n",
      "Epoch 251/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3166 - f1: 0.6272 - val_loss: 0.3849 - val_f1: 0.1445\n",
      "Epoch 252/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3175 - f1: 0.6284 - val_loss: 0.3865 - val_f1: 0.1448\n",
      "Epoch 253/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3152 - f1: 0.6299 - val_loss: 0.3866 - val_f1: 0.1459\n",
      "Epoch 254/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3141 - f1: 0.6333 - val_loss: 0.3857 - val_f1: 0.1445\n",
      "Epoch 255/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3134 - f1: 0.6369 - val_loss: 0.3860 - val_f1: 0.1450\n",
      "Epoch 256/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3157 - f1: 0.6333 - val_loss: 0.3867 - val_f1: 0.1439\n",
      "Epoch 257/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3163 - f1: 0.6328 - val_loss: 0.3867 - val_f1: 0.1450\n",
      "Epoch 258/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3167 - f1: 0.6331 - val_loss: 0.3873 - val_f1: 0.1456\n",
      "Epoch 259/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3145 - f1: 0.6334 - val_loss: 0.3872 - val_f1: 0.1440\n",
      "Epoch 260/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3158 - f1: 0.6319 - val_loss: 0.3875 - val_f1: 0.1455\n",
      "Epoch 261/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3151 - f1: 0.6320 - val_loss: 0.3885 - val_f1: 0.1455\n",
      "Epoch 262/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3156 - f1: 0.6308 - val_loss: 0.3897 - val_f1: 0.1464\n",
      "Epoch 263/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3156 - f1: 0.6315 - val_loss: 0.3880 - val_f1: 0.1452\n",
      "Epoch 264/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3159 - f1: 0.6272 - val_loss: 0.3873 - val_f1: 0.1441\n",
      "Epoch 265/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3134 - f1: 0.6308 - val_loss: 0.3892 - val_f1: 0.1448\n",
      "Epoch 266/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3138 - f1: 0.6338 - val_loss: 0.3884 - val_f1: 0.1453\n",
      "Epoch 267/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3143 - f1: 0.6330 - val_loss: 0.3870 - val_f1: 0.1459\n",
      "Epoch 268/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3144 - f1: 0.6342 - val_loss: 0.3871 - val_f1: 0.1448\n",
      "Epoch 269/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3126 - f1: 0.6379 - val_loss: 0.3869 - val_f1: 0.1456\n",
      "Epoch 270/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3145 - f1: 0.6317 - val_loss: 0.3872 - val_f1: 0.1451\n",
      "Epoch 271/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3145 - f1: 0.6344 - val_loss: 0.3884 - val_f1: 0.1456\n",
      "Epoch 272/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3124 - f1: 0.6356 - val_loss: 0.3874 - val_f1: 0.1448\n",
      "Epoch 273/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3131 - f1: 0.6350 - val_loss: 0.3880 - val_f1: 0.1447\n",
      "Epoch 274/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3123 - f1: 0.6395 - val_loss: 0.3890 - val_f1: 0.1456\n",
      "Epoch 275/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3138 - f1: 0.6362 - val_loss: 0.3875 - val_f1: 0.1443\n",
      "Epoch 276/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3112 - f1: 0.6398 - val_loss: 0.3884 - val_f1: 0.1439\n",
      "Epoch 277/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3116 - f1: 0.6413 - val_loss: 0.3901 - val_f1: 0.1458\n",
      "Epoch 278/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3122 - f1: 0.6371 - val_loss: 0.3880 - val_f1: 0.1450\n",
      "Epoch 279/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3122 - f1: 0.6370 - val_loss: 0.3896 - val_f1: 0.1456\n",
      "Epoch 280/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.3111 - f1: 0.6445 - val_loss: 0.3901 - val_f1: 0.1456\n",
      "Epoch 281/2000\n",
      "64440/64440 [==============================] - 2s 36us/step - loss: 0.3109 - f1: 0.6398 - val_loss: 0.3874 - val_f1: 0.1453\n",
      "Epoch 282/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3097 - f1: 0.6459 - val_loss: 0.3890 - val_f1: 0.1453\n",
      "Epoch 283/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3119 - f1: 0.6385 - val_loss: 0.3866 - val_f1: 0.1452\n",
      "Epoch 284/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3121 - f1: 0.6422 - val_loss: 0.3891 - val_f1: 0.1457\n",
      "Epoch 285/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3095 - f1: 0.6443 - val_loss: 0.3891 - val_f1: 0.1456\n",
      "Epoch 286/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3108 - f1: 0.6403 - val_loss: 0.3894 - val_f1: 0.1455\n",
      "Epoch 287/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3084 - f1: 0.6426 - val_loss: 0.3888 - val_f1: 0.1465\n",
      "Epoch 288/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3115 - f1: 0.6399 - val_loss: 0.3910 - val_f1: 0.1451\n",
      "Epoch 289/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3098 - f1: 0.6417 - val_loss: 0.3907 - val_f1: 0.1468\n",
      "Epoch 290/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3112 - f1: 0.6434 - val_loss: 0.3907 - val_f1: 0.1453\n",
      "Epoch 291/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3111 - f1: 0.6334 - val_loss: 0.3908 - val_f1: 0.1448\n",
      "Epoch 292/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3114 - f1: 0.6407 - val_loss: 0.3910 - val_f1: 0.1468\n",
      "Epoch 293/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3096 - f1: 0.6438 - val_loss: 0.3909 - val_f1: 0.1458\n",
      "Epoch 294/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3110 - f1: 0.6401 - val_loss: 0.3903 - val_f1: 0.1447\n",
      "Epoch 295/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3097 - f1: 0.6430 - val_loss: 0.3893 - val_f1: 0.1453\n",
      "Epoch 296/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3102 - f1: 0.6410 - val_loss: 0.3920 - val_f1: 0.1457\n",
      "Epoch 297/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3092 - f1: 0.6457 - val_loss: 0.3887 - val_f1: 0.1460\n",
      "Epoch 298/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3083 - f1: 0.6438 - val_loss: 0.3893 - val_f1: 0.1454\n",
      "Epoch 299/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3090 - f1: 0.6428 - val_loss: 0.3903 - val_f1: 0.1461\n",
      "Epoch 300/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3109 - f1: 0.6368 - val_loss: 0.3886 - val_f1: 0.1452\n",
      "Epoch 301/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3091 - f1: 0.6419 - val_loss: 0.3929 - val_f1: 0.1460\n",
      "Epoch 302/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3099 - f1: 0.6352 - val_loss: 0.3916 - val_f1: 0.1455\n",
      "Epoch 303/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3077 - f1: 0.6463 - val_loss: 0.3915 - val_f1: 0.1463\n",
      "Epoch 304/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.3086 - f1: 0.6461 - val_loss: 0.3920 - val_f1: 0.1458\n",
      "Epoch 305/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3093 - f1: 0.6440 - val_loss: 0.3908 - val_f1: 0.1453\n",
      "Epoch 306/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3091 - f1: 0.6458 - val_loss: 0.3896 - val_f1: 0.1451\n",
      "Epoch 307/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3111 - f1: 0.6400 - val_loss: 0.3907 - val_f1: 0.1458\n",
      "Epoch 308/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3086 - f1: 0.6441 - val_loss: 0.3898 - val_f1: 0.1466\n",
      "Epoch 309/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3091 - f1: 0.6451 - val_loss: 0.3903 - val_f1: 0.1449\n",
      "Epoch 310/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3089 - f1: 0.6429 - val_loss: 0.3924 - val_f1: 0.1463\n",
      "Epoch 311/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3083 - f1: 0.6442 - val_loss: 0.3907 - val_f1: 0.1455\n",
      "Epoch 312/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3078 - f1: 0.6412 - val_loss: 0.3922 - val_f1: 0.1458\n",
      "Epoch 313/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3083 - f1: 0.6457 - val_loss: 0.3929 - val_f1: 0.1449\n",
      "Epoch 314/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3065 - f1: 0.6445 - val_loss: 0.3920 - val_f1: 0.1458\n",
      "Epoch 315/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3078 - f1: 0.6451 - val_loss: 0.3933 - val_f1: 0.1454\n",
      "Epoch 316/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3091 - f1: 0.6401 - val_loss: 0.3901 - val_f1: 0.1463\n",
      "Epoch 317/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3053 - f1: 0.6487 - val_loss: 0.3899 - val_f1: 0.1458\n",
      "Epoch 318/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3075 - f1: 0.6466 - val_loss: 0.3947 - val_f1: 0.1461\n",
      "Epoch 319/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3066 - f1: 0.6436 - val_loss: 0.3921 - val_f1: 0.1455\n",
      "Epoch 320/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3075 - f1: 0.6489 - val_loss: 0.3909 - val_f1: 0.1459\n",
      "Epoch 321/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3087 - f1: 0.6430 - val_loss: 0.3909 - val_f1: 0.1462\n",
      "Epoch 322/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3077 - f1: 0.6445 - val_loss: 0.3913 - val_f1: 0.1462\n",
      "Epoch 323/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3053 - f1: 0.6458 - val_loss: 0.3926 - val_f1: 0.1467\n",
      "Epoch 324/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3056 - f1: 0.6494 - val_loss: 0.3932 - val_f1: 0.1463\n",
      "Epoch 325/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3074 - f1: 0.6430 - val_loss: 0.3908 - val_f1: 0.1449\n",
      "Epoch 326/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3075 - f1: 0.6398 - val_loss: 0.3916 - val_f1: 0.1461\n",
      "Epoch 327/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3067 - f1: 0.6503 - val_loss: 0.3905 - val_f1: 0.1457\n",
      "Epoch 328/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3074 - f1: 0.6478 - val_loss: 0.3931 - val_f1: 0.1446\n",
      "Epoch 329/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3054 - f1: 0.6495 - val_loss: 0.3933 - val_f1: 0.1462\n",
      "Epoch 330/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3056 - f1: 0.6494 - val_loss: 0.3948 - val_f1: 0.1460\n",
      "Epoch 331/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3056 - f1: 0.6497 - val_loss: 0.3922 - val_f1: 0.1462\n",
      "Epoch 332/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3043 - f1: 0.6519 - val_loss: 0.3953 - val_f1: 0.1463\n",
      "Epoch 333/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3038 - f1: 0.6489 - val_loss: 0.3932 - val_f1: 0.1456\n",
      "Epoch 334/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3055 - f1: 0.6457 - val_loss: 0.3938 - val_f1: 0.1463\n",
      "Epoch 335/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3052 - f1: 0.6499 - val_loss: 0.3901 - val_f1: 0.1452\n",
      "Epoch 336/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3063 - f1: 0.6437 - val_loss: 0.3944 - val_f1: 0.1467\n",
      "Epoch 337/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3050 - f1: 0.6491 - val_loss: 0.3938 - val_f1: 0.1460\n",
      "Epoch 338/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3052 - f1: 0.6490 - val_loss: 0.3951 - val_f1: 0.1460\n",
      "Epoch 339/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3042 - f1: 0.6509 - val_loss: 0.3937 - val_f1: 0.1458\n",
      "Epoch 340/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3051 - f1: 0.6538 - val_loss: 0.3934 - val_f1: 0.1457\n",
      "Epoch 341/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3040 - f1: 0.6516 - val_loss: 0.3970 - val_f1: 0.1463\n",
      "Epoch 342/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3048 - f1: 0.6493 - val_loss: 0.3965 - val_f1: 0.1462\n",
      "Epoch 343/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3056 - f1: 0.6500 - val_loss: 0.3920 - val_f1: 0.1459\n",
      "Epoch 344/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3035 - f1: 0.6573 - val_loss: 0.3978 - val_f1: 0.1464\n",
      "Epoch 345/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3038 - f1: 0.6501 - val_loss: 0.3961 - val_f1: 0.1461\n",
      "Epoch 346/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3044 - f1: 0.6517 - val_loss: 0.3976 - val_f1: 0.1473\n",
      "Epoch 347/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3036 - f1: 0.6520 - val_loss: 0.3948 - val_f1: 0.1462\n",
      "Epoch 348/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3025 - f1: 0.6551 - val_loss: 0.3955 - val_f1: 0.1459\n",
      "Epoch 349/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3041 - f1: 0.6521 - val_loss: 0.3931 - val_f1: 0.1456\n",
      "Epoch 350/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3040 - f1: 0.6516 - val_loss: 0.3960 - val_f1: 0.1468\n",
      "Epoch 351/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3027 - f1: 0.6502 - val_loss: 0.3936 - val_f1: 0.1457\n",
      "Epoch 352/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3025 - f1: 0.6545 - val_loss: 0.3950 - val_f1: 0.1468\n",
      "Epoch 353/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3032 - f1: 0.6482 - val_loss: 0.3936 - val_f1: 0.1463\n",
      "Epoch 354/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3011 - f1: 0.6530 - val_loss: 0.3957 - val_f1: 0.1468\n",
      "Epoch 355/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3028 - f1: 0.6560 - val_loss: 0.3935 - val_f1: 0.1460\n",
      "Epoch 356/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3018 - f1: 0.6544 - val_loss: 0.3922 - val_f1: 0.1460\n",
      "Epoch 357/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3032 - f1: 0.6532 - val_loss: 0.3952 - val_f1: 0.1458\n",
      "Epoch 358/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3015 - f1: 0.6527 - val_loss: 0.3945 - val_f1: 0.1454\n",
      "Epoch 359/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3032 - f1: 0.6522 - val_loss: 0.3956 - val_f1: 0.1463\n",
      "Epoch 360/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3020 - f1: 0.6531 - val_loss: 0.3966 - val_f1: 0.1459\n",
      "Epoch 361/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3042 - f1: 0.6496 - val_loss: 0.3964 - val_f1: 0.1459\n",
      "Epoch 362/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3013 - f1: 0.6584 - val_loss: 0.3935 - val_f1: 0.1465\n",
      "Epoch 363/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3018 - f1: 0.6513 - val_loss: 0.3917 - val_f1: 0.1456\n",
      "Epoch 364/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3015 - f1: 0.6556 - val_loss: 0.3960 - val_f1: 0.1457\n",
      "Epoch 365/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3021 - f1: 0.6493 - val_loss: 0.3965 - val_f1: 0.1469\n",
      "Epoch 366/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3002 - f1: 0.6567 - val_loss: 0.3980 - val_f1: 0.1456\n",
      "Epoch 367/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3036 - f1: 0.6504 - val_loss: 0.3965 - val_f1: 0.1462\n",
      "Epoch 368/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3018 - f1: 0.6539 - val_loss: 0.3952 - val_f1: 0.1454\n",
      "Epoch 369/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3005 - f1: 0.6599 - val_loss: 0.3957 - val_f1: 0.1451\n",
      "Epoch 370/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3007 - f1: 0.6585 - val_loss: 0.3972 - val_f1: 0.1459\n",
      "Epoch 371/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3019 - f1: 0.6524 - val_loss: 0.3964 - val_f1: 0.1455\n",
      "Epoch 372/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3028 - f1: 0.6537 - val_loss: 0.3970 - val_f1: 0.1449\n",
      "Epoch 373/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3008 - f1: 0.6554 - val_loss: 0.3961 - val_f1: 0.1464\n",
      "Epoch 374/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3012 - f1: 0.6559 - val_loss: 0.3962 - val_f1: 0.1464\n",
      "Epoch 375/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3021 - f1: 0.6531 - val_loss: 0.3969 - val_f1: 0.1457\n",
      "Epoch 376/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3000 - f1: 0.6600 - val_loss: 0.3973 - val_f1: 0.1453\n",
      "Epoch 377/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3005 - f1: 0.6583 - val_loss: 0.3957 - val_f1: 0.1465\n",
      "Epoch 378/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.3008 - f1: 0.6596 - val_loss: 0.3971 - val_f1: 0.1455\n",
      "Epoch 379/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2996 - f1: 0.6562 - val_loss: 0.3959 - val_f1: 0.1463\n",
      "Epoch 380/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3009 - f1: 0.6548 - val_loss: 0.3985 - val_f1: 0.1464\n",
      "Epoch 381/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3004 - f1: 0.6608 - val_loss: 0.3980 - val_f1: 0.1456\n",
      "Epoch 382/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2989 - f1: 0.6595 - val_loss: 0.3962 - val_f1: 0.1464\n",
      "Epoch 383/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3015 - f1: 0.6529 - val_loss: 0.3993 - val_f1: 0.1469\n",
      "Epoch 384/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3000 - f1: 0.6599 - val_loss: 0.3964 - val_f1: 0.1449\n",
      "Epoch 385/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2982 - f1: 0.6607 - val_loss: 0.3934 - val_f1: 0.1455\n",
      "Epoch 386/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3007 - f1: 0.6582 - val_loss: 0.3975 - val_f1: 0.1465\n",
      "Epoch 387/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3006 - f1: 0.6593 - val_loss: 0.3973 - val_f1: 0.1465\n",
      "Epoch 388/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2992 - f1: 0.6604 - val_loss: 0.3967 - val_f1: 0.1454\n",
      "Epoch 389/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2996 - f1: 0.6595 - val_loss: 0.4019 - val_f1: 0.1464\n",
      "Epoch 390/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3004 - f1: 0.6540 - val_loss: 0.3978 - val_f1: 0.1459\n",
      "Epoch 391/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2993 - f1: 0.6598 - val_loss: 0.3978 - val_f1: 0.1459\n",
      "Epoch 392/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2994 - f1: 0.6577 - val_loss: 0.3944 - val_f1: 0.1461\n",
      "Epoch 393/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3004 - f1: 0.6546 - val_loss: 0.4001 - val_f1: 0.1461\n",
      "Epoch 394/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.3004 - f1: 0.6580 - val_loss: 0.3955 - val_f1: 0.1453\n",
      "Epoch 395/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2992 - f1: 0.6590 - val_loss: 0.4002 - val_f1: 0.1461\n",
      "Epoch 396/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2989 - f1: 0.6605 - val_loss: 0.3993 - val_f1: 0.1455\n",
      "Epoch 397/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2992 - f1: 0.6558 - val_loss: 0.3974 - val_f1: 0.1461\n",
      "Epoch 398/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2987 - f1: 0.6602 - val_loss: 0.4004 - val_f1: 0.1460\n",
      "Epoch 399/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3006 - f1: 0.6572 - val_loss: 0.3984 - val_f1: 0.1444\n",
      "Epoch 400/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2976 - f1: 0.6619 - val_loss: 0.3990 - val_f1: 0.1465\n",
      "Epoch 401/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2982 - f1: 0.6638 - val_loss: 0.3975 - val_f1: 0.1466\n",
      "Epoch 402/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2971 - f1: 0.6666 - val_loss: 0.3985 - val_f1: 0.1457\n",
      "Epoch 403/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2991 - f1: 0.6591 - val_loss: 0.4021 - val_f1: 0.1472\n",
      "Epoch 404/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2963 - f1: 0.6657 - val_loss: 0.3974 - val_f1: 0.1459\n",
      "Epoch 405/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2989 - f1: 0.6616 - val_loss: 0.4009 - val_f1: 0.1460\n",
      "Epoch 406/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2973 - f1: 0.6609 - val_loss: 0.4007 - val_f1: 0.1465\n",
      "Epoch 407/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2989 - f1: 0.6574 - val_loss: 0.3965 - val_f1: 0.1461\n",
      "Epoch 408/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2980 - f1: 0.6670 - val_loss: 0.3991 - val_f1: 0.1457\n",
      "Epoch 409/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2961 - f1: 0.6629 - val_loss: 0.4007 - val_f1: 0.1460\n",
      "Epoch 410/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2978 - f1: 0.6646 - val_loss: 0.3976 - val_f1: 0.1458\n",
      "Epoch 411/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2978 - f1: 0.6610 - val_loss: 0.3969 - val_f1: 0.1447\n",
      "Epoch 412/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2973 - f1: 0.6671 - val_loss: 0.4010 - val_f1: 0.1453\n",
      "Epoch 413/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2983 - f1: 0.6606 - val_loss: 0.3954 - val_f1: 0.1456\n",
      "Epoch 414/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2977 - f1: 0.6557 - val_loss: 0.3972 - val_f1: 0.1462\n",
      "Epoch 415/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2971 - f1: 0.6676 - val_loss: 0.3961 - val_f1: 0.1455\n",
      "Epoch 416/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2979 - f1: 0.6624 - val_loss: 0.3982 - val_f1: 0.1456\n",
      "Epoch 417/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2977 - f1: 0.6579 - val_loss: 0.3977 - val_f1: 0.1465\n",
      "Epoch 418/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2970 - f1: 0.6663 - val_loss: 0.3973 - val_f1: 0.1463\n",
      "Epoch 419/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2972 - f1: 0.6621 - val_loss: 0.4025 - val_f1: 0.1466\n",
      "Epoch 420/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2982 - f1: 0.6621 - val_loss: 0.3982 - val_f1: 0.1454\n",
      "Epoch 421/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2975 - f1: 0.6609 - val_loss: 0.3997 - val_f1: 0.1455\n",
      "Epoch 422/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2988 - f1: 0.6570 - val_loss: 0.3983 - val_f1: 0.1464\n",
      "Epoch 423/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2969 - f1: 0.6641 - val_loss: 0.4000 - val_f1: 0.1458\n",
      "Epoch 424/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2957 - f1: 0.6679 - val_loss: 0.3985 - val_f1: 0.1468\n",
      "Epoch 425/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2963 - f1: 0.6662 - val_loss: 0.3962 - val_f1: 0.1457\n",
      "Epoch 426/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2955 - f1: 0.6688 - val_loss: 0.4010 - val_f1: 0.1455\n",
      "Epoch 427/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2962 - f1: 0.6643 - val_loss: 0.3996 - val_f1: 0.1468\n",
      "Epoch 428/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2958 - f1: 0.6675 - val_loss: 0.4001 - val_f1: 0.1466\n",
      "Epoch 429/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2952 - f1: 0.6658 - val_loss: 0.3977 - val_f1: 0.1465\n",
      "Epoch 430/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2980 - f1: 0.6580 - val_loss: 0.3974 - val_f1: 0.1463\n",
      "Epoch 431/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2957 - f1: 0.6632 - val_loss: 0.3997 - val_f1: 0.1458\n",
      "Epoch 432/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2960 - f1: 0.6675 - val_loss: 0.3987 - val_f1: 0.1465\n",
      "Epoch 433/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2955 - f1: 0.6617 - val_loss: 0.3996 - val_f1: 0.1455\n",
      "Epoch 434/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2961 - f1: 0.6655 - val_loss: 0.3984 - val_f1: 0.1462\n",
      "Epoch 435/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2960 - f1: 0.6659 - val_loss: 0.3997 - val_f1: 0.1457\n",
      "Epoch 436/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2943 - f1: 0.6656 - val_loss: 0.4034 - val_f1: 0.1461\n",
      "Epoch 437/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2959 - f1: 0.6645 - val_loss: 0.4015 - val_f1: 0.1464\n",
      "Epoch 438/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2954 - f1: 0.6632 - val_loss: 0.3989 - val_f1: 0.1459\n",
      "Epoch 439/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2948 - f1: 0.6638 - val_loss: 0.3989 - val_f1: 0.1454\n",
      "Epoch 440/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2939 - f1: 0.6647 - val_loss: 0.3989 - val_f1: 0.1469\n",
      "Epoch 441/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2940 - f1: 0.6660 - val_loss: 0.4018 - val_f1: 0.1460\n",
      "Epoch 442/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2957 - f1: 0.6643 - val_loss: 0.4016 - val_f1: 0.1449\n",
      "Epoch 443/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2958 - f1: 0.6637 - val_loss: 0.3993 - val_f1: 0.1461\n",
      "Epoch 444/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2946 - f1: 0.6682 - val_loss: 0.4004 - val_f1: 0.1461\n",
      "Epoch 445/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2940 - f1: 0.6611 - val_loss: 0.4044 - val_f1: 0.1471\n",
      "Epoch 446/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2946 - f1: 0.6681 - val_loss: 0.4047 - val_f1: 0.1466\n",
      "Epoch 447/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2939 - f1: 0.6645 - val_loss: 0.4026 - val_f1: 0.1467\n",
      "Epoch 448/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2950 - f1: 0.6671 - val_loss: 0.4034 - val_f1: 0.1465\n",
      "Epoch 449/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2939 - f1: 0.6680 - val_loss: 0.4051 - val_f1: 0.1466\n",
      "Epoch 450/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2937 - f1: 0.6718 - val_loss: 0.4033 - val_f1: 0.1456\n",
      "Epoch 451/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2946 - f1: 0.6671 - val_loss: 0.4001 - val_f1: 0.1456\n",
      "Epoch 452/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2944 - f1: 0.6654 - val_loss: 0.4006 - val_f1: 0.1457\n",
      "Epoch 453/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2956 - f1: 0.6590 - val_loss: 0.4031 - val_f1: 0.1467\n",
      "Epoch 454/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2934 - f1: 0.6686 - val_loss: 0.4007 - val_f1: 0.1463\n",
      "Epoch 455/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2923 - f1: 0.6699 - val_loss: 0.4027 - val_f1: 0.1466\n",
      "Epoch 456/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2951 - f1: 0.6644 - val_loss: 0.4011 - val_f1: 0.1454\n",
      "Epoch 457/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2930 - f1: 0.6719 - val_loss: 0.4009 - val_f1: 0.1457\n",
      "Epoch 458/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2952 - f1: 0.6684 - val_loss: 0.3966 - val_f1: 0.1461\n",
      "Epoch 459/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2953 - f1: 0.6633 - val_loss: 0.3954 - val_f1: 0.1463\n",
      "Epoch 460/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2937 - f1: 0.6679 - val_loss: 0.4021 - val_f1: 0.1457\n",
      "Epoch 461/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2941 - f1: 0.6698 - val_loss: 0.4030 - val_f1: 0.1464\n",
      "Epoch 462/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2953 - f1: 0.6679 - val_loss: 0.3993 - val_f1: 0.1454\n",
      "Epoch 463/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2921 - f1: 0.6662 - val_loss: 0.4011 - val_f1: 0.1464\n",
      "Epoch 464/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2928 - f1: 0.6714 - val_loss: 0.4024 - val_f1: 0.1458\n",
      "Epoch 465/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2957 - f1: 0.6632 - val_loss: 0.3987 - val_f1: 0.1465\n",
      "Epoch 466/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2925 - f1: 0.6736 - val_loss: 0.3989 - val_f1: 0.1453\n",
      "Epoch 467/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2946 - f1: 0.6637 - val_loss: 0.4061 - val_f1: 0.1464\n",
      "Epoch 468/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2932 - f1: 0.6720 - val_loss: 0.4004 - val_f1: 0.1464\n",
      "Epoch 469/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2944 - f1: 0.6700 - val_loss: 0.4002 - val_f1: 0.1458\n",
      "Epoch 470/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2920 - f1: 0.6705 - val_loss: 0.4011 - val_f1: 0.1463\n",
      "Epoch 471/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2925 - f1: 0.6700 - val_loss: 0.3993 - val_f1: 0.1460\n",
      "Epoch 472/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2938 - f1: 0.6684 - val_loss: 0.4006 - val_f1: 0.1458\n",
      "Epoch 473/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2927 - f1: 0.6686 - val_loss: 0.4013 - val_f1: 0.1468\n",
      "Epoch 474/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2931 - f1: 0.6717 - val_loss: 0.4038 - val_f1: 0.1459\n",
      "Epoch 475/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2929 - f1: 0.6703 - val_loss: 0.4009 - val_f1: 0.1458\n",
      "Epoch 476/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2925 - f1: 0.6710 - val_loss: 0.4026 - val_f1: 0.1462\n",
      "Epoch 477/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2908 - f1: 0.6685 - val_loss: 0.4067 - val_f1: 0.1459\n",
      "Epoch 478/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2927 - f1: 0.6723 - val_loss: 0.4008 - val_f1: 0.1459\n",
      "Epoch 479/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2905 - f1: 0.6719 - val_loss: 0.4085 - val_f1: 0.1466\n",
      "Epoch 480/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2911 - f1: 0.6757 - val_loss: 0.4035 - val_f1: 0.1463\n",
      "Epoch 481/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2902 - f1: 0.6764 - val_loss: 0.4043 - val_f1: 0.1455\n",
      "Epoch 482/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2916 - f1: 0.6724 - val_loss: 0.4048 - val_f1: 0.1453\n",
      "Epoch 483/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2943 - f1: 0.6658 - val_loss: 0.4045 - val_f1: 0.1456\n",
      "Epoch 484/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2925 - f1: 0.6702 - val_loss: 0.3975 - val_f1: 0.1453\n",
      "Epoch 485/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2919 - f1: 0.6739 - val_loss: 0.4044 - val_f1: 0.1456\n",
      "Epoch 486/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2908 - f1: 0.6732 - val_loss: 0.3981 - val_f1: 0.1451\n",
      "Epoch 487/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2912 - f1: 0.6690 - val_loss: 0.4022 - val_f1: 0.1463\n",
      "Epoch 488/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2927 - f1: 0.6698 - val_loss: 0.4040 - val_f1: 0.1459\n",
      "Epoch 489/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2912 - f1: 0.6683 - val_loss: 0.4003 - val_f1: 0.1457\n",
      "Epoch 490/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2903 - f1: 0.6760 - val_loss: 0.4033 - val_f1: 0.1461\n",
      "Epoch 491/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2924 - f1: 0.6734 - val_loss: 0.4047 - val_f1: 0.1463\n",
      "Epoch 492/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2909 - f1: 0.6700 - val_loss: 0.4042 - val_f1: 0.1471\n",
      "Epoch 493/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2931 - f1: 0.6712 - val_loss: 0.4022 - val_f1: 0.1458\n",
      "Epoch 494/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2907 - f1: 0.6709 - val_loss: 0.4021 - val_f1: 0.1464\n",
      "Epoch 495/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2915 - f1: 0.6713 - val_loss: 0.4010 - val_f1: 0.1453\n",
      "Epoch 496/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2903 - f1: 0.6728 - val_loss: 0.4051 - val_f1: 0.1459\n",
      "Epoch 497/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2932 - f1: 0.6674 - val_loss: 0.4007 - val_f1: 0.1464\n",
      "Epoch 498/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2912 - f1: 0.6682 - val_loss: 0.4012 - val_f1: 0.1456\n",
      "Epoch 499/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2908 - f1: 0.6732 - val_loss: 0.4017 - val_f1: 0.1459\n",
      "Epoch 500/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2901 - f1: 0.6725 - val_loss: 0.4030 - val_f1: 0.1465\n",
      "Epoch 501/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2911 - f1: 0.6764 - val_loss: 0.4017 - val_f1: 0.1453\n",
      "Epoch 502/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2908 - f1: 0.6718 - val_loss: 0.4022 - val_f1: 0.1472\n",
      "Epoch 503/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2898 - f1: 0.6751 - val_loss: 0.4032 - val_f1: 0.1464\n",
      "Epoch 504/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2922 - f1: 0.6705 - val_loss: 0.4025 - val_f1: 0.1458\n",
      "Epoch 505/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2902 - f1: 0.6724 - val_loss: 0.4028 - val_f1: 0.1458\n",
      "Epoch 506/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2893 - f1: 0.6738 - val_loss: 0.4007 - val_f1: 0.1467\n",
      "Epoch 507/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2910 - f1: 0.6700 - val_loss: 0.4051 - val_f1: 0.1470\n",
      "Epoch 508/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2890 - f1: 0.6735 - val_loss: 0.4061 - val_f1: 0.1469\n",
      "Epoch 509/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2935 - f1: 0.6686 - val_loss: 0.4022 - val_f1: 0.1457\n",
      "Epoch 510/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2911 - f1: 0.6652 - val_loss: 0.4046 - val_f1: 0.1465\n",
      "Epoch 511/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2908 - f1: 0.6715 - val_loss: 0.4050 - val_f1: 0.1459\n",
      "Epoch 512/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2917 - f1: 0.6702 - val_loss: 0.4053 - val_f1: 0.1458\n",
      "Epoch 513/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2884 - f1: 0.6746 - val_loss: 0.4041 - val_f1: 0.1455\n",
      "Epoch 514/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2902 - f1: 0.6716 - val_loss: 0.4045 - val_f1: 0.1459\n",
      "Epoch 515/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2899 - f1: 0.6721 - val_loss: 0.4042 - val_f1: 0.1450\n",
      "Epoch 516/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2907 - f1: 0.6740 - val_loss: 0.4057 - val_f1: 0.1457\n",
      "Epoch 517/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2895 - f1: 0.6719 - val_loss: 0.4052 - val_f1: 0.1466\n",
      "Epoch 518/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2896 - f1: 0.6749 - val_loss: 0.4063 - val_f1: 0.1462\n",
      "Epoch 519/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2900 - f1: 0.6723 - val_loss: 0.4000 - val_f1: 0.1454\n",
      "Epoch 520/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2893 - f1: 0.6704 - val_loss: 0.4043 - val_f1: 0.1450\n",
      "Epoch 521/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2901 - f1: 0.6752 - val_loss: 0.4034 - val_f1: 0.1464\n",
      "Epoch 522/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2921 - f1: 0.6692 - val_loss: 0.4060 - val_f1: 0.1455\n",
      "Epoch 523/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2897 - f1: 0.6727 - val_loss: 0.4078 - val_f1: 0.1464\n",
      "Epoch 524/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2903 - f1: 0.6730 - val_loss: 0.4038 - val_f1: 0.1457\n",
      "Epoch 525/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2907 - f1: 0.6698 - val_loss: 0.4019 - val_f1: 0.1466\n",
      "Epoch 526/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2874 - f1: 0.6761 - val_loss: 0.4064 - val_f1: 0.1469\n",
      "Epoch 527/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2920 - f1: 0.6784 - val_loss: 0.4009 - val_f1: 0.1446\n",
      "Epoch 528/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2893 - f1: 0.6733 - val_loss: 0.4055 - val_f1: 0.1458\n",
      "Epoch 529/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2884 - f1: 0.6758 - val_loss: 0.4073 - val_f1: 0.1464\n",
      "Epoch 530/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2872 - f1: 0.6829 - val_loss: 0.4054 - val_f1: 0.1455\n",
      "Epoch 531/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2884 - f1: 0.6699 - val_loss: 0.4057 - val_f1: 0.1451\n",
      "Epoch 532/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2914 - f1: 0.6688 - val_loss: 0.4069 - val_f1: 0.1458\n",
      "Epoch 533/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2898 - f1: 0.6751 - val_loss: 0.4023 - val_f1: 0.1450\n",
      "Epoch 534/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2894 - f1: 0.6738 - val_loss: 0.3997 - val_f1: 0.1460\n",
      "Epoch 535/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2893 - f1: 0.6728 - val_loss: 0.4034 - val_f1: 0.1457\n",
      "Epoch 536/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2896 - f1: 0.6714 - val_loss: 0.4057 - val_f1: 0.1468\n",
      "Epoch 537/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2861 - f1: 0.6799 - val_loss: 0.4028 - val_f1: 0.1467\n",
      "Epoch 538/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2893 - f1: 0.6773 - val_loss: 0.4060 - val_f1: 0.1463\n",
      "Epoch 539/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2879 - f1: 0.6763 - val_loss: 0.4078 - val_f1: 0.1458\n",
      "Epoch 540/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2902 - f1: 0.6777 - val_loss: 0.4045 - val_f1: 0.1451\n",
      "Epoch 541/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2869 - f1: 0.6772 - val_loss: 0.4077 - val_f1: 0.1455\n",
      "Epoch 542/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2870 - f1: 0.6786 - val_loss: 0.4074 - val_f1: 0.1465\n",
      "Epoch 543/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2870 - f1: 0.6786 - val_loss: 0.4068 - val_f1: 0.1460\n",
      "Epoch 544/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2874 - f1: 0.6810 - val_loss: 0.4069 - val_f1: 0.1468\n",
      "Epoch 545/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2888 - f1: 0.6754 - val_loss: 0.4041 - val_f1: 0.1462\n",
      "Epoch 546/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2877 - f1: 0.6791 - val_loss: 0.4086 - val_f1: 0.1468\n",
      "Epoch 547/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2874 - f1: 0.6786 - val_loss: 0.4076 - val_f1: 0.1458\n",
      "Epoch 548/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2894 - f1: 0.6775 - val_loss: 0.4031 - val_f1: 0.1450\n",
      "Epoch 549/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2891 - f1: 0.6768 - val_loss: 0.4042 - val_f1: 0.1459\n",
      "Epoch 550/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2892 - f1: 0.6767 - val_loss: 0.4093 - val_f1: 0.1455\n",
      "Epoch 551/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2878 - f1: 0.6755 - val_loss: 0.4023 - val_f1: 0.1455\n",
      "Epoch 552/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2888 - f1: 0.6736 - val_loss: 0.4022 - val_f1: 0.1451\n",
      "Epoch 553/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2860 - f1: 0.6807 - val_loss: 0.4029 - val_f1: 0.1463\n",
      "Epoch 554/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2887 - f1: 0.6730 - val_loss: 0.4048 - val_f1: 0.1471\n",
      "Epoch 555/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2873 - f1: 0.6771 - val_loss: 0.4069 - val_f1: 0.1453\n",
      "Epoch 556/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2847 - f1: 0.6778 - val_loss: 0.4099 - val_f1: 0.1465\n",
      "Epoch 557/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2867 - f1: 0.6800 - val_loss: 0.4081 - val_f1: 0.1456\n",
      "Epoch 558/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2889 - f1: 0.6755 - val_loss: 0.4040 - val_f1: 0.1458\n",
      "Epoch 559/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2866 - f1: 0.6793 - val_loss: 0.4056 - val_f1: 0.1456\n",
      "Epoch 560/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2876 - f1: 0.6754 - val_loss: 0.4018 - val_f1: 0.1459\n",
      "Epoch 561/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2873 - f1: 0.6813 - val_loss: 0.4035 - val_f1: 0.1452\n",
      "Epoch 562/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2889 - f1: 0.6753 - val_loss: 0.4029 - val_f1: 0.1462\n",
      "Epoch 563/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2888 - f1: 0.6711 - val_loss: 0.4055 - val_f1: 0.1464\n",
      "Epoch 564/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2876 - f1: 0.6740 - val_loss: 0.4120 - val_f1: 0.1465\n",
      "Epoch 565/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2879 - f1: 0.6772 - val_loss: 0.4025 - val_f1: 0.1453\n",
      "Epoch 566/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2885 - f1: 0.6748 - val_loss: 0.4085 - val_f1: 0.1458\n",
      "Epoch 567/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2868 - f1: 0.6804 - val_loss: 0.4035 - val_f1: 0.1453\n",
      "Epoch 568/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2848 - f1: 0.6818 - val_loss: 0.4020 - val_f1: 0.1455\n",
      "Epoch 569/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2873 - f1: 0.6788 - val_loss: 0.4079 - val_f1: 0.1460\n",
      "Epoch 570/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2861 - f1: 0.6814 - val_loss: 0.4076 - val_f1: 0.1457\n",
      "Epoch 571/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2872 - f1: 0.6785 - val_loss: 0.4074 - val_f1: 0.1462\n",
      "Epoch 572/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2870 - f1: 0.6783 - val_loss: 0.4052 - val_f1: 0.1458\n",
      "Epoch 573/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2877 - f1: 0.6803 - val_loss: 0.4066 - val_f1: 0.1448\n",
      "Epoch 574/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2869 - f1: 0.6806 - val_loss: 0.4049 - val_f1: 0.1458\n",
      "Epoch 575/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2852 - f1: 0.6756 - val_loss: 0.4046 - val_f1: 0.1463\n",
      "Epoch 576/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2854 - f1: 0.6830 - val_loss: 0.4065 - val_f1: 0.1462\n",
      "Epoch 577/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2851 - f1: 0.6824 - val_loss: 0.4077 - val_f1: 0.1455\n",
      "Epoch 578/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2863 - f1: 0.6821 - val_loss: 0.4039 - val_f1: 0.1463\n",
      "Epoch 579/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2861 - f1: 0.6791 - val_loss: 0.4091 - val_f1: 0.1455\n",
      "Epoch 580/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2852 - f1: 0.6806 - val_loss: 0.4080 - val_f1: 0.1457\n",
      "Epoch 581/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2869 - f1: 0.6762 - val_loss: 0.4088 - val_f1: 0.1458\n",
      "Epoch 582/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2851 - f1: 0.6839 - val_loss: 0.4076 - val_f1: 0.1458\n",
      "Epoch 583/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2845 - f1: 0.6848 - val_loss: 0.4073 - val_f1: 0.1459\n",
      "Epoch 584/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2859 - f1: 0.6789 - val_loss: 0.4052 - val_f1: 0.1458\n",
      "Epoch 585/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2856 - f1: 0.6873 - val_loss: 0.4081 - val_f1: 0.1448\n",
      "Epoch 586/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2854 - f1: 0.6809 - val_loss: 0.4064 - val_f1: 0.1463\n",
      "Epoch 587/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2868 - f1: 0.6803 - val_loss: 0.4088 - val_f1: 0.1464\n",
      "Epoch 588/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2854 - f1: 0.6861 - val_loss: 0.4069 - val_f1: 0.1459\n",
      "Epoch 589/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2855 - f1: 0.6848 - val_loss: 0.4084 - val_f1: 0.1462\n",
      "Epoch 590/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2862 - f1: 0.6841 - val_loss: 0.4045 - val_f1: 0.1455\n",
      "Epoch 591/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2845 - f1: 0.6817 - val_loss: 0.4059 - val_f1: 0.1453\n",
      "Epoch 592/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2845 - f1: 0.6812 - val_loss: 0.4090 - val_f1: 0.1456\n",
      "Epoch 593/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2849 - f1: 0.6817 - val_loss: 0.4082 - val_f1: 0.1458\n",
      "Epoch 594/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2843 - f1: 0.6818 - val_loss: 0.4104 - val_f1: 0.1453\n",
      "Epoch 595/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2855 - f1: 0.6831 - val_loss: 0.4055 - val_f1: 0.1460\n",
      "Epoch 596/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2860 - f1: 0.6817 - val_loss: 0.4043 - val_f1: 0.1461\n",
      "Epoch 597/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2855 - f1: 0.6820 - val_loss: 0.4047 - val_f1: 0.1454\n",
      "Epoch 598/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2868 - f1: 0.6773 - val_loss: 0.4078 - val_f1: 0.1463\n",
      "Epoch 599/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2839 - f1: 0.6872 - val_loss: 0.4071 - val_f1: 0.1461\n",
      "Epoch 600/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2857 - f1: 0.6830 - val_loss: 0.4084 - val_f1: 0.1461\n",
      "Epoch 601/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2852 - f1: 0.6778 - val_loss: 0.4076 - val_f1: 0.1461\n",
      "Epoch 602/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2852 - f1: 0.6810 - val_loss: 0.4109 - val_f1: 0.1464\n",
      "Epoch 603/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2856 - f1: 0.6836 - val_loss: 0.4085 - val_f1: 0.1463\n",
      "Epoch 604/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2858 - f1: 0.6814 - val_loss: 0.4007 - val_f1: 0.1463\n",
      "Epoch 605/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2847 - f1: 0.6774 - val_loss: 0.4069 - val_f1: 0.1469\n",
      "Epoch 606/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2859 - f1: 0.6834 - val_loss: 0.4040 - val_f1: 0.1444\n",
      "Epoch 607/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2815 - f1: 0.6894 - val_loss: 0.4113 - val_f1: 0.1467\n",
      "Epoch 608/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2844 - f1: 0.6807 - val_loss: 0.4063 - val_f1: 0.1460\n",
      "Epoch 609/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2848 - f1: 0.6807 - val_loss: 0.4064 - val_f1: 0.1458\n",
      "Epoch 610/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2858 - f1: 0.6770 - val_loss: 0.4077 - val_f1: 0.1464\n",
      "Epoch 611/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2850 - f1: 0.6807 - val_loss: 0.4036 - val_f1: 0.1460\n",
      "Epoch 612/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2864 - f1: 0.6798 - val_loss: 0.4065 - val_f1: 0.1455\n",
      "Epoch 613/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2851 - f1: 0.6796 - val_loss: 0.4048 - val_f1: 0.1459\n",
      "Epoch 614/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2838 - f1: 0.6876 - val_loss: 0.4064 - val_f1: 0.1462\n",
      "Epoch 615/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2830 - f1: 0.6804 - val_loss: 0.4089 - val_f1: 0.1457\n",
      "Epoch 616/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2859 - f1: 0.6788 - val_loss: 0.4087 - val_f1: 0.1457\n",
      "Epoch 617/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2828 - f1: 0.6852 - val_loss: 0.4085 - val_f1: 0.1461\n",
      "Epoch 618/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2837 - f1: 0.6814 - val_loss: 0.4096 - val_f1: 0.1463\n",
      "Epoch 619/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2847 - f1: 0.6837 - val_loss: 0.4087 - val_f1: 0.1461\n",
      "Epoch 620/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2853 - f1: 0.6888 - val_loss: 0.4059 - val_f1: 0.1463\n",
      "Epoch 621/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2835 - f1: 0.6884 - val_loss: 0.4085 - val_f1: 0.1459\n",
      "Epoch 622/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2827 - f1: 0.6821 - val_loss: 0.4069 - val_f1: 0.1456\n",
      "Epoch 623/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2814 - f1: 0.6923 - val_loss: 0.4092 - val_f1: 0.1461\n",
      "Epoch 624/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2846 - f1: 0.6831 - val_loss: 0.4055 - val_f1: 0.1463\n",
      "Epoch 625/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2838 - f1: 0.6856 - val_loss: 0.4069 - val_f1: 0.1463\n",
      "Epoch 626/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2849 - f1: 0.6795 - val_loss: 0.4072 - val_f1: 0.1470\n",
      "Epoch 627/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2846 - f1: 0.6837 - val_loss: 0.4111 - val_f1: 0.1466\n",
      "Epoch 628/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2838 - f1: 0.6811 - val_loss: 0.4101 - val_f1: 0.1454\n",
      "Epoch 629/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2844 - f1: 0.6845 - val_loss: 0.4047 - val_f1: 0.1458\n",
      "Epoch 630/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2840 - f1: 0.6836 - val_loss: 0.4058 - val_f1: 0.1455\n",
      "Epoch 631/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2847 - f1: 0.6815 - val_loss: 0.4068 - val_f1: 0.1466\n",
      "Epoch 632/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2846 - f1: 0.6808 - val_loss: 0.4036 - val_f1: 0.1459\n",
      "Epoch 633/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2844 - f1: 0.6811 - val_loss: 0.4073 - val_f1: 0.1454\n",
      "Epoch 634/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2812 - f1: 0.6831 - val_loss: 0.4084 - val_f1: 0.1462\n",
      "Epoch 635/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2838 - f1: 0.6826 - val_loss: 0.4071 - val_f1: 0.1465\n",
      "Epoch 636/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2821 - f1: 0.6883 - val_loss: 0.4114 - val_f1: 0.1462\n",
      "Epoch 637/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2854 - f1: 0.6812 - val_loss: 0.4080 - val_f1: 0.1460\n",
      "Epoch 638/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2833 - f1: 0.6796 - val_loss: 0.4084 - val_f1: 0.1459\n",
      "Epoch 639/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2830 - f1: 0.6851 - val_loss: 0.4071 - val_f1: 0.1461\n",
      "Epoch 640/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2820 - f1: 0.6874 - val_loss: 0.4135 - val_f1: 0.1453\n",
      "Epoch 641/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2838 - f1: 0.6810 - val_loss: 0.4049 - val_f1: 0.1455\n",
      "Epoch 642/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2836 - f1: 0.6822 - val_loss: 0.4100 - val_f1: 0.1459\n",
      "Epoch 643/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2826 - f1: 0.6833 - val_loss: 0.4078 - val_f1: 0.1461\n",
      "Epoch 644/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2855 - f1: 0.6758 - val_loss: 0.4057 - val_f1: 0.1469\n",
      "Epoch 645/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2821 - f1: 0.6861 - val_loss: 0.4072 - val_f1: 0.1462\n",
      "Epoch 646/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2812 - f1: 0.6872 - val_loss: 0.4112 - val_f1: 0.1463\n",
      "Epoch 647/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2837 - f1: 0.6813 - val_loss: 0.4094 - val_f1: 0.1460\n",
      "Epoch 648/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2820 - f1: 0.6821 - val_loss: 0.4086 - val_f1: 0.1461\n",
      "Epoch 649/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2822 - f1: 0.6866 - val_loss: 0.4133 - val_f1: 0.1465\n",
      "Epoch 650/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2805 - f1: 0.6873 - val_loss: 0.4084 - val_f1: 0.1461\n",
      "Epoch 651/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2827 - f1: 0.6831 - val_loss: 0.4055 - val_f1: 0.1458\n",
      "Epoch 652/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2851 - f1: 0.6837 - val_loss: 0.4071 - val_f1: 0.1451\n",
      "Epoch 653/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2826 - f1: 0.6843 - val_loss: 0.4146 - val_f1: 0.1463\n",
      "Epoch 654/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2820 - f1: 0.6847 - val_loss: 0.4074 - val_f1: 0.1462\n",
      "Epoch 655/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2822 - f1: 0.6857 - val_loss: 0.4083 - val_f1: 0.1459\n",
      "Epoch 656/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2823 - f1: 0.6836 - val_loss: 0.4063 - val_f1: 0.1457\n",
      "Epoch 657/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2833 - f1: 0.6864 - val_loss: 0.4067 - val_f1: 0.1452\n",
      "Epoch 658/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2820 - f1: 0.6835 - val_loss: 0.4113 - val_f1: 0.1459\n",
      "Epoch 659/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2828 - f1: 0.6824 - val_loss: 0.4064 - val_f1: 0.1458\n",
      "Epoch 660/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2817 - f1: 0.6850 - val_loss: 0.4096 - val_f1: 0.1456\n",
      "Epoch 661/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2831 - f1: 0.6833 - val_loss: 0.4080 - val_f1: 0.1456\n",
      "Epoch 662/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2838 - f1: 0.6799 - val_loss: 0.4072 - val_f1: 0.1460\n",
      "Epoch 663/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2834 - f1: 0.6848 - val_loss: 0.4137 - val_f1: 0.1465\n",
      "Epoch 664/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2824 - f1: 0.6862 - val_loss: 0.4053 - val_f1: 0.1456\n",
      "Epoch 665/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2804 - f1: 0.6905 - val_loss: 0.4101 - val_f1: 0.1453\n",
      "Epoch 666/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2830 - f1: 0.6805 - val_loss: 0.4082 - val_f1: 0.1463\n",
      "Epoch 667/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2821 - f1: 0.6842 - val_loss: 0.4107 - val_f1: 0.1457\n",
      "Epoch 668/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2830 - f1: 0.6888 - val_loss: 0.4105 - val_f1: 0.1457\n",
      "Epoch 669/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2811 - f1: 0.6901 - val_loss: 0.4106 - val_f1: 0.1456\n",
      "Epoch 670/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2822 - f1: 0.6829 - val_loss: 0.4100 - val_f1: 0.1460\n",
      "Epoch 671/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2820 - f1: 0.6891 - val_loss: 0.4096 - val_f1: 0.1456\n",
      "Epoch 672/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2832 - f1: 0.6790 - val_loss: 0.4050 - val_f1: 0.1450\n",
      "Epoch 673/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2807 - f1: 0.6890 - val_loss: 0.4105 - val_f1: 0.1459\n",
      "Epoch 674/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2823 - f1: 0.6812 - val_loss: 0.4115 - val_f1: 0.1458\n",
      "Epoch 675/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2829 - f1: 0.6835 - val_loss: 0.4062 - val_f1: 0.1452\n",
      "Epoch 676/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2824 - f1: 0.6836 - val_loss: 0.4084 - val_f1: 0.1455\n",
      "Epoch 677/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2811 - f1: 0.6857 - val_loss: 0.4082 - val_f1: 0.1469\n",
      "Epoch 678/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2821 - f1: 0.6885 - val_loss: 0.4096 - val_f1: 0.1453\n",
      "Epoch 679/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2824 - f1: 0.6897 - val_loss: 0.4105 - val_f1: 0.1449\n",
      "Epoch 680/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2838 - f1: 0.6863 - val_loss: 0.4052 - val_f1: 0.1460\n",
      "Epoch 681/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2825 - f1: 0.6795 - val_loss: 0.4060 - val_f1: 0.1455\n",
      "Epoch 682/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2817 - f1: 0.6840 - val_loss: 0.4069 - val_f1: 0.1458\n",
      "Epoch 683/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2815 - f1: 0.6875 - val_loss: 0.4085 - val_f1: 0.1454\n",
      "Epoch 684/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2824 - f1: 0.6849 - val_loss: 0.4063 - val_f1: 0.1461\n",
      "Epoch 685/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2800 - f1: 0.6869 - val_loss: 0.4135 - val_f1: 0.1465\n",
      "Epoch 686/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2829 - f1: 0.6820 - val_loss: 0.4137 - val_f1: 0.1461\n",
      "Epoch 687/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2801 - f1: 0.6839 - val_loss: 0.4100 - val_f1: 0.1460\n",
      "Epoch 688/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2809 - f1: 0.6872 - val_loss: 0.4074 - val_f1: 0.1454\n",
      "Epoch 689/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2815 - f1: 0.6863 - val_loss: 0.4099 - val_f1: 0.1457\n",
      "Epoch 690/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2810 - f1: 0.6882 - val_loss: 0.4108 - val_f1: 0.1467\n",
      "Epoch 691/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2820 - f1: 0.6872 - val_loss: 0.4072 - val_f1: 0.1452\n",
      "Epoch 692/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2799 - f1: 0.6869 - val_loss: 0.4128 - val_f1: 0.1457\n",
      "Epoch 693/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2797 - f1: 0.6909 - val_loss: 0.4077 - val_f1: 0.1456\n",
      "Epoch 694/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2793 - f1: 0.6917 - val_loss: 0.4078 - val_f1: 0.1461\n",
      "Epoch 695/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2807 - f1: 0.6910 - val_loss: 0.4104 - val_f1: 0.1461\n",
      "Epoch 696/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2805 - f1: 0.6899 - val_loss: 0.4080 - val_f1: 0.1458\n",
      "Epoch 697/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2804 - f1: 0.6920 - val_loss: 0.4126 - val_f1: 0.1455\n",
      "Epoch 698/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2808 - f1: 0.6941 - val_loss: 0.4078 - val_f1: 0.1454\n",
      "Epoch 699/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2798 - f1: 0.6917 - val_loss: 0.4154 - val_f1: 0.1458\n",
      "Epoch 700/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2817 - f1: 0.6886 - val_loss: 0.4103 - val_f1: 0.1462\n",
      "Epoch 701/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2795 - f1: 0.6922 - val_loss: 0.4115 - val_f1: 0.1453\n",
      "Epoch 702/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2817 - f1: 0.6864 - val_loss: 0.4105 - val_f1: 0.1457\n",
      "Epoch 703/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2812 - f1: 0.6871 - val_loss: 0.4088 - val_f1: 0.1460\n",
      "Epoch 704/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2781 - f1: 0.6858 - val_loss: 0.4102 - val_f1: 0.1458\n",
      "Epoch 705/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2802 - f1: 0.6831 - val_loss: 0.4093 - val_f1: 0.1458\n",
      "Epoch 706/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2800 - f1: 0.6924 - val_loss: 0.4064 - val_f1: 0.1453\n",
      "Epoch 707/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2797 - f1: 0.6858 - val_loss: 0.4134 - val_f1: 0.1455\n",
      "Epoch 708/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2806 - f1: 0.6863 - val_loss: 0.4122 - val_f1: 0.1457\n",
      "Epoch 709/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2819 - f1: 0.6902 - val_loss: 0.4132 - val_f1: 0.1459\n",
      "Epoch 710/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2803 - f1: 0.6898 - val_loss: 0.4124 - val_f1: 0.1459\n",
      "Epoch 711/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2809 - f1: 0.6889 - val_loss: 0.4113 - val_f1: 0.1454\n",
      "Epoch 712/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2799 - f1: 0.6915 - val_loss: 0.4076 - val_f1: 0.1450\n",
      "Epoch 713/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2794 - f1: 0.6876 - val_loss: 0.4128 - val_f1: 0.1468\n",
      "Epoch 714/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2807 - f1: 0.6872 - val_loss: 0.4069 - val_f1: 0.1461\n",
      "Epoch 715/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2805 - f1: 0.6881 - val_loss: 0.4125 - val_f1: 0.1458\n",
      "Epoch 716/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2801 - f1: 0.6910 - val_loss: 0.4120 - val_f1: 0.1453\n",
      "Epoch 717/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2803 - f1: 0.6855 - val_loss: 0.4081 - val_f1: 0.1454\n",
      "Epoch 718/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2778 - f1: 0.6900 - val_loss: 0.4106 - val_f1: 0.1460\n",
      "Epoch 719/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2810 - f1: 0.6866 - val_loss: 0.4132 - val_f1: 0.1461\n",
      "Epoch 720/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2801 - f1: 0.6925 - val_loss: 0.4088 - val_f1: 0.1460\n",
      "Epoch 721/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2806 - f1: 0.6895 - val_loss: 0.4138 - val_f1: 0.1463\n",
      "Epoch 722/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2777 - f1: 0.6954 - val_loss: 0.4162 - val_f1: 0.1459\n",
      "Epoch 723/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2806 - f1: 0.6891 - val_loss: 0.4063 - val_f1: 0.1453\n",
      "Epoch 724/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2801 - f1: 0.6873 - val_loss: 0.4116 - val_f1: 0.1460\n",
      "Epoch 725/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2797 - f1: 0.6881 - val_loss: 0.4153 - val_f1: 0.1460\n",
      "Epoch 726/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2805 - f1: 0.6864 - val_loss: 0.4109 - val_f1: 0.1465\n",
      "Epoch 727/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2783 - f1: 0.6887 - val_loss: 0.4109 - val_f1: 0.1455\n",
      "Epoch 728/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2791 - f1: 0.6910 - val_loss: 0.4107 - val_f1: 0.1455\n",
      "Epoch 729/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2795 - f1: 0.6912 - val_loss: 0.4116 - val_f1: 0.1455\n",
      "Epoch 730/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2787 - f1: 0.6927 - val_loss: 0.4100 - val_f1: 0.1467\n",
      "Epoch 731/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2788 - f1: 0.6918 - val_loss: 0.4124 - val_f1: 0.1461\n",
      "Epoch 732/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2782 - f1: 0.6869 - val_loss: 0.4114 - val_f1: 0.1462\n",
      "Epoch 733/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2810 - f1: 0.6849 - val_loss: 0.4113 - val_f1: 0.1464\n",
      "Epoch 734/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2785 - f1: 0.6916 - val_loss: 0.4115 - val_f1: 0.1454\n",
      "Epoch 735/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2807 - f1: 0.6878 - val_loss: 0.4099 - val_f1: 0.1454\n",
      "Epoch 736/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2780 - f1: 0.6911 - val_loss: 0.4134 - val_f1: 0.1456\n",
      "Epoch 737/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2800 - f1: 0.6882 - val_loss: 0.4162 - val_f1: 0.1460\n",
      "Epoch 738/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2800 - f1: 0.6905 - val_loss: 0.4107 - val_f1: 0.1456\n",
      "Epoch 739/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2791 - f1: 0.6925 - val_loss: 0.4126 - val_f1: 0.1470\n",
      "Epoch 740/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2823 - f1: 0.6858 - val_loss: 0.4105 - val_f1: 0.1460\n",
      "Epoch 741/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2780 - f1: 0.6926 - val_loss: 0.4107 - val_f1: 0.1459\n",
      "Epoch 742/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2785 - f1: 0.6930 - val_loss: 0.4127 - val_f1: 0.1462\n",
      "Epoch 743/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2811 - f1: 0.6850 - val_loss: 0.4095 - val_f1: 0.1460\n",
      "Epoch 744/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2796 - f1: 0.6927 - val_loss: 0.4084 - val_f1: 0.1463\n",
      "Epoch 745/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2797 - f1: 0.6924 - val_loss: 0.4077 - val_f1: 0.1459\n",
      "Epoch 746/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2773 - f1: 0.6963 - val_loss: 0.4091 - val_f1: 0.1461\n",
      "Epoch 747/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2794 - f1: 0.6908 - val_loss: 0.4103 - val_f1: 0.1461\n",
      "Epoch 748/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2786 - f1: 0.6904 - val_loss: 0.4122 - val_f1: 0.1458\n",
      "Epoch 749/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2778 - f1: 0.6905 - val_loss: 0.4074 - val_f1: 0.1456\n",
      "Epoch 750/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2790 - f1: 0.6873 - val_loss: 0.4178 - val_f1: 0.1453\n",
      "Epoch 751/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2783 - f1: 0.6916 - val_loss: 0.4099 - val_f1: 0.1462\n",
      "Epoch 752/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2793 - f1: 0.6905 - val_loss: 0.4093 - val_f1: 0.1466\n",
      "Epoch 753/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2780 - f1: 0.6937 - val_loss: 0.4124 - val_f1: 0.1463\n",
      "Epoch 754/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2799 - f1: 0.6895 - val_loss: 0.4161 - val_f1: 0.1464\n",
      "Epoch 755/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2784 - f1: 0.6922 - val_loss: 0.4093 - val_f1: 0.1463\n",
      "Epoch 756/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2790 - f1: 0.6895 - val_loss: 0.4118 - val_f1: 0.1469\n",
      "Epoch 757/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2777 - f1: 0.6929 - val_loss: 0.4151 - val_f1: 0.1462\n",
      "Epoch 758/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2800 - f1: 0.6908 - val_loss: 0.4104 - val_f1: 0.1467\n",
      "Epoch 759/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2789 - f1: 0.6885 - val_loss: 0.4127 - val_f1: 0.1463\n",
      "Epoch 760/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2770 - f1: 0.6918 - val_loss: 0.4149 - val_f1: 0.1468\n",
      "Epoch 761/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2769 - f1: 0.6946 - val_loss: 0.4130 - val_f1: 0.1468\n",
      "Epoch 762/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2779 - f1: 0.6929 - val_loss: 0.4159 - val_f1: 0.1469\n",
      "Epoch 763/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2772 - f1: 0.6918 - val_loss: 0.4123 - val_f1: 0.1462\n",
      "Epoch 764/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2777 - f1: 0.6899 - val_loss: 0.4116 - val_f1: 0.1462\n",
      "Epoch 765/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2777 - f1: 0.6878 - val_loss: 0.4138 - val_f1: 0.1466\n",
      "Epoch 766/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2765 - f1: 0.6938 - val_loss: 0.4134 - val_f1: 0.1468\n",
      "Epoch 767/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2796 - f1: 0.6870 - val_loss: 0.4098 - val_f1: 0.1459\n",
      "Epoch 768/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2771 - f1: 0.6944 - val_loss: 0.4104 - val_f1: 0.1459\n",
      "Epoch 769/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2766 - f1: 0.6928 - val_loss: 0.4114 - val_f1: 0.1459\n",
      "Epoch 770/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2783 - f1: 0.6928 - val_loss: 0.4098 - val_f1: 0.1460\n",
      "Epoch 771/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2803 - f1: 0.6923 - val_loss: 0.4078 - val_f1: 0.1457\n",
      "Epoch 772/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2754 - f1: 0.6983 - val_loss: 0.4147 - val_f1: 0.1464\n",
      "Epoch 773/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2753 - f1: 0.6957 - val_loss: 0.4112 - val_f1: 0.1460\n",
      "Epoch 774/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2776 - f1: 0.6963 - val_loss: 0.4127 - val_f1: 0.1460\n",
      "Epoch 775/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2767 - f1: 0.6933 - val_loss: 0.4179 - val_f1: 0.1468\n",
      "Epoch 776/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2761 - f1: 0.6940 - val_loss: 0.4186 - val_f1: 0.1466\n",
      "Epoch 777/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2801 - f1: 0.6900 - val_loss: 0.4093 - val_f1: 0.1459\n",
      "Epoch 778/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2780 - f1: 0.6896 - val_loss: 0.4121 - val_f1: 0.1458\n",
      "Epoch 779/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2790 - f1: 0.6848 - val_loss: 0.4116 - val_f1: 0.1461\n",
      "Epoch 780/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2775 - f1: 0.6945 - val_loss: 0.4151 - val_f1: 0.1463\n",
      "Epoch 781/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2783 - f1: 0.6876 - val_loss: 0.4151 - val_f1: 0.1465\n",
      "Epoch 782/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2775 - f1: 0.6906 - val_loss: 0.4141 - val_f1: 0.1462\n",
      "Epoch 783/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2785 - f1: 0.6865 - val_loss: 0.4072 - val_f1: 0.1456\n",
      "Epoch 784/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2782 - f1: 0.6900 - val_loss: 0.4106 - val_f1: 0.1465\n",
      "Epoch 785/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2789 - f1: 0.6901 - val_loss: 0.4139 - val_f1: 0.1459\n",
      "Epoch 786/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2804 - f1: 0.6903 - val_loss: 0.4094 - val_f1: 0.1455\n",
      "Epoch 787/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2779 - f1: 0.6880 - val_loss: 0.4118 - val_f1: 0.1462\n",
      "Epoch 788/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2772 - f1: 0.6938 - val_loss: 0.4123 - val_f1: 0.1465\n",
      "Epoch 789/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2774 - f1: 0.6935 - val_loss: 0.4121 - val_f1: 0.1464\n",
      "Epoch 790/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2767 - f1: 0.6894 - val_loss: 0.4133 - val_f1: 0.1467\n",
      "Epoch 791/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2790 - f1: 0.6914 - val_loss: 0.4108 - val_f1: 0.1458\n",
      "Epoch 792/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2761 - f1: 0.6954 - val_loss: 0.4139 - val_f1: 0.1461\n",
      "Epoch 793/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2785 - f1: 0.6885 - val_loss: 0.4145 - val_f1: 0.1460\n",
      "Epoch 794/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.2775 - f1: 0.69 - 3s 43us/step - loss: 0.2773 - f1: 0.6946 - val_loss: 0.4192 - val_f1: 0.1464\n",
      "Epoch 795/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2779 - f1: 0.6887 - val_loss: 0.4127 - val_f1: 0.1464\n",
      "Epoch 796/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2777 - f1: 0.6913 - val_loss: 0.4092 - val_f1: 0.1453\n",
      "Epoch 797/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2751 - f1: 0.6913 - val_loss: 0.4141 - val_f1: 0.1467\n",
      "Epoch 798/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2785 - f1: 0.6959 - val_loss: 0.4065 - val_f1: 0.1458\n",
      "Epoch 799/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2775 - f1: 0.6963 - val_loss: 0.4113 - val_f1: 0.1456\n",
      "Epoch 800/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2789 - f1: 0.6898 - val_loss: 0.4130 - val_f1: 0.1465\n",
      "Epoch 801/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2788 - f1: 0.6918 - val_loss: 0.4119 - val_f1: 0.1454\n",
      "Epoch 802/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2758 - f1: 0.6954 - val_loss: 0.4137 - val_f1: 0.1464\n",
      "Epoch 803/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2771 - f1: 0.6919 - val_loss: 0.4126 - val_f1: 0.1465\n",
      "Epoch 804/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2768 - f1: 0.6918 - val_loss: 0.4135 - val_f1: 0.1460\n",
      "Epoch 805/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2769 - f1: 0.6915 - val_loss: 0.4153 - val_f1: 0.1454\n",
      "Epoch 806/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2770 - f1: 0.6938 - val_loss: 0.4155 - val_f1: 0.1460\n",
      "Epoch 807/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2763 - f1: 0.6949 - val_loss: 0.4131 - val_f1: 0.1464\n",
      "Epoch 808/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2777 - f1: 0.6890 - val_loss: 0.4129 - val_f1: 0.1462\n",
      "Epoch 809/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2767 - f1: 0.6934 - val_loss: 0.4123 - val_f1: 0.1460\n",
      "Epoch 810/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2762 - f1: 0.6941 - val_loss: 0.4124 - val_f1: 0.1464\n",
      "Epoch 811/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2765 - f1: 0.6931 - val_loss: 0.4165 - val_f1: 0.1464\n",
      "Epoch 812/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2768 - f1: 0.6916 - val_loss: 0.4203 - val_f1: 0.1468\n",
      "Epoch 813/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2774 - f1: 0.6893 - val_loss: 0.4141 - val_f1: 0.1457\n",
      "Epoch 814/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2750 - f1: 0.6975 - val_loss: 0.4129 - val_f1: 0.1462\n",
      "Epoch 815/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2771 - f1: 0.6997 - val_loss: 0.4129 - val_f1: 0.1460\n",
      "Epoch 816/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2755 - f1: 0.6942 - val_loss: 0.4105 - val_f1: 0.1463\n",
      "Epoch 817/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2778 - f1: 0.6938 - val_loss: 0.4116 - val_f1: 0.1460\n",
      "Epoch 818/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2756 - f1: 0.6962 - val_loss: 0.4184 - val_f1: 0.1459\n",
      "Epoch 819/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2760 - f1: 0.6928 - val_loss: 0.4190 - val_f1: 0.1460\n",
      "Epoch 820/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2773 - f1: 0.6934 - val_loss: 0.4151 - val_f1: 0.1457\n",
      "Epoch 821/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2753 - f1: 0.6935 - val_loss: 0.4168 - val_f1: 0.1461\n",
      "Epoch 822/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2763 - f1: 0.6980 - val_loss: 0.4130 - val_f1: 0.1462\n",
      "Epoch 823/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2743 - f1: 0.6949 - val_loss: 0.4205 - val_f1: 0.1464\n",
      "Epoch 824/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2761 - f1: 0.6942 - val_loss: 0.4145 - val_f1: 0.1454\n",
      "Epoch 825/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2751 - f1: 0.6942 - val_loss: 0.4194 - val_f1: 0.1462\n",
      "Epoch 826/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2773 - f1: 0.6920 - val_loss: 0.4146 - val_f1: 0.1458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2762 - f1: 0.6951 - val_loss: 0.4125 - val_f1: 0.1461\n",
      "Epoch 828/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2750 - f1: 0.6952 - val_loss: 0.4145 - val_f1: 0.1459\n",
      "Epoch 829/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2777 - f1: 0.6964 - val_loss: 0.4131 - val_f1: 0.1456\n",
      "Epoch 830/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2757 - f1: 0.6938 - val_loss: 0.4119 - val_f1: 0.1462\n",
      "Epoch 831/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2762 - f1: 0.6948 - val_loss: 0.4128 - val_f1: 0.1459\n",
      "Epoch 832/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2782 - f1: 0.6905 - val_loss: 0.4148 - val_f1: 0.1468\n",
      "Epoch 833/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2759 - f1: 0.6974 - val_loss: 0.4172 - val_f1: 0.1459\n",
      "Epoch 834/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2768 - f1: 0.6933 - val_loss: 0.4187 - val_f1: 0.1464\n",
      "Epoch 835/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2752 - f1: 0.6975 - val_loss: 0.4156 - val_f1: 0.1462\n",
      "Epoch 836/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2772 - f1: 0.6902 - val_loss: 0.4117 - val_f1: 0.1451\n",
      "Epoch 837/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2752 - f1: 0.6940 - val_loss: 0.4116 - val_f1: 0.1466\n",
      "Epoch 838/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2768 - f1: 0.6934 - val_loss: 0.4102 - val_f1: 0.1464\n",
      "Epoch 839/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2771 - f1: 0.6941 - val_loss: 0.4161 - val_f1: 0.1460\n",
      "Epoch 840/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2777 - f1: 0.6911 - val_loss: 0.4118 - val_f1: 0.1473\n",
      "Epoch 841/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2757 - f1: 0.6968 - val_loss: 0.4140 - val_f1: 0.1460\n",
      "Epoch 842/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2755 - f1: 0.6935 - val_loss: 0.4144 - val_f1: 0.1463\n",
      "Epoch 843/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2766 - f1: 0.6940 - val_loss: 0.4091 - val_f1: 0.1460\n",
      "Epoch 844/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2793 - f1: 0.6879 - val_loss: 0.4152 - val_f1: 0.1454\n",
      "Epoch 845/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2760 - f1: 0.6923 - val_loss: 0.4157 - val_f1: 0.1459\n",
      "Epoch 846/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2768 - f1: 0.6957 - val_loss: 0.4106 - val_f1: 0.1456\n",
      "Epoch 847/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2767 - f1: 0.6937 - val_loss: 0.4109 - val_f1: 0.1457\n",
      "Epoch 848/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2754 - f1: 0.6945 - val_loss: 0.4159 - val_f1: 0.1470\n",
      "Epoch 849/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2750 - f1: 0.6963 - val_loss: 0.4174 - val_f1: 0.1466\n",
      "Epoch 850/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2763 - f1: 0.6930 - val_loss: 0.4140 - val_f1: 0.1462\n",
      "Epoch 851/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2764 - f1: 0.6922 - val_loss: 0.4162 - val_f1: 0.1462\n",
      "Epoch 852/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2757 - f1: 0.6940 - val_loss: 0.4134 - val_f1: 0.1461\n",
      "Epoch 853/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2738 - f1: 0.6982 - val_loss: 0.4158 - val_f1: 0.1455\n",
      "Epoch 854/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2736 - f1: 0.6979 - val_loss: 0.4140 - val_f1: 0.1457\n",
      "Epoch 855/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2738 - f1: 0.7003 - val_loss: 0.4154 - val_f1: 0.1469\n",
      "Epoch 856/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2763 - f1: 0.6961 - val_loss: 0.4149 - val_f1: 0.1458\n",
      "Epoch 857/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2753 - f1: 0.6931 - val_loss: 0.4130 - val_f1: 0.1462\n",
      "Epoch 858/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2732 - f1: 0.6996 - val_loss: 0.4147 - val_f1: 0.1460\n",
      "Epoch 859/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2779 - f1: 0.6931 - val_loss: 0.4117 - val_f1: 0.1458\n",
      "Epoch 860/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2751 - f1: 0.6991 - val_loss: 0.4161 - val_f1: 0.1457\n",
      "Epoch 861/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2747 - f1: 0.6983 - val_loss: 0.4150 - val_f1: 0.1459\n",
      "Epoch 862/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2760 - f1: 0.6982 - val_loss: 0.4191 - val_f1: 0.1459\n",
      "Epoch 863/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2744 - f1: 0.6960 - val_loss: 0.4169 - val_f1: 0.1464\n",
      "Epoch 864/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2737 - f1: 0.6965 - val_loss: 0.4137 - val_f1: 0.1458\n",
      "Epoch 865/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2735 - f1: 0.6988 - val_loss: 0.4151 - val_f1: 0.1462\n",
      "Epoch 866/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2745 - f1: 0.6975 - val_loss: 0.4121 - val_f1: 0.1451\n",
      "Epoch 867/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2750 - f1: 0.6928 - val_loss: 0.4139 - val_f1: 0.1452\n",
      "Epoch 868/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2763 - f1: 0.6929 - val_loss: 0.4139 - val_f1: 0.1459\n",
      "Epoch 869/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2750 - f1: 0.6939 - val_loss: 0.4133 - val_f1: 0.1469\n",
      "Epoch 870/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2752 - f1: 0.6980 - val_loss: 0.4154 - val_f1: 0.1462\n",
      "Epoch 871/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2754 - f1: 0.6963 - val_loss: 0.4154 - val_f1: 0.1467\n",
      "Epoch 872/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2756 - f1: 0.6929 - val_loss: 0.4125 - val_f1: 0.1457\n",
      "Epoch 873/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2746 - f1: 0.6980 - val_loss: 0.4158 - val_f1: 0.1462\n",
      "Epoch 874/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2777 - f1: 0.6918 - val_loss: 0.4115 - val_f1: 0.1461\n",
      "Epoch 875/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2743 - f1: 0.6968 - val_loss: 0.4153 - val_f1: 0.1463\n",
      "Epoch 876/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2727 - f1: 0.7012 - val_loss: 0.4170 - val_f1: 0.1465\n",
      "Epoch 877/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2757 - f1: 0.6986 - val_loss: 0.4160 - val_f1: 0.1460\n",
      "Epoch 878/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2731 - f1: 0.7026 - val_loss: 0.4149 - val_f1: 0.1454\n",
      "Epoch 879/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2731 - f1: 0.6991 - val_loss: 0.4180 - val_f1: 0.1459\n",
      "Epoch 880/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2757 - f1: 0.6941 - val_loss: 0.4124 - val_f1: 0.1460\n",
      "Epoch 881/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2740 - f1: 0.6987 - val_loss: 0.4165 - val_f1: 0.1460\n",
      "Epoch 882/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2738 - f1: 0.6961 - val_loss: 0.4148 - val_f1: 0.1461\n",
      "Epoch 883/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2744 - f1: 0.6959 - val_loss: 0.4160 - val_f1: 0.1462\n",
      "Epoch 884/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2742 - f1: 0.6982 - val_loss: 0.4162 - val_f1: 0.1455\n",
      "Epoch 885/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2743 - f1: 0.6980 - val_loss: 0.4164 - val_f1: 0.1470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 886/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2742 - f1: 0.6963 - val_loss: 0.4127 - val_f1: 0.1455\n",
      "Epoch 887/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2728 - f1: 0.6982 - val_loss: 0.4131 - val_f1: 0.1453\n",
      "Epoch 888/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2742 - f1: 0.6982 - val_loss: 0.4163 - val_f1: 0.1458\n",
      "Epoch 889/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2740 - f1: 0.6945 - val_loss: 0.4141 - val_f1: 0.1456\n",
      "Epoch 890/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2755 - f1: 0.6943 - val_loss: 0.4149 - val_f1: 0.1461\n",
      "Epoch 891/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2760 - f1: 0.6979 - val_loss: 0.4174 - val_f1: 0.1460\n",
      "Epoch 892/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2752 - f1: 0.6926 - val_loss: 0.4133 - val_f1: 0.1455\n",
      "Epoch 893/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2729 - f1: 0.6986 - val_loss: 0.4144 - val_f1: 0.1455\n",
      "Epoch 894/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2737 - f1: 0.6959 - val_loss: 0.4188 - val_f1: 0.1459\n",
      "Epoch 895/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2741 - f1: 0.6994 - val_loss: 0.4199 - val_f1: 0.1457\n",
      "Epoch 896/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2727 - f1: 0.7006 - val_loss: 0.4193 - val_f1: 0.1464\n",
      "Epoch 897/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2744 - f1: 0.6967 - val_loss: 0.4214 - val_f1: 0.1458\n",
      "Epoch 898/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2744 - f1: 0.6936 - val_loss: 0.4142 - val_f1: 0.1458\n",
      "Epoch 899/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2741 - f1: 0.6936 - val_loss: 0.4164 - val_f1: 0.1461\n",
      "Epoch 900/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2729 - f1: 0.7009 - val_loss: 0.4158 - val_f1: 0.1465\n",
      "Epoch 901/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2741 - f1: 0.7013 - val_loss: 0.4140 - val_f1: 0.1456\n",
      "Epoch 902/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2746 - f1: 0.6993 - val_loss: 0.4165 - val_f1: 0.1456\n",
      "Epoch 903/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2737 - f1: 0.7002 - val_loss: 0.4164 - val_f1: 0.1462\n",
      "Epoch 904/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2736 - f1: 0.6978 - val_loss: 0.4177 - val_f1: 0.1465\n",
      "Epoch 905/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2748 - f1: 0.6963 - val_loss: 0.4121 - val_f1: 0.1460\n",
      "Epoch 906/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2736 - f1: 0.6990 - val_loss: 0.4157 - val_f1: 0.1452\n",
      "Epoch 907/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2718 - f1: 0.6984 - val_loss: 0.4149 - val_f1: 0.1467\n",
      "Epoch 908/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2740 - f1: 0.7002 - val_loss: 0.4154 - val_f1: 0.1458\n",
      "Epoch 909/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2766 - f1: 0.6958 - val_loss: 0.4188 - val_f1: 0.1454\n",
      "Epoch 910/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2756 - f1: 0.6946 - val_loss: 0.4148 - val_f1: 0.1457\n",
      "Epoch 911/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2739 - f1: 0.6957 - val_loss: 0.4115 - val_f1: 0.1451\n",
      "Epoch 912/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2745 - f1: 0.6960 - val_loss: 0.4142 - val_f1: 0.1456\n",
      "Epoch 913/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2753 - f1: 0.6973 - val_loss: 0.4182 - val_f1: 0.1460\n",
      "Epoch 914/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2724 - f1: 0.7006 - val_loss: 0.4159 - val_f1: 0.1457\n",
      "Epoch 915/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2728 - f1: 0.6994 - val_loss: 0.4171 - val_f1: 0.1455\n",
      "Epoch 916/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2760 - f1: 0.6951 - val_loss: 0.4133 - val_f1: 0.1456\n",
      "Epoch 917/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2748 - f1: 0.6976 - val_loss: 0.4108 - val_f1: 0.1461\n",
      "Epoch 918/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2756 - f1: 0.6975 - val_loss: 0.4126 - val_f1: 0.1457\n",
      "Epoch 919/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2753 - f1: 0.6961 - val_loss: 0.4133 - val_f1: 0.1452\n",
      "Epoch 920/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2741 - f1: 0.6969 - val_loss: 0.4157 - val_f1: 0.1455\n",
      "Epoch 921/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2756 - f1: 0.6960 - val_loss: 0.4147 - val_f1: 0.1458\n",
      "Epoch 922/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2710 - f1: 0.7044 - val_loss: 0.4159 - val_f1: 0.1457\n",
      "Epoch 923/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2728 - f1: 0.7028 - val_loss: 0.4148 - val_f1: 0.1459\n",
      "Epoch 924/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2743 - f1: 0.6992 - val_loss: 0.4161 - val_f1: 0.1455\n",
      "Epoch 925/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2726 - f1: 0.6988 - val_loss: 0.4159 - val_f1: 0.1450\n",
      "Epoch 926/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2739 - f1: 0.6973 - val_loss: 0.4207 - val_f1: 0.1456\n",
      "Epoch 927/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2739 - f1: 0.6983 - val_loss: 0.4172 - val_f1: 0.1459\n",
      "Epoch 928/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2735 - f1: 0.6975 - val_loss: 0.4161 - val_f1: 0.1457\n",
      "Epoch 929/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2731 - f1: 0.7022 - val_loss: 0.4167 - val_f1: 0.1453\n",
      "Epoch 930/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2727 - f1: 0.6989 - val_loss: 0.4174 - val_f1: 0.1453\n",
      "Epoch 931/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2731 - f1: 0.6973 - val_loss: 0.4128 - val_f1: 0.1451\n",
      "Epoch 932/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2729 - f1: 0.6980 - val_loss: 0.4147 - val_f1: 0.1448\n",
      "Epoch 933/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2730 - f1: 0.7014 - val_loss: 0.4174 - val_f1: 0.1457\n",
      "Epoch 934/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2743 - f1: 0.6978 - val_loss: 0.4166 - val_f1: 0.1453\n",
      "Epoch 935/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2721 - f1: 0.7003 - val_loss: 0.4160 - val_f1: 0.1454\n",
      "Epoch 936/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2721 - f1: 0.6991 - val_loss: 0.4160 - val_f1: 0.1454\n",
      "Epoch 937/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2725 - f1: 0.7030 - val_loss: 0.4131 - val_f1: 0.1455\n",
      "Epoch 938/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2745 - f1: 0.6983 - val_loss: 0.4205 - val_f1: 0.1456\n",
      "Epoch 939/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2732 - f1: 0.6972 - val_loss: 0.4183 - val_f1: 0.1462\n",
      "Epoch 940/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2741 - f1: 0.6974 - val_loss: 0.4177 - val_f1: 0.1456\n",
      "Epoch 941/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2733 - f1: 0.7031 - val_loss: 0.4168 - val_f1: 0.1453\n",
      "Epoch 942/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2718 - f1: 0.7024 - val_loss: 0.4128 - val_f1: 0.1455\n",
      "Epoch 943/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2720 - f1: 0.6986 - val_loss: 0.4179 - val_f1: 0.1459\n",
      "Epoch 944/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2727 - f1: 0.7024 - val_loss: 0.4170 - val_f1: 0.1455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 945/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2742 - f1: 0.6935 - val_loss: 0.4151 - val_f1: 0.1452\n",
      "Epoch 946/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2711 - f1: 0.6980 - val_loss: 0.4196 - val_f1: 0.1450\n",
      "Epoch 947/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2730 - f1: 0.6965 - val_loss: 0.4146 - val_f1: 0.1455\n",
      "Epoch 948/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2726 - f1: 0.7039 - val_loss: 0.4184 - val_f1: 0.1456\n",
      "Epoch 949/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2731 - f1: 0.7004 - val_loss: 0.4137 - val_f1: 0.1453\n",
      "Epoch 950/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2727 - f1: 0.6991 - val_loss: 0.4204 - val_f1: 0.1458\n",
      "Epoch 951/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2725 - f1: 0.6999 - val_loss: 0.4191 - val_f1: 0.1460\n",
      "Epoch 952/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2720 - f1: 0.7014 - val_loss: 0.4174 - val_f1: 0.1452\n",
      "Epoch 953/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2696 - f1: 0.7079 - val_loss: 0.4200 - val_f1: 0.1457\n",
      "Epoch 954/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2741 - f1: 0.7028 - val_loss: 0.4147 - val_f1: 0.1451\n",
      "Epoch 955/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2723 - f1: 0.7013 - val_loss: 0.4206 - val_f1: 0.1458\n",
      "Epoch 956/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2734 - f1: 0.6994 - val_loss: 0.4128 - val_f1: 0.1454\n",
      "Epoch 957/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2733 - f1: 0.6951 - val_loss: 0.4191 - val_f1: 0.1461\n",
      "Epoch 958/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2704 - f1: 0.7056 - val_loss: 0.4190 - val_f1: 0.1457\n",
      "Epoch 959/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2721 - f1: 0.7007 - val_loss: 0.4159 - val_f1: 0.1460\n",
      "Epoch 960/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2731 - f1: 0.7018 - val_loss: 0.4161 - val_f1: 0.1455\n",
      "Epoch 961/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2730 - f1: 0.7002 - val_loss: 0.4163 - val_f1: 0.1452\n",
      "Epoch 962/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2719 - f1: 0.6998 - val_loss: 0.4189 - val_f1: 0.1460\n",
      "Epoch 963/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2739 - f1: 0.7001 - val_loss: 0.4188 - val_f1: 0.1457\n",
      "Epoch 964/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2714 - f1: 0.7033 - val_loss: 0.4169 - val_f1: 0.1454\n",
      "Epoch 965/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2740 - f1: 0.6949 - val_loss: 0.4147 - val_f1: 0.1461\n",
      "Epoch 966/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2717 - f1: 0.7026 - val_loss: 0.4203 - val_f1: 0.1462\n",
      "Epoch 967/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2698 - f1: 0.7027 - val_loss: 0.4158 - val_f1: 0.1466\n",
      "Epoch 968/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2742 - f1: 0.6968 - val_loss: 0.4156 - val_f1: 0.1453\n",
      "Epoch 969/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2726 - f1: 0.7008 - val_loss: 0.4202 - val_f1: 0.1458\n",
      "Epoch 970/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2713 - f1: 0.7013 - val_loss: 0.4163 - val_f1: 0.1458\n",
      "Epoch 971/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2705 - f1: 0.7002 - val_loss: 0.4219 - val_f1: 0.1467\n",
      "Epoch 972/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2707 - f1: 0.7004 - val_loss: 0.4182 - val_f1: 0.1454\n",
      "Epoch 973/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2740 - f1: 0.6967 - val_loss: 0.4178 - val_f1: 0.1462\n",
      "Epoch 974/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2729 - f1: 0.6983 - val_loss: 0.4206 - val_f1: 0.1463\n",
      "Epoch 975/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2688 - f1: 0.7072 - val_loss: 0.4210 - val_f1: 0.1464\n",
      "Epoch 976/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2708 - f1: 0.7016 - val_loss: 0.4200 - val_f1: 0.1461\n",
      "Epoch 977/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2730 - f1: 0.6969 - val_loss: 0.4157 - val_f1: 0.1457\n",
      "Epoch 978/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2717 - f1: 0.7023 - val_loss: 0.4212 - val_f1: 0.1459\n",
      "Epoch 979/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2721 - f1: 0.7002 - val_loss: 0.4162 - val_f1: 0.1458\n",
      "Epoch 980/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2710 - f1: 0.7022 - val_loss: 0.4114 - val_f1: 0.1448\n",
      "Epoch 981/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2717 - f1: 0.7030 - val_loss: 0.4171 - val_f1: 0.1459\n",
      "Epoch 982/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2728 - f1: 0.7017 - val_loss: 0.4183 - val_f1: 0.1450\n",
      "Epoch 983/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2706 - f1: 0.7023 - val_loss: 0.4182 - val_f1: 0.1453\n",
      "Epoch 984/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2713 - f1: 0.7025 - val_loss: 0.4195 - val_f1: 0.1461\n",
      "Epoch 985/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2701 - f1: 0.7037 - val_loss: 0.4223 - val_f1: 0.1458\n",
      "Epoch 986/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2736 - f1: 0.7013 - val_loss: 0.4166 - val_f1: 0.1450\n",
      "Epoch 987/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2708 - f1: 0.7064 - val_loss: 0.4193 - val_f1: 0.1450\n",
      "Epoch 988/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2720 - f1: 0.7014 - val_loss: 0.4191 - val_f1: 0.1464\n",
      "Epoch 989/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2713 - f1: 0.7044 - val_loss: 0.4137 - val_f1: 0.1458\n",
      "Epoch 990/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2720 - f1: 0.7034 - val_loss: 0.4179 - val_f1: 0.1454\n",
      "Epoch 991/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2721 - f1: 0.7009 - val_loss: 0.4159 - val_f1: 0.1454\n",
      "Epoch 992/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2739 - f1: 0.6943 - val_loss: 0.4143 - val_f1: 0.1460\n",
      "Epoch 993/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2694 - f1: 0.7039 - val_loss: 0.4217 - val_f1: 0.1461\n",
      "Epoch 994/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2721 - f1: 0.7020 - val_loss: 0.4174 - val_f1: 0.1453\n",
      "Epoch 995/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2700 - f1: 0.7054 - val_loss: 0.4192 - val_f1: 0.1461\n",
      "Epoch 996/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2721 - f1: 0.6997 - val_loss: 0.4208 - val_f1: 0.1457\n",
      "Epoch 997/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2742 - f1: 0.6972 - val_loss: 0.4111 - val_f1: 0.1456\n",
      "Epoch 998/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2718 - f1: 0.6958 - val_loss: 0.4193 - val_f1: 0.1460\n",
      "Epoch 999/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2724 - f1: 0.7058 - val_loss: 0.4161 - val_f1: 0.1465\n",
      "Epoch 1000/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2722 - f1: 0.7012 - val_loss: 0.4172 - val_f1: 0.1460\n",
      "Epoch 1001/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2720 - f1: 0.6968 - val_loss: 0.4200 - val_f1: 0.1465\n",
      "Epoch 1002/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2710 - f1: 0.6999 - val_loss: 0.4185 - val_f1: 0.1459\n",
      "Epoch 1003/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2698 - f1: 0.7039 - val_loss: 0.4212 - val_f1: 0.1455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1004/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2712 - f1: 0.7001 - val_loss: 0.4178 - val_f1: 0.1458\n",
      "Epoch 1005/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2700 - f1: 0.7043 - val_loss: 0.4232 - val_f1: 0.1461\n",
      "Epoch 1006/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2692 - f1: 0.7022 - val_loss: 0.4170 - val_f1: 0.1465\n",
      "Epoch 1007/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2730 - f1: 0.6972 - val_loss: 0.4158 - val_f1: 0.1455\n",
      "Epoch 1008/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2694 - f1: 0.7030 - val_loss: 0.4236 - val_f1: 0.1458\n",
      "Epoch 1009/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2722 - f1: 0.6976 - val_loss: 0.4201 - val_f1: 0.1453\n",
      "Epoch 1010/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2708 - f1: 0.7032 - val_loss: 0.4218 - val_f1: 0.1452\n",
      "Epoch 1011/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2708 - f1: 0.7014 - val_loss: 0.4196 - val_f1: 0.1453\n",
      "Epoch 1012/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2717 - f1: 0.7014 - val_loss: 0.4197 - val_f1: 0.1459\n",
      "Epoch 1013/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2699 - f1: 0.7036 - val_loss: 0.4182 - val_f1: 0.1459\n",
      "Epoch 1014/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2698 - f1: 0.7018 - val_loss: 0.4217 - val_f1: 0.1459\n",
      "Epoch 1015/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2701 - f1: 0.7035 - val_loss: 0.4164 - val_f1: 0.1464\n",
      "Epoch 1016/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2718 - f1: 0.6991 - val_loss: 0.4164 - val_f1: 0.1464\n",
      "Epoch 1017/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2707 - f1: 0.7021 - val_loss: 0.4143 - val_f1: 0.1454\n",
      "Epoch 1018/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2684 - f1: 0.7048 - val_loss: 0.4215 - val_f1: 0.1468\n",
      "Epoch 1019/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2718 - f1: 0.7025 - val_loss: 0.4189 - val_f1: 0.1462\n",
      "Epoch 1020/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2702 - f1: 0.7062 - val_loss: 0.4179 - val_f1: 0.1458\n",
      "Epoch 1021/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2724 - f1: 0.7008 - val_loss: 0.4158 - val_f1: 0.1450\n",
      "Epoch 1022/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2702 - f1: 0.7012 - val_loss: 0.4213 - val_f1: 0.1459\n",
      "Epoch 1023/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2720 - f1: 0.6976 - val_loss: 0.4189 - val_f1: 0.1464\n",
      "Epoch 1024/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2709 - f1: 0.7018 - val_loss: 0.4182 - val_f1: 0.1454\n",
      "Epoch 1025/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2715 - f1: 0.7015 - val_loss: 0.4154 - val_f1: 0.1459\n",
      "Epoch 1026/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2723 - f1: 0.7020 - val_loss: 0.4203 - val_f1: 0.1465\n",
      "Epoch 1027/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2693 - f1: 0.6996 - val_loss: 0.4169 - val_f1: 0.1450\n",
      "Epoch 1028/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2715 - f1: 0.7035 - val_loss: 0.4161 - val_f1: 0.1457\n",
      "Epoch 1029/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2716 - f1: 0.7036 - val_loss: 0.4180 - val_f1: 0.1455\n",
      "Epoch 1030/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2716 - f1: 0.7021 - val_loss: 0.4177 - val_f1: 0.1458\n",
      "Epoch 1031/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2705 - f1: 0.7052 - val_loss: 0.4181 - val_f1: 0.1459\n",
      "Epoch 1032/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2689 - f1: 0.7036 - val_loss: 0.4208 - val_f1: 0.1465\n",
      "Epoch 1033/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2697 - f1: 0.7041 - val_loss: 0.4206 - val_f1: 0.1466\n",
      "Epoch 1034/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2707 - f1: 0.7023 - val_loss: 0.4210 - val_f1: 0.1460\n",
      "Epoch 1035/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2713 - f1: 0.6966 - val_loss: 0.4167 - val_f1: 0.1460\n",
      "Epoch 1036/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2714 - f1: 0.7051 - val_loss: 0.4168 - val_f1: 0.1454\n",
      "Epoch 1037/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2698 - f1: 0.7002 - val_loss: 0.4198 - val_f1: 0.1460\n",
      "Epoch 1038/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2692 - f1: 0.7061 - val_loss: 0.4194 - val_f1: 0.1465\n",
      "Epoch 1039/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2683 - f1: 0.7079 - val_loss: 0.4216 - val_f1: 0.1463\n",
      "Epoch 1040/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2713 - f1: 0.6996 - val_loss: 0.4212 - val_f1: 0.1459\n",
      "Epoch 1041/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2697 - f1: 0.7088 - val_loss: 0.4197 - val_f1: 0.1453\n",
      "Epoch 1042/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2698 - f1: 0.7035 - val_loss: 0.4219 - val_f1: 0.1460\n",
      "Epoch 1043/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2700 - f1: 0.7052 - val_loss: 0.4164 - val_f1: 0.1455\n",
      "Epoch 1044/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2699 - f1: 0.6995 - val_loss: 0.4183 - val_f1: 0.1457\n",
      "Epoch 1045/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2720 - f1: 0.7012 - val_loss: 0.4197 - val_f1: 0.1456\n",
      "Epoch 1046/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2707 - f1: 0.6995 - val_loss: 0.4160 - val_f1: 0.1458\n",
      "Epoch 1047/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2708 - f1: 0.7004 - val_loss: 0.4195 - val_f1: 0.1452\n",
      "Epoch 1048/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2716 - f1: 0.6994 - val_loss: 0.4191 - val_f1: 0.1459\n",
      "Epoch 1049/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2712 - f1: 0.7019 - val_loss: 0.4188 - val_f1: 0.1456\n",
      "Epoch 1050/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2713 - f1: 0.7030 - val_loss: 0.4205 - val_f1: 0.1459\n",
      "Epoch 1051/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2696 - f1: 0.7002 - val_loss: 0.4206 - val_f1: 0.1452\n",
      "Epoch 1052/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2710 - f1: 0.7014 - val_loss: 0.4210 - val_f1: 0.1459\n",
      "Epoch 1053/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2703 - f1: 0.7038 - val_loss: 0.4188 - val_f1: 0.1450\n",
      "Epoch 1054/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2705 - f1: 0.7026 - val_loss: 0.4249 - val_f1: 0.1458\n",
      "Epoch 1055/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2695 - f1: 0.7062 - val_loss: 0.4206 - val_f1: 0.1461\n",
      "Epoch 1056/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2696 - f1: 0.7059 - val_loss: 0.4215 - val_f1: 0.1456\n",
      "Epoch 1057/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2705 - f1: 0.7004 - val_loss: 0.4198 - val_f1: 0.1459\n",
      "Epoch 1058/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2691 - f1: 0.7055 - val_loss: 0.4236 - val_f1: 0.1458\n",
      "Epoch 1059/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2706 - f1: 0.7048 - val_loss: 0.4193 - val_f1: 0.1452\n",
      "Epoch 1060/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2697 - f1: 0.7056 - val_loss: 0.4169 - val_f1: 0.1461\n",
      "Epoch 1061/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2721 - f1: 0.6973 - val_loss: 0.4186 - val_f1: 0.1459\n",
      "Epoch 1062/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2682 - f1: 0.7073 - val_loss: 0.4192 - val_f1: 0.1460\n",
      "Epoch 1063/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2719 - f1: 0.6997 - val_loss: 0.4198 - val_f1: 0.1453\n",
      "Epoch 1064/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2698 - f1: 0.7043 - val_loss: 0.4208 - val_f1: 0.1454\n",
      "Epoch 1065/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2720 - f1: 0.7026 - val_loss: 0.4139 - val_f1: 0.1452\n",
      "Epoch 1066/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2682 - f1: 0.7039 - val_loss: 0.4194 - val_f1: 0.1457\n",
      "Epoch 1067/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2702 - f1: 0.7025 - val_loss: 0.4200 - val_f1: 0.1455\n",
      "Epoch 1068/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2715 - f1: 0.7028 - val_loss: 0.4220 - val_f1: 0.1457\n",
      "Epoch 1069/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2695 - f1: 0.7017 - val_loss: 0.4210 - val_f1: 0.1458\n",
      "Epoch 1070/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2683 - f1: 0.7046 - val_loss: 0.4201 - val_f1: 0.1461\n",
      "Epoch 1071/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2689 - f1: 0.7060 - val_loss: 0.4160 - val_f1: 0.1454\n",
      "Epoch 1072/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2679 - f1: 0.7109 - val_loss: 0.4216 - val_f1: 0.1461\n",
      "Epoch 1073/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2691 - f1: 0.7051 - val_loss: 0.4151 - val_f1: 0.1460\n",
      "Epoch 1074/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2691 - f1: 0.7050 - val_loss: 0.4215 - val_f1: 0.1456\n",
      "Epoch 1075/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2694 - f1: 0.7015 - val_loss: 0.4235 - val_f1: 0.1456\n",
      "Epoch 1076/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2708 - f1: 0.7002 - val_loss: 0.4220 - val_f1: 0.1452\n",
      "Epoch 1077/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2687 - f1: 0.7054 - val_loss: 0.4183 - val_f1: 0.1457\n",
      "Epoch 1078/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2679 - f1: 0.7094 - val_loss: 0.4216 - val_f1: 0.1459\n",
      "Epoch 1079/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2701 - f1: 0.7034 - val_loss: 0.4156 - val_f1: 0.1450\n",
      "Epoch 1080/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2712 - f1: 0.7018 - val_loss: 0.4172 - val_f1: 0.1452\n",
      "Epoch 1081/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2728 - f1: 0.6991 - val_loss: 0.4166 - val_f1: 0.1454\n",
      "Epoch 1082/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2668 - f1: 0.7040 - val_loss: 0.4232 - val_f1: 0.1461\n",
      "Epoch 1083/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2710 - f1: 0.7036 - val_loss: 0.4175 - val_f1: 0.1455\n",
      "Epoch 1084/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2705 - f1: 0.7042 - val_loss: 0.4182 - val_f1: 0.1454\n",
      "Epoch 1085/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2704 - f1: 0.7004 - val_loss: 0.4189 - val_f1: 0.1461\n",
      "Epoch 1086/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2712 - f1: 0.7015 - val_loss: 0.4204 - val_f1: 0.1458\n",
      "Epoch 1087/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2705 - f1: 0.7008 - val_loss: 0.4210 - val_f1: 0.1453\n",
      "Epoch 1088/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2688 - f1: 0.7041 - val_loss: 0.4200 - val_f1: 0.1457\n",
      "Epoch 1089/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2697 - f1: 0.7025 - val_loss: 0.4232 - val_f1: 0.1458\n",
      "Epoch 1090/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2705 - f1: 0.7032 - val_loss: 0.4203 - val_f1: 0.1450\n",
      "Epoch 1091/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2702 - f1: 0.7057 - val_loss: 0.4174 - val_f1: 0.1450\n",
      "Epoch 1092/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2681 - f1: 0.7055 - val_loss: 0.4235 - val_f1: 0.1457\n",
      "Epoch 1093/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2684 - f1: 0.7071 - val_loss: 0.4250 - val_f1: 0.1454\n",
      "Epoch 1094/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2716 - f1: 0.7017 - val_loss: 0.4218 - val_f1: 0.1457\n",
      "Epoch 1095/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2676 - f1: 0.7062 - val_loss: 0.4259 - val_f1: 0.1464\n",
      "Epoch 1096/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2708 - f1: 0.7045 - val_loss: 0.4199 - val_f1: 0.1458\n",
      "Epoch 1097/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2692 - f1: 0.7036 - val_loss: 0.4222 - val_f1: 0.1455\n",
      "Epoch 1098/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2686 - f1: 0.7053 - val_loss: 0.4223 - val_f1: 0.1461\n",
      "Epoch 1099/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2712 - f1: 0.6998 - val_loss: 0.4234 - val_f1: 0.1449\n",
      "Epoch 1100/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2689 - f1: 0.7034 - val_loss: 0.4195 - val_f1: 0.1451\n",
      "Epoch 1101/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2701 - f1: 0.7029 - val_loss: 0.4210 - val_f1: 0.1449\n",
      "Epoch 1102/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2684 - f1: 0.7079 - val_loss: 0.4190 - val_f1: 0.1458\n",
      "Epoch 1103/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2694 - f1: 0.7061 - val_loss: 0.4230 - val_f1: 0.1454\n",
      "Epoch 1104/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2690 - f1: 0.7082 - val_loss: 0.4187 - val_f1: 0.1454\n",
      "Epoch 1105/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2697 - f1: 0.7032 - val_loss: 0.4198 - val_f1: 0.1454\n",
      "Epoch 1106/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2684 - f1: 0.7024 - val_loss: 0.4248 - val_f1: 0.1459\n",
      "Epoch 1107/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2716 - f1: 0.7030 - val_loss: 0.4220 - val_f1: 0.1454\n",
      "Epoch 1108/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2681 - f1: 0.7054 - val_loss: 0.4250 - val_f1: 0.1459\n",
      "Epoch 1109/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2704 - f1: 0.7033 - val_loss: 0.4226 - val_f1: 0.1463\n",
      "Epoch 1110/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2678 - f1: 0.7045 - val_loss: 0.4209 - val_f1: 0.1460\n",
      "Epoch 1111/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2672 - f1: 0.7089 - val_loss: 0.4210 - val_f1: 0.1463\n",
      "Epoch 1112/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2689 - f1: 0.7022 - val_loss: 0.4210 - val_f1: 0.1455\n",
      "Epoch 1113/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2676 - f1: 0.7056 - val_loss: 0.4237 - val_f1: 0.1460\n",
      "Epoch 1114/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2684 - f1: 0.7064 - val_loss: 0.4185 - val_f1: 0.1455\n",
      "Epoch 1115/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2683 - f1: 0.7057 - val_loss: 0.4216 - val_f1: 0.1454\n",
      "Epoch 1116/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2680 - f1: 0.7069 - val_loss: 0.4145 - val_f1: 0.1449\n",
      "Epoch 1117/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2705 - f1: 0.7012 - val_loss: 0.4202 - val_f1: 0.1457\n",
      "Epoch 1118/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2684 - f1: 0.7074 - val_loss: 0.4225 - val_f1: 0.1457\n",
      "Epoch 1119/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2672 - f1: 0.7063 - val_loss: 0.4228 - val_f1: 0.1460\n",
      "Epoch 1120/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2697 - f1: 0.6993 - val_loss: 0.4173 - val_f1: 0.1454\n",
      "Epoch 1121/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2683 - f1: 0.7094 - val_loss: 0.4154 - val_f1: 0.1461\n",
      "Epoch 1122/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2654 - f1: 0.7136 - val_loss: 0.4329 - val_f1: 0.1460\n",
      "Epoch 1123/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2682 - f1: 0.7053 - val_loss: 0.4173 - val_f1: 0.1448\n",
      "Epoch 1124/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2679 - f1: 0.7048 - val_loss: 0.4239 - val_f1: 0.1461\n",
      "Epoch 1125/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2687 - f1: 0.7012 - val_loss: 0.4195 - val_f1: 0.1459\n",
      "Epoch 1126/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2689 - f1: 0.7061 - val_loss: 0.4199 - val_f1: 0.1456\n",
      "Epoch 1127/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2700 - f1: 0.7040 - val_loss: 0.4257 - val_f1: 0.1464\n",
      "Epoch 1128/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2702 - f1: 0.7052 - val_loss: 0.4188 - val_f1: 0.1450\n",
      "Epoch 1129/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2682 - f1: 0.7025 - val_loss: 0.4230 - val_f1: 0.1449\n",
      "Epoch 1130/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2681 - f1: 0.7026 - val_loss: 0.4226 - val_f1: 0.1463\n",
      "Epoch 1131/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2697 - f1: 0.7047 - val_loss: 0.4176 - val_f1: 0.1451\n",
      "Epoch 1132/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2696 - f1: 0.7021 - val_loss: 0.4211 - val_f1: 0.1463\n",
      "Epoch 1133/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2697 - f1: 0.7027 - val_loss: 0.4197 - val_f1: 0.1455\n",
      "Epoch 1134/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2690 - f1: 0.7041 - val_loss: 0.4175 - val_f1: 0.1459\n",
      "Epoch 1135/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2663 - f1: 0.7093 - val_loss: 0.4200 - val_f1: 0.1455\n",
      "Epoch 1136/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2669 - f1: 0.7087 - val_loss: 0.4270 - val_f1: 0.1457\n",
      "Epoch 1137/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2696 - f1: 0.7064 - val_loss: 0.4249 - val_f1: 0.1455\n",
      "Epoch 1138/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2681 - f1: 0.7076 - val_loss: 0.4227 - val_f1: 0.1454\n",
      "Epoch 1139/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2679 - f1: 0.7082 - val_loss: 0.4251 - val_f1: 0.1458\n",
      "Epoch 1140/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2678 - f1: 0.7073 - val_loss: 0.4166 - val_f1: 0.1455\n",
      "Epoch 1141/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2679 - f1: 0.7072 - val_loss: 0.4186 - val_f1: 0.1456\n",
      "Epoch 1142/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2657 - f1: 0.7084 - val_loss: 0.4266 - val_f1: 0.1470\n",
      "Epoch 1143/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2681 - f1: 0.7053 - val_loss: 0.4219 - val_f1: 0.1460\n",
      "Epoch 1144/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2675 - f1: 0.7065 - val_loss: 0.4204 - val_f1: 0.1446\n",
      "Epoch 1145/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2695 - f1: 0.7037 - val_loss: 0.4235 - val_f1: 0.1458\n",
      "Epoch 1146/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2678 - f1: 0.7083 - val_loss: 0.4268 - val_f1: 0.1461\n",
      "Epoch 1147/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2661 - f1: 0.7091 - val_loss: 0.4243 - val_f1: 0.1453\n",
      "Epoch 1148/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2686 - f1: 0.7052 - val_loss: 0.4235 - val_f1: 0.1456\n",
      "Epoch 1149/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2681 - f1: 0.7049 - val_loss: 0.4197 - val_f1: 0.1463\n",
      "Epoch 1150/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2659 - f1: 0.7042 - val_loss: 0.4211 - val_f1: 0.1456\n",
      "Epoch 1151/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2695 - f1: 0.7071 - val_loss: 0.4219 - val_f1: 0.1453\n",
      "Epoch 1152/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2657 - f1: 0.7139 - val_loss: 0.4237 - val_f1: 0.1457\n",
      "Epoch 1153/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2687 - f1: 0.7049 - val_loss: 0.4222 - val_f1: 0.1460\n",
      "Epoch 1154/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2658 - f1: 0.7114 - val_loss: 0.4232 - val_f1: 0.1460\n",
      "Epoch 1155/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2676 - f1: 0.7080 - val_loss: 0.4204 - val_f1: 0.1455\n",
      "Epoch 1156/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2676 - f1: 0.7061 - val_loss: 0.4228 - val_f1: 0.1461\n",
      "Epoch 1157/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2650 - f1: 0.7126 - val_loss: 0.4252 - val_f1: 0.1462\n",
      "Epoch 1158/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2699 - f1: 0.7037 - val_loss: 0.4222 - val_f1: 0.1456\n",
      "Epoch 1159/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2673 - f1: 0.7052 - val_loss: 0.4188 - val_f1: 0.1460\n",
      "Epoch 1160/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2658 - f1: 0.7117 - val_loss: 0.4264 - val_f1: 0.1462\n",
      "Epoch 1161/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2661 - f1: 0.7100 - val_loss: 0.4280 - val_f1: 0.1467\n",
      "Epoch 1162/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2674 - f1: 0.7120 - val_loss: 0.4222 - val_f1: 0.1458\n",
      "Epoch 1163/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2678 - f1: 0.7063 - val_loss: 0.4268 - val_f1: 0.1457\n",
      "Epoch 1164/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2699 - f1: 0.7072 - val_loss: 0.4258 - val_f1: 0.1456\n",
      "Epoch 1165/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2697 - f1: 0.7043 - val_loss: 0.4217 - val_f1: 0.1461\n",
      "Epoch 1166/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2655 - f1: 0.7125 - val_loss: 0.4221 - val_f1: 0.1456\n",
      "Epoch 1167/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2674 - f1: 0.7084 - val_loss: 0.4187 - val_f1: 0.1463\n",
      "Epoch 1168/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2671 - f1: 0.7085 - val_loss: 0.4229 - val_f1: 0.1464\n",
      "Epoch 1169/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2675 - f1: 0.7062 - val_loss: 0.4256 - val_f1: 0.1461\n",
      "Epoch 1170/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2689 - f1: 0.7018 - val_loss: 0.4218 - val_f1: 0.1454\n",
      "Epoch 1171/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2699 - f1: 0.7051 - val_loss: 0.4208 - val_f1: 0.1457\n",
      "Epoch 1172/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2664 - f1: 0.7092 - val_loss: 0.4259 - val_f1: 0.1462\n",
      "Epoch 1173/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2661 - f1: 0.7086 - val_loss: 0.4263 - val_f1: 0.1459\n",
      "Epoch 1174/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2669 - f1: 0.7118 - val_loss: 0.4217 - val_f1: 0.1462\n",
      "Epoch 1175/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2677 - f1: 0.7091 - val_loss: 0.4170 - val_f1: 0.1453\n",
      "Epoch 1176/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2680 - f1: 0.7030 - val_loss: 0.4240 - val_f1: 0.1458\n",
      "Epoch 1177/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2677 - f1: 0.7067 - val_loss: 0.4190 - val_f1: 0.1455\n",
      "Epoch 1178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2661 - f1: 0.7073 - val_loss: 0.4252 - val_f1: 0.1455\n",
      "Epoch 1179/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2669 - f1: 0.7103 - val_loss: 0.4216 - val_f1: 0.1466\n",
      "Epoch 1180/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2673 - f1: 0.7026 - val_loss: 0.4265 - val_f1: 0.1455\n",
      "Epoch 1181/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2681 - f1: 0.7039 - val_loss: 0.4206 - val_f1: 0.1457\n",
      "Epoch 1182/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2686 - f1: 0.7097 - val_loss: 0.4228 - val_f1: 0.1459\n",
      "Epoch 1183/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2700 - f1: 0.7019 - val_loss: 0.4188 - val_f1: 0.1461\n",
      "Epoch 1184/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2667 - f1: 0.7097 - val_loss: 0.4216 - val_f1: 0.1457\n",
      "Epoch 1185/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2660 - f1: 0.7099 - val_loss: 0.4216 - val_f1: 0.1465\n",
      "Epoch 1186/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2645 - f1: 0.7108 - val_loss: 0.4234 - val_f1: 0.1463\n",
      "Epoch 1187/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2674 - f1: 0.7029 - val_loss: 0.4204 - val_f1: 0.1451\n",
      "Epoch 1188/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2679 - f1: 0.7071 - val_loss: 0.4191 - val_f1: 0.1465\n",
      "Epoch 1189/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2678 - f1: 0.7053 - val_loss: 0.4171 - val_f1: 0.1462\n",
      "Epoch 1190/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2653 - f1: 0.7101 - val_loss: 0.4301 - val_f1: 0.1468\n",
      "Epoch 1191/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2671 - f1: 0.7045 - val_loss: 0.4192 - val_f1: 0.1458\n",
      "Epoch 1192/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2671 - f1: 0.7080 - val_loss: 0.4186 - val_f1: 0.1468\n",
      "Epoch 1193/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2671 - f1: 0.7101 - val_loss: 0.4221 - val_f1: 0.1459\n",
      "Epoch 1194/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2678 - f1: 0.7052 - val_loss: 0.4240 - val_f1: 0.1467\n",
      "Epoch 1195/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2678 - f1: 0.7070 - val_loss: 0.4266 - val_f1: 0.1459\n",
      "Epoch 1196/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2677 - f1: 0.7099 - val_loss: 0.4233 - val_f1: 0.1457\n",
      "Epoch 1197/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2670 - f1: 0.7078 - val_loss: 0.4286 - val_f1: 0.1461\n",
      "Epoch 1198/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2672 - f1: 0.7083 - val_loss: 0.4189 - val_f1: 0.1449\n",
      "Epoch 1199/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2655 - f1: 0.7147 - val_loss: 0.4228 - val_f1: 0.1461\n",
      "Epoch 1200/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2672 - f1: 0.7072 - val_loss: 0.4206 - val_f1: 0.1453\n",
      "Epoch 1201/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2677 - f1: 0.7032 - val_loss: 0.4225 - val_f1: 0.1460\n",
      "Epoch 1202/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2679 - f1: 0.7085 - val_loss: 0.4246 - val_f1: 0.1459\n",
      "Epoch 1203/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2693 - f1: 0.7053 - val_loss: 0.4223 - val_f1: 0.1457\n",
      "Epoch 1204/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2646 - f1: 0.7174 - val_loss: 0.4223 - val_f1: 0.1462\n",
      "Epoch 1205/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2669 - f1: 0.7076 - val_loss: 0.4223 - val_f1: 0.1451\n",
      "Epoch 1206/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2683 - f1: 0.7108 - val_loss: 0.4238 - val_f1: 0.1462\n",
      "Epoch 1207/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2656 - f1: 0.7106 - val_loss: 0.4272 - val_f1: 0.1457\n",
      "Epoch 1208/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2686 - f1: 0.7051 - val_loss: 0.4200 - val_f1: 0.1449\n",
      "Epoch 1209/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2658 - f1: 0.7126 - val_loss: 0.4267 - val_f1: 0.1462\n",
      "Epoch 1210/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2642 - f1: 0.7124 - val_loss: 0.4266 - val_f1: 0.1460\n",
      "Epoch 1211/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2674 - f1: 0.7050 - val_loss: 0.4227 - val_f1: 0.1457\n",
      "Epoch 1212/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2640 - f1: 0.7121 - val_loss: 0.4288 - val_f1: 0.1462\n",
      "Epoch 1213/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2669 - f1: 0.7069 - val_loss: 0.4240 - val_f1: 0.1458\n",
      "Epoch 1214/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2692 - f1: 0.7061 - val_loss: 0.4210 - val_f1: 0.1456\n",
      "Epoch 1215/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2684 - f1: 0.7058 - val_loss: 0.4233 - val_f1: 0.1462\n",
      "Epoch 1216/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2654 - f1: 0.7113 - val_loss: 0.4248 - val_f1: 0.1451\n",
      "Epoch 1217/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2649 - f1: 0.7140 - val_loss: 0.4226 - val_f1: 0.1454\n",
      "Epoch 1218/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2662 - f1: 0.7068 - val_loss: 0.4252 - val_f1: 0.1463\n",
      "Epoch 1219/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2674 - f1: 0.7061 - val_loss: 0.4190 - val_f1: 0.1454\n",
      "Epoch 1220/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2655 - f1: 0.7078 - val_loss: 0.4225 - val_f1: 0.1451\n",
      "Epoch 1221/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2680 - f1: 0.7115 - val_loss: 0.4233 - val_f1: 0.1456\n",
      "Epoch 1222/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2669 - f1: 0.7037 - val_loss: 0.4250 - val_f1: 0.1455\n",
      "Epoch 1223/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2671 - f1: 0.7045 - val_loss: 0.4265 - val_f1: 0.1454\n",
      "Epoch 1224/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2691 - f1: 0.7073 - val_loss: 0.4211 - val_f1: 0.1441\n",
      "Epoch 1225/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2672 - f1: 0.7074 - val_loss: 0.4215 - val_f1: 0.1455\n",
      "Epoch 1226/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2666 - f1: 0.7065 - val_loss: 0.4265 - val_f1: 0.1459\n",
      "Epoch 1227/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2671 - f1: 0.7111 - val_loss: 0.4206 - val_f1: 0.1455\n",
      "Epoch 1228/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2671 - f1: 0.7072 - val_loss: 0.4231 - val_f1: 0.1455\n",
      "Epoch 1229/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2680 - f1: 0.7082 - val_loss: 0.4261 - val_f1: 0.1451\n",
      "Epoch 1230/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2693 - f1: 0.7014 - val_loss: 0.4210 - val_f1: 0.1455\n",
      "Epoch 1231/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2671 - f1: 0.7083 - val_loss: 0.4204 - val_f1: 0.1461\n",
      "Epoch 1232/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2680 - f1: 0.7085 - val_loss: 0.4231 - val_f1: 0.1453\n",
      "Epoch 1233/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2666 - f1: 0.7076 - val_loss: 0.4266 - val_f1: 0.1460\n",
      "Epoch 1234/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2665 - f1: 0.7085 - val_loss: 0.4234 - val_f1: 0.1461\n",
      "Epoch 1235/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2666 - f1: 0.7077 - val_loss: 0.4230 - val_f1: 0.1457\n",
      "Epoch 1236/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2662 - f1: 0.7105 - val_loss: 0.4269 - val_f1: 0.1463\n",
      "Epoch 1237/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2660 - f1: 0.7095 - val_loss: 0.4259 - val_f1: 0.1455\n",
      "Epoch 1238/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2666 - f1: 0.7079 - val_loss: 0.4275 - val_f1: 0.1459\n",
      "Epoch 1239/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2629 - f1: 0.7088 - val_loss: 0.4222 - val_f1: 0.1459\n",
      "Epoch 1240/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2644 - f1: 0.7116 - val_loss: 0.4245 - val_f1: 0.1452\n",
      "Epoch 1241/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2643 - f1: 0.7124 - val_loss: 0.4200 - val_f1: 0.1458\n",
      "Epoch 1242/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2655 - f1: 0.7119 - val_loss: 0.4202 - val_f1: 0.1454\n",
      "Epoch 1243/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2648 - f1: 0.7092 - val_loss: 0.4270 - val_f1: 0.1453\n",
      "Epoch 1244/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2693 - f1: 0.7078 - val_loss: 0.4204 - val_f1: 0.1461\n",
      "Epoch 1245/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2678 - f1: 0.7068 - val_loss: 0.4265 - val_f1: 0.1461\n",
      "Epoch 1246/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2685 - f1: 0.7021 - val_loss: 0.4251 - val_f1: 0.1457\n",
      "Epoch 1247/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2662 - f1: 0.7096 - val_loss: 0.4243 - val_f1: 0.1452\n",
      "Epoch 1248/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2653 - f1: 0.7144 - val_loss: 0.4236 - val_f1: 0.1463\n",
      "Epoch 1249/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2671 - f1: 0.7112 - val_loss: 0.4240 - val_f1: 0.1459\n",
      "Epoch 1250/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2668 - f1: 0.7077 - val_loss: 0.4200 - val_f1: 0.1459\n",
      "Epoch 1251/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2680 - f1: 0.7075 - val_loss: 0.4184 - val_f1: 0.1453\n",
      "Epoch 1252/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2640 - f1: 0.7169 - val_loss: 0.4186 - val_f1: 0.1463\n",
      "Epoch 1253/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2665 - f1: 0.7101 - val_loss: 0.4249 - val_f1: 0.1458\n",
      "Epoch 1254/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2649 - f1: 0.7109 - val_loss: 0.4293 - val_f1: 0.1458\n",
      "Epoch 1255/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2657 - f1: 0.7052 - val_loss: 0.4239 - val_f1: 0.1456\n",
      "Epoch 1256/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2669 - f1: 0.7116 - val_loss: 0.4234 - val_f1: 0.1449\n",
      "Epoch 1257/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2642 - f1: 0.7088 - val_loss: 0.4254 - val_f1: 0.1454\n",
      "Epoch 1258/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2672 - f1: 0.7105 - val_loss: 0.4252 - val_f1: 0.1458\n",
      "Epoch 1259/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2663 - f1: 0.7095 - val_loss: 0.4268 - val_f1: 0.1456\n",
      "Epoch 1260/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2669 - f1: 0.7076 - val_loss: 0.4254 - val_f1: 0.1458\n",
      "Epoch 1261/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2651 - f1: 0.7112 - val_loss: 0.4232 - val_f1: 0.1460\n",
      "Epoch 1262/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2665 - f1: 0.7148 - val_loss: 0.4273 - val_f1: 0.1452\n",
      "Epoch 1263/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2656 - f1: 0.7110 - val_loss: 0.4243 - val_f1: 0.1457\n",
      "Epoch 1264/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2624 - f1: 0.7127 - val_loss: 0.4295 - val_f1: 0.1462\n",
      "Epoch 1265/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2649 - f1: 0.7108 - val_loss: 0.4206 - val_f1: 0.1459\n",
      "Epoch 1266/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2633 - f1: 0.7128 - val_loss: 0.4226 - val_f1: 0.1456\n",
      "Epoch 1267/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2638 - f1: 0.7122 - val_loss: 0.4244 - val_f1: 0.1451\n",
      "Epoch 1268/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2662 - f1: 0.7073 - val_loss: 0.4208 - val_f1: 0.1462\n",
      "Epoch 1269/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2658 - f1: 0.7102 - val_loss: 0.4261 - val_f1: 0.1453\n",
      "Epoch 1270/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2644 - f1: 0.7136 - val_loss: 0.4252 - val_f1: 0.1456\n",
      "Epoch 1271/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2643 - f1: 0.7148 - val_loss: 0.4219 - val_f1: 0.1457\n",
      "Epoch 1272/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2658 - f1: 0.7094 - val_loss: 0.4279 - val_f1: 0.1461\n",
      "Epoch 1273/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2638 - f1: 0.7165 - val_loss: 0.4258 - val_f1: 0.1457\n",
      "Epoch 1274/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2685 - f1: 0.7045 - val_loss: 0.4254 - val_f1: 0.1457\n",
      "Epoch 1275/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2687 - f1: 0.7076 - val_loss: 0.4232 - val_f1: 0.1454\n",
      "Epoch 1276/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2659 - f1: 0.7083 - val_loss: 0.4224 - val_f1: 0.1452\n",
      "Epoch 1277/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2665 - f1: 0.7064 - val_loss: 0.4271 - val_f1: 0.1446\n",
      "Epoch 1278/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2662 - f1: 0.7066 - val_loss: 0.4258 - val_f1: 0.1457\n",
      "Epoch 1279/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2649 - f1: 0.7092 - val_loss: 0.4235 - val_f1: 0.1464\n",
      "Epoch 1280/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2655 - f1: 0.7107 - val_loss: 0.4296 - val_f1: 0.1462\n",
      "Epoch 1281/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2653 - f1: 0.7085 - val_loss: 0.4248 - val_f1: 0.1453\n",
      "Epoch 1282/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2653 - f1: 0.7113 - val_loss: 0.4296 - val_f1: 0.1460\n",
      "Epoch 1283/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2666 - f1: 0.7110 - val_loss: 0.4206 - val_f1: 0.1458\n",
      "Epoch 1284/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2658 - f1: 0.7124 - val_loss: 0.4211 - val_f1: 0.1452\n",
      "Epoch 1285/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2656 - f1: 0.7101 - val_loss: 0.4241 - val_f1: 0.1456\n",
      "Epoch 1286/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2696 - f1: 0.7047 - val_loss: 0.4177 - val_f1: 0.1451\n",
      "Epoch 1287/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2671 - f1: 0.7064 - val_loss: 0.4304 - val_f1: 0.1454\n",
      "Epoch 1288/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2643 - f1: 0.7077 - val_loss: 0.4232 - val_f1: 0.1462\n",
      "Epoch 1289/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2670 - f1: 0.7101 - val_loss: 0.4183 - val_f1: 0.1462\n",
      "Epoch 1290/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2661 - f1: 0.7120 - val_loss: 0.4224 - val_f1: 0.1461\n",
      "Epoch 1291/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2621 - f1: 0.7143 - val_loss: 0.4186 - val_f1: 0.1463\n",
      "Epoch 1292/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2668 - f1: 0.7111 - val_loss: 0.4222 - val_f1: 0.1453\n",
      "Epoch 1293/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2663 - f1: 0.7088 - val_loss: 0.4247 - val_f1: 0.1460\n",
      "Epoch 1294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2673 - f1: 0.7083 - val_loss: 0.4209 - val_f1: 0.1453\n",
      "Epoch 1295/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2636 - f1: 0.7086 - val_loss: 0.4287 - val_f1: 0.1464\n",
      "Epoch 1296/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2673 - f1: 0.7111 - val_loss: 0.4205 - val_f1: 0.1452\n",
      "Epoch 1297/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2653 - f1: 0.7103 - val_loss: 0.4237 - val_f1: 0.1466\n",
      "Epoch 1298/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2641 - f1: 0.7162 - val_loss: 0.4261 - val_f1: 0.1461\n",
      "Epoch 1299/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2665 - f1: 0.7084 - val_loss: 0.4260 - val_f1: 0.1459\n",
      "Epoch 1300/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2655 - f1: 0.7125 - val_loss: 0.4222 - val_f1: 0.1458\n",
      "Epoch 1301/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2655 - f1: 0.7080 - val_loss: 0.4235 - val_f1: 0.1447\n",
      "Epoch 1302/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2653 - f1: 0.7075 - val_loss: 0.4266 - val_f1: 0.1451\n",
      "Epoch 1303/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2659 - f1: 0.7109 - val_loss: 0.4224 - val_f1: 0.1443\n",
      "Epoch 1304/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2656 - f1: 0.7099 - val_loss: 0.4253 - val_f1: 0.1452\n",
      "Epoch 1305/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2644 - f1: 0.7096 - val_loss: 0.4194 - val_f1: 0.1447\n",
      "Epoch 1306/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2669 - f1: 0.7057 - val_loss: 0.4224 - val_f1: 0.1459\n",
      "Epoch 1307/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2647 - f1: 0.7137 - val_loss: 0.4230 - val_f1: 0.1452\n",
      "Epoch 1308/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2642 - f1: 0.7109 - val_loss: 0.4257 - val_f1: 0.1453\n",
      "Epoch 1309/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2658 - f1: 0.7115 - val_loss: 0.4250 - val_f1: 0.1447\n",
      "Epoch 1310/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2667 - f1: 0.7062 - val_loss: 0.4220 - val_f1: 0.1452\n",
      "Epoch 1311/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2665 - f1: 0.7092 - val_loss: 0.4236 - val_f1: 0.1449\n",
      "Epoch 1312/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2626 - f1: 0.7169 - val_loss: 0.4223 - val_f1: 0.1450\n",
      "Epoch 1313/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2652 - f1: 0.7120 - val_loss: 0.4217 - val_f1: 0.1447\n",
      "Epoch 1314/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2646 - f1: 0.7127 - val_loss: 0.4270 - val_f1: 0.1455\n",
      "Epoch 1315/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2673 - f1: 0.7088 - val_loss: 0.4278 - val_f1: 0.1451\n",
      "Epoch 1316/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2652 - f1: 0.7101 - val_loss: 0.4230 - val_f1: 0.1457\n",
      "Epoch 1317/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2655 - f1: 0.7076 - val_loss: 0.4300 - val_f1: 0.1461\n",
      "Epoch 1318/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2637 - f1: 0.7129 - val_loss: 0.4279 - val_f1: 0.1455\n",
      "Epoch 1319/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2648 - f1: 0.7068 - val_loss: 0.4243 - val_f1: 0.1461\n",
      "Epoch 1320/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2649 - f1: 0.7108 - val_loss: 0.4226 - val_f1: 0.1453\n",
      "Epoch 1321/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2639 - f1: 0.7154 - val_loss: 0.4276 - val_f1: 0.1460\n",
      "Epoch 1322/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2641 - f1: 0.7131 - val_loss: 0.4266 - val_f1: 0.1451\n",
      "Epoch 1323/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2651 - f1: 0.7096 - val_loss: 0.4244 - val_f1: 0.1445\n",
      "Epoch 1324/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2663 - f1: 0.7059 - val_loss: 0.4204 - val_f1: 0.1453\n",
      "Epoch 1325/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2652 - f1: 0.7089 - val_loss: 0.4211 - val_f1: 0.1453\n",
      "Epoch 1326/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2660 - f1: 0.7068 - val_loss: 0.4234 - val_f1: 0.1452\n",
      "Epoch 1327/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2625 - f1: 0.7155 - val_loss: 0.4261 - val_f1: 0.1444\n",
      "Epoch 1328/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2634 - f1: 0.7134 - val_loss: 0.4253 - val_f1: 0.1453\n",
      "Epoch 1329/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2643 - f1: 0.7136 - val_loss: 0.4301 - val_f1: 0.1454\n",
      "Epoch 1330/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2677 - f1: 0.7053 - val_loss: 0.4243 - val_f1: 0.1449\n",
      "Epoch 1331/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2651 - f1: 0.7104 - val_loss: 0.4249 - val_f1: 0.1455\n",
      "Epoch 1332/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2623 - f1: 0.7127 - val_loss: 0.4258 - val_f1: 0.1464\n",
      "Epoch 1333/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2663 - f1: 0.7114 - val_loss: 0.4209 - val_f1: 0.1449\n",
      "Epoch 1334/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2628 - f1: 0.7131 - val_loss: 0.4285 - val_f1: 0.1441\n",
      "Epoch 1335/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2647 - f1: 0.7120 - val_loss: 0.4279 - val_f1: 0.1443\n",
      "Epoch 1336/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2629 - f1: 0.7102 - val_loss: 0.4252 - val_f1: 0.1457\n",
      "Epoch 1337/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2644 - f1: 0.7095 - val_loss: 0.4244 - val_f1: 0.1454\n",
      "Epoch 1338/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2655 - f1: 0.7084 - val_loss: 0.4284 - val_f1: 0.1449\n",
      "Epoch 1339/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2641 - f1: 0.7150 - val_loss: 0.4271 - val_f1: 0.1446\n",
      "Epoch 1340/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2640 - f1: 0.7114 - val_loss: 0.4229 - val_f1: 0.1448\n",
      "Epoch 1341/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2644 - f1: 0.7100 - val_loss: 0.4261 - val_f1: 0.1452\n",
      "Epoch 1342/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2636 - f1: 0.7125 - val_loss: 0.4276 - val_f1: 0.1459\n",
      "Epoch 1343/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2615 - f1: 0.7160 - val_loss: 0.4227 - val_f1: 0.1445\n",
      "Epoch 1344/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2629 - f1: 0.7157 - val_loss: 0.4287 - val_f1: 0.1452\n",
      "Epoch 1345/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2629 - f1: 0.7127 - val_loss: 0.4236 - val_f1: 0.1452\n",
      "Epoch 1346/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2629 - f1: 0.7123 - val_loss: 0.4232 - val_f1: 0.1452\n",
      "Epoch 1347/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2619 - f1: 0.7108 - val_loss: 0.4292 - val_f1: 0.1458\n",
      "Epoch 1348/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2630 - f1: 0.7170 - val_loss: 0.4295 - val_f1: 0.1445\n",
      "Epoch 1349/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2641 - f1: 0.7109 - val_loss: 0.4241 - val_f1: 0.1451\n",
      "Epoch 1350/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2645 - f1: 0.7109 - val_loss: 0.4249 - val_f1: 0.1454\n",
      "Epoch 1351/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2668 - f1: 0.7091 - val_loss: 0.4229 - val_f1: 0.1457\n",
      "Epoch 1352/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2644 - f1: 0.7133 - val_loss: 0.4299 - val_f1: 0.1452\n",
      "Epoch 1353/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2670 - f1: 0.7083 - val_loss: 0.4254 - val_f1: 0.1448\n",
      "Epoch 1354/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2635 - f1: 0.7143 - val_loss: 0.4207 - val_f1: 0.1455\n",
      "Epoch 1355/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2644 - f1: 0.7102 - val_loss: 0.4257 - val_f1: 0.1453\n",
      "Epoch 1356/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2648 - f1: 0.7128 - val_loss: 0.4234 - val_f1: 0.1453\n",
      "Epoch 1357/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2634 - f1: 0.7149 - val_loss: 0.4244 - val_f1: 0.1460\n",
      "Epoch 1358/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2641 - f1: 0.7118 - val_loss: 0.4208 - val_f1: 0.1453\n",
      "Epoch 1359/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2614 - f1: 0.7135 - val_loss: 0.4277 - val_f1: 0.1452\n",
      "Epoch 1360/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2635 - f1: 0.7130 - val_loss: 0.4242 - val_f1: 0.1463\n",
      "Epoch 1361/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2634 - f1: 0.7110 - val_loss: 0.4283 - val_f1: 0.1459\n",
      "Epoch 1362/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2640 - f1: 0.7128 - val_loss: 0.4277 - val_f1: 0.1450\n",
      "Epoch 1363/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2654 - f1: 0.7091 - val_loss: 0.4219 - val_f1: 0.1462\n",
      "Epoch 1364/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2635 - f1: 0.7107 - val_loss: 0.4297 - val_f1: 0.1455\n",
      "Epoch 1365/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2651 - f1: 0.7137 - val_loss: 0.4278 - val_f1: 0.1454\n",
      "Epoch 1366/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2644 - f1: 0.7099 - val_loss: 0.4251 - val_f1: 0.1453\n",
      "Epoch 1367/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2663 - f1: 0.7096 - val_loss: 0.4234 - val_f1: 0.1459\n",
      "Epoch 1368/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2647 - f1: 0.7094 - val_loss: 0.4254 - val_f1: 0.1448\n",
      "Epoch 1369/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2633 - f1: 0.7137 - val_loss: 0.4276 - val_f1: 0.1460\n",
      "Epoch 1370/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2629 - f1: 0.7132 - val_loss: 0.4265 - val_f1: 0.1464\n",
      "Epoch 1371/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2617 - f1: 0.7143 - val_loss: 0.4288 - val_f1: 0.1462\n",
      "Epoch 1372/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2641 - f1: 0.7123 - val_loss: 0.4260 - val_f1: 0.1464\n",
      "Epoch 1373/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2655 - f1: 0.7050 - val_loss: 0.4245 - val_f1: 0.1457\n",
      "Epoch 1374/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2615 - f1: 0.7164 - val_loss: 0.4288 - val_f1: 0.1455\n",
      "Epoch 1375/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2621 - f1: 0.7138 - val_loss: 0.4270 - val_f1: 0.1458\n",
      "Epoch 1376/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2635 - f1: 0.7106 - val_loss: 0.4293 - val_f1: 0.1468\n",
      "Epoch 1377/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2621 - f1: 0.7160 - val_loss: 0.4265 - val_f1: 0.1457\n",
      "Epoch 1378/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2654 - f1: 0.7087 - val_loss: 0.4267 - val_f1: 0.1452\n",
      "Epoch 1379/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2630 - f1: 0.7127 - val_loss: 0.4303 - val_f1: 0.1455\n",
      "Epoch 1380/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2649 - f1: 0.7094 - val_loss: 0.4264 - val_f1: 0.1449\n",
      "Epoch 1381/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2649 - f1: 0.7088 - val_loss: 0.4227 - val_f1: 0.1447\n",
      "Epoch 1382/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2621 - f1: 0.7152 - val_loss: 0.4267 - val_f1: 0.1458\n",
      "Epoch 1383/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2646 - f1: 0.7127 - val_loss: 0.4280 - val_f1: 0.1453\n",
      "Epoch 1384/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2623 - f1: 0.7170 - val_loss: 0.4279 - val_f1: 0.1455\n",
      "Epoch 1385/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2650 - f1: 0.7110 - val_loss: 0.4240 - val_f1: 0.1455\n",
      "Epoch 1386/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2652 - f1: 0.7099 - val_loss: 0.4250 - val_f1: 0.1454\n",
      "Epoch 1387/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2626 - f1: 0.7158 - val_loss: 0.4309 - val_f1: 0.1463\n",
      "Epoch 1388/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2623 - f1: 0.7144 - val_loss: 0.4225 - val_f1: 0.1459\n",
      "Epoch 1389/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2627 - f1: 0.7133 - val_loss: 0.4253 - val_f1: 0.1459\n",
      "Epoch 1390/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2647 - f1: 0.7120 - val_loss: 0.4242 - val_f1: 0.1460\n",
      "Epoch 1391/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2631 - f1: 0.7128 - val_loss: 0.4235 - val_f1: 0.1448\n",
      "Epoch 1392/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2644 - f1: 0.7096 - val_loss: 0.4247 - val_f1: 0.1456\n",
      "Epoch 1393/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2631 - f1: 0.7146 - val_loss: 0.4270 - val_f1: 0.1450\n",
      "Epoch 1394/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2615 - f1: 0.7170 - val_loss: 0.4321 - val_f1: 0.1457\n",
      "Epoch 1395/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2622 - f1: 0.7128 - val_loss: 0.4283 - val_f1: 0.1451\n",
      "Epoch 1396/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2620 - f1: 0.7208 - val_loss: 0.4282 - val_f1: 0.1464\n",
      "Epoch 1397/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2641 - f1: 0.7111 - val_loss: 0.4259 - val_f1: 0.1446\n",
      "Epoch 1398/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2639 - f1: 0.7145 - val_loss: 0.4268 - val_f1: 0.1446\n",
      "Epoch 1399/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2656 - f1: 0.7097 - val_loss: 0.4250 - val_f1: 0.1456\n",
      "Epoch 1400/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2632 - f1: 0.7181 - val_loss: 0.4255 - val_f1: 0.1451\n",
      "Epoch 1401/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2633 - f1: 0.7120 - val_loss: 0.4248 - val_f1: 0.1454\n",
      "Epoch 1402/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2641 - f1: 0.7110 - val_loss: 0.4278 - val_f1: 0.1451\n",
      "Epoch 1403/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2627 - f1: 0.7105 - val_loss: 0.4277 - val_f1: 0.1462\n",
      "Epoch 1404/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2632 - f1: 0.7128 - val_loss: 0.4253 - val_f1: 0.1459\n",
      "Epoch 1405/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2637 - f1: 0.7111 - val_loss: 0.4243 - val_f1: 0.1448\n",
      "Epoch 1406/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2632 - f1: 0.7117 - val_loss: 0.4297 - val_f1: 0.1449\n",
      "Epoch 1407/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2646 - f1: 0.7135 - val_loss: 0.4269 - val_f1: 0.1462\n",
      "Epoch 1408/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2629 - f1: 0.7130 - val_loss: 0.4234 - val_f1: 0.1445\n",
      "Epoch 1409/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2622 - f1: 0.7142 - val_loss: 0.4230 - val_f1: 0.1449\n",
      "Epoch 1410/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2632 - f1: 0.7092 - val_loss: 0.4255 - val_f1: 0.1448\n",
      "Epoch 1411/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2647 - f1: 0.7153 - val_loss: 0.4252 - val_f1: 0.1450\n",
      "Epoch 1412/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2643 - f1: 0.7143 - val_loss: 0.4246 - val_f1: 0.1448\n",
      "Epoch 1413/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2633 - f1: 0.7132 - val_loss: 0.4254 - val_f1: 0.1459\n",
      "Epoch 1414/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2618 - f1: 0.7143 - val_loss: 0.4237 - val_f1: 0.1451\n",
      "Epoch 1415/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2632 - f1: 0.7111 - val_loss: 0.4274 - val_f1: 0.1447\n",
      "Epoch 1416/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2626 - f1: 0.7093 - val_loss: 0.4281 - val_f1: 0.1462\n",
      "Epoch 1417/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2623 - f1: 0.7159 - val_loss: 0.4298 - val_f1: 0.1456\n",
      "Epoch 1418/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2632 - f1: 0.7102 - val_loss: 0.4327 - val_f1: 0.1448\n",
      "Epoch 1419/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2613 - f1: 0.7137 - val_loss: 0.4204 - val_f1: 0.1449\n",
      "Epoch 1420/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2635 - f1: 0.7118 - val_loss: 0.4284 - val_f1: 0.1450\n",
      "Epoch 1421/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2629 - f1: 0.7143 - val_loss: 0.4276 - val_f1: 0.1450\n",
      "Epoch 1422/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2612 - f1: 0.7132 - val_loss: 0.4325 - val_f1: 0.1451\n",
      "Epoch 1423/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2621 - f1: 0.7087 - val_loss: 0.4281 - val_f1: 0.1468\n",
      "Epoch 1424/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2627 - f1: 0.7124 - val_loss: 0.4254 - val_f1: 0.1466\n",
      "Epoch 1425/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2613 - f1: 0.7144 - val_loss: 0.4236 - val_f1: 0.1451\n",
      "Epoch 1426/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2623 - f1: 0.7172 - val_loss: 0.4293 - val_f1: 0.1457\n",
      "Epoch 1427/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2643 - f1: 0.7192 - val_loss: 0.4241 - val_f1: 0.1454\n",
      "Epoch 1428/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2625 - f1: 0.7137 - val_loss: 0.4305 - val_f1: 0.1460\n",
      "Epoch 1429/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2600 - f1: 0.7170 - val_loss: 0.4313 - val_f1: 0.1456\n",
      "Epoch 1430/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2618 - f1: 0.7135 - val_loss: 0.4262 - val_f1: 0.1457\n",
      "Epoch 1431/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2640 - f1: 0.7139 - val_loss: 0.4270 - val_f1: 0.1457\n",
      "Epoch 1432/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2652 - f1: 0.7148 - val_loss: 0.4232 - val_f1: 0.1448\n",
      "Epoch 1433/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.2637 - f1: 0.71 - 3s 41us/step - loss: 0.2636 - f1: 0.7141 - val_loss: 0.4217 - val_f1: 0.1458\n",
      "Epoch 1434/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2651 - f1: 0.7122 - val_loss: 0.4242 - val_f1: 0.1460\n",
      "Epoch 1435/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2637 - f1: 0.7111 - val_loss: 0.4270 - val_f1: 0.1450\n",
      "Epoch 1436/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2631 - f1: 0.7134 - val_loss: 0.4228 - val_f1: 0.1452\n",
      "Epoch 1437/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2642 - f1: 0.7141 - val_loss: 0.4242 - val_f1: 0.1454\n",
      "Epoch 1438/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2623 - f1: 0.7177 - val_loss: 0.4272 - val_f1: 0.1448\n",
      "Epoch 1439/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2646 - f1: 0.7117 - val_loss: 0.4242 - val_f1: 0.1455\n",
      "Epoch 1440/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2630 - f1: 0.7178 - val_loss: 0.4263 - val_f1: 0.1455\n",
      "Epoch 1441/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2630 - f1: 0.7131 - val_loss: 0.4298 - val_f1: 0.1461\n",
      "Epoch 1442/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2614 - f1: 0.7191 - val_loss: 0.4261 - val_f1: 0.1462\n",
      "Epoch 1443/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2641 - f1: 0.7147 - val_loss: 0.4281 - val_f1: 0.1457\n",
      "Epoch 1444/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2640 - f1: 0.7128 - val_loss: 0.4329 - val_f1: 0.1466\n",
      "Epoch 1445/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2636 - f1: 0.7116 - val_loss: 0.4275 - val_f1: 0.1457\n",
      "Epoch 1446/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2638 - f1: 0.7154 - val_loss: 0.4201 - val_f1: 0.1447\n",
      "Epoch 1447/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2634 - f1: 0.7116 - val_loss: 0.4257 - val_f1: 0.1458\n",
      "Epoch 1448/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2649 - f1: 0.7151 - val_loss: 0.4294 - val_f1: 0.1459\n",
      "Epoch 1449/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2648 - f1: 0.7095 - val_loss: 0.4310 - val_f1: 0.1457\n",
      "Epoch 1450/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2620 - f1: 0.7132 - val_loss: 0.4296 - val_f1: 0.1460\n",
      "Epoch 1451/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2637 - f1: 0.7151 - val_loss: 0.4227 - val_f1: 0.1452\n",
      "Epoch 1452/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2614 - f1: 0.7182 - val_loss: 0.4283 - val_f1: 0.1450\n",
      "Epoch 1453/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2611 - f1: 0.7181 - val_loss: 0.4273 - val_f1: 0.1456\n",
      "Epoch 1454/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2641 - f1: 0.7121 - val_loss: 0.4293 - val_f1: 0.1454\n",
      "Epoch 1455/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2638 - f1: 0.7109 - val_loss: 0.4237 - val_f1: 0.1458\n",
      "Epoch 1456/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2643 - f1: 0.7110 - val_loss: 0.4198 - val_f1: 0.1447\n",
      "Epoch 1457/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2622 - f1: 0.7129 - val_loss: 0.4287 - val_f1: 0.1461\n",
      "Epoch 1458/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2625 - f1: 0.7142 - val_loss: 0.4265 - val_f1: 0.1455\n",
      "Epoch 1459/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2633 - f1: 0.7126 - val_loss: 0.4291 - val_f1: 0.1452\n",
      "Epoch 1460/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2618 - f1: 0.7134 - val_loss: 0.4289 - val_f1: 0.1462\n",
      "Epoch 1461/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2623 - f1: 0.7119 - val_loss: 0.4259 - val_f1: 0.1469\n",
      "Epoch 1462/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2633 - f1: 0.7138 - val_loss: 0.4230 - val_f1: 0.1456\n",
      "Epoch 1463/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2636 - f1: 0.7138 - val_loss: 0.4241 - val_f1: 0.1444\n",
      "Epoch 1464/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2645 - f1: 0.7101 - val_loss: 0.4274 - val_f1: 0.1457\n",
      "Epoch 1465/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2603 - f1: 0.7187 - val_loss: 0.4312 - val_f1: 0.1465\n",
      "Epoch 1466/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2627 - f1: 0.7165 - val_loss: 0.4262 - val_f1: 0.1458\n",
      "Epoch 1467/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2615 - f1: 0.7180 - val_loss: 0.4245 - val_f1: 0.1457\n",
      "Epoch 1468/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2629 - f1: 0.7145 - val_loss: 0.4264 - val_f1: 0.1449\n",
      "Epoch 1469/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2633 - f1: 0.7134 - val_loss: 0.4286 - val_f1: 0.1460\n",
      "Epoch 1470/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2624 - f1: 0.7154 - val_loss: 0.4275 - val_f1: 0.1453\n",
      "Epoch 1471/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2663 - f1: 0.7111 - val_loss: 0.4223 - val_f1: 0.1451\n",
      "Epoch 1472/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2601 - f1: 0.7233 - val_loss: 0.4267 - val_f1: 0.1463\n",
      "Epoch 1473/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2611 - f1: 0.7201 - val_loss: 0.4277 - val_f1: 0.1457\n",
      "Epoch 1474/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2638 - f1: 0.7115 - val_loss: 0.4303 - val_f1: 0.1456\n",
      "Epoch 1475/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2615 - f1: 0.7148 - val_loss: 0.4318 - val_f1: 0.1461\n",
      "Epoch 1476/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2631 - f1: 0.7181 - val_loss: 0.4247 - val_f1: 0.1446\n",
      "Epoch 1477/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2633 - f1: 0.7064 - val_loss: 0.4287 - val_f1: 0.1456\n",
      "Epoch 1478/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2628 - f1: 0.7126 - val_loss: 0.4308 - val_f1: 0.1450\n",
      "Epoch 1479/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2615 - f1: 0.7163 - val_loss: 0.4294 - val_f1: 0.1454\n",
      "Epoch 1480/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2625 - f1: 0.7128 - val_loss: 0.4292 - val_f1: 0.1454\n",
      "Epoch 1481/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2640 - f1: 0.7119 - val_loss: 0.4244 - val_f1: 0.1453\n",
      "Epoch 1482/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2627 - f1: 0.7112 - val_loss: 0.4248 - val_f1: 0.1458\n",
      "Epoch 1483/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2607 - f1: 0.7187 - val_loss: 0.4292 - val_f1: 0.1460\n",
      "Epoch 1484/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2624 - f1: 0.7177 - val_loss: 0.4262 - val_f1: 0.1447\n",
      "Epoch 1485/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2605 - f1: 0.7124 - val_loss: 0.4271 - val_f1: 0.1459\n",
      "Epoch 1486/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2608 - f1: 0.7144 - val_loss: 0.4246 - val_f1: 0.1451\n",
      "Epoch 1487/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2624 - f1: 0.7176 - val_loss: 0.4258 - val_f1: 0.1451\n",
      "Epoch 1488/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2625 - f1: 0.7117 - val_loss: 0.4277 - val_f1: 0.1455\n",
      "Epoch 1489/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2611 - f1: 0.7149 - val_loss: 0.4266 - val_f1: 0.1451\n",
      "Epoch 1490/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2640 - f1: 0.7156 - val_loss: 0.4270 - val_f1: 0.1445\n",
      "Epoch 1491/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2614 - f1: 0.7144 - val_loss: 0.4252 - val_f1: 0.1452\n",
      "Epoch 1492/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2638 - f1: 0.7074 - val_loss: 0.4247 - val_f1: 0.1461\n",
      "Epoch 1493/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2626 - f1: 0.7169 - val_loss: 0.4282 - val_f1: 0.1458\n",
      "Epoch 1494/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2616 - f1: 0.7143 - val_loss: 0.4263 - val_f1: 0.1450\n",
      "Epoch 1495/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2606 - f1: 0.7172 - val_loss: 0.4295 - val_f1: 0.1455\n",
      "Epoch 1496/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2623 - f1: 0.7149 - val_loss: 0.4291 - val_f1: 0.1452\n",
      "Epoch 1497/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2611 - f1: 0.7145 - val_loss: 0.4324 - val_f1: 0.1451\n",
      "Epoch 1498/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2603 - f1: 0.7183 - val_loss: 0.4241 - val_f1: 0.1447\n",
      "Epoch 1499/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2629 - f1: 0.7165 - val_loss: 0.4275 - val_f1: 0.1454\n",
      "Epoch 1500/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2621 - f1: 0.7145 - val_loss: 0.4274 - val_f1: 0.1463\n",
      "Epoch 1501/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2615 - f1: 0.7168 - val_loss: 0.4257 - val_f1: 0.1451\n",
      "Epoch 1502/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2633 - f1: 0.7127 - val_loss: 0.4231 - val_f1: 0.1453\n",
      "Epoch 1503/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2624 - f1: 0.7126 - val_loss: 0.4316 - val_f1: 0.1456\n",
      "Epoch 1504/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2628 - f1: 0.7157 - val_loss: 0.4219 - val_f1: 0.1454\n",
      "Epoch 1505/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2622 - f1: 0.7168 - val_loss: 0.4305 - val_f1: 0.1456\n",
      "Epoch 1506/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2623 - f1: 0.7111 - val_loss: 0.4220 - val_f1: 0.1450\n",
      "Epoch 1507/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2637 - f1: 0.7121 - val_loss: 0.4226 - val_f1: 0.1454\n",
      "Epoch 1508/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2610 - f1: 0.7188 - val_loss: 0.4249 - val_f1: 0.1453\n",
      "Epoch 1509/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2608 - f1: 0.7171 - val_loss: 0.4286 - val_f1: 0.1451\n",
      "Epoch 1510/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2618 - f1: 0.7112 - val_loss: 0.4282 - val_f1: 0.1458\n",
      "Epoch 1511/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2593 - f1: 0.7176 - val_loss: 0.4295 - val_f1: 0.1454\n",
      "Epoch 1512/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2618 - f1: 0.7146 - val_loss: 0.4294 - val_f1: 0.1454\n",
      "Epoch 1513/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2606 - f1: 0.7163 - val_loss: 0.4279 - val_f1: 0.1461\n",
      "Epoch 1514/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2631 - f1: 0.7163 - val_loss: 0.4266 - val_f1: 0.1445\n",
      "Epoch 1515/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2621 - f1: 0.7150 - val_loss: 0.4343 - val_f1: 0.1457\n",
      "Epoch 1516/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2610 - f1: 0.7181 - val_loss: 0.4283 - val_f1: 0.1450\n",
      "Epoch 1517/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2591 - f1: 0.7195 - val_loss: 0.4285 - val_f1: 0.1462\n",
      "Epoch 1518/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2620 - f1: 0.7165 - val_loss: 0.4255 - val_f1: 0.1455\n",
      "Epoch 1519/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2607 - f1: 0.7190 - val_loss: 0.4259 - val_f1: 0.1451\n",
      "Epoch 1520/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2625 - f1: 0.7112 - val_loss: 0.4283 - val_f1: 0.1451\n",
      "Epoch 1521/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2621 - f1: 0.7177 - val_loss: 0.4292 - val_f1: 0.1449\n",
      "Epoch 1522/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2624 - f1: 0.7143 - val_loss: 0.4321 - val_f1: 0.1449\n",
      "Epoch 1523/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2611 - f1: 0.7168 - val_loss: 0.4307 - val_f1: 0.1452\n",
      "Epoch 1524/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2599 - f1: 0.7176 - val_loss: 0.4311 - val_f1: 0.1458\n",
      "Epoch 1525/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2592 - f1: 0.7175 - val_loss: 0.4280 - val_f1: 0.1453\n",
      "Epoch 1526/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2609 - f1: 0.7155 - val_loss: 0.4308 - val_f1: 0.1461\n",
      "Epoch 1527/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2607 - f1: 0.7154 - val_loss: 0.4239 - val_f1: 0.1449\n",
      "Epoch 1528/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2622 - f1: 0.7128 - val_loss: 0.4308 - val_f1: 0.1451\n",
      "Epoch 1529/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2604 - f1: 0.7196 - val_loss: 0.4316 - val_f1: 0.1457\n",
      "Epoch 1530/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2629 - f1: 0.7084 - val_loss: 0.4304 - val_f1: 0.1452\n",
      "Epoch 1531/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2619 - f1: 0.7176 - val_loss: 0.4304 - val_f1: 0.1455\n",
      "Epoch 1532/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2627 - f1: 0.7155 - val_loss: 0.4273 - val_f1: 0.1460\n",
      "Epoch 1533/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2634 - f1: 0.7117 - val_loss: 0.4298 - val_f1: 0.1444\n",
      "Epoch 1534/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2613 - f1: 0.7173 - val_loss: 0.4292 - val_f1: 0.1448\n",
      "Epoch 1535/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2624 - f1: 0.7143 - val_loss: 0.4312 - val_f1: 0.1456\n",
      "Epoch 1536/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2610 - f1: 0.7188 - val_loss: 0.4279 - val_f1: 0.1450\n",
      "Epoch 1537/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2612 - f1: 0.7163 - val_loss: 0.4272 - val_f1: 0.1459\n",
      "Epoch 1538/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2611 - f1: 0.7209 - val_loss: 0.4278 - val_f1: 0.1450\n",
      "Epoch 1539/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2629 - f1: 0.7109 - val_loss: 0.4294 - val_f1: 0.1456\n",
      "Epoch 1540/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2611 - f1: 0.7176 - val_loss: 0.4254 - val_f1: 0.1451\n",
      "Epoch 1541/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2589 - f1: 0.7177 - val_loss: 0.4274 - val_f1: 0.1455\n",
      "Epoch 1542/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2630 - f1: 0.7154 - val_loss: 0.4306 - val_f1: 0.1448\n",
      "Epoch 1543/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2620 - f1: 0.7170 - val_loss: 0.4282 - val_f1: 0.1456\n",
      "Epoch 1544/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2629 - f1: 0.7112 - val_loss: 0.4226 - val_f1: 0.1445\n",
      "Epoch 1545/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2625 - f1: 0.7147 - val_loss: 0.4266 - val_f1: 0.1447\n",
      "Epoch 1546/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2615 - f1: 0.7159 - val_loss: 0.4296 - val_f1: 0.1458\n",
      "Epoch 1547/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2607 - f1: 0.7153 - val_loss: 0.4264 - val_f1: 0.1455\n",
      "Epoch 1548/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2602 - f1: 0.7144 - val_loss: 0.4312 - val_f1: 0.1459\n",
      "Epoch 1549/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2632 - f1: 0.7103 - val_loss: 0.4282 - val_f1: 0.1452\n",
      "Epoch 1550/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2628 - f1: 0.7114 - val_loss: 0.4285 - val_f1: 0.1454\n",
      "Epoch 1551/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2625 - f1: 0.7163 - val_loss: 0.4266 - val_f1: 0.1452\n",
      "Epoch 1552/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2615 - f1: 0.7157 - val_loss: 0.4287 - val_f1: 0.1457\n",
      "Epoch 1553/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2597 - f1: 0.7153 - val_loss: 0.4276 - val_f1: 0.1462\n",
      "Epoch 1554/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2617 - f1: 0.7120 - val_loss: 0.4298 - val_f1: 0.1456\n",
      "Epoch 1555/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2622 - f1: 0.7159 - val_loss: 0.4285 - val_f1: 0.1450\n",
      "Epoch 1556/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2602 - f1: 0.7184 - val_loss: 0.4303 - val_f1: 0.1444\n",
      "Epoch 1557/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2624 - f1: 0.7171 - val_loss: 0.4269 - val_f1: 0.1453\n",
      "Epoch 1558/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2607 - f1: 0.7135 - val_loss: 0.4296 - val_f1: 0.1459\n",
      "Epoch 1559/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2603 - f1: 0.7140 - val_loss: 0.4321 - val_f1: 0.1462\n",
      "Epoch 1560/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2623 - f1: 0.7146 - val_loss: 0.4258 - val_f1: 0.1448\n",
      "Epoch 1561/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2607 - f1: 0.7155 - val_loss: 0.4303 - val_f1: 0.1451\n",
      "Epoch 1562/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2621 - f1: 0.7150 - val_loss: 0.4245 - val_f1: 0.1461\n",
      "Epoch 1563/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2604 - f1: 0.7182 - val_loss: 0.4294 - val_f1: 0.1461\n",
      "Epoch 1564/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2618 - f1: 0.7166 - val_loss: 0.4309 - val_f1: 0.1462\n",
      "Epoch 1565/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2596 - f1: 0.7165 - val_loss: 0.4298 - val_f1: 0.1453\n",
      "Epoch 1566/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2625 - f1: 0.7121 - val_loss: 0.4257 - val_f1: 0.1456\n",
      "Epoch 1567/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2633 - f1: 0.7149 - val_loss: 0.4251 - val_f1: 0.1456\n",
      "Epoch 1568/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2637 - f1: 0.7180 - val_loss: 0.4267 - val_f1: 0.1446\n",
      "Epoch 1569/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2616 - f1: 0.7175 - val_loss: 0.4278 - val_f1: 0.1459\n",
      "Epoch 1570/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2623 - f1: 0.7168 - val_loss: 0.4275 - val_f1: 0.1451\n",
      "Epoch 1571/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2611 - f1: 0.7174 - val_loss: 0.4309 - val_f1: 0.1452\n",
      "Epoch 1572/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2603 - f1: 0.7189 - val_loss: 0.4273 - val_f1: 0.1454\n",
      "Epoch 1573/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2621 - f1: 0.7169 - val_loss: 0.4289 - val_f1: 0.1454\n",
      "Epoch 1574/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2611 - f1: 0.7132 - val_loss: 0.4274 - val_f1: 0.1452\n",
      "Epoch 1575/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2624 - f1: 0.7136 - val_loss: 0.4247 - val_f1: 0.1453\n",
      "Epoch 1576/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2598 - f1: 0.7157 - val_loss: 0.4314 - val_f1: 0.1451\n",
      "Epoch 1577/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2638 - f1: 0.7120 - val_loss: 0.4264 - val_f1: 0.1458\n",
      "Epoch 1578/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2620 - f1: 0.7156 - val_loss: 0.4246 - val_f1: 0.1465\n",
      "Epoch 1579/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2594 - f1: 0.7197 - val_loss: 0.4310 - val_f1: 0.1451\n",
      "Epoch 1580/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2610 - f1: 0.7142 - val_loss: 0.4277 - val_f1: 0.1464\n",
      "Epoch 1581/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2630 - f1: 0.7109 - val_loss: 0.4294 - val_f1: 0.1460\n",
      "Epoch 1582/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2616 - f1: 0.7140 - val_loss: 0.4342 - val_f1: 0.1454\n",
      "Epoch 1583/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2597 - f1: 0.7198 - val_loss: 0.4252 - val_f1: 0.1452\n",
      "Epoch 1584/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2592 - f1: 0.7211 - val_loss: 0.4317 - val_f1: 0.1455\n",
      "Epoch 1585/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2587 - f1: 0.7199 - val_loss: 0.4341 - val_f1: 0.1455\n",
      "Epoch 1586/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2612 - f1: 0.7169 - val_loss: 0.4289 - val_f1: 0.1452\n",
      "Epoch 1587/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2612 - f1: 0.7168 - val_loss: 0.4293 - val_f1: 0.1456\n",
      "Epoch 1588/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2604 - f1: 0.7169 - val_loss: 0.4286 - val_f1: 0.1452\n",
      "Epoch 1589/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2609 - f1: 0.7144 - val_loss: 0.4287 - val_f1: 0.1454\n",
      "Epoch 1590/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2623 - f1: 0.7113 - val_loss: 0.4315 - val_f1: 0.1458\n",
      "Epoch 1591/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2610 - f1: 0.7170 - val_loss: 0.4323 - val_f1: 0.1465\n",
      "Epoch 1592/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2607 - f1: 0.7148 - val_loss: 0.4327 - val_f1: 0.1462\n",
      "Epoch 1593/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2612 - f1: 0.7160 - val_loss: 0.4329 - val_f1: 0.1457\n",
      "Epoch 1594/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2621 - f1: 0.7134 - val_loss: 0.4284 - val_f1: 0.1459\n",
      "Epoch 1595/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2590 - f1: 0.7214 - val_loss: 0.4313 - val_f1: 0.1455\n",
      "Epoch 1596/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2621 - f1: 0.7128 - val_loss: 0.4250 - val_f1: 0.1458\n",
      "Epoch 1597/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2601 - f1: 0.7140 - val_loss: 0.4304 - val_f1: 0.1465\n",
      "Epoch 1598/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2597 - f1: 0.7180 - val_loss: 0.4333 - val_f1: 0.1453\n",
      "Epoch 1599/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2614 - f1: 0.7142 - val_loss: 0.4302 - val_f1: 0.1450\n",
      "Epoch 1600/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2612 - f1: 0.7146 - val_loss: 0.4309 - val_f1: 0.1450\n",
      "Epoch 1601/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2625 - f1: 0.7126 - val_loss: 0.4300 - val_f1: 0.1467\n",
      "Epoch 1602/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2606 - f1: 0.7171 - val_loss: 0.4278 - val_f1: 0.1461\n",
      "Epoch 1603/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2621 - f1: 0.7177 - val_loss: 0.4282 - val_f1: 0.1444\n",
      "Epoch 1604/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2603 - f1: 0.7188 - val_loss: 0.4357 - val_f1: 0.1447\n",
      "Epoch 1605/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2611 - f1: 0.7197 - val_loss: 0.4286 - val_f1: 0.1449\n",
      "Epoch 1606/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2601 - f1: 0.7179 - val_loss: 0.4292 - val_f1: 0.1464\n",
      "Epoch 1607/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2614 - f1: 0.7177 - val_loss: 0.4269 - val_f1: 0.1448\n",
      "Epoch 1608/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2611 - f1: 0.7179 - val_loss: 0.4323 - val_f1: 0.1457\n",
      "Epoch 1609/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2597 - f1: 0.7190 - val_loss: 0.4333 - val_f1: 0.1454\n",
      "Epoch 1610/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2611 - f1: 0.7155 - val_loss: 0.4274 - val_f1: 0.1456\n",
      "Epoch 1611/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2617 - f1: 0.7179 - val_loss: 0.4286 - val_f1: 0.1455\n",
      "Epoch 1612/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2614 - f1: 0.7189 - val_loss: 0.4296 - val_f1: 0.1454\n",
      "Epoch 1613/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2615 - f1: 0.7141 - val_loss: 0.4342 - val_f1: 0.1456\n",
      "Epoch 1614/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2618 - f1: 0.7160 - val_loss: 0.4295 - val_f1: 0.1454\n",
      "Epoch 1615/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2625 - f1: 0.7156 - val_loss: 0.4321 - val_f1: 0.1460\n",
      "Epoch 1616/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2610 - f1: 0.7196 - val_loss: 0.4285 - val_f1: 0.1457\n",
      "Epoch 1617/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2618 - f1: 0.7191 - val_loss: 0.4314 - val_f1: 0.1463\n",
      "Epoch 1618/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2591 - f1: 0.7220 - val_loss: 0.4298 - val_f1: 0.1459\n",
      "Epoch 1619/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2599 - f1: 0.7174 - val_loss: 0.4255 - val_f1: 0.1465\n",
      "Epoch 1620/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2620 - f1: 0.7139 - val_loss: 0.4268 - val_f1: 0.1454\n",
      "Epoch 1621/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2621 - f1: 0.7162 - val_loss: 0.4275 - val_f1: 0.1456\n",
      "Epoch 1622/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2617 - f1: 0.7136 - val_loss: 0.4295 - val_f1: 0.1464\n",
      "Epoch 1623/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2615 - f1: 0.7131 - val_loss: 0.4252 - val_f1: 0.1456\n",
      "Epoch 1624/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2611 - f1: 0.7173 - val_loss: 0.4286 - val_f1: 0.1458\n",
      "Epoch 1625/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2598 - f1: 0.7167 - val_loss: 0.4331 - val_f1: 0.1458\n",
      "Epoch 1626/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2618 - f1: 0.7190 - val_loss: 0.4292 - val_f1: 0.1459\n",
      "Epoch 1627/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2602 - f1: 0.7153 - val_loss: 0.4304 - val_f1: 0.1447\n",
      "Epoch 1628/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2598 - f1: 0.7144 - val_loss: 0.4303 - val_f1: 0.1458\n",
      "Epoch 1629/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2618 - f1: 0.7115 - val_loss: 0.4258 - val_f1: 0.1456\n",
      "Epoch 1630/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2610 - f1: 0.7118 - val_loss: 0.4312 - val_f1: 0.1458\n",
      "Epoch 1631/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2588 - f1: 0.7183 - val_loss: 0.4297 - val_f1: 0.1465\n",
      "Epoch 1632/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2602 - f1: 0.7170 - val_loss: 0.4285 - val_f1: 0.1459\n",
      "Epoch 1633/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2609 - f1: 0.7167 - val_loss: 0.4240 - val_f1: 0.1458\n",
      "Epoch 1634/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2591 - f1: 0.7215 - val_loss: 0.4288 - val_f1: 0.1456\n",
      "Epoch 1635/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2590 - f1: 0.7194 - val_loss: 0.4281 - val_f1: 0.1452\n",
      "Epoch 1636/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2612 - f1: 0.7189 - val_loss: 0.4296 - val_f1: 0.1448\n",
      "Epoch 1637/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2621 - f1: 0.7155 - val_loss: 0.4282 - val_f1: 0.1454\n",
      "Epoch 1638/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2603 - f1: 0.7166 - val_loss: 0.4258 - val_f1: 0.1461\n",
      "Epoch 1639/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2602 - f1: 0.7190 - val_loss: 0.4312 - val_f1: 0.1454\n",
      "Epoch 1640/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2608 - f1: 0.7195 - val_loss: 0.4296 - val_f1: 0.1446\n",
      "Epoch 1641/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2587 - f1: 0.7199 - val_loss: 0.4316 - val_f1: 0.1451\n",
      "Epoch 1642/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2599 - f1: 0.7183 - val_loss: 0.4297 - val_f1: 0.1453\n",
      "Epoch 1643/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2589 - f1: 0.7206 - val_loss: 0.4327 - val_f1: 0.1456\n",
      "Epoch 1644/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2598 - f1: 0.7164 - val_loss: 0.4345 - val_f1: 0.1453\n",
      "Epoch 1645/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2599 - f1: 0.7186 - val_loss: 0.4288 - val_f1: 0.1454\n",
      "Epoch 1646/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2588 - f1: 0.7225 - val_loss: 0.4293 - val_f1: 0.1454\n",
      "Epoch 1647/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2604 - f1: 0.7183 - val_loss: 0.4313 - val_f1: 0.1465\n",
      "Epoch 1648/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2579 - f1: 0.7192 - val_loss: 0.4316 - val_f1: 0.1451\n",
      "Epoch 1649/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2593 - f1: 0.7160 - val_loss: 0.4270 - val_f1: 0.1459\n",
      "Epoch 1650/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2604 - f1: 0.7177 - val_loss: 0.4295 - val_f1: 0.1452\n",
      "Epoch 1651/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2590 - f1: 0.7192 - val_loss: 0.4362 - val_f1: 0.1462\n",
      "Epoch 1652/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2626 - f1: 0.7137 - val_loss: 0.4277 - val_f1: 0.1453\n",
      "Epoch 1653/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2611 - f1: 0.7194 - val_loss: 0.4275 - val_f1: 0.1457\n",
      "Epoch 1654/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2593 - f1: 0.7185 - val_loss: 0.4284 - val_f1: 0.1461\n",
      "Epoch 1655/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2599 - f1: 0.7195 - val_loss: 0.4304 - val_f1: 0.1460\n",
      "Epoch 1656/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2628 - f1: 0.7174 - val_loss: 0.4282 - val_f1: 0.1456\n",
      "Epoch 1657/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2600 - f1: 0.7210 - val_loss: 0.4333 - val_f1: 0.1456\n",
      "Epoch 1658/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2594 - f1: 0.7166 - val_loss: 0.4301 - val_f1: 0.1455\n",
      "Epoch 1659/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2619 - f1: 0.7150 - val_loss: 0.4279 - val_f1: 0.1456\n",
      "Epoch 1660/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2600 - f1: 0.7135 - val_loss: 0.4301 - val_f1: 0.1458\n",
      "Epoch 1661/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2605 - f1: 0.7158 - val_loss: 0.4306 - val_f1: 0.1451\n",
      "Epoch 1662/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2598 - f1: 0.7163 - val_loss: 0.4324 - val_f1: 0.1456\n",
      "Epoch 1663/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2582 - f1: 0.7188 - val_loss: 0.4309 - val_f1: 0.1456\n",
      "Epoch 1664/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2603 - f1: 0.7145 - val_loss: 0.4295 - val_f1: 0.1455\n",
      "Epoch 1665/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2573 - f1: 0.7226 - val_loss: 0.4295 - val_f1: 0.1458\n",
      "Epoch 1666/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2612 - f1: 0.7143 - val_loss: 0.4324 - val_f1: 0.1458\n",
      "Epoch 1667/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2609 - f1: 0.7143 - val_loss: 0.4318 - val_f1: 0.1453\n",
      "Epoch 1668/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2608 - f1: 0.7115 - val_loss: 0.4269 - val_f1: 0.1453\n",
      "Epoch 1669/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2602 - f1: 0.7175 - val_loss: 0.4302 - val_f1: 0.1461\n",
      "Epoch 1670/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2588 - f1: 0.7180 - val_loss: 0.4319 - val_f1: 0.1457\n",
      "Epoch 1671/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2592 - f1: 0.7204 - val_loss: 0.4283 - val_f1: 0.1449\n",
      "Epoch 1672/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2598 - f1: 0.7200 - val_loss: 0.4263 - val_f1: 0.1448\n",
      "Epoch 1673/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2611 - f1: 0.7146 - val_loss: 0.4249 - val_f1: 0.1454\n",
      "Epoch 1674/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2587 - f1: 0.7176 - val_loss: 0.4307 - val_f1: 0.1459\n",
      "Epoch 1675/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2606 - f1: 0.7168 - val_loss: 0.4339 - val_f1: 0.1457\n",
      "Epoch 1676/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2623 - f1: 0.7175 - val_loss: 0.4307 - val_f1: 0.1457\n",
      "Epoch 1677/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2599 - f1: 0.7174 - val_loss: 0.4243 - val_f1: 0.1457\n",
      "Epoch 1678/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2606 - f1: 0.7189 - val_loss: 0.4288 - val_f1: 0.1460\n",
      "Epoch 1679/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2618 - f1: 0.7160 - val_loss: 0.4233 - val_f1: 0.1456\n",
      "Epoch 1680/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2606 - f1: 0.7160 - val_loss: 0.4265 - val_f1: 0.1449\n",
      "Epoch 1681/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2582 - f1: 0.7152 - val_loss: 0.4292 - val_f1: 0.1459\n",
      "Epoch 1682/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2597 - f1: 0.7169 - val_loss: 0.4251 - val_f1: 0.1461\n",
      "Epoch 1683/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2595 - f1: 0.7204 - val_loss: 0.4322 - val_f1: 0.1457\n",
      "Epoch 1684/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2599 - f1: 0.7167 - val_loss: 0.4302 - val_f1: 0.1464\n",
      "Epoch 1685/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2614 - f1: 0.7155 - val_loss: 0.4298 - val_f1: 0.1458\n",
      "Epoch 1686/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2603 - f1: 0.7212 - val_loss: 0.4272 - val_f1: 0.1450\n",
      "Epoch 1687/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2602 - f1: 0.7166 - val_loss: 0.4316 - val_f1: 0.1446\n",
      "Epoch 1688/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2582 - f1: 0.7209 - val_loss: 0.4318 - val_f1: 0.1452\n",
      "Epoch 1689/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2594 - f1: 0.7165 - val_loss: 0.4317 - val_f1: 0.1463\n",
      "Epoch 1690/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2586 - f1: 0.7167 - val_loss: 0.4305 - val_f1: 0.1465\n",
      "Epoch 1691/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2580 - f1: 0.7193 - val_loss: 0.4283 - val_f1: 0.1459\n",
      "Epoch 1692/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2584 - f1: 0.7239 - val_loss: 0.4310 - val_f1: 0.1459\n",
      "Epoch 1693/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2598 - f1: 0.7179 - val_loss: 0.4264 - val_f1: 0.1453\n",
      "Epoch 1694/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2604 - f1: 0.7184 - val_loss: 0.4290 - val_f1: 0.1451\n",
      "Epoch 1695/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2584 - f1: 0.7210 - val_loss: 0.4301 - val_f1: 0.1453\n",
      "Epoch 1696/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2565 - f1: 0.7254 - val_loss: 0.4320 - val_f1: 0.1457\n",
      "Epoch 1697/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2592 - f1: 0.7202 - val_loss: 0.4345 - val_f1: 0.1456\n",
      "Epoch 1698/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2603 - f1: 0.7187 - val_loss: 0.4270 - val_f1: 0.1465\n",
      "Epoch 1699/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2624 - f1: 0.7120 - val_loss: 0.4268 - val_f1: 0.1452\n",
      "Epoch 1700/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2596 - f1: 0.7185 - val_loss: 0.4302 - val_f1: 0.1460\n",
      "Epoch 1701/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2596 - f1: 0.7164 - val_loss: 0.4288 - val_f1: 0.1465\n",
      "Epoch 1702/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2600 - f1: 0.7173 - val_loss: 0.4254 - val_f1: 0.1449\n",
      "Epoch 1703/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2593 - f1: 0.7172 - val_loss: 0.4287 - val_f1: 0.1455\n",
      "Epoch 1704/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2597 - f1: 0.7192 - val_loss: 0.4284 - val_f1: 0.1455\n",
      "Epoch 1705/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2607 - f1: 0.7190 - val_loss: 0.4263 - val_f1: 0.1452\n",
      "Epoch 1706/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2618 - f1: 0.7153 - val_loss: 0.4314 - val_f1: 0.1452\n",
      "Epoch 1707/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2579 - f1: 0.7211 - val_loss: 0.4307 - val_f1: 0.1459\n",
      "Epoch 1708/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2596 - f1: 0.7181 - val_loss: 0.4313 - val_f1: 0.1456\n",
      "Epoch 1709/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2572 - f1: 0.7235 - val_loss: 0.4341 - val_f1: 0.1462\n",
      "Epoch 1710/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2592 - f1: 0.7204 - val_loss: 0.4291 - val_f1: 0.1454\n",
      "Epoch 1711/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2585 - f1: 0.7210 - val_loss: 0.4288 - val_f1: 0.1460\n",
      "Epoch 1712/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2600 - f1: 0.7139 - val_loss: 0.4318 - val_f1: 0.1459\n",
      "Epoch 1713/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2601 - f1: 0.7157 - val_loss: 0.4315 - val_f1: 0.1453\n",
      "Epoch 1714/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2573 - f1: 0.7207 - val_loss: 0.4314 - val_f1: 0.1452\n",
      "Epoch 1715/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2578 - f1: 0.7201 - val_loss: 0.4280 - val_f1: 0.1466\n",
      "Epoch 1716/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2593 - f1: 0.7177 - val_loss: 0.4286 - val_f1: 0.1455\n",
      "Epoch 1717/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2583 - f1: 0.7212 - val_loss: 0.4305 - val_f1: 0.1452\n",
      "Epoch 1718/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2585 - f1: 0.7169 - val_loss: 0.4268 - val_f1: 0.1457\n",
      "Epoch 1719/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2595 - f1: 0.7152 - val_loss: 0.4301 - val_f1: 0.1458\n",
      "Epoch 1720/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2581 - f1: 0.7218 - val_loss: 0.4318 - val_f1: 0.1453\n",
      "Epoch 1721/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2585 - f1: 0.7231 - val_loss: 0.4340 - val_f1: 0.1455\n",
      "Epoch 1722/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2581 - f1: 0.7227 - val_loss: 0.4355 - val_f1: 0.1458\n",
      "Epoch 1723/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2566 - f1: 0.7210 - val_loss: 0.4327 - val_f1: 0.1456\n",
      "Epoch 1724/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2583 - f1: 0.7206 - val_loss: 0.4310 - val_f1: 0.1456\n",
      "Epoch 1725/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2606 - f1: 0.7155 - val_loss: 0.4303 - val_f1: 0.1462\n",
      "Epoch 1726/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2609 - f1: 0.7177 - val_loss: 0.4308 - val_f1: 0.1454\n",
      "Epoch 1727/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2590 - f1: 0.7199 - val_loss: 0.4305 - val_f1: 0.1459\n",
      "Epoch 1728/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2602 - f1: 0.7185 - val_loss: 0.4269 - val_f1: 0.1448\n",
      "Epoch 1729/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2583 - f1: 0.7205 - val_loss: 0.4289 - val_f1: 0.1452\n",
      "Epoch 1730/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2598 - f1: 0.7157 - val_loss: 0.4277 - val_f1: 0.1454\n",
      "Epoch 1731/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2594 - f1: 0.7152 - val_loss: 0.4279 - val_f1: 0.1451\n",
      "Epoch 1732/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2598 - f1: 0.7160 - val_loss: 0.4264 - val_f1: 0.1446\n",
      "Epoch 1733/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.2589 - f1: 0.72 - 3s 42us/step - loss: 0.2587 - f1: 0.7214 - val_loss: 0.4326 - val_f1: 0.1459\n",
      "Epoch 1734/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2592 - f1: 0.7196 - val_loss: 0.4335 - val_f1: 0.1449\n",
      "Epoch 1735/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2562 - f1: 0.7212 - val_loss: 0.4308 - val_f1: 0.1446\n",
      "Epoch 1736/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2574 - f1: 0.7228 - val_loss: 0.4276 - val_f1: 0.1454\n",
      "Epoch 1737/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2589 - f1: 0.7207 - val_loss: 0.4310 - val_f1: 0.1453\n",
      "Epoch 1738/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2602 - f1: 0.7150 - val_loss: 0.4351 - val_f1: 0.1460\n",
      "Epoch 1739/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2590 - f1: 0.7198 - val_loss: 0.4337 - val_f1: 0.1451\n",
      "Epoch 1740/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2596 - f1: 0.7148 - val_loss: 0.4299 - val_f1: 0.1452\n",
      "Epoch 1741/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2610 - f1: 0.7149 - val_loss: 0.4251 - val_f1: 0.1456\n",
      "Epoch 1742/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2589 - f1: 0.7220 - val_loss: 0.4321 - val_f1: 0.1464\n",
      "Epoch 1743/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2570 - f1: 0.7228 - val_loss: 0.4281 - val_f1: 0.1461\n",
      "Epoch 1744/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2584 - f1: 0.7173 - val_loss: 0.4286 - val_f1: 0.1456\n",
      "Epoch 1745/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2594 - f1: 0.7168 - val_loss: 0.4275 - val_f1: 0.1458\n",
      "Epoch 1746/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2609 - f1: 0.7152 - val_loss: 0.4265 - val_f1: 0.1457\n",
      "Epoch 1747/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2567 - f1: 0.7232 - val_loss: 0.4338 - val_f1: 0.1459\n",
      "Epoch 1748/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2576 - f1: 0.7225 - val_loss: 0.4331 - val_f1: 0.1456\n",
      "Epoch 1749/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2596 - f1: 0.7194 - val_loss: 0.4315 - val_f1: 0.1459\n",
      "Epoch 1750/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2595 - f1: 0.7203 - val_loss: 0.4288 - val_f1: 0.1442\n",
      "Epoch 1751/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2607 - f1: 0.7197 - val_loss: 0.4292 - val_f1: 0.1445\n",
      "Epoch 1752/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2585 - f1: 0.7229 - val_loss: 0.4302 - val_f1: 0.1455\n",
      "Epoch 1753/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2581 - f1: 0.7215 - val_loss: 0.4317 - val_f1: 0.1456\n",
      "Epoch 1754/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2595 - f1: 0.7214 - val_loss: 0.4312 - val_f1: 0.1451\n",
      "Epoch 1755/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2586 - f1: 0.7217 - val_loss: 0.4294 - val_f1: 0.1447\n",
      "Epoch 1756/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2588 - f1: 0.7197 - val_loss: 0.4334 - val_f1: 0.1452\n",
      "Epoch 1757/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2578 - f1: 0.7193 - val_loss: 0.4263 - val_f1: 0.1460\n",
      "Epoch 1758/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2580 - f1: 0.7200 - val_loss: 0.4356 - val_f1: 0.1455\n",
      "Epoch 1759/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2592 - f1: 0.7211 - val_loss: 0.4266 - val_f1: 0.1456\n",
      "Epoch 1760/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2586 - f1: 0.7217 - val_loss: 0.4358 - val_f1: 0.1456\n",
      "Epoch 1761/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2597 - f1: 0.7182 - val_loss: 0.4310 - val_f1: 0.1454\n",
      "Epoch 1762/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2611 - f1: 0.7156 - val_loss: 0.4307 - val_f1: 0.1458\n",
      "Epoch 1763/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2583 - f1: 0.7204 - val_loss: 0.4313 - val_f1: 0.1451\n",
      "Epoch 1764/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2592 - f1: 0.7193 - val_loss: 0.4289 - val_f1: 0.1452\n",
      "Epoch 1765/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2584 - f1: 0.7205 - val_loss: 0.4310 - val_f1: 0.1451\n",
      "Epoch 1766/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.2576 - f1: 0.72 - 3s 41us/step - loss: 0.2574 - f1: 0.7209 - val_loss: 0.4355 - val_f1: 0.1456\n",
      "Epoch 1767/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2602 - f1: 0.7180 - val_loss: 0.4250 - val_f1: 0.1453\n",
      "Epoch 1768/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2589 - f1: 0.7203 - val_loss: 0.4368 - val_f1: 0.1458\n",
      "Epoch 1769/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2595 - f1: 0.7200 - val_loss: 0.4323 - val_f1: 0.1454\n",
      "Epoch 1770/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2602 - f1: 0.7195 - val_loss: 0.4259 - val_f1: 0.1444\n",
      "Epoch 1771/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2570 - f1: 0.7216 - val_loss: 0.4335 - val_f1: 0.1444\n",
      "Epoch 1772/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2593 - f1: 0.7189 - val_loss: 0.4304 - val_f1: 0.1455\n",
      "Epoch 1773/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2597 - f1: 0.7274 - val_loss: 0.4280 - val_f1: 0.1449\n",
      "Epoch 1774/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2585 - f1: 0.7245 - val_loss: 0.4374 - val_f1: 0.1459\n",
      "Epoch 1775/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2602 - f1: 0.7155 - val_loss: 0.4293 - val_f1: 0.1450\n",
      "Epoch 1776/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2585 - f1: 0.7210 - val_loss: 0.4305 - val_f1: 0.1453\n",
      "Epoch 1777/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2621 - f1: 0.7137 - val_loss: 0.4263 - val_f1: 0.1448\n",
      "Epoch 1778/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2583 - f1: 0.7218 - val_loss: 0.4353 - val_f1: 0.1451\n",
      "Epoch 1779/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2598 - f1: 0.7193 - val_loss: 0.4303 - val_f1: 0.1452\n",
      "Epoch 1780/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2597 - f1: 0.7153 - val_loss: 0.4317 - val_f1: 0.1456\n",
      "Epoch 1781/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2588 - f1: 0.7199 - val_loss: 0.4260 - val_f1: 0.1450\n",
      "Epoch 1782/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2582 - f1: 0.7222 - val_loss: 0.4280 - val_f1: 0.1454\n",
      "Epoch 1783/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2557 - f1: 0.7211 - val_loss: 0.4321 - val_f1: 0.1459\n",
      "Epoch 1784/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2567 - f1: 0.7212 - val_loss: 0.4328 - val_f1: 0.1454\n",
      "Epoch 1785/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2598 - f1: 0.7228 - val_loss: 0.4321 - val_f1: 0.1449\n",
      "Epoch 1786/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2581 - f1: 0.7136 - val_loss: 0.4297 - val_f1: 0.1450\n",
      "Epoch 1787/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2568 - f1: 0.7238 - val_loss: 0.4346 - val_f1: 0.1454\n",
      "Epoch 1788/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2566 - f1: 0.7219 - val_loss: 0.4336 - val_f1: 0.1448\n",
      "Epoch 1789/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2555 - f1: 0.7261 - val_loss: 0.4355 - val_f1: 0.1454\n",
      "Epoch 1790/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2594 - f1: 0.7202 - val_loss: 0.4256 - val_f1: 0.1451\n",
      "Epoch 1791/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2567 - f1: 0.7236 - val_loss: 0.4293 - val_f1: 0.1452\n",
      "Epoch 1792/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2562 - f1: 0.7252 - val_loss: 0.4353 - val_f1: 0.1455\n",
      "Epoch 1793/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2578 - f1: 0.7226 - val_loss: 0.4343 - val_f1: 0.1459\n",
      "Epoch 1794/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2611 - f1: 0.7175 - val_loss: 0.4290 - val_f1: 0.1454\n",
      "Epoch 1795/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2570 - f1: 0.7258 - val_loss: 0.4326 - val_f1: 0.1464\n",
      "Epoch 1796/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2597 - f1: 0.7173 - val_loss: 0.4285 - val_f1: 0.1451\n",
      "Epoch 1797/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2590 - f1: 0.7178 - val_loss: 0.4322 - val_f1: 0.1452\n",
      "Epoch 1798/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2577 - f1: 0.7195 - val_loss: 0.4305 - val_f1: 0.1460\n",
      "Epoch 1799/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2565 - f1: 0.7207 - val_loss: 0.4338 - val_f1: 0.1460\n",
      "Epoch 1800/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2579 - f1: 0.7225 - val_loss: 0.4341 - val_f1: 0.1452\n",
      "Epoch 1801/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2580 - f1: 0.7183 - val_loss: 0.4331 - val_f1: 0.1459\n",
      "Epoch 1802/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2599 - f1: 0.7193 - val_loss: 0.4262 - val_f1: 0.1456\n",
      "Epoch 1803/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2596 - f1: 0.7190 - val_loss: 0.4331 - val_f1: 0.1460\n",
      "Epoch 1804/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2578 - f1: 0.7180 - val_loss: 0.4330 - val_f1: 0.1461\n",
      "Epoch 1805/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2567 - f1: 0.7260 - val_loss: 0.4326 - val_f1: 0.1463\n",
      "Epoch 1806/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2542 - f1: 0.7284 - val_loss: 0.4298 - val_f1: 0.1457\n",
      "Epoch 1807/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2580 - f1: 0.7194 - val_loss: 0.4297 - val_f1: 0.1458\n",
      "Epoch 1808/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2581 - f1: 0.7220 - val_loss: 0.4274 - val_f1: 0.1452\n",
      "Epoch 1809/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2592 - f1: 0.7241 - val_loss: 0.4283 - val_f1: 0.1454\n",
      "Epoch 1810/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2579 - f1: 0.7206 - val_loss: 0.4316 - val_f1: 0.1461\n",
      "Epoch 1811/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2587 - f1: 0.7229 - val_loss: 0.4344 - val_f1: 0.1458\n",
      "Epoch 1812/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2608 - f1: 0.7154 - val_loss: 0.4266 - val_f1: 0.1460\n",
      "Epoch 1813/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2584 - f1: 0.7231 - val_loss: 0.4319 - val_f1: 0.1450\n",
      "Epoch 1814/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2597 - f1: 0.7179 - val_loss: 0.4295 - val_f1: 0.1452\n",
      "Epoch 1815/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2589 - f1: 0.7202 - val_loss: 0.4322 - val_f1: 0.1462\n",
      "Epoch 1816/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2591 - f1: 0.7189 - val_loss: 0.4266 - val_f1: 0.1457\n",
      "Epoch 1817/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2594 - f1: 0.7219 - val_loss: 0.4336 - val_f1: 0.1453\n",
      "Epoch 1818/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2563 - f1: 0.7211 - val_loss: 0.4345 - val_f1: 0.1450\n",
      "Epoch 1819/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2592 - f1: 0.7200 - val_loss: 0.4305 - val_f1: 0.1460\n",
      "Epoch 1820/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2607 - f1: 0.7214 - val_loss: 0.4277 - val_f1: 0.1447\n",
      "Epoch 1821/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2589 - f1: 0.7163 - val_loss: 0.4320 - val_f1: 0.1456\n",
      "Epoch 1822/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2570 - f1: 0.7215 - val_loss: 0.4329 - val_f1: 0.1457\n",
      "Epoch 1823/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2586 - f1: 0.7235 - val_loss: 0.4356 - val_f1: 0.1447\n",
      "Epoch 1824/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2580 - f1: 0.7192 - val_loss: 0.4332 - val_f1: 0.1459\n",
      "Epoch 1825/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2563 - f1: 0.7251 - val_loss: 0.4312 - val_f1: 0.1459\n",
      "Epoch 1826/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2599 - f1: 0.7194 - val_loss: 0.4342 - val_f1: 0.1456\n",
      "Epoch 1827/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2593 - f1: 0.7205 - val_loss: 0.4250 - val_f1: 0.1451\n",
      "Epoch 1828/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2585 - f1: 0.7192 - val_loss: 0.4311 - val_f1: 0.1459\n",
      "Epoch 1829/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2573 - f1: 0.7205 - val_loss: 0.4300 - val_f1: 0.1452\n",
      "Epoch 1830/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2590 - f1: 0.7210 - val_loss: 0.4322 - val_f1: 0.1451\n",
      "Epoch 1831/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2575 - f1: 0.7247 - val_loss: 0.4353 - val_f1: 0.1465\n",
      "Epoch 1832/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2587 - f1: 0.7227 - val_loss: 0.4296 - val_f1: 0.1450\n",
      "Epoch 1833/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2587 - f1: 0.7210 - val_loss: 0.4346 - val_f1: 0.1454\n",
      "Epoch 1834/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2588 - f1: 0.7176 - val_loss: 0.4286 - val_f1: 0.1456\n",
      "Epoch 1835/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2563 - f1: 0.7246 - val_loss: 0.4361 - val_f1: 0.1459\n",
      "Epoch 1836/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2571 - f1: 0.7199 - val_loss: 0.4347 - val_f1: 0.1458\n",
      "Epoch 1837/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2573 - f1: 0.7238 - val_loss: 0.4280 - val_f1: 0.1462\n",
      "Epoch 1838/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2557 - f1: 0.7286 - val_loss: 0.4368 - val_f1: 0.1460\n",
      "Epoch 1839/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2569 - f1: 0.7214 - val_loss: 0.4322 - val_f1: 0.1457\n",
      "Epoch 1840/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2566 - f1: 0.7203 - val_loss: 0.4352 - val_f1: 0.1452\n",
      "Epoch 1841/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2584 - f1: 0.7190 - val_loss: 0.4271 - val_f1: 0.1454\n",
      "Epoch 1842/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2596 - f1: 0.7156 - val_loss: 0.4304 - val_f1: 0.1457\n",
      "Epoch 1843/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2578 - f1: 0.7201 - val_loss: 0.4346 - val_f1: 0.1457\n",
      "Epoch 1844/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2554 - f1: 0.7232 - val_loss: 0.4297 - val_f1: 0.1461\n",
      "Epoch 1845/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2605 - f1: 0.7149 - val_loss: 0.4268 - val_f1: 0.1458\n",
      "Epoch 1846/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2576 - f1: 0.7171 - val_loss: 0.4333 - val_f1: 0.1459\n",
      "Epoch 1847/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2601 - f1: 0.7168 - val_loss: 0.4271 - val_f1: 0.1452\n",
      "Epoch 1848/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2573 - f1: 0.7231 - val_loss: 0.4271 - val_f1: 0.1451\n",
      "Epoch 1849/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2570 - f1: 0.7216 - val_loss: 0.4352 - val_f1: 0.1465\n",
      "Epoch 1850/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2593 - f1: 0.7190 - val_loss: 0.4274 - val_f1: 0.1449\n",
      "Epoch 1851/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2577 - f1: 0.7221 - val_loss: 0.4304 - val_f1: 0.1458\n",
      "Epoch 1852/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2591 - f1: 0.7164 - val_loss: 0.4339 - val_f1: 0.1464\n",
      "Epoch 1853/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2579 - f1: 0.7225 - val_loss: 0.4307 - val_f1: 0.1452\n",
      "Epoch 1854/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2595 - f1: 0.7175 - val_loss: 0.4305 - val_f1: 0.1448\n",
      "Epoch 1855/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2590 - f1: 0.7220 - val_loss: 0.4309 - val_f1: 0.1447\n",
      "Epoch 1856/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2570 - f1: 0.7203 - val_loss: 0.4289 - val_f1: 0.1455\n",
      "Epoch 1857/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2568 - f1: 0.7244 - val_loss: 0.4272 - val_f1: 0.1451\n",
      "Epoch 1858/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2586 - f1: 0.7177 - val_loss: 0.4331 - val_f1: 0.1454\n",
      "Epoch 1859/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2558 - f1: 0.7256 - val_loss: 0.4322 - val_f1: 0.1460\n",
      "Epoch 1860/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2575 - f1: 0.7201 - val_loss: 0.4337 - val_f1: 0.1459\n",
      "Epoch 1861/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2584 - f1: 0.7195 - val_loss: 0.4300 - val_f1: 0.1459\n",
      "Epoch 1862/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2592 - f1: 0.7184 - val_loss: 0.4314 - val_f1: 0.1456\n",
      "Epoch 1863/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2566 - f1: 0.7235 - val_loss: 0.4276 - val_f1: 0.1461\n",
      "Epoch 1864/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2553 - f1: 0.7217 - val_loss: 0.4340 - val_f1: 0.1459\n",
      "Epoch 1865/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2598 - f1: 0.7199 - val_loss: 0.4335 - val_f1: 0.1459\n",
      "Epoch 1866/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2558 - f1: 0.7240 - val_loss: 0.4386 - val_f1: 0.1463\n",
      "Epoch 1867/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2553 - f1: 0.7258 - val_loss: 0.4331 - val_f1: 0.1455\n",
      "Epoch 1868/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2576 - f1: 0.7186 - val_loss: 0.4340 - val_f1: 0.1450\n",
      "Epoch 1869/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2569 - f1: 0.7194 - val_loss: 0.4336 - val_f1: 0.1463\n",
      "Epoch 1870/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2576 - f1: 0.7222 - val_loss: 0.4292 - val_f1: 0.1453\n",
      "Epoch 1871/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2598 - f1: 0.7229 - val_loss: 0.4312 - val_f1: 0.1457\n",
      "Epoch 1872/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2571 - f1: 0.7192 - val_loss: 0.4337 - val_f1: 0.1457\n",
      "Epoch 1873/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2553 - f1: 0.7213 - val_loss: 0.4378 - val_f1: 0.1455\n",
      "Epoch 1874/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2568 - f1: 0.7224 - val_loss: 0.4365 - val_f1: 0.1460\n",
      "Epoch 1875/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2559 - f1: 0.7243 - val_loss: 0.4332 - val_f1: 0.1459\n",
      "Epoch 1876/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2566 - f1: 0.7253 - val_loss: 0.4330 - val_f1: 0.1461\n",
      "Epoch 1877/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2607 - f1: 0.7190 - val_loss: 0.4316 - val_f1: 0.1456\n",
      "Epoch 1878/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2599 - f1: 0.7188 - val_loss: 0.4367 - val_f1: 0.1462\n",
      "Epoch 1879/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2583 - f1: 0.7180 - val_loss: 0.4355 - val_f1: 0.1461\n",
      "Epoch 1880/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2574 - f1: 0.7206 - val_loss: 0.4307 - val_f1: 0.1460\n",
      "Epoch 1881/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2578 - f1: 0.7202 - val_loss: 0.4332 - val_f1: 0.1462\n",
      "Epoch 1882/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2573 - f1: 0.7223 - val_loss: 0.4271 - val_f1: 0.1455\n",
      "Epoch 1883/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2587 - f1: 0.7209 - val_loss: 0.4290 - val_f1: 0.1464\n",
      "Epoch 1884/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2577 - f1: 0.7248 - val_loss: 0.4273 - val_f1: 0.1453\n",
      "Epoch 1885/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2578 - f1: 0.7224 - val_loss: 0.4302 - val_f1: 0.1451\n",
      "Epoch 1886/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2575 - f1: 0.7228 - val_loss: 0.4383 - val_f1: 0.1465\n",
      "Epoch 1887/2000\n",
      "64440/64440 [==============================] - 2s 37us/step - loss: 0.2586 - f1: 0.7196 - val_loss: 0.4319 - val_f1: 0.1457\n",
      "Epoch 1888/2000\n",
      "64440/64440 [==============================] - 3s 39us/step - loss: 0.2586 - f1: 0.7187 - val_loss: 0.4313 - val_f1: 0.1456\n",
      "Epoch 1889/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2570 - f1: 0.7244 - val_loss: 0.4271 - val_f1: 0.1448\n",
      "Epoch 1890/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2570 - f1: 0.7176 - val_loss: 0.4319 - val_f1: 0.1456\n",
      "Epoch 1891/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2553 - f1: 0.7258 - val_loss: 0.4365 - val_f1: 0.1452\n",
      "Epoch 1892/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2564 - f1: 0.7239 - val_loss: 0.4300 - val_f1: 0.1455\n",
      "Epoch 1893/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2585 - f1: 0.7178 - val_loss: 0.4334 - val_f1: 0.1459\n",
      "Epoch 1894/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2572 - f1: 0.7193 - val_loss: 0.4323 - val_f1: 0.1452\n",
      "Epoch 1895/2000\n",
      "64440/64440 [==============================] - 3s 40us/step - loss: 0.2590 - f1: 0.7203 - val_loss: 0.4339 - val_f1: 0.1459\n",
      "Epoch 1896/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2614 - f1: 0.7181 - val_loss: 0.4304 - val_f1: 0.1451\n",
      "Epoch 1897/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2578 - f1: 0.7214 - val_loss: 0.4270 - val_f1: 0.1458\n",
      "Epoch 1898/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2578 - f1: 0.7226 - val_loss: 0.4309 - val_f1: 0.1458\n",
      "Epoch 1899/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2591 - f1: 0.7179 - val_loss: 0.4329 - val_f1: 0.1452\n",
      "Epoch 1900/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2561 - f1: 0.7209 - val_loss: 0.4372 - val_f1: 0.1456\n",
      "Epoch 1901/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2577 - f1: 0.7240 - val_loss: 0.4276 - val_f1: 0.1461\n",
      "Epoch 1902/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2580 - f1: 0.7221 - val_loss: 0.4305 - val_f1: 0.1457\n",
      "Epoch 1903/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2584 - f1: 0.7201 - val_loss: 0.4337 - val_f1: 0.1458\n",
      "Epoch 1904/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2562 - f1: 0.7248 - val_loss: 0.4340 - val_f1: 0.1454\n",
      "Epoch 1905/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2576 - f1: 0.7172 - val_loss: 0.4325 - val_f1: 0.1462\n",
      "Epoch 1906/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2591 - f1: 0.7212 - val_loss: 0.4279 - val_f1: 0.1455\n",
      "Epoch 1907/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2576 - f1: 0.7201 - val_loss: 0.4325 - val_f1: 0.1458\n",
      "Epoch 1908/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2582 - f1: 0.7212 - val_loss: 0.4347 - val_f1: 0.1455\n",
      "Epoch 1909/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2569 - f1: 0.7163 - val_loss: 0.4371 - val_f1: 0.1460\n",
      "Epoch 1910/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2558 - f1: 0.7239 - val_loss: 0.4295 - val_f1: 0.1451\n",
      "Epoch 1911/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2565 - f1: 0.7255 - val_loss: 0.4323 - val_f1: 0.1461\n",
      "Epoch 1912/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2548 - f1: 0.7273 - val_loss: 0.4335 - val_f1: 0.1458\n",
      "Epoch 1913/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2585 - f1: 0.7200 - val_loss: 0.4306 - val_f1: 0.1451\n",
      "Epoch 1914/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2537 - f1: 0.7250 - val_loss: 0.4329 - val_f1: 0.1460\n",
      "Epoch 1915/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2552 - f1: 0.7300 - val_loss: 0.4339 - val_f1: 0.1459\n",
      "Epoch 1916/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2581 - f1: 0.7207 - val_loss: 0.4296 - val_f1: 0.1458\n",
      "Epoch 1917/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2579 - f1: 0.7210 - val_loss: 0.4310 - val_f1: 0.1459\n",
      "Epoch 1918/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2550 - f1: 0.7269 - val_loss: 0.4352 - val_f1: 0.1454\n",
      "Epoch 1919/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2558 - f1: 0.7215 - val_loss: 0.4330 - val_f1: 0.1455\n",
      "Epoch 1920/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2565 - f1: 0.7274 - val_loss: 0.4287 - val_f1: 0.1448\n",
      "Epoch 1921/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2577 - f1: 0.7198 - val_loss: 0.4301 - val_f1: 0.1451\n",
      "Epoch 1922/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2584 - f1: 0.7188 - val_loss: 0.4321 - val_f1: 0.1451\n",
      "Epoch 1923/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2581 - f1: 0.7223 - val_loss: 0.4297 - val_f1: 0.1451\n",
      "Epoch 1924/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2576 - f1: 0.7177 - val_loss: 0.4319 - val_f1: 0.1453\n",
      "Epoch 1925/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2581 - f1: 0.7227 - val_loss: 0.4355 - val_f1: 0.1459\n",
      "Epoch 1926/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2581 - f1: 0.7222 - val_loss: 0.4306 - val_f1: 0.1458\n",
      "Epoch 1927/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2565 - f1: 0.7192 - val_loss: 0.4359 - val_f1: 0.1455\n",
      "Epoch 1928/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2578 - f1: 0.7233 - val_loss: 0.4378 - val_f1: 0.1455\n",
      "Epoch 1929/2000\n",
      "64440/64440 [==============================] - 2s 38us/step - loss: 0.2574 - f1: 0.7229 - val_loss: 0.4323 - val_f1: 0.1454\n",
      "Epoch 1930/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2601 - f1: 0.7201 - val_loss: 0.4306 - val_f1: 0.1449\n",
      "Epoch 1931/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2550 - f1: 0.7224 - val_loss: 0.4309 - val_f1: 0.1457\n",
      "Epoch 1932/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2559 - f1: 0.7237 - val_loss: 0.4362 - val_f1: 0.1457\n",
      "Epoch 1933/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2560 - f1: 0.7205 - val_loss: 0.4288 - val_f1: 0.1455\n",
      "Epoch 1934/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2580 - f1: 0.7252 - val_loss: 0.4274 - val_f1: 0.1451\n",
      "Epoch 1935/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2587 - f1: 0.7194 - val_loss: 0.4283 - val_f1: 0.1450\n",
      "Epoch 1936/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2570 - f1: 0.7196 - val_loss: 0.4321 - val_f1: 0.1456\n",
      "Epoch 1937/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2582 - f1: 0.7205 - val_loss: 0.4323 - val_f1: 0.1459\n",
      "Epoch 1938/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2559 - f1: 0.7215 - val_loss: 0.4361 - val_f1: 0.1449\n",
      "Epoch 1939/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2577 - f1: 0.7243 - val_loss: 0.4253 - val_f1: 0.1451\n",
      "Epoch 1940/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2569 - f1: 0.7234 - val_loss: 0.4325 - val_f1: 0.1453\n",
      "Epoch 1941/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2551 - f1: 0.7235 - val_loss: 0.4326 - val_f1: 0.1460\n",
      "Epoch 1942/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2553 - f1: 0.7242 - val_loss: 0.4303 - val_f1: 0.1448\n",
      "Epoch 1943/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2572 - f1: 0.7206 - val_loss: 0.4357 - val_f1: 0.1458\n",
      "Epoch 1944/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2577 - f1: 0.7192 - val_loss: 0.4326 - val_f1: 0.1455\n",
      "Epoch 1945/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2576 - f1: 0.7236 - val_loss: 0.4283 - val_f1: 0.1447\n",
      "Epoch 1946/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2566 - f1: 0.7185 - val_loss: 0.4356 - val_f1: 0.1460\n",
      "Epoch 1947/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2568 - f1: 0.7247 - val_loss: 0.4331 - val_f1: 0.1458\n",
      "Epoch 1948/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2562 - f1: 0.7236 - val_loss: 0.4352 - val_f1: 0.1453\n",
      "Epoch 1949/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2582 - f1: 0.7206 - val_loss: 0.4292 - val_f1: 0.1465\n",
      "Epoch 1950/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2572 - f1: 0.7151 - val_loss: 0.4333 - val_f1: 0.1456\n",
      "Epoch 1951/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2572 - f1: 0.7222 - val_loss: 0.4325 - val_f1: 0.1449\n",
      "Epoch 1952/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2583 - f1: 0.7233 - val_loss: 0.4286 - val_f1: 0.1451\n",
      "Epoch 1953/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2581 - f1: 0.7215 - val_loss: 0.4285 - val_f1: 0.1449\n",
      "Epoch 1954/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2599 - f1: 0.7173 - val_loss: 0.4343 - val_f1: 0.1459\n",
      "Epoch 1955/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2570 - f1: 0.7241 - val_loss: 0.4282 - val_f1: 0.1458\n",
      "Epoch 1956/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2568 - f1: 0.7209 - val_loss: 0.4354 - val_f1: 0.1460\n",
      "Epoch 1957/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2575 - f1: 0.7221 - val_loss: 0.4277 - val_f1: 0.1455\n",
      "Epoch 1958/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2561 - f1: 0.7227 - val_loss: 0.4321 - val_f1: 0.1463\n",
      "Epoch 1959/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2548 - f1: 0.7260 - val_loss: 0.4310 - val_f1: 0.1459\n",
      "Epoch 1960/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2542 - f1: 0.7267 - val_loss: 0.4327 - val_f1: 0.1453\n",
      "Epoch 1961/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2562 - f1: 0.7226 - val_loss: 0.4325 - val_f1: 0.1450\n",
      "Epoch 1962/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2580 - f1: 0.7180 - val_loss: 0.4301 - val_f1: 0.1459\n",
      "Epoch 1963/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2544 - f1: 0.7220 - val_loss: 0.4345 - val_f1: 0.1456\n",
      "Epoch 1964/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2573 - f1: 0.7229 - val_loss: 0.4317 - val_f1: 0.1458\n",
      "Epoch 1965/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2568 - f1: 0.7204 - val_loss: 0.4290 - val_f1: 0.1453\n",
      "Epoch 1966/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2556 - f1: 0.7239 - val_loss: 0.4345 - val_f1: 0.1451\n",
      "Epoch 1967/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2573 - f1: 0.7232 - val_loss: 0.4334 - val_f1: 0.1448\n",
      "Epoch 1968/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2554 - f1: 0.7260 - val_loss: 0.4370 - val_f1: 0.1453\n",
      "Epoch 1969/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2555 - f1: 0.7261 - val_loss: 0.4305 - val_f1: 0.1457\n",
      "Epoch 1970/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2576 - f1: 0.7224 - val_loss: 0.4263 - val_f1: 0.1452\n",
      "Epoch 1971/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2558 - f1: 0.7286 - val_loss: 0.4344 - val_f1: 0.1454\n",
      "Epoch 1972/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2563 - f1: 0.7241 - val_loss: 0.4311 - val_f1: 0.1456\n",
      "Epoch 1973/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2572 - f1: 0.7236 - val_loss: 0.4295 - val_f1: 0.1455\n",
      "Epoch 1974/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2565 - f1: 0.7279 - val_loss: 0.4334 - val_f1: 0.1452\n",
      "Epoch 1975/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2565 - f1: 0.7229 - val_loss: 0.4391 - val_f1: 0.1456\n",
      "Epoch 1976/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2564 - f1: 0.7211 - val_loss: 0.4318 - val_f1: 0.1463\n",
      "Epoch 1977/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2557 - f1: 0.7237 - val_loss: 0.4299 - val_f1: 0.1451\n",
      "Epoch 1978/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2581 - f1: 0.7217 - val_loss: 0.4324 - val_f1: 0.1454\n",
      "Epoch 1979/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2572 - f1: 0.7233 - val_loss: 0.4358 - val_f1: 0.1460\n",
      "Epoch 1980/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2572 - f1: 0.7273 - val_loss: 0.4352 - val_f1: 0.1459\n",
      "Epoch 1981/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2562 - f1: 0.7233 - val_loss: 0.4355 - val_f1: 0.1461\n",
      "Epoch 1982/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2557 - f1: 0.7216 - val_loss: 0.4371 - val_f1: 0.1458\n",
      "Epoch 1983/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2578 - f1: 0.7212 - val_loss: 0.4345 - val_f1: 0.1457\n",
      "Epoch 1984/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2542 - f1: 0.7281 - val_loss: 0.4350 - val_f1: 0.1464\n",
      "Epoch 1985/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2565 - f1: 0.7237 - val_loss: 0.4342 - val_f1: 0.1453\n",
      "Epoch 1986/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2583 - f1: 0.7191 - val_loss: 0.4312 - val_f1: 0.1459\n",
      "Epoch 1987/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2574 - f1: 0.7203 - val_loss: 0.4376 - val_f1: 0.1459\n",
      "Epoch 1988/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2551 - f1: 0.7242 - val_loss: 0.4345 - val_f1: 0.1451\n",
      "Epoch 1989/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.2583 - f1: 0.7166 - val_loss: 0.4258 - val_f1: 0.1456\n",
      "Epoch 1990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2572 - f1: 0.7226 - val_loss: 0.4382 - val_f1: 0.1452\n",
      "Epoch 1991/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2562 - f1: 0.7255 - val_loss: 0.4370 - val_f1: 0.1459\n",
      "Epoch 1992/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2550 - f1: 0.7272 - val_loss: 0.4380 - val_f1: 0.1465\n",
      "Epoch 1993/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2557 - f1: 0.7247 - val_loss: 0.4331 - val_f1: 0.1445\n",
      "Epoch 1994/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2575 - f1: 0.7204 - val_loss: 0.4329 - val_f1: 0.1456\n",
      "Epoch 1995/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2549 - f1: 0.7242 - val_loss: 0.4318 - val_f1: 0.1454\n",
      "Epoch 1996/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2568 - f1: 0.7246 - val_loss: 0.4332 - val_f1: 0.1456\n",
      "Epoch 1997/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2580 - f1: 0.7172 - val_loss: 0.4302 - val_f1: 0.1451\n",
      "Epoch 1998/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2570 - f1: 0.7218 - val_loss: 0.4297 - val_f1: 0.1462\n",
      "Epoch 1999/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2564 - f1: 0.7231 - val_loss: 0.4383 - val_f1: 0.1463\n",
      "Epoch 2000/2000\n",
      "64440/64440 [==============================] - 3s 41us/step - loss: 0.2556 - f1: 0.7235 - val_loss: 0.4344 - val_f1: 0.1460\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna2.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[10019   775]\n",
      " [ 1542  1473]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[9938  857]\n",
      " [1492 1523]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[49317  1055]\n",
      " [ 3491 10577]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna2.predict(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list3 = [100,100,1]\n",
    "activation_list3 = ['tanh', 'tanh', 'sigmoid']\n",
    "dropout_list3 = [0.3,0.3,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 30,301\n",
      "Trainable params: 30,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna3 = new_rna()\n",
    "rna3.build_model(data_shape,n_list3,activation_list3,dropout_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64440 samples, validate on 13810 samples\n",
      "Epoch 1/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.4062 - f1: 0.4813 - val_loss: 0.3700 - val_f1: 0.1433\n",
      "Epoch 2/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3747 - f1: 0.5386 - val_loss: 0.3668 - val_f1: 0.1420\n",
      "Epoch 3/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3713 - f1: 0.5335 - val_loss: 0.3681 - val_f1: 0.1432\n",
      "Epoch 4/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3678 - f1: 0.5384 - val_loss: 0.3673 - val_f1: 0.1454\n",
      "Epoch 5/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3662 - f1: 0.5451 - val_loss: 0.3670 - val_f1: 0.1410\n",
      "Epoch 6/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3668 - f1: 0.5462 - val_loss: 0.3672 - val_f1: 0.1428\n",
      "Epoch 7/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3651 - f1: 0.5492 - val_loss: 0.3676 - val_f1: 0.1427\n",
      "Epoch 8/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3651 - f1: 0.5506 - val_loss: 0.3668 - val_f1: 0.1415\n",
      "Epoch 9/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3636 - f1: 0.5489 - val_loss: 0.3673 - val_f1: 0.1451\n",
      "Epoch 10/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3642 - f1: 0.5525 - val_loss: 0.3678 - val_f1: 0.1462\n",
      "Epoch 11/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3626 - f1: 0.5527 - val_loss: 0.3666 - val_f1: 0.1442\n",
      "Epoch 12/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3628 - f1: 0.5519 - val_loss: 0.3680 - val_f1: 0.1465\n",
      "Epoch 13/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.3624 - f1: 0.55 - 3s 45us/step - loss: 0.3625 - f1: 0.5514 - val_loss: 0.3672 - val_f1: 0.1433\n",
      "Epoch 14/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3625 - f1: 0.5503 - val_loss: 0.3676 - val_f1: 0.1455\n",
      "Epoch 15/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3619 - f1: 0.5583 - val_loss: 0.3681 - val_f1: 0.1457\n",
      "Epoch 16/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3624 - f1: 0.5542 - val_loss: 0.3677 - val_f1: 0.1448\n",
      "Epoch 17/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3612 - f1: 0.5568 - val_loss: 0.3675 - val_f1: 0.1453\n",
      "Epoch 18/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3608 - f1: 0.5583 - val_loss: 0.3674 - val_f1: 0.1451\n",
      "Epoch 19/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3613 - f1: 0.5544 - val_loss: 0.3673 - val_f1: 0.1461\n",
      "Epoch 20/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3611 - f1: 0.5585 - val_loss: 0.3674 - val_f1: 0.1446\n",
      "Epoch 21/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3599 - f1: 0.5550 - val_loss: 0.3680 - val_f1: 0.1475\n",
      "Epoch 22/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3600 - f1: 0.5587 - val_loss: 0.3681 - val_f1: 0.1469\n",
      "Epoch 23/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3603 - f1: 0.5603 - val_loss: 0.3687 - val_f1: 0.1474\n",
      "Epoch 24/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3607 - f1: 0.5611 - val_loss: 0.3675 - val_f1: 0.1436\n",
      "Epoch 25/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3601 - f1: 0.5563 - val_loss: 0.3674 - val_f1: 0.1439\n",
      "Epoch 26/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3597 - f1: 0.5602 - val_loss: 0.3676 - val_f1: 0.1437\n",
      "Epoch 27/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3599 - f1: 0.5589 - val_loss: 0.3681 - val_f1: 0.1457\n",
      "Epoch 28/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3596 - f1: 0.5614 - val_loss: 0.3674 - val_f1: 0.1466\n",
      "Epoch 29/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3593 - f1: 0.5615 - val_loss: 0.3680 - val_f1: 0.1471\n",
      "Epoch 30/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3579 - f1: 0.5630 - val_loss: 0.3679 - val_f1: 0.1460\n",
      "Epoch 31/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3590 - f1: 0.5576 - val_loss: 0.3677 - val_f1: 0.1461\n",
      "Epoch 32/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3588 - f1: 0.5612 - val_loss: 0.3675 - val_f1: 0.1455\n",
      "Epoch 33/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3585 - f1: 0.5610 - val_loss: 0.3685 - val_f1: 0.1453\n",
      "Epoch 34/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3583 - f1: 0.5615 - val_loss: 0.3680 - val_f1: 0.1456\n",
      "Epoch 35/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3589 - f1: 0.5634 - val_loss: 0.3684 - val_f1: 0.1450\n",
      "Epoch 36/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3576 - f1: 0.5612 - val_loss: 0.3676 - val_f1: 0.1456\n",
      "Epoch 37/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3578 - f1: 0.5625 - val_loss: 0.3676 - val_f1: 0.1444\n",
      "Epoch 38/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3567 - f1: 0.5618 - val_loss: 0.3691 - val_f1: 0.1467\n",
      "Epoch 39/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3569 - f1: 0.5619 - val_loss: 0.3674 - val_f1: 0.1443\n",
      "Epoch 40/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3567 - f1: 0.5657 - val_loss: 0.3682 - val_f1: 0.1452\n",
      "Epoch 41/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3573 - f1: 0.5629 - val_loss: 0.3682 - val_f1: 0.1455\n",
      "Epoch 42/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3567 - f1: 0.5623 - val_loss: 0.3687 - val_f1: 0.1455\n",
      "Epoch 43/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3568 - f1: 0.5646 - val_loss: 0.3683 - val_f1: 0.1440\n",
      "Epoch 44/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3564 - f1: 0.5614 - val_loss: 0.3685 - val_f1: 0.1459\n",
      "Epoch 45/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3564 - f1: 0.5621 - val_loss: 0.3685 - val_f1: 0.1443\n",
      "Epoch 46/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3555 - f1: 0.5652 - val_loss: 0.3678 - val_f1: 0.1441\n",
      "Epoch 47/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3557 - f1: 0.5632 - val_loss: 0.3682 - val_f1: 0.1453\n",
      "Epoch 48/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3557 - f1: 0.5682 - val_loss: 0.3678 - val_f1: 0.1446\n",
      "Epoch 49/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3559 - f1: 0.5648 - val_loss: 0.3687 - val_f1: 0.1446\n",
      "Epoch 50/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3546 - f1: 0.5622 - val_loss: 0.3691 - val_f1: 0.1451\n",
      "Epoch 51/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3548 - f1: 0.5637 - val_loss: 0.3685 - val_f1: 0.1435\n",
      "Epoch 52/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3551 - f1: 0.5642 - val_loss: 0.3688 - val_f1: 0.1447\n",
      "Epoch 53/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3541 - f1: 0.5653 - val_loss: 0.3681 - val_f1: 0.1445\n",
      "Epoch 54/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3544 - f1: 0.5646 - val_loss: 0.3682 - val_f1: 0.1448\n",
      "Epoch 55/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3545 - f1: 0.5651 - val_loss: 0.3681 - val_f1: 0.1446\n",
      "Epoch 56/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3544 - f1: 0.5632 - val_loss: 0.3700 - val_f1: 0.1458\n",
      "Epoch 57/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3540 - f1: 0.5682 - val_loss: 0.3691 - val_f1: 0.1445\n",
      "Epoch 58/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3539 - f1: 0.5653 - val_loss: 0.3694 - val_f1: 0.1462\n",
      "Epoch 59/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3539 - f1: 0.5685 - val_loss: 0.3699 - val_f1: 0.1439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3529 - f1: 0.5654 - val_loss: 0.3688 - val_f1: 0.1443\n",
      "Epoch 61/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3535 - f1: 0.5678 - val_loss: 0.3684 - val_f1: 0.1420\n",
      "Epoch 62/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3530 - f1: 0.5610 - val_loss: 0.3685 - val_f1: 0.1447\n",
      "Epoch 63/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3527 - f1: 0.5711 - val_loss: 0.3681 - val_f1: 0.1431\n",
      "Epoch 64/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3517 - f1: 0.5689 - val_loss: 0.3688 - val_f1: 0.1441\n",
      "Epoch 65/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3525 - f1: 0.5696 - val_loss: 0.3684 - val_f1: 0.1439\n",
      "Epoch 66/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3522 - f1: 0.5651 - val_loss: 0.3690 - val_f1: 0.1446\n",
      "Epoch 67/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3522 - f1: 0.5649 - val_loss: 0.3693 - val_f1: 0.1451\n",
      "Epoch 68/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3521 - f1: 0.5686 - val_loss: 0.3686 - val_f1: 0.1429\n",
      "Epoch 69/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3511 - f1: 0.5671 - val_loss: 0.3697 - val_f1: 0.1440\n",
      "Epoch 70/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3513 - f1: 0.5680 - val_loss: 0.3696 - val_f1: 0.1435\n",
      "Epoch 71/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3508 - f1: 0.5673 - val_loss: 0.3695 - val_f1: 0.1440\n",
      "Epoch 72/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3502 - f1: 0.5726 - val_loss: 0.3703 - val_f1: 0.1443\n",
      "Epoch 73/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3506 - f1: 0.5667 - val_loss: 0.3694 - val_f1: 0.1453\n",
      "Epoch 74/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3507 - f1: 0.5655 - val_loss: 0.3686 - val_f1: 0.1436\n",
      "Epoch 75/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3491 - f1: 0.5716 - val_loss: 0.3687 - val_f1: 0.1446\n",
      "Epoch 76/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3491 - f1: 0.5659 - val_loss: 0.3701 - val_f1: 0.1444\n",
      "Epoch 77/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3499 - f1: 0.5665 - val_loss: 0.3696 - val_f1: 0.1440\n",
      "Epoch 78/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3489 - f1: 0.5673 - val_loss: 0.3701 - val_f1: 0.1441\n",
      "Epoch 79/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3483 - f1: 0.5734 - val_loss: 0.3701 - val_f1: 0.1440\n",
      "Epoch 80/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3486 - f1: 0.5688 - val_loss: 0.3689 - val_f1: 0.1431\n",
      "Epoch 81/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3489 - f1: 0.5700 - val_loss: 0.3691 - val_f1: 0.1440\n",
      "Epoch 82/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3484 - f1: 0.5711 - val_loss: 0.3684 - val_f1: 0.1436\n",
      "Epoch 83/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3482 - f1: 0.5692 - val_loss: 0.3689 - val_f1: 0.1428\n",
      "Epoch 84/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3481 - f1: 0.5717 - val_loss: 0.3709 - val_f1: 0.1454\n",
      "Epoch 85/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3469 - f1: 0.5758 - val_loss: 0.3693 - val_f1: 0.1442\n",
      "Epoch 86/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3474 - f1: 0.5710 - val_loss: 0.3710 - val_f1: 0.1437\n",
      "Epoch 87/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3467 - f1: 0.5759 - val_loss: 0.3696 - val_f1: 0.1433\n",
      "Epoch 88/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3464 - f1: 0.5726 - val_loss: 0.3693 - val_f1: 0.1441\n",
      "Epoch 89/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3464 - f1: 0.5698 - val_loss: 0.3700 - val_f1: 0.1429\n",
      "Epoch 90/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3462 - f1: 0.5704 - val_loss: 0.3704 - val_f1: 0.1446\n",
      "Epoch 91/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3458 - f1: 0.5783 - val_loss: 0.3695 - val_f1: 0.1432\n",
      "Epoch 92/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3453 - f1: 0.5735 - val_loss: 0.3708 - val_f1: 0.1445\n",
      "Epoch 93/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3457 - f1: 0.5760 - val_loss: 0.3712 - val_f1: 0.1442\n",
      "Epoch 94/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3448 - f1: 0.5749 - val_loss: 0.3704 - val_f1: 0.1433\n",
      "Epoch 95/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3448 - f1: 0.5781 - val_loss: 0.3714 - val_f1: 0.1440\n",
      "Epoch 96/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3449 - f1: 0.5746 - val_loss: 0.3707 - val_f1: 0.1442\n",
      "Epoch 97/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3434 - f1: 0.5765 - val_loss: 0.3717 - val_f1: 0.1437\n",
      "Epoch 98/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3439 - f1: 0.5768 - val_loss: 0.3712 - val_f1: 0.1440\n",
      "Epoch 99/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3439 - f1: 0.5734 - val_loss: 0.3711 - val_f1: 0.1432\n",
      "Epoch 100/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3435 - f1: 0.5802 - val_loss: 0.3709 - val_f1: 0.1448\n",
      "Epoch 101/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3438 - f1: 0.5741 - val_loss: 0.3724 - val_f1: 0.1437\n",
      "Epoch 102/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3432 - f1: 0.5791 - val_loss: 0.3714 - val_f1: 0.1436\n",
      "Epoch 103/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3423 - f1: 0.5789 - val_loss: 0.3702 - val_f1: 0.1430\n",
      "Epoch 104/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3422 - f1: 0.5787 - val_loss: 0.3719 - val_f1: 0.1433\n",
      "Epoch 105/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3430 - f1: 0.5787 - val_loss: 0.3731 - val_f1: 0.1442\n",
      "Epoch 106/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3422 - f1: 0.5820 - val_loss: 0.3702 - val_f1: 0.1411\n",
      "Epoch 107/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3414 - f1: 0.5806 - val_loss: 0.3705 - val_f1: 0.1434\n",
      "Epoch 108/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3409 - f1: 0.5800 - val_loss: 0.3728 - val_f1: 0.1437\n",
      "Epoch 109/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3412 - f1: 0.5784 - val_loss: 0.3712 - val_f1: 0.1436\n",
      "Epoch 110/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3411 - f1: 0.5860 - val_loss: 0.3722 - val_f1: 0.1428\n",
      "Epoch 111/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3401 - f1: 0.5813 - val_loss: 0.3712 - val_f1: 0.1444\n",
      "Epoch 112/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3397 - f1: 0.5866 - val_loss: 0.3719 - val_f1: 0.1421\n",
      "Epoch 113/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3400 - f1: 0.5795 - val_loss: 0.3708 - val_f1: 0.1430\n",
      "Epoch 114/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3390 - f1: 0.5823 - val_loss: 0.3721 - val_f1: 0.1439\n",
      "Epoch 115/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3386 - f1: 0.5866 - val_loss: 0.3733 - val_f1: 0.1425\n",
      "Epoch 116/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3394 - f1: 0.5837 - val_loss: 0.3721 - val_f1: 0.1434\n",
      "Epoch 117/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3365 - f1: 0.5887 - val_loss: 0.3717 - val_f1: 0.1440\n",
      "Epoch 118/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3376 - f1: 0.5847 - val_loss: 0.3735 - val_f1: 0.1444\n",
      "Epoch 119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3370 - f1: 0.5861 - val_loss: 0.3729 - val_f1: 0.1453\n",
      "Epoch 120/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3361 - f1: 0.5895 - val_loss: 0.3733 - val_f1: 0.1442\n",
      "Epoch 121/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3370 - f1: 0.5872 - val_loss: 0.3736 - val_f1: 0.1439\n",
      "Epoch 122/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3369 - f1: 0.5882 - val_loss: 0.3715 - val_f1: 0.1434\n",
      "Epoch 123/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3367 - f1: 0.5860 - val_loss: 0.3725 - val_f1: 0.1443\n",
      "Epoch 124/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3369 - f1: 0.5908 - val_loss: 0.3717 - val_f1: 0.1444\n",
      "Epoch 125/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3358 - f1: 0.5908 - val_loss: 0.3724 - val_f1: 0.1442\n",
      "Epoch 126/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3361 - f1: 0.5898 - val_loss: 0.3736 - val_f1: 0.1446\n",
      "Epoch 127/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3346 - f1: 0.5930 - val_loss: 0.3726 - val_f1: 0.1436\n",
      "Epoch 128/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3357 - f1: 0.5901 - val_loss: 0.3744 - val_f1: 0.1427\n",
      "Epoch 129/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3344 - f1: 0.5931 - val_loss: 0.3744 - val_f1: 0.1431\n",
      "Epoch 130/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3342 - f1: 0.5919 - val_loss: 0.3742 - val_f1: 0.1439\n",
      "Epoch 131/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3321 - f1: 0.5968 - val_loss: 0.3739 - val_f1: 0.1440\n",
      "Epoch 132/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3337 - f1: 0.5965 - val_loss: 0.3741 - val_f1: 0.1429\n",
      "Epoch 133/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3320 - f1: 0.5962 - val_loss: 0.3752 - val_f1: 0.1443\n",
      "Epoch 134/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3326 - f1: 0.5972 - val_loss: 0.3755 - val_f1: 0.1429\n",
      "Epoch 135/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3325 - f1: 0.5941 - val_loss: 0.3724 - val_f1: 0.1430\n",
      "Epoch 136/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3320 - f1: 0.5946 - val_loss: 0.3746 - val_f1: 0.1442\n",
      "Epoch 137/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3298 - f1: 0.6030 - val_loss: 0.3749 - val_f1: 0.1439\n",
      "Epoch 138/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3318 - f1: 0.5927 - val_loss: 0.3748 - val_f1: 0.1437\n",
      "Epoch 139/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3296 - f1: 0.6018 - val_loss: 0.3761 - val_f1: 0.1439\n",
      "Epoch 140/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3310 - f1: 0.5988 - val_loss: 0.3773 - val_f1: 0.1435\n",
      "Epoch 141/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3291 - f1: 0.6025 - val_loss: 0.3740 - val_f1: 0.1430\n",
      "Epoch 142/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3299 - f1: 0.6012 - val_loss: 0.3762 - val_f1: 0.1425\n",
      "Epoch 143/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3291 - f1: 0.6021 - val_loss: 0.3747 - val_f1: 0.1443\n",
      "Epoch 144/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3283 - f1: 0.6022 - val_loss: 0.3747 - val_f1: 0.1452\n",
      "Epoch 145/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3289 - f1: 0.6040 - val_loss: 0.3776 - val_f1: 0.1449\n",
      "Epoch 146/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3283 - f1: 0.6049 - val_loss: 0.3763 - val_f1: 0.1439\n",
      "Epoch 147/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3275 - f1: 0.6045 - val_loss: 0.3771 - val_f1: 0.1444\n",
      "Epoch 148/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3271 - f1: 0.6060 - val_loss: 0.3770 - val_f1: 0.1440\n",
      "Epoch 149/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3270 - f1: 0.6056 - val_loss: 0.3757 - val_f1: 0.1442\n",
      "Epoch 150/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3255 - f1: 0.6041 - val_loss: 0.3777 - val_f1: 0.1440\n",
      "Epoch 151/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3252 - f1: 0.6102 - val_loss: 0.3758 - val_f1: 0.1454\n",
      "Epoch 152/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3261 - f1: 0.6029 - val_loss: 0.3782 - val_f1: 0.1446\n",
      "Epoch 153/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3250 - f1: 0.6081 - val_loss: 0.3778 - val_f1: 0.1437\n",
      "Epoch 154/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3246 - f1: 0.6090 - val_loss: 0.3787 - val_f1: 0.1431\n",
      "Epoch 155/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3261 - f1: 0.6095 - val_loss: 0.3798 - val_f1: 0.1428\n",
      "Epoch 156/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3234 - f1: 0.6086 - val_loss: 0.3768 - val_f1: 0.1444\n",
      "Epoch 157/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3239 - f1: 0.6093 - val_loss: 0.3777 - val_f1: 0.1441\n",
      "Epoch 158/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3229 - f1: 0.6128 - val_loss: 0.3787 - val_f1: 0.1439\n",
      "Epoch 159/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3237 - f1: 0.6160 - val_loss: 0.3790 - val_f1: 0.1438\n",
      "Epoch 160/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3232 - f1: 0.6092 - val_loss: 0.3793 - val_f1: 0.1443\n",
      "Epoch 161/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3232 - f1: 0.6127 - val_loss: 0.3792 - val_f1: 0.1426\n",
      "Epoch 162/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3233 - f1: 0.6085 - val_loss: 0.3783 - val_f1: 0.1448\n",
      "Epoch 163/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3218 - f1: 0.6106 - val_loss: 0.3803 - val_f1: 0.1437\n",
      "Epoch 164/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3223 - f1: 0.6171 - val_loss: 0.3796 - val_f1: 0.1433\n",
      "Epoch 165/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3198 - f1: 0.6152 - val_loss: 0.3790 - val_f1: 0.1426\n",
      "Epoch 166/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3211 - f1: 0.6137 - val_loss: 0.3828 - val_f1: 0.1426\n",
      "Epoch 167/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3187 - f1: 0.6129 - val_loss: 0.3807 - val_f1: 0.1437\n",
      "Epoch 168/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3198 - f1: 0.6177 - val_loss: 0.3798 - val_f1: 0.1438\n",
      "Epoch 169/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3196 - f1: 0.6211 - val_loss: 0.3799 - val_f1: 0.1429\n",
      "Epoch 170/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3183 - f1: 0.6157 - val_loss: 0.3808 - val_f1: 0.1433\n",
      "Epoch 171/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3186 - f1: 0.6196 - val_loss: 0.3816 - val_f1: 0.1437\n",
      "Epoch 172/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3172 - f1: 0.6216 - val_loss: 0.3813 - val_f1: 0.1436\n",
      "Epoch 173/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3175 - f1: 0.6202 - val_loss: 0.3818 - val_f1: 0.1429\n",
      "Epoch 174/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3183 - f1: 0.6240 - val_loss: 0.3824 - val_f1: 0.1443\n",
      "Epoch 175/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3180 - f1: 0.6239 - val_loss: 0.3811 - val_f1: 0.1428\n",
      "Epoch 176/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3160 - f1: 0.6246 - val_loss: 0.3819 - val_f1: 0.1433\n",
      "Epoch 177/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3176 - f1: 0.6182 - val_loss: 0.3809 - val_f1: 0.1430\n",
      "Epoch 178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3163 - f1: 0.6232 - val_loss: 0.3812 - val_f1: 0.1421\n",
      "Epoch 179/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3156 - f1: 0.6219 - val_loss: 0.3825 - val_f1: 0.1439\n",
      "Epoch 180/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3159 - f1: 0.6281 - val_loss: 0.3818 - val_f1: 0.1419\n",
      "Epoch 181/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3154 - f1: 0.6287 - val_loss: 0.3800 - val_f1: 0.1452\n",
      "Epoch 182/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3136 - f1: 0.6296 - val_loss: 0.3819 - val_f1: 0.1435\n",
      "Epoch 183/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3138 - f1: 0.6276 - val_loss: 0.3829 - val_f1: 0.1429\n",
      "Epoch 184/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3143 - f1: 0.6277 - val_loss: 0.3836 - val_f1: 0.1439\n",
      "Epoch 185/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3138 - f1: 0.6252 - val_loss: 0.3854 - val_f1: 0.1424\n",
      "Epoch 186/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3137 - f1: 0.6267 - val_loss: 0.3859 - val_f1: 0.1425\n",
      "Epoch 187/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3133 - f1: 0.6307 - val_loss: 0.3855 - val_f1: 0.1426\n",
      "Epoch 188/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3143 - f1: 0.6280 - val_loss: 0.3833 - val_f1: 0.1428\n",
      "Epoch 189/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3118 - f1: 0.6295 - val_loss: 0.3841 - val_f1: 0.1419\n",
      "Epoch 190/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3098 - f1: 0.6327 - val_loss: 0.3862 - val_f1: 0.1417\n",
      "Epoch 191/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3108 - f1: 0.6324 - val_loss: 0.3858 - val_f1: 0.1427\n",
      "Epoch 192/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3103 - f1: 0.6325 - val_loss: 0.3896 - val_f1: 0.1422\n",
      "Epoch 193/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.3099 - f1: 0.6356 - val_loss: 0.3858 - val_f1: 0.1424\n",
      "Epoch 194/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3092 - f1: 0.6340 - val_loss: 0.3872 - val_f1: 0.1431\n",
      "Epoch 195/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3090 - f1: 0.6364 - val_loss: 0.3846 - val_f1: 0.1429\n",
      "Epoch 196/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3087 - f1: 0.6374 - val_loss: 0.3834 - val_f1: 0.1431\n",
      "Epoch 197/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3089 - f1: 0.6360 - val_loss: 0.3848 - val_f1: 0.1442\n",
      "Epoch 198/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3084 - f1: 0.6385 - val_loss: 0.3866 - val_f1: 0.1420\n",
      "Epoch 199/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3063 - f1: 0.6397 - val_loss: 0.3917 - val_f1: 0.1424\n",
      "Epoch 200/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3084 - f1: 0.6389 - val_loss: 0.3865 - val_f1: 0.1415\n",
      "Epoch 201/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3080 - f1: 0.6386 - val_loss: 0.3873 - val_f1: 0.1439\n",
      "Epoch 202/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3072 - f1: 0.6388 - val_loss: 0.3879 - val_f1: 0.1421\n",
      "Epoch 203/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3057 - f1: 0.6384 - val_loss: 0.3885 - val_f1: 0.1411\n",
      "Epoch 204/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3058 - f1: 0.6409 - val_loss: 0.3869 - val_f1: 0.1428\n",
      "Epoch 205/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3067 - f1: 0.6418 - val_loss: 0.3903 - val_f1: 0.1424\n",
      "Epoch 206/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3062 - f1: 0.6440 - val_loss: 0.3881 - val_f1: 0.1410\n",
      "Epoch 207/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3062 - f1: 0.6398 - val_loss: 0.3866 - val_f1: 0.1427\n",
      "Epoch 208/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3070 - f1: 0.6404 - val_loss: 0.3871 - val_f1: 0.1422\n",
      "Epoch 209/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3046 - f1: 0.6427 - val_loss: 0.3888 - val_f1: 0.1446\n",
      "Epoch 210/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3045 - f1: 0.6428 - val_loss: 0.3908 - val_f1: 0.1443\n",
      "Epoch 211/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3040 - f1: 0.6472 - val_loss: 0.3904 - val_f1: 0.1431\n",
      "Epoch 212/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3027 - f1: 0.6448 - val_loss: 0.3907 - val_f1: 0.1441\n",
      "Epoch 213/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3029 - f1: 0.6473 - val_loss: 0.3903 - val_f1: 0.1437\n",
      "Epoch 214/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3026 - f1: 0.6458 - val_loss: 0.3939 - val_f1: 0.1418\n",
      "Epoch 215/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3026 - f1: 0.6465 - val_loss: 0.3903 - val_f1: 0.1424\n",
      "Epoch 216/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3024 - f1: 0.6472 - val_loss: 0.3889 - val_f1: 0.1427\n",
      "Epoch 217/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2996 - f1: 0.6512 - val_loss: 0.3911 - val_f1: 0.1418\n",
      "Epoch 218/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3013 - f1: 0.6513 - val_loss: 0.3935 - val_f1: 0.1417\n",
      "Epoch 219/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3046 - f1: 0.6462 - val_loss: 0.3923 - val_f1: 0.1405\n",
      "Epoch 220/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3007 - f1: 0.6468 - val_loss: 0.3890 - val_f1: 0.1419\n",
      "Epoch 221/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3008 - f1: 0.6527 - val_loss: 0.3922 - val_f1: 0.1420\n",
      "Epoch 222/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3011 - f1: 0.6516 - val_loss: 0.3915 - val_f1: 0.1417\n",
      "Epoch 223/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3002 - f1: 0.6525 - val_loss: 0.3938 - val_f1: 0.1422\n",
      "Epoch 224/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3006 - f1: 0.6521 - val_loss: 0.3913 - val_f1: 0.1422\n",
      "Epoch 225/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2987 - f1: 0.6519 - val_loss: 0.3952 - val_f1: 0.1409\n",
      "Epoch 226/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2988 - f1: 0.6496 - val_loss: 0.3943 - val_f1: 0.1421\n",
      "Epoch 227/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2985 - f1: 0.6480 - val_loss: 0.3909 - val_f1: 0.1429\n",
      "Epoch 228/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2960 - f1: 0.6592 - val_loss: 0.3982 - val_f1: 0.1415\n",
      "Epoch 229/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2995 - f1: 0.6528 - val_loss: 0.3949 - val_f1: 0.1410\n",
      "Epoch 230/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2962 - f1: 0.6600 - val_loss: 0.3929 - val_f1: 0.1413\n",
      "Epoch 231/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2971 - f1: 0.6557 - val_loss: 0.3917 - val_f1: 0.1427\n",
      "Epoch 232/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2961 - f1: 0.6594 - val_loss: 0.3936 - val_f1: 0.1418\n",
      "Epoch 233/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2968 - f1: 0.6577 - val_loss: 0.3931 - val_f1: 0.1413\n",
      "Epoch 234/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2944 - f1: 0.6583 - val_loss: 0.3985 - val_f1: 0.1403\n",
      "Epoch 235/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2951 - f1: 0.6607 - val_loss: 0.3922 - val_f1: 0.1417\n",
      "Epoch 236/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2970 - f1: 0.6596 - val_loss: 0.3925 - val_f1: 0.1433\n",
      "Epoch 237/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2959 - f1: 0.6570 - val_loss: 0.3939 - val_f1: 0.1428\n",
      "Epoch 238/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2958 - f1: 0.6572 - val_loss: 0.3941 - val_f1: 0.1424\n",
      "Epoch 239/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2935 - f1: 0.6604 - val_loss: 0.3910 - val_f1: 0.1434\n",
      "Epoch 240/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2945 - f1: 0.6558 - val_loss: 0.3967 - val_f1: 0.1417\n",
      "Epoch 241/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2942 - f1: 0.6628 - val_loss: 0.4008 - val_f1: 0.1398\n",
      "Epoch 242/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2917 - f1: 0.6635 - val_loss: 0.3944 - val_f1: 0.1421\n",
      "Epoch 243/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2938 - f1: 0.6613 - val_loss: 0.3998 - val_f1: 0.1415\n",
      "Epoch 244/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2929 - f1: 0.6619 - val_loss: 0.3975 - val_f1: 0.1410\n",
      "Epoch 245/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2952 - f1: 0.6627 - val_loss: 0.3944 - val_f1: 0.1412\n",
      "Epoch 246/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2918 - f1: 0.6618 - val_loss: 0.3947 - val_f1: 0.1429\n",
      "Epoch 247/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2916 - f1: 0.6732 - val_loss: 0.3935 - val_f1: 0.1422\n",
      "Epoch 248/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2906 - f1: 0.6682 - val_loss: 0.4012 - val_f1: 0.1410\n",
      "Epoch 249/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2911 - f1: 0.6631 - val_loss: 0.3958 - val_f1: 0.1409\n",
      "Epoch 250/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2927 - f1: 0.6640 - val_loss: 0.3977 - val_f1: 0.1417\n",
      "Epoch 251/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2909 - f1: 0.6623 - val_loss: 0.3959 - val_f1: 0.1424\n",
      "Epoch 252/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2909 - f1: 0.6628 - val_loss: 0.3960 - val_f1: 0.1423\n",
      "Epoch 253/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2896 - f1: 0.6623 - val_loss: 0.3972 - val_f1: 0.1418\n",
      "Epoch 254/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2914 - f1: 0.6566 - val_loss: 0.3980 - val_f1: 0.1418\n",
      "Epoch 255/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2894 - f1: 0.6657 - val_loss: 0.3959 - val_f1: 0.1424\n",
      "Epoch 256/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2904 - f1: 0.6673 - val_loss: 0.3981 - val_f1: 0.1409\n",
      "Epoch 257/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2888 - f1: 0.6680 - val_loss: 0.3972 - val_f1: 0.1413\n",
      "Epoch 258/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2898 - f1: 0.6678 - val_loss: 0.3984 - val_f1: 0.1413\n",
      "Epoch 259/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2899 - f1: 0.6668 - val_loss: 0.3986 - val_f1: 0.1415\n",
      "Epoch 260/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2875 - f1: 0.6722 - val_loss: 0.4005 - val_f1: 0.1418\n",
      "Epoch 261/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2870 - f1: 0.6702 - val_loss: 0.4023 - val_f1: 0.1398\n",
      "Epoch 262/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2878 - f1: 0.6702 - val_loss: 0.4031 - val_f1: 0.1407\n",
      "Epoch 263/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2875 - f1: 0.6730 - val_loss: 0.4001 - val_f1: 0.1412\n",
      "Epoch 264/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2869 - f1: 0.6742 - val_loss: 0.3963 - val_f1: 0.1409\n",
      "Epoch 265/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2881 - f1: 0.6691 - val_loss: 0.3993 - val_f1: 0.1401\n",
      "Epoch 266/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2865 - f1: 0.6738 - val_loss: 0.4014 - val_f1: 0.1411\n",
      "Epoch 267/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2853 - f1: 0.6731 - val_loss: 0.3985 - val_f1: 0.1429\n",
      "Epoch 268/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2861 - f1: 0.6743 - val_loss: 0.3997 - val_f1: 0.1424\n",
      "Epoch 269/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2840 - f1: 0.6798 - val_loss: 0.4009 - val_f1: 0.1418\n",
      "Epoch 270/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2852 - f1: 0.6756 - val_loss: 0.4007 - val_f1: 0.1413\n",
      "Epoch 271/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2850 - f1: 0.6760 - val_loss: 0.3982 - val_f1: 0.1417\n",
      "Epoch 272/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2838 - f1: 0.6790 - val_loss: 0.4065 - val_f1: 0.1414\n",
      "Epoch 273/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2827 - f1: 0.6805 - val_loss: 0.4034 - val_f1: 0.1402\n",
      "Epoch 274/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2845 - f1: 0.6733 - val_loss: 0.4010 - val_f1: 0.1401\n",
      "Epoch 275/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2858 - f1: 0.6685 - val_loss: 0.4018 - val_f1: 0.1408\n",
      "Epoch 276/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2822 - f1: 0.6765 - val_loss: 0.4074 - val_f1: 0.1402\n",
      "Epoch 277/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2833 - f1: 0.6757 - val_loss: 0.4017 - val_f1: 0.1406\n",
      "Epoch 278/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2844 - f1: 0.6714 - val_loss: 0.4034 - val_f1: 0.1408\n",
      "Epoch 279/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2819 - f1: 0.6795 - val_loss: 0.4019 - val_f1: 0.1420\n",
      "Epoch 280/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2824 - f1: 0.6799 - val_loss: 0.4015 - val_f1: 0.1403\n",
      "Epoch 281/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2807 - f1: 0.6802 - val_loss: 0.4051 - val_f1: 0.1387\n",
      "Epoch 282/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2822 - f1: 0.6796 - val_loss: 0.4044 - val_f1: 0.1419\n",
      "Epoch 283/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2807 - f1: 0.6803 - val_loss: 0.4052 - val_f1: 0.1402\n",
      "Epoch 284/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2805 - f1: 0.6795 - val_loss: 0.4042 - val_f1: 0.1410\n",
      "Epoch 285/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2815 - f1: 0.6832 - val_loss: 0.4043 - val_f1: 0.1405\n",
      "Epoch 286/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2790 - f1: 0.6863 - val_loss: 0.4041 - val_f1: 0.1405\n",
      "Epoch 287/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2792 - f1: 0.6846 - val_loss: 0.4079 - val_f1: 0.1402\n",
      "Epoch 288/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2804 - f1: 0.6825 - val_loss: 0.4067 - val_f1: 0.1409\n",
      "Epoch 289/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2814 - f1: 0.6843 - val_loss: 0.4084 - val_f1: 0.1390\n",
      "Epoch 290/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2773 - f1: 0.6830 - val_loss: 0.4080 - val_f1: 0.1396\n",
      "Epoch 291/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2789 - f1: 0.6848 - val_loss: 0.4060 - val_f1: 0.1398\n",
      "Epoch 292/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2796 - f1: 0.6821 - val_loss: 0.4077 - val_f1: 0.1395\n",
      "Epoch 293/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2773 - f1: 0.6859 - val_loss: 0.4081 - val_f1: 0.1389\n",
      "Epoch 294/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2779 - f1: 0.6804 - val_loss: 0.4053 - val_f1: 0.1417\n",
      "Epoch 295/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2774 - f1: 0.6834 - val_loss: 0.4099 - val_f1: 0.1395\n",
      "Epoch 296/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2780 - f1: 0.6830 - val_loss: 0.4033 - val_f1: 0.1404\n",
      "Epoch 297/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2777 - f1: 0.6850 - val_loss: 0.4064 - val_f1: 0.1405\n",
      "Epoch 298/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2774 - f1: 0.6907 - val_loss: 0.4081 - val_f1: 0.1398\n",
      "Epoch 299/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2781 - f1: 0.6890 - val_loss: 0.4064 - val_f1: 0.1417\n",
      "Epoch 300/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2780 - f1: 0.6845 - val_loss: 0.4059 - val_f1: 0.1401\n",
      "Epoch 301/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2769 - f1: 0.6850 - val_loss: 0.4092 - val_f1: 0.1405\n",
      "Epoch 302/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2767 - f1: 0.6846 - val_loss: 0.4075 - val_f1: 0.1397\n",
      "Epoch 303/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2758 - f1: 0.6883 - val_loss: 0.4112 - val_f1: 0.1393\n",
      "Epoch 304/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2745 - f1: 0.6927 - val_loss: 0.4095 - val_f1: 0.1386\n",
      "Epoch 305/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2748 - f1: 0.6888 - val_loss: 0.4075 - val_f1: 0.1405\n",
      "Epoch 306/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2762 - f1: 0.6876 - val_loss: 0.4083 - val_f1: 0.1410\n",
      "Epoch 307/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2714 - f1: 0.6966 - val_loss: 0.4085 - val_f1: 0.1404\n",
      "Epoch 308/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2744 - f1: 0.6930 - val_loss: 0.4100 - val_f1: 0.1392\n",
      "Epoch 309/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2731 - f1: 0.6977 - val_loss: 0.4088 - val_f1: 0.1399\n",
      "Epoch 310/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2708 - f1: 0.6923 - val_loss: 0.4118 - val_f1: 0.1396\n",
      "Epoch 311/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2740 - f1: 0.6911 - val_loss: 0.4100 - val_f1: 0.1397\n",
      "Epoch 312/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2734 - f1: 0.6906 - val_loss: 0.4073 - val_f1: 0.1398\n",
      "Epoch 313/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2746 - f1: 0.6891 - val_loss: 0.4055 - val_f1: 0.1402\n",
      "Epoch 314/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2723 - f1: 0.6952 - val_loss: 0.4122 - val_f1: 0.1387\n",
      "Epoch 315/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2748 - f1: 0.6850 - val_loss: 0.4100 - val_f1: 0.1406\n",
      "Epoch 316/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2724 - f1: 0.6916 - val_loss: 0.4108 - val_f1: 0.1406\n",
      "Epoch 317/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2746 - f1: 0.6902 - val_loss: 0.4089 - val_f1: 0.1409\n",
      "Epoch 318/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2722 - f1: 0.6967 - val_loss: 0.4168 - val_f1: 0.1394\n",
      "Epoch 319/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2729 - f1: 0.6928 - val_loss: 0.4150 - val_f1: 0.1378\n",
      "Epoch 320/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2707 - f1: 0.6943 - val_loss: 0.4108 - val_f1: 0.1406\n",
      "Epoch 321/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2708 - f1: 0.6981 - val_loss: 0.4106 - val_f1: 0.1413\n",
      "Epoch 322/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2701 - f1: 0.6982 - val_loss: 0.4099 - val_f1: 0.1416\n",
      "Epoch 323/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2709 - f1: 0.6959 - val_loss: 0.4137 - val_f1: 0.1393\n",
      "Epoch 324/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2682 - f1: 0.7033 - val_loss: 0.4129 - val_f1: 0.1407\n",
      "Epoch 325/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2725 - f1: 0.6958 - val_loss: 0.4118 - val_f1: 0.1404\n",
      "Epoch 326/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2723 - f1: 0.6926 - val_loss: 0.4127 - val_f1: 0.1390\n",
      "Epoch 327/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2686 - f1: 0.6964 - val_loss: 0.4164 - val_f1: 0.1389\n",
      "Epoch 328/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2685 - f1: 0.7036 - val_loss: 0.4140 - val_f1: 0.1396\n",
      "Epoch 329/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2711 - f1: 0.6920 - val_loss: 0.4118 - val_f1: 0.1403\n",
      "Epoch 330/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2708 - f1: 0.6976 - val_loss: 0.4194 - val_f1: 0.1386\n",
      "Epoch 331/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2693 - f1: 0.7023 - val_loss: 0.4115 - val_f1: 0.1415\n",
      "Epoch 332/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2695 - f1: 0.7021 - val_loss: 0.4101 - val_f1: 0.1400\n",
      "Epoch 333/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2678 - f1: 0.6981 - val_loss: 0.4182 - val_f1: 0.1391\n",
      "Epoch 334/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2687 - f1: 0.6986 - val_loss: 0.4148 - val_f1: 0.1401\n",
      "Epoch 335/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2671 - f1: 0.7022 - val_loss: 0.4176 - val_f1: 0.1398\n",
      "Epoch 336/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2665 - f1: 0.7045 - val_loss: 0.4141 - val_f1: 0.1406\n",
      "Epoch 337/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2686 - f1: 0.7009 - val_loss: 0.4159 - val_f1: 0.1383\n",
      "Epoch 338/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2681 - f1: 0.6961 - val_loss: 0.4116 - val_f1: 0.1403\n",
      "Epoch 339/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2654 - f1: 0.7037 - val_loss: 0.4171 - val_f1: 0.1394\n",
      "Epoch 340/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2676 - f1: 0.7025 - val_loss: 0.4172 - val_f1: 0.1405\n",
      "Epoch 341/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2676 - f1: 0.7040 - val_loss: 0.4149 - val_f1: 0.1394\n",
      "Epoch 342/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2653 - f1: 0.7017 - val_loss: 0.4204 - val_f1: 0.1388\n",
      "Epoch 343/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2660 - f1: 0.7031 - val_loss: 0.4170 - val_f1: 0.1394\n",
      "Epoch 344/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2640 - f1: 0.7045 - val_loss: 0.4191 - val_f1: 0.1398\n",
      "Epoch 345/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2651 - f1: 0.7057 - val_loss: 0.4128 - val_f1: 0.1398\n",
      "Epoch 346/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2660 - f1: 0.7026 - val_loss: 0.4153 - val_f1: 0.1393\n",
      "Epoch 347/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2659 - f1: 0.7006 - val_loss: 0.4177 - val_f1: 0.1384\n",
      "Epoch 348/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2649 - f1: 0.7022 - val_loss: 0.4168 - val_f1: 0.1387\n",
      "Epoch 349/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2650 - f1: 0.7050 - val_loss: 0.4174 - val_f1: 0.1398\n",
      "Epoch 350/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2655 - f1: 0.7055 - val_loss: 0.4147 - val_f1: 0.1403\n",
      "Epoch 351/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2653 - f1: 0.7026 - val_loss: 0.4203 - val_f1: 0.1388\n",
      "Epoch 352/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2651 - f1: 0.7039 - val_loss: 0.4191 - val_f1: 0.1381\n",
      "Epoch 353/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2632 - f1: 0.7070 - val_loss: 0.4134 - val_f1: 0.1405\n",
      "Epoch 354/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2637 - f1: 0.7045 - val_loss: 0.4176 - val_f1: 0.1392\n",
      "Epoch 355/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2640 - f1: 0.7089 - val_loss: 0.4192 - val_f1: 0.1390\n",
      "Epoch 356/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2632 - f1: 0.7067 - val_loss: 0.4180 - val_f1: 0.1388\n",
      "Epoch 357/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2609 - f1: 0.7128 - val_loss: 0.4174 - val_f1: 0.1394\n",
      "Epoch 358/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2639 - f1: 0.7079 - val_loss: 0.4148 - val_f1: 0.1404\n",
      "Epoch 359/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2638 - f1: 0.7059 - val_loss: 0.4203 - val_f1: 0.1389\n",
      "Epoch 360/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2612 - f1: 0.7131 - val_loss: 0.4207 - val_f1: 0.1383\n",
      "Epoch 361/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2617 - f1: 0.7056 - val_loss: 0.4244 - val_f1: 0.1390\n",
      "Epoch 362/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2616 - f1: 0.7096 - val_loss: 0.4202 - val_f1: 0.1386\n",
      "Epoch 363/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2621 - f1: 0.7061 - val_loss: 0.4208 - val_f1: 0.1389\n",
      "Epoch 364/2000\n",
      "64440/64440 [==============================] - 4s 66us/step - loss: 0.2610 - f1: 0.7097 - val_loss: 0.4217 - val_f1: 0.1379\n",
      "Epoch 365/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2600 - f1: 0.7087 - val_loss: 0.4194 - val_f1: 0.1400\n",
      "Epoch 366/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2610 - f1: 0.7124 - val_loss: 0.4220 - val_f1: 0.1391\n",
      "Epoch 367/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2595 - f1: 0.7100 - val_loss: 0.4242 - val_f1: 0.1396\n",
      "Epoch 368/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2608 - f1: 0.7092 - val_loss: 0.4211 - val_f1: 0.1388\n",
      "Epoch 369/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2599 - f1: 0.7100 - val_loss: 0.4236 - val_f1: 0.1377\n",
      "Epoch 370/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2606 - f1: 0.7102 - val_loss: 0.4198 - val_f1: 0.1388\n",
      "Epoch 371/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2615 - f1: 0.7078 - val_loss: 0.4238 - val_f1: 0.1389\n",
      "Epoch 372/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2587 - f1: 0.7145 - val_loss: 0.4248 - val_f1: 0.1396\n",
      "Epoch 373/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2619 - f1: 0.7078 - val_loss: 0.4243 - val_f1: 0.1389\n",
      "Epoch 374/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2595 - f1: 0.7108 - val_loss: 0.4247 - val_f1: 0.1382\n",
      "Epoch 375/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2601 - f1: 0.7058 - val_loss: 0.4253 - val_f1: 0.1389\n",
      "Epoch 376/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2593 - f1: 0.7120 - val_loss: 0.4224 - val_f1: 0.1396\n",
      "Epoch 377/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2588 - f1: 0.7136 - val_loss: 0.4190 - val_f1: 0.1398\n",
      "Epoch 378/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2596 - f1: 0.7111 - val_loss: 0.4165 - val_f1: 0.1400\n",
      "Epoch 379/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2574 - f1: 0.7153 - val_loss: 0.4242 - val_f1: 0.1399\n",
      "Epoch 380/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2553 - f1: 0.7133 - val_loss: 0.4287 - val_f1: 0.1382\n",
      "Epoch 381/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2528 - f1: 0.7167 - val_loss: 0.4280 - val_f1: 0.1380\n",
      "Epoch 382/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2586 - f1: 0.7085 - val_loss: 0.4226 - val_f1: 0.1384\n",
      "Epoch 383/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2557 - f1: 0.7182 - val_loss: 0.4247 - val_f1: 0.1376\n",
      "Epoch 384/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2583 - f1: 0.7128 - val_loss: 0.4253 - val_f1: 0.1386\n",
      "Epoch 385/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2575 - f1: 0.7053 - val_loss: 0.4265 - val_f1: 0.1390\n",
      "Epoch 386/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2578 - f1: 0.7121 - val_loss: 0.4267 - val_f1: 0.1391\n",
      "Epoch 387/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2566 - f1: 0.7161 - val_loss: 0.4219 - val_f1: 0.1384\n",
      "Epoch 388/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2561 - f1: 0.7109 - val_loss: 0.4238 - val_f1: 0.1404\n",
      "Epoch 389/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2552 - f1: 0.7181 - val_loss: 0.4257 - val_f1: 0.1393\n",
      "Epoch 390/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2565 - f1: 0.7142 - val_loss: 0.4258 - val_f1: 0.1404\n",
      "Epoch 391/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2552 - f1: 0.7189 - val_loss: 0.4259 - val_f1: 0.1396\n",
      "Epoch 392/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2559 - f1: 0.7161 - val_loss: 0.4256 - val_f1: 0.1378\n",
      "Epoch 393/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2563 - f1: 0.7135 - val_loss: 0.4237 - val_f1: 0.1400\n",
      "Epoch 394/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2563 - f1: 0.7184 - val_loss: 0.4281 - val_f1: 0.1380\n",
      "Epoch 395/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2555 - f1: 0.7158 - val_loss: 0.4235 - val_f1: 0.1396\n",
      "Epoch 396/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2539 - f1: 0.7176 - val_loss: 0.4274 - val_f1: 0.1388\n",
      "Epoch 397/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2534 - f1: 0.7215 - val_loss: 0.4257 - val_f1: 0.1390\n",
      "Epoch 398/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2549 - f1: 0.7154 - val_loss: 0.4255 - val_f1: 0.1393\n",
      "Epoch 399/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2548 - f1: 0.7165 - val_loss: 0.4229 - val_f1: 0.1388\n",
      "Epoch 400/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2534 - f1: 0.7208 - val_loss: 0.4247 - val_f1: 0.1405\n",
      "Epoch 401/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2557 - f1: 0.7159 - val_loss: 0.4248 - val_f1: 0.1391\n",
      "Epoch 402/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2550 - f1: 0.7184 - val_loss: 0.4225 - val_f1: 0.1395\n",
      "Epoch 403/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2547 - f1: 0.7156 - val_loss: 0.4215 - val_f1: 0.1399\n",
      "Epoch 404/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2523 - f1: 0.7225 - val_loss: 0.4361 - val_f1: 0.1380\n",
      "Epoch 405/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2547 - f1: 0.7202 - val_loss: 0.4294 - val_f1: 0.1384\n",
      "Epoch 406/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2533 - f1: 0.7218 - val_loss: 0.4276 - val_f1: 0.1392\n",
      "Epoch 407/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2535 - f1: 0.7227 - val_loss: 0.4318 - val_f1: 0.1386\n",
      "Epoch 408/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2543 - f1: 0.7174 - val_loss: 0.4224 - val_f1: 0.1399\n",
      "Epoch 409/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2501 - f1: 0.7232 - val_loss: 0.4318 - val_f1: 0.1388\n",
      "Epoch 410/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2519 - f1: 0.7194 - val_loss: 0.4333 - val_f1: 0.1397\n",
      "Epoch 411/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2540 - f1: 0.7183 - val_loss: 0.4281 - val_f1: 0.1382\n",
      "Epoch 412/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2547 - f1: 0.7201 - val_loss: 0.4301 - val_f1: 0.1380\n",
      "Epoch 413/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2506 - f1: 0.7242 - val_loss: 0.4327 - val_f1: 0.1386\n",
      "Epoch 414/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2504 - f1: 0.7256 - val_loss: 0.4273 - val_f1: 0.1383\n",
      "Epoch 415/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2532 - f1: 0.7191 - val_loss: 0.4305 - val_f1: 0.1382\n",
      "Epoch 416/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2522 - f1: 0.7205 - val_loss: 0.4316 - val_f1: 0.1380\n",
      "Epoch 417/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2528 - f1: 0.7237 - val_loss: 0.4302 - val_f1: 0.1380\n",
      "Epoch 418/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2526 - f1: 0.7192 - val_loss: 0.4295 - val_f1: 0.1392\n",
      "Epoch 419/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2506 - f1: 0.7266 - val_loss: 0.4302 - val_f1: 0.1389\n",
      "Epoch 420/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2506 - f1: 0.7228 - val_loss: 0.4304 - val_f1: 0.1384\n",
      "Epoch 421/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2493 - f1: 0.7242 - val_loss: 0.4350 - val_f1: 0.1387\n",
      "Epoch 422/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2525 - f1: 0.7257 - val_loss: 0.4291 - val_f1: 0.1384\n",
      "Epoch 423/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2512 - f1: 0.7233 - val_loss: 0.4271 - val_f1: 0.1394\n",
      "Epoch 424/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2478 - f1: 0.7263 - val_loss: 0.4326 - val_f1: 0.1392\n",
      "Epoch 425/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2477 - f1: 0.7280 - val_loss: 0.4342 - val_f1: 0.1386\n",
      "Epoch 426/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2493 - f1: 0.7234 - val_loss: 0.4323 - val_f1: 0.1387\n",
      "Epoch 427/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2503 - f1: 0.7261 - val_loss: 0.4309 - val_f1: 0.1395\n",
      "Epoch 428/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2481 - f1: 0.7235 - val_loss: 0.4328 - val_f1: 0.1373\n",
      "Epoch 429/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2487 - f1: 0.7225 - val_loss: 0.4368 - val_f1: 0.1382\n",
      "Epoch 430/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2486 - f1: 0.7263 - val_loss: 0.4297 - val_f1: 0.1400\n",
      "Epoch 431/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2495 - f1: 0.7275 - val_loss: 0.4309 - val_f1: 0.1393\n",
      "Epoch 432/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2493 - f1: 0.7251 - val_loss: 0.4377 - val_f1: 0.1377\n",
      "Epoch 433/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2476 - f1: 0.7266 - val_loss: 0.4341 - val_f1: 0.1381\n",
      "Epoch 434/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2491 - f1: 0.7290 - val_loss: 0.4336 - val_f1: 0.1395\n",
      "Epoch 435/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2471 - f1: 0.7273 - val_loss: 0.4290 - val_f1: 0.1412\n",
      "Epoch 436/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2473 - f1: 0.7315 - val_loss: 0.4305 - val_f1: 0.1386\n",
      "Epoch 437/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2461 - f1: 0.7286 - val_loss: 0.4308 - val_f1: 0.1392\n",
      "Epoch 438/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2484 - f1: 0.7266 - val_loss: 0.4366 - val_f1: 0.1385\n",
      "Epoch 439/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2472 - f1: 0.7268 - val_loss: 0.4301 - val_f1: 0.1394\n",
      "Epoch 440/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2460 - f1: 0.7295 - val_loss: 0.4325 - val_f1: 0.1397\n",
      "Epoch 441/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2479 - f1: 0.7301 - val_loss: 0.4346 - val_f1: 0.1393\n",
      "Epoch 442/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2500 - f1: 0.7268 - val_loss: 0.4344 - val_f1: 0.1379\n",
      "Epoch 443/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2466 - f1: 0.7279 - val_loss: 0.4381 - val_f1: 0.1387\n",
      "Epoch 444/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2484 - f1: 0.7271 - val_loss: 0.4376 - val_f1: 0.1380\n",
      "Epoch 445/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2479 - f1: 0.7246 - val_loss: 0.4284 - val_f1: 0.1408\n",
      "Epoch 446/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2484 - f1: 0.7293 - val_loss: 0.4320 - val_f1: 0.1393\n",
      "Epoch 447/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2467 - f1: 0.7285 - val_loss: 0.4339 - val_f1: 0.1387\n",
      "Epoch 448/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2477 - f1: 0.7310 - val_loss: 0.4308 - val_f1: 0.1403\n",
      "Epoch 449/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2483 - f1: 0.7302 - val_loss: 0.4333 - val_f1: 0.1391\n",
      "Epoch 450/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2420 - f1: 0.7364 - val_loss: 0.4336 - val_f1: 0.1407\n",
      "Epoch 451/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2455 - f1: 0.7274 - val_loss: 0.4330 - val_f1: 0.1410\n",
      "Epoch 452/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2475 - f1: 0.7243 - val_loss: 0.4320 - val_f1: 0.1399\n",
      "Epoch 453/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2446 - f1: 0.7337 - val_loss: 0.4334 - val_f1: 0.1395\n",
      "Epoch 454/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2466 - f1: 0.7291 - val_loss: 0.4325 - val_f1: 0.1398\n",
      "Epoch 455/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2464 - f1: 0.7311 - val_loss: 0.4386 - val_f1: 0.1379\n",
      "Epoch 456/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2448 - f1: 0.7325 - val_loss: 0.4389 - val_f1: 0.1392\n",
      "Epoch 457/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2422 - f1: 0.7384 - val_loss: 0.4367 - val_f1: 0.1392\n",
      "Epoch 458/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2432 - f1: 0.7344 - val_loss: 0.4367 - val_f1: 0.1407\n",
      "Epoch 459/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2418 - f1: 0.7398 - val_loss: 0.4377 - val_f1: 0.1395\n",
      "Epoch 460/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2450 - f1: 0.7327 - val_loss: 0.4335 - val_f1: 0.1388\n",
      "Epoch 461/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2458 - f1: 0.7283 - val_loss: 0.4370 - val_f1: 0.1384\n",
      "Epoch 462/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2459 - f1: 0.7293 - val_loss: 0.4347 - val_f1: 0.1398\n",
      "Epoch 463/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2426 - f1: 0.7326 - val_loss: 0.4381 - val_f1: 0.1386\n",
      "Epoch 464/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2425 - f1: 0.7329 - val_loss: 0.4354 - val_f1: 0.1391\n",
      "Epoch 465/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2456 - f1: 0.7347 - val_loss: 0.4336 - val_f1: 0.1399\n",
      "Epoch 466/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2431 - f1: 0.7344 - val_loss: 0.4384 - val_f1: 0.1401\n",
      "Epoch 467/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2435 - f1: 0.7338 - val_loss: 0.4360 - val_f1: 0.1394\n",
      "Epoch 468/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2426 - f1: 0.7359 - val_loss: 0.4368 - val_f1: 0.1391\n",
      "Epoch 469/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2441 - f1: 0.7306 - val_loss: 0.4349 - val_f1: 0.1398\n",
      "Epoch 470/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2408 - f1: 0.7358 - val_loss: 0.4408 - val_f1: 0.1389\n",
      "Epoch 471/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2405 - f1: 0.7359 - val_loss: 0.4441 - val_f1: 0.1394\n",
      "Epoch 472/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2422 - f1: 0.7384 - val_loss: 0.4468 - val_f1: 0.1389\n",
      "Epoch 473/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2416 - f1: 0.7365 - val_loss: 0.4278 - val_f1: 0.1413\n",
      "Epoch 474/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2415 - f1: 0.7334 - val_loss: 0.4387 - val_f1: 0.1394\n",
      "Epoch 475/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2410 - f1: 0.7355 - val_loss: 0.4366 - val_f1: 0.1397\n",
      "Epoch 476/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2426 - f1: 0.7367 - val_loss: 0.4392 - val_f1: 0.1375\n",
      "Epoch 477/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2412 - f1: 0.7335 - val_loss: 0.4394 - val_f1: 0.1390\n",
      "Epoch 478/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2413 - f1: 0.7350 - val_loss: 0.4391 - val_f1: 0.1397\n",
      "Epoch 479/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2423 - f1: 0.7348 - val_loss: 0.4403 - val_f1: 0.1384\n",
      "Epoch 480/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2415 - f1: 0.7349 - val_loss: 0.4408 - val_f1: 0.1392\n",
      "Epoch 481/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2390 - f1: 0.7388 - val_loss: 0.4346 - val_f1: 0.1406\n",
      "Epoch 482/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2412 - f1: 0.7346 - val_loss: 0.4386 - val_f1: 0.1392\n",
      "Epoch 483/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2402 - f1: 0.7391 - val_loss: 0.4373 - val_f1: 0.1396\n",
      "Epoch 484/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2427 - f1: 0.7321 - val_loss: 0.4390 - val_f1: 0.1375\n",
      "Epoch 485/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2405 - f1: 0.7351 - val_loss: 0.4453 - val_f1: 0.1382\n",
      "Epoch 486/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2403 - f1: 0.7429 - val_loss: 0.4433 - val_f1: 0.1397\n",
      "Epoch 487/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2423 - f1: 0.7367 - val_loss: 0.4377 - val_f1: 0.1390\n",
      "Epoch 488/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2418 - f1: 0.7360 - val_loss: 0.4418 - val_f1: 0.1381\n",
      "Epoch 489/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2392 - f1: 0.7436 - val_loss: 0.4390 - val_f1: 0.1393\n",
      "Epoch 490/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2396 - f1: 0.7394 - val_loss: 0.4412 - val_f1: 0.1387\n",
      "Epoch 491/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2391 - f1: 0.7386 - val_loss: 0.4412 - val_f1: 0.1380\n",
      "Epoch 492/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2365 - f1: 0.7445 - val_loss: 0.4485 - val_f1: 0.1385\n",
      "Epoch 493/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2396 - f1: 0.7378 - val_loss: 0.4395 - val_f1: 0.1394\n",
      "Epoch 494/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2405 - f1: 0.7371 - val_loss: 0.4395 - val_f1: 0.1395\n",
      "Epoch 495/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2392 - f1: 0.7391 - val_loss: 0.4458 - val_f1: 0.1385\n",
      "Epoch 496/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2355 - f1: 0.7452 - val_loss: 0.4373 - val_f1: 0.1407\n",
      "Epoch 497/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2381 - f1: 0.7415 - val_loss: 0.4412 - val_f1: 0.1396\n",
      "Epoch 498/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2388 - f1: 0.7401 - val_loss: 0.4482 - val_f1: 0.1371\n",
      "Epoch 499/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2364 - f1: 0.7440 - val_loss: 0.4403 - val_f1: 0.1393\n",
      "Epoch 500/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2353 - f1: 0.7428 - val_loss: 0.4471 - val_f1: 0.1391\n",
      "Epoch 501/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2346 - f1: 0.7417 - val_loss: 0.4484 - val_f1: 0.1385\n",
      "Epoch 502/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2383 - f1: 0.7445 - val_loss: 0.4432 - val_f1: 0.1396\n",
      "Epoch 503/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2371 - f1: 0.7434 - val_loss: 0.4428 - val_f1: 0.1382\n",
      "Epoch 504/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2373 - f1: 0.7439 - val_loss: 0.4475 - val_f1: 0.1378\n",
      "Epoch 505/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2339 - f1: 0.7495 - val_loss: 0.4455 - val_f1: 0.1389\n",
      "Epoch 506/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2359 - f1: 0.7433 - val_loss: 0.4437 - val_f1: 0.1394\n",
      "Epoch 507/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2392 - f1: 0.7421 - val_loss: 0.4429 - val_f1: 0.1395\n",
      "Epoch 508/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2380 - f1: 0.7409 - val_loss: 0.4446 - val_f1: 0.1389\n",
      "Epoch 509/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2351 - f1: 0.7415 - val_loss: 0.4408 - val_f1: 0.1404\n",
      "Epoch 510/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2389 - f1: 0.7391 - val_loss: 0.4441 - val_f1: 0.1391\n",
      "Epoch 511/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2341 - f1: 0.7480 - val_loss: 0.4465 - val_f1: 0.1396\n",
      "Epoch 512/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2369 - f1: 0.7400 - val_loss: 0.4436 - val_f1: 0.1396\n",
      "Epoch 513/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2364 - f1: 0.7465 - val_loss: 0.4458 - val_f1: 0.1399\n",
      "Epoch 514/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2362 - f1: 0.7400 - val_loss: 0.4443 - val_f1: 0.1388\n",
      "Epoch 515/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2354 - f1: 0.7445 - val_loss: 0.4454 - val_f1: 0.1392\n",
      "Epoch 516/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2355 - f1: 0.7462 - val_loss: 0.4450 - val_f1: 0.1398\n",
      "Epoch 517/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2342 - f1: 0.7413 - val_loss: 0.4472 - val_f1: 0.1399\n",
      "Epoch 518/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2353 - f1: 0.7464 - val_loss: 0.4443 - val_f1: 0.1399\n",
      "Epoch 519/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2363 - f1: 0.7416 - val_loss: 0.4502 - val_f1: 0.1380\n",
      "Epoch 520/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2359 - f1: 0.7411 - val_loss: 0.4474 - val_f1: 0.1398\n",
      "Epoch 521/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2356 - f1: 0.7401 - val_loss: 0.4449 - val_f1: 0.1401\n",
      "Epoch 522/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2341 - f1: 0.7459 - val_loss: 0.4434 - val_f1: 0.1402\n",
      "Epoch 523/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2354 - f1: 0.7443 - val_loss: 0.4494 - val_f1: 0.1393\n",
      "Epoch 524/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2356 - f1: 0.7408 - val_loss: 0.4457 - val_f1: 0.1396\n",
      "Epoch 525/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2337 - f1: 0.7462 - val_loss: 0.4467 - val_f1: 0.1403\n",
      "Epoch 526/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2336 - f1: 0.7477 - val_loss: 0.4505 - val_f1: 0.1373\n",
      "Epoch 527/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2344 - f1: 0.7470 - val_loss: 0.4510 - val_f1: 0.1393\n",
      "Epoch 528/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2357 - f1: 0.7413 - val_loss: 0.4502 - val_f1: 0.1381\n",
      "Epoch 529/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2363 - f1: 0.7396 - val_loss: 0.4506 - val_f1: 0.1391\n",
      "Epoch 530/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2316 - f1: 0.7486 - val_loss: 0.4431 - val_f1: 0.1400\n",
      "Epoch 531/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2355 - f1: 0.7475 - val_loss: 0.4460 - val_f1: 0.1398\n",
      "Epoch 532/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2344 - f1: 0.7441 - val_loss: 0.4538 - val_f1: 0.1392\n",
      "Epoch 533/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2336 - f1: 0.7480 - val_loss: 0.4452 - val_f1: 0.1404\n",
      "Epoch 534/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2330 - f1: 0.7487 - val_loss: 0.4545 - val_f1: 0.1398\n",
      "Epoch 535/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2334 - f1: 0.7481 - val_loss: 0.4458 - val_f1: 0.1401\n",
      "Epoch 536/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2343 - f1: 0.7477 - val_loss: 0.4495 - val_f1: 0.1402\n",
      "Epoch 537/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2353 - f1: 0.7466 - val_loss: 0.4451 - val_f1: 0.1385\n",
      "Epoch 538/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2331 - f1: 0.7469 - val_loss: 0.4506 - val_f1: 0.1396\n",
      "Epoch 539/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2357 - f1: 0.7476 - val_loss: 0.4478 - val_f1: 0.1402\n",
      "Epoch 540/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2310 - f1: 0.7475 - val_loss: 0.4514 - val_f1: 0.1394\n",
      "Epoch 541/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2333 - f1: 0.7493 - val_loss: 0.4533 - val_f1: 0.1400\n",
      "Epoch 542/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2317 - f1: 0.7506 - val_loss: 0.4500 - val_f1: 0.1406\n",
      "Epoch 543/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2324 - f1: 0.7493 - val_loss: 0.4488 - val_f1: 0.1408\n",
      "Epoch 544/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2321 - f1: 0.7456 - val_loss: 0.4576 - val_f1: 0.1390\n",
      "Epoch 545/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2314 - f1: 0.7458 - val_loss: 0.4469 - val_f1: 0.1398\n",
      "Epoch 546/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2337 - f1: 0.7458 - val_loss: 0.4491 - val_f1: 0.1394\n",
      "Epoch 547/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2312 - f1: 0.7489 - val_loss: 0.4534 - val_f1: 0.1386\n",
      "Epoch 548/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2292 - f1: 0.7547 - val_loss: 0.4503 - val_f1: 0.1394\n",
      "Epoch 549/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2345 - f1: 0.7435 - val_loss: 0.4436 - val_f1: 0.1415\n",
      "Epoch 550/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2310 - f1: 0.7478 - val_loss: 0.4520 - val_f1: 0.1406\n",
      "Epoch 551/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2299 - f1: 0.7513 - val_loss: 0.4519 - val_f1: 0.1404\n",
      "Epoch 552/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2325 - f1: 0.7491 - val_loss: 0.4476 - val_f1: 0.1389\n",
      "Epoch 553/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2304 - f1: 0.7480 - val_loss: 0.4531 - val_f1: 0.1390\n",
      "Epoch 554/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2301 - f1: 0.7485 - val_loss: 0.4412 - val_f1: 0.1410\n",
      "Epoch 555/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2302 - f1: 0.7508 - val_loss: 0.4559 - val_f1: 0.1387\n",
      "Epoch 556/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2315 - f1: 0.7500 - val_loss: 0.4549 - val_f1: 0.1383\n",
      "Epoch 557/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2317 - f1: 0.7486 - val_loss: 0.4503 - val_f1: 0.1401\n",
      "Epoch 558/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2301 - f1: 0.7532 - val_loss: 0.4576 - val_f1: 0.1373\n",
      "Epoch 559/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2286 - f1: 0.7516 - val_loss: 0.4521 - val_f1: 0.1400\n",
      "Epoch 560/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2327 - f1: 0.7475 - val_loss: 0.4525 - val_f1: 0.1389\n",
      "Epoch 561/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2322 - f1: 0.7452 - val_loss: 0.4541 - val_f1: 0.1394\n",
      "Epoch 562/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2296 - f1: 0.7506 - val_loss: 0.4540 - val_f1: 0.1390\n",
      "Epoch 563/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2319 - f1: 0.7496 - val_loss: 0.4544 - val_f1: 0.1396\n",
      "Epoch 564/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2320 - f1: 0.7462 - val_loss: 0.4499 - val_f1: 0.1400\n",
      "Epoch 565/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2311 - f1: 0.7507 - val_loss: 0.4509 - val_f1: 0.1387\n",
      "Epoch 566/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2323 - f1: 0.7538 - val_loss: 0.4549 - val_f1: 0.1382\n",
      "Epoch 567/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2329 - f1: 0.7496 - val_loss: 0.4514 - val_f1: 0.1387\n",
      "Epoch 568/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2296 - f1: 0.7484 - val_loss: 0.4525 - val_f1: 0.1398\n",
      "Epoch 569/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2317 - f1: 0.7501 - val_loss: 0.4484 - val_f1: 0.1397\n",
      "Epoch 570/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2294 - f1: 0.7530 - val_loss: 0.4531 - val_f1: 0.1393\n",
      "Epoch 571/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2291 - f1: 0.7491 - val_loss: 0.4554 - val_f1: 0.1389\n",
      "Epoch 572/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2292 - f1: 0.7557 - val_loss: 0.4481 - val_f1: 0.1401\n",
      "Epoch 573/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2305 - f1: 0.7470 - val_loss: 0.4479 - val_f1: 0.1395\n",
      "Epoch 574/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2289 - f1: 0.7542 - val_loss: 0.4516 - val_f1: 0.1408\n",
      "Epoch 575/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2288 - f1: 0.7519 - val_loss: 0.4595 - val_f1: 0.1375\n",
      "Epoch 576/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2291 - f1: 0.7547 - val_loss: 0.4533 - val_f1: 0.1390\n",
      "Epoch 577/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2323 - f1: 0.7464 - val_loss: 0.4525 - val_f1: 0.1382\n",
      "Epoch 578/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2282 - f1: 0.7537 - val_loss: 0.4584 - val_f1: 0.1384\n",
      "Epoch 579/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2309 - f1: 0.7522 - val_loss: 0.4513 - val_f1: 0.1405\n",
      "Epoch 580/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2284 - f1: 0.7506 - val_loss: 0.4582 - val_f1: 0.1386\n",
      "Epoch 581/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2271 - f1: 0.7569 - val_loss: 0.4591 - val_f1: 0.1383\n",
      "Epoch 582/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2280 - f1: 0.7539 - val_loss: 0.4553 - val_f1: 0.1391\n",
      "Epoch 583/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2287 - f1: 0.7518 - val_loss: 0.4525 - val_f1: 0.1394\n",
      "Epoch 584/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2279 - f1: 0.7523 - val_loss: 0.4539 - val_f1: 0.1389\n",
      "Epoch 585/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2273 - f1: 0.7566 - val_loss: 0.4554 - val_f1: 0.1388\n",
      "Epoch 586/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2269 - f1: 0.7561 - val_loss: 0.4610 - val_f1: 0.1381\n",
      "Epoch 587/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2283 - f1: 0.7514 - val_loss: 0.4588 - val_f1: 0.1377\n",
      "Epoch 588/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2286 - f1: 0.7539 - val_loss: 0.4582 - val_f1: 0.1381\n",
      "Epoch 589/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2276 - f1: 0.7559 - val_loss: 0.4525 - val_f1: 0.1395\n",
      "Epoch 590/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2276 - f1: 0.7547 - val_loss: 0.4540 - val_f1: 0.1397\n",
      "Epoch 591/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2256 - f1: 0.7582 - val_loss: 0.4535 - val_f1: 0.1398\n",
      "Epoch 592/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2259 - f1: 0.7556 - val_loss: 0.4521 - val_f1: 0.1405\n",
      "Epoch 593/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2294 - f1: 0.7519 - val_loss: 0.4613 - val_f1: 0.1390\n",
      "Epoch 594/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2248 - f1: 0.7533 - val_loss: 0.4507 - val_f1: 0.1396\n",
      "Epoch 595/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2257 - f1: 0.7564 - val_loss: 0.4564 - val_f1: 0.1395\n",
      "Epoch 596/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2276 - f1: 0.7567 - val_loss: 0.4573 - val_f1: 0.1390\n",
      "Epoch 597/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2260 - f1: 0.7563 - val_loss: 0.4543 - val_f1: 0.1401\n",
      "Epoch 598/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2259 - f1: 0.7588 - val_loss: 0.4602 - val_f1: 0.1392\n",
      "Epoch 599/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2266 - f1: 0.7545 - val_loss: 0.4530 - val_f1: 0.1401\n",
      "Epoch 600/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2256 - f1: 0.7544 - val_loss: 0.4625 - val_f1: 0.1388\n",
      "Epoch 601/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2265 - f1: 0.7545 - val_loss: 0.4622 - val_f1: 0.1378\n",
      "Epoch 602/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2263 - f1: 0.7588 - val_loss: 0.4588 - val_f1: 0.1388\n",
      "Epoch 603/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2251 - f1: 0.7571 - val_loss: 0.4581 - val_f1: 0.1394\n",
      "Epoch 604/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2293 - f1: 0.7538 - val_loss: 0.4643 - val_f1: 0.1369\n",
      "Epoch 605/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2256 - f1: 0.7543 - val_loss: 0.4519 - val_f1: 0.1408\n",
      "Epoch 606/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2236 - f1: 0.7573 - val_loss: 0.4586 - val_f1: 0.1395\n",
      "Epoch 607/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2267 - f1: 0.7557 - val_loss: 0.4577 - val_f1: 0.1389\n",
      "Epoch 608/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2249 - f1: 0.7600 - val_loss: 0.4638 - val_f1: 0.1387\n",
      "Epoch 609/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2229 - f1: 0.7587 - val_loss: 0.4590 - val_f1: 0.1384\n",
      "Epoch 610/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2254 - f1: 0.7572 - val_loss: 0.4601 - val_f1: 0.1380\n",
      "Epoch 611/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2258 - f1: 0.7568 - val_loss: 0.4564 - val_f1: 0.1391\n",
      "Epoch 612/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2249 - f1: 0.7553 - val_loss: 0.4554 - val_f1: 0.1385\n",
      "Epoch 613/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2246 - f1: 0.7582 - val_loss: 0.4674 - val_f1: 0.1366\n",
      "Epoch 614/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2238 - f1: 0.7571 - val_loss: 0.4610 - val_f1: 0.1390\n",
      "Epoch 615/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2243 - f1: 0.7593 - val_loss: 0.4601 - val_f1: 0.1383\n",
      "Epoch 616/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2258 - f1: 0.7551 - val_loss: 0.4593 - val_f1: 0.1386\n",
      "Epoch 617/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2251 - f1: 0.7572 - val_loss: 0.4609 - val_f1: 0.1385\n",
      "Epoch 618/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2234 - f1: 0.7586 - val_loss: 0.4589 - val_f1: 0.1404\n",
      "Epoch 619/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2228 - f1: 0.7611 - val_loss: 0.4618 - val_f1: 0.1380\n",
      "Epoch 620/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2230 - f1: 0.7609 - val_loss: 0.4641 - val_f1: 0.1381\n",
      "Epoch 621/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2232 - f1: 0.7563 - val_loss: 0.4654 - val_f1: 0.1386\n",
      "Epoch 622/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2248 - f1: 0.7606 - val_loss: 0.4543 - val_f1: 0.1385\n",
      "Epoch 623/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2252 - f1: 0.7585 - val_loss: 0.4577 - val_f1: 0.1393\n",
      "Epoch 624/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2261 - f1: 0.7540 - val_loss: 0.4624 - val_f1: 0.1378\n",
      "Epoch 625/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2232 - f1: 0.7576 - val_loss: 0.4637 - val_f1: 0.1374\n",
      "Epoch 626/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2223 - f1: 0.7604 - val_loss: 0.4674 - val_f1: 0.1375\n",
      "Epoch 627/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2245 - f1: 0.7620 - val_loss: 0.4567 - val_f1: 0.1384\n",
      "Epoch 628/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2232 - f1: 0.7575 - val_loss: 0.4611 - val_f1: 0.1391\n",
      "Epoch 629/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2229 - f1: 0.7592 - val_loss: 0.4628 - val_f1: 0.1375\n",
      "Epoch 630/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2209 - f1: 0.7640 - val_loss: 0.4616 - val_f1: 0.1375\n",
      "Epoch 631/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2231 - f1: 0.7623 - val_loss: 0.4655 - val_f1: 0.1374\n",
      "Epoch 632/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2219 - f1: 0.7647 - val_loss: 0.4604 - val_f1: 0.1392\n",
      "Epoch 633/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2232 - f1: 0.7534 - val_loss: 0.4619 - val_f1: 0.1389\n",
      "Epoch 634/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2233 - f1: 0.7640 - val_loss: 0.4592 - val_f1: 0.1385\n",
      "Epoch 635/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2215 - f1: 0.7610 - val_loss: 0.4597 - val_f1: 0.1386\n",
      "Epoch 636/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2234 - f1: 0.7619 - val_loss: 0.4648 - val_f1: 0.1381\n",
      "Epoch 637/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2219 - f1: 0.7639 - val_loss: 0.4659 - val_f1: 0.1368\n",
      "Epoch 638/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2210 - f1: 0.7649 - val_loss: 0.4603 - val_f1: 0.1392\n",
      "Epoch 639/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2230 - f1: 0.7610 - val_loss: 0.4625 - val_f1: 0.1387\n",
      "Epoch 640/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2251 - f1: 0.7560 - val_loss: 0.4609 - val_f1: 0.1391\n",
      "Epoch 641/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2185 - f1: 0.7654 - val_loss: 0.4705 - val_f1: 0.1379\n",
      "Epoch 642/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2204 - f1: 0.7619 - val_loss: 0.4619 - val_f1: 0.1389\n",
      "Epoch 643/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2229 - f1: 0.7588 - val_loss: 0.4741 - val_f1: 0.1368\n",
      "Epoch 644/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2193 - f1: 0.7645 - val_loss: 0.4643 - val_f1: 0.1377\n",
      "Epoch 645/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2203 - f1: 0.7689 - val_loss: 0.4634 - val_f1: 0.1381\n",
      "Epoch 646/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2206 - f1: 0.7615 - val_loss: 0.4556 - val_f1: 0.1397\n",
      "Epoch 647/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2236 - f1: 0.7594 - val_loss: 0.4620 - val_f1: 0.1382\n",
      "Epoch 648/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2231 - f1: 0.7610 - val_loss: 0.4612 - val_f1: 0.1387\n",
      "Epoch 649/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2224 - f1: 0.7616 - val_loss: 0.4587 - val_f1: 0.1384\n",
      "Epoch 650/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2232 - f1: 0.7589 - val_loss: 0.4587 - val_f1: 0.1391\n",
      "Epoch 651/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2218 - f1: 0.7598 - val_loss: 0.4621 - val_f1: 0.1386\n",
      "Epoch 652/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2228 - f1: 0.7616 - val_loss: 0.4628 - val_f1: 0.1385\n",
      "Epoch 653/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2208 - f1: 0.7610 - val_loss: 0.4603 - val_f1: 0.1382\n",
      "Epoch 654/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2213 - f1: 0.7589 - val_loss: 0.4621 - val_f1: 0.1390\n",
      "Epoch 655/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2222 - f1: 0.7626 - val_loss: 0.4616 - val_f1: 0.1393\n",
      "Epoch 656/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2203 - f1: 0.7642 - val_loss: 0.4681 - val_f1: 0.1376\n",
      "Epoch 657/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2223 - f1: 0.7603 - val_loss: 0.4627 - val_f1: 0.1384\n",
      "Epoch 658/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2206 - f1: 0.7620 - val_loss: 0.4669 - val_f1: 0.1367\n",
      "Epoch 659/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2218 - f1: 0.7599 - val_loss: 0.4694 - val_f1: 0.1377\n",
      "Epoch 660/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2214 - f1: 0.7617 - val_loss: 0.4659 - val_f1: 0.1380\n",
      "Epoch 661/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2196 - f1: 0.7661 - val_loss: 0.4644 - val_f1: 0.1380\n",
      "Epoch 662/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2211 - f1: 0.7598 - val_loss: 0.4654 - val_f1: 0.1379\n",
      "Epoch 663/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2224 - f1: 0.7601 - val_loss: 0.4695 - val_f1: 0.1364\n",
      "Epoch 664/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2213 - f1: 0.7640 - val_loss: 0.4649 - val_f1: 0.1377\n",
      "Epoch 665/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2221 - f1: 0.7599 - val_loss: 0.4648 - val_f1: 0.1385\n",
      "Epoch 666/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2176 - f1: 0.7652 - val_loss: 0.4661 - val_f1: 0.1385\n",
      "Epoch 667/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2196 - f1: 0.7673 - val_loss: 0.4629 - val_f1: 0.1386\n",
      "Epoch 668/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2217 - f1: 0.7616 - val_loss: 0.4621 - val_f1: 0.1384\n",
      "Epoch 669/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2194 - f1: 0.7674 - val_loss: 0.4666 - val_f1: 0.1388\n",
      "Epoch 670/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2194 - f1: 0.7650 - val_loss: 0.4652 - val_f1: 0.1383\n",
      "Epoch 671/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2197 - f1: 0.7670 - val_loss: 0.4653 - val_f1: 0.1386\n",
      "Epoch 672/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2186 - f1: 0.7636 - val_loss: 0.4659 - val_f1: 0.1393\n",
      "Epoch 673/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2181 - f1: 0.7638 - val_loss: 0.4647 - val_f1: 0.1395\n",
      "Epoch 674/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2177 - f1: 0.7649 - val_loss: 0.4688 - val_f1: 0.1375\n",
      "Epoch 675/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2176 - f1: 0.7620 - val_loss: 0.4679 - val_f1: 0.1383\n",
      "Epoch 676/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2197 - f1: 0.7642 - val_loss: 0.4694 - val_f1: 0.1379\n",
      "Epoch 677/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2184 - f1: 0.7619 - val_loss: 0.4686 - val_f1: 0.1387\n",
      "Epoch 678/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2166 - f1: 0.7672 - val_loss: 0.4672 - val_f1: 0.1390\n",
      "Epoch 679/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2183 - f1: 0.7636 - val_loss: 0.4690 - val_f1: 0.1381\n",
      "Epoch 680/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2173 - f1: 0.7614 - val_loss: 0.4724 - val_f1: 0.1375\n",
      "Epoch 681/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2180 - f1: 0.7653 - val_loss: 0.4592 - val_f1: 0.1405\n",
      "Epoch 682/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2174 - f1: 0.7681 - val_loss: 0.4688 - val_f1: 0.1382\n",
      "Epoch 683/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2191 - f1: 0.7627 - val_loss: 0.4716 - val_f1: 0.1382\n",
      "Epoch 684/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2181 - f1: 0.7644 - val_loss: 0.4634 - val_f1: 0.1388\n",
      "Epoch 685/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2191 - f1: 0.7638 - val_loss: 0.4709 - val_f1: 0.1385\n",
      "Epoch 686/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2205 - f1: 0.7623 - val_loss: 0.4686 - val_f1: 0.1379\n",
      "Epoch 687/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2191 - f1: 0.7591 - val_loss: 0.4661 - val_f1: 0.1399\n",
      "Epoch 688/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2169 - f1: 0.7683 - val_loss: 0.4702 - val_f1: 0.1384\n",
      "Epoch 689/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2191 - f1: 0.7633 - val_loss: 0.4688 - val_f1: 0.1383\n",
      "Epoch 690/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2191 - f1: 0.7627 - val_loss: 0.4675 - val_f1: 0.1389\n",
      "Epoch 691/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2176 - f1: 0.7644 - val_loss: 0.4589 - val_f1: 0.1403\n",
      "Epoch 692/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2175 - f1: 0.7651 - val_loss: 0.4618 - val_f1: 0.1390\n",
      "Epoch 693/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2173 - f1: 0.7626 - val_loss: 0.4579 - val_f1: 0.1411\n",
      "Epoch 694/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2198 - f1: 0.7676 - val_loss: 0.4696 - val_f1: 0.1394\n",
      "Epoch 695/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2172 - f1: 0.7650 - val_loss: 0.4670 - val_f1: 0.1381\n",
      "Epoch 696/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2165 - f1: 0.7643 - val_loss: 0.4635 - val_f1: 0.1398\n",
      "Epoch 697/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2182 - f1: 0.7665 - val_loss: 0.4704 - val_f1: 0.1385\n",
      "Epoch 698/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2181 - f1: 0.7622 - val_loss: 0.4631 - val_f1: 0.1393\n",
      "Epoch 699/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2164 - f1: 0.7634 - val_loss: 0.4665 - val_f1: 0.1395\n",
      "Epoch 700/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2160 - f1: 0.7663 - val_loss: 0.4769 - val_f1: 0.1378\n",
      "Epoch 701/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2177 - f1: 0.7688 - val_loss: 0.4684 - val_f1: 0.1383\n",
      "Epoch 702/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2176 - f1: 0.7698 - val_loss: 0.4607 - val_f1: 0.1381\n",
      "Epoch 703/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2188 - f1: 0.7645 - val_loss: 0.4667 - val_f1: 0.1379\n",
      "Epoch 704/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2158 - f1: 0.7698 - val_loss: 0.4710 - val_f1: 0.1380\n",
      "Epoch 705/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2158 - f1: 0.7685 - val_loss: 0.4631 - val_f1: 0.1387\n",
      "Epoch 706/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2176 - f1: 0.7706 - val_loss: 0.4751 - val_f1: 0.1378\n",
      "Epoch 707/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2163 - f1: 0.7681 - val_loss: 0.4675 - val_f1: 0.1390\n",
      "Epoch 708/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2162 - f1: 0.7669 - val_loss: 0.4686 - val_f1: 0.1388\n",
      "Epoch 709/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2144 - f1: 0.7742 - val_loss: 0.4629 - val_f1: 0.1391\n",
      "Epoch 710/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2154 - f1: 0.7698 - val_loss: 0.4681 - val_f1: 0.1396\n",
      "Epoch 711/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2184 - f1: 0.7658 - val_loss: 0.4729 - val_f1: 0.1383\n",
      "Epoch 712/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2185 - f1: 0.7633 - val_loss: 0.4607 - val_f1: 0.1406\n",
      "Epoch 713/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2161 - f1: 0.7661 - val_loss: 0.4662 - val_f1: 0.1395\n",
      "Epoch 714/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2164 - f1: 0.7682 - val_loss: 0.4796 - val_f1: 0.1373\n",
      "Epoch 715/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2160 - f1: 0.7698 - val_loss: 0.4699 - val_f1: 0.1376\n",
      "Epoch 716/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2185 - f1: 0.7649 - val_loss: 0.4640 - val_f1: 0.1387\n",
      "Epoch 717/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2168 - f1: 0.7688 - val_loss: 0.4714 - val_f1: 0.1378\n",
      "Epoch 718/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2153 - f1: 0.7670 - val_loss: 0.4684 - val_f1: 0.1384\n",
      "Epoch 719/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2163 - f1: 0.7658 - val_loss: 0.4678 - val_f1: 0.1383\n",
      "Epoch 720/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2174 - f1: 0.7695 - val_loss: 0.4698 - val_f1: 0.1374\n",
      "Epoch 721/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2159 - f1: 0.7681 - val_loss: 0.4715 - val_f1: 0.1380\n",
      "Epoch 722/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2175 - f1: 0.7661 - val_loss: 0.4714 - val_f1: 0.1376\n",
      "Epoch 723/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2138 - f1: 0.7713 - val_loss: 0.4696 - val_f1: 0.1397\n",
      "Epoch 724/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2167 - f1: 0.7659 - val_loss: 0.4740 - val_f1: 0.1384\n",
      "Epoch 725/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2135 - f1: 0.7720 - val_loss: 0.4743 - val_f1: 0.1387\n",
      "Epoch 726/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2158 - f1: 0.7713 - val_loss: 0.4668 - val_f1: 0.1395\n",
      "Epoch 727/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2132 - f1: 0.7745 - val_loss: 0.4689 - val_f1: 0.1388\n",
      "Epoch 728/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2148 - f1: 0.7716 - val_loss: 0.4745 - val_f1: 0.1381\n",
      "Epoch 729/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2142 - f1: 0.7725 - val_loss: 0.4734 - val_f1: 0.1389\n",
      "Epoch 730/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2154 - f1: 0.7720 - val_loss: 0.4782 - val_f1: 0.1377\n",
      "Epoch 731/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2171 - f1: 0.7682 - val_loss: 0.4715 - val_f1: 0.1376\n",
      "Epoch 732/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2136 - f1: 0.7701 - val_loss: 0.4657 - val_f1: 0.1392\n",
      "Epoch 733/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2155 - f1: 0.7682 - val_loss: 0.4667 - val_f1: 0.1393\n",
      "Epoch 734/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2188 - f1: 0.7661 - val_loss: 0.4667 - val_f1: 0.1386\n",
      "Epoch 735/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2174 - f1: 0.7675 - val_loss: 0.4654 - val_f1: 0.1384\n",
      "Epoch 736/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2144 - f1: 0.7697 - val_loss: 0.4735 - val_f1: 0.1374\n",
      "Epoch 737/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2162 - f1: 0.7699 - val_loss: 0.4683 - val_f1: 0.1383\n",
      "Epoch 738/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2156 - f1: 0.7666 - val_loss: 0.4636 - val_f1: 0.1396\n",
      "Epoch 739/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2120 - f1: 0.7710 - val_loss: 0.4677 - val_f1: 0.1395\n",
      "Epoch 740/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2166 - f1: 0.7668 - val_loss: 0.4680 - val_f1: 0.1381\n",
      "Epoch 741/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2145 - f1: 0.7676 - val_loss: 0.4677 - val_f1: 0.1394\n",
      "Epoch 742/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2151 - f1: 0.7714 - val_loss: 0.4680 - val_f1: 0.1396\n",
      "Epoch 743/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2188 - f1: 0.7682 - val_loss: 0.4650 - val_f1: 0.1402\n",
      "Epoch 744/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2161 - f1: 0.7665 - val_loss: 0.4649 - val_f1: 0.1390\n",
      "Epoch 745/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2174 - f1: 0.7680 - val_loss: 0.4725 - val_f1: 0.1384\n",
      "Epoch 746/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2139 - f1: 0.7701 - val_loss: 0.4759 - val_f1: 0.1384\n",
      "Epoch 747/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2099 - f1: 0.7785 - val_loss: 0.4764 - val_f1: 0.1380\n",
      "Epoch 748/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2146 - f1: 0.7688 - val_loss: 0.4792 - val_f1: 0.1377\n",
      "Epoch 749/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2144 - f1: 0.7692 - val_loss: 0.4708 - val_f1: 0.1390\n",
      "Epoch 750/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2130 - f1: 0.7721 - val_loss: 0.4657 - val_f1: 0.1397\n",
      "Epoch 751/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2150 - f1: 0.7686 - val_loss: 0.4712 - val_f1: 0.1391\n",
      "Epoch 752/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2112 - f1: 0.7806 - val_loss: 0.4770 - val_f1: 0.1387\n",
      "Epoch 753/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2111 - f1: 0.7758 - val_loss: 0.4696 - val_f1: 0.1391\n",
      "Epoch 754/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2131 - f1: 0.7747 - val_loss: 0.4792 - val_f1: 0.1377\n",
      "Epoch 755/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2128 - f1: 0.7734 - val_loss: 0.4672 - val_f1: 0.1398\n",
      "Epoch 756/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2129 - f1: 0.7721 - val_loss: 0.4675 - val_f1: 0.1384\n",
      "Epoch 757/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2127 - f1: 0.7707 - val_loss: 0.4836 - val_f1: 0.1368\n",
      "Epoch 758/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2141 - f1: 0.7688 - val_loss: 0.4733 - val_f1: 0.1381\n",
      "Epoch 759/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2136 - f1: 0.7704 - val_loss: 0.4779 - val_f1: 0.1377\n",
      "Epoch 760/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2126 - f1: 0.7720 - val_loss: 0.4744 - val_f1: 0.1385\n",
      "Epoch 761/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2142 - f1: 0.7691 - val_loss: 0.4699 - val_f1: 0.1392\n",
      "Epoch 762/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.2127 - f1: 0.7752 - val_loss: 0.4733 - val_f1: 0.1380\n",
      "Epoch 763/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2124 - f1: 0.7721 - val_loss: 0.4757 - val_f1: 0.1381\n",
      "Epoch 764/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2116 - f1: 0.7729 - val_loss: 0.4704 - val_f1: 0.1394\n",
      "Epoch 765/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2108 - f1: 0.7755 - val_loss: 0.4739 - val_f1: 0.1383\n",
      "Epoch 766/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2114 - f1: 0.7718 - val_loss: 0.4751 - val_f1: 0.1385\n",
      "Epoch 767/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2111 - f1: 0.7756 - val_loss: 0.4725 - val_f1: 0.1388\n",
      "Epoch 768/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2104 - f1: 0.7757 - val_loss: 0.4799 - val_f1: 0.1373\n",
      "Epoch 769/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2114 - f1: 0.7710 - val_loss: 0.4759 - val_f1: 0.1383\n",
      "Epoch 770/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2117 - f1: 0.7746 - val_loss: 0.4785 - val_f1: 0.1378\n",
      "Epoch 771/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2128 - f1: 0.7769 - val_loss: 0.4683 - val_f1: 0.1393\n",
      "Epoch 772/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2122 - f1: 0.7741 - val_loss: 0.4701 - val_f1: 0.1397\n",
      "Epoch 773/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2113 - f1: 0.7763 - val_loss: 0.4809 - val_f1: 0.1373\n",
      "Epoch 774/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2120 - f1: 0.7761 - val_loss: 0.4704 - val_f1: 0.1390\n",
      "Epoch 775/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2108 - f1: 0.7773 - val_loss: 0.4774 - val_f1: 0.1383\n",
      "Epoch 776/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2130 - f1: 0.7708 - val_loss: 0.4730 - val_f1: 0.1382\n",
      "Epoch 777/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2156 - f1: 0.7686 - val_loss: 0.4763 - val_f1: 0.1381\n",
      "Epoch 778/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2113 - f1: 0.7742 - val_loss: 0.4749 - val_f1: 0.1392\n",
      "Epoch 779/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2096 - f1: 0.7728 - val_loss: 0.4732 - val_f1: 0.1388\n",
      "Epoch 780/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2110 - f1: 0.7702 - val_loss: 0.4706 - val_f1: 0.1393\n",
      "Epoch 781/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2116 - f1: 0.7732 - val_loss: 0.4745 - val_f1: 0.1390\n",
      "Epoch 782/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2102 - f1: 0.7762 - val_loss: 0.4725 - val_f1: 0.1398\n",
      "Epoch 783/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2115 - f1: 0.7705 - val_loss: 0.4801 - val_f1: 0.1376\n",
      "Epoch 784/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2117 - f1: 0.7742 - val_loss: 0.4770 - val_f1: 0.1380\n",
      "Epoch 785/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2125 - f1: 0.7711 - val_loss: 0.4770 - val_f1: 0.1386\n",
      "Epoch 786/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2122 - f1: 0.7725 - val_loss: 0.4770 - val_f1: 0.1387\n",
      "Epoch 787/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2131 - f1: 0.7724 - val_loss: 0.4686 - val_f1: 0.1407\n",
      "Epoch 788/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2129 - f1: 0.7732 - val_loss: 0.4739 - val_f1: 0.1388\n",
      "Epoch 789/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2122 - f1: 0.7759 - val_loss: 0.4783 - val_f1: 0.1390\n",
      "Epoch 790/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2089 - f1: 0.7778 - val_loss: 0.4749 - val_f1: 0.1395\n",
      "Epoch 791/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2101 - f1: 0.7734 - val_loss: 0.4743 - val_f1: 0.1397\n",
      "Epoch 792/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2082 - f1: 0.7811 - val_loss: 0.4800 - val_f1: 0.1381\n",
      "Epoch 793/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2105 - f1: 0.7727 - val_loss: 0.4764 - val_f1: 0.1385\n",
      "Epoch 794/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2108 - f1: 0.7740 - val_loss: 0.4723 - val_f1: 0.1402\n",
      "Epoch 795/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2117 - f1: 0.7757 - val_loss: 0.4759 - val_f1: 0.1395\n",
      "Epoch 796/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2104 - f1: 0.7747 - val_loss: 0.4761 - val_f1: 0.1392\n",
      "Epoch 797/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2093 - f1: 0.7793 - val_loss: 0.4757 - val_f1: 0.1387\n",
      "Epoch 798/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2115 - f1: 0.7732 - val_loss: 0.4738 - val_f1: 0.1386\n",
      "Epoch 799/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2092 - f1: 0.7796 - val_loss: 0.4760 - val_f1: 0.1386\n",
      "Epoch 800/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2103 - f1: 0.7734 - val_loss: 0.4734 - val_f1: 0.1398\n",
      "Epoch 801/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2105 - f1: 0.7785 - val_loss: 0.4762 - val_f1: 0.1386\n",
      "Epoch 802/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2127 - f1: 0.7734 - val_loss: 0.4736 - val_f1: 0.1397\n",
      "Epoch 803/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2068 - f1: 0.7768 - val_loss: 0.4741 - val_f1: 0.1394\n",
      "Epoch 804/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2094 - f1: 0.7758 - val_loss: 0.4762 - val_f1: 0.1399\n",
      "Epoch 805/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2085 - f1: 0.7793 - val_loss: 0.4719 - val_f1: 0.1395\n",
      "Epoch 806/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2113 - f1: 0.7754 - val_loss: 0.4711 - val_f1: 0.1404\n",
      "Epoch 807/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2083 - f1: 0.7811 - val_loss: 0.4820 - val_f1: 0.1387\n",
      "Epoch 808/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2099 - f1: 0.7773 - val_loss: 0.4809 - val_f1: 0.1387\n",
      "Epoch 809/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2075 - f1: 0.7784 - val_loss: 0.4805 - val_f1: 0.1392\n",
      "Epoch 810/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2105 - f1: 0.7753 - val_loss: 0.4782 - val_f1: 0.1391\n",
      "Epoch 811/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2069 - f1: 0.7777 - val_loss: 0.4746 - val_f1: 0.1392\n",
      "Epoch 812/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2079 - f1: 0.7804 - val_loss: 0.4784 - val_f1: 0.1388\n",
      "Epoch 813/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2096 - f1: 0.7734 - val_loss: 0.4792 - val_f1: 0.1393\n",
      "Epoch 814/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2099 - f1: 0.7753 - val_loss: 0.4773 - val_f1: 0.1390\n",
      "Epoch 815/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2101 - f1: 0.7782 - val_loss: 0.4772 - val_f1: 0.1382\n",
      "Epoch 816/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2044 - f1: 0.7807 - val_loss: 0.4829 - val_f1: 0.1389\n",
      "Epoch 817/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2118 - f1: 0.7742 - val_loss: 0.4773 - val_f1: 0.1393\n",
      "Epoch 818/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2077 - f1: 0.7750 - val_loss: 0.4789 - val_f1: 0.1397\n",
      "Epoch 819/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2066 - f1: 0.7801 - val_loss: 0.4794 - val_f1: 0.1381\n",
      "Epoch 820/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2080 - f1: 0.7816 - val_loss: 0.4863 - val_f1: 0.1379\n",
      "Epoch 821/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2104 - f1: 0.7784 - val_loss: 0.4778 - val_f1: 0.1384\n",
      "Epoch 822/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2104 - f1: 0.7769 - val_loss: 0.4725 - val_f1: 0.1397\n",
      "Epoch 823/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2079 - f1: 0.7810 - val_loss: 0.4772 - val_f1: 0.1385\n",
      "Epoch 824/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2103 - f1: 0.7730 - val_loss: 0.4765 - val_f1: 0.1379\n",
      "Epoch 825/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2098 - f1: 0.7800 - val_loss: 0.4735 - val_f1: 0.1389\n",
      "Epoch 826/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2105 - f1: 0.7745 - val_loss: 0.4792 - val_f1: 0.1388\n",
      "Epoch 827/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2060 - f1: 0.7818 - val_loss: 0.4762 - val_f1: 0.1388\n",
      "Epoch 828/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2090 - f1: 0.7771 - val_loss: 0.4791 - val_f1: 0.1392\n",
      "Epoch 829/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2100 - f1: 0.7756 - val_loss: 0.4744 - val_f1: 0.1397\n",
      "Epoch 830/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2089 - f1: 0.7779 - val_loss: 0.4766 - val_f1: 0.1393\n",
      "Epoch 831/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2069 - f1: 0.7795 - val_loss: 0.4801 - val_f1: 0.1393\n",
      "Epoch 832/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2055 - f1: 0.7805 - val_loss: 0.4801 - val_f1: 0.1405\n",
      "Epoch 833/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2067 - f1: 0.7790 - val_loss: 0.4772 - val_f1: 0.1398\n",
      "Epoch 834/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2082 - f1: 0.7788 - val_loss: 0.4780 - val_f1: 0.1385\n",
      "Epoch 835/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2088 - f1: 0.7760 - val_loss: 0.4828 - val_f1: 0.1380\n",
      "Epoch 836/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2086 - f1: 0.7822 - val_loss: 0.4876 - val_f1: 0.1370\n",
      "Epoch 837/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2077 - f1: 0.7798 - val_loss: 0.4825 - val_f1: 0.1386\n",
      "Epoch 838/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2070 - f1: 0.7778 - val_loss: 0.4840 - val_f1: 0.1391\n",
      "Epoch 839/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2084 - f1: 0.7792 - val_loss: 0.4779 - val_f1: 0.1398\n",
      "Epoch 840/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2055 - f1: 0.7786 - val_loss: 0.4840 - val_f1: 0.1394\n",
      "Epoch 841/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2075 - f1: 0.7793 - val_loss: 0.4835 - val_f1: 0.1382\n",
      "Epoch 842/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2079 - f1: 0.7791 - val_loss: 0.4835 - val_f1: 0.1386\n",
      "Epoch 843/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2079 - f1: 0.7784 - val_loss: 0.4773 - val_f1: 0.1389\n",
      "Epoch 844/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2063 - f1: 0.7821 - val_loss: 0.4816 - val_f1: 0.1390\n",
      "Epoch 845/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2057 - f1: 0.7807 - val_loss: 0.4806 - val_f1: 0.1390\n",
      "Epoch 846/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2063 - f1: 0.7818 - val_loss: 0.4794 - val_f1: 0.1402\n",
      "Epoch 847/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2093 - f1: 0.7800 - val_loss: 0.4802 - val_f1: 0.1382\n",
      "Epoch 848/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2044 - f1: 0.7847 - val_loss: 0.4878 - val_f1: 0.1388\n",
      "Epoch 849/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2054 - f1: 0.7813 - val_loss: 0.4866 - val_f1: 0.1387\n",
      "Epoch 850/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2052 - f1: 0.7826 - val_loss: 0.4765 - val_f1: 0.1406\n",
      "Epoch 851/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2093 - f1: 0.7785 - val_loss: 0.4728 - val_f1: 0.1398\n",
      "Epoch 852/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2079 - f1: 0.7791 - val_loss: 0.4789 - val_f1: 0.1391\n",
      "Epoch 853/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2066 - f1: 0.7823 - val_loss: 0.4838 - val_f1: 0.1380\n",
      "Epoch 854/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2075 - f1: 0.7822 - val_loss: 0.4845 - val_f1: 0.1384\n",
      "Epoch 855/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2051 - f1: 0.7841 - val_loss: 0.4818 - val_f1: 0.1388\n",
      "Epoch 856/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2061 - f1: 0.7836 - val_loss: 0.4790 - val_f1: 0.1398\n",
      "Epoch 857/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2087 - f1: 0.7788 - val_loss: 0.4731 - val_f1: 0.1389\n",
      "Epoch 858/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2070 - f1: 0.7773 - val_loss: 0.4746 - val_f1: 0.1407\n",
      "Epoch 859/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2061 - f1: 0.7806 - val_loss: 0.4817 - val_f1: 0.1395\n",
      "Epoch 860/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2061 - f1: 0.7840 - val_loss: 0.4898 - val_f1: 0.1369\n",
      "Epoch 861/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2072 - f1: 0.7829 - val_loss: 0.4797 - val_f1: 0.1388\n",
      "Epoch 862/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2076 - f1: 0.7771 - val_loss: 0.4797 - val_f1: 0.1404\n",
      "Epoch 863/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2035 - f1: 0.7852 - val_loss: 0.4791 - val_f1: 0.1399\n",
      "Epoch 864/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2065 - f1: 0.7818 - val_loss: 0.4748 - val_f1: 0.1400\n",
      "Epoch 865/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2036 - f1: 0.7831 - val_loss: 0.4831 - val_f1: 0.1389\n",
      "Epoch 866/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2080 - f1: 0.7782 - val_loss: 0.4736 - val_f1: 0.1398\n",
      "Epoch 867/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2048 - f1: 0.7788 - val_loss: 0.4839 - val_f1: 0.1385\n",
      "Epoch 868/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2043 - f1: 0.7817 - val_loss: 0.4869 - val_f1: 0.1388\n",
      "Epoch 869/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2058 - f1: 0.7795 - val_loss: 0.4778 - val_f1: 0.1393\n",
      "Epoch 870/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2063 - f1: 0.7783 - val_loss: 0.4802 - val_f1: 0.1402\n",
      "Epoch 871/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2070 - f1: 0.7815 - val_loss: 0.4834 - val_f1: 0.1395\n",
      "Epoch 872/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2055 - f1: 0.7829 - val_loss: 0.4907 - val_f1: 0.1380\n",
      "Epoch 873/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2071 - f1: 0.7798 - val_loss: 0.4873 - val_f1: 0.1384\n",
      "Epoch 874/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2045 - f1: 0.7782 - val_loss: 0.4894 - val_f1: 0.1381\n",
      "Epoch 875/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2017 - f1: 0.7865 - val_loss: 0.4847 - val_f1: 0.1399\n",
      "Epoch 876/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2057 - f1: 0.7842 - val_loss: 0.4815 - val_f1: 0.1400\n",
      "Epoch 877/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2030 - f1: 0.7848 - val_loss: 0.4830 - val_f1: 0.1393\n",
      "Epoch 878/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2035 - f1: 0.7883 - val_loss: 0.4858 - val_f1: 0.1392\n",
      "Epoch 879/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2044 - f1: 0.7820 - val_loss: 0.4809 - val_f1: 0.1389\n",
      "Epoch 880/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2032 - f1: 0.7847 - val_loss: 0.4882 - val_f1: 0.1380\n",
      "Epoch 881/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2057 - f1: 0.7792 - val_loss: 0.4805 - val_f1: 0.1401\n",
      "Epoch 882/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2027 - f1: 0.7828 - val_loss: 0.4882 - val_f1: 0.1386\n",
      "Epoch 883/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2050 - f1: 0.7811 - val_loss: 0.4850 - val_f1: 0.1386\n",
      "Epoch 884/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2057 - f1: 0.7775 - val_loss: 0.4778 - val_f1: 0.1393\n",
      "Epoch 885/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2061 - f1: 0.7799 - val_loss: 0.4866 - val_f1: 0.1385\n",
      "Epoch 886/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2085 - f1: 0.7796 - val_loss: 0.4779 - val_f1: 0.1403\n",
      "Epoch 887/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2045 - f1: 0.7830 - val_loss: 0.4875 - val_f1: 0.1382\n",
      "Epoch 888/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2063 - f1: 0.7809 - val_loss: 0.4770 - val_f1: 0.1401\n",
      "Epoch 889/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2023 - f1: 0.7853 - val_loss: 0.4822 - val_f1: 0.1404\n",
      "Epoch 890/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2047 - f1: 0.7834 - val_loss: 0.4852 - val_f1: 0.1400\n",
      "Epoch 891/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2057 - f1: 0.7834 - val_loss: 0.4805 - val_f1: 0.1394\n",
      "Epoch 892/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2037 - f1: 0.7859 - val_loss: 0.4791 - val_f1: 0.1403\n",
      "Epoch 893/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2050 - f1: 0.7877 - val_loss: 0.4938 - val_f1: 0.1375\n",
      "Epoch 894/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2066 - f1: 0.7771 - val_loss: 0.4813 - val_f1: 0.1396\n",
      "Epoch 895/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2028 - f1: 0.7829 - val_loss: 0.4794 - val_f1: 0.1411\n",
      "Epoch 896/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2047 - f1: 0.7849 - val_loss: 0.4921 - val_f1: 0.1380\n",
      "Epoch 897/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2051 - f1: 0.7833 - val_loss: 0.4836 - val_f1: 0.1394\n",
      "Epoch 898/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2049 - f1: 0.7812 - val_loss: 0.4847 - val_f1: 0.1392\n",
      "Epoch 899/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2075 - f1: 0.7803 - val_loss: 0.4800 - val_f1: 0.1393\n",
      "Epoch 900/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2049 - f1: 0.7820 - val_loss: 0.4848 - val_f1: 0.1386\n",
      "Epoch 901/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2063 - f1: 0.7803 - val_loss: 0.4807 - val_f1: 0.1397\n",
      "Epoch 902/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2020 - f1: 0.7863 - val_loss: 0.4879 - val_f1: 0.1388\n",
      "Epoch 903/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2047 - f1: 0.7844 - val_loss: 0.4836 - val_f1: 0.1391\n",
      "Epoch 904/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2041 - f1: 0.7843 - val_loss: 0.4840 - val_f1: 0.1398\n",
      "Epoch 905/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2046 - f1: 0.7789 - val_loss: 0.4885 - val_f1: 0.1388\n",
      "Epoch 906/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2052 - f1: 0.7841 - val_loss: 0.4870 - val_f1: 0.1393\n",
      "Epoch 907/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2039 - f1: 0.7829 - val_loss: 0.4803 - val_f1: 0.1406\n",
      "Epoch 908/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2038 - f1: 0.7841 - val_loss: 0.4879 - val_f1: 0.1381\n",
      "Epoch 909/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2064 - f1: 0.7850 - val_loss: 0.4838 - val_f1: 0.1393\n",
      "Epoch 910/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2015 - f1: 0.7882 - val_loss: 0.4867 - val_f1: 0.1399\n",
      "Epoch 911/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2052 - f1: 0.7828 - val_loss: 0.4851 - val_f1: 0.1395\n",
      "Epoch 912/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2040 - f1: 0.7819 - val_loss: 0.4924 - val_f1: 0.1390\n",
      "Epoch 913/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2037 - f1: 0.7830 - val_loss: 0.4827 - val_f1: 0.1399\n",
      "Epoch 914/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2043 - f1: 0.7823 - val_loss: 0.4834 - val_f1: 0.1398\n",
      "Epoch 915/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2053 - f1: 0.7814 - val_loss: 0.4843 - val_f1: 0.1395\n",
      "Epoch 916/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2034 - f1: 0.7867 - val_loss: 0.4821 - val_f1: 0.1395\n",
      "Epoch 917/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2041 - f1: 0.7858 - val_loss: 0.4845 - val_f1: 0.1392\n",
      "Epoch 918/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2044 - f1: 0.7796 - val_loss: 0.4801 - val_f1: 0.1391\n",
      "Epoch 919/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2049 - f1: 0.7802 - val_loss: 0.4801 - val_f1: 0.1391\n",
      "Epoch 920/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2049 - f1: 0.7811 - val_loss: 0.4871 - val_f1: 0.1393\n",
      "Epoch 921/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1987 - f1: 0.7898 - val_loss: 0.4888 - val_f1: 0.1399\n",
      "Epoch 922/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2049 - f1: 0.7800 - val_loss: 0.4799 - val_f1: 0.1392\n",
      "Epoch 923/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2037 - f1: 0.7825 - val_loss: 0.4842 - val_f1: 0.1394\n",
      "Epoch 924/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2050 - f1: 0.7857 - val_loss: 0.4770 - val_f1: 0.1405\n",
      "Epoch 925/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2017 - f1: 0.7851 - val_loss: 0.4854 - val_f1: 0.1388\n",
      "Epoch 926/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2022 - f1: 0.7835 - val_loss: 0.4861 - val_f1: 0.1396\n",
      "Epoch 927/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2015 - f1: 0.7830 - val_loss: 0.4842 - val_f1: 0.1403\n",
      "Epoch 928/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2021 - f1: 0.7860 - val_loss: 0.4862 - val_f1: 0.1396\n",
      "Epoch 929/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2042 - f1: 0.7842 - val_loss: 0.4822 - val_f1: 0.1402\n",
      "Epoch 930/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2029 - f1: 0.7839 - val_loss: 0.4787 - val_f1: 0.1394\n",
      "Epoch 931/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2027 - f1: 0.7872 - val_loss: 0.4859 - val_f1: 0.1395\n",
      "Epoch 932/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2023 - f1: 0.7863 - val_loss: 0.4871 - val_f1: 0.1387\n",
      "Epoch 933/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2013 - f1: 0.7866 - val_loss: 0.4873 - val_f1: 0.1389\n",
      "Epoch 934/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2017 - f1: 0.7854 - val_loss: 0.4868 - val_f1: 0.1398\n",
      "Epoch 935/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2038 - f1: 0.7855 - val_loss: 0.4837 - val_f1: 0.1393\n",
      "Epoch 936/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2035 - f1: 0.7867 - val_loss: 0.4846 - val_f1: 0.1391\n",
      "Epoch 937/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2037 - f1: 0.7836 - val_loss: 0.4873 - val_f1: 0.1378\n",
      "Epoch 938/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2042 - f1: 0.7811 - val_loss: 0.4777 - val_f1: 0.1401\n",
      "Epoch 939/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2021 - f1: 0.7825 - val_loss: 0.4913 - val_f1: 0.1388\n",
      "Epoch 940/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2052 - f1: 0.7827 - val_loss: 0.4936 - val_f1: 0.1389\n",
      "Epoch 941/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2009 - f1: 0.7855 - val_loss: 0.4894 - val_f1: 0.1389\n",
      "Epoch 942/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2026 - f1: 0.7892 - val_loss: 0.4824 - val_f1: 0.1395\n",
      "Epoch 943/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2025 - f1: 0.7866 - val_loss: 0.4869 - val_f1: 0.1395\n",
      "Epoch 944/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2028 - f1: 0.7867 - val_loss: 0.4931 - val_f1: 0.1380\n",
      "Epoch 945/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2032 - f1: 0.7867 - val_loss: 0.4820 - val_f1: 0.1401\n",
      "Epoch 946/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2007 - f1: 0.7868 - val_loss: 0.4925 - val_f1: 0.1392\n",
      "Epoch 947/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2015 - f1: 0.7837 - val_loss: 0.4906 - val_f1: 0.1393\n",
      "Epoch 948/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2033 - f1: 0.7835 - val_loss: 0.4774 - val_f1: 0.1408\n",
      "Epoch 949/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1993 - f1: 0.7878 - val_loss: 0.4887 - val_f1: 0.1401\n",
      "Epoch 950/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2026 - f1: 0.7852 - val_loss: 0.4857 - val_f1: 0.1399\n",
      "Epoch 951/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2004 - f1: 0.7898 - val_loss: 0.4904 - val_f1: 0.1399\n",
      "Epoch 952/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2018 - f1: 0.7878 - val_loss: 0.4820 - val_f1: 0.1393\n",
      "Epoch 953/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2026 - f1: 0.7882 - val_loss: 0.4903 - val_f1: 0.1386\n",
      "Epoch 954/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2036 - f1: 0.7838 - val_loss: 0.4835 - val_f1: 0.1391\n",
      "Epoch 955/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1993 - f1: 0.7926 - val_loss: 0.4903 - val_f1: 0.1383\n",
      "Epoch 956/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1991 - f1: 0.7872 - val_loss: 0.4821 - val_f1: 0.1400\n",
      "Epoch 957/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1984 - f1: 0.7920 - val_loss: 0.4839 - val_f1: 0.1393\n",
      "Epoch 958/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1974 - f1: 0.7939 - val_loss: 0.4952 - val_f1: 0.1391\n",
      "Epoch 959/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2035 - f1: 0.7849 - val_loss: 0.4886 - val_f1: 0.1395\n",
      "Epoch 960/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2017 - f1: 0.7880 - val_loss: 0.4858 - val_f1: 0.1386\n",
      "Epoch 961/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2010 - f1: 0.7891 - val_loss: 0.4821 - val_f1: 0.1405\n",
      "Epoch 962/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2014 - f1: 0.7857 - val_loss: 0.4899 - val_f1: 0.1395\n",
      "Epoch 963/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2010 - f1: 0.7908 - val_loss: 0.4820 - val_f1: 0.1405\n",
      "Epoch 964/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2018 - f1: 0.7836 - val_loss: 0.4863 - val_f1: 0.1401\n",
      "Epoch 965/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2024 - f1: 0.7865 - val_loss: 0.4832 - val_f1: 0.1395\n",
      "Epoch 966/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2014 - f1: 0.7831 - val_loss: 0.4870 - val_f1: 0.1389\n",
      "Epoch 967/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2008 - f1: 0.7862 - val_loss: 0.4907 - val_f1: 0.1396\n",
      "Epoch 968/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2031 - f1: 0.7846 - val_loss: 0.4888 - val_f1: 0.1387\n",
      "Epoch 969/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1983 - f1: 0.7902 - val_loss: 0.4866 - val_f1: 0.1392\n",
      "Epoch 970/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2036 - f1: 0.7870 - val_loss: 0.4831 - val_f1: 0.1388\n",
      "Epoch 971/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2004 - f1: 0.7910 - val_loss: 0.4836 - val_f1: 0.1397\n",
      "Epoch 972/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2023 - f1: 0.7894 - val_loss: 0.4823 - val_f1: 0.1393\n",
      "Epoch 973/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2012 - f1: 0.7814 - val_loss: 0.4869 - val_f1: 0.1394\n",
      "Epoch 974/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2005 - f1: 0.7896 - val_loss: 0.4890 - val_f1: 0.1403\n",
      "Epoch 975/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2000 - f1: 0.7866 - val_loss: 0.4843 - val_f1: 0.1399\n",
      "Epoch 976/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1996 - f1: 0.7869 - val_loss: 0.5017 - val_f1: 0.1383\n",
      "Epoch 977/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2000 - f1: 0.7854 - val_loss: 0.4881 - val_f1: 0.1389\n",
      "Epoch 978/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2011 - f1: 0.7829 - val_loss: 0.4881 - val_f1: 0.1394\n",
      "Epoch 979/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2024 - f1: 0.7842 - val_loss: 0.4876 - val_f1: 0.1388\n",
      "Epoch 980/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2003 - f1: 0.7890 - val_loss: 0.4900 - val_f1: 0.1389\n",
      "Epoch 981/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2016 - f1: 0.7904 - val_loss: 0.4869 - val_f1: 0.1392\n",
      "Epoch 982/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2030 - f1: 0.7841 - val_loss: 0.4775 - val_f1: 0.1406\n",
      "Epoch 983/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1989 - f1: 0.7882 - val_loss: 0.4912 - val_f1: 0.1383\n",
      "Epoch 984/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1993 - f1: 0.7896 - val_loss: 0.4890 - val_f1: 0.1398\n",
      "Epoch 985/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1985 - f1: 0.7934 - val_loss: 0.4966 - val_f1: 0.1389\n",
      "Epoch 986/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1976 - f1: 0.7919 - val_loss: 0.4852 - val_f1: 0.1400\n",
      "Epoch 987/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1997 - f1: 0.7871 - val_loss: 0.4863 - val_f1: 0.1396\n",
      "Epoch 988/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2010 - f1: 0.7876 - val_loss: 0.4933 - val_f1: 0.1393\n",
      "Epoch 989/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1997 - f1: 0.7911 - val_loss: 0.4871 - val_f1: 0.1393\n",
      "Epoch 990/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2002 - f1: 0.7904 - val_loss: 0.4872 - val_f1: 0.1395\n",
      "Epoch 991/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1989 - f1: 0.7876 - val_loss: 0.4837 - val_f1: 0.1402\n",
      "Epoch 992/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2004 - f1: 0.7849 - val_loss: 0.4827 - val_f1: 0.1404\n",
      "Epoch 993/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1997 - f1: 0.7874 - val_loss: 0.4860 - val_f1: 0.1407\n",
      "Epoch 994/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1982 - f1: 0.7885 - val_loss: 0.4867 - val_f1: 0.1404\n",
      "Epoch 995/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1962 - f1: 0.7929 - val_loss: 0.4960 - val_f1: 0.1397\n",
      "Epoch 996/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1982 - f1: 0.7897 - val_loss: 0.4961 - val_f1: 0.1390\n",
      "Epoch 997/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2001 - f1: 0.7873 - val_loss: 0.4898 - val_f1: 0.1394\n",
      "Epoch 998/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2021 - f1: 0.7872 - val_loss: 0.4920 - val_f1: 0.1381\n",
      "Epoch 999/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2006 - f1: 0.7905 - val_loss: 0.4838 - val_f1: 0.1393\n",
      "Epoch 1000/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1988 - f1: 0.7889 - val_loss: 0.4931 - val_f1: 0.1402\n",
      "Epoch 1001/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2000 - f1: 0.7884 - val_loss: 0.4935 - val_f1: 0.1382\n",
      "Epoch 1002/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1984 - f1: 0.7874 - val_loss: 0.4888 - val_f1: 0.1401\n",
      "Epoch 1003/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1990 - f1: 0.7917 - val_loss: 0.4880 - val_f1: 0.1388\n",
      "Epoch 1004/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1990 - f1: 0.7913 - val_loss: 0.4968 - val_f1: 0.1380\n",
      "Epoch 1005/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1984 - f1: 0.7920 - val_loss: 0.4938 - val_f1: 0.1393\n",
      "Epoch 1006/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1984 - f1: 0.7906 - val_loss: 0.4885 - val_f1: 0.1396\n",
      "Epoch 1007/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2001 - f1: 0.7891 - val_loss: 0.4854 - val_f1: 0.1405\n",
      "Epoch 1008/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2022 - f1: 0.7850 - val_loss: 0.4843 - val_f1: 0.1395\n",
      "Epoch 1009/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1986 - f1: 0.7893 - val_loss: 0.4902 - val_f1: 0.1397\n",
      "Epoch 1010/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1981 - f1: 0.7908 - val_loss: 0.4934 - val_f1: 0.1387\n",
      "Epoch 1011/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1979 - f1: 0.7927 - val_loss: 0.4839 - val_f1: 0.1398\n",
      "Epoch 1012/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1981 - f1: 0.7866 - val_loss: 0.4843 - val_f1: 0.1392\n",
      "Epoch 1013/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1988 - f1: 0.7919 - val_loss: 0.4872 - val_f1: 0.1395\n",
      "Epoch 1014/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1991 - f1: 0.7904 - val_loss: 0.4839 - val_f1: 0.1397\n",
      "Epoch 1015/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1975 - f1: 0.7928 - val_loss: 0.4938 - val_f1: 0.1399\n",
      "Epoch 1016/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1966 - f1: 0.7924 - val_loss: 0.4906 - val_f1: 0.1411\n",
      "Epoch 1017/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1998 - f1: 0.7881 - val_loss: 0.4840 - val_f1: 0.1400\n",
      "Epoch 1018/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2002 - f1: 0.7856 - val_loss: 0.4845 - val_f1: 0.1402\n",
      "Epoch 1019/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1975 - f1: 0.7910 - val_loss: 0.4865 - val_f1: 0.1393\n",
      "Epoch 1020/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2005 - f1: 0.7891 - val_loss: 0.4969 - val_f1: 0.1377\n",
      "Epoch 1021/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1991 - f1: 0.7883 - val_loss: 0.4933 - val_f1: 0.1391\n",
      "Epoch 1022/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1974 - f1: 0.7895 - val_loss: 0.4909 - val_f1: 0.1386\n",
      "Epoch 1023/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1975 - f1: 0.7889 - val_loss: 0.4876 - val_f1: 0.1402\n",
      "Epoch 1024/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1982 - f1: 0.7902 - val_loss: 0.4950 - val_f1: 0.1382\n",
      "Epoch 1025/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1969 - f1: 0.7910 - val_loss: 0.4948 - val_f1: 0.1380\n",
      "Epoch 1026/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1970 - f1: 0.7933 - val_loss: 0.4941 - val_f1: 0.1386\n",
      "Epoch 1027/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1987 - f1: 0.7934 - val_loss: 0.4934 - val_f1: 0.1390\n",
      "Epoch 1028/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1994 - f1: 0.7885 - val_loss: 0.4925 - val_f1: 0.1382\n",
      "Epoch 1029/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1994 - f1: 0.7894 - val_loss: 0.4978 - val_f1: 0.1379\n",
      "Epoch 1030/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2002 - f1: 0.7859 - val_loss: 0.4910 - val_f1: 0.1389\n",
      "Epoch 1031/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1966 - f1: 0.7927 - val_loss: 0.4983 - val_f1: 0.1389\n",
      "Epoch 1032/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1946 - f1: 0.7939 - val_loss: 0.5032 - val_f1: 0.1380\n",
      "Epoch 1033/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1977 - f1: 0.7923 - val_loss: 0.4926 - val_f1: 0.1388\n",
      "Epoch 1034/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1987 - f1: 0.7908 - val_loss: 0.4890 - val_f1: 0.1395\n",
      "Epoch 1035/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1992 - f1: 0.7927 - val_loss: 0.4918 - val_f1: 0.1386\n",
      "Epoch 1036/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1958 - f1: 0.7939 - val_loss: 0.4941 - val_f1: 0.1386\n",
      "Epoch 1037/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1990 - f1: 0.7868 - val_loss: 0.4915 - val_f1: 0.1393\n",
      "Epoch 1038/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1980 - f1: 0.7923 - val_loss: 0.4911 - val_f1: 0.1391\n",
      "Epoch 1039/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1985 - f1: 0.7892 - val_loss: 0.4895 - val_f1: 0.1391\n",
      "Epoch 1040/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1973 - f1: 0.7907 - val_loss: 0.4934 - val_f1: 0.1392\n",
      "Epoch 1041/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1968 - f1: 0.7916 - val_loss: 0.4914 - val_f1: 0.1399\n",
      "Epoch 1042/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1993 - f1: 0.7898 - val_loss: 0.4944 - val_f1: 0.1395\n",
      "Epoch 1043/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1974 - f1: 0.7903 - val_loss: 0.4908 - val_f1: 0.1392\n",
      "Epoch 1044/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1983 - f1: 0.7892 - val_loss: 0.5003 - val_f1: 0.1375\n",
      "Epoch 1045/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1962 - f1: 0.7959 - val_loss: 0.4935 - val_f1: 0.1390\n",
      "Epoch 1046/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1987 - f1: 0.7887 - val_loss: 0.4964 - val_f1: 0.1387\n",
      "Epoch 1047/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1971 - f1: 0.7885 - val_loss: 0.4883 - val_f1: 0.1398\n",
      "Epoch 1048/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.1974 - f1: 0.7890 - val_loss: 0.4880 - val_f1: 0.1399\n",
      "Epoch 1049/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1969 - f1: 0.7928 - val_loss: 0.4943 - val_f1: 0.1395\n",
      "Epoch 1050/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1932 - f1: 0.7987 - val_loss: 0.4918 - val_f1: 0.1390\n",
      "Epoch 1051/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1975 - f1: 0.7921 - val_loss: 0.5026 - val_f1: 0.1377\n",
      "Epoch 1052/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1983 - f1: 0.7906 - val_loss: 0.4923 - val_f1: 0.1389\n",
      "Epoch 1053/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1986 - f1: 0.7946 - val_loss: 0.4901 - val_f1: 0.1391\n",
      "Epoch 1054/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1978 - f1: 0.7918 - val_loss: 0.4895 - val_f1: 0.1392\n",
      "Epoch 1055/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1978 - f1: 0.7931 - val_loss: 0.4860 - val_f1: 0.1405\n",
      "Epoch 1056/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1980 - f1: 0.7923 - val_loss: 0.4915 - val_f1: 0.1383\n",
      "Epoch 1057/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1950 - f1: 0.7973 - val_loss: 0.4978 - val_f1: 0.1385\n",
      "Epoch 1058/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1960 - f1: 0.7905 - val_loss: 0.4919 - val_f1: 0.1394\n",
      "Epoch 1059/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1969 - f1: 0.7951 - val_loss: 0.4928 - val_f1: 0.1388\n",
      "Epoch 1060/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1959 - f1: 0.7893 - val_loss: 0.4966 - val_f1: 0.1394\n",
      "Epoch 1061/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1952 - f1: 0.7955 - val_loss: 0.4939 - val_f1: 0.1386\n",
      "Epoch 1062/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1951 - f1: 0.7958 - val_loss: 0.4953 - val_f1: 0.1389\n",
      "Epoch 1063/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1983 - f1: 0.7907 - val_loss: 0.4917 - val_f1: 0.1392\n",
      "Epoch 1064/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1996 - f1: 0.7905 - val_loss: 0.4931 - val_f1: 0.1392\n",
      "Epoch 1065/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1947 - f1: 0.7936 - val_loss: 0.4922 - val_f1: 0.1395\n",
      "Epoch 1066/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1970 - f1: 0.7946 - val_loss: 0.4888 - val_f1: 0.1391\n",
      "Epoch 1067/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1947 - f1: 0.7936 - val_loss: 0.4982 - val_f1: 0.1389\n",
      "Epoch 1068/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1952 - f1: 0.7938 - val_loss: 0.4977 - val_f1: 0.1390\n",
      "Epoch 1069/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1945 - f1: 0.7949 - val_loss: 0.5091 - val_f1: 0.1370\n",
      "Epoch 1070/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1958 - f1: 0.7914 - val_loss: 0.4936 - val_f1: 0.1389\n",
      "Epoch 1071/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1981 - f1: 0.7905 - val_loss: 0.4904 - val_f1: 0.1389\n",
      "Epoch 1072/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1984 - f1: 0.7930 - val_loss: 0.5008 - val_f1: 0.1383\n",
      "Epoch 1073/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1966 - f1: 0.7884 - val_loss: 0.4927 - val_f1: 0.1393\n",
      "Epoch 1074/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1961 - f1: 0.7926 - val_loss: 0.4967 - val_f1: 0.1391\n",
      "Epoch 1075/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1944 - f1: 0.7960 - val_loss: 0.5009 - val_f1: 0.1387\n",
      "Epoch 1076/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1943 - f1: 0.7947 - val_loss: 0.5008 - val_f1: 0.1391\n",
      "Epoch 1077/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1980 - f1: 0.7895 - val_loss: 0.4938 - val_f1: 0.1382\n",
      "Epoch 1078/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1974 - f1: 0.7936 - val_loss: 0.4950 - val_f1: 0.1386\n",
      "Epoch 1079/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1971 - f1: 0.7913 - val_loss: 0.4875 - val_f1: 0.1403\n",
      "Epoch 1080/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1954 - f1: 0.7932 - val_loss: 0.4963 - val_f1: 0.1392\n",
      "Epoch 1081/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1928 - f1: 0.7959 - val_loss: 0.5021 - val_f1: 0.1387\n",
      "Epoch 1082/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1949 - f1: 0.7940 - val_loss: 0.4870 - val_f1: 0.1392\n",
      "Epoch 1083/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1965 - f1: 0.7935 - val_loss: 0.4886 - val_f1: 0.1395\n",
      "Epoch 1084/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1956 - f1: 0.7968 - val_loss: 0.4983 - val_f1: 0.1391\n",
      "Epoch 1085/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1953 - f1: 0.7939 - val_loss: 0.4976 - val_f1: 0.1381\n",
      "Epoch 1086/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1953 - f1: 0.7908 - val_loss: 0.4928 - val_f1: 0.1384\n",
      "Epoch 1087/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1945 - f1: 0.7944 - val_loss: 0.5016 - val_f1: 0.1380\n",
      "Epoch 1088/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1969 - f1: 0.7930 - val_loss: 0.4862 - val_f1: 0.1401\n",
      "Epoch 1089/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1975 - f1: 0.7907 - val_loss: 0.4903 - val_f1: 0.1387\n",
      "Epoch 1090/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1959 - f1: 0.7912 - val_loss: 0.4995 - val_f1: 0.1381\n",
      "Epoch 1091/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1963 - f1: 0.7888 - val_loss: 0.4949 - val_f1: 0.1388\n",
      "Epoch 1092/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1974 - f1: 0.7963 - val_loss: 0.4980 - val_f1: 0.1394\n",
      "Epoch 1093/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1971 - f1: 0.7906 - val_loss: 0.4897 - val_f1: 0.1404\n",
      "Epoch 1094/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1985 - f1: 0.7906 - val_loss: 0.4920 - val_f1: 0.1381\n",
      "Epoch 1095/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1961 - f1: 0.7960 - val_loss: 0.4885 - val_f1: 0.1390\n",
      "Epoch 1096/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1932 - f1: 0.7966 - val_loss: 0.5055 - val_f1: 0.1389\n",
      "Epoch 1097/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1964 - f1: 0.7937 - val_loss: 0.4981 - val_f1: 0.1385\n",
      "Epoch 1098/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1951 - f1: 0.7960 - val_loss: 0.4961 - val_f1: 0.1390\n",
      "Epoch 1099/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1930 - f1: 0.7954 - val_loss: 0.4982 - val_f1: 0.1389\n",
      "Epoch 1100/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1960 - f1: 0.7967 - val_loss: 0.5023 - val_f1: 0.1387\n",
      "Epoch 1101/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1938 - f1: 0.7974 - val_loss: 0.4955 - val_f1: 0.1392\n",
      "Epoch 1102/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1923 - f1: 0.7975 - val_loss: 0.5032 - val_f1: 0.1386\n",
      "Epoch 1103/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1947 - f1: 0.7972 - val_loss: 0.4995 - val_f1: 0.1378\n",
      "Epoch 1104/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1968 - f1: 0.7905 - val_loss: 0.4983 - val_f1: 0.1381\n",
      "Epoch 1105/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1964 - f1: 0.7930 - val_loss: 0.4898 - val_f1: 0.1393\n",
      "Epoch 1106/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1918 - f1: 0.7999 - val_loss: 0.4988 - val_f1: 0.1387\n",
      "Epoch 1107/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1956 - f1: 0.7951 - val_loss: 0.5010 - val_f1: 0.1386\n",
      "Epoch 1108/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1953 - f1: 0.7951 - val_loss: 0.4889 - val_f1: 0.1399\n",
      "Epoch 1109/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1966 - f1: 0.7947 - val_loss: 0.4969 - val_f1: 0.1391\n",
      "Epoch 1110/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1956 - f1: 0.7929 - val_loss: 0.4944 - val_f1: 0.1399\n",
      "Epoch 1111/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1951 - f1: 0.7950 - val_loss: 0.4880 - val_f1: 0.1395\n",
      "Epoch 1112/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1932 - f1: 0.7962 - val_loss: 0.5000 - val_f1: 0.1392\n",
      "Epoch 1113/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1942 - f1: 0.7936 - val_loss: 0.5049 - val_f1: 0.1382\n",
      "Epoch 1114/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1949 - f1: 0.7925 - val_loss: 0.4898 - val_f1: 0.1400\n",
      "Epoch 1115/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1942 - f1: 0.7963 - val_loss: 0.4947 - val_f1: 0.1387\n",
      "Epoch 1116/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1961 - f1: 0.7967 - val_loss: 0.4844 - val_f1: 0.1403\n",
      "Epoch 1117/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1938 - f1: 0.7971 - val_loss: 0.4922 - val_f1: 0.1388\n",
      "Epoch 1118/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1959 - f1: 0.7940 - val_loss: 0.5029 - val_f1: 0.1380\n",
      "Epoch 1119/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1937 - f1: 0.7980 - val_loss: 0.4913 - val_f1: 0.1396\n",
      "Epoch 1120/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1977 - f1: 0.7910 - val_loss: 0.4906 - val_f1: 0.1392\n",
      "Epoch 1121/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1948 - f1: 0.7907 - val_loss: 0.4965 - val_f1: 0.1377\n",
      "Epoch 1122/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1942 - f1: 0.7938 - val_loss: 0.4986 - val_f1: 0.1379\n",
      "Epoch 1123/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1931 - f1: 0.7957 - val_loss: 0.4970 - val_f1: 0.1384\n",
      "Epoch 1124/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1932 - f1: 0.7984 - val_loss: 0.4997 - val_f1: 0.1381\n",
      "Epoch 1125/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1924 - f1: 0.7968 - val_loss: 0.4974 - val_f1: 0.1382\n",
      "Epoch 1126/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1946 - f1: 0.7991 - val_loss: 0.4966 - val_f1: 0.1393\n",
      "Epoch 1127/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1948 - f1: 0.7932 - val_loss: 0.4943 - val_f1: 0.1390\n",
      "Epoch 1128/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1936 - f1: 0.7957 - val_loss: 0.5024 - val_f1: 0.1393\n",
      "Epoch 1129/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1964 - f1: 0.7919 - val_loss: 0.4992 - val_f1: 0.1385\n",
      "Epoch 1130/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1938 - f1: 0.7956 - val_loss: 0.4908 - val_f1: 0.1401\n",
      "Epoch 1131/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1934 - f1: 0.7945 - val_loss: 0.4960 - val_f1: 0.1396\n",
      "Epoch 1132/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1943 - f1: 0.7980 - val_loss: 0.4959 - val_f1: 0.1381\n",
      "Epoch 1133/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1948 - f1: 0.7923 - val_loss: 0.4943 - val_f1: 0.1394\n",
      "Epoch 1134/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1937 - f1: 0.7996 - val_loss: 0.5009 - val_f1: 0.1387\n",
      "Epoch 1135/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1951 - f1: 0.7933 - val_loss: 0.4921 - val_f1: 0.1393\n",
      "Epoch 1136/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1911 - f1: 0.7964 - val_loss: 0.4937 - val_f1: 0.1390\n",
      "Epoch 1137/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1949 - f1: 0.7980 - val_loss: 0.4945 - val_f1: 0.1391\n",
      "Epoch 1138/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1963 - f1: 0.7951 - val_loss: 0.4942 - val_f1: 0.1394\n",
      "Epoch 1139/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1923 - f1: 0.7985 - val_loss: 0.4999 - val_f1: 0.1388\n",
      "Epoch 1140/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1937 - f1: 0.7985 - val_loss: 0.4978 - val_f1: 0.1387\n",
      "Epoch 1141/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1933 - f1: 0.7965 - val_loss: 0.4952 - val_f1: 0.1387\n",
      "Epoch 1142/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1951 - f1: 0.7924 - val_loss: 0.4949 - val_f1: 0.1383\n",
      "Epoch 1143/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1915 - f1: 0.7972 - val_loss: 0.4999 - val_f1: 0.1397\n",
      "Epoch 1144/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1963 - f1: 0.7939 - val_loss: 0.4899 - val_f1: 0.1400\n",
      "Epoch 1145/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1921 - f1: 0.7958 - val_loss: 0.5001 - val_f1: 0.1374\n",
      "Epoch 1146/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1945 - f1: 0.7950 - val_loss: 0.4953 - val_f1: 0.1384\n",
      "Epoch 1147/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.1959 - f1: 0.7904 - val_loss: 0.4948 - val_f1: 0.1391\n",
      "Epoch 1148/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.1931 - f1: 0.7955 - val_loss: 0.5040 - val_f1: 0.1378\n",
      "Epoch 1149/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.1938 - f1: 0.7957 - val_loss: 0.5021 - val_f1: 0.1377\n",
      "Epoch 1150/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1924 - f1: 0.7984 - val_loss: 0.4985 - val_f1: 0.1381\n",
      "Epoch 1151/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1890 - f1: 0.7993 - val_loss: 0.5051 - val_f1: 0.1377\n",
      "Epoch 1152/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1936 - f1: 0.7968 - val_loss: 0.5056 - val_f1: 0.1386\n",
      "Epoch 1153/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1916 - f1: 0.7980 - val_loss: 0.5056 - val_f1: 0.1375\n",
      "Epoch 1154/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1923 - f1: 0.7955 - val_loss: 0.4948 - val_f1: 0.1385\n",
      "Epoch 1155/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1942 - f1: 0.7929 - val_loss: 0.4996 - val_f1: 0.1389\n",
      "Epoch 1156/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1949 - f1: 0.7955 - val_loss: 0.4939 - val_f1: 0.1388\n",
      "Epoch 1157/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1925 - f1: 0.8004 - val_loss: 0.5052 - val_f1: 0.1379\n",
      "Epoch 1158/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1936 - f1: 0.7998 - val_loss: 0.4931 - val_f1: 0.1395\n",
      "Epoch 1159/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1958 - f1: 0.7963 - val_loss: 0.4920 - val_f1: 0.1394\n",
      "Epoch 1160/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1939 - f1: 0.7958 - val_loss: 0.4917 - val_f1: 0.1397\n",
      "Epoch 1161/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1893 - f1: 0.8011 - val_loss: 0.5015 - val_f1: 0.1391\n",
      "Epoch 1162/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1937 - f1: 0.7956 - val_loss: 0.4936 - val_f1: 0.1396\n",
      "Epoch 1163/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1918 - f1: 0.8000 - val_loss: 0.4980 - val_f1: 0.1394\n",
      "Epoch 1164/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.1938 - f1: 0.7977 - val_loss: 0.4973 - val_f1: 0.1395\n",
      "Epoch 1165/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1892 - f1: 0.8011 - val_loss: 0.5065 - val_f1: 0.1378\n",
      "Epoch 1166/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1943 - f1: 0.7937 - val_loss: 0.5020 - val_f1: 0.1394\n",
      "Epoch 1167/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1930 - f1: 0.7950 - val_loss: 0.4945 - val_f1: 0.1391\n",
      "Epoch 1168/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1963 - f1: 0.7933 - val_loss: 0.4931 - val_f1: 0.1387\n",
      "Epoch 1169/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.1965 - f1: 0.7949 - val_loss: 0.4955 - val_f1: 0.1384\n",
      "Epoch 1170/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1932 - f1: 0.7959 - val_loss: 0.5011 - val_f1: 0.1381\n",
      "Epoch 1171/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1938 - f1: 0.7932 - val_loss: 0.4964 - val_f1: 0.1400\n",
      "Epoch 1172/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1914 - f1: 0.7972 - val_loss: 0.4967 - val_f1: 0.1386\n",
      "Epoch 1173/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.1909 - f1: 0.8024 - val_loss: 0.5072 - val_f1: 0.1380\n",
      "Epoch 1174/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1912 - f1: 0.8003 - val_loss: 0.4985 - val_f1: 0.1393\n",
      "Epoch 1175/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1941 - f1: 0.7976 - val_loss: 0.4989 - val_f1: 0.1390\n",
      "Epoch 1176/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1916 - f1: 0.7988 - val_loss: 0.5077 - val_f1: 0.1379\n",
      "Epoch 1177/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.1941 - f1: 0.7978 - val_loss: 0.4935 - val_f1: 0.1398\n",
      "Epoch 1178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1896 - f1: 0.7972 - val_loss: 0.4990 - val_f1: 0.1387\n",
      "Epoch 1179/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1909 - f1: 0.7960 - val_loss: 0.5018 - val_f1: 0.1386\n",
      "Epoch 1180/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1941 - f1: 0.7922 - val_loss: 0.5060 - val_f1: 0.1378\n",
      "Epoch 1181/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1938 - f1: 0.7976 - val_loss: 0.4989 - val_f1: 0.1383\n",
      "Epoch 1182/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1916 - f1: 0.7983 - val_loss: 0.5029 - val_f1: 0.1378\n",
      "Epoch 1183/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1927 - f1: 0.7982 - val_loss: 0.4999 - val_f1: 0.1378\n",
      "Epoch 1184/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1929 - f1: 0.7979 - val_loss: 0.5055 - val_f1: 0.1380\n",
      "Epoch 1185/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1909 - f1: 0.8004 - val_loss: 0.4985 - val_f1: 0.1384\n",
      "Epoch 1186/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1913 - f1: 0.7997 - val_loss: 0.5026 - val_f1: 0.1383\n",
      "Epoch 1187/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1932 - f1: 0.7947 - val_loss: 0.5007 - val_f1: 0.1397\n",
      "Epoch 1188/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1937 - f1: 0.7989 - val_loss: 0.5020 - val_f1: 0.1391\n",
      "Epoch 1189/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1910 - f1: 0.8001 - val_loss: 0.5011 - val_f1: 0.1383\n",
      "Epoch 1190/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1925 - f1: 0.7957 - val_loss: 0.4972 - val_f1: 0.1390\n",
      "Epoch 1191/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1918 - f1: 0.7964 - val_loss: 0.4893 - val_f1: 0.1402\n",
      "Epoch 1192/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1914 - f1: 0.8022 - val_loss: 0.4985 - val_f1: 0.1382\n",
      "Epoch 1193/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1936 - f1: 0.7990 - val_loss: 0.5061 - val_f1: 0.1371\n",
      "Epoch 1194/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1907 - f1: 0.7968 - val_loss: 0.5034 - val_f1: 0.1387\n",
      "Epoch 1195/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1907 - f1: 0.8009 - val_loss: 0.5049 - val_f1: 0.1379\n",
      "Epoch 1196/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1918 - f1: 0.7995 - val_loss: 0.5052 - val_f1: 0.1386\n",
      "Epoch 1197/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1906 - f1: 0.8008 - val_loss: 0.4968 - val_f1: 0.1395\n",
      "Epoch 1198/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1908 - f1: 0.7968 - val_loss: 0.4991 - val_f1: 0.1389\n",
      "Epoch 1199/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1917 - f1: 0.7985 - val_loss: 0.5073 - val_f1: 0.1386\n",
      "Epoch 1200/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1869 - f1: 0.8054 - val_loss: 0.4996 - val_f1: 0.1393\n",
      "Epoch 1201/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1929 - f1: 0.8015 - val_loss: 0.5007 - val_f1: 0.1393\n",
      "Epoch 1202/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1913 - f1: 0.7986 - val_loss: 0.5013 - val_f1: 0.1395\n",
      "Epoch 1203/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1919 - f1: 0.8016 - val_loss: 0.4955 - val_f1: 0.1379\n",
      "Epoch 1204/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1920 - f1: 0.8001 - val_loss: 0.4941 - val_f1: 0.1397\n",
      "Epoch 1205/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1910 - f1: 0.7979 - val_loss: 0.5069 - val_f1: 0.1386\n",
      "Epoch 1206/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1905 - f1: 0.7970 - val_loss: 0.5017 - val_f1: 0.1390\n",
      "Epoch 1207/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1914 - f1: 0.7965 - val_loss: 0.4956 - val_f1: 0.1390\n",
      "Epoch 1208/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1927 - f1: 0.7981 - val_loss: 0.4964 - val_f1: 0.1386\n",
      "Epoch 1209/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1916 - f1: 0.7991 - val_loss: 0.5037 - val_f1: 0.1387\n",
      "Epoch 1210/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1919 - f1: 0.7962 - val_loss: 0.4968 - val_f1: 0.1399\n",
      "Epoch 1211/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1874 - f1: 0.8028 - val_loss: 0.5028 - val_f1: 0.1390\n",
      "Epoch 1212/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1913 - f1: 0.7982 - val_loss: 0.5102 - val_f1: 0.1378\n",
      "Epoch 1213/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1912 - f1: 0.7972 - val_loss: 0.5054 - val_f1: 0.1380\n",
      "Epoch 1214/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1898 - f1: 0.8001 - val_loss: 0.5026 - val_f1: 0.1390\n",
      "Epoch 1215/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1919 - f1: 0.7992 - val_loss: 0.5048 - val_f1: 0.1382\n",
      "Epoch 1216/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.1920 - f1: 0.7992 - val_loss: 0.5062 - val_f1: 0.1375\n",
      "Epoch 1217/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1931 - f1: 0.7961 - val_loss: 0.5035 - val_f1: 0.1385\n",
      "Epoch 1218/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1907 - f1: 0.8019 - val_loss: 0.5015 - val_f1: 0.1383\n",
      "Epoch 1219/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1906 - f1: 0.8004 - val_loss: 0.5098 - val_f1: 0.1381\n",
      "Epoch 1220/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1916 - f1: 0.7949 - val_loss: 0.5030 - val_f1: 0.1388\n",
      "Epoch 1221/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1899 - f1: 0.8007 - val_loss: 0.5002 - val_f1: 0.1387\n",
      "Epoch 1222/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1903 - f1: 0.8000 - val_loss: 0.5104 - val_f1: 0.1378\n",
      "Epoch 1223/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1927 - f1: 0.7991 - val_loss: 0.5040 - val_f1: 0.1385\n",
      "Epoch 1224/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1915 - f1: 0.7980 - val_loss: 0.5030 - val_f1: 0.1393\n",
      "Epoch 1225/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1900 - f1: 0.8037 - val_loss: 0.4979 - val_f1: 0.1394\n",
      "Epoch 1226/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1897 - f1: 0.8048 - val_loss: 0.4977 - val_f1: 0.1392\n",
      "Epoch 1227/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1919 - f1: 0.7995 - val_loss: 0.5062 - val_f1: 0.1382\n",
      "Epoch 1228/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1916 - f1: 0.7973 - val_loss: 0.5031 - val_f1: 0.1388\n",
      "Epoch 1229/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1905 - f1: 0.8041 - val_loss: 0.5089 - val_f1: 0.1384\n",
      "Epoch 1230/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1909 - f1: 0.8027 - val_loss: 0.4936 - val_f1: 0.1392\n",
      "Epoch 1231/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1879 - f1: 0.8040 - val_loss: 0.5053 - val_f1: 0.1385\n",
      "Epoch 1232/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1895 - f1: 0.8064 - val_loss: 0.5065 - val_f1: 0.1382\n",
      "Epoch 1233/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1901 - f1: 0.7980 - val_loss: 0.5055 - val_f1: 0.1384\n",
      "Epoch 1234/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1922 - f1: 0.7959 - val_loss: 0.4999 - val_f1: 0.1391\n",
      "Epoch 1235/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1899 - f1: 0.7984 - val_loss: 0.4986 - val_f1: 0.1381\n",
      "Epoch 1236/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1875 - f1: 0.8022 - val_loss: 0.5050 - val_f1: 0.1381\n",
      "Epoch 1237/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1905 - f1: 0.8007 - val_loss: 0.4952 - val_f1: 0.1390\n",
      "Epoch 1238/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1884 - f1: 0.8021 - val_loss: 0.4967 - val_f1: 0.1390\n",
      "Epoch 1239/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1890 - f1: 0.8051 - val_loss: 0.5063 - val_f1: 0.1384\n",
      "Epoch 1240/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1862 - f1: 0.8066 - val_loss: 0.5162 - val_f1: 0.1387\n",
      "Epoch 1241/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1908 - f1: 0.8006 - val_loss: 0.5071 - val_f1: 0.1385\n",
      "Epoch 1242/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1885 - f1: 0.8015 - val_loss: 0.5041 - val_f1: 0.1384\n",
      "Epoch 1243/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1924 - f1: 0.8012 - val_loss: 0.5021 - val_f1: 0.1383\n",
      "Epoch 1244/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1908 - f1: 0.7986 - val_loss: 0.5042 - val_f1: 0.1388\n",
      "Epoch 1245/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1903 - f1: 0.7993 - val_loss: 0.5044 - val_f1: 0.1389\n",
      "Epoch 1246/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1921 - f1: 0.7967 - val_loss: 0.5010 - val_f1: 0.1388\n",
      "Epoch 1247/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1872 - f1: 0.8042 - val_loss: 0.5120 - val_f1: 0.1377\n",
      "Epoch 1248/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1894 - f1: 0.8015 - val_loss: 0.5046 - val_f1: 0.1389\n",
      "Epoch 1249/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1936 - f1: 0.8002 - val_loss: 0.4982 - val_f1: 0.1387\n",
      "Epoch 1250/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1898 - f1: 0.8013 - val_loss: 0.5124 - val_f1: 0.1383\n",
      "Epoch 1251/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1882 - f1: 0.8017 - val_loss: 0.5022 - val_f1: 0.1393\n",
      "Epoch 1252/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1932 - f1: 0.8015 - val_loss: 0.5001 - val_f1: 0.1378\n",
      "Epoch 1253/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1909 - f1: 0.7982 - val_loss: 0.4984 - val_f1: 0.1385\n",
      "Epoch 1254/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1903 - f1: 0.7991 - val_loss: 0.4946 - val_f1: 0.1395\n",
      "Epoch 1255/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1872 - f1: 0.8030 - val_loss: 0.5079 - val_f1: 0.1385\n",
      "Epoch 1256/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1887 - f1: 0.8017 - val_loss: 0.5036 - val_f1: 0.1397\n",
      "Epoch 1257/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1875 - f1: 0.8020 - val_loss: 0.5026 - val_f1: 0.1387\n",
      "Epoch 1258/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.1894 - f1: 0.7987 - val_loss: 0.5023 - val_f1: 0.1389\n",
      "Epoch 1259/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.1894 - f1: 0.8027 - val_loss: 0.5074 - val_f1: 0.1387\n",
      "Epoch 1260/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1902 - f1: 0.8042 - val_loss: 0.5054 - val_f1: 0.1386\n",
      "Epoch 1261/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1897 - f1: 0.8005 - val_loss: 0.5015 - val_f1: 0.1388\n",
      "Epoch 1262/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1905 - f1: 0.7972 - val_loss: 0.5128 - val_f1: 0.1382\n",
      "Epoch 1263/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1919 - f1: 0.7983 - val_loss: 0.4989 - val_f1: 0.1390\n",
      "Epoch 1264/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1886 - f1: 0.7986 - val_loss: 0.5047 - val_f1: 0.1389\n",
      "Epoch 1265/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1903 - f1: 0.7980 - val_loss: 0.5066 - val_f1: 0.1385\n",
      "Epoch 1266/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1859 - f1: 0.8096 - val_loss: 0.5096 - val_f1: 0.1394\n",
      "Epoch 1267/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1945 - f1: 0.7970 - val_loss: 0.5026 - val_f1: 0.1382\n",
      "Epoch 1268/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1889 - f1: 0.7978 - val_loss: 0.4948 - val_f1: 0.1398\n",
      "Epoch 1269/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1887 - f1: 0.8011 - val_loss: 0.5087 - val_f1: 0.1390\n",
      "Epoch 1270/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1910 - f1: 0.7985 - val_loss: 0.5061 - val_f1: 0.1389\n",
      "Epoch 1271/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1884 - f1: 0.8024 - val_loss: 0.5034 - val_f1: 0.1397\n",
      "Epoch 1272/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1888 - f1: 0.7995 - val_loss: 0.5096 - val_f1: 0.1380\n",
      "Epoch 1273/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1895 - f1: 0.7973 - val_loss: 0.5001 - val_f1: 0.1388\n",
      "Epoch 1274/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1865 - f1: 0.8046 - val_loss: 0.5152 - val_f1: 0.1387\n",
      "Epoch 1275/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1912 - f1: 0.8001 - val_loss: 0.5000 - val_f1: 0.1391\n",
      "Epoch 1276/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1900 - f1: 0.8033 - val_loss: 0.5097 - val_f1: 0.1377\n",
      "Epoch 1277/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1890 - f1: 0.8006 - val_loss: 0.5024 - val_f1: 0.1383\n",
      "Epoch 1278/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1878 - f1: 0.8039 - val_loss: 0.5117 - val_f1: 0.1379\n",
      "Epoch 1279/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1880 - f1: 0.8008 - val_loss: 0.5018 - val_f1: 0.1390\n",
      "Epoch 1280/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1900 - f1: 0.8052 - val_loss: 0.5038 - val_f1: 0.1386\n",
      "Epoch 1281/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1899 - f1: 0.8008 - val_loss: 0.4948 - val_f1: 0.1397\n",
      "Epoch 1282/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1892 - f1: 0.8014 - val_loss: 0.5059 - val_f1: 0.1385\n",
      "Epoch 1283/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1886 - f1: 0.8039 - val_loss: 0.5074 - val_f1: 0.1386\n",
      "Epoch 1284/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1863 - f1: 0.8033 - val_loss: 0.5073 - val_f1: 0.1389\n",
      "Epoch 1285/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1880 - f1: 0.7985 - val_loss: 0.4969 - val_f1: 0.1391\n",
      "Epoch 1286/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1905 - f1: 0.8025 - val_loss: 0.5029 - val_f1: 0.1386\n",
      "Epoch 1287/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1880 - f1: 0.8032 - val_loss: 0.5059 - val_f1: 0.1389\n",
      "Epoch 1288/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1915 - f1: 0.7947 - val_loss: 0.5042 - val_f1: 0.1380\n",
      "Epoch 1289/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1868 - f1: 0.8008 - val_loss: 0.5178 - val_f1: 0.1375\n",
      "Epoch 1290/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1873 - f1: 0.8004 - val_loss: 0.5125 - val_f1: 0.1385\n",
      "Epoch 1291/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1906 - f1: 0.7983 - val_loss: 0.5088 - val_f1: 0.1386\n",
      "Epoch 1292/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1859 - f1: 0.8060 - val_loss: 0.5088 - val_f1: 0.1387\n",
      "Epoch 1293/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1884 - f1: 0.8039 - val_loss: 0.5028 - val_f1: 0.1389\n",
      "Epoch 1294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1885 - f1: 0.8026 - val_loss: 0.5062 - val_f1: 0.1383\n",
      "Epoch 1295/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1848 - f1: 0.8033 - val_loss: 0.5137 - val_f1: 0.1389\n",
      "Epoch 1296/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1846 - f1: 0.8078 - val_loss: 0.5117 - val_f1: 0.1391\n",
      "Epoch 1297/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1874 - f1: 0.8052 - val_loss: 0.5108 - val_f1: 0.1384\n",
      "Epoch 1298/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1881 - f1: 0.7995 - val_loss: 0.5126 - val_f1: 0.1386\n",
      "Epoch 1299/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1894 - f1: 0.8025 - val_loss: 0.5064 - val_f1: 0.1387\n",
      "Epoch 1300/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1895 - f1: 0.8027 - val_loss: 0.5077 - val_f1: 0.1384\n",
      "Epoch 1301/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1880 - f1: 0.8024 - val_loss: 0.5085 - val_f1: 0.1379\n",
      "Epoch 1302/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1884 - f1: 0.8000 - val_loss: 0.5113 - val_f1: 0.1384\n",
      "Epoch 1303/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1901 - f1: 0.7988 - val_loss: 0.5027 - val_f1: 0.1390\n",
      "Epoch 1304/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1877 - f1: 0.8071 - val_loss: 0.5111 - val_f1: 0.1389\n",
      "Epoch 1305/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1884 - f1: 0.7994 - val_loss: 0.5139 - val_f1: 0.1386\n",
      "Epoch 1306/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1885 - f1: 0.8020 - val_loss: 0.5119 - val_f1: 0.1387\n",
      "Epoch 1307/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1886 - f1: 0.7998 - val_loss: 0.5033 - val_f1: 0.1396\n",
      "Epoch 1308/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1874 - f1: 0.8051 - val_loss: 0.5025 - val_f1: 0.1389\n",
      "Epoch 1309/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1873 - f1: 0.8007 - val_loss: 0.5109 - val_f1: 0.1384\n",
      "Epoch 1310/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1887 - f1: 0.8012 - val_loss: 0.4997 - val_f1: 0.1404\n",
      "Epoch 1311/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1852 - f1: 0.8058 - val_loss: 0.5040 - val_f1: 0.1394\n",
      "Epoch 1312/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1862 - f1: 0.8040 - val_loss: 0.5148 - val_f1: 0.1382\n",
      "Epoch 1313/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1884 - f1: 0.8006 - val_loss: 0.5042 - val_f1: 0.1389\n",
      "Epoch 1314/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1896 - f1: 0.8029 - val_loss: 0.5045 - val_f1: 0.1395\n",
      "Epoch 1315/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1853 - f1: 0.8073 - val_loss: 0.5152 - val_f1: 0.1384\n",
      "Epoch 1316/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1898 - f1: 0.8035 - val_loss: 0.5029 - val_f1: 0.1387\n",
      "Epoch 1317/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1881 - f1: 0.8053 - val_loss: 0.5028 - val_f1: 0.1394\n",
      "Epoch 1318/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1854 - f1: 0.8015 - val_loss: 0.5076 - val_f1: 0.1389\n",
      "Epoch 1319/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1909 - f1: 0.7960 - val_loss: 0.5003 - val_f1: 0.1396\n",
      "Epoch 1320/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1904 - f1: 0.7985 - val_loss: 0.5059 - val_f1: 0.1381\n",
      "Epoch 1321/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1864 - f1: 0.8040 - val_loss: 0.5120 - val_f1: 0.1387\n",
      "Epoch 1322/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1863 - f1: 0.8052 - val_loss: 0.5091 - val_f1: 0.1389\n",
      "Epoch 1323/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1859 - f1: 0.8097 - val_loss: 0.5056 - val_f1: 0.1394\n",
      "Epoch 1324/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1857 - f1: 0.8075 - val_loss: 0.5112 - val_f1: 0.1387\n",
      "Epoch 1325/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1867 - f1: 0.8074 - val_loss: 0.5098 - val_f1: 0.1393\n",
      "Epoch 1326/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1892 - f1: 0.8011 - val_loss: 0.5092 - val_f1: 0.1385\n",
      "Epoch 1327/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1876 - f1: 0.8046 - val_loss: 0.5133 - val_f1: 0.1380\n",
      "Epoch 1328/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1868 - f1: 0.8051 - val_loss: 0.5101 - val_f1: 0.1386\n",
      "Epoch 1329/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1872 - f1: 0.8022 - val_loss: 0.5084 - val_f1: 0.1388\n",
      "Epoch 1330/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1888 - f1: 0.8029 - val_loss: 0.5016 - val_f1: 0.1397\n",
      "Epoch 1331/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1859 - f1: 0.8035 - val_loss: 0.5088 - val_f1: 0.1395\n",
      "Epoch 1332/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1854 - f1: 0.8062 - val_loss: 0.5025 - val_f1: 0.1396\n",
      "Epoch 1333/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1881 - f1: 0.8037 - val_loss: 0.5116 - val_f1: 0.1383\n",
      "Epoch 1334/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1866 - f1: 0.8060 - val_loss: 0.5139 - val_f1: 0.1373\n",
      "Epoch 1335/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1852 - f1: 0.8079 - val_loss: 0.5099 - val_f1: 0.1392\n",
      "Epoch 1336/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1868 - f1: 0.8055 - val_loss: 0.5036 - val_f1: 0.1388\n",
      "Epoch 1337/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1905 - f1: 0.7995 - val_loss: 0.5065 - val_f1: 0.1384\n",
      "Epoch 1338/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1861 - f1: 0.8015 - val_loss: 0.5051 - val_f1: 0.1395\n",
      "Epoch 1339/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1887 - f1: 0.8018 - val_loss: 0.5144 - val_f1: 0.1378\n",
      "Epoch 1340/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1868 - f1: 0.8054 - val_loss: 0.5052 - val_f1: 0.1387\n",
      "Epoch 1341/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1884 - f1: 0.8022 - val_loss: 0.5036 - val_f1: 0.1389\n",
      "Epoch 1342/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1844 - f1: 0.8047 - val_loss: 0.5029 - val_f1: 0.1399\n",
      "Epoch 1343/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1878 - f1: 0.8024 - val_loss: 0.5013 - val_f1: 0.1396\n",
      "Epoch 1344/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1863 - f1: 0.8050 - val_loss: 0.5082 - val_f1: 0.1385\n",
      "Epoch 1345/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1881 - f1: 0.8057 - val_loss: 0.5085 - val_f1: 0.1388\n",
      "Epoch 1346/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1873 - f1: 0.8038 - val_loss: 0.5120 - val_f1: 0.1384\n",
      "Epoch 1347/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1853 - f1: 0.8083 - val_loss: 0.5110 - val_f1: 0.1390\n",
      "Epoch 1348/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1873 - f1: 0.8044 - val_loss: 0.5069 - val_f1: 0.1387\n",
      "Epoch 1349/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1875 - f1: 0.8049 - val_loss: 0.5001 - val_f1: 0.1396\n",
      "Epoch 1350/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1857 - f1: 0.8062 - val_loss: 0.5101 - val_f1: 0.1382\n",
      "Epoch 1351/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1886 - f1: 0.8032 - val_loss: 0.5103 - val_f1: 0.1381\n",
      "Epoch 1352/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1872 - f1: 0.8046 - val_loss: 0.5097 - val_f1: 0.1380\n",
      "Epoch 1353/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1886 - f1: 0.8066 - val_loss: 0.5042 - val_f1: 0.1387\n",
      "Epoch 1354/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1880 - f1: 0.8036 - val_loss: 0.5035 - val_f1: 0.1388\n",
      "Epoch 1355/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1857 - f1: 0.8067 - val_loss: 0.5105 - val_f1: 0.1377\n",
      "Epoch 1356/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.1862 - f1: 0.8020 - val_loss: 0.5083 - val_f1: 0.1380\n",
      "Epoch 1357/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.1850 - f1: 0.8078 - val_loss: 0.5056 - val_f1: 0.1384\n",
      "Epoch 1358/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1871 - f1: 0.8007 - val_loss: 0.5150 - val_f1: 0.1368\n",
      "Epoch 1359/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1883 - f1: 0.8041 - val_loss: 0.5088 - val_f1: 0.1387\n",
      "Epoch 1360/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1865 - f1: 0.8055 - val_loss: 0.5086 - val_f1: 0.1383\n",
      "Epoch 1361/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1863 - f1: 0.8031 - val_loss: 0.5073 - val_f1: 0.1384\n",
      "Epoch 1362/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1856 - f1: 0.8047 - val_loss: 0.5070 - val_f1: 0.1382\n",
      "Epoch 1363/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1844 - f1: 0.8052 - val_loss: 0.5100 - val_f1: 0.1388\n",
      "Epoch 1364/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1854 - f1: 0.8037 - val_loss: 0.5087 - val_f1: 0.1392\n",
      "Epoch 1365/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1846 - f1: 0.8052 - val_loss: 0.5155 - val_f1: 0.1383\n",
      "Epoch 1366/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1868 - f1: 0.8072 - val_loss: 0.5093 - val_f1: 0.1383\n",
      "Epoch 1367/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1874 - f1: 0.8008 - val_loss: 0.5103 - val_f1: 0.1375\n",
      "Epoch 1368/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1852 - f1: 0.8094 - val_loss: 0.5110 - val_f1: 0.1387\n",
      "Epoch 1369/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1848 - f1: 0.8070 - val_loss: 0.5055 - val_f1: 0.1392\n",
      "Epoch 1370/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1852 - f1: 0.8072 - val_loss: 0.5110 - val_f1: 0.1388\n",
      "Epoch 1371/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1880 - f1: 0.8027 - val_loss: 0.5072 - val_f1: 0.1386\n",
      "Epoch 1372/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1854 - f1: 0.8034 - val_loss: 0.5032 - val_f1: 0.1394\n",
      "Epoch 1373/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1858 - f1: 0.8074 - val_loss: 0.5092 - val_f1: 0.1383\n",
      "Epoch 1374/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1853 - f1: 0.8053 - val_loss: 0.5159 - val_f1: 0.1381\n",
      "Epoch 1375/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1868 - f1: 0.8015 - val_loss: 0.5162 - val_f1: 0.1382\n",
      "Epoch 1376/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1871 - f1: 0.8057 - val_loss: 0.5123 - val_f1: 0.1381\n",
      "Epoch 1377/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1865 - f1: 0.8053 - val_loss: 0.5136 - val_f1: 0.1386\n",
      "Epoch 1378/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1858 - f1: 0.8038 - val_loss: 0.5115 - val_f1: 0.1380\n",
      "Epoch 1379/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1869 - f1: 0.8055 - val_loss: 0.5036 - val_f1: 0.1393\n",
      "Epoch 1380/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1873 - f1: 0.8023 - val_loss: 0.5088 - val_f1: 0.1387\n",
      "Epoch 1381/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1862 - f1: 0.8061 - val_loss: 0.5150 - val_f1: 0.1376\n",
      "Epoch 1382/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1849 - f1: 0.8065 - val_loss: 0.5196 - val_f1: 0.1361\n",
      "Epoch 1383/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1853 - f1: 0.8076 - val_loss: 0.5069 - val_f1: 0.1391\n",
      "Epoch 1384/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1844 - f1: 0.8081 - val_loss: 0.5106 - val_f1: 0.1393\n",
      "Epoch 1385/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1860 - f1: 0.8088 - val_loss: 0.5117 - val_f1: 0.1387\n",
      "Epoch 1386/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1835 - f1: 0.8103 - val_loss: 0.5113 - val_f1: 0.1388\n",
      "Epoch 1387/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1851 - f1: 0.8096 - val_loss: 0.5132 - val_f1: 0.1386\n",
      "Epoch 1388/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1867 - f1: 0.8072 - val_loss: 0.5055 - val_f1: 0.1394\n",
      "Epoch 1389/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1844 - f1: 0.8068 - val_loss: 0.5207 - val_f1: 0.1376\n",
      "Epoch 1390/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1860 - f1: 0.8014 - val_loss: 0.5105 - val_f1: 0.1386\n",
      "Epoch 1391/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1871 - f1: 0.8028 - val_loss: 0.5108 - val_f1: 0.1381\n",
      "Epoch 1392/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1856 - f1: 0.8054 - val_loss: 0.5101 - val_f1: 0.1382\n",
      "Epoch 1393/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1879 - f1: 0.8013 - val_loss: 0.5107 - val_f1: 0.1394\n",
      "Epoch 1394/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1877 - f1: 0.7993 - val_loss: 0.5118 - val_f1: 0.1375\n",
      "Epoch 1395/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1839 - f1: 0.8081 - val_loss: 0.5129 - val_f1: 0.1389\n",
      "Epoch 1396/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1846 - f1: 0.8041 - val_loss: 0.5114 - val_f1: 0.1385\n",
      "Epoch 1397/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1873 - f1: 0.8047 - val_loss: 0.5041 - val_f1: 0.1392\n",
      "Epoch 1398/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1892 - f1: 0.8017 - val_loss: 0.5082 - val_f1: 0.1381\n",
      "Epoch 1399/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1875 - f1: 0.8026 - val_loss: 0.5042 - val_f1: 0.1387\n",
      "Epoch 1400/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1824 - f1: 0.8057 - val_loss: 0.5055 - val_f1: 0.1387\n",
      "Epoch 1401/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1831 - f1: 0.8083 - val_loss: 0.5084 - val_f1: 0.1394\n",
      "Epoch 1402/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1863 - f1: 0.8041 - val_loss: 0.5068 - val_f1: 0.1387\n",
      "Epoch 1403/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1837 - f1: 0.8075 - val_loss: 0.5089 - val_f1: 0.1389\n",
      "Epoch 1404/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1829 - f1: 0.8087 - val_loss: 0.5167 - val_f1: 0.1380\n",
      "Epoch 1405/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1859 - f1: 0.8032 - val_loss: 0.5183 - val_f1: 0.1381\n",
      "Epoch 1406/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1854 - f1: 0.8029 - val_loss: 0.5104 - val_f1: 0.1393\n",
      "Epoch 1407/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1866 - f1: 0.8051 - val_loss: 0.5092 - val_f1: 0.1384\n",
      "Epoch 1408/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1860 - f1: 0.8062 - val_loss: 0.5176 - val_f1: 0.1378\n",
      "Epoch 1409/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1841 - f1: 0.8107 - val_loss: 0.5077 - val_f1: 0.1382\n",
      "Epoch 1410/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1830 - f1: 0.8109 - val_loss: 0.5143 - val_f1: 0.1382\n",
      "Epoch 1411/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1858 - f1: 0.8051 - val_loss: 0.5154 - val_f1: 0.1379\n",
      "Epoch 1412/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1832 - f1: 0.8091 - val_loss: 0.5103 - val_f1: 0.1386\n",
      "Epoch 1413/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1826 - f1: 0.8094 - val_loss: 0.5146 - val_f1: 0.1389\n",
      "Epoch 1414/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1850 - f1: 0.8044 - val_loss: 0.5063 - val_f1: 0.1395\n",
      "Epoch 1415/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1867 - f1: 0.8053 - val_loss: 0.5156 - val_f1: 0.1381\n",
      "Epoch 1416/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1855 - f1: 0.8073 - val_loss: 0.5090 - val_f1: 0.1386\n",
      "Epoch 1417/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1861 - f1: 0.8065 - val_loss: 0.5117 - val_f1: 0.1386\n",
      "Epoch 1418/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1858 - f1: 0.8073 - val_loss: 0.5153 - val_f1: 0.1383\n",
      "Epoch 1419/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1846 - f1: 0.8034 - val_loss: 0.5178 - val_f1: 0.1383\n",
      "Epoch 1420/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1861 - f1: 0.8037 - val_loss: 0.5232 - val_f1: 0.1358\n",
      "Epoch 1421/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1865 - f1: 0.8060 - val_loss: 0.5083 - val_f1: 0.1391\n",
      "Epoch 1422/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1851 - f1: 0.8068 - val_loss: 0.5116 - val_f1: 0.1383\n",
      "Epoch 1423/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1883 - f1: 0.8009 - val_loss: 0.5022 - val_f1: 0.1389\n",
      "Epoch 1424/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1813 - f1: 0.8116 - val_loss: 0.5106 - val_f1: 0.1393\n",
      "Epoch 1425/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1825 - f1: 0.8080 - val_loss: 0.5146 - val_f1: 0.1391\n",
      "Epoch 1426/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1852 - f1: 0.8066 - val_loss: 0.5054 - val_f1: 0.1396\n",
      "Epoch 1427/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1872 - f1: 0.8054 - val_loss: 0.5123 - val_f1: 0.1387\n",
      "Epoch 1428/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1862 - f1: 0.8047 - val_loss: 0.5093 - val_f1: 0.1387\n",
      "Epoch 1429/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1841 - f1: 0.8092 - val_loss: 0.5131 - val_f1: 0.1388\n",
      "Epoch 1430/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1842 - f1: 0.8100 - val_loss: 0.5227 - val_f1: 0.1374\n",
      "Epoch 1431/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1845 - f1: 0.8072 - val_loss: 0.5188 - val_f1: 0.1380\n",
      "Epoch 1432/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1850 - f1: 0.8082 - val_loss: 0.5137 - val_f1: 0.1383\n",
      "Epoch 1433/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1824 - f1: 0.8073 - val_loss: 0.5135 - val_f1: 0.1384\n",
      "Epoch 1434/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1825 - f1: 0.8096 - val_loss: 0.5130 - val_f1: 0.1392\n",
      "Epoch 1435/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1859 - f1: 0.8049 - val_loss: 0.5136 - val_f1: 0.1380\n",
      "Epoch 1436/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1857 - f1: 0.8049 - val_loss: 0.5175 - val_f1: 0.1379\n",
      "Epoch 1437/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1859 - f1: 0.8061 - val_loss: 0.5180 - val_f1: 0.1384\n",
      "Epoch 1438/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1834 - f1: 0.8096 - val_loss: 0.5146 - val_f1: 0.1390\n",
      "Epoch 1439/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1870 - f1: 0.8073 - val_loss: 0.5098 - val_f1: 0.1392\n",
      "Epoch 1440/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1831 - f1: 0.8085 - val_loss: 0.5129 - val_f1: 0.1389\n",
      "Epoch 1441/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1825 - f1: 0.8099 - val_loss: 0.5161 - val_f1: 0.1383\n",
      "Epoch 1442/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1854 - f1: 0.8046 - val_loss: 0.5108 - val_f1: 0.1382\n",
      "Epoch 1443/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1833 - f1: 0.8093 - val_loss: 0.5112 - val_f1: 0.1395\n",
      "Epoch 1444/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1853 - f1: 0.8047 - val_loss: 0.5070 - val_f1: 0.1397\n",
      "Epoch 1445/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1825 - f1: 0.8107 - val_loss: 0.5193 - val_f1: 0.1383\n",
      "Epoch 1446/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1841 - f1: 0.8082 - val_loss: 0.5139 - val_f1: 0.1385\n",
      "Epoch 1447/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1843 - f1: 0.8065 - val_loss: 0.5098 - val_f1: 0.1384\n",
      "Epoch 1448/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1868 - f1: 0.8061 - val_loss: 0.5107 - val_f1: 0.1396\n",
      "Epoch 1449/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1833 - f1: 0.8067 - val_loss: 0.5204 - val_f1: 0.1383\n",
      "Epoch 1450/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1831 - f1: 0.8065 - val_loss: 0.5083 - val_f1: 0.1386\n",
      "Epoch 1451/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1819 - f1: 0.8106 - val_loss: 0.5130 - val_f1: 0.1387\n",
      "Epoch 1452/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1868 - f1: 0.8072 - val_loss: 0.5158 - val_f1: 0.1389\n",
      "Epoch 1453/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1832 - f1: 0.8106 - val_loss: 0.5155 - val_f1: 0.1389\n",
      "Epoch 1454/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1815 - f1: 0.8106 - val_loss: 0.5191 - val_f1: 0.1384\n",
      "Epoch 1455/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1864 - f1: 0.8088 - val_loss: 0.5128 - val_f1: 0.1389\n",
      "Epoch 1456/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1814 - f1: 0.8137 - val_loss: 0.5183 - val_f1: 0.1383\n",
      "Epoch 1457/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1850 - f1: 0.8058 - val_loss: 0.5141 - val_f1: 0.1388\n",
      "Epoch 1458/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1837 - f1: 0.8093 - val_loss: 0.5148 - val_f1: 0.1389\n",
      "Epoch 1459/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.1859 - f1: 0.8068 - val_loss: 0.5149 - val_f1: 0.1378\n",
      "Epoch 1460/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1833 - f1: 0.8083 - val_loss: 0.5084 - val_f1: 0.1379\n",
      "Epoch 1461/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1841 - f1: 0.8092 - val_loss: 0.5074 - val_f1: 0.1389\n",
      "Epoch 1462/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1842 - f1: 0.8091 - val_loss: 0.5146 - val_f1: 0.1384\n",
      "Epoch 1463/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1851 - f1: 0.8087 - val_loss: 0.5107 - val_f1: 0.1385\n",
      "Epoch 1464/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1827 - f1: 0.8105 - val_loss: 0.5075 - val_f1: 0.1396\n",
      "Epoch 1465/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1876 - f1: 0.8023 - val_loss: 0.5061 - val_f1: 0.1391\n",
      "Epoch 1466/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1818 - f1: 0.8115 - val_loss: 0.5108 - val_f1: 0.1394\n",
      "Epoch 1467/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1831 - f1: 0.8104 - val_loss: 0.5080 - val_f1: 0.1396\n",
      "Epoch 1468/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1855 - f1: 0.8071 - val_loss: 0.5141 - val_f1: 0.1389\n",
      "Epoch 1469/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1832 - f1: 0.8069 - val_loss: 0.5101 - val_f1: 0.1400\n",
      "Epoch 1470/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1825 - f1: 0.8092 - val_loss: 0.5200 - val_f1: 0.1386\n",
      "Epoch 1471/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1829 - f1: 0.8066 - val_loss: 0.5254 - val_f1: 0.1385\n",
      "Epoch 1472/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1836 - f1: 0.8058 - val_loss: 0.5152 - val_f1: 0.1391\n",
      "Epoch 1473/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1816 - f1: 0.8062 - val_loss: 0.5189 - val_f1: 0.1388\n",
      "Epoch 1474/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1833 - f1: 0.8073 - val_loss: 0.5066 - val_f1: 0.1395\n",
      "Epoch 1475/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1826 - f1: 0.8113 - val_loss: 0.5047 - val_f1: 0.1396\n",
      "Epoch 1476/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1838 - f1: 0.8065 - val_loss: 0.5084 - val_f1: 0.1394\n",
      "Epoch 1477/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1828 - f1: 0.8082 - val_loss: 0.5175 - val_f1: 0.1391\n",
      "Epoch 1478/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1831 - f1: 0.8074 - val_loss: 0.5168 - val_f1: 0.1370\n",
      "Epoch 1479/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1824 - f1: 0.8094 - val_loss: 0.5146 - val_f1: 0.1392\n",
      "Epoch 1480/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1834 - f1: 0.8104 - val_loss: 0.5175 - val_f1: 0.1383\n",
      "Epoch 1481/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1827 - f1: 0.8131 - val_loss: 0.5043 - val_f1: 0.1397\n",
      "Epoch 1482/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1860 - f1: 0.8027 - val_loss: 0.5086 - val_f1: 0.1397\n",
      "Epoch 1483/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1823 - f1: 0.8120 - val_loss: 0.5097 - val_f1: 0.1395\n",
      "Epoch 1484/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1825 - f1: 0.8089 - val_loss: 0.5148 - val_f1: 0.1384\n",
      "Epoch 1485/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1822 - f1: 0.8078 - val_loss: 0.5094 - val_f1: 0.1398\n",
      "Epoch 1486/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1832 - f1: 0.8126 - val_loss: 0.5156 - val_f1: 0.1377\n",
      "Epoch 1487/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1809 - f1: 0.8082 - val_loss: 0.5256 - val_f1: 0.1385\n",
      "Epoch 1488/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1850 - f1: 0.8059 - val_loss: 0.5151 - val_f1: 0.1387\n",
      "Epoch 1489/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1826 - f1: 0.8132 - val_loss: 0.5108 - val_f1: 0.1390\n",
      "Epoch 1490/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1831 - f1: 0.8073 - val_loss: 0.5121 - val_f1: 0.1383\n",
      "Epoch 1491/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1835 - f1: 0.8069 - val_loss: 0.5125 - val_f1: 0.1388\n",
      "Epoch 1492/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1808 - f1: 0.8108 - val_loss: 0.5199 - val_f1: 0.1382\n",
      "Epoch 1493/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1807 - f1: 0.8108 - val_loss: 0.5201 - val_f1: 0.1384\n",
      "Epoch 1494/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1788 - f1: 0.8138 - val_loss: 0.5199 - val_f1: 0.1380\n",
      "Epoch 1495/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1828 - f1: 0.8064 - val_loss: 0.5214 - val_f1: 0.1380\n",
      "Epoch 1496/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1831 - f1: 0.8098 - val_loss: 0.5180 - val_f1: 0.1385\n",
      "Epoch 1497/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1823 - f1: 0.8092 - val_loss: 0.5176 - val_f1: 0.1392\n",
      "Epoch 1498/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1810 - f1: 0.8138 - val_loss: 0.5171 - val_f1: 0.1387\n",
      "Epoch 1499/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1815 - f1: 0.8114 - val_loss: 0.5202 - val_f1: 0.1376\n",
      "Epoch 1500/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1842 - f1: 0.8080 - val_loss: 0.5158 - val_f1: 0.1384\n",
      "Epoch 1501/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1820 - f1: 0.8114 - val_loss: 0.5113 - val_f1: 0.1400\n",
      "Epoch 1502/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1808 - f1: 0.8149 - val_loss: 0.5241 - val_f1: 0.1389\n",
      "Epoch 1503/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1836 - f1: 0.8107 - val_loss: 0.5104 - val_f1: 0.1394\n",
      "Epoch 1504/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1844 - f1: 0.8081 - val_loss: 0.5052 - val_f1: 0.1390\n",
      "Epoch 1505/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1825 - f1: 0.8087 - val_loss: 0.5171 - val_f1: 0.1386\n",
      "Epoch 1506/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1820 - f1: 0.8128 - val_loss: 0.5150 - val_f1: 0.1392\n",
      "Epoch 1507/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1851 - f1: 0.8063 - val_loss: 0.5143 - val_f1: 0.1387\n",
      "Epoch 1508/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1824 - f1: 0.8075 - val_loss: 0.5097 - val_f1: 0.1386\n",
      "Epoch 1509/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1844 - f1: 0.8061 - val_loss: 0.5183 - val_f1: 0.1383\n",
      "Epoch 1510/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1828 - f1: 0.8082 - val_loss: 0.5159 - val_f1: 0.1384\n",
      "Epoch 1511/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1829 - f1: 0.8103 - val_loss: 0.5137 - val_f1: 0.1393\n",
      "Epoch 1512/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1842 - f1: 0.8095 - val_loss: 0.5140 - val_f1: 0.1384\n",
      "Epoch 1513/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1824 - f1: 0.8091 - val_loss: 0.5243 - val_f1: 0.1378\n",
      "Epoch 1514/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1835 - f1: 0.8093 - val_loss: 0.5149 - val_f1: 0.1381\n",
      "Epoch 1515/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1821 - f1: 0.8075 - val_loss: 0.5220 - val_f1: 0.1377\n",
      "Epoch 1516/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1820 - f1: 0.8068 - val_loss: 0.5230 - val_f1: 0.1372\n",
      "Epoch 1517/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1802 - f1: 0.8091 - val_loss: 0.5248 - val_f1: 0.1373\n",
      "Epoch 1518/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1791 - f1: 0.8130 - val_loss: 0.5183 - val_f1: 0.1388\n",
      "Epoch 1519/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1828 - f1: 0.8092 - val_loss: 0.5113 - val_f1: 0.1387\n",
      "Epoch 1520/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1813 - f1: 0.8095 - val_loss: 0.5139 - val_f1: 0.1387\n",
      "Epoch 1521/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1816 - f1: 0.8090 - val_loss: 0.5170 - val_f1: 0.1389\n",
      "Epoch 1522/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1818 - f1: 0.8074 - val_loss: 0.5070 - val_f1: 0.1397\n",
      "Epoch 1523/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1824 - f1: 0.8070 - val_loss: 0.5145 - val_f1: 0.1384\n",
      "Epoch 1524/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1827 - f1: 0.8117 - val_loss: 0.5124 - val_f1: 0.1386\n",
      "Epoch 1525/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1821 - f1: 0.8111 - val_loss: 0.5121 - val_f1: 0.1391\n",
      "Epoch 1526/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1823 - f1: 0.8092 - val_loss: 0.5181 - val_f1: 0.1390\n",
      "Epoch 1527/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1825 - f1: 0.8091 - val_loss: 0.5174 - val_f1: 0.1383\n",
      "Epoch 1528/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1798 - f1: 0.8136 - val_loss: 0.5240 - val_f1: 0.1377\n",
      "Epoch 1529/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1808 - f1: 0.8101 - val_loss: 0.5245 - val_f1: 0.1377\n",
      "Epoch 1530/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1790 - f1: 0.8125 - val_loss: 0.5229 - val_f1: 0.1379\n",
      "Epoch 1531/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1817 - f1: 0.8079 - val_loss: 0.5213 - val_f1: 0.1379\n",
      "Epoch 1532/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1860 - f1: 0.8056 - val_loss: 0.5143 - val_f1: 0.1384\n",
      "Epoch 1533/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1838 - f1: 0.8065 - val_loss: 0.5066 - val_f1: 0.1391\n",
      "Epoch 1534/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1816 - f1: 0.8067 - val_loss: 0.5182 - val_f1: 0.1383\n",
      "Epoch 1535/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1837 - f1: 0.8058 - val_loss: 0.5158 - val_f1: 0.1387\n",
      "Epoch 1536/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1815 - f1: 0.8127 - val_loss: 0.5234 - val_f1: 0.1385\n",
      "Epoch 1537/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1847 - f1: 0.8064 - val_loss: 0.5096 - val_f1: 0.1393\n",
      "Epoch 1538/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1819 - f1: 0.8087 - val_loss: 0.5174 - val_f1: 0.1388\n",
      "Epoch 1539/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1811 - f1: 0.8146 - val_loss: 0.5185 - val_f1: 0.1377\n",
      "Epoch 1540/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1849 - f1: 0.8071 - val_loss: 0.5128 - val_f1: 0.1388\n",
      "Epoch 1541/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1827 - f1: 0.8119 - val_loss: 0.5153 - val_f1: 0.1383\n",
      "Epoch 1542/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1819 - f1: 0.8083 - val_loss: 0.5162 - val_f1: 0.1383\n",
      "Epoch 1543/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1825 - f1: 0.8074 - val_loss: 0.5178 - val_f1: 0.1382\n",
      "Epoch 1544/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1816 - f1: 0.8098 - val_loss: 0.5141 - val_f1: 0.1383\n",
      "Epoch 1545/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1819 - f1: 0.8089 - val_loss: 0.5080 - val_f1: 0.1390\n",
      "Epoch 1546/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1813 - f1: 0.8145 - val_loss: 0.5197 - val_f1: 0.1379\n",
      "Epoch 1547/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1839 - f1: 0.8061 - val_loss: 0.5126 - val_f1: 0.1387\n",
      "Epoch 1548/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1835 - f1: 0.8082 - val_loss: 0.5212 - val_f1: 0.1379\n",
      "Epoch 1549/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1826 - f1: 0.8083 - val_loss: 0.5181 - val_f1: 0.1387\n",
      "Epoch 1550/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1835 - f1: 0.8101 - val_loss: 0.5153 - val_f1: 0.1391\n",
      "Epoch 1551/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1823 - f1: 0.8070 - val_loss: 0.5157 - val_f1: 0.1389\n",
      "Epoch 1552/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1801 - f1: 0.8123 - val_loss: 0.5139 - val_f1: 0.1382\n",
      "Epoch 1553/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1831 - f1: 0.8117 - val_loss: 0.5086 - val_f1: 0.1383\n",
      "Epoch 1554/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1812 - f1: 0.8100 - val_loss: 0.5145 - val_f1: 0.1386\n",
      "Epoch 1555/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1790 - f1: 0.8171 - val_loss: 0.5131 - val_f1: 0.1388\n",
      "Epoch 1556/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1788 - f1: 0.8125 - val_loss: 0.5234 - val_f1: 0.1381\n",
      "Epoch 1557/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1787 - f1: 0.8171 - val_loss: 0.5238 - val_f1: 0.1382\n",
      "Epoch 1558/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1839 - f1: 0.8116 - val_loss: 0.5140 - val_f1: 0.1383\n",
      "Epoch 1559/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1815 - f1: 0.8116 - val_loss: 0.5086 - val_f1: 0.1392\n",
      "Epoch 1560/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1823 - f1: 0.8119 - val_loss: 0.5093 - val_f1: 0.1382\n",
      "Epoch 1561/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1798 - f1: 0.8122 - val_loss: 0.5188 - val_f1: 0.1384\n",
      "Epoch 1562/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1835 - f1: 0.8074 - val_loss: 0.5059 - val_f1: 0.1401\n",
      "Epoch 1563/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1820 - f1: 0.8102 - val_loss: 0.5129 - val_f1: 0.1384\n",
      "Epoch 1564/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1794 - f1: 0.8136 - val_loss: 0.5138 - val_f1: 0.1395\n",
      "Epoch 1565/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1820 - f1: 0.8093 - val_loss: 0.5130 - val_f1: 0.1391\n",
      "Epoch 1566/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1785 - f1: 0.8145 - val_loss: 0.5197 - val_f1: 0.1391\n",
      "Epoch 1567/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1804 - f1: 0.8162 - val_loss: 0.5226 - val_f1: 0.1378\n",
      "Epoch 1568/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1798 - f1: 0.8108 - val_loss: 0.5119 - val_f1: 0.1391\n",
      "Epoch 1569/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1825 - f1: 0.8097 - val_loss: 0.5174 - val_f1: 0.1386\n",
      "Epoch 1570/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1816 - f1: 0.8099 - val_loss: 0.5171 - val_f1: 0.1381\n",
      "Epoch 1571/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1801 - f1: 0.8150 - val_loss: 0.5126 - val_f1: 0.1391\n",
      "Epoch 1572/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1805 - f1: 0.8124 - val_loss: 0.5076 - val_f1: 0.1394\n",
      "Epoch 1573/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1816 - f1: 0.8080 - val_loss: 0.5137 - val_f1: 0.1397\n",
      "Epoch 1574/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1805 - f1: 0.8113 - val_loss: 0.5238 - val_f1: 0.1379\n",
      "Epoch 1575/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1831 - f1: 0.8115 - val_loss: 0.5165 - val_f1: 0.1380\n",
      "Epoch 1576/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1800 - f1: 0.8158 - val_loss: 0.5174 - val_f1: 0.1386\n",
      "Epoch 1577/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1804 - f1: 0.8111 - val_loss: 0.5206 - val_f1: 0.1387\n",
      "Epoch 1578/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1794 - f1: 0.8122 - val_loss: 0.5196 - val_f1: 0.1386\n",
      "Epoch 1579/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1820 - f1: 0.8104 - val_loss: 0.5166 - val_f1: 0.1384\n",
      "Epoch 1580/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1806 - f1: 0.8076 - val_loss: 0.5127 - val_f1: 0.1392\n",
      "Epoch 1581/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1817 - f1: 0.8088 - val_loss: 0.5203 - val_f1: 0.1368\n",
      "Epoch 1582/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1777 - f1: 0.8151 - val_loss: 0.5103 - val_f1: 0.1397\n",
      "Epoch 1583/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1816 - f1: 0.8131 - val_loss: 0.5193 - val_f1: 0.1391\n",
      "Epoch 1584/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1810 - f1: 0.8119 - val_loss: 0.5244 - val_f1: 0.1376\n",
      "Epoch 1585/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1810 - f1: 0.8108 - val_loss: 0.5198 - val_f1: 0.1385\n",
      "Epoch 1586/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1820 - f1: 0.8109 - val_loss: 0.5142 - val_f1: 0.1392\n",
      "Epoch 1587/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1796 - f1: 0.8106 - val_loss: 0.5097 - val_f1: 0.1392\n",
      "Epoch 1588/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1810 - f1: 0.8099 - val_loss: 0.5161 - val_f1: 0.1383\n",
      "Epoch 1589/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1796 - f1: 0.8133 - val_loss: 0.5120 - val_f1: 0.1393\n",
      "Epoch 1590/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1798 - f1: 0.8150 - val_loss: 0.5231 - val_f1: 0.1384\n",
      "Epoch 1591/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1827 - f1: 0.8105 - val_loss: 0.5145 - val_f1: 0.1389\n",
      "Epoch 1592/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1794 - f1: 0.8129 - val_loss: 0.5134 - val_f1: 0.1396\n",
      "Epoch 1593/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1814 - f1: 0.8104 - val_loss: 0.5170 - val_f1: 0.1383\n",
      "Epoch 1594/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1817 - f1: 0.8153 - val_loss: 0.5231 - val_f1: 0.1376\n",
      "Epoch 1595/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1817 - f1: 0.8104 - val_loss: 0.5157 - val_f1: 0.1383\n",
      "Epoch 1596/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1767 - f1: 0.8161 - val_loss: 0.5252 - val_f1: 0.1376\n",
      "Epoch 1597/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1820 - f1: 0.8149 - val_loss: 0.5225 - val_f1: 0.1372\n",
      "Epoch 1598/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1822 - f1: 0.8113 - val_loss: 0.5154 - val_f1: 0.1388\n",
      "Epoch 1599/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1811 - f1: 0.8102 - val_loss: 0.5222 - val_f1: 0.1383\n",
      "Epoch 1600/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1802 - f1: 0.8108 - val_loss: 0.5063 - val_f1: 0.1392\n",
      "Epoch 1601/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1810 - f1: 0.8102 - val_loss: 0.5224 - val_f1: 0.1371\n",
      "Epoch 1602/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1796 - f1: 0.8105 - val_loss: 0.5208 - val_f1: 0.1385\n",
      "Epoch 1603/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1792 - f1: 0.8125 - val_loss: 0.5161 - val_f1: 0.1385\n",
      "Epoch 1604/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1798 - f1: 0.8132 - val_loss: 0.5231 - val_f1: 0.1374\n",
      "Epoch 1605/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1810 - f1: 0.8119 - val_loss: 0.5124 - val_f1: 0.1382\n",
      "Epoch 1606/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1807 - f1: 0.8139 - val_loss: 0.5185 - val_f1: 0.1381\n",
      "Epoch 1607/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1802 - f1: 0.8119 - val_loss: 0.5169 - val_f1: 0.1386\n",
      "Epoch 1608/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1799 - f1: 0.8112 - val_loss: 0.5232 - val_f1: 0.1375\n",
      "Epoch 1609/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1804 - f1: 0.8093 - val_loss: 0.5171 - val_f1: 0.1384\n",
      "Epoch 1610/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1783 - f1: 0.8163 - val_loss: 0.5238 - val_f1: 0.1366\n",
      "Epoch 1611/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1817 - f1: 0.8118 - val_loss: 0.5173 - val_f1: 0.1376\n",
      "Epoch 1612/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1827 - f1: 0.8103 - val_loss: 0.5086 - val_f1: 0.1387\n",
      "Epoch 1613/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1769 - f1: 0.8131 - val_loss: 0.5229 - val_f1: 0.1372\n",
      "Epoch 1614/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1803 - f1: 0.8096 - val_loss: 0.5181 - val_f1: 0.1385\n",
      "Epoch 1615/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1800 - f1: 0.8130 - val_loss: 0.5211 - val_f1: 0.1387\n",
      "Epoch 1616/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1784 - f1: 0.8164 - val_loss: 0.5240 - val_f1: 0.1380\n",
      "Epoch 1617/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1780 - f1: 0.8136 - val_loss: 0.5219 - val_f1: 0.1378\n",
      "Epoch 1618/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1805 - f1: 0.8140 - val_loss: 0.5269 - val_f1: 0.1376\n",
      "Epoch 1619/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1805 - f1: 0.8137 - val_loss: 0.5163 - val_f1: 0.1386\n",
      "Epoch 1620/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1795 - f1: 0.8148 - val_loss: 0.5162 - val_f1: 0.1388\n",
      "Epoch 1621/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1796 - f1: 0.8142 - val_loss: 0.5188 - val_f1: 0.1385\n",
      "Epoch 1622/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1771 - f1: 0.8187 - val_loss: 0.5256 - val_f1: 0.1380\n",
      "Epoch 1623/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1791 - f1: 0.8130 - val_loss: 0.5200 - val_f1: 0.1388\n",
      "Epoch 1624/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1794 - f1: 0.8121 - val_loss: 0.5163 - val_f1: 0.1388\n",
      "Epoch 1625/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1810 - f1: 0.8135 - val_loss: 0.5192 - val_f1: 0.1386\n",
      "Epoch 1626/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1815 - f1: 0.8133 - val_loss: 0.5205 - val_f1: 0.1381\n",
      "Epoch 1627/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1797 - f1: 0.8144 - val_loss: 0.5191 - val_f1: 0.1391\n",
      "Epoch 1628/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1801 - f1: 0.8143 - val_loss: 0.5168 - val_f1: 0.1384\n",
      "Epoch 1629/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1794 - f1: 0.8118 - val_loss: 0.5176 - val_f1: 0.1387\n",
      "Epoch 1630/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1773 - f1: 0.8141 - val_loss: 0.5200 - val_f1: 0.1391\n",
      "Epoch 1631/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1793 - f1: 0.8136 - val_loss: 0.5237 - val_f1: 0.1391\n",
      "Epoch 1632/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1822 - f1: 0.8112 - val_loss: 0.5143 - val_f1: 0.1392\n",
      "Epoch 1633/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1820 - f1: 0.8104 - val_loss: 0.5200 - val_f1: 0.1386\n",
      "Epoch 1634/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1833 - f1: 0.8026 - val_loss: 0.5198 - val_f1: 0.1385\n",
      "Epoch 1635/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1792 - f1: 0.8167 - val_loss: 0.5154 - val_f1: 0.1391\n",
      "Epoch 1636/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1776 - f1: 0.8140 - val_loss: 0.5159 - val_f1: 0.1395\n",
      "Epoch 1637/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1812 - f1: 0.8129 - val_loss: 0.5135 - val_f1: 0.1384\n",
      "Epoch 1638/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1784 - f1: 0.8152 - val_loss: 0.5064 - val_f1: 0.1401\n",
      "Epoch 1639/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1782 - f1: 0.8116 - val_loss: 0.5254 - val_f1: 0.1385\n",
      "Epoch 1640/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.1815 - f1: 0.8105 - val_loss: 0.5159 - val_f1: 0.1391\n",
      "Epoch 1641/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.1793 - f1: 0.8103 - val_loss: 0.5206 - val_f1: 0.1390\n",
      "Epoch 1642/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1809 - f1: 0.8116 - val_loss: 0.5254 - val_f1: 0.1372\n",
      "Epoch 1643/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1796 - f1: 0.8117 - val_loss: 0.5227 - val_f1: 0.1380\n",
      "Epoch 1644/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1814 - f1: 0.8075 - val_loss: 0.5234 - val_f1: 0.1382\n",
      "Epoch 1645/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1802 - f1: 0.8105 - val_loss: 0.5253 - val_f1: 0.1381\n",
      "Epoch 1646/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1797 - f1: 0.8152 - val_loss: 0.5168 - val_f1: 0.1379\n",
      "Epoch 1647/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1785 - f1: 0.8134 - val_loss: 0.5256 - val_f1: 0.1390\n",
      "Epoch 1648/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1802 - f1: 0.8129 - val_loss: 0.5174 - val_f1: 0.1388\n",
      "Epoch 1649/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1788 - f1: 0.8167 - val_loss: 0.5251 - val_f1: 0.1379\n",
      "Epoch 1650/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1805 - f1: 0.8132 - val_loss: 0.5165 - val_f1: 0.1393\n",
      "Epoch 1651/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1765 - f1: 0.8159 - val_loss: 0.5214 - val_f1: 0.1384\n",
      "Epoch 1652/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1795 - f1: 0.8174 - val_loss: 0.5152 - val_f1: 0.1396\n",
      "Epoch 1653/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1768 - f1: 0.8150 - val_loss: 0.5274 - val_f1: 0.1380\n",
      "Epoch 1654/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1788 - f1: 0.8159 - val_loss: 0.5201 - val_f1: 0.1384\n",
      "Epoch 1655/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1796 - f1: 0.8130 - val_loss: 0.5092 - val_f1: 0.1388\n",
      "Epoch 1656/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1777 - f1: 0.8132 - val_loss: 0.5193 - val_f1: 0.1389\n",
      "Epoch 1657/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1812 - f1: 0.8100 - val_loss: 0.5130 - val_f1: 0.1393\n",
      "Epoch 1658/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1769 - f1: 0.8156 - val_loss: 0.5200 - val_f1: 0.1387\n",
      "Epoch 1659/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1802 - f1: 0.8131 - val_loss: 0.5203 - val_f1: 0.1385\n",
      "Epoch 1660/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1805 - f1: 0.8119 - val_loss: 0.5153 - val_f1: 0.1396\n",
      "Epoch 1661/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1782 - f1: 0.8143 - val_loss: 0.5230 - val_f1: 0.1376\n",
      "Epoch 1662/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1757 - f1: 0.8193 - val_loss: 0.5309 - val_f1: 0.1379\n",
      "Epoch 1663/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1784 - f1: 0.8164 - val_loss: 0.5238 - val_f1: 0.1381\n",
      "Epoch 1664/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1808 - f1: 0.8119 - val_loss: 0.5153 - val_f1: 0.1385\n",
      "Epoch 1665/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1781 - f1: 0.8160 - val_loss: 0.5208 - val_f1: 0.1379\n",
      "Epoch 1666/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1764 - f1: 0.8115 - val_loss: 0.5276 - val_f1: 0.1382\n",
      "Epoch 1667/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1801 - f1: 0.8104 - val_loss: 0.5175 - val_f1: 0.1383\n",
      "Epoch 1668/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1797 - f1: 0.8099 - val_loss: 0.5308 - val_f1: 0.1376\n",
      "Epoch 1669/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1792 - f1: 0.8147 - val_loss: 0.5156 - val_f1: 0.1390\n",
      "Epoch 1670/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1810 - f1: 0.8107 - val_loss: 0.5148 - val_f1: 0.1391\n",
      "Epoch 1671/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1767 - f1: 0.8178 - val_loss: 0.5211 - val_f1: 0.1389\n",
      "Epoch 1672/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1804 - f1: 0.8104 - val_loss: 0.5137 - val_f1: 0.1389\n",
      "Epoch 1673/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1777 - f1: 0.8163 - val_loss: 0.5267 - val_f1: 0.1375\n",
      "Epoch 1674/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1806 - f1: 0.8118 - val_loss: 0.5181 - val_f1: 0.1383\n",
      "Epoch 1675/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1785 - f1: 0.8125 - val_loss: 0.5268 - val_f1: 0.1373\n",
      "Epoch 1676/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1807 - f1: 0.8147 - val_loss: 0.5140 - val_f1: 0.1393\n",
      "Epoch 1677/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1802 - f1: 0.8103 - val_loss: 0.5249 - val_f1: 0.1385\n",
      "Epoch 1678/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1795 - f1: 0.8119 - val_loss: 0.5194 - val_f1: 0.1382\n",
      "Epoch 1679/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1754 - f1: 0.8177 - val_loss: 0.5187 - val_f1: 0.1390\n",
      "Epoch 1680/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1778 - f1: 0.8163 - val_loss: 0.5281 - val_f1: 0.1372\n",
      "Epoch 1681/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1792 - f1: 0.8127 - val_loss: 0.5219 - val_f1: 0.1379\n",
      "Epoch 1682/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1779 - f1: 0.8148 - val_loss: 0.5158 - val_f1: 0.1382\n",
      "Epoch 1683/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1795 - f1: 0.8120 - val_loss: 0.5172 - val_f1: 0.1386\n",
      "Epoch 1684/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1810 - f1: 0.8123 - val_loss: 0.5211 - val_f1: 0.1375\n",
      "Epoch 1685/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1783 - f1: 0.8176 - val_loss: 0.5255 - val_f1: 0.1377\n",
      "Epoch 1686/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1800 - f1: 0.8142 - val_loss: 0.5210 - val_f1: 0.1374\n",
      "Epoch 1687/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1784 - f1: 0.8177 - val_loss: 0.5192 - val_f1: 0.1381\n",
      "Epoch 1688/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1789 - f1: 0.8088 - val_loss: 0.5240 - val_f1: 0.1385\n",
      "Epoch 1689/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1753 - f1: 0.8157 - val_loss: 0.5199 - val_f1: 0.1390\n",
      "Epoch 1690/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1798 - f1: 0.8155 - val_loss: 0.5264 - val_f1: 0.1377\n",
      "Epoch 1691/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1783 - f1: 0.8173 - val_loss: 0.5238 - val_f1: 0.1378\n",
      "Epoch 1692/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1773 - f1: 0.8168 - val_loss: 0.5223 - val_f1: 0.1383\n",
      "Epoch 1693/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1794 - f1: 0.8154 - val_loss: 0.5228 - val_f1: 0.1378\n",
      "Epoch 1694/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1757 - f1: 0.8173 - val_loss: 0.5230 - val_f1: 0.1385\n",
      "Epoch 1695/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1803 - f1: 0.8112 - val_loss: 0.5225 - val_f1: 0.1386\n",
      "Epoch 1696/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1784 - f1: 0.8146 - val_loss: 0.5213 - val_f1: 0.1387\n",
      "Epoch 1697/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1797 - f1: 0.8135 - val_loss: 0.5230 - val_f1: 0.1379\n",
      "Epoch 1698/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1783 - f1: 0.8202 - val_loss: 0.5208 - val_f1: 0.1384\n",
      "Epoch 1699/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1811 - f1: 0.8135 - val_loss: 0.5161 - val_f1: 0.1386\n",
      "Epoch 1700/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1797 - f1: 0.8160 - val_loss: 0.5170 - val_f1: 0.1378\n",
      "Epoch 1701/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1795 - f1: 0.8153 - val_loss: 0.5182 - val_f1: 0.1387\n",
      "Epoch 1702/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1801 - f1: 0.8132 - val_loss: 0.5059 - val_f1: 0.1397\n",
      "Epoch 1703/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1777 - f1: 0.8188 - val_loss: 0.5246 - val_f1: 0.1387\n",
      "Epoch 1704/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1765 - f1: 0.8175 - val_loss: 0.5216 - val_f1: 0.1388\n",
      "Epoch 1705/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.1785 - f1: 0.8143 - val_loss: 0.5201 - val_f1: 0.1383\n",
      "Epoch 1706/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.1750 - f1: 0.8180 - val_loss: 0.5117 - val_f1: 0.1392\n",
      "Epoch 1707/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1780 - f1: 0.8167 - val_loss: 0.5200 - val_f1: 0.1387\n",
      "Epoch 1708/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1762 - f1: 0.8192 - val_loss: 0.5277 - val_f1: 0.1379\n",
      "Epoch 1709/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1761 - f1: 0.8166 - val_loss: 0.5189 - val_f1: 0.1383\n",
      "Epoch 1710/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1761 - f1: 0.8166 - val_loss: 0.5259 - val_f1: 0.1374\n",
      "Epoch 1711/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1767 - f1: 0.8166 - val_loss: 0.5239 - val_f1: 0.1377\n",
      "Epoch 1712/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1791 - f1: 0.8159 - val_loss: 0.5237 - val_f1: 0.1380\n",
      "Epoch 1713/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1793 - f1: 0.8103 - val_loss: 0.5250 - val_f1: 0.1382\n",
      "Epoch 1714/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1808 - f1: 0.8132 - val_loss: 0.5203 - val_f1: 0.1384\n",
      "Epoch 1715/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1759 - f1: 0.8161 - val_loss: 0.5289 - val_f1: 0.1381\n",
      "Epoch 1716/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.1765 - f1: 0.8172 - val_loss: 0.5208 - val_f1: 0.1391\n",
      "Epoch 1717/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.1797 - f1: 0.8103 - val_loss: 0.5152 - val_f1: 0.1388\n",
      "Epoch 1718/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1802 - f1: 0.8135 - val_loss: 0.5220 - val_f1: 0.1390\n",
      "Epoch 1719/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1808 - f1: 0.8138 - val_loss: 0.5134 - val_f1: 0.1394\n",
      "Epoch 1720/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1757 - f1: 0.8159 - val_loss: 0.5223 - val_f1: 0.1382\n",
      "Epoch 1721/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1789 - f1: 0.8133 - val_loss: 0.5195 - val_f1: 0.1383\n",
      "Epoch 1722/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.1787 - f1: 0.81 - 3s 48us/step - loss: 0.1787 - f1: 0.8123 - val_loss: 0.5186 - val_f1: 0.1389\n",
      "Epoch 1723/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1774 - f1: 0.8148 - val_loss: 0.5212 - val_f1: 0.1386\n",
      "Epoch 1724/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1760 - f1: 0.8145 - val_loss: 0.5276 - val_f1: 0.1381\n",
      "Epoch 1725/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1802 - f1: 0.8157 - val_loss: 0.5169 - val_f1: 0.1383\n",
      "Epoch 1726/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1783 - f1: 0.8153 - val_loss: 0.5134 - val_f1: 0.1392\n",
      "Epoch 1727/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1775 - f1: 0.8164 - val_loss: 0.5234 - val_f1: 0.1381\n",
      "Epoch 1728/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1761 - f1: 0.8185 - val_loss: 0.5248 - val_f1: 0.1381\n",
      "Epoch 1729/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1801 - f1: 0.8128 - val_loss: 0.5147 - val_f1: 0.1385\n",
      "Epoch 1730/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1774 - f1: 0.8166 - val_loss: 0.5242 - val_f1: 0.1380\n",
      "Epoch 1731/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1748 - f1: 0.8181 - val_loss: 0.5217 - val_f1: 0.1392\n",
      "Epoch 1732/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1767 - f1: 0.8161 - val_loss: 0.5169 - val_f1: 0.1380\n",
      "Epoch 1733/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.1803 - f1: 0.8113 - val_loss: 0.5249 - val_f1: 0.1376\n",
      "Epoch 1734/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.1758 - f1: 0.8158 - val_loss: 0.5233 - val_f1: 0.1389\n",
      "Epoch 1735/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1788 - f1: 0.8128 - val_loss: 0.5261 - val_f1: 0.1371\n",
      "Epoch 1736/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1796 - f1: 0.8143 - val_loss: 0.5193 - val_f1: 0.1376\n",
      "Epoch 1737/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1769 - f1: 0.8191 - val_loss: 0.5171 - val_f1: 0.1395\n",
      "Epoch 1738/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1765 - f1: 0.8170 - val_loss: 0.5267 - val_f1: 0.1378\n",
      "Epoch 1739/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1760 - f1: 0.8180 - val_loss: 0.5176 - val_f1: 0.1391\n",
      "Epoch 1740/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1778 - f1: 0.8173 - val_loss: 0.5133 - val_f1: 0.1390\n",
      "Epoch 1741/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1742 - f1: 0.8184 - val_loss: 0.5312 - val_f1: 0.1380\n",
      "Epoch 1742/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1769 - f1: 0.8159 - val_loss: 0.5312 - val_f1: 0.1383\n",
      "Epoch 1743/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1787 - f1: 0.8163 - val_loss: 0.5263 - val_f1: 0.1377\n",
      "Epoch 1744/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1814 - f1: 0.8099 - val_loss: 0.5217 - val_f1: 0.1384\n",
      "Epoch 1745/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1762 - f1: 0.8175 - val_loss: 0.5211 - val_f1: 0.1386\n",
      "Epoch 1746/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1770 - f1: 0.8185 - val_loss: 0.5261 - val_f1: 0.1379\n",
      "Epoch 1747/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1765 - f1: 0.8154 - val_loss: 0.5176 - val_f1: 0.1397\n",
      "Epoch 1748/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1759 - f1: 0.8138 - val_loss: 0.5270 - val_f1: 0.1386\n",
      "Epoch 1749/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1785 - f1: 0.8147 - val_loss: 0.5243 - val_f1: 0.1381\n",
      "Epoch 1750/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1754 - f1: 0.8180 - val_loss: 0.5262 - val_f1: 0.1387\n",
      "Epoch 1751/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1764 - f1: 0.8141 - val_loss: 0.5265 - val_f1: 0.1386\n",
      "Epoch 1752/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1774 - f1: 0.8146 - val_loss: 0.5239 - val_f1: 0.1379\n",
      "Epoch 1753/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1763 - f1: 0.8186 - val_loss: 0.5224 - val_f1: 0.1388\n",
      "Epoch 1754/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1782 - f1: 0.8147 - val_loss: 0.5213 - val_f1: 0.1395\n",
      "Epoch 1755/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1748 - f1: 0.8185 - val_loss: 0.5315 - val_f1: 0.1378\n",
      "Epoch 1756/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1758 - f1: 0.8190 - val_loss: 0.5279 - val_f1: 0.1400\n",
      "Epoch 1757/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1794 - f1: 0.8158 - val_loss: 0.5193 - val_f1: 0.1382\n",
      "Epoch 1758/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1771 - f1: 0.8197 - val_loss: 0.5163 - val_f1: 0.1382\n",
      "Epoch 1759/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1784 - f1: 0.8112 - val_loss: 0.5278 - val_f1: 0.1389\n",
      "Epoch 1760/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1749 - f1: 0.8170 - val_loss: 0.5277 - val_f1: 0.1381\n",
      "Epoch 1761/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1780 - f1: 0.8135 - val_loss: 0.5211 - val_f1: 0.1380\n",
      "Epoch 1762/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1762 - f1: 0.8133 - val_loss: 0.5248 - val_f1: 0.1395\n",
      "Epoch 1763/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1751 - f1: 0.8169 - val_loss: 0.5175 - val_f1: 0.1395\n",
      "Epoch 1764/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1806 - f1: 0.8129 - val_loss: 0.5251 - val_f1: 0.1391\n",
      "Epoch 1765/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1775 - f1: 0.8162 - val_loss: 0.5243 - val_f1: 0.1393\n",
      "Epoch 1766/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1797 - f1: 0.8129 - val_loss: 0.5219 - val_f1: 0.1384\n",
      "Epoch 1767/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1769 - f1: 0.8176 - val_loss: 0.5247 - val_f1: 0.1386\n",
      "Epoch 1768/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1767 - f1: 0.8151 - val_loss: 0.5190 - val_f1: 0.1396\n",
      "Epoch 1769/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1778 - f1: 0.8172 - val_loss: 0.5341 - val_f1: 0.1377\n",
      "Epoch 1770/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1746 - f1: 0.8173 - val_loss: 0.5241 - val_f1: 0.1383\n",
      "Epoch 1771/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1740 - f1: 0.8199 - val_loss: 0.5236 - val_f1: 0.1387\n",
      "Epoch 1772/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1778 - f1: 0.8130 - val_loss: 0.5201 - val_f1: 0.1395\n",
      "Epoch 1773/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1785 - f1: 0.8167 - val_loss: 0.5260 - val_f1: 0.1372\n",
      "Epoch 1774/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1760 - f1: 0.8170 - val_loss: 0.5203 - val_f1: 0.1390\n",
      "Epoch 1775/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1756 - f1: 0.8167 - val_loss: 0.5325 - val_f1: 0.1381\n",
      "Epoch 1776/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1784 - f1: 0.8123 - val_loss: 0.5240 - val_f1: 0.1379\n",
      "Epoch 1777/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1797 - f1: 0.8111 - val_loss: 0.5225 - val_f1: 0.1376\n",
      "Epoch 1778/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1787 - f1: 0.8139 - val_loss: 0.5191 - val_f1: 0.1396\n",
      "Epoch 1779/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1746 - f1: 0.8198 - val_loss: 0.5232 - val_f1: 0.1394\n",
      "Epoch 1780/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1752 - f1: 0.8216 - val_loss: 0.5309 - val_f1: 0.1386\n",
      "Epoch 1781/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1791 - f1: 0.8131 - val_loss: 0.5267 - val_f1: 0.1379\n",
      "Epoch 1782/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1767 - f1: 0.8189 - val_loss: 0.5167 - val_f1: 0.1392\n",
      "Epoch 1783/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1762 - f1: 0.8187 - val_loss: 0.5245 - val_f1: 0.1391\n",
      "Epoch 1784/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1763 - f1: 0.8145 - val_loss: 0.5253 - val_f1: 0.1385\n",
      "Epoch 1785/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1784 - f1: 0.8134 - val_loss: 0.5213 - val_f1: 0.1386\n",
      "Epoch 1786/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1762 - f1: 0.8196 - val_loss: 0.5181 - val_f1: 0.1381\n",
      "Epoch 1787/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1749 - f1: 0.8175 - val_loss: 0.5258 - val_f1: 0.1390\n",
      "Epoch 1788/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1767 - f1: 0.8171 - val_loss: 0.5270 - val_f1: 0.1388\n",
      "Epoch 1789/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1755 - f1: 0.8223 - val_loss: 0.5334 - val_f1: 0.1380\n",
      "Epoch 1790/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1780 - f1: 0.8118 - val_loss: 0.5228 - val_f1: 0.1391\n",
      "Epoch 1791/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.1781 - f1: 0.8129 - val_loss: 0.5260 - val_f1: 0.1381\n",
      "Epoch 1792/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1780 - f1: 0.8133 - val_loss: 0.5178 - val_f1: 0.1384\n",
      "Epoch 1793/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1756 - f1: 0.8119 - val_loss: 0.5301 - val_f1: 0.1376\n",
      "Epoch 1794/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1782 - f1: 0.8181 - val_loss: 0.5193 - val_f1: 0.1387\n",
      "Epoch 1795/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1760 - f1: 0.8166 - val_loss: 0.5201 - val_f1: 0.1372\n",
      "Epoch 1796/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1741 - f1: 0.8171 - val_loss: 0.5272 - val_f1: 0.1375\n",
      "Epoch 1797/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1787 - f1: 0.8146 - val_loss: 0.5149 - val_f1: 0.1389\n",
      "Epoch 1798/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1778 - f1: 0.8145 - val_loss: 0.5181 - val_f1: 0.1384\n",
      "Epoch 1799/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1770 - f1: 0.8164 - val_loss: 0.5276 - val_f1: 0.1374\n",
      "Epoch 1800/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1792 - f1: 0.8132 - val_loss: 0.5310 - val_f1: 0.1370\n",
      "Epoch 1801/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1771 - f1: 0.8156 - val_loss: 0.5161 - val_f1: 0.1386\n",
      "Epoch 1802/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1774 - f1: 0.8138 - val_loss: 0.5216 - val_f1: 0.1374\n",
      "Epoch 1803/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1740 - f1: 0.8206 - val_loss: 0.5293 - val_f1: 0.1377\n",
      "Epoch 1804/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1756 - f1: 0.8164 - val_loss: 0.5202 - val_f1: 0.1385\n",
      "Epoch 1805/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1778 - f1: 0.8170 - val_loss: 0.5213 - val_f1: 0.1379\n",
      "Epoch 1806/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1740 - f1: 0.8199 - val_loss: 0.5202 - val_f1: 0.1394\n",
      "Epoch 1807/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1755 - f1: 0.8166 - val_loss: 0.5298 - val_f1: 0.1381\n",
      "Epoch 1808/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1767 - f1: 0.8150 - val_loss: 0.5226 - val_f1: 0.1387\n",
      "Epoch 1809/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1764 - f1: 0.8169 - val_loss: 0.5291 - val_f1: 0.1386\n",
      "Epoch 1810/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1799 - f1: 0.8131 - val_loss: 0.5198 - val_f1: 0.1387\n",
      "Epoch 1811/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1740 - f1: 0.8205 - val_loss: 0.5252 - val_f1: 0.1385\n",
      "Epoch 1812/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1775 - f1: 0.8174 - val_loss: 0.5277 - val_f1: 0.1389\n",
      "Epoch 1813/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1750 - f1: 0.8170 - val_loss: 0.5201 - val_f1: 0.1396\n",
      "Epoch 1814/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1775 - f1: 0.8131 - val_loss: 0.5281 - val_f1: 0.1383\n",
      "Epoch 1815/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1751 - f1: 0.8155 - val_loss: 0.5148 - val_f1: 0.1389\n",
      "Epoch 1816/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1730 - f1: 0.8206 - val_loss: 0.5255 - val_f1: 0.1383\n",
      "Epoch 1817/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1770 - f1: 0.8197 - val_loss: 0.5271 - val_f1: 0.1380\n",
      "Epoch 1818/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1781 - f1: 0.8123 - val_loss: 0.5221 - val_f1: 0.1391\n",
      "Epoch 1819/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1735 - f1: 0.8199 - val_loss: 0.5211 - val_f1: 0.1395\n",
      "Epoch 1820/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1768 - f1: 0.8192 - val_loss: 0.5207 - val_f1: 0.1379\n",
      "Epoch 1821/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1810 - f1: 0.8116 - val_loss: 0.5243 - val_f1: 0.1376\n",
      "Epoch 1822/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1746 - f1: 0.8153 - val_loss: 0.5285 - val_f1: 0.1386\n",
      "Epoch 1823/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1750 - f1: 0.8213 - val_loss: 0.5333 - val_f1: 0.1380\n",
      "Epoch 1824/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1768 - f1: 0.8168 - val_loss: 0.5261 - val_f1: 0.1380\n",
      "Epoch 1825/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1773 - f1: 0.8148 - val_loss: 0.5243 - val_f1: 0.1389\n",
      "Epoch 1826/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1760 - f1: 0.8154 - val_loss: 0.5262 - val_f1: 0.1382\n",
      "Epoch 1827/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1779 - f1: 0.8157 - val_loss: 0.5219 - val_f1: 0.1379\n",
      "Epoch 1828/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1789 - f1: 0.8158 - val_loss: 0.5259 - val_f1: 0.1379\n",
      "Epoch 1829/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1768 - f1: 0.8158 - val_loss: 0.5271 - val_f1: 0.1380\n",
      "Epoch 1830/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1746 - f1: 0.8191 - val_loss: 0.5221 - val_f1: 0.1379\n",
      "Epoch 1831/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1757 - f1: 0.8164 - val_loss: 0.5255 - val_f1: 0.1381\n",
      "Epoch 1832/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1762 - f1: 0.8184 - val_loss: 0.5292 - val_f1: 0.1389\n",
      "Epoch 1833/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1766 - f1: 0.8155 - val_loss: 0.5178 - val_f1: 0.1395\n",
      "Epoch 1834/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1765 - f1: 0.8197 - val_loss: 0.5228 - val_f1: 0.1382\n",
      "Epoch 1835/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1754 - f1: 0.8174 - val_loss: 0.5189 - val_f1: 0.1389\n",
      "Epoch 1836/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1753 - f1: 0.8144 - val_loss: 0.5277 - val_f1: 0.1381\n",
      "Epoch 1837/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1767 - f1: 0.8154 - val_loss: 0.5324 - val_f1: 0.1380\n",
      "Epoch 1838/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1770 - f1: 0.8158 - val_loss: 0.5253 - val_f1: 0.1380\n",
      "Epoch 1839/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1780 - f1: 0.8167 - val_loss: 0.5270 - val_f1: 0.1377\n",
      "Epoch 1840/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1745 - f1: 0.8219 - val_loss: 0.5399 - val_f1: 0.1373\n",
      "Epoch 1841/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1775 - f1: 0.8171 - val_loss: 0.5175 - val_f1: 0.1383\n",
      "Epoch 1842/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1756 - f1: 0.8184 - val_loss: 0.5255 - val_f1: 0.1379\n",
      "Epoch 1843/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1777 - f1: 0.8188 - val_loss: 0.5243 - val_f1: 0.1382\n",
      "Epoch 1844/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1771 - f1: 0.8195 - val_loss: 0.5278 - val_f1: 0.1381\n",
      "Epoch 1845/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1760 - f1: 0.8181 - val_loss: 0.5293 - val_f1: 0.1378\n",
      "Epoch 1846/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1750 - f1: 0.8185 - val_loss: 0.5288 - val_f1: 0.1374\n",
      "Epoch 1847/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1746 - f1: 0.8199 - val_loss: 0.5227 - val_f1: 0.1380\n",
      "Epoch 1848/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1767 - f1: 0.8168 - val_loss: 0.5127 - val_f1: 0.1392\n",
      "Epoch 1849/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1731 - f1: 0.8205 - val_loss: 0.5285 - val_f1: 0.1383\n",
      "Epoch 1850/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1763 - f1: 0.8156 - val_loss: 0.5263 - val_f1: 0.1379\n",
      "Epoch 1851/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1743 - f1: 0.8214 - val_loss: 0.5164 - val_f1: 0.1392\n",
      "Epoch 1852/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1774 - f1: 0.8157 - val_loss: 0.5213 - val_f1: 0.1377\n",
      "Epoch 1853/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1740 - f1: 0.8217 - val_loss: 0.5276 - val_f1: 0.1383\n",
      "Epoch 1854/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1756 - f1: 0.8180 - val_loss: 0.5214 - val_f1: 0.1382\n",
      "Epoch 1855/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1767 - f1: 0.8189 - val_loss: 0.5275 - val_f1: 0.1382\n",
      "Epoch 1856/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1725 - f1: 0.8249 - val_loss: 0.5248 - val_f1: 0.1379\n",
      "Epoch 1857/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1781 - f1: 0.8168 - val_loss: 0.5166 - val_f1: 0.1388\n",
      "Epoch 1858/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1764 - f1: 0.8127 - val_loss: 0.5255 - val_f1: 0.1379\n",
      "Epoch 1859/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.1749 - f1: 0.82 - 3s 49us/step - loss: 0.1749 - f1: 0.8198 - val_loss: 0.5308 - val_f1: 0.1371\n",
      "Epoch 1860/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1781 - f1: 0.8168 - val_loss: 0.5265 - val_f1: 0.1375\n",
      "Epoch 1861/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1778 - f1: 0.8145 - val_loss: 0.5205 - val_f1: 0.1377\n",
      "Epoch 1862/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1777 - f1: 0.8128 - val_loss: 0.5289 - val_f1: 0.1373\n",
      "Epoch 1863/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1763 - f1: 0.8154 - val_loss: 0.5156 - val_f1: 0.1392\n",
      "Epoch 1864/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1754 - f1: 0.8189 - val_loss: 0.5262 - val_f1: 0.1380\n",
      "Epoch 1865/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1767 - f1: 0.8161 - val_loss: 0.5145 - val_f1: 0.1390\n",
      "Epoch 1866/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1754 - f1: 0.8219 - val_loss: 0.5285 - val_f1: 0.1382\n",
      "Epoch 1867/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1768 - f1: 0.8176 - val_loss: 0.5214 - val_f1: 0.1380\n",
      "Epoch 1868/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1755 - f1: 0.8168 - val_loss: 0.5274 - val_f1: 0.1382\n",
      "Epoch 1869/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1790 - f1: 0.8157 - val_loss: 0.5234 - val_f1: 0.1378\n",
      "Epoch 1870/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1747 - f1: 0.8175 - val_loss: 0.5278 - val_f1: 0.1374\n",
      "Epoch 1871/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1753 - f1: 0.8185 - val_loss: 0.5284 - val_f1: 0.1374\n",
      "Epoch 1872/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.1756 - f1: 0.8223 - val_loss: 0.5293 - val_f1: 0.1375\n",
      "Epoch 1873/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1727 - f1: 0.8219 - val_loss: 0.5320 - val_f1: 0.1381\n",
      "Epoch 1874/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1767 - f1: 0.8164 - val_loss: 0.5298 - val_f1: 0.1380\n",
      "Epoch 1875/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1750 - f1: 0.8196 - val_loss: 0.5216 - val_f1: 0.1390\n",
      "Epoch 1876/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1736 - f1: 0.8207 - val_loss: 0.5249 - val_f1: 0.1389\n",
      "Epoch 1877/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1752 - f1: 0.8177 - val_loss: 0.5306 - val_f1: 0.1379\n",
      "Epoch 1878/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1771 - f1: 0.8160 - val_loss: 0.5131 - val_f1: 0.1396\n",
      "Epoch 1879/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1749 - f1: 0.8181 - val_loss: 0.5303 - val_f1: 0.1383\n",
      "Epoch 1880/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1752 - f1: 0.8173 - val_loss: 0.5250 - val_f1: 0.1378\n",
      "Epoch 1881/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1780 - f1: 0.8146 - val_loss: 0.5278 - val_f1: 0.1381\n",
      "Epoch 1882/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1754 - f1: 0.8187 - val_loss: 0.5295 - val_f1: 0.1378\n",
      "Epoch 1883/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1722 - f1: 0.8233 - val_loss: 0.5305 - val_f1: 0.1375\n",
      "Epoch 1884/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1752 - f1: 0.8234 - val_loss: 0.5196 - val_f1: 0.1383\n",
      "Epoch 1885/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1748 - f1: 0.8183 - val_loss: 0.5212 - val_f1: 0.1390\n",
      "Epoch 1886/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1747 - f1: 0.8203 - val_loss: 0.5288 - val_f1: 0.1371\n",
      "Epoch 1887/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1730 - f1: 0.8189 - val_loss: 0.5280 - val_f1: 0.1380\n",
      "Epoch 1888/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1743 - f1: 0.8222 - val_loss: 0.5232 - val_f1: 0.1392\n",
      "Epoch 1889/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1754 - f1: 0.8187 - val_loss: 0.5275 - val_f1: 0.1376\n",
      "Epoch 1890/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1756 - f1: 0.8134 - val_loss: 0.5263 - val_f1: 0.1376\n",
      "Epoch 1891/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1761 - f1: 0.8197 - val_loss: 0.5303 - val_f1: 0.1371\n",
      "Epoch 1892/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1773 - f1: 0.8161 - val_loss: 0.5217 - val_f1: 0.1375\n",
      "Epoch 1893/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1751 - f1: 0.8167 - val_loss: 0.5252 - val_f1: 0.1383\n",
      "Epoch 1894/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1760 - f1: 0.8166 - val_loss: 0.5247 - val_f1: 0.1387\n",
      "Epoch 1895/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1767 - f1: 0.8194 - val_loss: 0.5230 - val_f1: 0.1378\n",
      "Epoch 1896/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1736 - f1: 0.8198 - val_loss: 0.5329 - val_f1: 0.1378\n",
      "Epoch 1897/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1752 - f1: 0.8192 - val_loss: 0.5297 - val_f1: 0.1380\n",
      "Epoch 1898/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1718 - f1: 0.8228 - val_loss: 0.5284 - val_f1: 0.1380\n",
      "Epoch 1899/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1719 - f1: 0.8231 - val_loss: 0.5269 - val_f1: 0.1385\n",
      "Epoch 1900/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1737 - f1: 0.8222 - val_loss: 0.5226 - val_f1: 0.1388\n",
      "Epoch 1901/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1735 - f1: 0.8208 - val_loss: 0.5195 - val_f1: 0.1401\n",
      "Epoch 1902/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1751 - f1: 0.8185 - val_loss: 0.5311 - val_f1: 0.1385\n",
      "Epoch 1903/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1719 - f1: 0.8241 - val_loss: 0.5308 - val_f1: 0.1386\n",
      "Epoch 1904/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1752 - f1: 0.8195 - val_loss: 0.5281 - val_f1: 0.1376\n",
      "Epoch 1905/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1709 - f1: 0.8213 - val_loss: 0.5281 - val_f1: 0.1384\n",
      "Epoch 1906/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1748 - f1: 0.8224 - val_loss: 0.5266 - val_f1: 0.1383\n",
      "Epoch 1907/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1758 - f1: 0.8159 - val_loss: 0.5288 - val_f1: 0.1389\n",
      "Epoch 1908/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1753 - f1: 0.8148 - val_loss: 0.5310 - val_f1: 0.1385\n",
      "Epoch 1909/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1750 - f1: 0.8209 - val_loss: 0.5306 - val_f1: 0.1384\n",
      "Epoch 1910/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1749 - f1: 0.8189 - val_loss: 0.5222 - val_f1: 0.1393\n",
      "Epoch 1911/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1751 - f1: 0.8209 - val_loss: 0.5264 - val_f1: 0.1381\n",
      "Epoch 1912/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1744 - f1: 0.8212 - val_loss: 0.5219 - val_f1: 0.1390\n",
      "Epoch 1913/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1769 - f1: 0.8174 - val_loss: 0.5268 - val_f1: 0.1383\n",
      "Epoch 1914/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1748 - f1: 0.8182 - val_loss: 0.5309 - val_f1: 0.1382\n",
      "Epoch 1915/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1737 - f1: 0.8218 - val_loss: 0.5241 - val_f1: 0.1378\n",
      "Epoch 1916/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1748 - f1: 0.8183 - val_loss: 0.5339 - val_f1: 0.1372\n",
      "Epoch 1917/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1744 - f1: 0.8164 - val_loss: 0.5223 - val_f1: 0.1375\n",
      "Epoch 1918/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.1752 - f1: 0.8177 - val_loss: 0.5270 - val_f1: 0.1383\n",
      "Epoch 1919/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1735 - f1: 0.8193 - val_loss: 0.5261 - val_f1: 0.1388\n",
      "Epoch 1920/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1747 - f1: 0.8175 - val_loss: 0.5233 - val_f1: 0.1381\n",
      "Epoch 1921/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1756 - f1: 0.8178 - val_loss: 0.5179 - val_f1: 0.1389\n",
      "Epoch 1922/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1734 - f1: 0.8200 - val_loss: 0.5204 - val_f1: 0.1389\n",
      "Epoch 1923/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1748 - f1: 0.8208 - val_loss: 0.5269 - val_f1: 0.1388\n",
      "Epoch 1924/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1762 - f1: 0.8185 - val_loss: 0.5268 - val_f1: 0.1389\n",
      "Epoch 1925/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1739 - f1: 0.8205 - val_loss: 0.5251 - val_f1: 0.1388\n",
      "Epoch 1926/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1746 - f1: 0.8210 - val_loss: 0.5239 - val_f1: 0.1385\n",
      "Epoch 1927/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1744 - f1: 0.8195 - val_loss: 0.5264 - val_f1: 0.1388\n",
      "Epoch 1928/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1733 - f1: 0.8229 - val_loss: 0.5294 - val_f1: 0.1394\n",
      "Epoch 1929/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1744 - f1: 0.8194 - val_loss: 0.5269 - val_f1: 0.1381\n",
      "Epoch 1930/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1720 - f1: 0.8225 - val_loss: 0.5271 - val_f1: 0.1388\n",
      "Epoch 1931/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1752 - f1: 0.8199 - val_loss: 0.5309 - val_f1: 0.1380\n",
      "Epoch 1932/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1746 - f1: 0.8199 - val_loss: 0.5332 - val_f1: 0.1382\n",
      "Epoch 1933/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1757 - f1: 0.8176 - val_loss: 0.5260 - val_f1: 0.1387\n",
      "Epoch 1934/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1731 - f1: 0.8224 - val_loss: 0.5316 - val_f1: 0.1389\n",
      "Epoch 1935/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1740 - f1: 0.8216 - val_loss: 0.5204 - val_f1: 0.1381\n",
      "Epoch 1936/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1761 - f1: 0.8193 - val_loss: 0.5351 - val_f1: 0.1367\n",
      "Epoch 1937/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1731 - f1: 0.8164 - val_loss: 0.5322 - val_f1: 0.1377\n",
      "Epoch 1938/2000\n",
      "64440/64440 [==============================] - 3s 43us/step - loss: 0.1734 - f1: 0.8211 - val_loss: 0.5225 - val_f1: 0.1391\n",
      "Epoch 1939/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1743 - f1: 0.8183 - val_loss: 0.5317 - val_f1: 0.1378\n",
      "Epoch 1940/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1772 - f1: 0.8184 - val_loss: 0.5170 - val_f1: 0.1389\n",
      "Epoch 1941/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1761 - f1: 0.8206 - val_loss: 0.5316 - val_f1: 0.1372\n",
      "Epoch 1942/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1747 - f1: 0.8202 - val_loss: 0.5367 - val_f1: 0.1363\n",
      "Epoch 1943/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1731 - f1: 0.8209 - val_loss: 0.5277 - val_f1: 0.1377\n",
      "Epoch 1944/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1732 - f1: 0.8199 - val_loss: 0.5261 - val_f1: 0.1385\n",
      "Epoch 1945/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1749 - f1: 0.8191 - val_loss: 0.5359 - val_f1: 0.1369\n",
      "Epoch 1946/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1739 - f1: 0.8199 - val_loss: 0.5355 - val_f1: 0.1375\n",
      "Epoch 1947/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1734 - f1: 0.8192 - val_loss: 0.5302 - val_f1: 0.1383\n",
      "Epoch 1948/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1715 - f1: 0.8236 - val_loss: 0.5295 - val_f1: 0.1380\n",
      "Epoch 1949/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1763 - f1: 0.8179 - val_loss: 0.5203 - val_f1: 0.1384\n",
      "Epoch 1950/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1749 - f1: 0.8156 - val_loss: 0.5283 - val_f1: 0.1379\n",
      "Epoch 1951/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1750 - f1: 0.8207 - val_loss: 0.5195 - val_f1: 0.1392\n",
      "Epoch 1952/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1746 - f1: 0.8172 - val_loss: 0.5267 - val_f1: 0.1390\n",
      "Epoch 1953/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1743 - f1: 0.8205 - val_loss: 0.5250 - val_f1: 0.1397\n",
      "Epoch 1954/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1759 - f1: 0.8190 - val_loss: 0.5263 - val_f1: 0.1379\n",
      "Epoch 1955/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1759 - f1: 0.8191 - val_loss: 0.5250 - val_f1: 0.1384\n",
      "Epoch 1956/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1732 - f1: 0.8180 - val_loss: 0.5307 - val_f1: 0.1380\n",
      "Epoch 1957/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1735 - f1: 0.8209 - val_loss: 0.5257 - val_f1: 0.1383\n",
      "Epoch 1958/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1730 - f1: 0.8221 - val_loss: 0.5303 - val_f1: 0.1386\n",
      "Epoch 1959/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1790 - f1: 0.8142 - val_loss: 0.5267 - val_f1: 0.1377\n",
      "Epoch 1960/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1728 - f1: 0.8191 - val_loss: 0.5303 - val_f1: 0.1367\n",
      "Epoch 1961/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1715 - f1: 0.8173 - val_loss: 0.5269 - val_f1: 0.1381\n",
      "Epoch 1962/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1742 - f1: 0.8174 - val_loss: 0.5202 - val_f1: 0.1396\n",
      "Epoch 1963/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1719 - f1: 0.8225 - val_loss: 0.5291 - val_f1: 0.1383\n",
      "Epoch 1964/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1738 - f1: 0.8204 - val_loss: 0.5343 - val_f1: 0.1372\n",
      "Epoch 1965/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1759 - f1: 0.8175 - val_loss: 0.5308 - val_f1: 0.1374\n",
      "Epoch 1966/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1736 - f1: 0.8216 - val_loss: 0.5251 - val_f1: 0.1383\n",
      "Epoch 1967/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1760 - f1: 0.8160 - val_loss: 0.5327 - val_f1: 0.1369\n",
      "Epoch 1968/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1762 - f1: 0.8183 - val_loss: 0.5251 - val_f1: 0.1382\n",
      "Epoch 1969/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1726 - f1: 0.8218 - val_loss: 0.5323 - val_f1: 0.1369\n",
      "Epoch 1970/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1697 - f1: 0.8243 - val_loss: 0.5252 - val_f1: 0.1385\n",
      "Epoch 1971/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1745 - f1: 0.8190 - val_loss: 0.5281 - val_f1: 0.1377\n",
      "Epoch 1972/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1747 - f1: 0.8227 - val_loss: 0.5226 - val_f1: 0.1388\n",
      "Epoch 1973/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1703 - f1: 0.8247 - val_loss: 0.5409 - val_f1: 0.1371\n",
      "Epoch 1974/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1724 - f1: 0.8247 - val_loss: 0.5316 - val_f1: 0.1375\n",
      "Epoch 1975/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1725 - f1: 0.8231 - val_loss: 0.5244 - val_f1: 0.1387\n",
      "Epoch 1976/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1726 - f1: 0.8218 - val_loss: 0.5265 - val_f1: 0.1389\n",
      "Epoch 1977/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1756 - f1: 0.8180 - val_loss: 0.5232 - val_f1: 0.1393\n",
      "Epoch 1978/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1739 - f1: 0.8220 - val_loss: 0.5250 - val_f1: 0.1385\n",
      "Epoch 1979/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1739 - f1: 0.8202 - val_loss: 0.5293 - val_f1: 0.1377\n",
      "Epoch 1980/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1728 - f1: 0.8209 - val_loss: 0.5261 - val_f1: 0.1395\n",
      "Epoch 1981/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1701 - f1: 0.8262 - val_loss: 0.5345 - val_f1: 0.1386\n",
      "Epoch 1982/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1707 - f1: 0.8261 - val_loss: 0.5354 - val_f1: 0.1379\n",
      "Epoch 1983/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1757 - f1: 0.8186 - val_loss: 0.5243 - val_f1: 0.1385\n",
      "Epoch 1984/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1717 - f1: 0.8201 - val_loss: 0.5373 - val_f1: 0.1376\n",
      "Epoch 1985/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1734 - f1: 0.8191 - val_loss: 0.5344 - val_f1: 0.1379\n",
      "Epoch 1986/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1720 - f1: 0.8214 - val_loss: 0.5327 - val_f1: 0.1381\n",
      "Epoch 1987/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1747 - f1: 0.8210 - val_loss: 0.5286 - val_f1: 0.1378\n",
      "Epoch 1988/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.1756 - f1: 0.8185 - val_loss: 0.5199 - val_f1: 0.1390\n",
      "Epoch 1989/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1730 - f1: 0.8205 - val_loss: 0.5206 - val_f1: 0.1392\n",
      "Epoch 1990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1713 - f1: 0.8216 - val_loss: 0.5376 - val_f1: 0.1369\n",
      "Epoch 1991/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1723 - f1: 0.8208 - val_loss: 0.5306 - val_f1: 0.1386\n",
      "Epoch 1992/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1741 - f1: 0.8189 - val_loss: 0.5311 - val_f1: 0.1376\n",
      "Epoch 1993/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1755 - f1: 0.8200 - val_loss: 0.5160 - val_f1: 0.1391\n",
      "Epoch 1994/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1752 - f1: 0.8193 - val_loss: 0.5297 - val_f1: 0.1379\n",
      "Epoch 1995/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.1741 - f1: 0.8191 - val_loss: 0.5321 - val_f1: 0.1384\n",
      "Epoch 1996/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.1743 - f1: 0.8184 - val_loss: 0.5209 - val_f1: 0.1391\n",
      "Epoch 1997/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1730 - f1: 0.8223 - val_loss: 0.5372 - val_f1: 0.1377\n",
      "Epoch 1998/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1716 - f1: 0.8230 - val_loss: 0.5332 - val_f1: 0.1381\n",
      "Epoch 1999/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.1740 - f1: 0.8154 - val_loss: 0.5301 - val_f1: 0.1376\n",
      "Epoch 2000/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.1713 - f1: 0.8239 - val_loss: 0.5246 - val_f1: 0.1380\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna3.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[10116   678]\n",
      " [ 1641  1374]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[10084   711]\n",
      " [ 1614  1401]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[50296    76]\n",
      " [ 1273 12795]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna3.predict(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list4 = [50,50,50,1]\n",
    "activation_list4 = ['tanh','tanh','tanh','sigmoid']\n",
    "dropout_list4 = [0.3,0.3,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 15,201\n",
      "Trainable params: 15,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna4 = new_rna()\n",
    "rna4.build_model(data_shape,n_list4,activation_list4,dropout_list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64440 samples, validate on 13810 samples\n",
      "Epoch 1/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.4120 - f1: 0.4740 - val_loss: 0.3715 - val_f1: 0.1452\n",
      "Epoch 2/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3813 - f1: 0.5308 - val_loss: 0.3700 - val_f1: 0.1484\n",
      "Epoch 3/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3772 - f1: 0.5424 - val_loss: 0.3700 - val_f1: 0.1444\n",
      "Epoch 4/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3743 - f1: 0.5471 - val_loss: 0.3707 - val_f1: 0.1478\n",
      "Epoch 5/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3724 - f1: 0.5518 - val_loss: 0.3711 - val_f1: 0.1511\n",
      "Epoch 6/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3716 - f1: 0.5522 - val_loss: 0.3694 - val_f1: 0.1482\n",
      "Epoch 7/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3698 - f1: 0.5586 - val_loss: 0.3697 - val_f1: 0.1483\n",
      "Epoch 8/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3694 - f1: 0.5528 - val_loss: 0.3720 - val_f1: 0.1503\n",
      "Epoch 9/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3694 - f1: 0.5565 - val_loss: 0.3714 - val_f1: 0.1500\n",
      "Epoch 10/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3682 - f1: 0.5587 - val_loss: 0.3712 - val_f1: 0.1495\n",
      "Epoch 11/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3687 - f1: 0.5562 - val_loss: 0.3700 - val_f1: 0.1469\n",
      "Epoch 12/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3682 - f1: 0.5534 - val_loss: 0.3709 - val_f1: 0.1501\n",
      "Epoch 13/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3673 - f1: 0.5553 - val_loss: 0.3702 - val_f1: 0.1489\n",
      "Epoch 14/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3667 - f1: 0.5587 - val_loss: 0.3706 - val_f1: 0.1496\n",
      "Epoch 15/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3657 - f1: 0.5584 - val_loss: 0.3715 - val_f1: 0.1500\n",
      "Epoch 16/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3659 - f1: 0.5598 - val_loss: 0.3708 - val_f1: 0.1508\n",
      "Epoch 17/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3655 - f1: 0.5625 - val_loss: 0.3704 - val_f1: 0.1493\n",
      "Epoch 18/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3644 - f1: 0.5612 - val_loss: 0.3722 - val_f1: 0.1485\n",
      "Epoch 19/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3649 - f1: 0.5622 - val_loss: 0.3704 - val_f1: 0.1483\n",
      "Epoch 20/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3653 - f1: 0.5587 - val_loss: 0.3717 - val_f1: 0.1500\n",
      "Epoch 21/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3636 - f1: 0.5643 - val_loss: 0.3709 - val_f1: 0.1483\n",
      "Epoch 22/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3636 - f1: 0.5641 - val_loss: 0.3714 - val_f1: 0.1493\n",
      "Epoch 23/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3642 - f1: 0.5610 - val_loss: 0.3714 - val_f1: 0.1492\n",
      "Epoch 24/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3640 - f1: 0.5649 - val_loss: 0.3714 - val_f1: 0.1488\n",
      "Epoch 25/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3636 - f1: 0.5612 - val_loss: 0.3722 - val_f1: 0.1496\n",
      "Epoch 26/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3626 - f1: 0.5606 - val_loss: 0.3714 - val_f1: 0.1498\n",
      "Epoch 27/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3631 - f1: 0.5632 - val_loss: 0.3712 - val_f1: 0.1487\n",
      "Epoch 28/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3625 - f1: 0.5593 - val_loss: 0.3709 - val_f1: 0.1488\n",
      "Epoch 29/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3627 - f1: 0.5649 - val_loss: 0.3701 - val_f1: 0.1481\n",
      "Epoch 30/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3620 - f1: 0.5612 - val_loss: 0.3716 - val_f1: 0.1471\n",
      "Epoch 31/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3622 - f1: 0.5640 - val_loss: 0.3718 - val_f1: 0.1500\n",
      "Epoch 32/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3614 - f1: 0.5671 - val_loss: 0.3724 - val_f1: 0.1487\n",
      "Epoch 33/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3617 - f1: 0.5641 - val_loss: 0.3708 - val_f1: 0.1465\n",
      "Epoch 34/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3614 - f1: 0.5643 - val_loss: 0.3732 - val_f1: 0.1502\n",
      "Epoch 35/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3606 - f1: 0.5640 - val_loss: 0.3719 - val_f1: 0.1479\n",
      "Epoch 36/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3605 - f1: 0.5666 - val_loss: 0.3712 - val_f1: 0.1488\n",
      "Epoch 37/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3602 - f1: 0.5673 - val_loss: 0.3729 - val_f1: 0.1488\n",
      "Epoch 38/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3591 - f1: 0.5662 - val_loss: 0.3716 - val_f1: 0.1459\n",
      "Epoch 39/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3588 - f1: 0.5671 - val_loss: 0.3734 - val_f1: 0.1473\n",
      "Epoch 40/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3593 - f1: 0.5655 - val_loss: 0.3737 - val_f1: 0.1491\n",
      "Epoch 41/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3603 - f1: 0.5657 - val_loss: 0.3738 - val_f1: 0.1485\n",
      "Epoch 42/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3600 - f1: 0.5652 - val_loss: 0.3721 - val_f1: 0.1475\n",
      "Epoch 43/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3595 - f1: 0.5646 - val_loss: 0.3723 - val_f1: 0.1491\n",
      "Epoch 44/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3590 - f1: 0.5696 - val_loss: 0.3726 - val_f1: 0.1482\n",
      "Epoch 45/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3593 - f1: 0.5631 - val_loss: 0.3745 - val_f1: 0.1498\n",
      "Epoch 46/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3586 - f1: 0.5693 - val_loss: 0.3730 - val_f1: 0.1481\n",
      "Epoch 47/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3591 - f1: 0.5667 - val_loss: 0.3728 - val_f1: 0.1462\n",
      "Epoch 48/2000\n",
      "64440/64440 [==============================] - 3s 42us/step - loss: 0.3589 - f1: 0.5678 - val_loss: 0.3744 - val_f1: 0.1476\n",
      "Epoch 49/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.3578 - f1: 0.5660 - val_loss: 0.3732 - val_f1: 0.1488\n",
      "Epoch 50/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3582 - f1: 0.5652 - val_loss: 0.3752 - val_f1: 0.1494\n",
      "Epoch 51/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3576 - f1: 0.5662 - val_loss: 0.3739 - val_f1: 0.1487\n",
      "Epoch 52/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3566 - f1: 0.5712 - val_loss: 0.3734 - val_f1: 0.1481\n",
      "Epoch 53/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3577 - f1: 0.5663 - val_loss: 0.3731 - val_f1: 0.1475\n",
      "Epoch 54/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3561 - f1: 0.5675 - val_loss: 0.3742 - val_f1: 0.1479\n",
      "Epoch 55/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3571 - f1: 0.5701 - val_loss: 0.3740 - val_f1: 0.1464\n",
      "Epoch 56/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3574 - f1: 0.5622 - val_loss: 0.3729 - val_f1: 0.1483\n",
      "Epoch 57/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3564 - f1: 0.5684 - val_loss: 0.3724 - val_f1: 0.1476\n",
      "Epoch 58/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3555 - f1: 0.5701 - val_loss: 0.3734 - val_f1: 0.1471\n",
      "Epoch 59/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3555 - f1: 0.5688 - val_loss: 0.3733 - val_f1: 0.1485\n",
      "Epoch 60/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3557 - f1: 0.5717 - val_loss: 0.3738 - val_f1: 0.1476\n",
      "Epoch 61/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3553 - f1: 0.5713 - val_loss: 0.3739 - val_f1: 0.1466\n",
      "Epoch 62/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3555 - f1: 0.5659 - val_loss: 0.3753 - val_f1: 0.1479\n",
      "Epoch 63/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3551 - f1: 0.5718 - val_loss: 0.3742 - val_f1: 0.1476\n",
      "Epoch 64/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3546 - f1: 0.5722 - val_loss: 0.3745 - val_f1: 0.1471\n",
      "Epoch 65/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3551 - f1: 0.5700 - val_loss: 0.3744 - val_f1: 0.1486\n",
      "Epoch 66/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3544 - f1: 0.5690 - val_loss: 0.3740 - val_f1: 0.1473\n",
      "Epoch 67/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3545 - f1: 0.5693 - val_loss: 0.3751 - val_f1: 0.1490\n",
      "Epoch 68/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3548 - f1: 0.5686 - val_loss: 0.3754 - val_f1: 0.1481\n",
      "Epoch 69/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3538 - f1: 0.5703 - val_loss: 0.3746 - val_f1: 0.1476\n",
      "Epoch 70/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.3537 - f1: 0.5716 - val_loss: 0.3765 - val_f1: 0.1476\n",
      "Epoch 71/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3536 - f1: 0.5716 - val_loss: 0.3747 - val_f1: 0.1472\n",
      "Epoch 72/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3532 - f1: 0.5716 - val_loss: 0.3738 - val_f1: 0.1462\n",
      "Epoch 73/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3538 - f1: 0.5741 - val_loss: 0.3749 - val_f1: 0.1483\n",
      "Epoch 74/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3533 - f1: 0.5714 - val_loss: 0.3748 - val_f1: 0.1473\n",
      "Epoch 75/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3528 - f1: 0.5707 - val_loss: 0.3753 - val_f1: 0.1489\n",
      "Epoch 76/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3531 - f1: 0.5746 - val_loss: 0.3740 - val_f1: 0.1473\n",
      "Epoch 77/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3530 - f1: 0.5740 - val_loss: 0.3744 - val_f1: 0.1463\n",
      "Epoch 78/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3536 - f1: 0.5737 - val_loss: 0.3763 - val_f1: 0.1489\n",
      "Epoch 79/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3523 - f1: 0.5748 - val_loss: 0.3746 - val_f1: 0.1476\n",
      "Epoch 80/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3511 - f1: 0.5720 - val_loss: 0.3765 - val_f1: 0.1482\n",
      "Epoch 81/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3515 - f1: 0.5765 - val_loss: 0.3764 - val_f1: 0.1489\n",
      "Epoch 82/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3509 - f1: 0.5752 - val_loss: 0.3756 - val_f1: 0.1477\n",
      "Epoch 83/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3509 - f1: 0.5744 - val_loss: 0.3749 - val_f1: 0.1484\n",
      "Epoch 84/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3512 - f1: 0.5705 - val_loss: 0.3752 - val_f1: 0.1478\n",
      "Epoch 85/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3511 - f1: 0.5736 - val_loss: 0.3756 - val_f1: 0.1468\n",
      "Epoch 86/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3510 - f1: 0.5738 - val_loss: 0.3783 - val_f1: 0.1492\n",
      "Epoch 87/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3503 - f1: 0.5757 - val_loss: 0.3751 - val_f1: 0.1466\n",
      "Epoch 88/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3505 - f1: 0.5751 - val_loss: 0.3763 - val_f1: 0.1480\n",
      "Epoch 89/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3504 - f1: 0.5771 - val_loss: 0.3755 - val_f1: 0.1464\n",
      "Epoch 90/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3490 - f1: 0.5757 - val_loss: 0.3764 - val_f1: 0.1471\n",
      "Epoch 91/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3496 - f1: 0.5750 - val_loss: 0.3793 - val_f1: 0.1491\n",
      "Epoch 92/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3502 - f1: 0.5773 - val_loss: 0.3764 - val_f1: 0.1462\n",
      "Epoch 93/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3487 - f1: 0.5758 - val_loss: 0.3772 - val_f1: 0.1477\n",
      "Epoch 94/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3503 - f1: 0.5753 - val_loss: 0.3756 - val_f1: 0.1464\n",
      "Epoch 95/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3481 - f1: 0.5760 - val_loss: 0.3755 - val_f1: 0.1467\n",
      "Epoch 96/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3489 - f1: 0.5746 - val_loss: 0.3766 - val_f1: 0.1486\n",
      "Epoch 97/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3477 - f1: 0.5780 - val_loss: 0.3761 - val_f1: 0.1477\n",
      "Epoch 98/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3490 - f1: 0.5774 - val_loss: 0.3774 - val_f1: 0.1481\n",
      "Epoch 99/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3489 - f1: 0.5791 - val_loss: 0.3764 - val_f1: 0.1475\n",
      "Epoch 100/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3477 - f1: 0.5826 - val_loss: 0.3776 - val_f1: 0.1473\n",
      "Epoch 101/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3483 - f1: 0.5806 - val_loss: 0.3786 - val_f1: 0.1479\n",
      "Epoch 102/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3474 - f1: 0.5826 - val_loss: 0.3785 - val_f1: 0.1478\n",
      "Epoch 103/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3475 - f1: 0.5787 - val_loss: 0.3781 - val_f1: 0.1478\n",
      "Epoch 104/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3483 - f1: 0.5804 - val_loss: 0.3753 - val_f1: 0.1470\n",
      "Epoch 105/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3481 - f1: 0.5773 - val_loss: 0.3763 - val_f1: 0.1472\n",
      "Epoch 106/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3478 - f1: 0.5790 - val_loss: 0.3775 - val_f1: 0.1465\n",
      "Epoch 107/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3473 - f1: 0.5813 - val_loss: 0.3761 - val_f1: 0.1468\n",
      "Epoch 108/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3477 - f1: 0.5793 - val_loss: 0.3771 - val_f1: 0.1481\n",
      "Epoch 109/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3467 - f1: 0.5781 - val_loss: 0.3777 - val_f1: 0.1475\n",
      "Epoch 110/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3457 - f1: 0.5857 - val_loss: 0.3792 - val_f1: 0.1483\n",
      "Epoch 111/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3462 - f1: 0.5790 - val_loss: 0.3785 - val_f1: 0.1483\n",
      "Epoch 112/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3454 - f1: 0.5860 - val_loss: 0.3767 - val_f1: 0.1468\n",
      "Epoch 113/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3457 - f1: 0.5818 - val_loss: 0.3763 - val_f1: 0.1464\n",
      "Epoch 114/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3462 - f1: 0.5820 - val_loss: 0.3787 - val_f1: 0.1479\n",
      "Epoch 115/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3457 - f1: 0.5844 - val_loss: 0.3779 - val_f1: 0.1473\n",
      "Epoch 116/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3450 - f1: 0.5821 - val_loss: 0.3812 - val_f1: 0.1479\n",
      "Epoch 117/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3438 - f1: 0.5845 - val_loss: 0.3783 - val_f1: 0.1490\n",
      "Epoch 118/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3445 - f1: 0.5858 - val_loss: 0.3794 - val_f1: 0.1477\n",
      "Epoch 119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3453 - f1: 0.5814 - val_loss: 0.3781 - val_f1: 0.1479\n",
      "Epoch 120/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3442 - f1: 0.5852 - val_loss: 0.3804 - val_f1: 0.1477\n",
      "Epoch 121/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3451 - f1: 0.5863 - val_loss: 0.3781 - val_f1: 0.1471\n",
      "Epoch 122/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3446 - f1: 0.5857 - val_loss: 0.3785 - val_f1: 0.1481\n",
      "Epoch 123/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3435 - f1: 0.5860 - val_loss: 0.3796 - val_f1: 0.1485\n",
      "Epoch 124/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3443 - f1: 0.5852 - val_loss: 0.3791 - val_f1: 0.1488\n",
      "Epoch 125/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3427 - f1: 0.5889 - val_loss: 0.3783 - val_f1: 0.1466\n",
      "Epoch 126/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3420 - f1: 0.5896 - val_loss: 0.3799 - val_f1: 0.1474\n",
      "Epoch 127/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3432 - f1: 0.5852 - val_loss: 0.3790 - val_f1: 0.1472\n",
      "Epoch 128/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3419 - f1: 0.5854 - val_loss: 0.3792 - val_f1: 0.1472\n",
      "Epoch 129/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.3426 - f1: 0.5927 - val_loss: 0.3809 - val_f1: 0.1474\n",
      "Epoch 130/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3430 - f1: 0.5830 - val_loss: 0.3803 - val_f1: 0.1481\n",
      "Epoch 131/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3427 - f1: 0.5882 - val_loss: 0.3810 - val_f1: 0.1473\n",
      "Epoch 132/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3417 - f1: 0.5889 - val_loss: 0.3770 - val_f1: 0.1478\n",
      "Epoch 133/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3417 - f1: 0.5853 - val_loss: 0.3793 - val_f1: 0.1468\n",
      "Epoch 134/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3412 - f1: 0.5884 - val_loss: 0.3800 - val_f1: 0.1471\n",
      "Epoch 135/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3423 - f1: 0.5868 - val_loss: 0.3813 - val_f1: 0.1486\n",
      "Epoch 136/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3422 - f1: 0.5904 - val_loss: 0.3791 - val_f1: 0.1468\n",
      "Epoch 137/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3424 - f1: 0.5894 - val_loss: 0.3823 - val_f1: 0.1486\n",
      "Epoch 138/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3405 - f1: 0.5894 - val_loss: 0.3808 - val_f1: 0.1473\n",
      "Epoch 139/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3413 - f1: 0.5924 - val_loss: 0.3788 - val_f1: 0.1470\n",
      "Epoch 140/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3394 - f1: 0.5941 - val_loss: 0.3808 - val_f1: 0.1481\n",
      "Epoch 141/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3407 - f1: 0.5938 - val_loss: 0.3790 - val_f1: 0.1485\n",
      "Epoch 142/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3397 - f1: 0.5951 - val_loss: 0.3824 - val_f1: 0.1475\n",
      "Epoch 143/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3405 - f1: 0.5901 - val_loss: 0.3777 - val_f1: 0.1468\n",
      "Epoch 144/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3398 - f1: 0.5910 - val_loss: 0.3810 - val_f1: 0.1470\n",
      "Epoch 145/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3394 - f1: 0.5919 - val_loss: 0.3798 - val_f1: 0.1469\n",
      "Epoch 146/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3403 - f1: 0.5885 - val_loss: 0.3831 - val_f1: 0.1494\n",
      "Epoch 147/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3391 - f1: 0.5985 - val_loss: 0.3827 - val_f1: 0.1482\n",
      "Epoch 148/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3390 - f1: 0.5949 - val_loss: 0.3809 - val_f1: 0.1481\n",
      "Epoch 149/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3395 - f1: 0.5941 - val_loss: 0.3805 - val_f1: 0.1472\n",
      "Epoch 150/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3385 - f1: 0.5978 - val_loss: 0.3805 - val_f1: 0.1470\n",
      "Epoch 151/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3389 - f1: 0.5945 - val_loss: 0.3818 - val_f1: 0.1458\n",
      "Epoch 152/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3370 - f1: 0.5936 - val_loss: 0.3831 - val_f1: 0.1472\n",
      "Epoch 153/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3374 - f1: 0.5983 - val_loss: 0.3855 - val_f1: 0.1478\n",
      "Epoch 154/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3377 - f1: 0.5983 - val_loss: 0.3802 - val_f1: 0.1463\n",
      "Epoch 155/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3376 - f1: 0.5942 - val_loss: 0.3827 - val_f1: 0.1476\n",
      "Epoch 156/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3369 - f1: 0.5965 - val_loss: 0.3835 - val_f1: 0.1482\n",
      "Epoch 157/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3365 - f1: 0.5971 - val_loss: 0.3859 - val_f1: 0.1477\n",
      "Epoch 158/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3371 - f1: 0.5927 - val_loss: 0.3824 - val_f1: 0.1475\n",
      "Epoch 159/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3370 - f1: 0.5996 - val_loss: 0.3795 - val_f1: 0.1462\n",
      "Epoch 160/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3375 - f1: 0.5959 - val_loss: 0.3825 - val_f1: 0.1475\n",
      "Epoch 161/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3352 - f1: 0.6018 - val_loss: 0.3816 - val_f1: 0.1465\n",
      "Epoch 162/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3367 - f1: 0.5950 - val_loss: 0.3796 - val_f1: 0.1461\n",
      "Epoch 163/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3352 - f1: 0.5997 - val_loss: 0.3838 - val_f1: 0.1482\n",
      "Epoch 164/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3369 - f1: 0.5982 - val_loss: 0.3810 - val_f1: 0.1475\n",
      "Epoch 165/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3359 - f1: 0.5976 - val_loss: 0.3817 - val_f1: 0.1469\n",
      "Epoch 166/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3350 - f1: 0.5985 - val_loss: 0.3816 - val_f1: 0.1470\n",
      "Epoch 167/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3352 - f1: 0.6019 - val_loss: 0.3828 - val_f1: 0.1474\n",
      "Epoch 168/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3346 - f1: 0.6013 - val_loss: 0.3837 - val_f1: 0.1472\n",
      "Epoch 169/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3353 - f1: 0.5991 - val_loss: 0.3872 - val_f1: 0.1480\n",
      "Epoch 170/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3348 - f1: 0.6064 - val_loss: 0.3850 - val_f1: 0.1481\n",
      "Epoch 171/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3342 - f1: 0.6041 - val_loss: 0.3825 - val_f1: 0.1469\n",
      "Epoch 172/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3345 - f1: 0.6049 - val_loss: 0.3849 - val_f1: 0.1474\n",
      "Epoch 173/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3345 - f1: 0.6058 - val_loss: 0.3858 - val_f1: 0.1478\n",
      "Epoch 174/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3323 - f1: 0.6097 - val_loss: 0.3869 - val_f1: 0.1475\n",
      "Epoch 175/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3332 - f1: 0.6039 - val_loss: 0.3856 - val_f1: 0.1469\n",
      "Epoch 176/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3339 - f1: 0.6005 - val_loss: 0.3844 - val_f1: 0.1481\n",
      "Epoch 177/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3357 - f1: 0.6026 - val_loss: 0.3840 - val_f1: 0.1467\n",
      "Epoch 178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3330 - f1: 0.6037 - val_loss: 0.3835 - val_f1: 0.1484\n",
      "Epoch 179/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3338 - f1: 0.6058 - val_loss: 0.3816 - val_f1: 0.1462\n",
      "Epoch 180/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3343 - f1: 0.6023 - val_loss: 0.3828 - val_f1: 0.1474\n",
      "Epoch 181/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3337 - f1: 0.6043 - val_loss: 0.3864 - val_f1: 0.1468\n",
      "Epoch 182/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3329 - f1: 0.6088 - val_loss: 0.3842 - val_f1: 0.1477\n",
      "Epoch 183/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3332 - f1: 0.6088 - val_loss: 0.3849 - val_f1: 0.1473\n",
      "Epoch 184/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3326 - f1: 0.6084 - val_loss: 0.3823 - val_f1: 0.1465\n",
      "Epoch 185/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3330 - f1: 0.6074 - val_loss: 0.3840 - val_f1: 0.1470\n",
      "Epoch 186/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3333 - f1: 0.6037 - val_loss: 0.3841 - val_f1: 0.1482\n",
      "Epoch 187/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3311 - f1: 0.6116 - val_loss: 0.3857 - val_f1: 0.1465\n",
      "Epoch 188/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3323 - f1: 0.6042 - val_loss: 0.3850 - val_f1: 0.1462\n",
      "Epoch 189/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3313 - f1: 0.6064 - val_loss: 0.3834 - val_f1: 0.1460\n",
      "Epoch 190/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3316 - f1: 0.6086 - val_loss: 0.3845 - val_f1: 0.1470\n",
      "Epoch 191/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3302 - f1: 0.6133 - val_loss: 0.3861 - val_f1: 0.1465\n",
      "Epoch 192/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3294 - f1: 0.6130 - val_loss: 0.3860 - val_f1: 0.1464\n",
      "Epoch 193/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3313 - f1: 0.6034 - val_loss: 0.3848 - val_f1: 0.1460\n",
      "Epoch 194/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3308 - f1: 0.6070 - val_loss: 0.3825 - val_f1: 0.1466\n",
      "Epoch 195/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3300 - f1: 0.6124 - val_loss: 0.3859 - val_f1: 0.1475\n",
      "Epoch 196/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3296 - f1: 0.6094 - val_loss: 0.3886 - val_f1: 0.1481\n",
      "Epoch 197/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3297 - f1: 0.6138 - val_loss: 0.3836 - val_f1: 0.1464\n",
      "Epoch 198/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3302 - f1: 0.6107 - val_loss: 0.3837 - val_f1: 0.1472\n",
      "Epoch 199/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3292 - f1: 0.6105 - val_loss: 0.3857 - val_f1: 0.1469\n",
      "Epoch 200/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3298 - f1: 0.6093 - val_loss: 0.3851 - val_f1: 0.1468\n",
      "Epoch 201/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3301 - f1: 0.6099 - val_loss: 0.3859 - val_f1: 0.1462\n",
      "Epoch 202/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3290 - f1: 0.6123 - val_loss: 0.3835 - val_f1: 0.1479\n",
      "Epoch 203/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3300 - f1: 0.6162 - val_loss: 0.3874 - val_f1: 0.1465\n",
      "Epoch 204/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3295 - f1: 0.6091 - val_loss: 0.3877 - val_f1: 0.1480\n",
      "Epoch 205/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3282 - f1: 0.6109 - val_loss: 0.3866 - val_f1: 0.1479\n",
      "Epoch 206/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3291 - f1: 0.6124 - val_loss: 0.3840 - val_f1: 0.1460\n",
      "Epoch 207/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3291 - f1: 0.6109 - val_loss: 0.3867 - val_f1: 0.1475\n",
      "Epoch 208/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3273 - f1: 0.6144 - val_loss: 0.3859 - val_f1: 0.1470\n",
      "Epoch 209/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3290 - f1: 0.6112 - val_loss: 0.3886 - val_f1: 0.1464\n",
      "Epoch 210/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3269 - f1: 0.6179 - val_loss: 0.3882 - val_f1: 0.1477\n",
      "Epoch 211/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3270 - f1: 0.6118 - val_loss: 0.3870 - val_f1: 0.1477\n",
      "Epoch 212/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3271 - f1: 0.6158 - val_loss: 0.3900 - val_f1: 0.1479\n",
      "Epoch 213/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3269 - f1: 0.6179 - val_loss: 0.3853 - val_f1: 0.1477\n",
      "Epoch 214/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3285 - f1: 0.6107 - val_loss: 0.3876 - val_f1: 0.1464\n",
      "Epoch 215/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3278 - f1: 0.6177 - val_loss: 0.3924 - val_f1: 0.1477\n",
      "Epoch 216/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3276 - f1: 0.6137 - val_loss: 0.3894 - val_f1: 0.1474\n",
      "Epoch 217/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3280 - f1: 0.6181 - val_loss: 0.3877 - val_f1: 0.1468\n",
      "Epoch 218/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3259 - f1: 0.6198 - val_loss: 0.3925 - val_f1: 0.1482\n",
      "Epoch 219/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3255 - f1: 0.6186 - val_loss: 0.3898 - val_f1: 0.1473\n",
      "Epoch 220/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3263 - f1: 0.6140 - val_loss: 0.3925 - val_f1: 0.1480\n",
      "Epoch 221/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3264 - f1: 0.6159 - val_loss: 0.3909 - val_f1: 0.1471\n",
      "Epoch 222/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3253 - f1: 0.6220 - val_loss: 0.3900 - val_f1: 0.1466\n",
      "Epoch 223/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3265 - f1: 0.6164 - val_loss: 0.3886 - val_f1: 0.1473\n",
      "Epoch 224/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3260 - f1: 0.6170 - val_loss: 0.3883 - val_f1: 0.1459\n",
      "Epoch 225/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3263 - f1: 0.6181 - val_loss: 0.3909 - val_f1: 0.1479\n",
      "Epoch 226/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3243 - f1: 0.6217 - val_loss: 0.3883 - val_f1: 0.1472\n",
      "Epoch 227/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3246 - f1: 0.6210 - val_loss: 0.3903 - val_f1: 0.1481\n",
      "Epoch 228/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3253 - f1: 0.6218 - val_loss: 0.3901 - val_f1: 0.1479\n",
      "Epoch 229/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3258 - f1: 0.6223 - val_loss: 0.3892 - val_f1: 0.1473\n",
      "Epoch 230/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3257 - f1: 0.6141 - val_loss: 0.3880 - val_f1: 0.1475\n",
      "Epoch 231/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3241 - f1: 0.6203 - val_loss: 0.3892 - val_f1: 0.1477\n",
      "Epoch 232/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3243 - f1: 0.6166 - val_loss: 0.3870 - val_f1: 0.1476\n",
      "Epoch 233/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3253 - f1: 0.6157 - val_loss: 0.3880 - val_f1: 0.1472\n",
      "Epoch 234/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3241 - f1: 0.6238 - val_loss: 0.3924 - val_f1: 0.1477\n",
      "Epoch 235/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3234 - f1: 0.6259 - val_loss: 0.3898 - val_f1: 0.1476\n",
      "Epoch 236/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3231 - f1: 0.6221 - val_loss: 0.3932 - val_f1: 0.1479\n",
      "Epoch 237/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3241 - f1: 0.6236 - val_loss: 0.3913 - val_f1: 0.1469\n",
      "Epoch 238/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3247 - f1: 0.6233 - val_loss: 0.3934 - val_f1: 0.1471\n",
      "Epoch 239/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3247 - f1: 0.6172 - val_loss: 0.3892 - val_f1: 0.1474\n",
      "Epoch 240/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3226 - f1: 0.6275 - val_loss: 0.3885 - val_f1: 0.1473\n",
      "Epoch 241/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3243 - f1: 0.6217 - val_loss: 0.3919 - val_f1: 0.1481\n",
      "Epoch 242/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3250 - f1: 0.6209 - val_loss: 0.3908 - val_f1: 0.1477\n",
      "Epoch 243/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3228 - f1: 0.6271 - val_loss: 0.3901 - val_f1: 0.1469\n",
      "Epoch 244/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3233 - f1: 0.6262 - val_loss: 0.3917 - val_f1: 0.1469\n",
      "Epoch 245/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3209 - f1: 0.6281 - val_loss: 0.3896 - val_f1: 0.1476\n",
      "Epoch 246/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.3225 - f1: 0.62 - 3s 47us/step - loss: 0.3222 - f1: 0.6252 - val_loss: 0.3927 - val_f1: 0.1467\n",
      "Epoch 247/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3212 - f1: 0.6263 - val_loss: 0.3906 - val_f1: 0.1471\n",
      "Epoch 248/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3239 - f1: 0.6253 - val_loss: 0.3931 - val_f1: 0.1479\n",
      "Epoch 249/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3215 - f1: 0.6231 - val_loss: 0.3925 - val_f1: 0.1471\n",
      "Epoch 250/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3222 - f1: 0.6204 - val_loss: 0.3914 - val_f1: 0.1472\n",
      "Epoch 251/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3220 - f1: 0.6217 - val_loss: 0.3899 - val_f1: 0.1475\n",
      "Epoch 252/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3200 - f1: 0.6281 - val_loss: 0.3861 - val_f1: 0.1463\n",
      "Epoch 253/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3226 - f1: 0.6278 - val_loss: 0.3924 - val_f1: 0.1482\n",
      "Epoch 254/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3211 - f1: 0.6240 - val_loss: 0.3899 - val_f1: 0.1471\n",
      "Epoch 255/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3216 - f1: 0.6248 - val_loss: 0.3925 - val_f1: 0.1473\n",
      "Epoch 256/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3197 - f1: 0.6259 - val_loss: 0.3946 - val_f1: 0.1478\n",
      "Epoch 257/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3200 - f1: 0.6263 - val_loss: 0.3920 - val_f1: 0.1476\n",
      "Epoch 258/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3214 - f1: 0.6278 - val_loss: 0.3911 - val_f1: 0.1471\n",
      "Epoch 259/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3205 - f1: 0.6299 - val_loss: 0.3929 - val_f1: 0.1477\n",
      "Epoch 260/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3208 - f1: 0.6268 - val_loss: 0.3951 - val_f1: 0.1475\n",
      "Epoch 261/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3203 - f1: 0.6284 - val_loss: 0.3881 - val_f1: 0.1472\n",
      "Epoch 262/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3211 - f1: 0.6251 - val_loss: 0.3941 - val_f1: 0.1489\n",
      "Epoch 263/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3213 - f1: 0.6244 - val_loss: 0.3895 - val_f1: 0.1469\n",
      "Epoch 264/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3193 - f1: 0.6316 - val_loss: 0.3906 - val_f1: 0.1473\n",
      "Epoch 265/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3174 - f1: 0.6320 - val_loss: 0.3957 - val_f1: 0.1476\n",
      "Epoch 266/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3193 - f1: 0.6263 - val_loss: 0.3924 - val_f1: 0.1470\n",
      "Epoch 267/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3204 - f1: 0.6271 - val_loss: 0.3923 - val_f1: 0.1474\n",
      "Epoch 268/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3191 - f1: 0.6278 - val_loss: 0.3933 - val_f1: 0.1474\n",
      "Epoch 269/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3195 - f1: 0.6311 - val_loss: 0.3929 - val_f1: 0.1475\n",
      "Epoch 270/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3199 - f1: 0.6294 - val_loss: 0.3947 - val_f1: 0.1477\n",
      "Epoch 271/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3196 - f1: 0.6298 - val_loss: 0.3965 - val_f1: 0.1480\n",
      "Epoch 272/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3159 - f1: 0.6390 - val_loss: 0.3951 - val_f1: 0.1475\n",
      "Epoch 273/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3168 - f1: 0.6333 - val_loss: 0.3921 - val_f1: 0.1469\n",
      "Epoch 274/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3170 - f1: 0.6353 - val_loss: 0.3940 - val_f1: 0.1476\n",
      "Epoch 275/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3168 - f1: 0.6399 - val_loss: 0.3923 - val_f1: 0.1454\n",
      "Epoch 276/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3187 - f1: 0.6310 - val_loss: 0.3942 - val_f1: 0.1474\n",
      "Epoch 277/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3163 - f1: 0.6344 - val_loss: 0.3947 - val_f1: 0.1467\n",
      "Epoch 278/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3168 - f1: 0.6310 - val_loss: 0.3981 - val_f1: 0.1476\n",
      "Epoch 279/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3178 - f1: 0.6342 - val_loss: 0.3915 - val_f1: 0.1462\n",
      "Epoch 280/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3156 - f1: 0.6334 - val_loss: 0.3940 - val_f1: 0.1471\n",
      "Epoch 281/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3180 - f1: 0.6313 - val_loss: 0.3938 - val_f1: 0.1461\n",
      "Epoch 282/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3175 - f1: 0.6311 - val_loss: 0.3917 - val_f1: 0.1467\n",
      "Epoch 283/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3166 - f1: 0.6357 - val_loss: 0.3917 - val_f1: 0.1466\n",
      "Epoch 284/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3152 - f1: 0.6401 - val_loss: 0.3945 - val_f1: 0.1466\n",
      "Epoch 285/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3173 - f1: 0.6329 - val_loss: 0.3961 - val_f1: 0.1477\n",
      "Epoch 286/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3168 - f1: 0.6323 - val_loss: 0.3965 - val_f1: 0.1479\n",
      "Epoch 287/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3162 - f1: 0.6338 - val_loss: 0.3947 - val_f1: 0.1472\n",
      "Epoch 288/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3170 - f1: 0.6326 - val_loss: 0.3973 - val_f1: 0.1478\n",
      "Epoch 289/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3168 - f1: 0.6331 - val_loss: 0.3977 - val_f1: 0.1479\n",
      "Epoch 290/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3158 - f1: 0.6388 - val_loss: 0.3914 - val_f1: 0.1471\n",
      "Epoch 291/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3148 - f1: 0.6352 - val_loss: 0.3938 - val_f1: 0.1470\n",
      "Epoch 292/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3156 - f1: 0.6328 - val_loss: 0.3964 - val_f1: 0.1467\n",
      "Epoch 293/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3150 - f1: 0.6378 - val_loss: 0.3953 - val_f1: 0.1473\n",
      "Epoch 294/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3161 - f1: 0.6323 - val_loss: 0.3932 - val_f1: 0.1477\n",
      "Epoch 295/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3158 - f1: 0.6392 - val_loss: 0.3930 - val_f1: 0.1465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3153 - f1: 0.6367 - val_loss: 0.3925 - val_f1: 0.1466\n",
      "Epoch 297/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3142 - f1: 0.6369 - val_loss: 0.3945 - val_f1: 0.1468\n",
      "Epoch 298/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3160 - f1: 0.6367 - val_loss: 0.3934 - val_f1: 0.1466\n",
      "Epoch 299/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3149 - f1: 0.6355 - val_loss: 0.3935 - val_f1: 0.1467\n",
      "Epoch 300/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3132 - f1: 0.6408 - val_loss: 0.3935 - val_f1: 0.1460\n",
      "Epoch 301/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3148 - f1: 0.6383 - val_loss: 0.3940 - val_f1: 0.1471\n",
      "Epoch 302/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3140 - f1: 0.6391 - val_loss: 0.3950 - val_f1: 0.1472\n",
      "Epoch 303/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3143 - f1: 0.6377 - val_loss: 0.3973 - val_f1: 0.1480\n",
      "Epoch 304/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3159 - f1: 0.6348 - val_loss: 0.3942 - val_f1: 0.1469\n",
      "Epoch 305/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3145 - f1: 0.6355 - val_loss: 0.3925 - val_f1: 0.1469\n",
      "Epoch 306/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3127 - f1: 0.6394 - val_loss: 0.3966 - val_f1: 0.1466\n",
      "Epoch 307/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3140 - f1: 0.6409 - val_loss: 0.3916 - val_f1: 0.1460\n",
      "Epoch 308/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3128 - f1: 0.6415 - val_loss: 0.4016 - val_f1: 0.1481\n",
      "Epoch 309/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3146 - f1: 0.6354 - val_loss: 0.3963 - val_f1: 0.1474\n",
      "Epoch 310/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3142 - f1: 0.6355 - val_loss: 0.3947 - val_f1: 0.1475\n",
      "Epoch 311/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3138 - f1: 0.6407 - val_loss: 0.3969 - val_f1: 0.1478\n",
      "Epoch 312/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3131 - f1: 0.6453 - val_loss: 0.3978 - val_f1: 0.1489\n",
      "Epoch 313/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3110 - f1: 0.6456 - val_loss: 0.3963 - val_f1: 0.1466\n",
      "Epoch 314/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3146 - f1: 0.6414 - val_loss: 0.4013 - val_f1: 0.1478\n",
      "Epoch 315/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3126 - f1: 0.6399 - val_loss: 0.3947 - val_f1: 0.1459\n",
      "Epoch 316/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3114 - f1: 0.6427 - val_loss: 0.3969 - val_f1: 0.1466\n",
      "Epoch 317/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3130 - f1: 0.6417 - val_loss: 0.3971 - val_f1: 0.1468\n",
      "Epoch 318/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3141 - f1: 0.6411 - val_loss: 0.4014 - val_f1: 0.1470\n",
      "Epoch 319/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3126 - f1: 0.6373 - val_loss: 0.3986 - val_f1: 0.1463\n",
      "Epoch 320/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3105 - f1: 0.6433 - val_loss: 0.3959 - val_f1: 0.1465\n",
      "Epoch 321/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3118 - f1: 0.6433 - val_loss: 0.3958 - val_f1: 0.1466\n",
      "Epoch 322/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3115 - f1: 0.6436 - val_loss: 0.4004 - val_f1: 0.1470\n",
      "Epoch 323/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3131 - f1: 0.6410 - val_loss: 0.3977 - val_f1: 0.1471\n",
      "Epoch 324/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3115 - f1: 0.6406 - val_loss: 0.3970 - val_f1: 0.1471\n",
      "Epoch 325/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3126 - f1: 0.6441 - val_loss: 0.3963 - val_f1: 0.1463\n",
      "Epoch 326/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3108 - f1: 0.6437 - val_loss: 0.3965 - val_f1: 0.1466\n",
      "Epoch 327/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3105 - f1: 0.6445 - val_loss: 0.3981 - val_f1: 0.1462\n",
      "Epoch 328/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3134 - f1: 0.6427 - val_loss: 0.3986 - val_f1: 0.1464\n",
      "Epoch 329/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3103 - f1: 0.6439 - val_loss: 0.3989 - val_f1: 0.1470\n",
      "Epoch 330/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3107 - f1: 0.6426 - val_loss: 0.4025 - val_f1: 0.1472\n",
      "Epoch 331/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3122 - f1: 0.6418 - val_loss: 0.3986 - val_f1: 0.1460\n",
      "Epoch 332/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3112 - f1: 0.6426 - val_loss: 0.3971 - val_f1: 0.1464\n",
      "Epoch 333/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3109 - f1: 0.6417 - val_loss: 0.3998 - val_f1: 0.1471\n",
      "Epoch 334/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3132 - f1: 0.6420 - val_loss: 0.3955 - val_f1: 0.1453\n",
      "Epoch 335/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3100 - f1: 0.6460 - val_loss: 0.3981 - val_f1: 0.1458\n",
      "Epoch 336/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3103 - f1: 0.6421 - val_loss: 0.3986 - val_f1: 0.1470\n",
      "Epoch 337/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3105 - f1: 0.6474 - val_loss: 0.4001 - val_f1: 0.1484\n",
      "Epoch 338/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3098 - f1: 0.6448 - val_loss: 0.3970 - val_f1: 0.1469\n",
      "Epoch 339/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3114 - f1: 0.6463 - val_loss: 0.3977 - val_f1: 0.1459\n",
      "Epoch 340/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3103 - f1: 0.6440 - val_loss: 0.3970 - val_f1: 0.1461\n",
      "Epoch 341/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3079 - f1: 0.6475 - val_loss: 0.3994 - val_f1: 0.1470\n",
      "Epoch 342/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3087 - f1: 0.6454 - val_loss: 0.3973 - val_f1: 0.1461\n",
      "Epoch 343/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3090 - f1: 0.6470 - val_loss: 0.3987 - val_f1: 0.1465\n",
      "Epoch 344/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3090 - f1: 0.6474 - val_loss: 0.4006 - val_f1: 0.1475\n",
      "Epoch 345/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3077 - f1: 0.6488 - val_loss: 0.3994 - val_f1: 0.1469\n",
      "Epoch 346/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3106 - f1: 0.6496 - val_loss: 0.3997 - val_f1: 0.1473\n",
      "Epoch 347/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3094 - f1: 0.6483 - val_loss: 0.3959 - val_f1: 0.1465\n",
      "Epoch 348/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3092 - f1: 0.6483 - val_loss: 0.3992 - val_f1: 0.1470\n",
      "Epoch 349/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3083 - f1: 0.6484 - val_loss: 0.4006 - val_f1: 0.1468\n",
      "Epoch 350/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3091 - f1: 0.6474 - val_loss: 0.3968 - val_f1: 0.1463\n",
      "Epoch 351/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3073 - f1: 0.6458 - val_loss: 0.3979 - val_f1: 0.1462\n",
      "Epoch 352/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3073 - f1: 0.6504 - val_loss: 0.4003 - val_f1: 0.1473\n",
      "Epoch 353/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3073 - f1: 0.6476 - val_loss: 0.3987 - val_f1: 0.1470\n",
      "Epoch 354/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3084 - f1: 0.6527 - val_loss: 0.3982 - val_f1: 0.1459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3082 - f1: 0.6487 - val_loss: 0.4033 - val_f1: 0.1468\n",
      "Epoch 356/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.3085 - f1: 0.6506 - val_loss: 0.4030 - val_f1: 0.1468\n",
      "Epoch 357/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3091 - f1: 0.6496 - val_loss: 0.4030 - val_f1: 0.1473\n",
      "Epoch 358/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3089 - f1: 0.6462 - val_loss: 0.3977 - val_f1: 0.1463\n",
      "Epoch 359/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3097 - f1: 0.6487 - val_loss: 0.3943 - val_f1: 0.1456\n",
      "Epoch 360/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3085 - f1: 0.6467 - val_loss: 0.4023 - val_f1: 0.1476\n",
      "Epoch 361/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3076 - f1: 0.6493 - val_loss: 0.4020 - val_f1: 0.1474\n",
      "Epoch 362/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3081 - f1: 0.6492 - val_loss: 0.4006 - val_f1: 0.1471\n",
      "Epoch 363/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3057 - f1: 0.6523 - val_loss: 0.3992 - val_f1: 0.1467\n",
      "Epoch 364/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3084 - f1: 0.6507 - val_loss: 0.3990 - val_f1: 0.1465\n",
      "Epoch 365/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3067 - f1: 0.6445 - val_loss: 0.4019 - val_f1: 0.1484\n",
      "Epoch 366/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3067 - f1: 0.6504 - val_loss: 0.3979 - val_f1: 0.1469\n",
      "Epoch 367/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3052 - f1: 0.6545 - val_loss: 0.4013 - val_f1: 0.1466\n",
      "Epoch 368/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3066 - f1: 0.6522 - val_loss: 0.4046 - val_f1: 0.1482\n",
      "Epoch 369/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3056 - f1: 0.6545 - val_loss: 0.4006 - val_f1: 0.1468\n",
      "Epoch 370/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3060 - f1: 0.6508 - val_loss: 0.3994 - val_f1: 0.1466\n",
      "Epoch 371/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3082 - f1: 0.6502 - val_loss: 0.3991 - val_f1: 0.1457\n",
      "Epoch 372/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3058 - f1: 0.6522 - val_loss: 0.4000 - val_f1: 0.1467\n",
      "Epoch 373/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3075 - f1: 0.6498 - val_loss: 0.3986 - val_f1: 0.1475\n",
      "Epoch 374/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3061 - f1: 0.6502 - val_loss: 0.4042 - val_f1: 0.1473\n",
      "Epoch 375/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3078 - f1: 0.6516 - val_loss: 0.4028 - val_f1: 0.1470\n",
      "Epoch 376/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3075 - f1: 0.6475 - val_loss: 0.4018 - val_f1: 0.1472\n",
      "Epoch 377/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3062 - f1: 0.6495 - val_loss: 0.4008 - val_f1: 0.1467\n",
      "Epoch 378/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3066 - f1: 0.6506 - val_loss: 0.3998 - val_f1: 0.1470\n",
      "Epoch 379/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3041 - f1: 0.6523 - val_loss: 0.4008 - val_f1: 0.1463\n",
      "Epoch 380/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3070 - f1: 0.6520 - val_loss: 0.4008 - val_f1: 0.1473\n",
      "Epoch 381/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3063 - f1: 0.6524 - val_loss: 0.3999 - val_f1: 0.1469\n",
      "Epoch 382/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3054 - f1: 0.6565 - val_loss: 0.3991 - val_f1: 0.1456\n",
      "Epoch 383/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3045 - f1: 0.6525 - val_loss: 0.4014 - val_f1: 0.1468\n",
      "Epoch 384/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3057 - f1: 0.6509 - val_loss: 0.4037 - val_f1: 0.1473\n",
      "Epoch 385/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3062 - f1: 0.6525 - val_loss: 0.4004 - val_f1: 0.1464\n",
      "Epoch 386/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3048 - f1: 0.6577 - val_loss: 0.4023 - val_f1: 0.1467\n",
      "Epoch 387/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3049 - f1: 0.6539 - val_loss: 0.4030 - val_f1: 0.1462\n",
      "Epoch 388/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3037 - f1: 0.6560 - val_loss: 0.4044 - val_f1: 0.1459\n",
      "Epoch 389/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3038 - f1: 0.6555 - val_loss: 0.4047 - val_f1: 0.1467\n",
      "Epoch 390/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3071 - f1: 0.6498 - val_loss: 0.4041 - val_f1: 0.1458\n",
      "Epoch 391/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3047 - f1: 0.6557 - val_loss: 0.4080 - val_f1: 0.1464\n",
      "Epoch 392/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3049 - f1: 0.6537 - val_loss: 0.3968 - val_f1: 0.1457\n",
      "Epoch 393/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3037 - f1: 0.6561 - val_loss: 0.3990 - val_f1: 0.1465\n",
      "Epoch 394/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3045 - f1: 0.6614 - val_loss: 0.4001 - val_f1: 0.1461\n",
      "Epoch 395/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3052 - f1: 0.6522 - val_loss: 0.4026 - val_f1: 0.1469\n",
      "Epoch 396/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3047 - f1: 0.6493 - val_loss: 0.4045 - val_f1: 0.1469\n",
      "Epoch 397/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3047 - f1: 0.6529 - val_loss: 0.4079 - val_f1: 0.1474\n",
      "Epoch 398/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3030 - f1: 0.6572 - val_loss: 0.4049 - val_f1: 0.1460\n",
      "Epoch 399/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3063 - f1: 0.6500 - val_loss: 0.3976 - val_f1: 0.1451\n",
      "Epoch 400/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3060 - f1: 0.6476 - val_loss: 0.4014 - val_f1: 0.1477\n",
      "Epoch 401/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3020 - f1: 0.6571 - val_loss: 0.4049 - val_f1: 0.1472\n",
      "Epoch 402/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3047 - f1: 0.6563 - val_loss: 0.3994 - val_f1: 0.1453\n",
      "Epoch 403/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3044 - f1: 0.6540 - val_loss: 0.4012 - val_f1: 0.1463\n",
      "Epoch 404/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3023 - f1: 0.6560 - val_loss: 0.4019 - val_f1: 0.1470\n",
      "Epoch 405/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3034 - f1: 0.6574 - val_loss: 0.4022 - val_f1: 0.1461\n",
      "Epoch 406/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3029 - f1: 0.6599 - val_loss: 0.4019 - val_f1: 0.1472\n",
      "Epoch 407/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3032 - f1: 0.6590 - val_loss: 0.4043 - val_f1: 0.1473\n",
      "Epoch 408/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3028 - f1: 0.6571 - val_loss: 0.4003 - val_f1: 0.1457\n",
      "Epoch 409/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3009 - f1: 0.6593 - val_loss: 0.4023 - val_f1: 0.1474\n",
      "Epoch 410/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3031 - f1: 0.6553 - val_loss: 0.4048 - val_f1: 0.1465\n",
      "Epoch 411/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3032 - f1: 0.6603 - val_loss: 0.4031 - val_f1: 0.1464\n",
      "Epoch 412/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3016 - f1: 0.6611 - val_loss: 0.4067 - val_f1: 0.1471\n",
      "Epoch 413/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3027 - f1: 0.6561 - val_loss: 0.4064 - val_f1: 0.1479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 414/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3033 - f1: 0.6603 - val_loss: 0.4039 - val_f1: 0.1467\n",
      "Epoch 415/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3033 - f1: 0.6562 - val_loss: 0.4022 - val_f1: 0.1464\n",
      "Epoch 416/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3021 - f1: 0.6518 - val_loss: 0.4012 - val_f1: 0.1464\n",
      "Epoch 417/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3028 - f1: 0.6575 - val_loss: 0.4004 - val_f1: 0.1446\n",
      "Epoch 418/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3012 - f1: 0.6572 - val_loss: 0.4019 - val_f1: 0.1462\n",
      "Epoch 419/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3030 - f1: 0.6579 - val_loss: 0.4045 - val_f1: 0.1470\n",
      "Epoch 420/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3033 - f1: 0.6538 - val_loss: 0.4029 - val_f1: 0.1467\n",
      "Epoch 421/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3035 - f1: 0.6572 - val_loss: 0.4030 - val_f1: 0.1463\n",
      "Epoch 422/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3014 - f1: 0.6595 - val_loss: 0.4017 - val_f1: 0.1474\n",
      "Epoch 423/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3017 - f1: 0.6614 - val_loss: 0.4054 - val_f1: 0.1470\n",
      "Epoch 424/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3030 - f1: 0.6566 - val_loss: 0.4072 - val_f1: 0.1481\n",
      "Epoch 425/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3013 - f1: 0.6609 - val_loss: 0.4045 - val_f1: 0.1460\n",
      "Epoch 426/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3043 - f1: 0.6581 - val_loss: 0.4026 - val_f1: 0.1460\n",
      "Epoch 427/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3022 - f1: 0.6584 - val_loss: 0.4037 - val_f1: 0.1469\n",
      "Epoch 428/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3022 - f1: 0.6586 - val_loss: 0.4003 - val_f1: 0.1461\n",
      "Epoch 429/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3028 - f1: 0.6609 - val_loss: 0.4048 - val_f1: 0.1468\n",
      "Epoch 430/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3016 - f1: 0.6610 - val_loss: 0.4080 - val_f1: 0.1472\n",
      "Epoch 431/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3023 - f1: 0.6573 - val_loss: 0.4027 - val_f1: 0.1463\n",
      "Epoch 432/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3003 - f1: 0.6575 - val_loss: 0.4081 - val_f1: 0.1476\n",
      "Epoch 433/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2992 - f1: 0.6652 - val_loss: 0.4043 - val_f1: 0.1465\n",
      "Epoch 434/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2987 - f1: 0.6616 - val_loss: 0.4055 - val_f1: 0.1470\n",
      "Epoch 435/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3012 - f1: 0.6595 - val_loss: 0.4022 - val_f1: 0.1456\n",
      "Epoch 436/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3020 - f1: 0.6561 - val_loss: 0.4058 - val_f1: 0.1462\n",
      "Epoch 437/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3004 - f1: 0.6604 - val_loss: 0.4049 - val_f1: 0.1462\n",
      "Epoch 438/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3017 - f1: 0.6585 - val_loss: 0.4037 - val_f1: 0.1458\n",
      "Epoch 439/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3010 - f1: 0.6615 - val_loss: 0.4012 - val_f1: 0.1458\n",
      "Epoch 440/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3019 - f1: 0.6608 - val_loss: 0.3991 - val_f1: 0.1447\n",
      "Epoch 441/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3033 - f1: 0.6552 - val_loss: 0.4040 - val_f1: 0.1464\n",
      "Epoch 442/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3018 - f1: 0.6620 - val_loss: 0.4057 - val_f1: 0.1470\n",
      "Epoch 443/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3007 - f1: 0.6578 - val_loss: 0.4046 - val_f1: 0.1463\n",
      "Epoch 444/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3009 - f1: 0.6618 - val_loss: 0.4065 - val_f1: 0.1469\n",
      "Epoch 445/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3010 - f1: 0.6593 - val_loss: 0.4058 - val_f1: 0.1462\n",
      "Epoch 446/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3014 - f1: 0.6621 - val_loss: 0.4081 - val_f1: 0.1461\n",
      "Epoch 447/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3005 - f1: 0.6594 - val_loss: 0.4059 - val_f1: 0.1459\n",
      "Epoch 448/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2987 - f1: 0.6628 - val_loss: 0.4101 - val_f1: 0.1464\n",
      "Epoch 449/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2994 - f1: 0.6612 - val_loss: 0.4027 - val_f1: 0.1455\n",
      "Epoch 450/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3002 - f1: 0.6610 - val_loss: 0.4069 - val_f1: 0.1461\n",
      "Epoch 451/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2983 - f1: 0.6638 - val_loss: 0.4075 - val_f1: 0.1461\n",
      "Epoch 452/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3009 - f1: 0.6574 - val_loss: 0.4031 - val_f1: 0.1459\n",
      "Epoch 453/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.3000 - f1: 0.6643 - val_loss: 0.4057 - val_f1: 0.1456\n",
      "Epoch 454/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2990 - f1: 0.6648 - val_loss: 0.4072 - val_f1: 0.1461\n",
      "Epoch 455/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2994 - f1: 0.6631 - val_loss: 0.4048 - val_f1: 0.1460\n",
      "Epoch 456/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2987 - f1: 0.6689 - val_loss: 0.4060 - val_f1: 0.1469\n",
      "Epoch 457/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2978 - f1: 0.6634 - val_loss: 0.4065 - val_f1: 0.1459\n",
      "Epoch 458/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2991 - f1: 0.6637 - val_loss: 0.4047 - val_f1: 0.1459\n",
      "Epoch 459/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.3013 - f1: 0.6596 - val_loss: 0.4051 - val_f1: 0.1453\n",
      "Epoch 460/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2981 - f1: 0.6632 - val_loss: 0.4056 - val_f1: 0.1455\n",
      "Epoch 461/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2968 - f1: 0.6702 - val_loss: 0.4099 - val_f1: 0.1467\n",
      "Epoch 462/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2974 - f1: 0.6662 - val_loss: 0.4114 - val_f1: 0.1460\n",
      "Epoch 463/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2987 - f1: 0.6622 - val_loss: 0.4084 - val_f1: 0.1460\n",
      "Epoch 464/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2993 - f1: 0.6603 - val_loss: 0.4048 - val_f1: 0.1446\n",
      "Epoch 465/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2977 - f1: 0.6622 - val_loss: 0.4052 - val_f1: 0.1459\n",
      "Epoch 466/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2962 - f1: 0.6682 - val_loss: 0.4110 - val_f1: 0.1459\n",
      "Epoch 467/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2978 - f1: 0.6704 - val_loss: 0.4092 - val_f1: 0.1464\n",
      "Epoch 468/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2983 - f1: 0.6638 - val_loss: 0.4079 - val_f1: 0.1470\n",
      "Epoch 469/2000\n",
      "64440/64440 [==============================] - 4s 54us/step - loss: 0.3010 - f1: 0.6654 - val_loss: 0.4081 - val_f1: 0.1456\n",
      "Epoch 470/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2995 - f1: 0.6638 - val_loss: 0.4028 - val_f1: 0.1454\n",
      "Epoch 471/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2982 - f1: 0.6660 - val_loss: 0.4080 - val_f1: 0.1461\n",
      "Epoch 472/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2974 - f1: 0.6669 - val_loss: 0.4045 - val_f1: 0.1457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2989 - f1: 0.6632 - val_loss: 0.4061 - val_f1: 0.1461\n",
      "Epoch 474/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2972 - f1: 0.6659 - val_loss: 0.4076 - val_f1: 0.1467\n",
      "Epoch 475/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.3000 - f1: 0.6633 - val_loss: 0.4050 - val_f1: 0.1457\n",
      "Epoch 476/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2984 - f1: 0.6599 - val_loss: 0.4072 - val_f1: 0.1461\n",
      "Epoch 477/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2986 - f1: 0.6642 - val_loss: 0.4074 - val_f1: 0.1467\n",
      "Epoch 478/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2975 - f1: 0.6657 - val_loss: 0.4129 - val_f1: 0.1471\n",
      "Epoch 479/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2986 - f1: 0.6658 - val_loss: 0.4096 - val_f1: 0.1465\n",
      "Epoch 480/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2965 - f1: 0.6661 - val_loss: 0.4077 - val_f1: 0.1462\n",
      "Epoch 481/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2975 - f1: 0.6680 - val_loss: 0.4114 - val_f1: 0.1467\n",
      "Epoch 482/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2978 - f1: 0.6653 - val_loss: 0.4049 - val_f1: 0.1449\n",
      "Epoch 483/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2961 - f1: 0.6720 - val_loss: 0.4108 - val_f1: 0.1462\n",
      "Epoch 484/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2970 - f1: 0.6680 - val_loss: 0.4056 - val_f1: 0.1465\n",
      "Epoch 485/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2981 - f1: 0.6665 - val_loss: 0.4106 - val_f1: 0.1466\n",
      "Epoch 486/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2963 - f1: 0.6685 - val_loss: 0.4127 - val_f1: 0.1467\n",
      "Epoch 487/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2972 - f1: 0.6632 - val_loss: 0.4101 - val_f1: 0.1474\n",
      "Epoch 488/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2959 - f1: 0.6664 - val_loss: 0.4105 - val_f1: 0.1470\n",
      "Epoch 489/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2976 - f1: 0.6676 - val_loss: 0.4036 - val_f1: 0.1450\n",
      "Epoch 490/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2981 - f1: 0.6655 - val_loss: 0.4067 - val_f1: 0.1464\n",
      "Epoch 491/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2985 - f1: 0.6641 - val_loss: 0.4066 - val_f1: 0.1458\n",
      "Epoch 492/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2982 - f1: 0.6639 - val_loss: 0.4074 - val_f1: 0.1463\n",
      "Epoch 493/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2978 - f1: 0.6642 - val_loss: 0.4049 - val_f1: 0.1454\n",
      "Epoch 494/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2973 - f1: 0.6673 - val_loss: 0.4076 - val_f1: 0.1461\n",
      "Epoch 495/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2961 - f1: 0.6658 - val_loss: 0.4126 - val_f1: 0.1475\n",
      "Epoch 496/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2955 - f1: 0.6694 - val_loss: 0.4069 - val_f1: 0.1462\n",
      "Epoch 497/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2962 - f1: 0.6669 - val_loss: 0.4096 - val_f1: 0.1469\n",
      "Epoch 498/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2960 - f1: 0.6704 - val_loss: 0.4098 - val_f1: 0.1464\n",
      "Epoch 499/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2968 - f1: 0.6698 - val_loss: 0.4058 - val_f1: 0.1464\n",
      "Epoch 500/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2965 - f1: 0.6661 - val_loss: 0.4100 - val_f1: 0.1466\n",
      "Epoch 501/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2955 - f1: 0.6679 - val_loss: 0.4068 - val_f1: 0.1469\n",
      "Epoch 502/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2960 - f1: 0.6674 - val_loss: 0.4129 - val_f1: 0.1458\n",
      "Epoch 503/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2952 - f1: 0.6684 - val_loss: 0.4142 - val_f1: 0.1469\n",
      "Epoch 504/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2953 - f1: 0.6690 - val_loss: 0.4117 - val_f1: 0.1470\n",
      "Epoch 505/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2951 - f1: 0.6695 - val_loss: 0.4090 - val_f1: 0.1468\n",
      "Epoch 506/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2950 - f1: 0.6707 - val_loss: 0.4129 - val_f1: 0.1463\n",
      "Epoch 507/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2964 - f1: 0.6677 - val_loss: 0.4122 - val_f1: 0.1465\n",
      "Epoch 508/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2953 - f1: 0.6682 - val_loss: 0.4092 - val_f1: 0.1463\n",
      "Epoch 509/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2962 - f1: 0.6705 - val_loss: 0.4060 - val_f1: 0.1457\n",
      "Epoch 510/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2954 - f1: 0.6702 - val_loss: 0.4076 - val_f1: 0.1458\n",
      "Epoch 511/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2973 - f1: 0.6687 - val_loss: 0.4126 - val_f1: 0.1470\n",
      "Epoch 512/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2948 - f1: 0.6679 - val_loss: 0.4100 - val_f1: 0.1470\n",
      "Epoch 513/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2960 - f1: 0.6681 - val_loss: 0.4133 - val_f1: 0.1475\n",
      "Epoch 514/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2957 - f1: 0.6699 - val_loss: 0.4168 - val_f1: 0.1473\n",
      "Epoch 515/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2945 - f1: 0.6704 - val_loss: 0.4090 - val_f1: 0.1464\n",
      "Epoch 516/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2945 - f1: 0.6718 - val_loss: 0.4157 - val_f1: 0.1469\n",
      "Epoch 517/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2964 - f1: 0.6663 - val_loss: 0.4073 - val_f1: 0.1458\n",
      "Epoch 518/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2960 - f1: 0.6659 - val_loss: 0.4070 - val_f1: 0.1449\n",
      "Epoch 519/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2949 - f1: 0.6689 - val_loss: 0.4093 - val_f1: 0.1455\n",
      "Epoch 520/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2951 - f1: 0.6683 - val_loss: 0.4100 - val_f1: 0.1464\n",
      "Epoch 521/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2948 - f1: 0.6677 - val_loss: 0.4106 - val_f1: 0.1477\n",
      "Epoch 522/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2948 - f1: 0.6699 - val_loss: 0.4071 - val_f1: 0.1465\n",
      "Epoch 523/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2948 - f1: 0.6732 - val_loss: 0.4150 - val_f1: 0.1461\n",
      "Epoch 524/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2961 - f1: 0.6696 - val_loss: 0.4110 - val_f1: 0.1472\n",
      "Epoch 525/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2927 - f1: 0.6707 - val_loss: 0.4155 - val_f1: 0.1469\n",
      "Epoch 526/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2959 - f1: 0.6668 - val_loss: 0.4123 - val_f1: 0.1456\n",
      "Epoch 527/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2926 - f1: 0.6763 - val_loss: 0.4159 - val_f1: 0.1462\n",
      "Epoch 528/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2947 - f1: 0.6681 - val_loss: 0.4079 - val_f1: 0.1451\n",
      "Epoch 529/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2953 - f1: 0.6666 - val_loss: 0.4149 - val_f1: 0.1460\n",
      "Epoch 530/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2956 - f1: 0.6665 - val_loss: 0.4134 - val_f1: 0.1463\n",
      "Epoch 531/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2943 - f1: 0.6710 - val_loss: 0.4100 - val_f1: 0.1456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 532/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2956 - f1: 0.6689 - val_loss: 0.4098 - val_f1: 0.1464\n",
      "Epoch 533/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2938 - f1: 0.6732 - val_loss: 0.4097 - val_f1: 0.1463\n",
      "Epoch 534/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2932 - f1: 0.6724 - val_loss: 0.4105 - val_f1: 0.1459\n",
      "Epoch 535/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2939 - f1: 0.6747 - val_loss: 0.4152 - val_f1: 0.1463\n",
      "Epoch 536/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2927 - f1: 0.6747 - val_loss: 0.4113 - val_f1: 0.1459\n",
      "Epoch 537/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2937 - f1: 0.6727 - val_loss: 0.4145 - val_f1: 0.1462\n",
      "Epoch 538/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2924 - f1: 0.6754 - val_loss: 0.4101 - val_f1: 0.1454\n",
      "Epoch 539/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2959 - f1: 0.6699 - val_loss: 0.4061 - val_f1: 0.1443\n",
      "Epoch 540/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2933 - f1: 0.6696 - val_loss: 0.4135 - val_f1: 0.1463\n",
      "Epoch 541/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2935 - f1: 0.6771 - val_loss: 0.4107 - val_f1: 0.1457\n",
      "Epoch 542/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2941 - f1: 0.6707 - val_loss: 0.4119 - val_f1: 0.1454\n",
      "Epoch 543/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2936 - f1: 0.6744 - val_loss: 0.4086 - val_f1: 0.1463\n",
      "Epoch 544/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2955 - f1: 0.6678 - val_loss: 0.4099 - val_f1: 0.1445\n",
      "Epoch 545/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2935 - f1: 0.6699 - val_loss: 0.4160 - val_f1: 0.1463\n",
      "Epoch 546/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2938 - f1: 0.6766 - val_loss: 0.4061 - val_f1: 0.1448\n",
      "Epoch 547/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2936 - f1: 0.6723 - val_loss: 0.4129 - val_f1: 0.1463\n",
      "Epoch 548/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2941 - f1: 0.6716 - val_loss: 0.4121 - val_f1: 0.1446\n",
      "Epoch 549/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2950 - f1: 0.6702 - val_loss: 0.4098 - val_f1: 0.1459\n",
      "Epoch 550/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2916 - f1: 0.6724 - val_loss: 0.4120 - val_f1: 0.1463\n",
      "Epoch 551/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2935 - f1: 0.6706 - val_loss: 0.4139 - val_f1: 0.1471\n",
      "Epoch 552/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2912 - f1: 0.6772 - val_loss: 0.4164 - val_f1: 0.1482\n",
      "Epoch 553/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2922 - f1: 0.6774 - val_loss: 0.4126 - val_f1: 0.1451\n",
      "Epoch 554/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2922 - f1: 0.6751 - val_loss: 0.4173 - val_f1: 0.1477\n",
      "Epoch 555/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2932 - f1: 0.6772 - val_loss: 0.4111 - val_f1: 0.1456\n",
      "Epoch 556/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2946 - f1: 0.6707 - val_loss: 0.4115 - val_f1: 0.1445\n",
      "Epoch 557/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2942 - f1: 0.6687 - val_loss: 0.4145 - val_f1: 0.1465\n",
      "Epoch 558/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2938 - f1: 0.6685 - val_loss: 0.4127 - val_f1: 0.1463\n",
      "Epoch 559/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2919 - f1: 0.6757 - val_loss: 0.4103 - val_f1: 0.1458\n",
      "Epoch 560/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2912 - f1: 0.6768 - val_loss: 0.4171 - val_f1: 0.1461\n",
      "Epoch 561/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2954 - f1: 0.6652 - val_loss: 0.4085 - val_f1: 0.1460\n",
      "Epoch 562/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2896 - f1: 0.6754 - val_loss: 0.4122 - val_f1: 0.1466\n",
      "Epoch 563/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2919 - f1: 0.6743 - val_loss: 0.4117 - val_f1: 0.1455\n",
      "Epoch 564/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2923 - f1: 0.6748 - val_loss: 0.4142 - val_f1: 0.1460\n",
      "Epoch 565/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2929 - f1: 0.6758 - val_loss: 0.4116 - val_f1: 0.1464\n",
      "Epoch 566/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2909 - f1: 0.6768 - val_loss: 0.4150 - val_f1: 0.1473\n",
      "Epoch 567/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2923 - f1: 0.6730 - val_loss: 0.4124 - val_f1: 0.1466\n",
      "Epoch 568/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2908 - f1: 0.6739 - val_loss: 0.4137 - val_f1: 0.1468\n",
      "Epoch 569/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2921 - f1: 0.6737 - val_loss: 0.4136 - val_f1: 0.1474\n",
      "Epoch 570/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2911 - f1: 0.6733 - val_loss: 0.4149 - val_f1: 0.1460\n",
      "Epoch 571/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2912 - f1: 0.6732 - val_loss: 0.4153 - val_f1: 0.1473\n",
      "Epoch 572/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2933 - f1: 0.6728 - val_loss: 0.4110 - val_f1: 0.1456\n",
      "Epoch 573/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2907 - f1: 0.6810 - val_loss: 0.4167 - val_f1: 0.1469\n",
      "Epoch 574/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2918 - f1: 0.6744 - val_loss: 0.4114 - val_f1: 0.1465\n",
      "Epoch 575/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2924 - f1: 0.6737 - val_loss: 0.4068 - val_f1: 0.1461\n",
      "Epoch 576/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2929 - f1: 0.6710 - val_loss: 0.4115 - val_f1: 0.1465\n",
      "Epoch 577/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2922 - f1: 0.6723 - val_loss: 0.4156 - val_f1: 0.1464\n",
      "Epoch 578/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2917 - f1: 0.6726 - val_loss: 0.4172 - val_f1: 0.1473\n",
      "Epoch 579/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2909 - f1: 0.6763 - val_loss: 0.4137 - val_f1: 0.1460\n",
      "Epoch 580/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2905 - f1: 0.6776 - val_loss: 0.4175 - val_f1: 0.1468\n",
      "Epoch 581/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2922 - f1: 0.6745 - val_loss: 0.4116 - val_f1: 0.1457\n",
      "Epoch 582/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2920 - f1: 0.6801 - val_loss: 0.4101 - val_f1: 0.1470\n",
      "Epoch 583/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2918 - f1: 0.6755 - val_loss: 0.4111 - val_f1: 0.1472\n",
      "Epoch 584/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2902 - f1: 0.6768 - val_loss: 0.4121 - val_f1: 0.1471\n",
      "Epoch 585/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2898 - f1: 0.6754 - val_loss: 0.4144 - val_f1: 0.1470\n",
      "Epoch 586/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2908 - f1: 0.6751 - val_loss: 0.4191 - val_f1: 0.1471\n",
      "Epoch 587/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2931 - f1: 0.6743 - val_loss: 0.4122 - val_f1: 0.1459\n",
      "Epoch 588/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2902 - f1: 0.6794 - val_loss: 0.4083 - val_f1: 0.1454\n",
      "Epoch 589/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2917 - f1: 0.6686 - val_loss: 0.4132 - val_f1: 0.1460\n",
      "Epoch 590/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2918 - f1: 0.6736 - val_loss: 0.4175 - val_f1: 0.1472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2910 - f1: 0.6727 - val_loss: 0.4187 - val_f1: 0.1477\n",
      "Epoch 592/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2898 - f1: 0.6776 - val_loss: 0.4146 - val_f1: 0.1454\n",
      "Epoch 593/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2901 - f1: 0.6785 - val_loss: 0.4106 - val_f1: 0.1456\n",
      "Epoch 594/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2896 - f1: 0.6757 - val_loss: 0.4132 - val_f1: 0.1468\n",
      "Epoch 595/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2908 - f1: 0.6752 - val_loss: 0.4178 - val_f1: 0.1465\n",
      "Epoch 596/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2913 - f1: 0.6756 - val_loss: 0.4115 - val_f1: 0.1471\n",
      "Epoch 597/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2920 - f1: 0.6751 - val_loss: 0.4124 - val_f1: 0.1468\n",
      "Epoch 598/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2909 - f1: 0.6756 - val_loss: 0.4180 - val_f1: 0.1467\n",
      "Epoch 599/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2891 - f1: 0.6779 - val_loss: 0.4168 - val_f1: 0.1469\n",
      "Epoch 600/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2906 - f1: 0.6718 - val_loss: 0.4126 - val_f1: 0.1468\n",
      "Epoch 601/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2893 - f1: 0.6827 - val_loss: 0.4142 - val_f1: 0.1460\n",
      "Epoch 602/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2918 - f1: 0.6774 - val_loss: 0.4080 - val_f1: 0.1469\n",
      "Epoch 603/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2898 - f1: 0.6781 - val_loss: 0.4172 - val_f1: 0.1474\n",
      "Epoch 604/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2922 - f1: 0.6739 - val_loss: 0.4165 - val_f1: 0.1452\n",
      "Epoch 605/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2904 - f1: 0.6765 - val_loss: 0.4126 - val_f1: 0.1468\n",
      "Epoch 606/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2906 - f1: 0.6751 - val_loss: 0.4136 - val_f1: 0.1463\n",
      "Epoch 607/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2892 - f1: 0.6764 - val_loss: 0.4149 - val_f1: 0.1465\n",
      "Epoch 608/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2889 - f1: 0.6772 - val_loss: 0.4141 - val_f1: 0.1474\n",
      "Epoch 609/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2894 - f1: 0.6800 - val_loss: 0.4184 - val_f1: 0.1465\n",
      "Epoch 610/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2915 - f1: 0.6761 - val_loss: 0.4147 - val_f1: 0.1457\n",
      "Epoch 611/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2886 - f1: 0.6820 - val_loss: 0.4162 - val_f1: 0.1468\n",
      "Epoch 612/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2881 - f1: 0.6808 - val_loss: 0.4247 - val_f1: 0.1476\n",
      "Epoch 613/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2897 - f1: 0.6781 - val_loss: 0.4176 - val_f1: 0.1477\n",
      "Epoch 614/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2908 - f1: 0.6750 - val_loss: 0.4199 - val_f1: 0.1475\n",
      "Epoch 615/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2882 - f1: 0.6757 - val_loss: 0.4124 - val_f1: 0.1457\n",
      "Epoch 616/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2888 - f1: 0.6838 - val_loss: 0.4183 - val_f1: 0.1470\n",
      "Epoch 617/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2893 - f1: 0.6773 - val_loss: 0.4157 - val_f1: 0.1468\n",
      "Epoch 618/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2900 - f1: 0.6792 - val_loss: 0.4132 - val_f1: 0.1466\n",
      "Epoch 619/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2901 - f1: 0.6813 - val_loss: 0.4129 - val_f1: 0.1460\n",
      "Epoch 620/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2890 - f1: 0.6772 - val_loss: 0.4174 - val_f1: 0.1471\n",
      "Epoch 621/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.2882 - f1: 0.68 - 3s 50us/step - loss: 0.2881 - f1: 0.6823 - val_loss: 0.4248 - val_f1: 0.1472\n",
      "Epoch 622/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2897 - f1: 0.6742 - val_loss: 0.4168 - val_f1: 0.1465\n",
      "Epoch 623/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2886 - f1: 0.6807 - val_loss: 0.4162 - val_f1: 0.1462\n",
      "Epoch 624/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2870 - f1: 0.6798 - val_loss: 0.4123 - val_f1: 0.1468\n",
      "Epoch 625/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2902 - f1: 0.6755 - val_loss: 0.4115 - val_f1: 0.1465\n",
      "Epoch 626/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2905 - f1: 0.6795 - val_loss: 0.4186 - val_f1: 0.1460\n",
      "Epoch 627/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2893 - f1: 0.6771 - val_loss: 0.4117 - val_f1: 0.1453\n",
      "Epoch 628/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2879 - f1: 0.6807 - val_loss: 0.4162 - val_f1: 0.1467\n",
      "Epoch 629/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2890 - f1: 0.6802 - val_loss: 0.4185 - val_f1: 0.1469\n",
      "Epoch 630/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2887 - f1: 0.6777 - val_loss: 0.4111 - val_f1: 0.1455\n",
      "Epoch 631/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2894 - f1: 0.6798 - val_loss: 0.4199 - val_f1: 0.1476\n",
      "Epoch 632/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2878 - f1: 0.6824 - val_loss: 0.4193 - val_f1: 0.1466\n",
      "Epoch 633/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2885 - f1: 0.6782 - val_loss: 0.4217 - val_f1: 0.1475\n",
      "Epoch 634/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2895 - f1: 0.6783 - val_loss: 0.4160 - val_f1: 0.1465\n",
      "Epoch 635/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2890 - f1: 0.6780 - val_loss: 0.4197 - val_f1: 0.1475\n",
      "Epoch 636/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2889 - f1: 0.6810 - val_loss: 0.4196 - val_f1: 0.1460\n",
      "Epoch 637/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2897 - f1: 0.6803 - val_loss: 0.4199 - val_f1: 0.1474\n",
      "Epoch 638/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2885 - f1: 0.6821 - val_loss: 0.4148 - val_f1: 0.1461\n",
      "Epoch 639/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2894 - f1: 0.6756 - val_loss: 0.4101 - val_f1: 0.1463\n",
      "Epoch 640/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2883 - f1: 0.6798 - val_loss: 0.4140 - val_f1: 0.1451\n",
      "Epoch 641/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2888 - f1: 0.6813 - val_loss: 0.4220 - val_f1: 0.1481\n",
      "Epoch 642/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2882 - f1: 0.6777 - val_loss: 0.4227 - val_f1: 0.1473\n",
      "Epoch 643/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2874 - f1: 0.6837 - val_loss: 0.4157 - val_f1: 0.1463\n",
      "Epoch 644/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2902 - f1: 0.6809 - val_loss: 0.4179 - val_f1: 0.1469\n",
      "Epoch 645/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2879 - f1: 0.6822 - val_loss: 0.4107 - val_f1: 0.1454\n",
      "Epoch 646/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2860 - f1: 0.6837 - val_loss: 0.4175 - val_f1: 0.1476\n",
      "Epoch 647/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2901 - f1: 0.6787 - val_loss: 0.4149 - val_f1: 0.1474\n",
      "Epoch 648/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2879 - f1: 0.6773 - val_loss: 0.4143 - val_f1: 0.1460\n",
      "Epoch 649/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2879 - f1: 0.6796 - val_loss: 0.4147 - val_f1: 0.1462\n",
      "Epoch 650/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2882 - f1: 0.6826 - val_loss: 0.4145 - val_f1: 0.1458\n",
      "Epoch 651/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2887 - f1: 0.6817 - val_loss: 0.4174 - val_f1: 0.1460\n",
      "Epoch 652/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2895 - f1: 0.6747 - val_loss: 0.4116 - val_f1: 0.1458\n",
      "Epoch 653/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2884 - f1: 0.6827 - val_loss: 0.4179 - val_f1: 0.1459\n",
      "Epoch 654/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2897 - f1: 0.6776 - val_loss: 0.4129 - val_f1: 0.1455\n",
      "Epoch 655/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2878 - f1: 0.6785 - val_loss: 0.4148 - val_f1: 0.1466\n",
      "Epoch 656/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2880 - f1: 0.6828 - val_loss: 0.4179 - val_f1: 0.1467\n",
      "Epoch 657/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2901 - f1: 0.6810 - val_loss: 0.4147 - val_f1: 0.1457\n",
      "Epoch 658/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2852 - f1: 0.6900 - val_loss: 0.4195 - val_f1: 0.1463\n",
      "Epoch 659/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2887 - f1: 0.6766 - val_loss: 0.4200 - val_f1: 0.1468\n",
      "Epoch 660/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2867 - f1: 0.6794 - val_loss: 0.4176 - val_f1: 0.1472\n",
      "Epoch 661/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2890 - f1: 0.6794 - val_loss: 0.4141 - val_f1: 0.1467\n",
      "Epoch 662/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2865 - f1: 0.6810 - val_loss: 0.4148 - val_f1: 0.1458\n",
      "Epoch 663/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2868 - f1: 0.6803 - val_loss: 0.4200 - val_f1: 0.1479\n",
      "Epoch 664/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2886 - f1: 0.6778 - val_loss: 0.4158 - val_f1: 0.1462\n",
      "Epoch 665/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2855 - f1: 0.6851 - val_loss: 0.4206 - val_f1: 0.1465\n",
      "Epoch 666/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2879 - f1: 0.6831 - val_loss: 0.4147 - val_f1: 0.1453\n",
      "Epoch 667/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2884 - f1: 0.6836 - val_loss: 0.4199 - val_f1: 0.1472\n",
      "Epoch 668/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2881 - f1: 0.6805 - val_loss: 0.4173 - val_f1: 0.1468\n",
      "Epoch 669/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2870 - f1: 0.6808 - val_loss: 0.4123 - val_f1: 0.1451\n",
      "Epoch 670/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2888 - f1: 0.6820 - val_loss: 0.4116 - val_f1: 0.1459\n",
      "Epoch 671/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2882 - f1: 0.6817 - val_loss: 0.4133 - val_f1: 0.1452\n",
      "Epoch 672/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2880 - f1: 0.6781 - val_loss: 0.4154 - val_f1: 0.1455\n",
      "Epoch 673/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2880 - f1: 0.6776 - val_loss: 0.4179 - val_f1: 0.1460\n",
      "Epoch 674/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2865 - f1: 0.6884 - val_loss: 0.4160 - val_f1: 0.1460\n",
      "Epoch 675/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2875 - f1: 0.6832 - val_loss: 0.4141 - val_f1: 0.1453\n",
      "Epoch 676/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2875 - f1: 0.6809 - val_loss: 0.4157 - val_f1: 0.1470\n",
      "Epoch 677/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2881 - f1: 0.6822 - val_loss: 0.4173 - val_f1: 0.1477\n",
      "Epoch 678/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2878 - f1: 0.6823 - val_loss: 0.4174 - val_f1: 0.1473\n",
      "Epoch 679/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2884 - f1: 0.6800 - val_loss: 0.4166 - val_f1: 0.1466\n",
      "Epoch 680/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2864 - f1: 0.6888 - val_loss: 0.4193 - val_f1: 0.1471\n",
      "Epoch 681/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2878 - f1: 0.6848 - val_loss: 0.4198 - val_f1: 0.1470\n",
      "Epoch 682/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2861 - f1: 0.6821 - val_loss: 0.4152 - val_f1: 0.1460\n",
      "Epoch 683/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2883 - f1: 0.6783 - val_loss: 0.4114 - val_f1: 0.1441\n",
      "Epoch 684/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2883 - f1: 0.6799 - val_loss: 0.4162 - val_f1: 0.1471\n",
      "Epoch 685/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2866 - f1: 0.6872 - val_loss: 0.4197 - val_f1: 0.1465\n",
      "Epoch 686/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2888 - f1: 0.6816 - val_loss: 0.4195 - val_f1: 0.1463\n",
      "Epoch 687/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2856 - f1: 0.6866 - val_loss: 0.4203 - val_f1: 0.1472\n",
      "Epoch 688/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2869 - f1: 0.6839 - val_loss: 0.4229 - val_f1: 0.1481\n",
      "Epoch 689/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2852 - f1: 0.6859 - val_loss: 0.4200 - val_f1: 0.1468\n",
      "Epoch 690/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2874 - f1: 0.6822 - val_loss: 0.4181 - val_f1: 0.1468\n",
      "Epoch 691/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2858 - f1: 0.6838 - val_loss: 0.4176 - val_f1: 0.1461\n",
      "Epoch 692/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2879 - f1: 0.6796 - val_loss: 0.4143 - val_f1: 0.1451\n",
      "Epoch 693/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2861 - f1: 0.6809 - val_loss: 0.4203 - val_f1: 0.1449\n",
      "Epoch 694/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2864 - f1: 0.6829 - val_loss: 0.4196 - val_f1: 0.1475\n",
      "Epoch 695/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2859 - f1: 0.6794 - val_loss: 0.4174 - val_f1: 0.1456\n",
      "Epoch 696/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2873 - f1: 0.6809 - val_loss: 0.4189 - val_f1: 0.1467\n",
      "Epoch 697/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2868 - f1: 0.6818 - val_loss: 0.4146 - val_f1: 0.1450\n",
      "Epoch 698/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2868 - f1: 0.6833 - val_loss: 0.4165 - val_f1: 0.1451\n",
      "Epoch 699/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2866 - f1: 0.6814 - val_loss: 0.4168 - val_f1: 0.1465\n",
      "Epoch 700/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2865 - f1: 0.6795 - val_loss: 0.4210 - val_f1: 0.1460\n",
      "Epoch 701/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2828 - f1: 0.6907 - val_loss: 0.4208 - val_f1: 0.1466\n",
      "Epoch 702/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2859 - f1: 0.6787 - val_loss: 0.4222 - val_f1: 0.1469\n",
      "Epoch 703/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2858 - f1: 0.6815 - val_loss: 0.4194 - val_f1: 0.1476\n",
      "Epoch 704/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2874 - f1: 0.6802 - val_loss: 0.4194 - val_f1: 0.1463\n",
      "Epoch 705/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2858 - f1: 0.6819 - val_loss: 0.4127 - val_f1: 0.1461\n",
      "Epoch 706/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2840 - f1: 0.6902 - val_loss: 0.4237 - val_f1: 0.1469\n",
      "Epoch 707/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2865 - f1: 0.6852 - val_loss: 0.4207 - val_f1: 0.1463\n",
      "Epoch 708/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2860 - f1: 0.6823 - val_loss: 0.4204 - val_f1: 0.1463\n",
      "Epoch 709/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2879 - f1: 0.6828 - val_loss: 0.4192 - val_f1: 0.1468\n",
      "Epoch 710/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2865 - f1: 0.6824 - val_loss: 0.4199 - val_f1: 0.1459\n",
      "Epoch 711/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2866 - f1: 0.6796 - val_loss: 0.4184 - val_f1: 0.1468\n",
      "Epoch 712/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2874 - f1: 0.6819 - val_loss: 0.4195 - val_f1: 0.1468\n",
      "Epoch 713/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2861 - f1: 0.6818 - val_loss: 0.4185 - val_f1: 0.1466\n",
      "Epoch 714/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2841 - f1: 0.6859 - val_loss: 0.4258 - val_f1: 0.1469\n",
      "Epoch 715/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2853 - f1: 0.6862 - val_loss: 0.4218 - val_f1: 0.1463\n",
      "Epoch 716/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2871 - f1: 0.6809 - val_loss: 0.4179 - val_f1: 0.1461\n",
      "Epoch 717/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2849 - f1: 0.6861 - val_loss: 0.4206 - val_f1: 0.1468\n",
      "Epoch 718/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2844 - f1: 0.6882 - val_loss: 0.4214 - val_f1: 0.1465\n",
      "Epoch 719/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2831 - f1: 0.6854 - val_loss: 0.4169 - val_f1: 0.1461\n",
      "Epoch 720/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2847 - f1: 0.6833 - val_loss: 0.4224 - val_f1: 0.1473\n",
      "Epoch 721/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2860 - f1: 0.6867 - val_loss: 0.4195 - val_f1: 0.1467\n",
      "Epoch 722/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2849 - f1: 0.6871 - val_loss: 0.4187 - val_f1: 0.1472\n",
      "Epoch 723/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2842 - f1: 0.6889 - val_loss: 0.4227 - val_f1: 0.1469\n",
      "Epoch 724/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2853 - f1: 0.6856 - val_loss: 0.4197 - val_f1: 0.1469\n",
      "Epoch 725/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2840 - f1: 0.6863 - val_loss: 0.4202 - val_f1: 0.1462\n",
      "Epoch 726/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2856 - f1: 0.6858 - val_loss: 0.4190 - val_f1: 0.1466\n",
      "Epoch 727/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2842 - f1: 0.6858 - val_loss: 0.4263 - val_f1: 0.1471\n",
      "Epoch 728/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2861 - f1: 0.6846 - val_loss: 0.4165 - val_f1: 0.1468\n",
      "Epoch 729/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2872 - f1: 0.6831 - val_loss: 0.4220 - val_f1: 0.1464\n",
      "Epoch 730/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2853 - f1: 0.6838 - val_loss: 0.4189 - val_f1: 0.1462\n",
      "Epoch 731/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2840 - f1: 0.6894 - val_loss: 0.4200 - val_f1: 0.1459\n",
      "Epoch 732/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.2841 - f1: 0.68 - 3s 49us/step - loss: 0.2841 - f1: 0.6870 - val_loss: 0.4234 - val_f1: 0.1469\n",
      "Epoch 733/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2825 - f1: 0.6896 - val_loss: 0.4213 - val_f1: 0.1454\n",
      "Epoch 734/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2845 - f1: 0.6853 - val_loss: 0.4231 - val_f1: 0.1462\n",
      "Epoch 735/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2845 - f1: 0.6821 - val_loss: 0.4199 - val_f1: 0.1465\n",
      "Epoch 736/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2861 - f1: 0.6844 - val_loss: 0.4226 - val_f1: 0.1464\n",
      "Epoch 737/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2843 - f1: 0.6882 - val_loss: 0.4192 - val_f1: 0.1456\n",
      "Epoch 738/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2830 - f1: 0.6905 - val_loss: 0.4215 - val_f1: 0.1453\n",
      "Epoch 739/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2850 - f1: 0.6867 - val_loss: 0.4183 - val_f1: 0.1451\n",
      "Epoch 740/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2852 - f1: 0.6812 - val_loss: 0.4181 - val_f1: 0.1460\n",
      "Epoch 741/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2851 - f1: 0.6834 - val_loss: 0.4178 - val_f1: 0.1460\n",
      "Epoch 742/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2827 - f1: 0.6929 - val_loss: 0.4219 - val_f1: 0.1462\n",
      "Epoch 743/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2840 - f1: 0.6879 - val_loss: 0.4225 - val_f1: 0.1457\n",
      "Epoch 744/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2835 - f1: 0.6918 - val_loss: 0.4160 - val_f1: 0.1441\n",
      "Epoch 745/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2849 - f1: 0.6856 - val_loss: 0.4214 - val_f1: 0.1463\n",
      "Epoch 746/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2840 - f1: 0.6871 - val_loss: 0.4258 - val_f1: 0.1470\n",
      "Epoch 747/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2841 - f1: 0.6884 - val_loss: 0.4195 - val_f1: 0.1452\n",
      "Epoch 748/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2841 - f1: 0.6839 - val_loss: 0.4199 - val_f1: 0.1456\n",
      "Epoch 749/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2836 - f1: 0.6851 - val_loss: 0.4172 - val_f1: 0.1453\n",
      "Epoch 750/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2840 - f1: 0.6861 - val_loss: 0.4135 - val_f1: 0.1457\n",
      "Epoch 751/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2838 - f1: 0.6875 - val_loss: 0.4250 - val_f1: 0.1469\n",
      "Epoch 752/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2846 - f1: 0.6852 - val_loss: 0.4250 - val_f1: 0.1477\n",
      "Epoch 753/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2845 - f1: 0.6847 - val_loss: 0.4229 - val_f1: 0.1448\n",
      "Epoch 754/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2825 - f1: 0.6891 - val_loss: 0.4216 - val_f1: 0.1462\n",
      "Epoch 755/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2835 - f1: 0.6921 - val_loss: 0.4237 - val_f1: 0.1466\n",
      "Epoch 756/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2861 - f1: 0.6814 - val_loss: 0.4195 - val_f1: 0.1455\n",
      "Epoch 757/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2838 - f1: 0.6885 - val_loss: 0.4195 - val_f1: 0.1452\n",
      "Epoch 758/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2823 - f1: 0.6874 - val_loss: 0.4220 - val_f1: 0.1468\n",
      "Epoch 759/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2834 - f1: 0.6881 - val_loss: 0.4244 - val_f1: 0.1464\n",
      "Epoch 760/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2845 - f1: 0.6863 - val_loss: 0.4227 - val_f1: 0.1463\n",
      "Epoch 761/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2838 - f1: 0.6876 - val_loss: 0.4222 - val_f1: 0.1457\n",
      "Epoch 762/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2842 - f1: 0.6875 - val_loss: 0.4178 - val_f1: 0.1460\n",
      "Epoch 763/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2854 - f1: 0.6898 - val_loss: 0.4196 - val_f1: 0.1462\n",
      "Epoch 764/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2844 - f1: 0.6859 - val_loss: 0.4228 - val_f1: 0.1462\n",
      "Epoch 765/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2829 - f1: 0.6897 - val_loss: 0.4225 - val_f1: 0.1457\n",
      "Epoch 766/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2838 - f1: 0.6895 - val_loss: 0.4204 - val_f1: 0.1456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 767/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2840 - f1: 0.6859 - val_loss: 0.4236 - val_f1: 0.1453\n",
      "Epoch 768/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2844 - f1: 0.6852 - val_loss: 0.4225 - val_f1: 0.1458\n",
      "Epoch 769/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2835 - f1: 0.6879 - val_loss: 0.4162 - val_f1: 0.1457\n",
      "Epoch 770/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2833 - f1: 0.6865 - val_loss: 0.4193 - val_f1: 0.1459\n",
      "Epoch 771/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2840 - f1: 0.6829 - val_loss: 0.4214 - val_f1: 0.1450\n",
      "Epoch 772/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2818 - f1: 0.6877 - val_loss: 0.4188 - val_f1: 0.1456\n",
      "Epoch 773/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2827 - f1: 0.6868 - val_loss: 0.4182 - val_f1: 0.1463\n",
      "Epoch 774/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2838 - f1: 0.6839 - val_loss: 0.4182 - val_f1: 0.1446\n",
      "Epoch 775/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2815 - f1: 0.6872 - val_loss: 0.4269 - val_f1: 0.1465\n",
      "Epoch 776/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2848 - f1: 0.6794 - val_loss: 0.4217 - val_f1: 0.1463\n",
      "Epoch 777/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2821 - f1: 0.6876 - val_loss: 0.4189 - val_f1: 0.1453\n",
      "Epoch 778/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2820 - f1: 0.6916 - val_loss: 0.4212 - val_f1: 0.1461\n",
      "Epoch 779/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2830 - f1: 0.6889 - val_loss: 0.4171 - val_f1: 0.1453\n",
      "Epoch 780/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2845 - f1: 0.6843 - val_loss: 0.4210 - val_f1: 0.1452\n",
      "Epoch 781/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2823 - f1: 0.6855 - val_loss: 0.4225 - val_f1: 0.1448\n",
      "Epoch 782/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2823 - f1: 0.6875 - val_loss: 0.4165 - val_f1: 0.1451\n",
      "Epoch 783/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2822 - f1: 0.6917 - val_loss: 0.4234 - val_f1: 0.1464\n",
      "Epoch 784/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2836 - f1: 0.6900 - val_loss: 0.4193 - val_f1: 0.1454\n",
      "Epoch 785/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2817 - f1: 0.6919 - val_loss: 0.4219 - val_f1: 0.1454\n",
      "Epoch 786/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2836 - f1: 0.6908 - val_loss: 0.4234 - val_f1: 0.1456\n",
      "Epoch 787/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2828 - f1: 0.6837 - val_loss: 0.4152 - val_f1: 0.1450\n",
      "Epoch 788/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2820 - f1: 0.6925 - val_loss: 0.4239 - val_f1: 0.1462\n",
      "Epoch 789/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2840 - f1: 0.6872 - val_loss: 0.4197 - val_f1: 0.1457\n",
      "Epoch 790/2000\n",
      "64440/64440 [==============================] - 4s 54us/step - loss: 0.2850 - f1: 0.6882 - val_loss: 0.4184 - val_f1: 0.1446\n",
      "Epoch 791/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2827 - f1: 0.6872 - val_loss: 0.4244 - val_f1: 0.1463\n",
      "Epoch 792/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2841 - f1: 0.6895 - val_loss: 0.4223 - val_f1: 0.1456\n",
      "Epoch 793/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2825 - f1: 0.6898 - val_loss: 0.4232 - val_f1: 0.1458\n",
      "Epoch 794/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2815 - f1: 0.6884 - val_loss: 0.4270 - val_f1: 0.1470\n",
      "Epoch 795/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2847 - f1: 0.6870 - val_loss: 0.4192 - val_f1: 0.1445\n",
      "Epoch 796/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2819 - f1: 0.6892 - val_loss: 0.4253 - val_f1: 0.1466\n",
      "Epoch 797/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2826 - f1: 0.6885 - val_loss: 0.4296 - val_f1: 0.1450\n",
      "Epoch 798/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2838 - f1: 0.6875 - val_loss: 0.4209 - val_f1: 0.1457\n",
      "Epoch 799/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2840 - f1: 0.6860 - val_loss: 0.4227 - val_f1: 0.1456\n",
      "Epoch 800/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2809 - f1: 0.6925 - val_loss: 0.4195 - val_f1: 0.1452\n",
      "Epoch 801/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2820 - f1: 0.6896 - val_loss: 0.4167 - val_f1: 0.1454\n",
      "Epoch 802/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2816 - f1: 0.6900 - val_loss: 0.4185 - val_f1: 0.1454\n",
      "Epoch 803/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2813 - f1: 0.6907 - val_loss: 0.4223 - val_f1: 0.1463\n",
      "Epoch 804/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2805 - f1: 0.6976 - val_loss: 0.4239 - val_f1: 0.1465\n",
      "Epoch 805/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2817 - f1: 0.6921 - val_loss: 0.4247 - val_f1: 0.1455\n",
      "Epoch 806/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2828 - f1: 0.6901 - val_loss: 0.4227 - val_f1: 0.1459\n",
      "Epoch 807/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2834 - f1: 0.6874 - val_loss: 0.4217 - val_f1: 0.1447\n",
      "Epoch 808/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2837 - f1: 0.6864 - val_loss: 0.4251 - val_f1: 0.1458\n",
      "Epoch 809/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2812 - f1: 0.6915 - val_loss: 0.4301 - val_f1: 0.1464\n",
      "Epoch 810/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2832 - f1: 0.6890 - val_loss: 0.4226 - val_f1: 0.1450\n",
      "Epoch 811/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2817 - f1: 0.6900 - val_loss: 0.4245 - val_f1: 0.1449\n",
      "Epoch 812/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2803 - f1: 0.6915 - val_loss: 0.4312 - val_f1: 0.1458\n",
      "Epoch 813/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2819 - f1: 0.6893 - val_loss: 0.4235 - val_f1: 0.1451\n",
      "Epoch 814/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2819 - f1: 0.6926 - val_loss: 0.4202 - val_f1: 0.1445\n",
      "Epoch 815/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2839 - f1: 0.6870 - val_loss: 0.4187 - val_f1: 0.1449\n",
      "Epoch 816/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2830 - f1: 0.6875 - val_loss: 0.4266 - val_f1: 0.1458\n",
      "Epoch 817/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2825 - f1: 0.6898 - val_loss: 0.4208 - val_f1: 0.1458\n",
      "Epoch 818/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2818 - f1: 0.6907 - val_loss: 0.4280 - val_f1: 0.1453\n",
      "Epoch 819/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2835 - f1: 0.6898 - val_loss: 0.4225 - val_f1: 0.1455\n",
      "Epoch 820/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2822 - f1: 0.6888 - val_loss: 0.4269 - val_f1: 0.1458\n",
      "Epoch 821/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2841 - f1: 0.6865 - val_loss: 0.4216 - val_f1: 0.1457\n",
      "Epoch 822/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2830 - f1: 0.6858 - val_loss: 0.4221 - val_f1: 0.1457\n",
      "Epoch 823/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2823 - f1: 0.6920 - val_loss: 0.4209 - val_f1: 0.1443\n",
      "Epoch 824/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2810 - f1: 0.6931 - val_loss: 0.4253 - val_f1: 0.1451\n",
      "Epoch 825/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2807 - f1: 0.6948 - val_loss: 0.4253 - val_f1: 0.1449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 826/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2815 - f1: 0.6914 - val_loss: 0.4203 - val_f1: 0.1443\n",
      "Epoch 827/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2781 - f1: 0.6931 - val_loss: 0.4230 - val_f1: 0.1453\n",
      "Epoch 828/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2818 - f1: 0.6887 - val_loss: 0.4222 - val_f1: 0.1460\n",
      "Epoch 829/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2803 - f1: 0.6917 - val_loss: 0.4312 - val_f1: 0.1460\n",
      "Epoch 830/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2839 - f1: 0.6921 - val_loss: 0.4212 - val_f1: 0.1450\n",
      "Epoch 831/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2793 - f1: 0.6928 - val_loss: 0.4275 - val_f1: 0.1459\n",
      "Epoch 832/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2822 - f1: 0.6919 - val_loss: 0.4277 - val_f1: 0.1452\n",
      "Epoch 833/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2821 - f1: 0.6885 - val_loss: 0.4205 - val_f1: 0.1445\n",
      "Epoch 834/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2793 - f1: 0.6917 - val_loss: 0.4287 - val_f1: 0.1458\n",
      "Epoch 835/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2782 - f1: 0.6955 - val_loss: 0.4263 - val_f1: 0.1461\n",
      "Epoch 836/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2798 - f1: 0.6916 - val_loss: 0.4236 - val_f1: 0.1469\n",
      "Epoch 837/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2795 - f1: 0.6908 - val_loss: 0.4271 - val_f1: 0.1450\n",
      "Epoch 838/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2781 - f1: 0.6949 - val_loss: 0.4276 - val_f1: 0.1461\n",
      "Epoch 839/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2794 - f1: 0.6955 - val_loss: 0.4267 - val_f1: 0.1459\n",
      "Epoch 840/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2820 - f1: 0.6895 - val_loss: 0.4275 - val_f1: 0.1465\n",
      "Epoch 841/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2797 - f1: 0.6947 - val_loss: 0.4243 - val_f1: 0.1444\n",
      "Epoch 842/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2804 - f1: 0.6917 - val_loss: 0.4311 - val_f1: 0.1466\n",
      "Epoch 843/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2803 - f1: 0.6919 - val_loss: 0.4232 - val_f1: 0.1463\n",
      "Epoch 844/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2794 - f1: 0.6914 - val_loss: 0.4223 - val_f1: 0.1458\n",
      "Epoch 845/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2802 - f1: 0.6925 - val_loss: 0.4182 - val_f1: 0.1446\n",
      "Epoch 846/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2825 - f1: 0.6885 - val_loss: 0.4224 - val_f1: 0.1447\n",
      "Epoch 847/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2808 - f1: 0.6931 - val_loss: 0.4286 - val_f1: 0.1456\n",
      "Epoch 848/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2773 - f1: 0.6952 - val_loss: 0.4285 - val_f1: 0.1456\n",
      "Epoch 849/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2806 - f1: 0.6970 - val_loss: 0.4255 - val_f1: 0.1454\n",
      "Epoch 850/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2814 - f1: 0.6887 - val_loss: 0.4241 - val_f1: 0.1455\n",
      "Epoch 851/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2779 - f1: 0.6954 - val_loss: 0.4256 - val_f1: 0.1439\n",
      "Epoch 852/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2811 - f1: 0.6937 - val_loss: 0.4187 - val_f1: 0.1440\n",
      "Epoch 853/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2808 - f1: 0.6891 - val_loss: 0.4246 - val_f1: 0.1453\n",
      "Epoch 854/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2813 - f1: 0.6939 - val_loss: 0.4256 - val_f1: 0.1460\n",
      "Epoch 855/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2786 - f1: 0.6956 - val_loss: 0.4272 - val_f1: 0.1456\n",
      "Epoch 856/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2810 - f1: 0.6910 - val_loss: 0.4219 - val_f1: 0.1447\n",
      "Epoch 857/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2800 - f1: 0.6899 - val_loss: 0.4285 - val_f1: 0.1466\n",
      "Epoch 858/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2787 - f1: 0.6988 - val_loss: 0.4263 - val_f1: 0.1449\n",
      "Epoch 859/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2773 - f1: 0.6976 - val_loss: 0.4248 - val_f1: 0.1448\n",
      "Epoch 860/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2786 - f1: 0.6987 - val_loss: 0.4263 - val_f1: 0.1455\n",
      "Epoch 861/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2824 - f1: 0.6849 - val_loss: 0.4237 - val_f1: 0.1450\n",
      "Epoch 862/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2801 - f1: 0.6912 - val_loss: 0.4204 - val_f1: 0.1443\n",
      "Epoch 863/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2831 - f1: 0.6864 - val_loss: 0.4256 - val_f1: 0.1452\n",
      "Epoch 864/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2826 - f1: 0.6885 - val_loss: 0.4225 - val_f1: 0.1454\n",
      "Epoch 865/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2804 - f1: 0.6924 - val_loss: 0.4249 - val_f1: 0.1454\n",
      "Epoch 866/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2801 - f1: 0.6935 - val_loss: 0.4282 - val_f1: 0.1459\n",
      "Epoch 867/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2797 - f1: 0.6955 - val_loss: 0.4278 - val_f1: 0.1460\n",
      "Epoch 868/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2812 - f1: 0.6936 - val_loss: 0.4271 - val_f1: 0.1460\n",
      "Epoch 869/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2802 - f1: 0.6919 - val_loss: 0.4250 - val_f1: 0.1454\n",
      "Epoch 870/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2819 - f1: 0.6876 - val_loss: 0.4211 - val_f1: 0.1452\n",
      "Epoch 871/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2791 - f1: 0.6909 - val_loss: 0.4303 - val_f1: 0.1464\n",
      "Epoch 872/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2803 - f1: 0.6931 - val_loss: 0.4262 - val_f1: 0.1459\n",
      "Epoch 873/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2778 - f1: 0.6969 - val_loss: 0.4218 - val_f1: 0.1450\n",
      "Epoch 874/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2788 - f1: 0.6921 - val_loss: 0.4257 - val_f1: 0.1454\n",
      "Epoch 875/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2791 - f1: 0.6964 - val_loss: 0.4207 - val_f1: 0.1447\n",
      "Epoch 876/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2782 - f1: 0.6969 - val_loss: 0.4236 - val_f1: 0.1457\n",
      "Epoch 877/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2803 - f1: 0.6888 - val_loss: 0.4245 - val_f1: 0.1452\n",
      "Epoch 878/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2803 - f1: 0.6935 - val_loss: 0.4227 - val_f1: 0.1448\n",
      "Epoch 879/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2787 - f1: 0.6977 - val_loss: 0.4238 - val_f1: 0.1462\n",
      "Epoch 880/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2794 - f1: 0.6970 - val_loss: 0.4237 - val_f1: 0.1452\n",
      "Epoch 881/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2794 - f1: 0.6917 - val_loss: 0.4245 - val_f1: 0.1453\n",
      "Epoch 882/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2797 - f1: 0.6974 - val_loss: 0.4255 - val_f1: 0.1454\n",
      "Epoch 883/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2805 - f1: 0.6952 - val_loss: 0.4279 - val_f1: 0.1463\n",
      "Epoch 884/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2807 - f1: 0.6926 - val_loss: 0.4229 - val_f1: 0.1454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2785 - f1: 0.6955 - val_loss: 0.4222 - val_f1: 0.1457\n",
      "Epoch 886/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2804 - f1: 0.6916 - val_loss: 0.4275 - val_f1: 0.1449\n",
      "Epoch 887/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2779 - f1: 0.6953 - val_loss: 0.4261 - val_f1: 0.1456\n",
      "Epoch 888/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2805 - f1: 0.6924 - val_loss: 0.4297 - val_f1: 0.1465\n",
      "Epoch 889/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2815 - f1: 0.6941 - val_loss: 0.4250 - val_f1: 0.1464\n",
      "Epoch 890/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2794 - f1: 0.6928 - val_loss: 0.4213 - val_f1: 0.1450\n",
      "Epoch 891/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2791 - f1: 0.6927 - val_loss: 0.4243 - val_f1: 0.1459\n",
      "Epoch 892/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2777 - f1: 0.6947 - val_loss: 0.4223 - val_f1: 0.1451\n",
      "Epoch 893/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2782 - f1: 0.6977 - val_loss: 0.4208 - val_f1: 0.1447\n",
      "Epoch 894/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2795 - f1: 0.6918 - val_loss: 0.4246 - val_f1: 0.1470\n",
      "Epoch 895/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2794 - f1: 0.6953 - val_loss: 0.4255 - val_f1: 0.1448\n",
      "Epoch 896/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2793 - f1: 0.6958 - val_loss: 0.4269 - val_f1: 0.1456\n",
      "Epoch 897/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2780 - f1: 0.6963 - val_loss: 0.4219 - val_f1: 0.1451\n",
      "Epoch 898/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2791 - f1: 0.6925 - val_loss: 0.4263 - val_f1: 0.1456\n",
      "Epoch 899/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2782 - f1: 0.6998 - val_loss: 0.4311 - val_f1: 0.1466\n",
      "Epoch 900/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2791 - f1: 0.6939 - val_loss: 0.4255 - val_f1: 0.1457\n",
      "Epoch 901/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2792 - f1: 0.6940 - val_loss: 0.4229 - val_f1: 0.1452\n",
      "Epoch 902/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2788 - f1: 0.6952 - val_loss: 0.4230 - val_f1: 0.1448\n",
      "Epoch 903/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2793 - f1: 0.6951 - val_loss: 0.4335 - val_f1: 0.1458\n",
      "Epoch 904/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2783 - f1: 0.6970 - val_loss: 0.4278 - val_f1: 0.1458\n",
      "Epoch 905/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2791 - f1: 0.6925 - val_loss: 0.4275 - val_f1: 0.1451\n",
      "Epoch 906/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2775 - f1: 0.6966 - val_loss: 0.4210 - val_f1: 0.1450\n",
      "Epoch 907/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2793 - f1: 0.6941 - val_loss: 0.4218 - val_f1: 0.1461\n",
      "Epoch 908/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2794 - f1: 0.6941 - val_loss: 0.4304 - val_f1: 0.1464\n",
      "Epoch 909/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2792 - f1: 0.6937 - val_loss: 0.4232 - val_f1: 0.1457\n",
      "Epoch 910/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2774 - f1: 0.6922 - val_loss: 0.4262 - val_f1: 0.1451\n",
      "Epoch 911/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2786 - f1: 0.6920 - val_loss: 0.4278 - val_f1: 0.1452\n",
      "Epoch 912/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2794 - f1: 0.6949 - val_loss: 0.4274 - val_f1: 0.1453\n",
      "Epoch 913/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2813 - f1: 0.6924 - val_loss: 0.4257 - val_f1: 0.1455\n",
      "Epoch 914/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2804 - f1: 0.6921 - val_loss: 0.4268 - val_f1: 0.1451\n",
      "Epoch 915/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2794 - f1: 0.6957 - val_loss: 0.4235 - val_f1: 0.1458\n",
      "Epoch 916/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2804 - f1: 0.6920 - val_loss: 0.4270 - val_f1: 0.1447\n",
      "Epoch 917/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2790 - f1: 0.6951 - val_loss: 0.4263 - val_f1: 0.1467\n",
      "Epoch 918/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2792 - f1: 0.6947 - val_loss: 0.4240 - val_f1: 0.1461\n",
      "Epoch 919/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2772 - f1: 0.6931 - val_loss: 0.4287 - val_f1: 0.1456\n",
      "Epoch 920/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2788 - f1: 0.6953 - val_loss: 0.4252 - val_f1: 0.1454\n",
      "Epoch 921/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2770 - f1: 0.6988 - val_loss: 0.4226 - val_f1: 0.1447\n",
      "Epoch 922/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2786 - f1: 0.6977 - val_loss: 0.4305 - val_f1: 0.1457\n",
      "Epoch 923/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2798 - f1: 0.6942 - val_loss: 0.4181 - val_f1: 0.1456\n",
      "Epoch 924/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2802 - f1: 0.6946 - val_loss: 0.4201 - val_f1: 0.1445\n",
      "Epoch 925/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2784 - f1: 0.6916 - val_loss: 0.4307 - val_f1: 0.1457\n",
      "Epoch 926/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2793 - f1: 0.6959 - val_loss: 0.4279 - val_f1: 0.1448\n",
      "Epoch 927/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2763 - f1: 0.6978 - val_loss: 0.4241 - val_f1: 0.1448\n",
      "Epoch 928/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2771 - f1: 0.6909 - val_loss: 0.4330 - val_f1: 0.1470\n",
      "Epoch 929/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2781 - f1: 0.6944 - val_loss: 0.4279 - val_f1: 0.1460\n",
      "Epoch 930/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2776 - f1: 0.6954 - val_loss: 0.4271 - val_f1: 0.1449\n",
      "Epoch 931/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2790 - f1: 0.6949 - val_loss: 0.4255 - val_f1: 0.1460\n",
      "Epoch 932/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2785 - f1: 0.6954 - val_loss: 0.4239 - val_f1: 0.1453\n",
      "Epoch 933/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2780 - f1: 0.6957 - val_loss: 0.4226 - val_f1: 0.1450\n",
      "Epoch 934/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2772 - f1: 0.6947 - val_loss: 0.4338 - val_f1: 0.1460\n",
      "Epoch 935/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2772 - f1: 0.6984 - val_loss: 0.4294 - val_f1: 0.1460\n",
      "Epoch 936/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2773 - f1: 0.6975 - val_loss: 0.4336 - val_f1: 0.1465\n",
      "Epoch 937/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2778 - f1: 0.6964 - val_loss: 0.4230 - val_f1: 0.1461\n",
      "Epoch 938/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2767 - f1: 0.6989 - val_loss: 0.4339 - val_f1: 0.1467\n",
      "Epoch 939/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2771 - f1: 0.6995 - val_loss: 0.4221 - val_f1: 0.1458\n",
      "Epoch 940/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2791 - f1: 0.6898 - val_loss: 0.4197 - val_f1: 0.1460\n",
      "Epoch 941/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2777 - f1: 0.6957 - val_loss: 0.4246 - val_f1: 0.1448\n",
      "Epoch 942/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2797 - f1: 0.6923 - val_loss: 0.4272 - val_f1: 0.1454\n",
      "Epoch 943/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2776 - f1: 0.6950 - val_loss: 0.4230 - val_f1: 0.1462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2770 - f1: 0.6974 - val_loss: 0.4225 - val_f1: 0.1447\n",
      "Epoch 945/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2780 - f1: 0.6931 - val_loss: 0.4345 - val_f1: 0.1460\n",
      "Epoch 946/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2786 - f1: 0.6944 - val_loss: 0.4314 - val_f1: 0.1460\n",
      "Epoch 947/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2786 - f1: 0.6959 - val_loss: 0.4234 - val_f1: 0.1454\n",
      "Epoch 948/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2781 - f1: 0.6979 - val_loss: 0.4251 - val_f1: 0.1455\n",
      "Epoch 949/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2780 - f1: 0.6954 - val_loss: 0.4266 - val_f1: 0.1456\n",
      "Epoch 950/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2794 - f1: 0.6965 - val_loss: 0.4230 - val_f1: 0.1452\n",
      "Epoch 951/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2786 - f1: 0.6954 - val_loss: 0.4291 - val_f1: 0.1459\n",
      "Epoch 952/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2778 - f1: 0.6963 - val_loss: 0.4216 - val_f1: 0.1455\n",
      "Epoch 953/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2767 - f1: 0.6969 - val_loss: 0.4306 - val_f1: 0.1464\n",
      "Epoch 954/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2780 - f1: 0.6951 - val_loss: 0.4268 - val_f1: 0.1462\n",
      "Epoch 955/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2787 - f1: 0.6968 - val_loss: 0.4276 - val_f1: 0.1455\n",
      "Epoch 956/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2760 - f1: 0.6949 - val_loss: 0.4306 - val_f1: 0.1462\n",
      "Epoch 957/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2776 - f1: 0.7002 - val_loss: 0.4287 - val_f1: 0.1453\n",
      "Epoch 958/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2766 - f1: 0.6979 - val_loss: 0.4312 - val_f1: 0.1453\n",
      "Epoch 959/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2780 - f1: 0.7005 - val_loss: 0.4217 - val_f1: 0.1453\n",
      "Epoch 960/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2790 - f1: 0.6990 - val_loss: 0.4263 - val_f1: 0.1448\n",
      "Epoch 961/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2765 - f1: 0.7006 - val_loss: 0.4238 - val_f1: 0.1450\n",
      "Epoch 962/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2782 - f1: 0.6961 - val_loss: 0.4269 - val_f1: 0.1455\n",
      "Epoch 963/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2759 - f1: 0.6985 - val_loss: 0.4261 - val_f1: 0.1456\n",
      "Epoch 964/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2764 - f1: 0.7004 - val_loss: 0.4248 - val_f1: 0.1459\n",
      "Epoch 965/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2762 - f1: 0.6947 - val_loss: 0.4283 - val_f1: 0.1455\n",
      "Epoch 966/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2794 - f1: 0.6975 - val_loss: 0.4261 - val_f1: 0.1454\n",
      "Epoch 967/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2784 - f1: 0.6909 - val_loss: 0.4222 - val_f1: 0.1457\n",
      "Epoch 968/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2775 - f1: 0.6967 - val_loss: 0.4245 - val_f1: 0.1460\n",
      "Epoch 969/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2792 - f1: 0.6956 - val_loss: 0.4258 - val_f1: 0.1458\n",
      "Epoch 970/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2751 - f1: 0.7009 - val_loss: 0.4334 - val_f1: 0.1469\n",
      "Epoch 971/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2794 - f1: 0.6945 - val_loss: 0.4208 - val_f1: 0.1451\n",
      "Epoch 972/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2780 - f1: 0.6928 - val_loss: 0.4234 - val_f1: 0.1449\n",
      "Epoch 973/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2786 - f1: 0.6949 - val_loss: 0.4328 - val_f1: 0.1464\n",
      "Epoch 974/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2764 - f1: 0.6978 - val_loss: 0.4292 - val_f1: 0.1452\n",
      "Epoch 975/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2770 - f1: 0.6971 - val_loss: 0.4270 - val_f1: 0.1459\n",
      "Epoch 976/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2789 - f1: 0.6945 - val_loss: 0.4293 - val_f1: 0.1459\n",
      "Epoch 977/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2773 - f1: 0.6939 - val_loss: 0.4388 - val_f1: 0.1470\n",
      "Epoch 978/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2761 - f1: 0.6972 - val_loss: 0.4304 - val_f1: 0.1461\n",
      "Epoch 979/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2790 - f1: 0.6938 - val_loss: 0.4243 - val_f1: 0.1450\n",
      "Epoch 980/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2748 - f1: 0.6998 - val_loss: 0.4270 - val_f1: 0.1458\n",
      "Epoch 981/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2748 - f1: 0.6973 - val_loss: 0.4266 - val_f1: 0.1450\n",
      "Epoch 982/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2769 - f1: 0.6983 - val_loss: 0.4290 - val_f1: 0.1456\n",
      "Epoch 983/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2781 - f1: 0.6944 - val_loss: 0.4276 - val_f1: 0.1457\n",
      "Epoch 984/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2725 - f1: 0.7044 - val_loss: 0.4258 - val_f1: 0.1450\n",
      "Epoch 985/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2766 - f1: 0.6947 - val_loss: 0.4288 - val_f1: 0.1466\n",
      "Epoch 986/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2776 - f1: 0.6956 - val_loss: 0.4253 - val_f1: 0.1454\n",
      "Epoch 987/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2786 - f1: 0.6931 - val_loss: 0.4223 - val_f1: 0.1448\n",
      "Epoch 988/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2761 - f1: 0.6983 - val_loss: 0.4282 - val_f1: 0.1458\n",
      "Epoch 989/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2771 - f1: 0.6986 - val_loss: 0.4295 - val_f1: 0.1448\n",
      "Epoch 990/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2754 - f1: 0.7028 - val_loss: 0.4303 - val_f1: 0.1451\n",
      "Epoch 991/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2733 - f1: 0.7031 - val_loss: 0.4309 - val_f1: 0.1459\n",
      "Epoch 992/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2759 - f1: 0.6934 - val_loss: 0.4364 - val_f1: 0.1473\n",
      "Epoch 993/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2771 - f1: 0.6960 - val_loss: 0.4309 - val_f1: 0.1458\n",
      "Epoch 994/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2748 - f1: 0.6972 - val_loss: 0.4275 - val_f1: 0.1460\n",
      "Epoch 995/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2759 - f1: 0.6979 - val_loss: 0.4315 - val_f1: 0.1470\n",
      "Epoch 996/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2754 - f1: 0.6998 - val_loss: 0.4290 - val_f1: 0.1463\n",
      "Epoch 997/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2765 - f1: 0.6971 - val_loss: 0.4247 - val_f1: 0.1453\n",
      "Epoch 998/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2755 - f1: 0.6975 - val_loss: 0.4259 - val_f1: 0.1452\n",
      "Epoch 999/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2783 - f1: 0.6913 - val_loss: 0.4248 - val_f1: 0.1455\n",
      "Epoch 1000/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2765 - f1: 0.7001 - val_loss: 0.4289 - val_f1: 0.1456\n",
      "Epoch 1001/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2764 - f1: 0.6935 - val_loss: 0.4291 - val_f1: 0.1449\n",
      "Epoch 1002/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2748 - f1: 0.6966 - val_loss: 0.4319 - val_f1: 0.1460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1003/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2774 - f1: 0.6951 - val_loss: 0.4274 - val_f1: 0.1449\n",
      "Epoch 1004/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2770 - f1: 0.6943 - val_loss: 0.4302 - val_f1: 0.1459\n",
      "Epoch 1005/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2748 - f1: 0.6961 - val_loss: 0.4290 - val_f1: 0.1459\n",
      "Epoch 1006/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2762 - f1: 0.6982 - val_loss: 0.4214 - val_f1: 0.1453\n",
      "Epoch 1007/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2751 - f1: 0.7008 - val_loss: 0.4225 - val_f1: 0.1449\n",
      "Epoch 1008/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2745 - f1: 0.7019 - val_loss: 0.4277 - val_f1: 0.1447\n",
      "Epoch 1009/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2773 - f1: 0.6934 - val_loss: 0.4233 - val_f1: 0.1445\n",
      "Epoch 1010/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2769 - f1: 0.6979 - val_loss: 0.4239 - val_f1: 0.1453\n",
      "Epoch 1011/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2754 - f1: 0.7019 - val_loss: 0.4294 - val_f1: 0.1467\n",
      "Epoch 1012/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2765 - f1: 0.7008 - val_loss: 0.4254 - val_f1: 0.1461\n",
      "Epoch 1013/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2769 - f1: 0.6974 - val_loss: 0.4306 - val_f1: 0.1454\n",
      "Epoch 1014/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2752 - f1: 0.7007 - val_loss: 0.4354 - val_f1: 0.1462\n",
      "Epoch 1015/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2778 - f1: 0.6988 - val_loss: 0.4248 - val_f1: 0.1454\n",
      "Epoch 1016/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2769 - f1: 0.6977 - val_loss: 0.4295 - val_f1: 0.1451\n",
      "Epoch 1017/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2777 - f1: 0.6944 - val_loss: 0.4298 - val_f1: 0.1459\n",
      "Epoch 1018/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2750 - f1: 0.6999 - val_loss: 0.4264 - val_f1: 0.1454\n",
      "Epoch 1019/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2752 - f1: 0.7003 - val_loss: 0.4292 - val_f1: 0.1456\n",
      "Epoch 1020/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2757 - f1: 0.6972 - val_loss: 0.4303 - val_f1: 0.1462\n",
      "Epoch 1021/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2753 - f1: 0.7012 - val_loss: 0.4285 - val_f1: 0.1458\n",
      "Epoch 1022/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2770 - f1: 0.6994 - val_loss: 0.4336 - val_f1: 0.1454\n",
      "Epoch 1023/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2772 - f1: 0.6932 - val_loss: 0.4241 - val_f1: 0.1448\n",
      "Epoch 1024/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2752 - f1: 0.7050 - val_loss: 0.4318 - val_f1: 0.1466\n",
      "Epoch 1025/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2742 - f1: 0.7013 - val_loss: 0.4346 - val_f1: 0.1466\n",
      "Epoch 1026/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2770 - f1: 0.6995 - val_loss: 0.4293 - val_f1: 0.1455\n",
      "Epoch 1027/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2741 - f1: 0.6977 - val_loss: 0.4325 - val_f1: 0.1458\n",
      "Epoch 1028/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2761 - f1: 0.6959 - val_loss: 0.4337 - val_f1: 0.1462\n",
      "Epoch 1029/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2750 - f1: 0.7044 - val_loss: 0.4321 - val_f1: 0.1457\n",
      "Epoch 1030/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2766 - f1: 0.6982 - val_loss: 0.4279 - val_f1: 0.1455\n",
      "Epoch 1031/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2737 - f1: 0.7004 - val_loss: 0.4272 - val_f1: 0.1452\n",
      "Epoch 1032/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2747 - f1: 0.6983 - val_loss: 0.4399 - val_f1: 0.1475\n",
      "Epoch 1033/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2743 - f1: 0.7037 - val_loss: 0.4323 - val_f1: 0.1464\n",
      "Epoch 1034/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2728 - f1: 0.7038 - val_loss: 0.4325 - val_f1: 0.1465\n",
      "Epoch 1035/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2766 - f1: 0.6973 - val_loss: 0.4252 - val_f1: 0.1449\n",
      "Epoch 1036/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2739 - f1: 0.6957 - val_loss: 0.4288 - val_f1: 0.1459\n",
      "Epoch 1037/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2767 - f1: 0.7014 - val_loss: 0.4296 - val_f1: 0.1461\n",
      "Epoch 1038/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2743 - f1: 0.7014 - val_loss: 0.4265 - val_f1: 0.1453\n",
      "Epoch 1039/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2770 - f1: 0.6932 - val_loss: 0.4258 - val_f1: 0.1463\n",
      "Epoch 1040/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2753 - f1: 0.6996 - val_loss: 0.4290 - val_f1: 0.1461\n",
      "Epoch 1041/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2763 - f1: 0.6990 - val_loss: 0.4298 - val_f1: 0.1462\n",
      "Epoch 1042/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2763 - f1: 0.6966 - val_loss: 0.4371 - val_f1: 0.1465\n",
      "Epoch 1043/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2749 - f1: 0.7003 - val_loss: 0.4369 - val_f1: 0.1470\n",
      "Epoch 1044/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2772 - f1: 0.6952 - val_loss: 0.4331 - val_f1: 0.1455\n",
      "Epoch 1045/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2754 - f1: 0.7022 - val_loss: 0.4322 - val_f1: 0.1460\n",
      "Epoch 1046/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2753 - f1: 0.6992 - val_loss: 0.4198 - val_f1: 0.1450\n",
      "Epoch 1047/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2782 - f1: 0.6967 - val_loss: 0.4255 - val_f1: 0.1447\n",
      "Epoch 1048/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2744 - f1: 0.7024 - val_loss: 0.4285 - val_f1: 0.1457\n",
      "Epoch 1049/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2757 - f1: 0.7011 - val_loss: 0.4259 - val_f1: 0.1457\n",
      "Epoch 1050/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2744 - f1: 0.7039 - val_loss: 0.4348 - val_f1: 0.1465\n",
      "Epoch 1051/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2750 - f1: 0.7022 - val_loss: 0.4209 - val_f1: 0.1443\n",
      "Epoch 1052/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2743 - f1: 0.7016 - val_loss: 0.4318 - val_f1: 0.1459\n",
      "Epoch 1053/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2760 - f1: 0.6988 - val_loss: 0.4243 - val_f1: 0.1450\n",
      "Epoch 1054/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2766 - f1: 0.6990 - val_loss: 0.4271 - val_f1: 0.1460\n",
      "Epoch 1055/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2752 - f1: 0.7049 - val_loss: 0.4302 - val_f1: 0.1456\n",
      "Epoch 1056/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2744 - f1: 0.7038 - val_loss: 0.4255 - val_f1: 0.1451\n",
      "Epoch 1057/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2756 - f1: 0.6933 - val_loss: 0.4264 - val_f1: 0.1459\n",
      "Epoch 1058/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2740 - f1: 0.7000 - val_loss: 0.4319 - val_f1: 0.1461\n",
      "Epoch 1059/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2749 - f1: 0.7035 - val_loss: 0.4280 - val_f1: 0.1457\n",
      "Epoch 1060/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2722 - f1: 0.7039 - val_loss: 0.4317 - val_f1: 0.1455\n",
      "Epoch 1061/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2732 - f1: 0.7027 - val_loss: 0.4355 - val_f1: 0.1469\n",
      "Epoch 1062/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2748 - f1: 0.7052 - val_loss: 0.4319 - val_f1: 0.1463\n",
      "Epoch 1063/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2727 - f1: 0.7053 - val_loss: 0.4310 - val_f1: 0.1449\n",
      "Epoch 1064/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2760 - f1: 0.7034 - val_loss: 0.4301 - val_f1: 0.1458\n",
      "Epoch 1065/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2746 - f1: 0.7029 - val_loss: 0.4317 - val_f1: 0.1461\n",
      "Epoch 1066/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2769 - f1: 0.6986 - val_loss: 0.4282 - val_f1: 0.1451\n",
      "Epoch 1067/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2751 - f1: 0.7009 - val_loss: 0.4289 - val_f1: 0.1464\n",
      "Epoch 1068/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2756 - f1: 0.6969 - val_loss: 0.4330 - val_f1: 0.1459\n",
      "Epoch 1069/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2774 - f1: 0.6956 - val_loss: 0.4309 - val_f1: 0.1460\n",
      "Epoch 1070/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2767 - f1: 0.6993 - val_loss: 0.4293 - val_f1: 0.1465\n",
      "Epoch 1071/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2751 - f1: 0.6986 - val_loss: 0.4327 - val_f1: 0.1469\n",
      "Epoch 1072/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2719 - f1: 0.7045 - val_loss: 0.4273 - val_f1: 0.1453\n",
      "Epoch 1073/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2755 - f1: 0.7023 - val_loss: 0.4252 - val_f1: 0.1457\n",
      "Epoch 1074/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2757 - f1: 0.7042 - val_loss: 0.4215 - val_f1: 0.1448\n",
      "Epoch 1075/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2744 - f1: 0.7027 - val_loss: 0.4317 - val_f1: 0.1457\n",
      "Epoch 1076/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2752 - f1: 0.6978 - val_loss: 0.4302 - val_f1: 0.1467\n",
      "Epoch 1077/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2754 - f1: 0.6960 - val_loss: 0.4320 - val_f1: 0.1461\n",
      "Epoch 1078/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2754 - f1: 0.6994 - val_loss: 0.4291 - val_f1: 0.1469\n",
      "Epoch 1079/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2752 - f1: 0.7019 - val_loss: 0.4253 - val_f1: 0.1458\n",
      "Epoch 1080/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2720 - f1: 0.7067 - val_loss: 0.4289 - val_f1: 0.1456\n",
      "Epoch 1081/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2759 - f1: 0.6994 - val_loss: 0.4306 - val_f1: 0.1461\n",
      "Epoch 1082/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2766 - f1: 0.6981 - val_loss: 0.4300 - val_f1: 0.1465\n",
      "Epoch 1083/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2747 - f1: 0.7010 - val_loss: 0.4344 - val_f1: 0.1459\n",
      "Epoch 1084/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2734 - f1: 0.7031 - val_loss: 0.4289 - val_f1: 0.1457\n",
      "Epoch 1085/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2764 - f1: 0.6992 - val_loss: 0.4264 - val_f1: 0.1454\n",
      "Epoch 1086/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2742 - f1: 0.7013 - val_loss: 0.4276 - val_f1: 0.1456\n",
      "Epoch 1087/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2747 - f1: 0.7048 - val_loss: 0.4336 - val_f1: 0.1458\n",
      "Epoch 1088/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2743 - f1: 0.7023 - val_loss: 0.4347 - val_f1: 0.1467\n",
      "Epoch 1089/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2756 - f1: 0.7004 - val_loss: 0.4241 - val_f1: 0.1463\n",
      "Epoch 1090/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2731 - f1: 0.7042 - val_loss: 0.4282 - val_f1: 0.1459\n",
      "Epoch 1091/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2741 - f1: 0.6979 - val_loss: 0.4255 - val_f1: 0.1467\n",
      "Epoch 1092/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2731 - f1: 0.7020 - val_loss: 0.4334 - val_f1: 0.1467\n",
      "Epoch 1093/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2762 - f1: 0.7006 - val_loss: 0.4254 - val_f1: 0.1456\n",
      "Epoch 1094/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2732 - f1: 0.7023 - val_loss: 0.4299 - val_f1: 0.1464\n",
      "Epoch 1095/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2725 - f1: 0.7059 - val_loss: 0.4338 - val_f1: 0.1455\n",
      "Epoch 1096/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2748 - f1: 0.7018 - val_loss: 0.4339 - val_f1: 0.1463\n",
      "Epoch 1097/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2739 - f1: 0.7084 - val_loss: 0.4256 - val_f1: 0.1454\n",
      "Epoch 1098/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2724 - f1: 0.7048 - val_loss: 0.4291 - val_f1: 0.1456\n",
      "Epoch 1099/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2745 - f1: 0.7005 - val_loss: 0.4351 - val_f1: 0.1458\n",
      "Epoch 1100/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2727 - f1: 0.7031 - val_loss: 0.4321 - val_f1: 0.1464\n",
      "Epoch 1101/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2748 - f1: 0.6965 - val_loss: 0.4321 - val_f1: 0.1465\n",
      "Epoch 1102/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2745 - f1: 0.7024 - val_loss: 0.4221 - val_f1: 0.1457\n",
      "Epoch 1103/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2741 - f1: 0.7024 - val_loss: 0.4272 - val_f1: 0.1445\n",
      "Epoch 1104/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2742 - f1: 0.7015 - val_loss: 0.4309 - val_f1: 0.1467\n",
      "Epoch 1105/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2745 - f1: 0.7013 - val_loss: 0.4285 - val_f1: 0.1457\n",
      "Epoch 1106/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2735 - f1: 0.7056 - val_loss: 0.4329 - val_f1: 0.1459\n",
      "Epoch 1107/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2758 - f1: 0.6966 - val_loss: 0.4322 - val_f1: 0.1457\n",
      "Epoch 1108/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2745 - f1: 0.6997 - val_loss: 0.4276 - val_f1: 0.1459\n",
      "Epoch 1109/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2743 - f1: 0.6990 - val_loss: 0.4331 - val_f1: 0.1462\n",
      "Epoch 1110/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2728 - f1: 0.7035 - val_loss: 0.4264 - val_f1: 0.1450\n",
      "Epoch 1111/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2738 - f1: 0.6984 - val_loss: 0.4335 - val_f1: 0.1455\n",
      "Epoch 1112/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2730 - f1: 0.7064 - val_loss: 0.4385 - val_f1: 0.1467\n",
      "Epoch 1113/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2720 - f1: 0.7033 - val_loss: 0.4358 - val_f1: 0.1458\n",
      "Epoch 1114/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2742 - f1: 0.6979 - val_loss: 0.4324 - val_f1: 0.1463\n",
      "Epoch 1115/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2745 - f1: 0.6968 - val_loss: 0.4315 - val_f1: 0.1458\n",
      "Epoch 1116/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2757 - f1: 0.7037 - val_loss: 0.4253 - val_f1: 0.1449\n",
      "Epoch 1117/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2747 - f1: 0.7015 - val_loss: 0.4366 - val_f1: 0.1462\n",
      "Epoch 1118/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2756 - f1: 0.7011 - val_loss: 0.4296 - val_f1: 0.1458\n",
      "Epoch 1119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2741 - f1: 0.7061 - val_loss: 0.4346 - val_f1: 0.1453\n",
      "Epoch 1120/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2735 - f1: 0.7025 - val_loss: 0.4346 - val_f1: 0.1455\n",
      "Epoch 1121/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2731 - f1: 0.7053 - val_loss: 0.4261 - val_f1: 0.1455\n",
      "Epoch 1122/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2728 - f1: 0.7023 - val_loss: 0.4289 - val_f1: 0.1448\n",
      "Epoch 1123/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2740 - f1: 0.7020 - val_loss: 0.4317 - val_f1: 0.1466\n",
      "Epoch 1124/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2751 - f1: 0.7041 - val_loss: 0.4342 - val_f1: 0.1463\n",
      "Epoch 1125/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2744 - f1: 0.7038 - val_loss: 0.4333 - val_f1: 0.1458\n",
      "Epoch 1126/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2724 - f1: 0.7017 - val_loss: 0.4314 - val_f1: 0.1457\n",
      "Epoch 1127/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2752 - f1: 0.7025 - val_loss: 0.4276 - val_f1: 0.1454\n",
      "Epoch 1128/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2739 - f1: 0.7010 - val_loss: 0.4315 - val_f1: 0.1464\n",
      "Epoch 1129/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2741 - f1: 0.7044 - val_loss: 0.4290 - val_f1: 0.1455\n",
      "Epoch 1130/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2703 - f1: 0.7092 - val_loss: 0.4392 - val_f1: 0.1470\n",
      "Epoch 1131/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2752 - f1: 0.6987 - val_loss: 0.4317 - val_f1: 0.1451\n",
      "Epoch 1132/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2744 - f1: 0.7004 - val_loss: 0.4321 - val_f1: 0.1461\n",
      "Epoch 1133/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2748 - f1: 0.7003 - val_loss: 0.4327 - val_f1: 0.1452\n",
      "Epoch 1134/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2720 - f1: 0.7016 - val_loss: 0.4320 - val_f1: 0.1461\n",
      "Epoch 1135/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2750 - f1: 0.6994 - val_loss: 0.4305 - val_f1: 0.1457\n",
      "Epoch 1136/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2736 - f1: 0.6999 - val_loss: 0.4300 - val_f1: 0.1447\n",
      "Epoch 1137/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2748 - f1: 0.7001 - val_loss: 0.4319 - val_f1: 0.1460\n",
      "Epoch 1138/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2723 - f1: 0.7058 - val_loss: 0.4335 - val_f1: 0.1452\n",
      "Epoch 1139/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2748 - f1: 0.7018 - val_loss: 0.4279 - val_f1: 0.1455\n",
      "Epoch 1140/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2724 - f1: 0.7049 - val_loss: 0.4286 - val_f1: 0.1445\n",
      "Epoch 1141/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2728 - f1: 0.7039 - val_loss: 0.4361 - val_f1: 0.1463\n",
      "Epoch 1142/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2738 - f1: 0.7034 - val_loss: 0.4253 - val_f1: 0.1462\n",
      "Epoch 1143/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2734 - f1: 0.7030 - val_loss: 0.4314 - val_f1: 0.1456\n",
      "Epoch 1144/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2734 - f1: 0.7019 - val_loss: 0.4299 - val_f1: 0.1455\n",
      "Epoch 1145/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2744 - f1: 0.7016 - val_loss: 0.4347 - val_f1: 0.1465\n",
      "Epoch 1146/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2728 - f1: 0.7009 - val_loss: 0.4313 - val_f1: 0.1461\n",
      "Epoch 1147/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2719 - f1: 0.7041 - val_loss: 0.4349 - val_f1: 0.1452\n",
      "Epoch 1148/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2729 - f1: 0.6987 - val_loss: 0.4324 - val_f1: 0.1459\n",
      "Epoch 1149/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2729 - f1: 0.7020 - val_loss: 0.4338 - val_f1: 0.1450\n",
      "Epoch 1150/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2718 - f1: 0.7049 - val_loss: 0.4353 - val_f1: 0.1463\n",
      "Epoch 1151/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2726 - f1: 0.7088 - val_loss: 0.4412 - val_f1: 0.1467\n",
      "Epoch 1152/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2715 - f1: 0.7053 - val_loss: 0.4361 - val_f1: 0.1464\n",
      "Epoch 1153/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2732 - f1: 0.7043 - val_loss: 0.4295 - val_f1: 0.1458\n",
      "Epoch 1154/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2722 - f1: 0.7066 - val_loss: 0.4360 - val_f1: 0.1464\n",
      "Epoch 1155/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2733 - f1: 0.7017 - val_loss: 0.4297 - val_f1: 0.1459\n",
      "Epoch 1156/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2699 - f1: 0.7095 - val_loss: 0.4368 - val_f1: 0.1465\n",
      "Epoch 1157/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2729 - f1: 0.6986 - val_loss: 0.4350 - val_f1: 0.1464\n",
      "Epoch 1158/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2720 - f1: 0.7012 - val_loss: 0.4331 - val_f1: 0.1463\n",
      "Epoch 1159/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2725 - f1: 0.7047 - val_loss: 0.4282 - val_f1: 0.1452\n",
      "Epoch 1160/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2722 - f1: 0.7077 - val_loss: 0.4316 - val_f1: 0.1459\n",
      "Epoch 1161/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2715 - f1: 0.7079 - val_loss: 0.4418 - val_f1: 0.1455\n",
      "Epoch 1162/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2732 - f1: 0.7015 - val_loss: 0.4282 - val_f1: 0.1447\n",
      "Epoch 1163/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2731 - f1: 0.7039 - val_loss: 0.4319 - val_f1: 0.1449\n",
      "Epoch 1164/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2735 - f1: 0.7040 - val_loss: 0.4279 - val_f1: 0.1449\n",
      "Epoch 1165/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2712 - f1: 0.7037 - val_loss: 0.4451 - val_f1: 0.1464\n",
      "Epoch 1166/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2729 - f1: 0.7073 - val_loss: 0.4306 - val_f1: 0.1452\n",
      "Epoch 1167/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2742 - f1: 0.7016 - val_loss: 0.4340 - val_f1: 0.1454\n",
      "Epoch 1168/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2727 - f1: 0.7020 - val_loss: 0.4302 - val_f1: 0.1458\n",
      "Epoch 1169/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2725 - f1: 0.7045 - val_loss: 0.4344 - val_f1: 0.1457\n",
      "Epoch 1170/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2727 - f1: 0.7021 - val_loss: 0.4296 - val_f1: 0.1459\n",
      "Epoch 1171/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2722 - f1: 0.7057 - val_loss: 0.4294 - val_f1: 0.1455\n",
      "Epoch 1172/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2738 - f1: 0.7022 - val_loss: 0.4308 - val_f1: 0.1466\n",
      "Epoch 1173/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2736 - f1: 0.7048 - val_loss: 0.4272 - val_f1: 0.1458\n",
      "Epoch 1174/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2711 - f1: 0.7036 - val_loss: 0.4357 - val_f1: 0.1463\n",
      "Epoch 1175/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2720 - f1: 0.7053 - val_loss: 0.4326 - val_f1: 0.1452\n",
      "Epoch 1176/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2723 - f1: 0.7007 - val_loss: 0.4282 - val_f1: 0.1447\n",
      "Epoch 1177/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2710 - f1: 0.7039 - val_loss: 0.4304 - val_f1: 0.1455\n",
      "Epoch 1178/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2739 - f1: 0.7005 - val_loss: 0.4265 - val_f1: 0.1455\n",
      "Epoch 1179/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2729 - f1: 0.7055 - val_loss: 0.4297 - val_f1: 0.1457\n",
      "Epoch 1180/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2728 - f1: 0.7055 - val_loss: 0.4364 - val_f1: 0.1450\n",
      "Epoch 1181/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2744 - f1: 0.6997 - val_loss: 0.4307 - val_f1: 0.1446\n",
      "Epoch 1182/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2742 - f1: 0.6997 - val_loss: 0.4326 - val_f1: 0.1456\n",
      "Epoch 1183/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2726 - f1: 0.7044 - val_loss: 0.4350 - val_f1: 0.1460\n",
      "Epoch 1184/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2724 - f1: 0.7066 - val_loss: 0.4370 - val_f1: 0.1459\n",
      "Epoch 1185/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2730 - f1: 0.7035 - val_loss: 0.4321 - val_f1: 0.1454\n",
      "Epoch 1186/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2728 - f1: 0.7036 - val_loss: 0.4321 - val_f1: 0.1462\n",
      "Epoch 1187/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2719 - f1: 0.7062 - val_loss: 0.4347 - val_f1: 0.1464\n",
      "Epoch 1188/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2717 - f1: 0.7065 - val_loss: 0.4385 - val_f1: 0.1457\n",
      "Epoch 1189/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2735 - f1: 0.7041 - val_loss: 0.4313 - val_f1: 0.1453\n",
      "Epoch 1190/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2720 - f1: 0.7039 - val_loss: 0.4333 - val_f1: 0.1450\n",
      "Epoch 1191/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2724 - f1: 0.7020 - val_loss: 0.4297 - val_f1: 0.1455\n",
      "Epoch 1192/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2722 - f1: 0.7059 - val_loss: 0.4351 - val_f1: 0.1459\n",
      "Epoch 1193/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2722 - f1: 0.7062 - val_loss: 0.4338 - val_f1: 0.1457\n",
      "Epoch 1194/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2728 - f1: 0.7020 - val_loss: 0.4315 - val_f1: 0.1462\n",
      "Epoch 1195/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2721 - f1: 0.7027 - val_loss: 0.4301 - val_f1: 0.1461\n",
      "Epoch 1196/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2735 - f1: 0.7008 - val_loss: 0.4316 - val_f1: 0.1458\n",
      "Epoch 1197/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2722 - f1: 0.7035 - val_loss: 0.4328 - val_f1: 0.1461\n",
      "Epoch 1198/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2732 - f1: 0.7039 - val_loss: 0.4320 - val_f1: 0.1465\n",
      "Epoch 1199/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2721 - f1: 0.7046 - val_loss: 0.4326 - val_f1: 0.1463\n",
      "Epoch 1200/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2727 - f1: 0.7032 - val_loss: 0.4309 - val_f1: 0.1465\n",
      "Epoch 1201/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2702 - f1: 0.7125 - val_loss: 0.4295 - val_f1: 0.1457\n",
      "Epoch 1202/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2736 - f1: 0.7036 - val_loss: 0.4324 - val_f1: 0.1467\n",
      "Epoch 1203/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2711 - f1: 0.7127 - val_loss: 0.4277 - val_f1: 0.1454\n",
      "Epoch 1204/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2713 - f1: 0.7090 - val_loss: 0.4338 - val_f1: 0.1456\n",
      "Epoch 1205/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2721 - f1: 0.7045 - val_loss: 0.4270 - val_f1: 0.1442\n",
      "Epoch 1206/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2720 - f1: 0.7038 - val_loss: 0.4277 - val_f1: 0.1450\n",
      "Epoch 1207/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2708 - f1: 0.7094 - val_loss: 0.4323 - val_f1: 0.1458\n",
      "Epoch 1208/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2733 - f1: 0.7016 - val_loss: 0.4276 - val_f1: 0.1448\n",
      "Epoch 1209/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2716 - f1: 0.7048 - val_loss: 0.4301 - val_f1: 0.1452\n",
      "Epoch 1210/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2717 - f1: 0.7072 - val_loss: 0.4272 - val_f1: 0.1455\n",
      "Epoch 1211/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2722 - f1: 0.7042 - val_loss: 0.4282 - val_f1: 0.1451\n",
      "Epoch 1212/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2716 - f1: 0.7037 - val_loss: 0.4307 - val_f1: 0.1463\n",
      "Epoch 1213/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2722 - f1: 0.7011 - val_loss: 0.4323 - val_f1: 0.1460\n",
      "Epoch 1214/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2708 - f1: 0.7073 - val_loss: 0.4296 - val_f1: 0.1458\n",
      "Epoch 1215/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2699 - f1: 0.7070 - val_loss: 0.4370 - val_f1: 0.1462\n",
      "Epoch 1216/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2710 - f1: 0.7076 - val_loss: 0.4365 - val_f1: 0.1461\n",
      "Epoch 1217/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2720 - f1: 0.7031 - val_loss: 0.4269 - val_f1: 0.1440\n",
      "Epoch 1218/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2719 - f1: 0.7016 - val_loss: 0.4306 - val_f1: 0.1460\n",
      "Epoch 1219/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2712 - f1: 0.7041 - val_loss: 0.4294 - val_f1: 0.1461\n",
      "Epoch 1220/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2692 - f1: 0.7090 - val_loss: 0.4334 - val_f1: 0.1454\n",
      "Epoch 1221/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2724 - f1: 0.6986 - val_loss: 0.4416 - val_f1: 0.1459\n",
      "Epoch 1222/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2699 - f1: 0.7075 - val_loss: 0.4380 - val_f1: 0.1465\n",
      "Epoch 1223/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2723 - f1: 0.7057 - val_loss: 0.4334 - val_f1: 0.1455\n",
      "Epoch 1224/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2692 - f1: 0.7116 - val_loss: 0.4381 - val_f1: 0.1460\n",
      "Epoch 1225/2000\n",
      "64440/64440 [==============================] - 4s 54us/step - loss: 0.2738 - f1: 0.7054 - val_loss: 0.4303 - val_f1: 0.1451\n",
      "Epoch 1226/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2725 - f1: 0.7031 - val_loss: 0.4361 - val_f1: 0.1463\n",
      "Epoch 1227/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2712 - f1: 0.7039 - val_loss: 0.4354 - val_f1: 0.1456\n",
      "Epoch 1228/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2710 - f1: 0.7072 - val_loss: 0.4330 - val_f1: 0.1459\n",
      "Epoch 1229/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2716 - f1: 0.7045 - val_loss: 0.4352 - val_f1: 0.1465\n",
      "Epoch 1230/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2708 - f1: 0.7079 - val_loss: 0.4341 - val_f1: 0.1463\n",
      "Epoch 1231/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2720 - f1: 0.7070 - val_loss: 0.4335 - val_f1: 0.1466\n",
      "Epoch 1232/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2725 - f1: 0.7070 - val_loss: 0.4348 - val_f1: 0.1462\n",
      "Epoch 1233/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2703 - f1: 0.7072 - val_loss: 0.4319 - val_f1: 0.1458\n",
      "Epoch 1234/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2718 - f1: 0.7069 - val_loss: 0.4393 - val_f1: 0.1471\n",
      "Epoch 1235/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2707 - f1: 0.7046 - val_loss: 0.4358 - val_f1: 0.1467\n",
      "Epoch 1236/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2694 - f1: 0.7099 - val_loss: 0.4356 - val_f1: 0.1460\n",
      "Epoch 1237/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2731 - f1: 0.7058 - val_loss: 0.4291 - val_f1: 0.1452\n",
      "Epoch 1238/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2731 - f1: 0.7069 - val_loss: 0.4322 - val_f1: 0.1454\n",
      "Epoch 1239/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2714 - f1: 0.7047 - val_loss: 0.4339 - val_f1: 0.1458\n",
      "Epoch 1240/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2703 - f1: 0.7103 - val_loss: 0.4349 - val_f1: 0.1463\n",
      "Epoch 1241/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2710 - f1: 0.7071 - val_loss: 0.4321 - val_f1: 0.1460\n",
      "Epoch 1242/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2685 - f1: 0.7085 - val_loss: 0.4459 - val_f1: 0.1469\n",
      "Epoch 1243/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2701 - f1: 0.7104 - val_loss: 0.4337 - val_f1: 0.1453\n",
      "Epoch 1244/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2706 - f1: 0.7067 - val_loss: 0.4360 - val_f1: 0.1457\n",
      "Epoch 1245/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2692 - f1: 0.7034 - val_loss: 0.4324 - val_f1: 0.1461\n",
      "Epoch 1246/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2705 - f1: 0.7075 - val_loss: 0.4321 - val_f1: 0.1454\n",
      "Epoch 1247/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2713 - f1: 0.7096 - val_loss: 0.4300 - val_f1: 0.1454\n",
      "Epoch 1248/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2716 - f1: 0.7081 - val_loss: 0.4304 - val_f1: 0.1450\n",
      "Epoch 1249/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2724 - f1: 0.7046 - val_loss: 0.4316 - val_f1: 0.1457\n",
      "Epoch 1250/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2698 - f1: 0.7075 - val_loss: 0.4361 - val_f1: 0.1463\n",
      "Epoch 1251/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2718 - f1: 0.7106 - val_loss: 0.4327 - val_f1: 0.1464\n",
      "Epoch 1252/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2720 - f1: 0.7000 - val_loss: 0.4363 - val_f1: 0.1459\n",
      "Epoch 1253/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2714 - f1: 0.6999 - val_loss: 0.4299 - val_f1: 0.1452\n",
      "Epoch 1254/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2712 - f1: 0.7051 - val_loss: 0.4333 - val_f1: 0.1461\n",
      "Epoch 1255/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2718 - f1: 0.7067 - val_loss: 0.4368 - val_f1: 0.1455\n",
      "Epoch 1256/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2731 - f1: 0.7060 - val_loss: 0.4257 - val_f1: 0.1445\n",
      "Epoch 1257/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2719 - f1: 0.7055 - val_loss: 0.4310 - val_f1: 0.1450\n",
      "Epoch 1258/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2693 - f1: 0.7080 - val_loss: 0.4338 - val_f1: 0.1466\n",
      "Epoch 1259/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2710 - f1: 0.7081 - val_loss: 0.4380 - val_f1: 0.1455\n",
      "Epoch 1260/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2702 - f1: 0.7090 - val_loss: 0.4354 - val_f1: 0.1456\n",
      "Epoch 1261/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2708 - f1: 0.7042 - val_loss: 0.4366 - val_f1: 0.1458\n",
      "Epoch 1262/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2684 - f1: 0.7105 - val_loss: 0.4415 - val_f1: 0.1473\n",
      "Epoch 1263/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2718 - f1: 0.7045 - val_loss: 0.4350 - val_f1: 0.1466\n",
      "Epoch 1264/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2710 - f1: 0.7087 - val_loss: 0.4355 - val_f1: 0.1461\n",
      "Epoch 1265/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2694 - f1: 0.7078 - val_loss: 0.4318 - val_f1: 0.1452\n",
      "Epoch 1266/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2715 - f1: 0.7040 - val_loss: 0.4331 - val_f1: 0.1454\n",
      "Epoch 1267/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2685 - f1: 0.7111 - val_loss: 0.4423 - val_f1: 0.1458\n",
      "Epoch 1268/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2679 - f1: 0.7144 - val_loss: 0.4353 - val_f1: 0.1460\n",
      "Epoch 1269/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2699 - f1: 0.7088 - val_loss: 0.4351 - val_f1: 0.1457\n",
      "Epoch 1270/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2706 - f1: 0.7051 - val_loss: 0.4320 - val_f1: 0.1462\n",
      "Epoch 1271/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2710 - f1: 0.7091 - val_loss: 0.4312 - val_f1: 0.1449\n",
      "Epoch 1272/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2720 - f1: 0.7022 - val_loss: 0.4308 - val_f1: 0.1449\n",
      "Epoch 1273/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2689 - f1: 0.7124 - val_loss: 0.4341 - val_f1: 0.1461\n",
      "Epoch 1274/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2695 - f1: 0.7070 - val_loss: 0.4352 - val_f1: 0.1460\n",
      "Epoch 1275/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2711 - f1: 0.7063 - val_loss: 0.4312 - val_f1: 0.1455\n",
      "Epoch 1276/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2704 - f1: 0.7061 - val_loss: 0.4303 - val_f1: 0.1457\n",
      "Epoch 1277/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2707 - f1: 0.7097 - val_loss: 0.4335 - val_f1: 0.1459\n",
      "Epoch 1278/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2720 - f1: 0.7038 - val_loss: 0.4299 - val_f1: 0.1452\n",
      "Epoch 1279/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2710 - f1: 0.7056 - val_loss: 0.4334 - val_f1: 0.1452\n",
      "Epoch 1280/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2709 - f1: 0.7065 - val_loss: 0.4272 - val_f1: 0.1445\n",
      "Epoch 1281/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2707 - f1: 0.7085 - val_loss: 0.4348 - val_f1: 0.1466\n",
      "Epoch 1282/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2705 - f1: 0.7054 - val_loss: 0.4331 - val_f1: 0.1460\n",
      "Epoch 1283/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2737 - f1: 0.7007 - val_loss: 0.4277 - val_f1: 0.1455\n",
      "Epoch 1284/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2707 - f1: 0.7077 - val_loss: 0.4329 - val_f1: 0.1453\n",
      "Epoch 1285/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2683 - f1: 0.7133 - val_loss: 0.4330 - val_f1: 0.1460\n",
      "Epoch 1286/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2692 - f1: 0.7103 - val_loss: 0.4418 - val_f1: 0.1464\n",
      "Epoch 1287/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2709 - f1: 0.7088 - val_loss: 0.4323 - val_f1: 0.1453\n",
      "Epoch 1288/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2715 - f1: 0.7046 - val_loss: 0.4347 - val_f1: 0.1461\n",
      "Epoch 1289/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2693 - f1: 0.7067 - val_loss: 0.4316 - val_f1: 0.1453\n",
      "Epoch 1290/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2692 - f1: 0.7060 - val_loss: 0.4306 - val_f1: 0.1459\n",
      "Epoch 1291/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2686 - f1: 0.7125 - val_loss: 0.4290 - val_f1: 0.1452\n",
      "Epoch 1292/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2716 - f1: 0.7061 - val_loss: 0.4353 - val_f1: 0.1465\n",
      "Epoch 1293/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2699 - f1: 0.7042 - val_loss: 0.4369 - val_f1: 0.1463\n",
      "Epoch 1294/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2705 - f1: 0.7073 - val_loss: 0.4296 - val_f1: 0.1449\n",
      "Epoch 1295/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2696 - f1: 0.7041 - val_loss: 0.4381 - val_f1: 0.1467\n",
      "Epoch 1296/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2699 - f1: 0.7113 - val_loss: 0.4315 - val_f1: 0.1458\n",
      "Epoch 1297/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2720 - f1: 0.7057 - val_loss: 0.4394 - val_f1: 0.1465\n",
      "Epoch 1298/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2698 - f1: 0.7084 - val_loss: 0.4349 - val_f1: 0.1449\n",
      "Epoch 1299/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2688 - f1: 0.7076 - val_loss: 0.4375 - val_f1: 0.1455\n",
      "Epoch 1300/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2694 - f1: 0.7086 - val_loss: 0.4347 - val_f1: 0.1450\n",
      "Epoch 1301/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2696 - f1: 0.7100 - val_loss: 0.4363 - val_f1: 0.1453\n",
      "Epoch 1302/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2701 - f1: 0.7072 - val_loss: 0.4317 - val_f1: 0.1452\n",
      "Epoch 1303/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2716 - f1: 0.7066 - val_loss: 0.4351 - val_f1: 0.1459\n",
      "Epoch 1304/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2718 - f1: 0.7068 - val_loss: 0.4376 - val_f1: 0.1449\n",
      "Epoch 1305/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2719 - f1: 0.7023 - val_loss: 0.4358 - val_f1: 0.1452\n",
      "Epoch 1306/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2690 - f1: 0.7071 - val_loss: 0.4356 - val_f1: 0.1463\n",
      "Epoch 1307/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2704 - f1: 0.7082 - val_loss: 0.4298 - val_f1: 0.1446\n",
      "Epoch 1308/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2701 - f1: 0.7075 - val_loss: 0.4301 - val_f1: 0.1452\n",
      "Epoch 1309/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2673 - f1: 0.7151 - val_loss: 0.4365 - val_f1: 0.1459\n",
      "Epoch 1310/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2714 - f1: 0.7029 - val_loss: 0.4345 - val_f1: 0.1444\n",
      "Epoch 1311/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2697 - f1: 0.7090 - val_loss: 0.4280 - val_f1: 0.1446\n",
      "Epoch 1312/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2686 - f1: 0.7086 - val_loss: 0.4310 - val_f1: 0.1455\n",
      "Epoch 1313/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2691 - f1: 0.7082 - val_loss: 0.4392 - val_f1: 0.1464\n",
      "Epoch 1314/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2714 - f1: 0.7070 - val_loss: 0.4393 - val_f1: 0.1464\n",
      "Epoch 1315/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2719 - f1: 0.7086 - val_loss: 0.4340 - val_f1: 0.1445\n",
      "Epoch 1316/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2686 - f1: 0.7116 - val_loss: 0.4384 - val_f1: 0.1449\n",
      "Epoch 1317/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2699 - f1: 0.7067 - val_loss: 0.4349 - val_f1: 0.1448\n",
      "Epoch 1318/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2688 - f1: 0.7095 - val_loss: 0.4356 - val_f1: 0.1458\n",
      "Epoch 1319/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2696 - f1: 0.7082 - val_loss: 0.4373 - val_f1: 0.1458\n",
      "Epoch 1320/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2701 - f1: 0.7086 - val_loss: 0.4349 - val_f1: 0.1457\n",
      "Epoch 1321/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2695 - f1: 0.7095 - val_loss: 0.4307 - val_f1: 0.1460\n",
      "Epoch 1322/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2690 - f1: 0.7028 - val_loss: 0.4381 - val_f1: 0.1459\n",
      "Epoch 1323/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2720 - f1: 0.7039 - val_loss: 0.4292 - val_f1: 0.1454\n",
      "Epoch 1324/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2720 - f1: 0.7049 - val_loss: 0.4327 - val_f1: 0.1449\n",
      "Epoch 1325/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2711 - f1: 0.7065 - val_loss: 0.4355 - val_f1: 0.1461\n",
      "Epoch 1326/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2697 - f1: 0.7104 - val_loss: 0.4343 - val_f1: 0.1459\n",
      "Epoch 1327/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2704 - f1: 0.7090 - val_loss: 0.4388 - val_f1: 0.1458\n",
      "Epoch 1328/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2699 - f1: 0.7120 - val_loss: 0.4318 - val_f1: 0.1450\n",
      "Epoch 1329/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2691 - f1: 0.7110 - val_loss: 0.4308 - val_f1: 0.1456\n",
      "Epoch 1330/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2677 - f1: 0.7109 - val_loss: 0.4344 - val_f1: 0.1468\n",
      "Epoch 1331/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2695 - f1: 0.7064 - val_loss: 0.4357 - val_f1: 0.1463\n",
      "Epoch 1332/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2711 - f1: 0.7100 - val_loss: 0.4366 - val_f1: 0.1452\n",
      "Epoch 1333/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2695 - f1: 0.7054 - val_loss: 0.4307 - val_f1: 0.1448\n",
      "Epoch 1334/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2680 - f1: 0.7120 - val_loss: 0.4388 - val_f1: 0.1462\n",
      "Epoch 1335/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2689 - f1: 0.7057 - val_loss: 0.4351 - val_f1: 0.1458\n",
      "Epoch 1336/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2696 - f1: 0.7074 - val_loss: 0.4319 - val_f1: 0.1452\n",
      "Epoch 1337/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2680 - f1: 0.7118 - val_loss: 0.4324 - val_f1: 0.1456\n",
      "Epoch 1338/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2710 - f1: 0.7105 - val_loss: 0.4390 - val_f1: 0.1446\n",
      "Epoch 1339/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2711 - f1: 0.7084 - val_loss: 0.4379 - val_f1: 0.1458\n",
      "Epoch 1340/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2691 - f1: 0.7090 - val_loss: 0.4379 - val_f1: 0.1469\n",
      "Epoch 1341/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2705 - f1: 0.7057 - val_loss: 0.4353 - val_f1: 0.1450\n",
      "Epoch 1342/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2711 - f1: 0.7074 - val_loss: 0.4341 - val_f1: 0.1454\n",
      "Epoch 1343/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2707 - f1: 0.7080 - val_loss: 0.4367 - val_f1: 0.1451\n",
      "Epoch 1344/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2695 - f1: 0.7086 - val_loss: 0.4322 - val_f1: 0.1448\n",
      "Epoch 1345/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2716 - f1: 0.7048 - val_loss: 0.4439 - val_f1: 0.1463\n",
      "Epoch 1346/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2674 - f1: 0.7076 - val_loss: 0.4362 - val_f1: 0.1460\n",
      "Epoch 1347/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2700 - f1: 0.7041 - val_loss: 0.4410 - val_f1: 0.1458\n",
      "Epoch 1348/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2692 - f1: 0.7115 - val_loss: 0.4318 - val_f1: 0.1448\n",
      "Epoch 1349/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2715 - f1: 0.7063 - val_loss: 0.4425 - val_f1: 0.1459\n",
      "Epoch 1350/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2683 - f1: 0.7165 - val_loss: 0.4367 - val_f1: 0.1452\n",
      "Epoch 1351/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2698 - f1: 0.7070 - val_loss: 0.4342 - val_f1: 0.1451\n",
      "Epoch 1352/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2674 - f1: 0.7148 - val_loss: 0.4295 - val_f1: 0.1451\n",
      "Epoch 1353/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2696 - f1: 0.7116 - val_loss: 0.4324 - val_f1: 0.1451\n",
      "Epoch 1354/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2690 - f1: 0.7135 - val_loss: 0.4386 - val_f1: 0.1454\n",
      "Epoch 1355/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2704 - f1: 0.7071 - val_loss: 0.4382 - val_f1: 0.1457\n",
      "Epoch 1356/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2679 - f1: 0.7132 - val_loss: 0.4316 - val_f1: 0.1452\n",
      "Epoch 1357/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2707 - f1: 0.7087 - val_loss: 0.4363 - val_f1: 0.1455\n",
      "Epoch 1358/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2707 - f1: 0.7114 - val_loss: 0.4357 - val_f1: 0.1447\n",
      "Epoch 1359/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2701 - f1: 0.7030 - val_loss: 0.4306 - val_f1: 0.1450\n",
      "Epoch 1360/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2673 - f1: 0.7136 - val_loss: 0.4359 - val_f1: 0.1455\n",
      "Epoch 1361/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2680 - f1: 0.7134 - val_loss: 0.4294 - val_f1: 0.1455\n",
      "Epoch 1362/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2707 - f1: 0.7014 - val_loss: 0.4325 - val_f1: 0.1448\n",
      "Epoch 1363/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2683 - f1: 0.7107 - val_loss: 0.4367 - val_f1: 0.1454\n",
      "Epoch 1364/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2693 - f1: 0.7124 - val_loss: 0.4356 - val_f1: 0.1457\n",
      "Epoch 1365/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2676 - f1: 0.7110 - val_loss: 0.4328 - val_f1: 0.1449\n",
      "Epoch 1366/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2672 - f1: 0.7103 - val_loss: 0.4429 - val_f1: 0.1457\n",
      "Epoch 1367/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2704 - f1: 0.7100 - val_loss: 0.4338 - val_f1: 0.1448\n",
      "Epoch 1368/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2690 - f1: 0.7082 - val_loss: 0.4376 - val_f1: 0.1456\n",
      "Epoch 1369/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2700 - f1: 0.7116 - val_loss: 0.4334 - val_f1: 0.1447\n",
      "Epoch 1370/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2694 - f1: 0.7080 - val_loss: 0.4316 - val_f1: 0.1445\n",
      "Epoch 1371/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2704 - f1: 0.7043 - val_loss: 0.4343 - val_f1: 0.1457\n",
      "Epoch 1372/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2682 - f1: 0.7138 - val_loss: 0.4361 - val_f1: 0.1460\n",
      "Epoch 1373/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2672 - f1: 0.7135 - val_loss: 0.4419 - val_f1: 0.1471\n",
      "Epoch 1374/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2727 - f1: 0.7049 - val_loss: 0.4351 - val_f1: 0.1455\n",
      "Epoch 1375/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2699 - f1: 0.7052 - val_loss: 0.4317 - val_f1: 0.1454\n",
      "Epoch 1376/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2685 - f1: 0.7090 - val_loss: 0.4339 - val_f1: 0.1456\n",
      "Epoch 1377/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2703 - f1: 0.7077 - val_loss: 0.4328 - val_f1: 0.1453\n",
      "Epoch 1378/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2689 - f1: 0.7077 - val_loss: 0.4434 - val_f1: 0.1456\n",
      "Epoch 1379/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2695 - f1: 0.7093 - val_loss: 0.4352 - val_f1: 0.1454\n",
      "Epoch 1380/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2686 - f1: 0.7079 - val_loss: 0.4318 - val_f1: 0.1447\n",
      "Epoch 1381/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2679 - f1: 0.7124 - val_loss: 0.4351 - val_f1: 0.1457\n",
      "Epoch 1382/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2695 - f1: 0.7101 - val_loss: 0.4345 - val_f1: 0.1456\n",
      "Epoch 1383/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2704 - f1: 0.7061 - val_loss: 0.4314 - val_f1: 0.1454\n",
      "Epoch 1384/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2688 - f1: 0.7085 - val_loss: 0.4347 - val_f1: 0.1466\n",
      "Epoch 1385/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2695 - f1: 0.7111 - val_loss: 0.4422 - val_f1: 0.1467\n",
      "Epoch 1386/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2689 - f1: 0.7094 - val_loss: 0.4348 - val_f1: 0.1461\n",
      "Epoch 1387/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2683 - f1: 0.7076 - val_loss: 0.4351 - val_f1: 0.1461\n",
      "Epoch 1388/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2688 - f1: 0.7088 - val_loss: 0.4395 - val_f1: 0.1467\n",
      "Epoch 1389/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2674 - f1: 0.7090 - val_loss: 0.4386 - val_f1: 0.1460\n",
      "Epoch 1390/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2698 - f1: 0.7088 - val_loss: 0.4370 - val_f1: 0.1453\n",
      "Epoch 1391/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2685 - f1: 0.7143 - val_loss: 0.4340 - val_f1: 0.1453\n",
      "Epoch 1392/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2682 - f1: 0.7109 - val_loss: 0.4365 - val_f1: 0.1461\n",
      "Epoch 1393/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2692 - f1: 0.7102 - val_loss: 0.4358 - val_f1: 0.1460\n",
      "Epoch 1394/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2694 - f1: 0.7103 - val_loss: 0.4388 - val_f1: 0.1458\n",
      "Epoch 1395/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2668 - f1: 0.7152 - val_loss: 0.4347 - val_f1: 0.1455\n",
      "Epoch 1396/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2673 - f1: 0.7118 - val_loss: 0.4273 - val_f1: 0.1455\n",
      "Epoch 1397/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2666 - f1: 0.7132 - val_loss: 0.4321 - val_f1: 0.1459\n",
      "Epoch 1398/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2679 - f1: 0.7120 - val_loss: 0.4317 - val_f1: 0.1442\n",
      "Epoch 1399/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2684 - f1: 0.7122 - val_loss: 0.4292 - val_f1: 0.1448\n",
      "Epoch 1400/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2667 - f1: 0.7097 - val_loss: 0.4376 - val_f1: 0.1462\n",
      "Epoch 1401/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2672 - f1: 0.7084 - val_loss: 0.4335 - val_f1: 0.1451\n",
      "Epoch 1402/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2692 - f1: 0.7079 - val_loss: 0.4351 - val_f1: 0.1453\n",
      "Epoch 1403/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2677 - f1: 0.7085 - val_loss: 0.4413 - val_f1: 0.1468\n",
      "Epoch 1404/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2674 - f1: 0.7121 - val_loss: 0.4348 - val_f1: 0.1463\n",
      "Epoch 1405/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2677 - f1: 0.7126 - val_loss: 0.4369 - val_f1: 0.1453\n",
      "Epoch 1406/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2683 - f1: 0.7075 - val_loss: 0.4294 - val_f1: 0.1443\n",
      "Epoch 1407/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2678 - f1: 0.7139 - val_loss: 0.4365 - val_f1: 0.1468\n",
      "Epoch 1408/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2667 - f1: 0.7119 - val_loss: 0.4287 - val_f1: 0.1449\n",
      "Epoch 1409/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2683 - f1: 0.7130 - val_loss: 0.4333 - val_f1: 0.1456\n",
      "Epoch 1410/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2680 - f1: 0.7105 - val_loss: 0.4385 - val_f1: 0.1466\n",
      "Epoch 1411/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2680 - f1: 0.7093 - val_loss: 0.4392 - val_f1: 0.1457\n",
      "Epoch 1412/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2675 - f1: 0.7105 - val_loss: 0.4342 - val_f1: 0.1447\n",
      "Epoch 1413/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2672 - f1: 0.7101 - val_loss: 0.4350 - val_f1: 0.1458\n",
      "Epoch 1414/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2685 - f1: 0.7127 - val_loss: 0.4377 - val_f1: 0.1452\n",
      "Epoch 1415/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2693 - f1: 0.7071 - val_loss: 0.4355 - val_f1: 0.1459\n",
      "Epoch 1416/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2710 - f1: 0.7109 - val_loss: 0.4366 - val_f1: 0.1453\n",
      "Epoch 1417/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2681 - f1: 0.7106 - val_loss: 0.4342 - val_f1: 0.1454\n",
      "Epoch 1418/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2692 - f1: 0.7096 - val_loss: 0.4335 - val_f1: 0.1450\n",
      "Epoch 1419/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2676 - f1: 0.7113 - val_loss: 0.4383 - val_f1: 0.1450\n",
      "Epoch 1420/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2683 - f1: 0.7111 - val_loss: 0.4323 - val_f1: 0.1452\n",
      "Epoch 1421/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2659 - f1: 0.7131 - val_loss: 0.4304 - val_f1: 0.1446\n",
      "Epoch 1422/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2692 - f1: 0.7053 - val_loss: 0.4353 - val_f1: 0.1447\n",
      "Epoch 1423/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2672 - f1: 0.7074 - val_loss: 0.4429 - val_f1: 0.1461\n",
      "Epoch 1424/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2668 - f1: 0.7164 - val_loss: 0.4398 - val_f1: 0.1457\n",
      "Epoch 1425/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2671 - f1: 0.7178 - val_loss: 0.4449 - val_f1: 0.1465\n",
      "Epoch 1426/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2677 - f1: 0.7124 - val_loss: 0.4340 - val_f1: 0.1450\n",
      "Epoch 1427/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2677 - f1: 0.7105 - val_loss: 0.4378 - val_f1: 0.1464\n",
      "Epoch 1428/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2690 - f1: 0.7090 - val_loss: 0.4400 - val_f1: 0.1462\n",
      "Epoch 1429/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2664 - f1: 0.7125 - val_loss: 0.4399 - val_f1: 0.1466\n",
      "Epoch 1430/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2684 - f1: 0.7106 - val_loss: 0.4304 - val_f1: 0.1446\n",
      "Epoch 1431/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2685 - f1: 0.7064 - val_loss: 0.4319 - val_f1: 0.1449\n",
      "Epoch 1432/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2700 - f1: 0.7044 - val_loss: 0.4352 - val_f1: 0.1455\n",
      "Epoch 1433/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2676 - f1: 0.7125 - val_loss: 0.4407 - val_f1: 0.1457\n",
      "Epoch 1434/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2687 - f1: 0.7115 - val_loss: 0.4396 - val_f1: 0.1450\n",
      "Epoch 1435/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2675 - f1: 0.7130 - val_loss: 0.4421 - val_f1: 0.1453\n",
      "Epoch 1436/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2672 - f1: 0.7098 - val_loss: 0.4344 - val_f1: 0.1454\n",
      "Epoch 1437/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2704 - f1: 0.7071 - val_loss: 0.4337 - val_f1: 0.1448\n",
      "Epoch 1438/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2688 - f1: 0.7085 - val_loss: 0.4335 - val_f1: 0.1444\n",
      "Epoch 1439/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2685 - f1: 0.7076 - val_loss: 0.4343 - val_f1: 0.1453\n",
      "Epoch 1440/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2684 - f1: 0.7079 - val_loss: 0.4369 - val_f1: 0.1455\n",
      "Epoch 1441/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2672 - f1: 0.7095 - val_loss: 0.4351 - val_f1: 0.1446\n",
      "Epoch 1442/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2665 - f1: 0.7112 - val_loss: 0.4378 - val_f1: 0.1456\n",
      "Epoch 1443/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2681 - f1: 0.7070 - val_loss: 0.4321 - val_f1: 0.1447\n",
      "Epoch 1444/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2681 - f1: 0.7091 - val_loss: 0.4369 - val_f1: 0.1455\n",
      "Epoch 1445/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2691 - f1: 0.7083 - val_loss: 0.4325 - val_f1: 0.1460\n",
      "Epoch 1446/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2663 - f1: 0.7110 - val_loss: 0.4384 - val_f1: 0.1455\n",
      "Epoch 1447/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2672 - f1: 0.7127 - val_loss: 0.4412 - val_f1: 0.1464\n",
      "Epoch 1448/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2700 - f1: 0.7073 - val_loss: 0.4316 - val_f1: 0.1450\n",
      "Epoch 1449/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2704 - f1: 0.7055 - val_loss: 0.4314 - val_f1: 0.1459\n",
      "Epoch 1450/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2683 - f1: 0.7098 - val_loss: 0.4360 - val_f1: 0.1455\n",
      "Epoch 1451/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2698 - f1: 0.7102 - val_loss: 0.4328 - val_f1: 0.1458\n",
      "Epoch 1452/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2694 - f1: 0.7103 - val_loss: 0.4397 - val_f1: 0.1460\n",
      "Epoch 1453/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2682 - f1: 0.7114 - val_loss: 0.4341 - val_f1: 0.1463\n",
      "Epoch 1454/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2672 - f1: 0.7148 - val_loss: 0.4418 - val_f1: 0.1474\n",
      "Epoch 1455/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2667 - f1: 0.7129 - val_loss: 0.4399 - val_f1: 0.1464\n",
      "Epoch 1456/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2696 - f1: 0.7064 - val_loss: 0.4333 - val_f1: 0.1453\n",
      "Epoch 1457/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2662 - f1: 0.7165 - val_loss: 0.4329 - val_f1: 0.1446\n",
      "Epoch 1458/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2665 - f1: 0.7070 - val_loss: 0.4393 - val_f1: 0.1471\n",
      "Epoch 1459/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2674 - f1: 0.7169 - val_loss: 0.4395 - val_f1: 0.1458\n",
      "Epoch 1460/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2690 - f1: 0.7085 - val_loss: 0.4341 - val_f1: 0.1454\n",
      "Epoch 1461/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2685 - f1: 0.7145 - val_loss: 0.4367 - val_f1: 0.1446\n",
      "Epoch 1462/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2661 - f1: 0.7172 - val_loss: 0.4424 - val_f1: 0.1459\n",
      "Epoch 1463/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2672 - f1: 0.7116 - val_loss: 0.4413 - val_f1: 0.1462\n",
      "Epoch 1464/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2689 - f1: 0.7084 - val_loss: 0.4418 - val_f1: 0.1467\n",
      "Epoch 1465/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2682 - f1: 0.7100 - val_loss: 0.4339 - val_f1: 0.1450\n",
      "Epoch 1466/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2665 - f1: 0.7105 - val_loss: 0.4425 - val_f1: 0.1459\n",
      "Epoch 1467/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2671 - f1: 0.7111 - val_loss: 0.4309 - val_f1: 0.1447\n",
      "Epoch 1468/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2678 - f1: 0.7090 - val_loss: 0.4320 - val_f1: 0.1464\n",
      "Epoch 1469/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2662 - f1: 0.7125 - val_loss: 0.4363 - val_f1: 0.1457\n",
      "Epoch 1470/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2666 - f1: 0.7128 - val_loss: 0.4367 - val_f1: 0.1454\n",
      "Epoch 1471/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2673 - f1: 0.7107 - val_loss: 0.4319 - val_f1: 0.1451\n",
      "Epoch 1472/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2665 - f1: 0.7147 - val_loss: 0.4357 - val_f1: 0.1450\n",
      "Epoch 1473/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2680 - f1: 0.7126 - val_loss: 0.4319 - val_f1: 0.1448\n",
      "Epoch 1474/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2695 - f1: 0.7073 - val_loss: 0.4330 - val_f1: 0.1462\n",
      "Epoch 1475/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2703 - f1: 0.7101 - val_loss: 0.4389 - val_f1: 0.1457\n",
      "Epoch 1476/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2658 - f1: 0.7129 - val_loss: 0.4371 - val_f1: 0.1462\n",
      "Epoch 1477/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2688 - f1: 0.7081 - val_loss: 0.4312 - val_f1: 0.1457\n",
      "Epoch 1478/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2688 - f1: 0.7079 - val_loss: 0.4392 - val_f1: 0.1459\n",
      "Epoch 1479/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2663 - f1: 0.7154 - val_loss: 0.4343 - val_f1: 0.1459\n",
      "Epoch 1480/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2657 - f1: 0.7139 - val_loss: 0.4358 - val_f1: 0.1458\n",
      "Epoch 1481/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2683 - f1: 0.7094 - val_loss: 0.4396 - val_f1: 0.1465\n",
      "Epoch 1482/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2656 - f1: 0.7134 - val_loss: 0.4342 - val_f1: 0.1446\n",
      "Epoch 1483/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2681 - f1: 0.7081 - val_loss: 0.4367 - val_f1: 0.1463\n",
      "Epoch 1484/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2675 - f1: 0.7115 - val_loss: 0.4343 - val_f1: 0.1448\n",
      "Epoch 1485/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2666 - f1: 0.7137 - val_loss: 0.4354 - val_f1: 0.1460\n",
      "Epoch 1486/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2662 - f1: 0.7150 - val_loss: 0.4353 - val_f1: 0.1457\n",
      "Epoch 1487/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2671 - f1: 0.7117 - val_loss: 0.4326 - val_f1: 0.1452\n",
      "Epoch 1488/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2658 - f1: 0.7162 - val_loss: 0.4321 - val_f1: 0.1447\n",
      "Epoch 1489/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2654 - f1: 0.7164 - val_loss: 0.4358 - val_f1: 0.1458\n",
      "Epoch 1490/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2667 - f1: 0.7132 - val_loss: 0.4436 - val_f1: 0.1461\n",
      "Epoch 1491/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2692 - f1: 0.7070 - val_loss: 0.4361 - val_f1: 0.1457\n",
      "Epoch 1492/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2668 - f1: 0.7155 - val_loss: 0.4370 - val_f1: 0.1459\n",
      "Epoch 1493/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2651 - f1: 0.7104 - val_loss: 0.4342 - val_f1: 0.1446\n",
      "Epoch 1494/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2678 - f1: 0.7117 - val_loss: 0.4322 - val_f1: 0.1446\n",
      "Epoch 1495/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2669 - f1: 0.7109 - val_loss: 0.4379 - val_f1: 0.1452\n",
      "Epoch 1496/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2684 - f1: 0.7058 - val_loss: 0.4325 - val_f1: 0.1444\n",
      "Epoch 1497/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2672 - f1: 0.7070 - val_loss: 0.4328 - val_f1: 0.1453\n",
      "Epoch 1498/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2657 - f1: 0.7162 - val_loss: 0.4369 - val_f1: 0.1452\n",
      "Epoch 1499/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2664 - f1: 0.7109 - val_loss: 0.4392 - val_f1: 0.1463\n",
      "Epoch 1500/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2663 - f1: 0.7146 - val_loss: 0.4399 - val_f1: 0.1450\n",
      "Epoch 1501/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2656 - f1: 0.7149 - val_loss: 0.4365 - val_f1: 0.1459\n",
      "Epoch 1502/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2667 - f1: 0.7174 - val_loss: 0.4370 - val_f1: 0.1448\n",
      "Epoch 1503/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2659 - f1: 0.7172 - val_loss: 0.4367 - val_f1: 0.1447\n",
      "Epoch 1504/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2670 - f1: 0.7163 - val_loss: 0.4360 - val_f1: 0.1449\n",
      "Epoch 1505/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2689 - f1: 0.7096 - val_loss: 0.4317 - val_f1: 0.1444\n",
      "Epoch 1506/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2662 - f1: 0.7112 - val_loss: 0.4371 - val_f1: 0.1456\n",
      "Epoch 1507/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2662 - f1: 0.7144 - val_loss: 0.4319 - val_f1: 0.1452\n",
      "Epoch 1508/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2652 - f1: 0.7127 - val_loss: 0.4368 - val_f1: 0.1451\n",
      "Epoch 1509/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2673 - f1: 0.7131 - val_loss: 0.4416 - val_f1: 0.1466\n",
      "Epoch 1510/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2660 - f1: 0.7124 - val_loss: 0.4362 - val_f1: 0.1447\n",
      "Epoch 1511/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2673 - f1: 0.7081 - val_loss: 0.4341 - val_f1: 0.1454\n",
      "Epoch 1512/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2654 - f1: 0.7146 - val_loss: 0.4357 - val_f1: 0.1456\n",
      "Epoch 1513/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2675 - f1: 0.7067 - val_loss: 0.4302 - val_f1: 0.1454\n",
      "Epoch 1514/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2667 - f1: 0.7137 - val_loss: 0.4305 - val_f1: 0.1455\n",
      "Epoch 1515/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2661 - f1: 0.7134 - val_loss: 0.4413 - val_f1: 0.1461\n",
      "Epoch 1516/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2667 - f1: 0.7148 - val_loss: 0.4305 - val_f1: 0.1449\n",
      "Epoch 1517/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2669 - f1: 0.7133 - val_loss: 0.4370 - val_f1: 0.1447\n",
      "Epoch 1518/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2678 - f1: 0.7087 - val_loss: 0.4320 - val_f1: 0.1443\n",
      "Epoch 1519/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2655 - f1: 0.7145 - val_loss: 0.4438 - val_f1: 0.1456\n",
      "Epoch 1520/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2665 - f1: 0.7133 - val_loss: 0.4382 - val_f1: 0.1456\n",
      "Epoch 1521/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2656 - f1: 0.7137 - val_loss: 0.4402 - val_f1: 0.1461\n",
      "Epoch 1522/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2664 - f1: 0.7172 - val_loss: 0.4397 - val_f1: 0.1459\n",
      "Epoch 1523/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2644 - f1: 0.7143 - val_loss: 0.4355 - val_f1: 0.1446\n",
      "Epoch 1524/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2650 - f1: 0.7176 - val_loss: 0.4454 - val_f1: 0.1459\n",
      "Epoch 1525/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2667 - f1: 0.7106 - val_loss: 0.4440 - val_f1: 0.1454\n",
      "Epoch 1526/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2665 - f1: 0.7148 - val_loss: 0.4397 - val_f1: 0.1454\n",
      "Epoch 1527/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2651 - f1: 0.7172 - val_loss: 0.4382 - val_f1: 0.1446\n",
      "Epoch 1528/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2645 - f1: 0.7185 - val_loss: 0.4361 - val_f1: 0.1444\n",
      "Epoch 1529/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2660 - f1: 0.7145 - val_loss: 0.4408 - val_f1: 0.1452\n",
      "Epoch 1530/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2660 - f1: 0.7144 - val_loss: 0.4434 - val_f1: 0.1464\n",
      "Epoch 1531/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2672 - f1: 0.7140 - val_loss: 0.4400 - val_f1: 0.1447\n",
      "Epoch 1532/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2672 - f1: 0.7077 - val_loss: 0.4406 - val_f1: 0.1450\n",
      "Epoch 1533/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2646 - f1: 0.7159 - val_loss: 0.4334 - val_f1: 0.1449\n",
      "Epoch 1534/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2666 - f1: 0.7138 - val_loss: 0.4362 - val_f1: 0.1447\n",
      "Epoch 1535/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2671 - f1: 0.7139 - val_loss: 0.4396 - val_f1: 0.1443\n",
      "Epoch 1536/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2651 - f1: 0.7121 - val_loss: 0.4360 - val_f1: 0.1443\n",
      "Epoch 1537/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2683 - f1: 0.7104 - val_loss: 0.4420 - val_f1: 0.1454\n",
      "Epoch 1538/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2658 - f1: 0.7165 - val_loss: 0.4350 - val_f1: 0.1449\n",
      "Epoch 1539/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2679 - f1: 0.7112 - val_loss: 0.4393 - val_f1: 0.1439\n",
      "Epoch 1540/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2664 - f1: 0.7115 - val_loss: 0.4345 - val_f1: 0.1447\n",
      "Epoch 1541/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2648 - f1: 0.7151 - val_loss: 0.4337 - val_f1: 0.1452\n",
      "Epoch 1542/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2678 - f1: 0.7118 - val_loss: 0.4386 - val_f1: 0.1457\n",
      "Epoch 1543/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2659 - f1: 0.7098 - val_loss: 0.4409 - val_f1: 0.1450\n",
      "Epoch 1544/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2659 - f1: 0.7158 - val_loss: 0.4402 - val_f1: 0.1457\n",
      "Epoch 1545/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2656 - f1: 0.7148 - val_loss: 0.4403 - val_f1: 0.1465\n",
      "Epoch 1546/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2654 - f1: 0.7112 - val_loss: 0.4345 - val_f1: 0.1456\n",
      "Epoch 1547/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2667 - f1: 0.7123 - val_loss: 0.4415 - val_f1: 0.1450\n",
      "Epoch 1548/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2656 - f1: 0.7179 - val_loss: 0.4428 - val_f1: 0.1475\n",
      "Epoch 1549/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2680 - f1: 0.7131 - val_loss: 0.4392 - val_f1: 0.1456\n",
      "Epoch 1550/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2632 - f1: 0.7170 - val_loss: 0.4392 - val_f1: 0.1464\n",
      "Epoch 1551/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2668 - f1: 0.7095 - val_loss: 0.4372 - val_f1: 0.1453\n",
      "Epoch 1552/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2642 - f1: 0.7166 - val_loss: 0.4397 - val_f1: 0.1461\n",
      "Epoch 1553/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2651 - f1: 0.7136 - val_loss: 0.4398 - val_f1: 0.1467\n",
      "Epoch 1554/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2669 - f1: 0.7127 - val_loss: 0.4339 - val_f1: 0.1444\n",
      "Epoch 1555/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2660 - f1: 0.7192 - val_loss: 0.4390 - val_f1: 0.1451\n",
      "Epoch 1556/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2661 - f1: 0.7117 - val_loss: 0.4426 - val_f1: 0.1456\n",
      "Epoch 1557/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2636 - f1: 0.7148 - val_loss: 0.4391 - val_f1: 0.1453\n",
      "Epoch 1558/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2650 - f1: 0.7156 - val_loss: 0.4389 - val_f1: 0.1447\n",
      "Epoch 1559/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2647 - f1: 0.7135 - val_loss: 0.4432 - val_f1: 0.1458\n",
      "Epoch 1560/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2656 - f1: 0.7137 - val_loss: 0.4351 - val_f1: 0.1448\n",
      "Epoch 1561/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2661 - f1: 0.7145 - val_loss: 0.4315 - val_f1: 0.1452\n",
      "Epoch 1562/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2664 - f1: 0.7147 - val_loss: 0.4415 - val_f1: 0.1448\n",
      "Epoch 1563/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2662 - f1: 0.7137 - val_loss: 0.4384 - val_f1: 0.1443\n",
      "Epoch 1564/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2657 - f1: 0.7135 - val_loss: 0.4342 - val_f1: 0.1450\n",
      "Epoch 1565/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2658 - f1: 0.7144 - val_loss: 0.4399 - val_f1: 0.1457\n",
      "Epoch 1566/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2645 - f1: 0.7141 - val_loss: 0.4408 - val_f1: 0.1460\n",
      "Epoch 1567/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2655 - f1: 0.7137 - val_loss: 0.4358 - val_f1: 0.1460\n",
      "Epoch 1568/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2661 - f1: 0.7162 - val_loss: 0.4371 - val_f1: 0.1449\n",
      "Epoch 1569/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2649 - f1: 0.7171 - val_loss: 0.4350 - val_f1: 0.1449\n",
      "Epoch 1570/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2660 - f1: 0.7156 - val_loss: 0.4406 - val_f1: 0.1465\n",
      "Epoch 1571/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2651 - f1: 0.7193 - val_loss: 0.4366 - val_f1: 0.1453\n",
      "Epoch 1572/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2655 - f1: 0.7122 - val_loss: 0.4379 - val_f1: 0.1453\n",
      "Epoch 1573/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2653 - f1: 0.7190 - val_loss: 0.4379 - val_f1: 0.1447\n",
      "Epoch 1574/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2656 - f1: 0.7111 - val_loss: 0.4386 - val_f1: 0.1451\n",
      "Epoch 1575/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2664 - f1: 0.7100 - val_loss: 0.4357 - val_f1: 0.1445\n",
      "Epoch 1576/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2682 - f1: 0.7101 - val_loss: 0.4316 - val_f1: 0.1449\n",
      "Epoch 1577/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2652 - f1: 0.7125 - val_loss: 0.4368 - val_f1: 0.1448\n",
      "Epoch 1578/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2630 - f1: 0.7174 - val_loss: 0.4348 - val_f1: 0.1449\n",
      "Epoch 1579/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2661 - f1: 0.7170 - val_loss: 0.4412 - val_f1: 0.1464\n",
      "Epoch 1580/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2648 - f1: 0.7190 - val_loss: 0.4428 - val_f1: 0.1458\n",
      "Epoch 1581/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2632 - f1: 0.7188 - val_loss: 0.4361 - val_f1: 0.1447\n",
      "Epoch 1582/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2685 - f1: 0.7116 - val_loss: 0.4395 - val_f1: 0.1453\n",
      "Epoch 1583/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2644 - f1: 0.7135 - val_loss: 0.4370 - val_f1: 0.1463\n",
      "Epoch 1584/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2634 - f1: 0.7142 - val_loss: 0.4383 - val_f1: 0.1460\n",
      "Epoch 1585/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2667 - f1: 0.7109 - val_loss: 0.4316 - val_f1: 0.1451\n",
      "Epoch 1586/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2652 - f1: 0.7143 - val_loss: 0.4344 - val_f1: 0.1449\n",
      "Epoch 1587/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2646 - f1: 0.7160 - val_loss: 0.4434 - val_f1: 0.1467\n",
      "Epoch 1588/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2653 - f1: 0.7165 - val_loss: 0.4435 - val_f1: 0.1466\n",
      "Epoch 1589/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2654 - f1: 0.7157 - val_loss: 0.4378 - val_f1: 0.1448\n",
      "Epoch 1590/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2642 - f1: 0.7174 - val_loss: 0.4386 - val_f1: 0.1451\n",
      "Epoch 1591/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2641 - f1: 0.7158 - val_loss: 0.4389 - val_f1: 0.1461\n",
      "Epoch 1592/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2666 - f1: 0.7089 - val_loss: 0.4362 - val_f1: 0.1452\n",
      "Epoch 1593/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2663 - f1: 0.7148 - val_loss: 0.4381 - val_f1: 0.1445\n",
      "Epoch 1594/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2667 - f1: 0.7135 - val_loss: 0.4382 - val_f1: 0.1455\n",
      "Epoch 1595/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2661 - f1: 0.7127 - val_loss: 0.4350 - val_f1: 0.1443\n",
      "Epoch 1596/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2650 - f1: 0.7146 - val_loss: 0.4395 - val_f1: 0.1465\n",
      "Epoch 1597/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2634 - f1: 0.7182 - val_loss: 0.4401 - val_f1: 0.1460\n",
      "Epoch 1598/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2653 - f1: 0.7156 - val_loss: 0.4349 - val_f1: 0.1450\n",
      "Epoch 1599/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2645 - f1: 0.7150 - val_loss: 0.4454 - val_f1: 0.1459\n",
      "Epoch 1600/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2651 - f1: 0.7138 - val_loss: 0.4347 - val_f1: 0.1454\n",
      "Epoch 1601/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2667 - f1: 0.7082 - val_loss: 0.4314 - val_f1: 0.1457\n",
      "Epoch 1602/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2661 - f1: 0.7153 - val_loss: 0.4429 - val_f1: 0.1457\n",
      "Epoch 1603/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2636 - f1: 0.7166 - val_loss: 0.4417 - val_f1: 0.1461\n",
      "Epoch 1604/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2639 - f1: 0.7166 - val_loss: 0.4381 - val_f1: 0.1451\n",
      "Epoch 1605/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2660 - f1: 0.7114 - val_loss: 0.4386 - val_f1: 0.1449\n",
      "Epoch 1606/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2657 - f1: 0.7121 - val_loss: 0.4325 - val_f1: 0.1460\n",
      "Epoch 1607/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2665 - f1: 0.7146 - val_loss: 0.4399 - val_f1: 0.1457\n",
      "Epoch 1608/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2629 - f1: 0.7160 - val_loss: 0.4398 - val_f1: 0.1453\n",
      "Epoch 1609/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2664 - f1: 0.7186 - val_loss: 0.4371 - val_f1: 0.1454\n",
      "Epoch 1610/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2658 - f1: 0.7116 - val_loss: 0.4373 - val_f1: 0.1447\n",
      "Epoch 1611/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2653 - f1: 0.7165 - val_loss: 0.4373 - val_f1: 0.1454\n",
      "Epoch 1612/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2678 - f1: 0.7136 - val_loss: 0.4355 - val_f1: 0.1444\n",
      "Epoch 1613/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2679 - f1: 0.7159 - val_loss: 0.4386 - val_f1: 0.1462\n",
      "Epoch 1614/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2660 - f1: 0.7116 - val_loss: 0.4356 - val_f1: 0.1454\n",
      "Epoch 1615/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2648 - f1: 0.7116 - val_loss: 0.4435 - val_f1: 0.1462\n",
      "Epoch 1616/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2660 - f1: 0.7140 - val_loss: 0.4356 - val_f1: 0.1452\n",
      "Epoch 1617/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2662 - f1: 0.7142 - val_loss: 0.4345 - val_f1: 0.1450\n",
      "Epoch 1618/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2647 - f1: 0.7145 - val_loss: 0.4331 - val_f1: 0.1446\n",
      "Epoch 1619/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2653 - f1: 0.7092 - val_loss: 0.4394 - val_f1: 0.1460\n",
      "Epoch 1620/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2647 - f1: 0.7130 - val_loss: 0.4388 - val_f1: 0.1457\n",
      "Epoch 1621/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2659 - f1: 0.7164 - val_loss: 0.4344 - val_f1: 0.1447\n",
      "Epoch 1622/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2631 - f1: 0.7138 - val_loss: 0.4380 - val_f1: 0.1449\n",
      "Epoch 1623/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2656 - f1: 0.7105 - val_loss: 0.4380 - val_f1: 0.1459\n",
      "Epoch 1624/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2657 - f1: 0.7101 - val_loss: 0.4466 - val_f1: 0.1459\n",
      "Epoch 1625/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2660 - f1: 0.7152 - val_loss: 0.4394 - val_f1: 0.1442\n",
      "Epoch 1626/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2664 - f1: 0.7128 - val_loss: 0.4354 - val_f1: 0.1457\n",
      "Epoch 1627/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2646 - f1: 0.7116 - val_loss: 0.4391 - val_f1: 0.1457\n",
      "Epoch 1628/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2665 - f1: 0.7112 - val_loss: 0.4438 - val_f1: 0.1466\n",
      "Epoch 1629/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2644 - f1: 0.7164 - val_loss: 0.4408 - val_f1: 0.1456\n",
      "Epoch 1630/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2666 - f1: 0.7100 - val_loss: 0.4342 - val_f1: 0.1442\n",
      "Epoch 1631/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2672 - f1: 0.7126 - val_loss: 0.4330 - val_f1: 0.1441\n",
      "Epoch 1632/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2651 - f1: 0.7161 - val_loss: 0.4401 - val_f1: 0.1451\n",
      "Epoch 1633/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2646 - f1: 0.7198 - val_loss: 0.4362 - val_f1: 0.1448\n",
      "Epoch 1634/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2633 - f1: 0.7166 - val_loss: 0.4354 - val_f1: 0.1446\n",
      "Epoch 1635/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2655 - f1: 0.7149 - val_loss: 0.4331 - val_f1: 0.1449\n",
      "Epoch 1636/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2637 - f1: 0.7177 - val_loss: 0.4389 - val_f1: 0.1449\n",
      "Epoch 1637/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2646 - f1: 0.7172 - val_loss: 0.4371 - val_f1: 0.1449\n",
      "Epoch 1638/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2660 - f1: 0.7120 - val_loss: 0.4327 - val_f1: 0.1449\n",
      "Epoch 1639/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2680 - f1: 0.7087 - val_loss: 0.4307 - val_f1: 0.1446\n",
      "Epoch 1640/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2668 - f1: 0.7121 - val_loss: 0.4416 - val_f1: 0.1464\n",
      "Epoch 1641/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2658 - f1: 0.7186 - val_loss: 0.4408 - val_f1: 0.1459\n",
      "Epoch 1642/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2647 - f1: 0.7118 - val_loss: 0.4373 - val_f1: 0.1445\n",
      "Epoch 1643/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2661 - f1: 0.7155 - val_loss: 0.4362 - val_f1: 0.1458\n",
      "Epoch 1644/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2660 - f1: 0.7182 - val_loss: 0.4382 - val_f1: 0.1445\n",
      "Epoch 1645/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2642 - f1: 0.7170 - val_loss: 0.4424 - val_f1: 0.1468\n",
      "Epoch 1646/2000\n",
      "64440/64440 [==============================] - ETA: 0s - loss: 0.2659 - f1: 0.71 - 3s 51us/step - loss: 0.2658 - f1: 0.7118 - val_loss: 0.4367 - val_f1: 0.1446\n",
      "Epoch 1647/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2667 - f1: 0.7104 - val_loss: 0.4382 - val_f1: 0.1454\n",
      "Epoch 1648/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2648 - f1: 0.7157 - val_loss: 0.4420 - val_f1: 0.1450\n",
      "Epoch 1649/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2651 - f1: 0.7139 - val_loss: 0.4381 - val_f1: 0.1454\n",
      "Epoch 1650/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2654 - f1: 0.7128 - val_loss: 0.4350 - val_f1: 0.1447\n",
      "Epoch 1651/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2631 - f1: 0.7179 - val_loss: 0.4403 - val_f1: 0.1453\n",
      "Epoch 1652/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2673 - f1: 0.7133 - val_loss: 0.4363 - val_f1: 0.1449\n",
      "Epoch 1653/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2645 - f1: 0.7174 - val_loss: 0.4396 - val_f1: 0.1460\n",
      "Epoch 1654/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2632 - f1: 0.7198 - val_loss: 0.4390 - val_f1: 0.1449\n",
      "Epoch 1655/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2648 - f1: 0.7173 - val_loss: 0.4388 - val_f1: 0.1455\n",
      "Epoch 1656/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2634 - f1: 0.7146 - val_loss: 0.4431 - val_f1: 0.1446\n",
      "Epoch 1657/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2649 - f1: 0.7168 - val_loss: 0.4383 - val_f1: 0.1459\n",
      "Epoch 1658/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2646 - f1: 0.7162 - val_loss: 0.4415 - val_f1: 0.1449\n",
      "Epoch 1659/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2632 - f1: 0.7204 - val_loss: 0.4382 - val_f1: 0.1453\n",
      "Epoch 1660/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2642 - f1: 0.7197 - val_loss: 0.4382 - val_f1: 0.1456\n",
      "Epoch 1661/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2637 - f1: 0.7207 - val_loss: 0.4366 - val_f1: 0.1452\n",
      "Epoch 1662/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2645 - f1: 0.7176 - val_loss: 0.4452 - val_f1: 0.1462\n",
      "Epoch 1663/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2643 - f1: 0.7146 - val_loss: 0.4376 - val_f1: 0.1455\n",
      "Epoch 1664/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2659 - f1: 0.7175 - val_loss: 0.4386 - val_f1: 0.1443\n",
      "Epoch 1665/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2638 - f1: 0.7184 - val_loss: 0.4336 - val_f1: 0.1451\n",
      "Epoch 1666/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2628 - f1: 0.7199 - val_loss: 0.4422 - val_f1: 0.1458\n",
      "Epoch 1667/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2652 - f1: 0.7147 - val_loss: 0.4409 - val_f1: 0.1451\n",
      "Epoch 1668/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2663 - f1: 0.7123 - val_loss: 0.4399 - val_f1: 0.1454\n",
      "Epoch 1669/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2661 - f1: 0.7159 - val_loss: 0.4422 - val_f1: 0.1449\n",
      "Epoch 1670/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2634 - f1: 0.7178 - val_loss: 0.4396 - val_f1: 0.1457\n",
      "Epoch 1671/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2641 - f1: 0.7177 - val_loss: 0.4414 - val_f1: 0.1452\n",
      "Epoch 1672/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2628 - f1: 0.7174 - val_loss: 0.4380 - val_f1: 0.1458\n",
      "Epoch 1673/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2649 - f1: 0.7165 - val_loss: 0.4293 - val_f1: 0.1441\n",
      "Epoch 1674/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2655 - f1: 0.7165 - val_loss: 0.4376 - val_f1: 0.1437\n",
      "Epoch 1675/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2643 - f1: 0.7133 - val_loss: 0.4373 - val_f1: 0.1454\n",
      "Epoch 1676/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2661 - f1: 0.7134 - val_loss: 0.4399 - val_f1: 0.1441\n",
      "Epoch 1677/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2646 - f1: 0.7134 - val_loss: 0.4421 - val_f1: 0.1457\n",
      "Epoch 1678/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2662 - f1: 0.7143 - val_loss: 0.4352 - val_f1: 0.1444\n",
      "Epoch 1679/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2664 - f1: 0.7155 - val_loss: 0.4379 - val_f1: 0.1455\n",
      "Epoch 1680/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2649 - f1: 0.7141 - val_loss: 0.4351 - val_f1: 0.1440\n",
      "Epoch 1681/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2645 - f1: 0.7168 - val_loss: 0.4403 - val_f1: 0.1447\n",
      "Epoch 1682/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2657 - f1: 0.7115 - val_loss: 0.4358 - val_f1: 0.1444\n",
      "Epoch 1683/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2645 - f1: 0.7170 - val_loss: 0.4423 - val_f1: 0.1452\n",
      "Epoch 1684/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2641 - f1: 0.7166 - val_loss: 0.4412 - val_f1: 0.1450\n",
      "Epoch 1685/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2646 - f1: 0.7181 - val_loss: 0.4335 - val_f1: 0.1442\n",
      "Epoch 1686/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2620 - f1: 0.7173 - val_loss: 0.4337 - val_f1: 0.1459\n",
      "Epoch 1687/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2624 - f1: 0.7218 - val_loss: 0.4380 - val_f1: 0.1435\n",
      "Epoch 1688/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2629 - f1: 0.7172 - val_loss: 0.4396 - val_f1: 0.1456\n",
      "Epoch 1689/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2635 - f1: 0.7211 - val_loss: 0.4357 - val_f1: 0.1455\n",
      "Epoch 1690/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2654 - f1: 0.7118 - val_loss: 0.4406 - val_f1: 0.1446\n",
      "Epoch 1691/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2644 - f1: 0.7171 - val_loss: 0.4388 - val_f1: 0.1445\n",
      "Epoch 1692/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2657 - f1: 0.7140 - val_loss: 0.4374 - val_f1: 0.1453\n",
      "Epoch 1693/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2666 - f1: 0.7164 - val_loss: 0.4345 - val_f1: 0.1444\n",
      "Epoch 1694/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2668 - f1: 0.7083 - val_loss: 0.4424 - val_f1: 0.1457\n",
      "Epoch 1695/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2621 - f1: 0.7197 - val_loss: 0.4435 - val_f1: 0.1452\n",
      "Epoch 1696/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2643 - f1: 0.7096 - val_loss: 0.4372 - val_f1: 0.1448\n",
      "Epoch 1697/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2653 - f1: 0.7138 - val_loss: 0.4409 - val_f1: 0.1447\n",
      "Epoch 1698/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2636 - f1: 0.7197 - val_loss: 0.4443 - val_f1: 0.1469\n",
      "Epoch 1699/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2637 - f1: 0.7167 - val_loss: 0.4497 - val_f1: 0.1455\n",
      "Epoch 1700/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2642 - f1: 0.7115 - val_loss: 0.4417 - val_f1: 0.1465\n",
      "Epoch 1701/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2642 - f1: 0.7163 - val_loss: 0.4356 - val_f1: 0.1446\n",
      "Epoch 1702/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2631 - f1: 0.7184 - val_loss: 0.4399 - val_f1: 0.1446\n",
      "Epoch 1703/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2645 - f1: 0.7187 - val_loss: 0.4415 - val_f1: 0.1453\n",
      "Epoch 1704/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2646 - f1: 0.7142 - val_loss: 0.4369 - val_f1: 0.1457\n",
      "Epoch 1705/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2644 - f1: 0.7170 - val_loss: 0.4311 - val_f1: 0.1446\n",
      "Epoch 1706/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2655 - f1: 0.7160 - val_loss: 0.4446 - val_f1: 0.1463\n",
      "Epoch 1707/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2641 - f1: 0.7169 - val_loss: 0.4360 - val_f1: 0.1451\n",
      "Epoch 1708/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2641 - f1: 0.7184 - val_loss: 0.4427 - val_f1: 0.1446\n",
      "Epoch 1709/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2646 - f1: 0.7146 - val_loss: 0.4380 - val_f1: 0.1454\n",
      "Epoch 1710/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2633 - f1: 0.7165 - val_loss: 0.4499 - val_f1: 0.1463\n",
      "Epoch 1711/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2642 - f1: 0.7156 - val_loss: 0.4439 - val_f1: 0.1451\n",
      "Epoch 1712/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2633 - f1: 0.7170 - val_loss: 0.4387 - val_f1: 0.1457\n",
      "Epoch 1713/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2630 - f1: 0.7173 - val_loss: 0.4389 - val_f1: 0.1451\n",
      "Epoch 1714/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2640 - f1: 0.7187 - val_loss: 0.4386 - val_f1: 0.1442\n",
      "Epoch 1715/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2643 - f1: 0.7141 - val_loss: 0.4409 - val_f1: 0.1450\n",
      "Epoch 1716/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2630 - f1: 0.7186 - val_loss: 0.4374 - val_f1: 0.1445\n",
      "Epoch 1717/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2644 - f1: 0.7154 - val_loss: 0.4428 - val_f1: 0.1461\n",
      "Epoch 1718/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2658 - f1: 0.7155 - val_loss: 0.4382 - val_f1: 0.1458\n",
      "Epoch 1719/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2636 - f1: 0.7149 - val_loss: 0.4286 - val_f1: 0.1443\n",
      "Epoch 1720/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2644 - f1: 0.7163 - val_loss: 0.4413 - val_f1: 0.1458\n",
      "Epoch 1721/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2644 - f1: 0.7138 - val_loss: 0.4445 - val_f1: 0.1465\n",
      "Epoch 1722/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2633 - f1: 0.7167 - val_loss: 0.4430 - val_f1: 0.1456\n",
      "Epoch 1723/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2639 - f1: 0.7173 - val_loss: 0.4420 - val_f1: 0.1447\n",
      "Epoch 1724/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2654 - f1: 0.7101 - val_loss: 0.4468 - val_f1: 0.1459\n",
      "Epoch 1725/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2646 - f1: 0.7186 - val_loss: 0.4369 - val_f1: 0.1448\n",
      "Epoch 1726/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2645 - f1: 0.7068 - val_loss: 0.4395 - val_f1: 0.1450\n",
      "Epoch 1727/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2617 - f1: 0.7193 - val_loss: 0.4422 - val_f1: 0.1447\n",
      "Epoch 1728/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2657 - f1: 0.7146 - val_loss: 0.4422 - val_f1: 0.1448\n",
      "Epoch 1729/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2648 - f1: 0.7121 - val_loss: 0.4395 - val_f1: 0.1455\n",
      "Epoch 1730/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2619 - f1: 0.7186 - val_loss: 0.4358 - val_f1: 0.1453\n",
      "Epoch 1731/2000\n",
      "64440/64440 [==============================] - 3s 45us/step - loss: 0.2639 - f1: 0.7163 - val_loss: 0.4400 - val_f1: 0.1459\n",
      "Epoch 1732/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2637 - f1: 0.7237 - val_loss: 0.4414 - val_f1: 0.1460\n",
      "Epoch 1733/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2630 - f1: 0.7173 - val_loss: 0.4428 - val_f1: 0.1453\n",
      "Epoch 1734/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2659 - f1: 0.7123 - val_loss: 0.4435 - val_f1: 0.1454\n",
      "Epoch 1735/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2630 - f1: 0.7171 - val_loss: 0.4430 - val_f1: 0.1453\n",
      "Epoch 1736/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2632 - f1: 0.7196 - val_loss: 0.4367 - val_f1: 0.1447\n",
      "Epoch 1737/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2636 - f1: 0.7173 - val_loss: 0.4391 - val_f1: 0.1462\n",
      "Epoch 1738/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2637 - f1: 0.7159 - val_loss: 0.4371 - val_f1: 0.1455\n",
      "Epoch 1739/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2623 - f1: 0.7167 - val_loss: 0.4369 - val_f1: 0.1447\n",
      "Epoch 1740/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2629 - f1: 0.7196 - val_loss: 0.4358 - val_f1: 0.1449\n",
      "Epoch 1741/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2623 - f1: 0.7196 - val_loss: 0.4385 - val_f1: 0.1446\n",
      "Epoch 1742/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2631 - f1: 0.7187 - val_loss: 0.4354 - val_f1: 0.1452\n",
      "Epoch 1743/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2637 - f1: 0.7174 - val_loss: 0.4403 - val_f1: 0.1445\n",
      "Epoch 1744/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2625 - f1: 0.7180 - val_loss: 0.4397 - val_f1: 0.1447\n",
      "Epoch 1745/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2627 - f1: 0.7184 - val_loss: 0.4368 - val_f1: 0.1450\n",
      "Epoch 1746/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2643 - f1: 0.7167 - val_loss: 0.4374 - val_f1: 0.1445\n",
      "Epoch 1747/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2619 - f1: 0.7187 - val_loss: 0.4377 - val_f1: 0.1442\n",
      "Epoch 1748/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2635 - f1: 0.7183 - val_loss: 0.4381 - val_f1: 0.1451\n",
      "Epoch 1749/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2645 - f1: 0.7200 - val_loss: 0.4345 - val_f1: 0.1447\n",
      "Epoch 1750/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2651 - f1: 0.7187 - val_loss: 0.4416 - val_f1: 0.1456\n",
      "Epoch 1751/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2628 - f1: 0.7171 - val_loss: 0.4357 - val_f1: 0.1445\n",
      "Epoch 1752/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2630 - f1: 0.7180 - val_loss: 0.4388 - val_f1: 0.1445\n",
      "Epoch 1753/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2641 - f1: 0.7166 - val_loss: 0.4419 - val_f1: 0.1461\n",
      "Epoch 1754/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2652 - f1: 0.7144 - val_loss: 0.4341 - val_f1: 0.1448\n",
      "Epoch 1755/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2646 - f1: 0.7173 - val_loss: 0.4399 - val_f1: 0.1447\n",
      "Epoch 1756/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2634 - f1: 0.7172 - val_loss: 0.4442 - val_f1: 0.1454\n",
      "Epoch 1757/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2645 - f1: 0.7131 - val_loss: 0.4482 - val_f1: 0.1471\n",
      "Epoch 1758/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2641 - f1: 0.7158 - val_loss: 0.4397 - val_f1: 0.1458\n",
      "Epoch 1759/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2629 - f1: 0.7151 - val_loss: 0.4384 - val_f1: 0.1453\n",
      "Epoch 1760/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2643 - f1: 0.7171 - val_loss: 0.4433 - val_f1: 0.1451\n",
      "Epoch 1761/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2639 - f1: 0.7164 - val_loss: 0.4390 - val_f1: 0.1449\n",
      "Epoch 1762/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2644 - f1: 0.7177 - val_loss: 0.4430 - val_f1: 0.1448\n",
      "Epoch 1763/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2623 - f1: 0.7168 - val_loss: 0.4486 - val_f1: 0.1450\n",
      "Epoch 1764/2000\n",
      "64440/64440 [==============================] - 3s 46us/step - loss: 0.2627 - f1: 0.7188 - val_loss: 0.4438 - val_f1: 0.1457\n",
      "Epoch 1765/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2629 - f1: 0.7159 - val_loss: 0.4378 - val_f1: 0.1458\n",
      "Epoch 1766/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2643 - f1: 0.7138 - val_loss: 0.4395 - val_f1: 0.1452\n",
      "Epoch 1767/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2628 - f1: 0.7152 - val_loss: 0.4448 - val_f1: 0.1472\n",
      "Epoch 1768/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2639 - f1: 0.7169 - val_loss: 0.4303 - val_f1: 0.1441\n",
      "Epoch 1769/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2630 - f1: 0.7193 - val_loss: 0.4451 - val_f1: 0.1447\n",
      "Epoch 1770/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2622 - f1: 0.7172 - val_loss: 0.4500 - val_f1: 0.1464\n",
      "Epoch 1771/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2626 - f1: 0.7156 - val_loss: 0.4434 - val_f1: 0.1464\n",
      "Epoch 1772/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2621 - f1: 0.7212 - val_loss: 0.4391 - val_f1: 0.1453\n",
      "Epoch 1773/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2633 - f1: 0.7147 - val_loss: 0.4426 - val_f1: 0.1457\n",
      "Epoch 1774/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2637 - f1: 0.7170 - val_loss: 0.4347 - val_f1: 0.1448\n",
      "Epoch 1775/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2630 - f1: 0.7182 - val_loss: 0.4374 - val_f1: 0.1441\n",
      "Epoch 1776/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2627 - f1: 0.7199 - val_loss: 0.4410 - val_f1: 0.1452\n",
      "Epoch 1777/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2624 - f1: 0.7190 - val_loss: 0.4373 - val_f1: 0.1465\n",
      "Epoch 1778/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2644 - f1: 0.7142 - val_loss: 0.4351 - val_f1: 0.1445\n",
      "Epoch 1779/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2637 - f1: 0.7186 - val_loss: 0.4368 - val_f1: 0.1439\n",
      "Epoch 1780/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2613 - f1: 0.7199 - val_loss: 0.4426 - val_f1: 0.1454\n",
      "Epoch 1781/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2627 - f1: 0.7213 - val_loss: 0.4357 - val_f1: 0.1442\n",
      "Epoch 1782/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2635 - f1: 0.7120 - val_loss: 0.4380 - val_f1: 0.1461\n",
      "Epoch 1783/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2634 - f1: 0.7185 - val_loss: 0.4420 - val_f1: 0.1460\n",
      "Epoch 1784/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2610 - f1: 0.7222 - val_loss: 0.4386 - val_f1: 0.1455\n",
      "Epoch 1785/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2633 - f1: 0.7151 - val_loss: 0.4403 - val_f1: 0.1447\n",
      "Epoch 1786/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2633 - f1: 0.7139 - val_loss: 0.4332 - val_f1: 0.1442\n",
      "Epoch 1787/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2620 - f1: 0.7180 - val_loss: 0.4411 - val_f1: 0.1454\n",
      "Epoch 1788/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2616 - f1: 0.7214 - val_loss: 0.4415 - val_f1: 0.1459\n",
      "Epoch 1789/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2638 - f1: 0.7177 - val_loss: 0.4401 - val_f1: 0.1454\n",
      "Epoch 1790/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2611 - f1: 0.7213 - val_loss: 0.4398 - val_f1: 0.1468\n",
      "Epoch 1791/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2616 - f1: 0.7179 - val_loss: 0.4444 - val_f1: 0.1453\n",
      "Epoch 1792/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2650 - f1: 0.7119 - val_loss: 0.4351 - val_f1: 0.1451\n",
      "Epoch 1793/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2620 - f1: 0.7199 - val_loss: 0.4323 - val_f1: 0.1451\n",
      "Epoch 1794/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2608 - f1: 0.7228 - val_loss: 0.4382 - val_f1: 0.1458\n",
      "Epoch 1795/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2633 - f1: 0.7183 - val_loss: 0.4297 - val_f1: 0.1444\n",
      "Epoch 1796/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2633 - f1: 0.7194 - val_loss: 0.4455 - val_f1: 0.1460\n",
      "Epoch 1797/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2618 - f1: 0.7197 - val_loss: 0.4388 - val_f1: 0.1446\n",
      "Epoch 1798/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2638 - f1: 0.7175 - val_loss: 0.4405 - val_f1: 0.1456\n",
      "Epoch 1799/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2632 - f1: 0.7193 - val_loss: 0.4404 - val_f1: 0.1459\n",
      "Epoch 1800/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2650 - f1: 0.7127 - val_loss: 0.4367 - val_f1: 0.1456\n",
      "Epoch 1801/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2646 - f1: 0.7178 - val_loss: 0.4347 - val_f1: 0.1442\n",
      "Epoch 1802/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2632 - f1: 0.7158 - val_loss: 0.4380 - val_f1: 0.1451\n",
      "Epoch 1803/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2614 - f1: 0.7188 - val_loss: 0.4380 - val_f1: 0.1451\n",
      "Epoch 1804/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2643 - f1: 0.7151 - val_loss: 0.4418 - val_f1: 0.1443\n",
      "Epoch 1805/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2604 - f1: 0.7216 - val_loss: 0.4434 - val_f1: 0.1457\n",
      "Epoch 1806/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2615 - f1: 0.7188 - val_loss: 0.4367 - val_f1: 0.1454\n",
      "Epoch 1807/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2619 - f1: 0.7235 - val_loss: 0.4334 - val_f1: 0.1435\n",
      "Epoch 1808/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2626 - f1: 0.7181 - val_loss: 0.4360 - val_f1: 0.1450\n",
      "Epoch 1809/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2635 - f1: 0.7171 - val_loss: 0.4383 - val_f1: 0.1451\n",
      "Epoch 1810/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2628 - f1: 0.7173 - val_loss: 0.4359 - val_f1: 0.1442\n",
      "Epoch 1811/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2631 - f1: 0.7189 - val_loss: 0.4388 - val_f1: 0.1453\n",
      "Epoch 1812/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2616 - f1: 0.7173 - val_loss: 0.4390 - val_f1: 0.1455\n",
      "Epoch 1813/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2627 - f1: 0.7169 - val_loss: 0.4331 - val_f1: 0.1443\n",
      "Epoch 1814/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2632 - f1: 0.7172 - val_loss: 0.4377 - val_f1: 0.1453\n",
      "Epoch 1815/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2641 - f1: 0.7150 - val_loss: 0.4405 - val_f1: 0.1448\n",
      "Epoch 1816/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2635 - f1: 0.7186 - val_loss: 0.4385 - val_f1: 0.1452\n",
      "Epoch 1817/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2616 - f1: 0.7248 - val_loss: 0.4395 - val_f1: 0.1454\n",
      "Epoch 1818/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2633 - f1: 0.7200 - val_loss: 0.4285 - val_f1: 0.1439\n",
      "Epoch 1819/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2618 - f1: 0.7193 - val_loss: 0.4391 - val_f1: 0.1449\n",
      "Epoch 1820/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2628 - f1: 0.7221 - val_loss: 0.4440 - val_f1: 0.1457\n",
      "Epoch 1821/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2627 - f1: 0.7213 - val_loss: 0.4456 - val_f1: 0.1454\n",
      "Epoch 1822/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2618 - f1: 0.7186 - val_loss: 0.4433 - val_f1: 0.1457\n",
      "Epoch 1823/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2635 - f1: 0.7174 - val_loss: 0.4426 - val_f1: 0.1460\n",
      "Epoch 1824/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2652 - f1: 0.7137 - val_loss: 0.4388 - val_f1: 0.1451\n",
      "Epoch 1825/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2621 - f1: 0.7172 - val_loss: 0.4376 - val_f1: 0.1449\n",
      "Epoch 1826/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2627 - f1: 0.7144 - val_loss: 0.4394 - val_f1: 0.1446\n",
      "Epoch 1827/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2610 - f1: 0.7228 - val_loss: 0.4406 - val_f1: 0.1445\n",
      "Epoch 1828/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2641 - f1: 0.7159 - val_loss: 0.4367 - val_f1: 0.1446\n",
      "Epoch 1829/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2637 - f1: 0.7190 - val_loss: 0.4379 - val_f1: 0.1444\n",
      "Epoch 1830/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2606 - f1: 0.7211 - val_loss: 0.4446 - val_f1: 0.1455\n",
      "Epoch 1831/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2619 - f1: 0.7202 - val_loss: 0.4399 - val_f1: 0.1443\n",
      "Epoch 1832/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2611 - f1: 0.7249 - val_loss: 0.4361 - val_f1: 0.1444\n",
      "Epoch 1833/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2619 - f1: 0.7211 - val_loss: 0.4423 - val_f1: 0.1449\n",
      "Epoch 1834/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2617 - f1: 0.7202 - val_loss: 0.4404 - val_f1: 0.1451\n",
      "Epoch 1835/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2624 - f1: 0.7166 - val_loss: 0.4364 - val_f1: 0.1441\n",
      "Epoch 1836/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2608 - f1: 0.7194 - val_loss: 0.4447 - val_f1: 0.1446\n",
      "Epoch 1837/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2612 - f1: 0.7207 - val_loss: 0.4415 - val_f1: 0.1455\n",
      "Epoch 1838/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2620 - f1: 0.7222 - val_loss: 0.4388 - val_f1: 0.1452\n",
      "Epoch 1839/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2633 - f1: 0.7160 - val_loss: 0.4390 - val_f1: 0.1444\n",
      "Epoch 1840/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2641 - f1: 0.7149 - val_loss: 0.4351 - val_f1: 0.1467\n",
      "Epoch 1841/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2619 - f1: 0.7186 - val_loss: 0.4423 - val_f1: 0.1454\n",
      "Epoch 1842/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2641 - f1: 0.7168 - val_loss: 0.4459 - val_f1: 0.1451\n",
      "Epoch 1843/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2616 - f1: 0.7193 - val_loss: 0.4424 - val_f1: 0.1447\n",
      "Epoch 1844/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2664 - f1: 0.7137 - val_loss: 0.4355 - val_f1: 0.1450\n",
      "Epoch 1845/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2626 - f1: 0.7192 - val_loss: 0.4412 - val_f1: 0.1452\n",
      "Epoch 1846/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2635 - f1: 0.7152 - val_loss: 0.4394 - val_f1: 0.1458\n",
      "Epoch 1847/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2622 - f1: 0.7230 - val_loss: 0.4360 - val_f1: 0.1438\n",
      "Epoch 1848/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2627 - f1: 0.7196 - val_loss: 0.4351 - val_f1: 0.1453\n",
      "Epoch 1849/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2628 - f1: 0.7165 - val_loss: 0.4454 - val_f1: 0.1459\n",
      "Epoch 1850/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2644 - f1: 0.7164 - val_loss: 0.4335 - val_f1: 0.1449\n",
      "Epoch 1851/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2620 - f1: 0.7170 - val_loss: 0.4350 - val_f1: 0.1445\n",
      "Epoch 1852/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2621 - f1: 0.7180 - val_loss: 0.4415 - val_f1: 0.1458\n",
      "Epoch 1853/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2608 - f1: 0.7212 - val_loss: 0.4452 - val_f1: 0.1457\n",
      "Epoch 1854/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2619 - f1: 0.7241 - val_loss: 0.4421 - val_f1: 0.1443\n",
      "Epoch 1855/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2609 - f1: 0.7241 - val_loss: 0.4483 - val_f1: 0.1459\n",
      "Epoch 1856/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2621 - f1: 0.7172 - val_loss: 0.4427 - val_f1: 0.1457\n",
      "Epoch 1857/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2621 - f1: 0.7202 - val_loss: 0.4412 - val_f1: 0.1450\n",
      "Epoch 1858/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2616 - f1: 0.7165 - val_loss: 0.4453 - val_f1: 0.1459\n",
      "Epoch 1859/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2604 - f1: 0.7192 - val_loss: 0.4385 - val_f1: 0.1458\n",
      "Epoch 1860/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2605 - f1: 0.7243 - val_loss: 0.4411 - val_f1: 0.1465\n",
      "Epoch 1861/2000\n",
      "64440/64440 [==============================] - 3s 47us/step - loss: 0.2629 - f1: 0.7188 - val_loss: 0.4417 - val_f1: 0.1454\n",
      "Epoch 1862/2000\n",
      "64440/64440 [==============================] - 3s 44us/step - loss: 0.2629 - f1: 0.7194 - val_loss: 0.4401 - val_f1: 0.1456\n",
      "Epoch 1863/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2628 - f1: 0.7193 - val_loss: 0.4394 - val_f1: 0.1458\n",
      "Epoch 1864/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2638 - f1: 0.7135 - val_loss: 0.4380 - val_f1: 0.1443\n",
      "Epoch 1865/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2610 - f1: 0.7196 - val_loss: 0.4438 - val_f1: 0.1471\n",
      "Epoch 1866/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2634 - f1: 0.7192 - val_loss: 0.4331 - val_f1: 0.1452\n",
      "Epoch 1867/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2617 - f1: 0.7183 - val_loss: 0.4481 - val_f1: 0.1458\n",
      "Epoch 1868/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2604 - f1: 0.7201 - val_loss: 0.4451 - val_f1: 0.1454\n",
      "Epoch 1869/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2619 - f1: 0.7172 - val_loss: 0.4350 - val_f1: 0.1446\n",
      "Epoch 1870/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2631 - f1: 0.7148 - val_loss: 0.4385 - val_f1: 0.1459\n",
      "Epoch 1871/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2628 - f1: 0.7204 - val_loss: 0.4413 - val_f1: 0.1455\n",
      "Epoch 1872/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2622 - f1: 0.7161 - val_loss: 0.4379 - val_f1: 0.1456\n",
      "Epoch 1873/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2623 - f1: 0.7183 - val_loss: 0.4370 - val_f1: 0.1450\n",
      "Epoch 1874/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2643 - f1: 0.7146 - val_loss: 0.4390 - val_f1: 0.1455\n",
      "Epoch 1875/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2627 - f1: 0.7180 - val_loss: 0.4372 - val_f1: 0.1452\n",
      "Epoch 1876/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2611 - f1: 0.7227 - val_loss: 0.4397 - val_f1: 0.1455\n",
      "Epoch 1877/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2616 - f1: 0.7209 - val_loss: 0.4373 - val_f1: 0.1453\n",
      "Epoch 1878/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2615 - f1: 0.7217 - val_loss: 0.4380 - val_f1: 0.1452\n",
      "Epoch 1879/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2618 - f1: 0.7201 - val_loss: 0.4361 - val_f1: 0.1443\n",
      "Epoch 1880/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2612 - f1: 0.7213 - val_loss: 0.4466 - val_f1: 0.1454\n",
      "Epoch 1881/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2616 - f1: 0.7238 - val_loss: 0.4359 - val_f1: 0.1442\n",
      "Epoch 1882/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2626 - f1: 0.7194 - val_loss: 0.4387 - val_f1: 0.1448\n",
      "Epoch 1883/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2607 - f1: 0.7221 - val_loss: 0.4459 - val_f1: 0.1450\n",
      "Epoch 1884/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2625 - f1: 0.7192 - val_loss: 0.4423 - val_f1: 0.1451\n",
      "Epoch 1885/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2627 - f1: 0.7180 - val_loss: 0.4360 - val_f1: 0.1438\n",
      "Epoch 1886/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2606 - f1: 0.7197 - val_loss: 0.4401 - val_f1: 0.1444\n",
      "Epoch 1887/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2611 - f1: 0.7208 - val_loss: 0.4418 - val_f1: 0.1451\n",
      "Epoch 1888/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2623 - f1: 0.7170 - val_loss: 0.4434 - val_f1: 0.1454\n",
      "Epoch 1889/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2618 - f1: 0.7204 - val_loss: 0.4352 - val_f1: 0.1440\n",
      "Epoch 1890/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2586 - f1: 0.7246 - val_loss: 0.4299 - val_f1: 0.1441\n",
      "Epoch 1891/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2641 - f1: 0.7146 - val_loss: 0.4420 - val_f1: 0.1452\n",
      "Epoch 1892/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2616 - f1: 0.7211 - val_loss: 0.4402 - val_f1: 0.1454\n",
      "Epoch 1893/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2609 - f1: 0.7196 - val_loss: 0.4403 - val_f1: 0.1452\n",
      "Epoch 1894/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2635 - f1: 0.7185 - val_loss: 0.4406 - val_f1: 0.1458\n",
      "Epoch 1895/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2626 - f1: 0.7149 - val_loss: 0.4399 - val_f1: 0.1447\n",
      "Epoch 1896/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2623 - f1: 0.7165 - val_loss: 0.4443 - val_f1: 0.1467\n",
      "Epoch 1897/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2628 - f1: 0.7183 - val_loss: 0.4407 - val_f1: 0.1458\n",
      "Epoch 1898/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2609 - f1: 0.7261 - val_loss: 0.4422 - val_f1: 0.1458\n",
      "Epoch 1899/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2631 - f1: 0.7175 - val_loss: 0.4362 - val_f1: 0.1446\n",
      "Epoch 1900/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2622 - f1: 0.7173 - val_loss: 0.4437 - val_f1: 0.1457\n",
      "Epoch 1901/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2614 - f1: 0.7204 - val_loss: 0.4440 - val_f1: 0.1456\n",
      "Epoch 1902/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2610 - f1: 0.7199 - val_loss: 0.4389 - val_f1: 0.1452\n",
      "Epoch 1903/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2611 - f1: 0.7202 - val_loss: 0.4358 - val_f1: 0.1447\n",
      "Epoch 1904/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2621 - f1: 0.7196 - val_loss: 0.4396 - val_f1: 0.1453\n",
      "Epoch 1905/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2624 - f1: 0.7195 - val_loss: 0.4343 - val_f1: 0.1451\n",
      "Epoch 1906/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2614 - f1: 0.7201 - val_loss: 0.4459 - val_f1: 0.1450\n",
      "Epoch 1907/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2625 - f1: 0.7214 - val_loss: 0.4352 - val_f1: 0.1444\n",
      "Epoch 1908/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2620 - f1: 0.7203 - val_loss: 0.4399 - val_f1: 0.1450\n",
      "Epoch 1909/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2632 - f1: 0.7185 - val_loss: 0.4427 - val_f1: 0.1448\n",
      "Epoch 1910/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2617 - f1: 0.7201 - val_loss: 0.4424 - val_f1: 0.1454\n",
      "Epoch 1911/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2624 - f1: 0.7143 - val_loss: 0.4372 - val_f1: 0.1449\n",
      "Epoch 1912/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2613 - f1: 0.7195 - val_loss: 0.4360 - val_f1: 0.1450\n",
      "Epoch 1913/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2630 - f1: 0.7192 - val_loss: 0.4372 - val_f1: 0.1446\n",
      "Epoch 1914/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2612 - f1: 0.7202 - val_loss: 0.4390 - val_f1: 0.1443\n",
      "Epoch 1915/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2631 - f1: 0.7141 - val_loss: 0.4451 - val_f1: 0.1453\n",
      "Epoch 1916/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2609 - f1: 0.7161 - val_loss: 0.4332 - val_f1: 0.1443\n",
      "Epoch 1917/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2616 - f1: 0.7213 - val_loss: 0.4397 - val_f1: 0.1462\n",
      "Epoch 1918/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2615 - f1: 0.7201 - val_loss: 0.4307 - val_f1: 0.1449\n",
      "Epoch 1919/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2638 - f1: 0.7188 - val_loss: 0.4364 - val_f1: 0.1450\n",
      "Epoch 1920/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2617 - f1: 0.7209 - val_loss: 0.4408 - val_f1: 0.1451\n",
      "Epoch 1921/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2614 - f1: 0.7224 - val_loss: 0.4372 - val_f1: 0.1447\n",
      "Epoch 1922/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2593 - f1: 0.7288 - val_loss: 0.4463 - val_f1: 0.1456\n",
      "Epoch 1923/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2591 - f1: 0.7239 - val_loss: 0.4449 - val_f1: 0.1460\n",
      "Epoch 1924/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2606 - f1: 0.7249 - val_loss: 0.4405 - val_f1: 0.1448\n",
      "Epoch 1925/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2627 - f1: 0.7137 - val_loss: 0.4413 - val_f1: 0.1453\n",
      "Epoch 1926/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2630 - f1: 0.7164 - val_loss: 0.4380 - val_f1: 0.1455\n",
      "Epoch 1927/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2616 - f1: 0.7181 - val_loss: 0.4399 - val_f1: 0.1455\n",
      "Epoch 1928/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2621 - f1: 0.7178 - val_loss: 0.4365 - val_f1: 0.1446\n",
      "Epoch 1929/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2603 - f1: 0.7222 - val_loss: 0.4390 - val_f1: 0.1442\n",
      "Epoch 1930/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2627 - f1: 0.7200 - val_loss: 0.4472 - val_f1: 0.1454\n",
      "Epoch 1931/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2609 - f1: 0.7216 - val_loss: 0.4408 - val_f1: 0.1454\n",
      "Epoch 1932/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2617 - f1: 0.7205 - val_loss: 0.4386 - val_f1: 0.1446\n",
      "Epoch 1933/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2635 - f1: 0.7171 - val_loss: 0.4363 - val_f1: 0.1441\n",
      "Epoch 1934/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2596 - f1: 0.7206 - val_loss: 0.4394 - val_f1: 0.1457\n",
      "Epoch 1935/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2601 - f1: 0.7245 - val_loss: 0.4306 - val_f1: 0.1444\n",
      "Epoch 1936/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2613 - f1: 0.7169 - val_loss: 0.4362 - val_f1: 0.1449\n",
      "Epoch 1937/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2618 - f1: 0.7189 - val_loss: 0.4360 - val_f1: 0.1459\n",
      "Epoch 1938/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2587 - f1: 0.7256 - val_loss: 0.4383 - val_f1: 0.1454\n",
      "Epoch 1939/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2592 - f1: 0.7263 - val_loss: 0.4399 - val_f1: 0.1456\n",
      "Epoch 1940/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2629 - f1: 0.7187 - val_loss: 0.4339 - val_f1: 0.1443\n",
      "Epoch 1941/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2604 - f1: 0.7209 - val_loss: 0.4441 - val_f1: 0.1451\n",
      "Epoch 1942/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2616 - f1: 0.7229 - val_loss: 0.4405 - val_f1: 0.1439\n",
      "Epoch 1943/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2599 - f1: 0.7230 - val_loss: 0.4403 - val_f1: 0.1443\n",
      "Epoch 1944/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2611 - f1: 0.7185 - val_loss: 0.4391 - val_f1: 0.1439\n",
      "Epoch 1945/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2597 - f1: 0.7235 - val_loss: 0.4406 - val_f1: 0.1441\n",
      "Epoch 1946/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2637 - f1: 0.7146 - val_loss: 0.4392 - val_f1: 0.1448\n",
      "Epoch 1947/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2639 - f1: 0.7146 - val_loss: 0.4426 - val_f1: 0.1456\n",
      "Epoch 1948/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2630 - f1: 0.7204 - val_loss: 0.4425 - val_f1: 0.1455\n",
      "Epoch 1949/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2629 - f1: 0.7142 - val_loss: 0.4428 - val_f1: 0.1460\n",
      "Epoch 1950/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2625 - f1: 0.7203 - val_loss: 0.4355 - val_f1: 0.1448\n",
      "Epoch 1951/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2615 - f1: 0.7207 - val_loss: 0.4463 - val_f1: 0.1467\n",
      "Epoch 1952/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2629 - f1: 0.7196 - val_loss: 0.4372 - val_f1: 0.1449\n",
      "Epoch 1953/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2609 - f1: 0.7211 - val_loss: 0.4375 - val_f1: 0.1447\n",
      "Epoch 1954/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2612 - f1: 0.7203 - val_loss: 0.4445 - val_f1: 0.1459\n",
      "Epoch 1955/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2602 - f1: 0.7223 - val_loss: 0.4388 - val_f1: 0.1456\n",
      "Epoch 1956/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2616 - f1: 0.7230 - val_loss: 0.4465 - val_f1: 0.1452\n",
      "Epoch 1957/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2625 - f1: 0.7173 - val_loss: 0.4397 - val_f1: 0.1454\n",
      "Epoch 1958/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2616 - f1: 0.7213 - val_loss: 0.4508 - val_f1: 0.1463\n",
      "Epoch 1959/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2608 - f1: 0.7199 - val_loss: 0.4496 - val_f1: 0.1464\n",
      "Epoch 1960/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2585 - f1: 0.7288 - val_loss: 0.4472 - val_f1: 0.1452\n",
      "Epoch 1961/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2608 - f1: 0.7232 - val_loss: 0.4436 - val_f1: 0.1451\n",
      "Epoch 1962/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2625 - f1: 0.7209 - val_loss: 0.4401 - val_f1: 0.1444\n",
      "Epoch 1963/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2618 - f1: 0.7190 - val_loss: 0.4428 - val_f1: 0.1455\n",
      "Epoch 1964/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2591 - f1: 0.7223 - val_loss: 0.4385 - val_f1: 0.1452\n",
      "Epoch 1965/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2626 - f1: 0.7184 - val_loss: 0.4410 - val_f1: 0.1451\n",
      "Epoch 1966/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2611 - f1: 0.7238 - val_loss: 0.4484 - val_f1: 0.1447\n",
      "Epoch 1967/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2612 - f1: 0.7248 - val_loss: 0.4433 - val_f1: 0.1451\n",
      "Epoch 1968/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2619 - f1: 0.7202 - val_loss: 0.4444 - val_f1: 0.1456\n",
      "Epoch 1969/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2600 - f1: 0.7199 - val_loss: 0.4441 - val_f1: 0.1454\n",
      "Epoch 1970/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2592 - f1: 0.7237 - val_loss: 0.4435 - val_f1: 0.1456\n",
      "Epoch 1971/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2621 - f1: 0.7161 - val_loss: 0.4376 - val_f1: 0.1448\n",
      "Epoch 1972/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2607 - f1: 0.7199 - val_loss: 0.4389 - val_f1: 0.1449\n",
      "Epoch 1973/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2626 - f1: 0.7205 - val_loss: 0.4409 - val_f1: 0.1448\n",
      "Epoch 1974/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2596 - f1: 0.7212 - val_loss: 0.4322 - val_f1: 0.1454\n",
      "Epoch 1975/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2605 - f1: 0.7212 - val_loss: 0.4433 - val_f1: 0.1448\n",
      "Epoch 1976/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2594 - f1: 0.7285 - val_loss: 0.4376 - val_f1: 0.1442\n",
      "Epoch 1977/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2610 - f1: 0.7195 - val_loss: 0.4457 - val_f1: 0.1452\n",
      "Epoch 1978/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2603 - f1: 0.7245 - val_loss: 0.4454 - val_f1: 0.1454\n",
      "Epoch 1979/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2616 - f1: 0.7208 - val_loss: 0.4351 - val_f1: 0.1443\n",
      "Epoch 1980/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.2628 - f1: 0.7179 - val_loss: 0.4391 - val_f1: 0.1449\n",
      "Epoch 1981/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2609 - f1: 0.7205 - val_loss: 0.4443 - val_f1: 0.1441\n",
      "Epoch 1982/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2628 - f1: 0.7167 - val_loss: 0.4365 - val_f1: 0.1446\n",
      "Epoch 1983/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2619 - f1: 0.7189 - val_loss: 0.4416 - val_f1: 0.1449\n",
      "Epoch 1984/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2602 - f1: 0.7197 - val_loss: 0.4424 - val_f1: 0.1453\n",
      "Epoch 1985/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2630 - f1: 0.7196 - val_loss: 0.4449 - val_f1: 0.1452\n",
      "Epoch 1986/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2600 - f1: 0.7201 - val_loss: 0.4389 - val_f1: 0.1443\n",
      "Epoch 1987/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2585 - f1: 0.7226 - val_loss: 0.4417 - val_f1: 0.1471\n",
      "Epoch 1988/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2580 - f1: 0.7264 - val_loss: 0.4438 - val_f1: 0.1458\n",
      "Epoch 1989/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2622 - f1: 0.7196 - val_loss: 0.4399 - val_f1: 0.1458\n",
      "Epoch 1990/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2609 - f1: 0.7198 - val_loss: 0.4452 - val_f1: 0.1449\n",
      "Epoch 1991/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2590 - f1: 0.7272 - val_loss: 0.4346 - val_f1: 0.1454\n",
      "Epoch 1992/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2592 - f1: 0.7250 - val_loss: 0.4436 - val_f1: 0.1463\n",
      "Epoch 1993/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2622 - f1: 0.7172 - val_loss: 0.4395 - val_f1: 0.1451\n",
      "Epoch 1994/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2615 - f1: 0.7158 - val_loss: 0.4491 - val_f1: 0.1453\n",
      "Epoch 1995/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2627 - f1: 0.7156 - val_loss: 0.4352 - val_f1: 0.1451\n",
      "Epoch 1996/2000\n",
      "64440/64440 [==============================] - 3s 49us/step - loss: 0.2622 - f1: 0.7156 - val_loss: 0.4403 - val_f1: 0.1466\n",
      "Epoch 1997/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2596 - f1: 0.7222 - val_loss: 0.4479 - val_f1: 0.1454\n",
      "Epoch 1998/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2609 - f1: 0.7200 - val_loss: 0.4421 - val_f1: 0.1452\n",
      "Epoch 1999/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.2582 - f1: 0.7266 - val_loss: 0.4432 - val_f1: 0.1465\n",
      "Epoch 2000/2000\n",
      "64440/64440 [==============================] - 3s 48us/step - loss: 0.2608 - f1: 0.7218 - val_loss: 0.4406 - val_f1: 0.1452\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna4.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna4.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[9988  806]\n",
      " [1492 1523]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[9885  910]\n",
      " [1504 1511]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[49171  1201]\n",
      " [ 3364 10704]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna4.predict(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list5 = [100,100,100,1]\n",
    "activation_list5 = ['tanh','tanh','tanh','sigmoid']\n",
    "dropout_list5 = [0.3,0.3,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,401\n",
      "Trainable params: 40,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna5 = new_rna()\n",
    "rna5.build_model(data_shape,n_list5,activation_list5,dropout_list5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64440 samples, validate on 13810 samples\n",
      "Epoch 1/2000\n",
      "64440/64440 [==============================] - 4s 66us/step - loss: 0.4125 - f1: 0.4699 - val_loss: 0.3681 - val_f1: 0.1462\n",
      "Epoch 2/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3784 - f1: 0.5332 - val_loss: 0.3693 - val_f1: 0.1448\n",
      "Epoch 3/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3739 - f1: 0.5394 - val_loss: 0.3699 - val_f1: 0.1492\n",
      "Epoch 4/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3714 - f1: 0.5468 - val_loss: 0.3689 - val_f1: 0.1448\n",
      "Epoch 5/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3698 - f1: 0.5454 - val_loss: 0.3694 - val_f1: 0.1486\n",
      "Epoch 6/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3689 - f1: 0.5533 - val_loss: 0.3688 - val_f1: 0.1481\n",
      "Epoch 7/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3679 - f1: 0.5512 - val_loss: 0.3684 - val_f1: 0.1475\n",
      "Epoch 8/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3666 - f1: 0.5550 - val_loss: 0.3687 - val_f1: 0.1468\n",
      "Epoch 9/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3662 - f1: 0.5544 - val_loss: 0.3685 - val_f1: 0.1470\n",
      "Epoch 10/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3654 - f1: 0.5605 - val_loss: 0.3694 - val_f1: 0.1482\n",
      "Epoch 11/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3652 - f1: 0.5596 - val_loss: 0.3703 - val_f1: 0.1473\n",
      "Epoch 12/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3642 - f1: 0.5576 - val_loss: 0.3681 - val_f1: 0.1449\n",
      "Epoch 13/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3639 - f1: 0.5600 - val_loss: 0.3694 - val_f1: 0.1470\n",
      "Epoch 14/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3642 - f1: 0.5580 - val_loss: 0.3693 - val_f1: 0.1478\n",
      "Epoch 15/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3636 - f1: 0.5559 - val_loss: 0.3702 - val_f1: 0.1486\n",
      "Epoch 16/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3632 - f1: 0.5608 - val_loss: 0.3694 - val_f1: 0.1464\n",
      "Epoch 17/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3635 - f1: 0.5576 - val_loss: 0.3702 - val_f1: 0.1474\n",
      "Epoch 18/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3623 - f1: 0.5612 - val_loss: 0.3702 - val_f1: 0.1479\n",
      "Epoch 19/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3624 - f1: 0.5584 - val_loss: 0.3718 - val_f1: 0.1503\n",
      "Epoch 20/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3620 - f1: 0.5619 - val_loss: 0.3695 - val_f1: 0.1473\n",
      "Epoch 21/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3611 - f1: 0.5629 - val_loss: 0.3697 - val_f1: 0.1492\n",
      "Epoch 22/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3608 - f1: 0.5595 - val_loss: 0.3699 - val_f1: 0.1484\n",
      "Epoch 23/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3610 - f1: 0.5630 - val_loss: 0.3703 - val_f1: 0.1490\n",
      "Epoch 24/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3615 - f1: 0.5615 - val_loss: 0.3699 - val_f1: 0.1475\n",
      "Epoch 25/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3603 - f1: 0.5655 - val_loss: 0.3690 - val_f1: 0.1464\n",
      "Epoch 26/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3610 - f1: 0.5648 - val_loss: 0.3699 - val_f1: 0.1463\n",
      "Epoch 27/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3610 - f1: 0.5601 - val_loss: 0.3700 - val_f1: 0.1478\n",
      "Epoch 28/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3607 - f1: 0.5631 - val_loss: 0.3708 - val_f1: 0.1470\n",
      "Epoch 29/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3607 - f1: 0.5604 - val_loss: 0.3681 - val_f1: 0.1449\n",
      "Epoch 30/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3598 - f1: 0.5634 - val_loss: 0.3722 - val_f1: 0.1492\n",
      "Epoch 31/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3591 - f1: 0.5617 - val_loss: 0.3716 - val_f1: 0.1462\n",
      "Epoch 32/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3595 - f1: 0.5627 - val_loss: 0.3713 - val_f1: 0.1472\n",
      "Epoch 33/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3583 - f1: 0.5686 - val_loss: 0.3695 - val_f1: 0.1463\n",
      "Epoch 34/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3588 - f1: 0.5640 - val_loss: 0.3700 - val_f1: 0.1466\n",
      "Epoch 35/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3590 - f1: 0.5643 - val_loss: 0.3706 - val_f1: 0.1472\n",
      "Epoch 36/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3577 - f1: 0.5657 - val_loss: 0.3707 - val_f1: 0.1462\n",
      "Epoch 37/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3573 - f1: 0.5649 - val_loss: 0.3710 - val_f1: 0.1463\n",
      "Epoch 38/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3577 - f1: 0.5657 - val_loss: 0.3717 - val_f1: 0.1477\n",
      "Epoch 39/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3570 - f1: 0.5664 - val_loss: 0.3705 - val_f1: 0.1456\n",
      "Epoch 40/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3568 - f1: 0.5641 - val_loss: 0.3714 - val_f1: 0.1470\n",
      "Epoch 41/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3573 - f1: 0.5662 - val_loss: 0.3704 - val_f1: 0.1467\n",
      "Epoch 42/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3560 - f1: 0.5669 - val_loss: 0.3715 - val_f1: 0.1485\n",
      "Epoch 43/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3568 - f1: 0.5642 - val_loss: 0.3705 - val_f1: 0.1478\n",
      "Epoch 44/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3572 - f1: 0.5635 - val_loss: 0.3710 - val_f1: 0.1459\n",
      "Epoch 45/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3563 - f1: 0.5704 - val_loss: 0.3719 - val_f1: 0.1470\n",
      "Epoch 46/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3560 - f1: 0.5618 - val_loss: 0.3706 - val_f1: 0.1471\n",
      "Epoch 47/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3549 - f1: 0.5665 - val_loss: 0.3728 - val_f1: 0.1468\n",
      "Epoch 48/2000\n",
      "64440/64440 [==============================] - 3s 50us/step - loss: 0.3558 - f1: 0.5642 - val_loss: 0.3714 - val_f1: 0.1479\n",
      "Epoch 49/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.3557 - f1: 0.5647 - val_loss: 0.3708 - val_f1: 0.1457\n",
      "Epoch 50/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3555 - f1: 0.5659 - val_loss: 0.3726 - val_f1: 0.1470\n",
      "Epoch 51/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3545 - f1: 0.5663 - val_loss: 0.3725 - val_f1: 0.1471\n",
      "Epoch 52/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3550 - f1: 0.5668 - val_loss: 0.3716 - val_f1: 0.1466\n",
      "Epoch 53/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3551 - f1: 0.5655 - val_loss: 0.3699 - val_f1: 0.1464\n",
      "Epoch 54/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3549 - f1: 0.5666 - val_loss: 0.3709 - val_f1: 0.1467\n",
      "Epoch 55/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3529 - f1: 0.5687 - val_loss: 0.3714 - val_f1: 0.1456\n",
      "Epoch 56/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3544 - f1: 0.5698 - val_loss: 0.3731 - val_f1: 0.1460\n",
      "Epoch 57/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3530 - f1: 0.5703 - val_loss: 0.3718 - val_f1: 0.1448\n",
      "Epoch 58/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3539 - f1: 0.5659 - val_loss: 0.3736 - val_f1: 0.1465\n",
      "Epoch 59/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3538 - f1: 0.5669 - val_loss: 0.3717 - val_f1: 0.1457\n",
      "Epoch 60/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3525 - f1: 0.5672 - val_loss: 0.3723 - val_f1: 0.1455\n",
      "Epoch 61/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3524 - f1: 0.5701 - val_loss: 0.3724 - val_f1: 0.1449\n",
      "Epoch 62/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3517 - f1: 0.5709 - val_loss: 0.3736 - val_f1: 0.1464\n",
      "Epoch 63/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3525 - f1: 0.5683 - val_loss: 0.3732 - val_f1: 0.1468\n",
      "Epoch 64/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3526 - f1: 0.5709 - val_loss: 0.3733 - val_f1: 0.1464\n",
      "Epoch 65/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3518 - f1: 0.5654 - val_loss: 0.3732 - val_f1: 0.1470\n",
      "Epoch 66/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3521 - f1: 0.5680 - val_loss: 0.3725 - val_f1: 0.1470\n",
      "Epoch 67/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3513 - f1: 0.5676 - val_loss: 0.3705 - val_f1: 0.1453\n",
      "Epoch 68/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3512 - f1: 0.5712 - val_loss: 0.3756 - val_f1: 0.1475\n",
      "Epoch 69/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3510 - f1: 0.5710 - val_loss: 0.3724 - val_f1: 0.1457\n",
      "Epoch 70/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3502 - f1: 0.5733 - val_loss: 0.3743 - val_f1: 0.1466\n",
      "Epoch 71/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3502 - f1: 0.5715 - val_loss: 0.3732 - val_f1: 0.1467\n",
      "Epoch 72/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3504 - f1: 0.5683 - val_loss: 0.3750 - val_f1: 0.1466\n",
      "Epoch 73/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3503 - f1: 0.5717 - val_loss: 0.3737 - val_f1: 0.1455\n",
      "Epoch 74/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3497 - f1: 0.5714 - val_loss: 0.3767 - val_f1: 0.1472\n",
      "Epoch 75/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3497 - f1: 0.5716 - val_loss: 0.3731 - val_f1: 0.1466\n",
      "Epoch 76/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3493 - f1: 0.5740 - val_loss: 0.3721 - val_f1: 0.1455\n",
      "Epoch 77/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3494 - f1: 0.5688 - val_loss: 0.3762 - val_f1: 0.1457\n",
      "Epoch 78/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3488 - f1: 0.5662 - val_loss: 0.3765 - val_f1: 0.1472\n",
      "Epoch 79/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3489 - f1: 0.5742 - val_loss: 0.3754 - val_f1: 0.1475\n",
      "Epoch 80/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3471 - f1: 0.5735 - val_loss: 0.3758 - val_f1: 0.1458\n",
      "Epoch 81/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3492 - f1: 0.5718 - val_loss: 0.3720 - val_f1: 0.1455\n",
      "Epoch 82/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.3481 - f1: 0.5722 - val_loss: 0.3763 - val_f1: 0.1467\n",
      "Epoch 83/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3471 - f1: 0.5786 - val_loss: 0.3749 - val_f1: 0.1465\n",
      "Epoch 84/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3484 - f1: 0.5675 - val_loss: 0.3756 - val_f1: 0.1472\n",
      "Epoch 85/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3460 - f1: 0.5814 - val_loss: 0.3744 - val_f1: 0.1453\n",
      "Epoch 86/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3473 - f1: 0.5748 - val_loss: 0.3744 - val_f1: 0.1460\n",
      "Epoch 87/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3469 - f1: 0.5762 - val_loss: 0.3743 - val_f1: 0.1447\n",
      "Epoch 88/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3468 - f1: 0.5718 - val_loss: 0.3750 - val_f1: 0.1462\n",
      "Epoch 89/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3461 - f1: 0.5788 - val_loss: 0.3757 - val_f1: 0.1458\n",
      "Epoch 90/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3471 - f1: 0.5732 - val_loss: 0.3753 - val_f1: 0.1450\n",
      "Epoch 91/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3441 - f1: 0.5809 - val_loss: 0.3751 - val_f1: 0.1462\n",
      "Epoch 92/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3450 - f1: 0.5800 - val_loss: 0.3738 - val_f1: 0.1446\n",
      "Epoch 93/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3450 - f1: 0.5777 - val_loss: 0.3757 - val_f1: 0.1459\n",
      "Epoch 94/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3450 - f1: 0.5823 - val_loss: 0.3738 - val_f1: 0.1449\n",
      "Epoch 95/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3453 - f1: 0.5781 - val_loss: 0.3742 - val_f1: 0.1451\n",
      "Epoch 96/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3447 - f1: 0.5827 - val_loss: 0.3752 - val_f1: 0.1456\n",
      "Epoch 97/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3432 - f1: 0.5812 - val_loss: 0.3781 - val_f1: 0.1456\n",
      "Epoch 98/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3437 - f1: 0.5825 - val_loss: 0.3778 - val_f1: 0.1465\n",
      "Epoch 99/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.3446 - f1: 0.5783 - val_loss: 0.3758 - val_f1: 0.1446\n",
      "Epoch 100/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3424 - f1: 0.5836 - val_loss: 0.3773 - val_f1: 0.1457\n",
      "Epoch 101/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3437 - f1: 0.5778 - val_loss: 0.3760 - val_f1: 0.1446\n",
      "Epoch 102/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3426 - f1: 0.5822 - val_loss: 0.3750 - val_f1: 0.1455\n",
      "Epoch 103/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3426 - f1: 0.5808 - val_loss: 0.3739 - val_f1: 0.1461\n",
      "Epoch 104/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3417 - f1: 0.5861 - val_loss: 0.3793 - val_f1: 0.1466\n",
      "Epoch 105/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3420 - f1: 0.5829 - val_loss: 0.3761 - val_f1: 0.1457\n",
      "Epoch 106/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3419 - f1: 0.5795 - val_loss: 0.3743 - val_f1: 0.1451\n",
      "Epoch 107/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3422 - f1: 0.5807 - val_loss: 0.3752 - val_f1: 0.1450\n",
      "Epoch 108/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3413 - f1: 0.5829 - val_loss: 0.3788 - val_f1: 0.1451\n",
      "Epoch 109/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3413 - f1: 0.5777 - val_loss: 0.3780 - val_f1: 0.1454\n",
      "Epoch 110/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3405 - f1: 0.5834 - val_loss: 0.3788 - val_f1: 0.1462\n",
      "Epoch 111/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3397 - f1: 0.5871 - val_loss: 0.3761 - val_f1: 0.1445\n",
      "Epoch 112/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3389 - f1: 0.5880 - val_loss: 0.3774 - val_f1: 0.1447\n",
      "Epoch 113/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3400 - f1: 0.5893 - val_loss: 0.3764 - val_f1: 0.1445\n",
      "Epoch 114/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3397 - f1: 0.5882 - val_loss: 0.3785 - val_f1: 0.1450\n",
      "Epoch 115/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3400 - f1: 0.5847 - val_loss: 0.3782 - val_f1: 0.1455\n",
      "Epoch 116/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.3386 - f1: 0.5872 - val_loss: 0.3785 - val_f1: 0.1464\n",
      "Epoch 117/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3392 - f1: 0.5886 - val_loss: 0.3742 - val_f1: 0.1467\n",
      "Epoch 118/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3390 - f1: 0.5869 - val_loss: 0.3777 - val_f1: 0.1452\n",
      "Epoch 119/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3376 - f1: 0.5927 - val_loss: 0.3766 - val_f1: 0.1452\n",
      "Epoch 120/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3371 - f1: 0.5928 - val_loss: 0.3809 - val_f1: 0.1458\n",
      "Epoch 121/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3376 - f1: 0.5861 - val_loss: 0.3774 - val_f1: 0.1455\n",
      "Epoch 122/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3369 - f1: 0.5919 - val_loss: 0.3798 - val_f1: 0.1458\n",
      "Epoch 123/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3384 - f1: 0.5906 - val_loss: 0.3772 - val_f1: 0.1448\n",
      "Epoch 124/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3366 - f1: 0.5882 - val_loss: 0.3773 - val_f1: 0.1457\n",
      "Epoch 125/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3366 - f1: 0.5908 - val_loss: 0.3803 - val_f1: 0.1464\n",
      "Epoch 126/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3363 - f1: 0.5914 - val_loss: 0.3811 - val_f1: 0.1448\n",
      "Epoch 127/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3360 - f1: 0.5960 - val_loss: 0.3778 - val_f1: 0.1437\n",
      "Epoch 128/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3368 - f1: 0.5936 - val_loss: 0.3803 - val_f1: 0.1454\n",
      "Epoch 129/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3354 - f1: 0.5924 - val_loss: 0.3809 - val_f1: 0.1449\n",
      "Epoch 130/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3364 - f1: 0.5977 - val_loss: 0.3785 - val_f1: 0.1444\n",
      "Epoch 131/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3341 - f1: 0.6007 - val_loss: 0.3808 - val_f1: 0.1456\n",
      "Epoch 132/2000\n",
      "64440/64440 [==============================] - 3s 51us/step - loss: 0.3344 - f1: 0.5948 - val_loss: 0.3801 - val_f1: 0.1452\n",
      "Epoch 133/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.3333 - f1: 0.5985 - val_loss: 0.3792 - val_f1: 0.1450\n",
      "Epoch 134/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3334 - f1: 0.5964 - val_loss: 0.3805 - val_f1: 0.1461\n",
      "Epoch 135/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3339 - f1: 0.5982 - val_loss: 0.3794 - val_f1: 0.1445\n",
      "Epoch 136/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3329 - f1: 0.5982 - val_loss: 0.3853 - val_f1: 0.1459\n",
      "Epoch 137/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3325 - f1: 0.5978 - val_loss: 0.3797 - val_f1: 0.1466\n",
      "Epoch 138/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3333 - f1: 0.6012 - val_loss: 0.3840 - val_f1: 0.1443\n",
      "Epoch 139/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3318 - f1: 0.5985 - val_loss: 0.3815 - val_f1: 0.1455\n",
      "Epoch 140/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3320 - f1: 0.5983 - val_loss: 0.3830 - val_f1: 0.1442\n",
      "Epoch 141/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3311 - f1: 0.6008 - val_loss: 0.3833 - val_f1: 0.1467\n",
      "Epoch 142/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3317 - f1: 0.6009 - val_loss: 0.3801 - val_f1: 0.1453\n",
      "Epoch 143/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3298 - f1: 0.6053 - val_loss: 0.3827 - val_f1: 0.1446\n",
      "Epoch 144/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3312 - f1: 0.5991 - val_loss: 0.3819 - val_f1: 0.1442\n",
      "Epoch 145/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3307 - f1: 0.6054 - val_loss: 0.3829 - val_f1: 0.1448\n",
      "Epoch 146/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3302 - f1: 0.5998 - val_loss: 0.3848 - val_f1: 0.1455\n",
      "Epoch 147/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3288 - f1: 0.6046 - val_loss: 0.3830 - val_f1: 0.1445\n",
      "Epoch 148/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3285 - f1: 0.6010 - val_loss: 0.3837 - val_f1: 0.1442\n",
      "Epoch 149/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3284 - f1: 0.5982 - val_loss: 0.3825 - val_f1: 0.1459\n",
      "Epoch 150/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3261 - f1: 0.6060 - val_loss: 0.3795 - val_f1: 0.1455\n",
      "Epoch 151/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3283 - f1: 0.6052 - val_loss: 0.3824 - val_f1: 0.1457\n",
      "Epoch 152/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3260 - f1: 0.6151 - val_loss: 0.3884 - val_f1: 0.1452\n",
      "Epoch 153/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3283 - f1: 0.6055 - val_loss: 0.3847 - val_f1: 0.1447\n",
      "Epoch 154/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3263 - f1: 0.6120 - val_loss: 0.3835 - val_f1: 0.1446\n",
      "Epoch 155/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3276 - f1: 0.6059 - val_loss: 0.3830 - val_f1: 0.1455\n",
      "Epoch 156/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3257 - f1: 0.6094 - val_loss: 0.3817 - val_f1: 0.1462\n",
      "Epoch 157/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3248 - f1: 0.6115 - val_loss: 0.3820 - val_f1: 0.1459\n",
      "Epoch 158/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3260 - f1: 0.6111 - val_loss: 0.3808 - val_f1: 0.1441\n",
      "Epoch 159/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3263 - f1: 0.6080 - val_loss: 0.3819 - val_f1: 0.1449\n",
      "Epoch 160/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3256 - f1: 0.6150 - val_loss: 0.3831 - val_f1: 0.1454\n",
      "Epoch 161/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3235 - f1: 0.6119 - val_loss: 0.3860 - val_f1: 0.1453\n",
      "Epoch 162/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3235 - f1: 0.6161 - val_loss: 0.3868 - val_f1: 0.1452\n",
      "Epoch 163/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3237 - f1: 0.6138 - val_loss: 0.3877 - val_f1: 0.1455\n",
      "Epoch 164/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.3234 - f1: 0.6176 - val_loss: 0.3868 - val_f1: 0.1460\n",
      "Epoch 165/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3232 - f1: 0.6137 - val_loss: 0.3836 - val_f1: 0.1464\n",
      "Epoch 166/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3230 - f1: 0.6181 - val_loss: 0.3891 - val_f1: 0.1442\n",
      "Epoch 167/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3238 - f1: 0.6129 - val_loss: 0.3828 - val_f1: 0.1449\n",
      "Epoch 168/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3229 - f1: 0.6164 - val_loss: 0.3920 - val_f1: 0.1456\n",
      "Epoch 169/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3217 - f1: 0.6175 - val_loss: 0.3877 - val_f1: 0.1455\n",
      "Epoch 170/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3210 - f1: 0.6250 - val_loss: 0.3864 - val_f1: 0.1453\n",
      "Epoch 171/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3194 - f1: 0.6212 - val_loss: 0.3884 - val_f1: 0.1451\n",
      "Epoch 172/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3214 - f1: 0.6208 - val_loss: 0.3859 - val_f1: 0.1462\n",
      "Epoch 173/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3206 - f1: 0.6208 - val_loss: 0.3870 - val_f1: 0.1457\n",
      "Epoch 174/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3209 - f1: 0.6201 - val_loss: 0.3874 - val_f1: 0.1450\n",
      "Epoch 175/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3206 - f1: 0.6202 - val_loss: 0.3875 - val_f1: 0.1435\n",
      "Epoch 176/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3203 - f1: 0.6202 - val_loss: 0.3847 - val_f1: 0.1447\n",
      "Epoch 177/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3175 - f1: 0.6220 - val_loss: 0.3886 - val_f1: 0.1469\n",
      "Epoch 178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3182 - f1: 0.6233 - val_loss: 0.3885 - val_f1: 0.1445\n",
      "Epoch 179/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3189 - f1: 0.6240 - val_loss: 0.3866 - val_f1: 0.1449\n",
      "Epoch 180/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3191 - f1: 0.6236 - val_loss: 0.3856 - val_f1: 0.1448\n",
      "Epoch 181/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.3173 - f1: 0.6287 - val_loss: 0.3854 - val_f1: 0.1461\n",
      "Epoch 182/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3179 - f1: 0.6252 - val_loss: 0.3850 - val_f1: 0.1457\n",
      "Epoch 183/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3169 - f1: 0.6286 - val_loss: 0.3898 - val_f1: 0.1450\n",
      "Epoch 184/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3177 - f1: 0.6232 - val_loss: 0.3872 - val_f1: 0.1446\n",
      "Epoch 185/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3164 - f1: 0.6232 - val_loss: 0.3888 - val_f1: 0.1459\n",
      "Epoch 186/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3152 - f1: 0.6304 - val_loss: 0.3877 - val_f1: 0.1445\n",
      "Epoch 187/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3159 - f1: 0.6270 - val_loss: 0.3904 - val_f1: 0.1437\n",
      "Epoch 188/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.3145 - f1: 0.6240 - val_loss: 0.3913 - val_f1: 0.1451\n",
      "Epoch 189/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3147 - f1: 0.6263 - val_loss: 0.3880 - val_f1: 0.1448\n",
      "Epoch 190/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3146 - f1: 0.6286 - val_loss: 0.3896 - val_f1: 0.1444\n",
      "Epoch 191/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3138 - f1: 0.6290 - val_loss: 0.3922 - val_f1: 0.1450\n",
      "Epoch 192/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3138 - f1: 0.6318 - val_loss: 0.3888 - val_f1: 0.1453\n",
      "Epoch 193/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3139 - f1: 0.6348 - val_loss: 0.3913 - val_f1: 0.1439\n",
      "Epoch 194/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3140 - f1: 0.6294 - val_loss: 0.3929 - val_f1: 0.1446\n",
      "Epoch 195/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3136 - f1: 0.6326 - val_loss: 0.3909 - val_f1: 0.1451\n",
      "Epoch 196/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3116 - f1: 0.6376 - val_loss: 0.3903 - val_f1: 0.1438\n",
      "Epoch 197/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3132 - f1: 0.6391 - val_loss: 0.3906 - val_f1: 0.1438\n",
      "Epoch 198/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3124 - f1: 0.6344 - val_loss: 0.3937 - val_f1: 0.1438\n",
      "Epoch 199/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.3106 - f1: 0.6409 - val_loss: 0.3920 - val_f1: 0.1439\n",
      "Epoch 200/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3125 - f1: 0.6288 - val_loss: 0.3917 - val_f1: 0.1441\n",
      "Epoch 201/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3116 - f1: 0.6382 - val_loss: 0.3930 - val_f1: 0.1439\n",
      "Epoch 202/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3123 - f1: 0.6398 - val_loss: 0.3940 - val_f1: 0.1444\n",
      "Epoch 203/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3090 - f1: 0.6376 - val_loss: 0.3927 - val_f1: 0.1446\n",
      "Epoch 204/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3104 - f1: 0.6370 - val_loss: 0.3943 - val_f1: 0.1438\n",
      "Epoch 205/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3100 - f1: 0.6350 - val_loss: 0.3950 - val_f1: 0.1439\n",
      "Epoch 206/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3094 - f1: 0.6385 - val_loss: 0.3935 - val_f1: 0.1444\n",
      "Epoch 207/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3091 - f1: 0.6386 - val_loss: 0.3913 - val_f1: 0.1436\n",
      "Epoch 208/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3094 - f1: 0.6341 - val_loss: 0.3930 - val_f1: 0.1431\n",
      "Epoch 209/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3073 - f1: 0.6415 - val_loss: 0.3951 - val_f1: 0.1448\n",
      "Epoch 210/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3080 - f1: 0.6406 - val_loss: 0.3944 - val_f1: 0.1441\n",
      "Epoch 211/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3081 - f1: 0.6390 - val_loss: 0.3978 - val_f1: 0.1443\n",
      "Epoch 212/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3069 - f1: 0.6430 - val_loss: 0.3935 - val_f1: 0.1444\n",
      "Epoch 213/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3048 - f1: 0.6477 - val_loss: 0.3990 - val_f1: 0.1431\n",
      "Epoch 214/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3064 - f1: 0.6443 - val_loss: 0.3939 - val_f1: 0.1436\n",
      "Epoch 215/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3060 - f1: 0.6419 - val_loss: 0.3970 - val_f1: 0.1423\n",
      "Epoch 216/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.3064 - f1: 0.6452 - val_loss: 0.3933 - val_f1: 0.1446\n",
      "Epoch 217/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3047 - f1: 0.6444 - val_loss: 0.4005 - val_f1: 0.1429\n",
      "Epoch 218/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3056 - f1: 0.6439 - val_loss: 0.3970 - val_f1: 0.1432\n",
      "Epoch 219/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3053 - f1: 0.6457 - val_loss: 0.3995 - val_f1: 0.1440\n",
      "Epoch 220/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3060 - f1: 0.6440 - val_loss: 0.3995 - val_f1: 0.1446\n",
      "Epoch 221/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3052 - f1: 0.6446 - val_loss: 0.3931 - val_f1: 0.1442\n",
      "Epoch 222/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3042 - f1: 0.6466 - val_loss: 0.3921 - val_f1: 0.1439\n",
      "Epoch 223/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3044 - f1: 0.6486 - val_loss: 0.3964 - val_f1: 0.1441\n",
      "Epoch 224/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3027 - f1: 0.6492 - val_loss: 0.4002 - val_f1: 0.1437\n",
      "Epoch 225/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3021 - f1: 0.6509 - val_loss: 0.4013 - val_f1: 0.1437\n",
      "Epoch 226/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3037 - f1: 0.6478 - val_loss: 0.3970 - val_f1: 0.1444\n",
      "Epoch 227/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3021 - f1: 0.6517 - val_loss: 0.3960 - val_f1: 0.1442\n",
      "Epoch 228/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.3025 - f1: 0.6500 - val_loss: 0.4019 - val_f1: 0.1435\n",
      "Epoch 229/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.3026 - f1: 0.6497 - val_loss: 0.3972 - val_f1: 0.1441\n",
      "Epoch 230/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3015 - f1: 0.6529 - val_loss: 0.4013 - val_f1: 0.1437\n",
      "Epoch 231/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3000 - f1: 0.6522 - val_loss: 0.4006 - val_f1: 0.1427\n",
      "Epoch 232/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.3000 - f1: 0.6563 - val_loss: 0.3967 - val_f1: 0.1439\n",
      "Epoch 233/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.3006 - f1: 0.6530 - val_loss: 0.3972 - val_f1: 0.1427\n",
      "Epoch 234/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2984 - f1: 0.6545 - val_loss: 0.3999 - val_f1: 0.1449\n",
      "Epoch 235/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3013 - f1: 0.6514 - val_loss: 0.3998 - val_f1: 0.1430\n",
      "Epoch 236/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.3003 - f1: 0.6557 - val_loss: 0.3960 - val_f1: 0.1445\n",
      "Epoch 237/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2996 - f1: 0.6517 - val_loss: 0.4029 - val_f1: 0.1431\n",
      "Epoch 238/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2993 - f1: 0.6561 - val_loss: 0.3972 - val_f1: 0.1437\n",
      "Epoch 239/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2994 - f1: 0.6563 - val_loss: 0.4024 - val_f1: 0.1430\n",
      "Epoch 240/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2988 - f1: 0.6567 - val_loss: 0.4084 - val_f1: 0.1444\n",
      "Epoch 241/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2976 - f1: 0.6580 - val_loss: 0.3996 - val_f1: 0.1441\n",
      "Epoch 242/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2983 - f1: 0.6541 - val_loss: 0.4036 - val_f1: 0.1438\n",
      "Epoch 243/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2967 - f1: 0.6576 - val_loss: 0.4058 - val_f1: 0.1437\n",
      "Epoch 244/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2980 - f1: 0.6566 - val_loss: 0.4030 - val_f1: 0.1443\n",
      "Epoch 245/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2958 - f1: 0.6655 - val_loss: 0.4001 - val_f1: 0.1429\n",
      "Epoch 246/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2985 - f1: 0.6595 - val_loss: 0.4002 - val_f1: 0.1437\n",
      "Epoch 247/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2963 - f1: 0.6594 - val_loss: 0.4007 - val_f1: 0.1424\n",
      "Epoch 248/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2948 - f1: 0.6626 - val_loss: 0.3991 - val_f1: 0.1429\n",
      "Epoch 249/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2943 - f1: 0.6576 - val_loss: 0.4060 - val_f1: 0.1427\n",
      "Epoch 250/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2953 - f1: 0.6599 - val_loss: 0.3981 - val_f1: 0.1426\n",
      "Epoch 251/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2954 - f1: 0.6603 - val_loss: 0.4054 - val_f1: 0.1434\n",
      "Epoch 252/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2935 - f1: 0.6634 - val_loss: 0.4070 - val_f1: 0.1431\n",
      "Epoch 253/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2950 - f1: 0.6625 - val_loss: 0.4100 - val_f1: 0.1428\n",
      "Epoch 254/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2927 - f1: 0.6626 - val_loss: 0.4065 - val_f1: 0.1436\n",
      "Epoch 255/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2928 - f1: 0.6686 - val_loss: 0.4080 - val_f1: 0.1437\n",
      "Epoch 256/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2927 - f1: 0.6632 - val_loss: 0.4044 - val_f1: 0.1440\n",
      "Epoch 257/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2926 - f1: 0.6667 - val_loss: 0.4096 - val_f1: 0.1428\n",
      "Epoch 258/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2935 - f1: 0.6658 - val_loss: 0.3994 - val_f1: 0.1417\n",
      "Epoch 259/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2931 - f1: 0.6632 - val_loss: 0.4075 - val_f1: 0.1421\n",
      "Epoch 260/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2936 - f1: 0.6676 - val_loss: 0.4043 - val_f1: 0.1423\n",
      "Epoch 261/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2925 - f1: 0.6677 - val_loss: 0.4031 - val_f1: 0.1406\n",
      "Epoch 262/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2943 - f1: 0.6612 - val_loss: 0.4099 - val_f1: 0.1422\n",
      "Epoch 263/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2903 - f1: 0.6709 - val_loss: 0.4043 - val_f1: 0.1427\n",
      "Epoch 264/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2909 - f1: 0.6689 - val_loss: 0.4057 - val_f1: 0.1429\n",
      "Epoch 265/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2909 - f1: 0.6738 - val_loss: 0.4088 - val_f1: 0.1426\n",
      "Epoch 266/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2906 - f1: 0.6685 - val_loss: 0.4025 - val_f1: 0.1427\n",
      "Epoch 267/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2885 - f1: 0.6703 - val_loss: 0.4086 - val_f1: 0.1428\n",
      "Epoch 268/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2880 - f1: 0.6738 - val_loss: 0.4147 - val_f1: 0.1430\n",
      "Epoch 269/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2896 - f1: 0.6713 - val_loss: 0.4115 - val_f1: 0.1428\n",
      "Epoch 270/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2871 - f1: 0.6745 - val_loss: 0.4134 - val_f1: 0.1435\n",
      "Epoch 271/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2895 - f1: 0.6692 - val_loss: 0.4019 - val_f1: 0.1434\n",
      "Epoch 272/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2879 - f1: 0.6700 - val_loss: 0.4077 - val_f1: 0.1425\n",
      "Epoch 273/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2876 - f1: 0.6741 - val_loss: 0.4069 - val_f1: 0.1419\n",
      "Epoch 274/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2856 - f1: 0.6773 - val_loss: 0.4110 - val_f1: 0.1422\n",
      "Epoch 275/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2857 - f1: 0.6788 - val_loss: 0.4144 - val_f1: 0.1419\n",
      "Epoch 276/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2865 - f1: 0.6734 - val_loss: 0.4156 - val_f1: 0.1418\n",
      "Epoch 277/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2874 - f1: 0.6734 - val_loss: 0.4099 - val_f1: 0.1424\n",
      "Epoch 278/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2864 - f1: 0.6724 - val_loss: 0.4096 - val_f1: 0.1424\n",
      "Epoch 279/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2853 - f1: 0.6741 - val_loss: 0.4085 - val_f1: 0.1424\n",
      "Epoch 280/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2869 - f1: 0.6709 - val_loss: 0.4054 - val_f1: 0.1421\n",
      "Epoch 281/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2862 - f1: 0.6732 - val_loss: 0.4150 - val_f1: 0.1427\n",
      "Epoch 282/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2839 - f1: 0.6790 - val_loss: 0.4121 - val_f1: 0.1427\n",
      "Epoch 283/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2869 - f1: 0.6698 - val_loss: 0.4029 - val_f1: 0.1430\n",
      "Epoch 284/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2853 - f1: 0.6777 - val_loss: 0.4121 - val_f1: 0.1425\n",
      "Epoch 285/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2857 - f1: 0.6769 - val_loss: 0.4097 - val_f1: 0.1424\n",
      "Epoch 286/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2853 - f1: 0.6769 - val_loss: 0.4135 - val_f1: 0.1421\n",
      "Epoch 287/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2843 - f1: 0.6828 - val_loss: 0.4156 - val_f1: 0.1418\n",
      "Epoch 288/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2840 - f1: 0.6823 - val_loss: 0.4110 - val_f1: 0.1434\n",
      "Epoch 289/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2827 - f1: 0.6788 - val_loss: 0.4139 - val_f1: 0.1418\n",
      "Epoch 290/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2833 - f1: 0.6807 - val_loss: 0.4111 - val_f1: 0.1429\n",
      "Epoch 291/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2831 - f1: 0.6795 - val_loss: 0.4124 - val_f1: 0.1424\n",
      "Epoch 292/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2841 - f1: 0.6788 - val_loss: 0.4078 - val_f1: 0.1428\n",
      "Epoch 293/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2832 - f1: 0.6788 - val_loss: 0.4124 - val_f1: 0.1435\n",
      "Epoch 294/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2838 - f1: 0.6820 - val_loss: 0.4138 - val_f1: 0.1422\n",
      "Epoch 295/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2826 - f1: 0.6815 - val_loss: 0.4116 - val_f1: 0.1429\n",
      "Epoch 296/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2820 - f1: 0.6832 - val_loss: 0.4183 - val_f1: 0.1417\n",
      "Epoch 297/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2794 - f1: 0.6865 - val_loss: 0.4105 - val_f1: 0.1424\n",
      "Epoch 298/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2824 - f1: 0.6788 - val_loss: 0.4155 - val_f1: 0.1423\n",
      "Epoch 299/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2823 - f1: 0.6836 - val_loss: 0.4145 - val_f1: 0.1415\n",
      "Epoch 300/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2804 - f1: 0.6863 - val_loss: 0.4110 - val_f1: 0.1415\n",
      "Epoch 301/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2816 - f1: 0.6837 - val_loss: 0.4118 - val_f1: 0.1427\n",
      "Epoch 302/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2810 - f1: 0.6850 - val_loss: 0.4109 - val_f1: 0.1423\n",
      "Epoch 303/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2798 - f1: 0.6858 - val_loss: 0.4150 - val_f1: 0.1422\n",
      "Epoch 304/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2789 - f1: 0.6892 - val_loss: 0.4128 - val_f1: 0.1409\n",
      "Epoch 305/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2798 - f1: 0.6868 - val_loss: 0.4147 - val_f1: 0.1421\n",
      "Epoch 306/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2815 - f1: 0.6826 - val_loss: 0.4173 - val_f1: 0.1419\n",
      "Epoch 307/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2796 - f1: 0.6852 - val_loss: 0.4144 - val_f1: 0.1418\n",
      "Epoch 308/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2789 - f1: 0.6847 - val_loss: 0.4197 - val_f1: 0.1415\n",
      "Epoch 309/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2792 - f1: 0.6888 - val_loss: 0.4115 - val_f1: 0.1430\n",
      "Epoch 310/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2795 - f1: 0.6819 - val_loss: 0.4180 - val_f1: 0.1423\n",
      "Epoch 311/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2780 - f1: 0.6897 - val_loss: 0.4128 - val_f1: 0.1423\n",
      "Epoch 312/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2779 - f1: 0.6921 - val_loss: 0.4152 - val_f1: 0.1415\n",
      "Epoch 313/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2776 - f1: 0.6889 - val_loss: 0.4175 - val_f1: 0.1435\n",
      "Epoch 314/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2775 - f1: 0.6906 - val_loss: 0.4226 - val_f1: 0.1435\n",
      "Epoch 315/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2765 - f1: 0.6884 - val_loss: 0.4142 - val_f1: 0.1420\n",
      "Epoch 316/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2779 - f1: 0.6876 - val_loss: 0.4101 - val_f1: 0.1424\n",
      "Epoch 317/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2768 - f1: 0.6877 - val_loss: 0.4156 - val_f1: 0.1427\n",
      "Epoch 318/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2762 - f1: 0.6896 - val_loss: 0.4164 - val_f1: 0.1409\n",
      "Epoch 319/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2759 - f1: 0.6906 - val_loss: 0.4227 - val_f1: 0.1424\n",
      "Epoch 320/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2744 - f1: 0.6930 - val_loss: 0.4176 - val_f1: 0.1419\n",
      "Epoch 321/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2779 - f1: 0.6867 - val_loss: 0.4227 - val_f1: 0.1428\n",
      "Epoch 322/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2764 - f1: 0.6902 - val_loss: 0.4178 - val_f1: 0.1413\n",
      "Epoch 323/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2771 - f1: 0.6870 - val_loss: 0.4106 - val_f1: 0.1421\n",
      "Epoch 324/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2754 - f1: 0.6894 - val_loss: 0.4211 - val_f1: 0.1432\n",
      "Epoch 325/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2743 - f1: 0.6959 - val_loss: 0.4268 - val_f1: 0.1423\n",
      "Epoch 326/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2757 - f1: 0.6878 - val_loss: 0.4216 - val_f1: 0.1413\n",
      "Epoch 327/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2744 - f1: 0.6939 - val_loss: 0.4153 - val_f1: 0.1411\n",
      "Epoch 328/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2766 - f1: 0.6907 - val_loss: 0.4195 - val_f1: 0.1410\n",
      "Epoch 329/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2752 - f1: 0.6901 - val_loss: 0.4211 - val_f1: 0.1420\n",
      "Epoch 330/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2741 - f1: 0.6923 - val_loss: 0.4195 - val_f1: 0.1426\n",
      "Epoch 331/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2706 - f1: 0.7028 - val_loss: 0.4167 - val_f1: 0.1412\n",
      "Epoch 332/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2753 - f1: 0.6955 - val_loss: 0.4212 - val_f1: 0.1414\n",
      "Epoch 333/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2754 - f1: 0.6906 - val_loss: 0.4248 - val_f1: 0.1416\n",
      "Epoch 334/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2718 - f1: 0.6965 - val_loss: 0.4195 - val_f1: 0.1415\n",
      "Epoch 335/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2718 - f1: 0.6969 - val_loss: 0.4217 - val_f1: 0.1418\n",
      "Epoch 336/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2715 - f1: 0.6979 - val_loss: 0.4183 - val_f1: 0.1422\n",
      "Epoch 337/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2726 - f1: 0.6949 - val_loss: 0.4170 - val_f1: 0.1421\n",
      "Epoch 338/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2721 - f1: 0.6945 - val_loss: 0.4206 - val_f1: 0.1421\n",
      "Epoch 339/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2726 - f1: 0.6955 - val_loss: 0.4206 - val_f1: 0.1422\n",
      "Epoch 340/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2728 - f1: 0.6934 - val_loss: 0.4194 - val_f1: 0.1421\n",
      "Epoch 341/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2718 - f1: 0.6973 - val_loss: 0.4171 - val_f1: 0.1422\n",
      "Epoch 342/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2705 - f1: 0.7001 - val_loss: 0.4110 - val_f1: 0.1416\n",
      "Epoch 343/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2720 - f1: 0.6957 - val_loss: 0.4198 - val_f1: 0.1422\n",
      "Epoch 344/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2696 - f1: 0.7065 - val_loss: 0.4115 - val_f1: 0.1420\n",
      "Epoch 345/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2712 - f1: 0.6962 - val_loss: 0.4193 - val_f1: 0.1414\n",
      "Epoch 346/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2678 - f1: 0.6970 - val_loss: 0.4270 - val_f1: 0.1424\n",
      "Epoch 347/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2690 - f1: 0.6982 - val_loss: 0.4208 - val_f1: 0.1434\n",
      "Epoch 348/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2703 - f1: 0.6986 - val_loss: 0.4204 - val_f1: 0.1415\n",
      "Epoch 349/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2700 - f1: 0.7000 - val_loss: 0.4139 - val_f1: 0.1402\n",
      "Epoch 350/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2688 - f1: 0.7015 - val_loss: 0.4167 - val_f1: 0.1404\n",
      "Epoch 351/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2685 - f1: 0.6962 - val_loss: 0.4243 - val_f1: 0.1423\n",
      "Epoch 352/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2688 - f1: 0.7001 - val_loss: 0.4159 - val_f1: 0.1416\n",
      "Epoch 353/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2700 - f1: 0.6981 - val_loss: 0.4179 - val_f1: 0.1412\n",
      "Epoch 354/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2680 - f1: 0.7029 - val_loss: 0.4270 - val_f1: 0.1415\n",
      "Epoch 355/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2700 - f1: 0.6994 - val_loss: 0.4236 - val_f1: 0.1418\n",
      "Epoch 356/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2689 - f1: 0.6973 - val_loss: 0.4197 - val_f1: 0.1421\n",
      "Epoch 357/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2699 - f1: 0.7000 - val_loss: 0.4227 - val_f1: 0.1417\n",
      "Epoch 358/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2697 - f1: 0.7001 - val_loss: 0.4237 - val_f1: 0.1411\n",
      "Epoch 359/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2680 - f1: 0.7035 - val_loss: 0.4251 - val_f1: 0.1400\n",
      "Epoch 360/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2690 - f1: 0.7027 - val_loss: 0.4244 - val_f1: 0.1407\n",
      "Epoch 361/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2687 - f1: 0.7043 - val_loss: 0.4219 - val_f1: 0.1417\n",
      "Epoch 362/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2679 - f1: 0.7027 - val_loss: 0.4270 - val_f1: 0.1411\n",
      "Epoch 363/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2684 - f1: 0.7031 - val_loss: 0.4269 - val_f1: 0.1409\n",
      "Epoch 364/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2689 - f1: 0.6988 - val_loss: 0.4212 - val_f1: 0.1414\n",
      "Epoch 365/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2655 - f1: 0.7059 - val_loss: 0.4284 - val_f1: 0.1406\n",
      "Epoch 366/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2654 - f1: 0.7102 - val_loss: 0.4215 - val_f1: 0.1421\n",
      "Epoch 367/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2647 - f1: 0.7080 - val_loss: 0.4259 - val_f1: 0.1424\n",
      "Epoch 368/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2669 - f1: 0.7067 - val_loss: 0.4303 - val_f1: 0.1407\n",
      "Epoch 369/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2662 - f1: 0.7062 - val_loss: 0.4243 - val_f1: 0.1408\n",
      "Epoch 370/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2627 - f1: 0.7104 - val_loss: 0.4246 - val_f1: 0.1403\n",
      "Epoch 371/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2656 - f1: 0.7060 - val_loss: 0.4224 - val_f1: 0.1414\n",
      "Epoch 372/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2639 - f1: 0.7110 - val_loss: 0.4290 - val_f1: 0.1417\n",
      "Epoch 373/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2660 - f1: 0.7041 - val_loss: 0.4219 - val_f1: 0.1420\n",
      "Epoch 374/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2649 - f1: 0.7096 - val_loss: 0.4181 - val_f1: 0.1395\n",
      "Epoch 375/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2642 - f1: 0.7089 - val_loss: 0.4298 - val_f1: 0.1405\n",
      "Epoch 376/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2629 - f1: 0.7119 - val_loss: 0.4318 - val_f1: 0.1406\n",
      "Epoch 377/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2628 - f1: 0.7076 - val_loss: 0.4226 - val_f1: 0.1413\n",
      "Epoch 378/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2641 - f1: 0.7060 - val_loss: 0.4312 - val_f1: 0.1409\n",
      "Epoch 379/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2631 - f1: 0.7107 - val_loss: 0.4249 - val_f1: 0.1410\n",
      "Epoch 380/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2618 - f1: 0.7082 - val_loss: 0.4308 - val_f1: 0.1402\n",
      "Epoch 381/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2639 - f1: 0.7084 - val_loss: 0.4265 - val_f1: 0.1405\n",
      "Epoch 382/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2607 - f1: 0.7132 - val_loss: 0.4218 - val_f1: 0.1410\n",
      "Epoch 383/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2643 - f1: 0.7064 - val_loss: 0.4259 - val_f1: 0.1402\n",
      "Epoch 384/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2632 - f1: 0.7086 - val_loss: 0.4271 - val_f1: 0.1411\n",
      "Epoch 385/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2613 - f1: 0.7141 - val_loss: 0.4319 - val_f1: 0.1409\n",
      "Epoch 386/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2601 - f1: 0.7152 - val_loss: 0.4333 - val_f1: 0.1406\n",
      "Epoch 387/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2612 - f1: 0.7081 - val_loss: 0.4281 - val_f1: 0.1411\n",
      "Epoch 388/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2618 - f1: 0.7092 - val_loss: 0.4326 - val_f1: 0.1411\n",
      "Epoch 389/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2624 - f1: 0.7081 - val_loss: 0.4391 - val_f1: 0.1420\n",
      "Epoch 390/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2631 - f1: 0.7123 - val_loss: 0.4316 - val_f1: 0.1413\n",
      "Epoch 391/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2624 - f1: 0.7133 - val_loss: 0.4388 - val_f1: 0.1410\n",
      "Epoch 392/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2590 - f1: 0.7202 - val_loss: 0.4323 - val_f1: 0.1405\n",
      "Epoch 393/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2607 - f1: 0.7100 - val_loss: 0.4308 - val_f1: 0.1408\n",
      "Epoch 394/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2593 - f1: 0.7141 - val_loss: 0.4326 - val_f1: 0.1425\n",
      "Epoch 395/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2611 - f1: 0.7106 - val_loss: 0.4306 - val_f1: 0.1408\n",
      "Epoch 396/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2584 - f1: 0.7146 - val_loss: 0.4352 - val_f1: 0.1414\n",
      "Epoch 397/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2609 - f1: 0.7136 - val_loss: 0.4278 - val_f1: 0.1398\n",
      "Epoch 398/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2599 - f1: 0.7155 - val_loss: 0.4393 - val_f1: 0.1412\n",
      "Epoch 399/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2596 - f1: 0.7130 - val_loss: 0.4283 - val_f1: 0.1403\n",
      "Epoch 400/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2614 - f1: 0.7099 - val_loss: 0.4292 - val_f1: 0.1409\n",
      "Epoch 401/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2589 - f1: 0.7169 - val_loss: 0.4268 - val_f1: 0.1411\n",
      "Epoch 402/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2585 - f1: 0.7141 - val_loss: 0.4299 - val_f1: 0.1408\n",
      "Epoch 403/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2605 - f1: 0.7127 - val_loss: 0.4314 - val_f1: 0.1416\n",
      "Epoch 404/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2609 - f1: 0.7160 - val_loss: 0.4306 - val_f1: 0.1407\n",
      "Epoch 405/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2591 - f1: 0.7150 - val_loss: 0.4280 - val_f1: 0.1410\n",
      "Epoch 406/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2574 - f1: 0.7171 - val_loss: 0.4349 - val_f1: 0.1412\n",
      "Epoch 407/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2556 - f1: 0.7241 - val_loss: 0.4349 - val_f1: 0.1402\n",
      "Epoch 408/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2567 - f1: 0.7195 - val_loss: 0.4423 - val_f1: 0.1410\n",
      "Epoch 409/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2598 - f1: 0.7106 - val_loss: 0.4359 - val_f1: 0.1408\n",
      "Epoch 410/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2584 - f1: 0.7166 - val_loss: 0.4320 - val_f1: 0.1399\n",
      "Epoch 411/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2568 - f1: 0.7169 - val_loss: 0.4268 - val_f1: 0.1411\n",
      "Epoch 412/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2563 - f1: 0.7183 - val_loss: 0.4243 - val_f1: 0.1412\n",
      "Epoch 413/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2577 - f1: 0.7175 - val_loss: 0.4311 - val_f1: 0.1408\n",
      "Epoch 414/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2554 - f1: 0.7222 - val_loss: 0.4440 - val_f1: 0.1400\n",
      "Epoch 415/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2559 - f1: 0.7194 - val_loss: 0.4399 - val_f1: 0.1403\n",
      "Epoch 416/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2575 - f1: 0.7159 - val_loss: 0.4326 - val_f1: 0.1408\n",
      "Epoch 417/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2554 - f1: 0.7181 - val_loss: 0.4398 - val_f1: 0.1413\n",
      "Epoch 418/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2568 - f1: 0.7198 - val_loss: 0.4277 - val_f1: 0.1411\n",
      "Epoch 419/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2567 - f1: 0.7168 - val_loss: 0.4394 - val_f1: 0.1415\n",
      "Epoch 420/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2562 - f1: 0.7186 - val_loss: 0.4354 - val_f1: 0.1413\n",
      "Epoch 421/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2557 - f1: 0.7205 - val_loss: 0.4353 - val_f1: 0.1415\n",
      "Epoch 422/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2542 - f1: 0.7219 - val_loss: 0.4376 - val_f1: 0.1414\n",
      "Epoch 423/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2548 - f1: 0.7216 - val_loss: 0.4443 - val_f1: 0.1410\n",
      "Epoch 424/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2560 - f1: 0.7151 - val_loss: 0.4374 - val_f1: 0.1413\n",
      "Epoch 425/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2548 - f1: 0.7240 - val_loss: 0.4383 - val_f1: 0.1408\n",
      "Epoch 426/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2551 - f1: 0.7167 - val_loss: 0.4368 - val_f1: 0.1408\n",
      "Epoch 427/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2547 - f1: 0.7208 - val_loss: 0.4362 - val_f1: 0.1414\n",
      "Epoch 428/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2522 - f1: 0.7272 - val_loss: 0.4407 - val_f1: 0.1409\n",
      "Epoch 429/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2566 - f1: 0.7196 - val_loss: 0.4415 - val_f1: 0.1411\n",
      "Epoch 430/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2540 - f1: 0.7222 - val_loss: 0.4353 - val_f1: 0.1411\n",
      "Epoch 431/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2545 - f1: 0.7217 - val_loss: 0.4416 - val_f1: 0.1407\n",
      "Epoch 432/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2531 - f1: 0.7210 - val_loss: 0.4415 - val_f1: 0.1405\n",
      "Epoch 433/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2536 - f1: 0.7212 - val_loss: 0.4300 - val_f1: 0.1401\n",
      "Epoch 434/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2531 - f1: 0.7252 - val_loss: 0.4328 - val_f1: 0.1409\n",
      "Epoch 435/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2522 - f1: 0.7219 - val_loss: 0.4391 - val_f1: 0.1411\n",
      "Epoch 436/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2554 - f1: 0.7179 - val_loss: 0.4369 - val_f1: 0.1397\n",
      "Epoch 437/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2534 - f1: 0.7191 - val_loss: 0.4317 - val_f1: 0.1402\n",
      "Epoch 438/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2544 - f1: 0.7166 - val_loss: 0.4336 - val_f1: 0.1408\n",
      "Epoch 439/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2520 - f1: 0.7220 - val_loss: 0.4424 - val_f1: 0.1407\n",
      "Epoch 440/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2530 - f1: 0.7192 - val_loss: 0.4438 - val_f1: 0.1412\n",
      "Epoch 441/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2526 - f1: 0.7252 - val_loss: 0.4386 - val_f1: 0.1398\n",
      "Epoch 442/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2511 - f1: 0.7266 - val_loss: 0.4461 - val_f1: 0.1395\n",
      "Epoch 443/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2516 - f1: 0.7212 - val_loss: 0.4405 - val_f1: 0.1409\n",
      "Epoch 444/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2525 - f1: 0.7224 - val_loss: 0.4425 - val_f1: 0.1389\n",
      "Epoch 445/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2523 - f1: 0.7256 - val_loss: 0.4408 - val_f1: 0.1409\n",
      "Epoch 446/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2507 - f1: 0.7264 - val_loss: 0.4498 - val_f1: 0.1393\n",
      "Epoch 447/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2532 - f1: 0.7269 - val_loss: 0.4367 - val_f1: 0.1396\n",
      "Epoch 448/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2495 - f1: 0.7300 - val_loss: 0.4455 - val_f1: 0.1398\n",
      "Epoch 449/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2517 - f1: 0.7212 - val_loss: 0.4491 - val_f1: 0.1411\n",
      "Epoch 450/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2513 - f1: 0.7309 - val_loss: 0.4328 - val_f1: 0.1406\n",
      "Epoch 451/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2501 - f1: 0.7299 - val_loss: 0.4419 - val_f1: 0.1403\n",
      "Epoch 452/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2507 - f1: 0.7279 - val_loss: 0.4433 - val_f1: 0.1409\n",
      "Epoch 453/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2488 - f1: 0.7263 - val_loss: 0.4387 - val_f1: 0.1403\n",
      "Epoch 454/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2507 - f1: 0.7266 - val_loss: 0.4414 - val_f1: 0.1398\n",
      "Epoch 455/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2467 - f1: 0.7319 - val_loss: 0.4460 - val_f1: 0.1395\n",
      "Epoch 456/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2494 - f1: 0.7274 - val_loss: 0.4463 - val_f1: 0.1402\n",
      "Epoch 457/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2466 - f1: 0.7288 - val_loss: 0.4520 - val_f1: 0.1399\n",
      "Epoch 458/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2493 - f1: 0.7292 - val_loss: 0.4396 - val_f1: 0.1399\n",
      "Epoch 459/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2488 - f1: 0.7319 - val_loss: 0.4434 - val_f1: 0.1403\n",
      "Epoch 460/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2481 - f1: 0.7330 - val_loss: 0.4510 - val_f1: 0.1405\n",
      "Epoch 461/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2511 - f1: 0.7295 - val_loss: 0.4396 - val_f1: 0.1395\n",
      "Epoch 462/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2479 - f1: 0.7262 - val_loss: 0.4541 - val_f1: 0.1405\n",
      "Epoch 463/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2486 - f1: 0.7286 - val_loss: 0.4537 - val_f1: 0.1400\n",
      "Epoch 464/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2480 - f1: 0.7307 - val_loss: 0.4418 - val_f1: 0.1397\n",
      "Epoch 465/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2500 - f1: 0.7295 - val_loss: 0.4415 - val_f1: 0.1397\n",
      "Epoch 466/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2489 - f1: 0.7328 - val_loss: 0.4378 - val_f1: 0.1393\n",
      "Epoch 467/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2495 - f1: 0.7294 - val_loss: 0.4479 - val_f1: 0.1403\n",
      "Epoch 468/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2477 - f1: 0.7274 - val_loss: 0.4467 - val_f1: 0.1407\n",
      "Epoch 469/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2469 - f1: 0.7276 - val_loss: 0.4439 - val_f1: 0.1404\n",
      "Epoch 470/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2476 - f1: 0.7299 - val_loss: 0.4490 - val_f1: 0.1409\n",
      "Epoch 471/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2487 - f1: 0.7330 - val_loss: 0.4430 - val_f1: 0.1403\n",
      "Epoch 472/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2460 - f1: 0.7347 - val_loss: 0.4459 - val_f1: 0.1401\n",
      "Epoch 473/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2473 - f1: 0.7283 - val_loss: 0.4493 - val_f1: 0.1407\n",
      "Epoch 474/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2451 - f1: 0.7326 - val_loss: 0.4465 - val_f1: 0.1400\n",
      "Epoch 475/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2455 - f1: 0.7366 - val_loss: 0.4525 - val_f1: 0.1396\n",
      "Epoch 476/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2471 - f1: 0.7283 - val_loss: 0.4446 - val_f1: 0.1394\n",
      "Epoch 477/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2459 - f1: 0.7324 - val_loss: 0.4526 - val_f1: 0.1390\n",
      "Epoch 478/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2484 - f1: 0.7269 - val_loss: 0.4442 - val_f1: 0.1403\n",
      "Epoch 479/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2461 - f1: 0.7316 - val_loss: 0.4511 - val_f1: 0.1395\n",
      "Epoch 480/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2474 - f1: 0.7294 - val_loss: 0.4491 - val_f1: 0.1405\n",
      "Epoch 481/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2489 - f1: 0.7271 - val_loss: 0.4433 - val_f1: 0.1411\n",
      "Epoch 482/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2474 - f1: 0.7346 - val_loss: 0.4505 - val_f1: 0.1405\n",
      "Epoch 483/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2480 - f1: 0.7312 - val_loss: 0.4498 - val_f1: 0.1395\n",
      "Epoch 484/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2446 - f1: 0.7303 - val_loss: 0.4560 - val_f1: 0.1402\n",
      "Epoch 485/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2462 - f1: 0.7323 - val_loss: 0.4497 - val_f1: 0.1401\n",
      "Epoch 486/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2446 - f1: 0.7340 - val_loss: 0.4510 - val_f1: 0.1407\n",
      "Epoch 487/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2460 - f1: 0.7330 - val_loss: 0.4376 - val_f1: 0.1419\n",
      "Epoch 488/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2436 - f1: 0.7364 - val_loss: 0.4438 - val_f1: 0.1403\n",
      "Epoch 489/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2448 - f1: 0.7379 - val_loss: 0.4483 - val_f1: 0.1399\n",
      "Epoch 490/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2438 - f1: 0.7306 - val_loss: 0.4520 - val_f1: 0.1404\n",
      "Epoch 491/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2451 - f1: 0.7355 - val_loss: 0.4502 - val_f1: 0.1408\n",
      "Epoch 492/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2446 - f1: 0.7323 - val_loss: 0.4519 - val_f1: 0.1404\n",
      "Epoch 493/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2454 - f1: 0.7327 - val_loss: 0.4443 - val_f1: 0.1407\n",
      "Epoch 494/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2461 - f1: 0.7317 - val_loss: 0.4512 - val_f1: 0.1402\n",
      "Epoch 495/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2438 - f1: 0.7342 - val_loss: 0.4479 - val_f1: 0.1406\n",
      "Epoch 496/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2474 - f1: 0.7329 - val_loss: 0.4519 - val_f1: 0.1393\n",
      "Epoch 497/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2435 - f1: 0.7360 - val_loss: 0.4532 - val_f1: 0.1399\n",
      "Epoch 498/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2442 - f1: 0.7335 - val_loss: 0.4566 - val_f1: 0.1396\n",
      "Epoch 499/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2452 - f1: 0.7332 - val_loss: 0.4547 - val_f1: 0.1398\n",
      "Epoch 500/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2427 - f1: 0.7340 - val_loss: 0.4517 - val_f1: 0.1397\n",
      "Epoch 501/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2455 - f1: 0.7368 - val_loss: 0.4477 - val_f1: 0.1401\n",
      "Epoch 502/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2442 - f1: 0.7338 - val_loss: 0.4510 - val_f1: 0.1392\n",
      "Epoch 503/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2427 - f1: 0.7327 - val_loss: 0.4602 - val_f1: 0.1403\n",
      "Epoch 504/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2442 - f1: 0.7338 - val_loss: 0.4583 - val_f1: 0.1395\n",
      "Epoch 505/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2417 - f1: 0.7378 - val_loss: 0.4484 - val_f1: 0.1397\n",
      "Epoch 506/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2420 - f1: 0.7414 - val_loss: 0.4540 - val_f1: 0.1404\n",
      "Epoch 507/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2426 - f1: 0.7387 - val_loss: 0.4508 - val_f1: 0.1397\n",
      "Epoch 508/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2433 - f1: 0.7345 - val_loss: 0.4477 - val_f1: 0.1413\n",
      "Epoch 509/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2445 - f1: 0.7346 - val_loss: 0.4506 - val_f1: 0.1407\n",
      "Epoch 510/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2406 - f1: 0.7412 - val_loss: 0.4522 - val_f1: 0.1401\n",
      "Epoch 511/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2432 - f1: 0.7396 - val_loss: 0.4449 - val_f1: 0.1397\n",
      "Epoch 512/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2420 - f1: 0.7370 - val_loss: 0.4462 - val_f1: 0.1397\n",
      "Epoch 513/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2436 - f1: 0.7339 - val_loss: 0.4501 - val_f1: 0.1404\n",
      "Epoch 514/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2407 - f1: 0.7425 - val_loss: 0.4460 - val_f1: 0.1408\n",
      "Epoch 515/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2408 - f1: 0.7455 - val_loss: 0.4577 - val_f1: 0.1397\n",
      "Epoch 516/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2428 - f1: 0.7376 - val_loss: 0.4493 - val_f1: 0.1399\n",
      "Epoch 517/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2431 - f1: 0.7389 - val_loss: 0.4614 - val_f1: 0.1383\n",
      "Epoch 518/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2424 - f1: 0.7365 - val_loss: 0.4460 - val_f1: 0.1395\n",
      "Epoch 519/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2397 - f1: 0.7412 - val_loss: 0.4413 - val_f1: 0.1404\n",
      "Epoch 520/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2426 - f1: 0.7413 - val_loss: 0.4513 - val_f1: 0.1388\n",
      "Epoch 521/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2408 - f1: 0.7396 - val_loss: 0.4551 - val_f1: 0.1396\n",
      "Epoch 522/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2415 - f1: 0.7393 - val_loss: 0.4486 - val_f1: 0.1407\n",
      "Epoch 523/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2419 - f1: 0.7365 - val_loss: 0.4507 - val_f1: 0.1395\n",
      "Epoch 524/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2371 - f1: 0.7476 - val_loss: 0.4621 - val_f1: 0.1404\n",
      "Epoch 525/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2409 - f1: 0.7370 - val_loss: 0.4479 - val_f1: 0.1397\n",
      "Epoch 526/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2406 - f1: 0.7399 - val_loss: 0.4528 - val_f1: 0.1401\n",
      "Epoch 527/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2393 - f1: 0.7448 - val_loss: 0.4545 - val_f1: 0.1408\n",
      "Epoch 528/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2391 - f1: 0.7387 - val_loss: 0.4594 - val_f1: 0.1394\n",
      "Epoch 529/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2385 - f1: 0.7431 - val_loss: 0.4512 - val_f1: 0.1389\n",
      "Epoch 530/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2411 - f1: 0.7464 - val_loss: 0.4524 - val_f1: 0.1402\n",
      "Epoch 531/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2379 - f1: 0.7462 - val_loss: 0.4481 - val_f1: 0.1383\n",
      "Epoch 532/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2387 - f1: 0.7416 - val_loss: 0.4610 - val_f1: 0.1382\n",
      "Epoch 533/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2412 - f1: 0.7380 - val_loss: 0.4555 - val_f1: 0.1390\n",
      "Epoch 534/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2388 - f1: 0.7433 - val_loss: 0.4539 - val_f1: 0.1385\n",
      "Epoch 535/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2372 - f1: 0.7466 - val_loss: 0.4603 - val_f1: 0.1385\n",
      "Epoch 536/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2409 - f1: 0.7419 - val_loss: 0.4505 - val_f1: 0.1396\n",
      "Epoch 537/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2406 - f1: 0.7412 - val_loss: 0.4572 - val_f1: 0.1398\n",
      "Epoch 538/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2408 - f1: 0.7412 - val_loss: 0.4508 - val_f1: 0.1403\n",
      "Epoch 539/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2389 - f1: 0.7458 - val_loss: 0.4573 - val_f1: 0.1399\n",
      "Epoch 540/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2394 - f1: 0.7437 - val_loss: 0.4462 - val_f1: 0.1410\n",
      "Epoch 541/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2388 - f1: 0.7431 - val_loss: 0.4622 - val_f1: 0.1390\n",
      "Epoch 542/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2377 - f1: 0.7459 - val_loss: 0.4590 - val_f1: 0.1392\n",
      "Epoch 543/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2385 - f1: 0.7412 - val_loss: 0.4568 - val_f1: 0.1382\n",
      "Epoch 544/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2378 - f1: 0.7434 - val_loss: 0.4456 - val_f1: 0.1402\n",
      "Epoch 545/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2372 - f1: 0.7434 - val_loss: 0.4671 - val_f1: 0.1403\n",
      "Epoch 546/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2385 - f1: 0.7426 - val_loss: 0.4612 - val_f1: 0.1392\n",
      "Epoch 547/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2374 - f1: 0.7450 - val_loss: 0.4488 - val_f1: 0.1396\n",
      "Epoch 548/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2367 - f1: 0.7460 - val_loss: 0.4625 - val_f1: 0.1391\n",
      "Epoch 549/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2343 - f1: 0.7488 - val_loss: 0.4552 - val_f1: 0.1399\n",
      "Epoch 550/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2359 - f1: 0.7485 - val_loss: 0.4583 - val_f1: 0.1395\n",
      "Epoch 551/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2376 - f1: 0.7451 - val_loss: 0.4567 - val_f1: 0.1403\n",
      "Epoch 552/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2368 - f1: 0.7448 - val_loss: 0.4561 - val_f1: 0.1388\n",
      "Epoch 553/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2381 - f1: 0.7454 - val_loss: 0.4559 - val_f1: 0.1389\n",
      "Epoch 554/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2355 - f1: 0.7475 - val_loss: 0.4598 - val_f1: 0.1393\n",
      "Epoch 555/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2365 - f1: 0.7461 - val_loss: 0.4421 - val_f1: 0.1395\n",
      "Epoch 556/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2347 - f1: 0.7438 - val_loss: 0.4655 - val_f1: 0.1394\n",
      "Epoch 557/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2349 - f1: 0.7479 - val_loss: 0.4546 - val_f1: 0.1402\n",
      "Epoch 558/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2390 - f1: 0.7424 - val_loss: 0.4610 - val_f1: 0.1383\n",
      "Epoch 559/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2388 - f1: 0.7448 - val_loss: 0.4546 - val_f1: 0.1397\n",
      "Epoch 560/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2364 - f1: 0.7423 - val_loss: 0.4582 - val_f1: 0.1394\n",
      "Epoch 561/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2366 - f1: 0.7462 - val_loss: 0.4517 - val_f1: 0.1404\n",
      "Epoch 562/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2371 - f1: 0.7447 - val_loss: 0.4609 - val_f1: 0.1394\n",
      "Epoch 563/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2352 - f1: 0.7480 - val_loss: 0.4623 - val_f1: 0.1392\n",
      "Epoch 564/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2361 - f1: 0.7471 - val_loss: 0.4571 - val_f1: 0.1398\n",
      "Epoch 565/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2347 - f1: 0.7481 - val_loss: 0.4621 - val_f1: 0.1400\n",
      "Epoch 566/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2347 - f1: 0.7473 - val_loss: 0.4557 - val_f1: 0.1400\n",
      "Epoch 567/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2353 - f1: 0.7472 - val_loss: 0.4602 - val_f1: 0.1396\n",
      "Epoch 568/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2339 - f1: 0.7482 - val_loss: 0.4586 - val_f1: 0.1389\n",
      "Epoch 569/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2335 - f1: 0.7469 - val_loss: 0.4668 - val_f1: 0.1407\n",
      "Epoch 570/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2377 - f1: 0.7432 - val_loss: 0.4624 - val_f1: 0.1388\n",
      "Epoch 571/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2341 - f1: 0.7486 - val_loss: 0.4571 - val_f1: 0.1397\n",
      "Epoch 572/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2362 - f1: 0.7437 - val_loss: 0.4603 - val_f1: 0.1393\n",
      "Epoch 573/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2390 - f1: 0.7414 - val_loss: 0.4447 - val_f1: 0.1392\n",
      "Epoch 574/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2363 - f1: 0.7488 - val_loss: 0.4626 - val_f1: 0.1394\n",
      "Epoch 575/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2353 - f1: 0.7450 - val_loss: 0.4641 - val_f1: 0.1387\n",
      "Epoch 576/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2352 - f1: 0.7490 - val_loss: 0.4560 - val_f1: 0.1393\n",
      "Epoch 577/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2345 - f1: 0.7480 - val_loss: 0.4611 - val_f1: 0.1407\n",
      "Epoch 578/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2343 - f1: 0.7480 - val_loss: 0.4599 - val_f1: 0.1395\n",
      "Epoch 579/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2368 - f1: 0.7475 - val_loss: 0.4589 - val_f1: 0.1388\n",
      "Epoch 580/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2358 - f1: 0.7449 - val_loss: 0.4611 - val_f1: 0.1395\n",
      "Epoch 581/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2315 - f1: 0.7495 - val_loss: 0.4645 - val_f1: 0.1407\n",
      "Epoch 582/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2368 - f1: 0.7483 - val_loss: 0.4551 - val_f1: 0.1396\n",
      "Epoch 583/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2322 - f1: 0.7513 - val_loss: 0.4591 - val_f1: 0.1410\n",
      "Epoch 584/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2332 - f1: 0.7490 - val_loss: 0.4680 - val_f1: 0.1402\n",
      "Epoch 585/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2337 - f1: 0.7495 - val_loss: 0.4699 - val_f1: 0.1394\n",
      "Epoch 586/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2324 - f1: 0.7525 - val_loss: 0.4598 - val_f1: 0.1405\n",
      "Epoch 587/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2304 - f1: 0.7535 - val_loss: 0.4763 - val_f1: 0.1402\n",
      "Epoch 588/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2334 - f1: 0.7491 - val_loss: 0.4655 - val_f1: 0.1401\n",
      "Epoch 589/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2317 - f1: 0.7519 - val_loss: 0.4648 - val_f1: 0.1406\n",
      "Epoch 590/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2337 - f1: 0.7502 - val_loss: 0.4605 - val_f1: 0.1403\n",
      "Epoch 591/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2333 - f1: 0.7494 - val_loss: 0.4656 - val_f1: 0.1395\n",
      "Epoch 592/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2356 - f1: 0.7449 - val_loss: 0.4559 - val_f1: 0.1403\n",
      "Epoch 593/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2348 - f1: 0.7506 - val_loss: 0.4604 - val_f1: 0.1392\n",
      "Epoch 594/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2316 - f1: 0.7502 - val_loss: 0.4557 - val_f1: 0.1393\n",
      "Epoch 595/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2320 - f1: 0.7500 - val_loss: 0.4626 - val_f1: 0.1400\n",
      "Epoch 596/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2319 - f1: 0.7546 - val_loss: 0.4612 - val_f1: 0.1392\n",
      "Epoch 597/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2332 - f1: 0.7503 - val_loss: 0.4612 - val_f1: 0.1393\n",
      "Epoch 598/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2331 - f1: 0.7522 - val_loss: 0.4631 - val_f1: 0.1394\n",
      "Epoch 599/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2329 - f1: 0.7475 - val_loss: 0.4687 - val_f1: 0.1392\n",
      "Epoch 600/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2319 - f1: 0.7519 - val_loss: 0.4607 - val_f1: 0.1396\n",
      "Epoch 601/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2307 - f1: 0.7520 - val_loss: 0.4749 - val_f1: 0.1393\n",
      "Epoch 602/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2342 - f1: 0.7474 - val_loss: 0.4646 - val_f1: 0.1403\n",
      "Epoch 603/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2316 - f1: 0.7500 - val_loss: 0.4660 - val_f1: 0.1388\n",
      "Epoch 604/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2312 - f1: 0.7523 - val_loss: 0.4707 - val_f1: 0.1395\n",
      "Epoch 605/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2297 - f1: 0.7535 - val_loss: 0.4647 - val_f1: 0.1410\n",
      "Epoch 606/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2337 - f1: 0.7457 - val_loss: 0.4638 - val_f1: 0.1410\n",
      "Epoch 607/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2328 - f1: 0.7551 - val_loss: 0.4621 - val_f1: 0.1392\n",
      "Epoch 608/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2317 - f1: 0.7517 - val_loss: 0.4580 - val_f1: 0.1402\n",
      "Epoch 609/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2306 - f1: 0.7550 - val_loss: 0.4656 - val_f1: 0.1396\n",
      "Epoch 610/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2305 - f1: 0.7570 - val_loss: 0.4681 - val_f1: 0.1400\n",
      "Epoch 611/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2319 - f1: 0.7532 - val_loss: 0.4539 - val_f1: 0.1391\n",
      "Epoch 612/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2276 - f1: 0.7588 - val_loss: 0.4759 - val_f1: 0.1394\n",
      "Epoch 613/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2293 - f1: 0.7558 - val_loss: 0.4714 - val_f1: 0.1397\n",
      "Epoch 614/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2313 - f1: 0.7516 - val_loss: 0.4704 - val_f1: 0.1393\n",
      "Epoch 615/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2280 - f1: 0.7589 - val_loss: 0.4735 - val_f1: 0.1395\n",
      "Epoch 616/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2312 - f1: 0.7529 - val_loss: 0.4710 - val_f1: 0.1388\n",
      "Epoch 617/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2294 - f1: 0.7560 - val_loss: 0.4681 - val_f1: 0.1398\n",
      "Epoch 618/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2295 - f1: 0.7517 - val_loss: 0.4590 - val_f1: 0.1392\n",
      "Epoch 619/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2300 - f1: 0.7504 - val_loss: 0.4720 - val_f1: 0.1397\n",
      "Epoch 620/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2295 - f1: 0.7517 - val_loss: 0.4701 - val_f1: 0.1397\n",
      "Epoch 621/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2311 - f1: 0.7532 - val_loss: 0.4657 - val_f1: 0.1387\n",
      "Epoch 622/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2312 - f1: 0.7514 - val_loss: 0.4601 - val_f1: 0.1387\n",
      "Epoch 623/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.2308 - f1: 0.7535 - val_loss: 0.4625 - val_f1: 0.1402\n",
      "Epoch 624/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2296 - f1: 0.7539 - val_loss: 0.4714 - val_f1: 0.1395\n",
      "Epoch 625/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2285 - f1: 0.7572 - val_loss: 0.4678 - val_f1: 0.1399\n",
      "Epoch 626/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2301 - f1: 0.7514 - val_loss: 0.4682 - val_f1: 0.1390\n",
      "Epoch 627/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2308 - f1: 0.7549 - val_loss: 0.4615 - val_f1: 0.1398\n",
      "Epoch 628/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2280 - f1: 0.7570 - val_loss: 0.4667 - val_f1: 0.1404\n",
      "Epoch 629/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2290 - f1: 0.7583 - val_loss: 0.4647 - val_f1: 0.1389\n",
      "Epoch 630/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2305 - f1: 0.7574 - val_loss: 0.4670 - val_f1: 0.1402\n",
      "Epoch 631/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2270 - f1: 0.7597 - val_loss: 0.4780 - val_f1: 0.1394\n",
      "Epoch 632/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2303 - f1: 0.7528 - val_loss: 0.4698 - val_f1: 0.1401\n",
      "Epoch 633/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2288 - f1: 0.7569 - val_loss: 0.4805 - val_f1: 0.1388\n",
      "Epoch 634/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2294 - f1: 0.7591 - val_loss: 0.4687 - val_f1: 0.1393\n",
      "Epoch 635/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2283 - f1: 0.7526 - val_loss: 0.4660 - val_f1: 0.1395\n",
      "Epoch 636/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2288 - f1: 0.7561 - val_loss: 0.4705 - val_f1: 0.1405\n",
      "Epoch 637/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2293 - f1: 0.7542 - val_loss: 0.4712 - val_f1: 0.1406\n",
      "Epoch 638/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2289 - f1: 0.7577 - val_loss: 0.4688 - val_f1: 0.1399\n",
      "Epoch 639/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2285 - f1: 0.7560 - val_loss: 0.4680 - val_f1: 0.1402\n",
      "Epoch 640/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2278 - f1: 0.7557 - val_loss: 0.4612 - val_f1: 0.1404\n",
      "Epoch 641/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2281 - f1: 0.7597 - val_loss: 0.4685 - val_f1: 0.1407\n",
      "Epoch 642/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2269 - f1: 0.7632 - val_loss: 0.4728 - val_f1: 0.1401\n",
      "Epoch 643/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2287 - f1: 0.7596 - val_loss: 0.4727 - val_f1: 0.1400\n",
      "Epoch 644/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2284 - f1: 0.7563 - val_loss: 0.4656 - val_f1: 0.1404\n",
      "Epoch 645/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2281 - f1: 0.7552 - val_loss: 0.4779 - val_f1: 0.1392\n",
      "Epoch 646/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2285 - f1: 0.7537 - val_loss: 0.4782 - val_f1: 0.1403\n",
      "Epoch 647/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2303 - f1: 0.7518 - val_loss: 0.4675 - val_f1: 0.1396\n",
      "Epoch 648/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2280 - f1: 0.7582 - val_loss: 0.4645 - val_f1: 0.1391\n",
      "Epoch 649/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2259 - f1: 0.7590 - val_loss: 0.4741 - val_f1: 0.1404\n",
      "Epoch 650/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2284 - f1: 0.7545 - val_loss: 0.4670 - val_f1: 0.1397\n",
      "Epoch 651/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2269 - f1: 0.7571 - val_loss: 0.4671 - val_f1: 0.1409\n",
      "Epoch 652/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2269 - f1: 0.7548 - val_loss: 0.4718 - val_f1: 0.1398\n",
      "Epoch 653/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2266 - f1: 0.7592 - val_loss: 0.4744 - val_f1: 0.1395\n",
      "Epoch 654/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2258 - f1: 0.7620 - val_loss: 0.4686 - val_f1: 0.1401\n",
      "Epoch 655/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2274 - f1: 0.7564 - val_loss: 0.4785 - val_f1: 0.1394\n",
      "Epoch 656/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2275 - f1: 0.7589 - val_loss: 0.4715 - val_f1: 0.1390\n",
      "Epoch 657/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2243 - f1: 0.7619 - val_loss: 0.4753 - val_f1: 0.1395\n",
      "Epoch 658/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2259 - f1: 0.7591 - val_loss: 0.4636 - val_f1: 0.1407\n",
      "Epoch 659/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2260 - f1: 0.7575 - val_loss: 0.4833 - val_f1: 0.1398\n",
      "Epoch 660/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2238 - f1: 0.7537 - val_loss: 0.4875 - val_f1: 0.1403\n",
      "Epoch 661/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2285 - f1: 0.7538 - val_loss: 0.4646 - val_f1: 0.1404\n",
      "Epoch 662/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2274 - f1: 0.7603 - val_loss: 0.4767 - val_f1: 0.1386\n",
      "Epoch 663/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2282 - f1: 0.7583 - val_loss: 0.4649 - val_f1: 0.1402\n",
      "Epoch 664/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2256 - f1: 0.7584 - val_loss: 0.4794 - val_f1: 0.1401\n",
      "Epoch 665/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2264 - f1: 0.7565 - val_loss: 0.4658 - val_f1: 0.1398\n",
      "Epoch 666/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2264 - f1: 0.7590 - val_loss: 0.4689 - val_f1: 0.1393\n",
      "Epoch 667/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2242 - f1: 0.7617 - val_loss: 0.4624 - val_f1: 0.1400\n",
      "Epoch 668/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2257 - f1: 0.7622 - val_loss: 0.4796 - val_f1: 0.1398\n",
      "Epoch 669/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2258 - f1: 0.7578 - val_loss: 0.4664 - val_f1: 0.1399\n",
      "Epoch 670/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2244 - f1: 0.7614 - val_loss: 0.4765 - val_f1: 0.1396\n",
      "Epoch 671/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2250 - f1: 0.7610 - val_loss: 0.4785 - val_f1: 0.1405\n",
      "Epoch 672/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2249 - f1: 0.7636 - val_loss: 0.4747 - val_f1: 0.1392\n",
      "Epoch 673/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2273 - f1: 0.7584 - val_loss: 0.4739 - val_f1: 0.1392\n",
      "Epoch 674/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2243 - f1: 0.7615 - val_loss: 0.4809 - val_f1: 0.1395\n",
      "Epoch 675/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2251 - f1: 0.7588 - val_loss: 0.4829 - val_f1: 0.1398\n",
      "Epoch 676/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2236 - f1: 0.7589 - val_loss: 0.4732 - val_f1: 0.1411\n",
      "Epoch 677/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2224 - f1: 0.7628 - val_loss: 0.4669 - val_f1: 0.1400\n",
      "Epoch 678/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2256 - f1: 0.7592 - val_loss: 0.4709 - val_f1: 0.1393\n",
      "Epoch 679/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2241 - f1: 0.7580 - val_loss: 0.4779 - val_f1: 0.1407\n",
      "Epoch 680/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2248 - f1: 0.7618 - val_loss: 0.4656 - val_f1: 0.1389\n",
      "Epoch 681/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2234 - f1: 0.7637 - val_loss: 0.4692 - val_f1: 0.1395\n",
      "Epoch 682/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2275 - f1: 0.7581 - val_loss: 0.4710 - val_f1: 0.1392\n",
      "Epoch 683/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2236 - f1: 0.7630 - val_loss: 0.4766 - val_f1: 0.1392\n",
      "Epoch 684/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2262 - f1: 0.7569 - val_loss: 0.4740 - val_f1: 0.1397\n",
      "Epoch 685/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2253 - f1: 0.7624 - val_loss: 0.4853 - val_f1: 0.1392\n",
      "Epoch 686/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2232 - f1: 0.7622 - val_loss: 0.4738 - val_f1: 0.1393\n",
      "Epoch 687/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2223 - f1: 0.7632 - val_loss: 0.4881 - val_f1: 0.1395\n",
      "Epoch 688/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2212 - f1: 0.7682 - val_loss: 0.4744 - val_f1: 0.1399\n",
      "Epoch 689/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2245 - f1: 0.7617 - val_loss: 0.4781 - val_f1: 0.1396\n",
      "Epoch 690/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2238 - f1: 0.7635 - val_loss: 0.4698 - val_f1: 0.1401\n",
      "Epoch 691/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2250 - f1: 0.7580 - val_loss: 0.4779 - val_f1: 0.1404\n",
      "Epoch 692/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2232 - f1: 0.7627 - val_loss: 0.4776 - val_f1: 0.1402\n",
      "Epoch 693/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2227 - f1: 0.7615 - val_loss: 0.4838 - val_f1: 0.1402\n",
      "Epoch 694/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2240 - f1: 0.7597 - val_loss: 0.4705 - val_f1: 0.1403\n",
      "Epoch 695/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2245 - f1: 0.7610 - val_loss: 0.4801 - val_f1: 0.1402\n",
      "Epoch 696/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2233 - f1: 0.7645 - val_loss: 0.4828 - val_f1: 0.1389\n",
      "Epoch 697/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2243 - f1: 0.7608 - val_loss: 0.4792 - val_f1: 0.1394\n",
      "Epoch 698/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2231 - f1: 0.7642 - val_loss: 0.4812 - val_f1: 0.1392\n",
      "Epoch 699/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2244 - f1: 0.7635 - val_loss: 0.4667 - val_f1: 0.1403\n",
      "Epoch 700/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2234 - f1: 0.7590 - val_loss: 0.4801 - val_f1: 0.1401\n",
      "Epoch 701/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2225 - f1: 0.7652 - val_loss: 0.4723 - val_f1: 0.1387\n",
      "Epoch 702/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2226 - f1: 0.7590 - val_loss: 0.4768 - val_f1: 0.1393\n",
      "Epoch 703/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2224 - f1: 0.7603 - val_loss: 0.4779 - val_f1: 0.1392\n",
      "Epoch 704/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2214 - f1: 0.7639 - val_loss: 0.4742 - val_f1: 0.1403\n",
      "Epoch 705/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2212 - f1: 0.7667 - val_loss: 0.4832 - val_f1: 0.1398\n",
      "Epoch 706/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2207 - f1: 0.7627 - val_loss: 0.4842 - val_f1: 0.1391\n",
      "Epoch 707/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2233 - f1: 0.7654 - val_loss: 0.4748 - val_f1: 0.1393\n",
      "Epoch 708/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2253 - f1: 0.7556 - val_loss: 0.4730 - val_f1: 0.1399\n",
      "Epoch 709/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2196 - f1: 0.7688 - val_loss: 0.4774 - val_f1: 0.1394\n",
      "Epoch 710/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2227 - f1: 0.7660 - val_loss: 0.4869 - val_f1: 0.1393\n",
      "Epoch 711/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2233 - f1: 0.7642 - val_loss: 0.4770 - val_f1: 0.1394\n",
      "Epoch 712/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2241 - f1: 0.7656 - val_loss: 0.4794 - val_f1: 0.1394\n",
      "Epoch 713/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2224 - f1: 0.7645 - val_loss: 0.4793 - val_f1: 0.1401\n",
      "Epoch 714/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2204 - f1: 0.7655 - val_loss: 0.4832 - val_f1: 0.1399\n",
      "Epoch 715/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2218 - f1: 0.7637 - val_loss: 0.4760 - val_f1: 0.1414\n",
      "Epoch 716/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2217 - f1: 0.7664 - val_loss: 0.4830 - val_f1: 0.1399\n",
      "Epoch 717/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2208 - f1: 0.7627 - val_loss: 0.4721 - val_f1: 0.1404\n",
      "Epoch 718/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2233 - f1: 0.7629 - val_loss: 0.4861 - val_f1: 0.1403\n",
      "Epoch 719/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2226 - f1: 0.7621 - val_loss: 0.4692 - val_f1: 0.1400\n",
      "Epoch 720/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2214 - f1: 0.7641 - val_loss: 0.4719 - val_f1: 0.1397\n",
      "Epoch 721/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2213 - f1: 0.7648 - val_loss: 0.4798 - val_f1: 0.1392\n",
      "Epoch 722/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2211 - f1: 0.7666 - val_loss: 0.4863 - val_f1: 0.1395\n",
      "Epoch 723/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2222 - f1: 0.7592 - val_loss: 0.4878 - val_f1: 0.1393\n",
      "Epoch 724/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2230 - f1: 0.7663 - val_loss: 0.4769 - val_f1: 0.1392\n",
      "Epoch 725/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2188 - f1: 0.7714 - val_loss: 0.4789 - val_f1: 0.1393\n",
      "Epoch 726/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2230 - f1: 0.7642 - val_loss: 0.4739 - val_f1: 0.1393\n",
      "Epoch 727/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2204 - f1: 0.7661 - val_loss: 0.4804 - val_f1: 0.1399\n",
      "Epoch 728/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2184 - f1: 0.7703 - val_loss: 0.4769 - val_f1: 0.1404\n",
      "Epoch 729/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2210 - f1: 0.7657 - val_loss: 0.4724 - val_f1: 0.1402\n",
      "Epoch 730/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2251 - f1: 0.7635 - val_loss: 0.4765 - val_f1: 0.1402\n",
      "Epoch 731/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2206 - f1: 0.7638 - val_loss: 0.4845 - val_f1: 0.1398\n",
      "Epoch 732/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2214 - f1: 0.7649 - val_loss: 0.4856 - val_f1: 0.1396\n",
      "Epoch 733/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2215 - f1: 0.7599 - val_loss: 0.4736 - val_f1: 0.1392\n",
      "Epoch 734/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2208 - f1: 0.7643 - val_loss: 0.4780 - val_f1: 0.1408\n",
      "Epoch 735/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2201 - f1: 0.7669 - val_loss: 0.4836 - val_f1: 0.1398\n",
      "Epoch 736/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2207 - f1: 0.7646 - val_loss: 0.4838 - val_f1: 0.1395\n",
      "Epoch 737/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2217 - f1: 0.7626 - val_loss: 0.4770 - val_f1: 0.1392\n",
      "Epoch 738/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2209 - f1: 0.7688 - val_loss: 0.4766 - val_f1: 0.1404\n",
      "Epoch 739/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2207 - f1: 0.7699 - val_loss: 0.4725 - val_f1: 0.1404\n",
      "Epoch 740/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2197 - f1: 0.7651 - val_loss: 0.4911 - val_f1: 0.1404\n",
      "Epoch 741/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2210 - f1: 0.7680 - val_loss: 0.4777 - val_f1: 0.1400\n",
      "Epoch 742/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2197 - f1: 0.7665 - val_loss: 0.4832 - val_f1: 0.1400\n",
      "Epoch 743/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2184 - f1: 0.7711 - val_loss: 0.4858 - val_f1: 0.1396\n",
      "Epoch 744/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2203 - f1: 0.7683 - val_loss: 0.4793 - val_f1: 0.1403\n",
      "Epoch 745/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2206 - f1: 0.7649 - val_loss: 0.4822 - val_f1: 0.1400\n",
      "Epoch 746/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2209 - f1: 0.7672 - val_loss: 0.4843 - val_f1: 0.1399\n",
      "Epoch 747/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2181 - f1: 0.7725 - val_loss: 0.4836 - val_f1: 0.1398\n",
      "Epoch 748/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2204 - f1: 0.7648 - val_loss: 0.4700 - val_f1: 0.1390\n",
      "Epoch 749/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2198 - f1: 0.7642 - val_loss: 0.4818 - val_f1: 0.1401\n",
      "Epoch 750/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2184 - f1: 0.7660 - val_loss: 0.4905 - val_f1: 0.1399\n",
      "Epoch 751/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2217 - f1: 0.7672 - val_loss: 0.4813 - val_f1: 0.1406\n",
      "Epoch 752/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2177 - f1: 0.7725 - val_loss: 0.4946 - val_f1: 0.1388\n",
      "Epoch 753/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2206 - f1: 0.7664 - val_loss: 0.4815 - val_f1: 0.1398\n",
      "Epoch 754/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2190 - f1: 0.7652 - val_loss: 0.4766 - val_f1: 0.1393\n",
      "Epoch 755/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2167 - f1: 0.7708 - val_loss: 0.4839 - val_f1: 0.1392\n",
      "Epoch 756/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2202 - f1: 0.7660 - val_loss: 0.4814 - val_f1: 0.1398\n",
      "Epoch 757/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2184 - f1: 0.7671 - val_loss: 0.4796 - val_f1: 0.1399\n",
      "Epoch 758/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2191 - f1: 0.7685 - val_loss: 0.4816 - val_f1: 0.1398\n",
      "Epoch 759/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2191 - f1: 0.7677 - val_loss: 0.4854 - val_f1: 0.1382\n",
      "Epoch 760/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2195 - f1: 0.7670 - val_loss: 0.4826 - val_f1: 0.1395\n",
      "Epoch 761/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2175 - f1: 0.7714 - val_loss: 0.4864 - val_f1: 0.1392\n",
      "Epoch 762/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2207 - f1: 0.7660 - val_loss: 0.4780 - val_f1: 0.1393\n",
      "Epoch 763/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2199 - f1: 0.7663 - val_loss: 0.4802 - val_f1: 0.1398\n",
      "Epoch 764/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2175 - f1: 0.7672 - val_loss: 0.4865 - val_f1: 0.1398\n",
      "Epoch 765/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.2173 - f1: 0.7713 - val_loss: 0.4951 - val_f1: 0.1399\n",
      "Epoch 766/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2179 - f1: 0.7707 - val_loss: 0.4809 - val_f1: 0.1388\n",
      "Epoch 767/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2202 - f1: 0.7652 - val_loss: 0.4758 - val_f1: 0.1401\n",
      "Epoch 768/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2186 - f1: 0.7696 - val_loss: 0.4729 - val_f1: 0.1387\n",
      "Epoch 769/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2166 - f1: 0.7723 - val_loss: 0.4832 - val_f1: 0.1401\n",
      "Epoch 770/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2190 - f1: 0.7644 - val_loss: 0.4801 - val_f1: 0.1393\n",
      "Epoch 771/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2188 - f1: 0.7676 - val_loss: 0.4849 - val_f1: 0.1406\n",
      "Epoch 772/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2177 - f1: 0.7709 - val_loss: 0.4783 - val_f1: 0.1400\n",
      "Epoch 773/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2165 - f1: 0.7735 - val_loss: 0.4893 - val_f1: 0.1392\n",
      "Epoch 774/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2192 - f1: 0.7666 - val_loss: 0.4844 - val_f1: 0.1400\n",
      "Epoch 775/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2161 - f1: 0.7728 - val_loss: 0.4810 - val_f1: 0.1395\n",
      "Epoch 776/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2184 - f1: 0.7707 - val_loss: 0.4807 - val_f1: 0.1392\n",
      "Epoch 777/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2179 - f1: 0.7665 - val_loss: 0.4805 - val_f1: 0.1406\n",
      "Epoch 778/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2185 - f1: 0.7698 - val_loss: 0.4820 - val_f1: 0.1392\n",
      "Epoch 779/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2173 - f1: 0.7680 - val_loss: 0.4980 - val_f1: 0.1390\n",
      "Epoch 780/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2191 - f1: 0.7678 - val_loss: 0.4808 - val_f1: 0.1399\n",
      "Epoch 781/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2152 - f1: 0.7713 - val_loss: 0.4830 - val_f1: 0.1399\n",
      "Epoch 782/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2187 - f1: 0.7725 - val_loss: 0.4780 - val_f1: 0.1395\n",
      "Epoch 783/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2181 - f1: 0.7691 - val_loss: 0.4838 - val_f1: 0.1392\n",
      "Epoch 784/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2163 - f1: 0.7707 - val_loss: 0.4769 - val_f1: 0.1405\n",
      "Epoch 785/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2157 - f1: 0.7723 - val_loss: 0.4847 - val_f1: 0.1399\n",
      "Epoch 786/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2180 - f1: 0.7686 - val_loss: 0.4896 - val_f1: 0.1401\n",
      "Epoch 787/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2178 - f1: 0.7648 - val_loss: 0.4788 - val_f1: 0.1392\n",
      "Epoch 788/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2178 - f1: 0.7682 - val_loss: 0.4886 - val_f1: 0.1398\n",
      "Epoch 789/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2182 - f1: 0.7663 - val_loss: 0.4861 - val_f1: 0.1395\n",
      "Epoch 790/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2146 - f1: 0.7719 - val_loss: 0.4789 - val_f1: 0.1403\n",
      "Epoch 791/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2165 - f1: 0.7725 - val_loss: 0.4921 - val_f1: 0.1402\n",
      "Epoch 792/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2159 - f1: 0.7747 - val_loss: 0.4929 - val_f1: 0.1396\n",
      "Epoch 793/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2149 - f1: 0.7695 - val_loss: 0.4839 - val_f1: 0.1400\n",
      "Epoch 794/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2163 - f1: 0.7719 - val_loss: 0.4825 - val_f1: 0.1395\n",
      "Epoch 795/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2150 - f1: 0.7732 - val_loss: 0.4941 - val_f1: 0.1393\n",
      "Epoch 796/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2159 - f1: 0.7746 - val_loss: 0.4891 - val_f1: 0.1396\n",
      "Epoch 797/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2154 - f1: 0.7757 - val_loss: 0.4857 - val_f1: 0.1391\n",
      "Epoch 798/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2161 - f1: 0.7726 - val_loss: 0.4995 - val_f1: 0.1391\n",
      "Epoch 799/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2154 - f1: 0.7699 - val_loss: 0.4875 - val_f1: 0.1389\n",
      "Epoch 800/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2148 - f1: 0.7699 - val_loss: 0.4906 - val_f1: 0.1404\n",
      "Epoch 801/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2175 - f1: 0.7702 - val_loss: 0.4894 - val_f1: 0.1394\n",
      "Epoch 802/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2155 - f1: 0.7729 - val_loss: 0.4864 - val_f1: 0.1389\n",
      "Epoch 803/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2160 - f1: 0.7755 - val_loss: 0.4876 - val_f1: 0.1387\n",
      "Epoch 804/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2150 - f1: 0.7728 - val_loss: 0.4991 - val_f1: 0.1390\n",
      "Epoch 805/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2166 - f1: 0.7700 - val_loss: 0.4871 - val_f1: 0.1396\n",
      "Epoch 806/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2173 - f1: 0.7705 - val_loss: 0.4866 - val_f1: 0.1391\n",
      "Epoch 807/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2172 - f1: 0.7684 - val_loss: 0.4774 - val_f1: 0.1385\n",
      "Epoch 808/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2152 - f1: 0.7724 - val_loss: 0.4948 - val_f1: 0.1387\n",
      "Epoch 809/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2152 - f1: 0.7707 - val_loss: 0.4813 - val_f1: 0.1399\n",
      "Epoch 810/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2165 - f1: 0.7689 - val_loss: 0.4869 - val_f1: 0.1395\n",
      "Epoch 811/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2155 - f1: 0.7692 - val_loss: 0.4827 - val_f1: 0.1395\n",
      "Epoch 812/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2155 - f1: 0.7698 - val_loss: 0.4862 - val_f1: 0.1397\n",
      "Epoch 813/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2162 - f1: 0.7713 - val_loss: 0.4857 - val_f1: 0.1401\n",
      "Epoch 814/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2130 - f1: 0.7783 - val_loss: 0.4868 - val_f1: 0.1397\n",
      "Epoch 815/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2153 - f1: 0.7746 - val_loss: 0.4821 - val_f1: 0.1406\n",
      "Epoch 816/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2137 - f1: 0.7762 - val_loss: 0.4895 - val_f1: 0.1393\n",
      "Epoch 817/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2128 - f1: 0.7760 - val_loss: 0.4891 - val_f1: 0.1397\n",
      "Epoch 818/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2144 - f1: 0.7746 - val_loss: 0.4886 - val_f1: 0.1396\n",
      "Epoch 819/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2159 - f1: 0.7694 - val_loss: 0.4941 - val_f1: 0.1395\n",
      "Epoch 820/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2162 - f1: 0.7720 - val_loss: 0.4914 - val_f1: 0.1397\n",
      "Epoch 821/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2144 - f1: 0.7725 - val_loss: 0.4852 - val_f1: 0.1402\n",
      "Epoch 822/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2150 - f1: 0.7697 - val_loss: 0.4907 - val_f1: 0.1394\n",
      "Epoch 823/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2161 - f1: 0.7706 - val_loss: 0.4786 - val_f1: 0.1399\n",
      "Epoch 824/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2163 - f1: 0.7719 - val_loss: 0.4850 - val_f1: 0.1395\n",
      "Epoch 825/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2167 - f1: 0.7706 - val_loss: 0.4853 - val_f1: 0.1391\n",
      "Epoch 826/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2145 - f1: 0.7726 - val_loss: 0.4872 - val_f1: 0.1392\n",
      "Epoch 827/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2140 - f1: 0.7721 - val_loss: 0.4904 - val_f1: 0.1398\n",
      "Epoch 828/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2135 - f1: 0.7791 - val_loss: 0.4891 - val_f1: 0.1392\n",
      "Epoch 829/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2125 - f1: 0.7717 - val_loss: 0.4961 - val_f1: 0.1393\n",
      "Epoch 830/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2113 - f1: 0.7810 - val_loss: 0.4983 - val_f1: 0.1395\n",
      "Epoch 831/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2146 - f1: 0.7731 - val_loss: 0.4960 - val_f1: 0.1384\n",
      "Epoch 832/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2153 - f1: 0.7717 - val_loss: 0.4924 - val_f1: 0.1388\n",
      "Epoch 833/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2123 - f1: 0.7744 - val_loss: 0.4918 - val_f1: 0.1391\n",
      "Epoch 834/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2129 - f1: 0.7762 - val_loss: 0.4930 - val_f1: 0.1397\n",
      "Epoch 835/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2153 - f1: 0.7730 - val_loss: 0.4979 - val_f1: 0.1392\n",
      "Epoch 836/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2159 - f1: 0.7701 - val_loss: 0.4945 - val_f1: 0.1390\n",
      "Epoch 837/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2157 - f1: 0.7719 - val_loss: 0.4873 - val_f1: 0.1391\n",
      "Epoch 838/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2132 - f1: 0.7760 - val_loss: 0.4956 - val_f1: 0.1397\n",
      "Epoch 839/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2133 - f1: 0.7782 - val_loss: 0.4905 - val_f1: 0.1387\n",
      "Epoch 840/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2127 - f1: 0.7742 - val_loss: 0.4869 - val_f1: 0.1391\n",
      "Epoch 841/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2133 - f1: 0.7729 - val_loss: 0.4921 - val_f1: 0.1392\n",
      "Epoch 842/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2122 - f1: 0.7739 - val_loss: 0.5004 - val_f1: 0.1388\n",
      "Epoch 843/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2133 - f1: 0.7743 - val_loss: 0.4871 - val_f1: 0.1402\n",
      "Epoch 844/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2107 - f1: 0.7804 - val_loss: 0.4980 - val_f1: 0.1392\n",
      "Epoch 845/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2115 - f1: 0.7783 - val_loss: 0.4921 - val_f1: 0.1395\n",
      "Epoch 846/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2111 - f1: 0.7769 - val_loss: 0.5003 - val_f1: 0.1387\n",
      "Epoch 847/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2127 - f1: 0.7759 - val_loss: 0.4954 - val_f1: 0.1400\n",
      "Epoch 848/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2125 - f1: 0.7778 - val_loss: 0.4915 - val_f1: 0.1391\n",
      "Epoch 849/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2114 - f1: 0.7778 - val_loss: 0.4994 - val_f1: 0.1400\n",
      "Epoch 850/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2144 - f1: 0.7720 - val_loss: 0.4904 - val_f1: 0.1393\n",
      "Epoch 851/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2096 - f1: 0.7818 - val_loss: 0.4949 - val_f1: 0.1393\n",
      "Epoch 852/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2108 - f1: 0.7785 - val_loss: 0.5001 - val_f1: 0.1386\n",
      "Epoch 853/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2119 - f1: 0.7744 - val_loss: 0.4924 - val_f1: 0.1388\n",
      "Epoch 854/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2153 - f1: 0.7707 - val_loss: 0.4848 - val_f1: 0.1388\n",
      "Epoch 855/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2121 - f1: 0.7759 - val_loss: 0.4951 - val_f1: 0.1387\n",
      "Epoch 856/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2127 - f1: 0.7763 - val_loss: 0.4878 - val_f1: 0.1395\n",
      "Epoch 857/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2120 - f1: 0.7769 - val_loss: 0.4903 - val_f1: 0.1395\n",
      "Epoch 858/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2109 - f1: 0.7781 - val_loss: 0.5002 - val_f1: 0.1390\n",
      "Epoch 859/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2145 - f1: 0.7726 - val_loss: 0.4819 - val_f1: 0.1397\n",
      "Epoch 860/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2134 - f1: 0.7744 - val_loss: 0.4953 - val_f1: 0.1394\n",
      "Epoch 861/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2154 - f1: 0.7768 - val_loss: 0.4911 - val_f1: 0.1397\n",
      "Epoch 862/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2136 - f1: 0.7731 - val_loss: 0.4961 - val_f1: 0.1392\n",
      "Epoch 863/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2110 - f1: 0.7798 - val_loss: 0.4908 - val_f1: 0.1390\n",
      "Epoch 864/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2116 - f1: 0.7760 - val_loss: 0.4860 - val_f1: 0.1393\n",
      "Epoch 865/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2120 - f1: 0.7745 - val_loss: 0.4943 - val_f1: 0.1388\n",
      "Epoch 866/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2101 - f1: 0.7813 - val_loss: 0.4928 - val_f1: 0.1383\n",
      "Epoch 867/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2121 - f1: 0.7756 - val_loss: 0.4910 - val_f1: 0.1389\n",
      "Epoch 868/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2122 - f1: 0.7790 - val_loss: 0.4867 - val_f1: 0.1394\n",
      "Epoch 869/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2114 - f1: 0.7779 - val_loss: 0.4888 - val_f1: 0.1396\n",
      "Epoch 870/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2112 - f1: 0.7766 - val_loss: 0.4941 - val_f1: 0.1388\n",
      "Epoch 871/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2140 - f1: 0.7734 - val_loss: 0.4949 - val_f1: 0.1389\n",
      "Epoch 872/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2145 - f1: 0.7717 - val_loss: 0.4847 - val_f1: 0.1392\n",
      "Epoch 873/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2127 - f1: 0.7776 - val_loss: 0.4956 - val_f1: 0.1394\n",
      "Epoch 874/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2135 - f1: 0.7754 - val_loss: 0.4918 - val_f1: 0.1387\n",
      "Epoch 875/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2125 - f1: 0.7754 - val_loss: 0.4941 - val_f1: 0.1396\n",
      "Epoch 876/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2131 - f1: 0.7752 - val_loss: 0.4850 - val_f1: 0.1401\n",
      "Epoch 877/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2122 - f1: 0.7734 - val_loss: 0.5027 - val_f1: 0.1387\n",
      "Epoch 878/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2112 - f1: 0.7728 - val_loss: 0.4997 - val_f1: 0.1394\n",
      "Epoch 879/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2108 - f1: 0.7759 - val_loss: 0.5039 - val_f1: 0.1373\n",
      "Epoch 880/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2106 - f1: 0.7799 - val_loss: 0.4946 - val_f1: 0.1389\n",
      "Epoch 881/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2087 - f1: 0.7829 - val_loss: 0.4931 - val_f1: 0.1387\n",
      "Epoch 882/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2080 - f1: 0.7819 - val_loss: 0.4933 - val_f1: 0.1385\n",
      "Epoch 883/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2125 - f1: 0.7768 - val_loss: 0.5058 - val_f1: 0.1377\n",
      "Epoch 884/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2105 - f1: 0.7802 - val_loss: 0.4838 - val_f1: 0.1393\n",
      "Epoch 885/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2145 - f1: 0.7734 - val_loss: 0.4833 - val_f1: 0.1381\n",
      "Epoch 886/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2121 - f1: 0.7732 - val_loss: 0.4943 - val_f1: 0.1393\n",
      "Epoch 887/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2117 - f1: 0.7777 - val_loss: 0.4990 - val_f1: 0.1393\n",
      "Epoch 888/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2097 - f1: 0.7797 - val_loss: 0.4884 - val_f1: 0.1383\n",
      "Epoch 889/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2091 - f1: 0.7752 - val_loss: 0.5015 - val_f1: 0.1389\n",
      "Epoch 890/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2098 - f1: 0.7781 - val_loss: 0.5066 - val_f1: 0.1395\n",
      "Epoch 891/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.2108 - f1: 0.7784 - val_loss: 0.4960 - val_f1: 0.1395\n",
      "Epoch 892/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2117 - f1: 0.7776 - val_loss: 0.4947 - val_f1: 0.1388\n",
      "Epoch 893/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2079 - f1: 0.7817 - val_loss: 0.4922 - val_f1: 0.1385\n",
      "Epoch 894/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2094 - f1: 0.7774 - val_loss: 0.4953 - val_f1: 0.1388\n",
      "Epoch 895/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2129 - f1: 0.7786 - val_loss: 0.5005 - val_f1: 0.1392\n",
      "Epoch 896/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2104 - f1: 0.7782 - val_loss: 0.4916 - val_f1: 0.1392\n",
      "Epoch 897/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2101 - f1: 0.7829 - val_loss: 0.4978 - val_f1: 0.1394\n",
      "Epoch 898/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2104 - f1: 0.7773 - val_loss: 0.5043 - val_f1: 0.1388\n",
      "Epoch 899/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2094 - f1: 0.7807 - val_loss: 0.5004 - val_f1: 0.1389\n",
      "Epoch 900/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2082 - f1: 0.7829 - val_loss: 0.4880 - val_f1: 0.1397\n",
      "Epoch 901/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2107 - f1: 0.7837 - val_loss: 0.4922 - val_f1: 0.1389\n",
      "Epoch 902/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2075 - f1: 0.7838 - val_loss: 0.4997 - val_f1: 0.1386\n",
      "Epoch 903/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2094 - f1: 0.7775 - val_loss: 0.4894 - val_f1: 0.1387\n",
      "Epoch 904/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2103 - f1: 0.7770 - val_loss: 0.5003 - val_f1: 0.1396\n",
      "Epoch 905/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2109 - f1: 0.7775 - val_loss: 0.5028 - val_f1: 0.1387\n",
      "Epoch 906/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2100 - f1: 0.7763 - val_loss: 0.4922 - val_f1: 0.1393\n",
      "Epoch 907/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2094 - f1: 0.7810 - val_loss: 0.4929 - val_f1: 0.1383\n",
      "Epoch 908/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2084 - f1: 0.7833 - val_loss: 0.4986 - val_f1: 0.1387\n",
      "Epoch 909/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2116 - f1: 0.7784 - val_loss: 0.4934 - val_f1: 0.1388\n",
      "Epoch 910/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2096 - f1: 0.7813 - val_loss: 0.4898 - val_f1: 0.1383\n",
      "Epoch 911/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2096 - f1: 0.7801 - val_loss: 0.4964 - val_f1: 0.1398\n",
      "Epoch 912/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2111 - f1: 0.7819 - val_loss: 0.4871 - val_f1: 0.1390\n",
      "Epoch 913/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2106 - f1: 0.7802 - val_loss: 0.4978 - val_f1: 0.1390\n",
      "Epoch 914/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2057 - f1: 0.7815 - val_loss: 0.4930 - val_f1: 0.1391\n",
      "Epoch 915/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2095 - f1: 0.7794 - val_loss: 0.4899 - val_f1: 0.1394\n",
      "Epoch 916/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2114 - f1: 0.7781 - val_loss: 0.5022 - val_f1: 0.1382\n",
      "Epoch 917/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2083 - f1: 0.7791 - val_loss: 0.5035 - val_f1: 0.1391\n",
      "Epoch 918/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2090 - f1: 0.7797 - val_loss: 0.4917 - val_f1: 0.1388\n",
      "Epoch 919/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2099 - f1: 0.7812 - val_loss: 0.4964 - val_f1: 0.1386\n",
      "Epoch 920/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.2043 - f1: 0.7863 - val_loss: 0.5189 - val_f1: 0.1387\n",
      "Epoch 921/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2090 - f1: 0.7834 - val_loss: 0.4991 - val_f1: 0.1387\n",
      "Epoch 922/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2088 - f1: 0.7789 - val_loss: 0.5081 - val_f1: 0.1387\n",
      "Epoch 923/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2103 - f1: 0.7736 - val_loss: 0.4940 - val_f1: 0.1395\n",
      "Epoch 924/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2083 - f1: 0.7820 - val_loss: 0.5005 - val_f1: 0.1379\n",
      "Epoch 925/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2102 - f1: 0.7798 - val_loss: 0.4894 - val_f1: 0.1386\n",
      "Epoch 926/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2093 - f1: 0.7798 - val_loss: 0.4972 - val_f1: 0.1384\n",
      "Epoch 927/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2078 - f1: 0.7821 - val_loss: 0.4934 - val_f1: 0.1391\n",
      "Epoch 928/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2071 - f1: 0.7809 - val_loss: 0.5000 - val_f1: 0.1388\n",
      "Epoch 929/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2086 - f1: 0.7818 - val_loss: 0.5020 - val_f1: 0.1379\n",
      "Epoch 930/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2090 - f1: 0.7797 - val_loss: 0.4956 - val_f1: 0.1396\n",
      "Epoch 931/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2078 - f1: 0.7828 - val_loss: 0.5007 - val_f1: 0.1391\n",
      "Epoch 932/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2061 - f1: 0.7886 - val_loss: 0.4981 - val_f1: 0.1381\n",
      "Epoch 933/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2079 - f1: 0.7833 - val_loss: 0.4924 - val_f1: 0.1397\n",
      "Epoch 934/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2101 - f1: 0.7780 - val_loss: 0.4904 - val_f1: 0.1381\n",
      "Epoch 935/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2069 - f1: 0.7829 - val_loss: 0.5044 - val_f1: 0.1381\n",
      "Epoch 936/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2083 - f1: 0.7827 - val_loss: 0.5023 - val_f1: 0.1394\n",
      "Epoch 937/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2083 - f1: 0.7810 - val_loss: 0.5076 - val_f1: 0.1389\n",
      "Epoch 938/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2061 - f1: 0.7851 - val_loss: 0.5010 - val_f1: 0.1388\n",
      "Epoch 939/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2093 - f1: 0.7820 - val_loss: 0.4834 - val_f1: 0.1388\n",
      "Epoch 940/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2075 - f1: 0.7850 - val_loss: 0.5030 - val_f1: 0.1396\n",
      "Epoch 941/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2068 - f1: 0.7829 - val_loss: 0.4965 - val_f1: 0.1394\n",
      "Epoch 942/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2073 - f1: 0.7789 - val_loss: 0.5042 - val_f1: 0.1387\n",
      "Epoch 943/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2102 - f1: 0.7776 - val_loss: 0.5015 - val_f1: 0.1388\n",
      "Epoch 944/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2085 - f1: 0.7810 - val_loss: 0.4911 - val_f1: 0.1391\n",
      "Epoch 945/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2078 - f1: 0.7835 - val_loss: 0.5024 - val_f1: 0.1378\n",
      "Epoch 946/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2063 - f1: 0.7838 - val_loss: 0.4997 - val_f1: 0.1394\n",
      "Epoch 947/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2069 - f1: 0.7809 - val_loss: 0.4983 - val_f1: 0.1389\n",
      "Epoch 948/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2092 - f1: 0.7785 - val_loss: 0.4901 - val_f1: 0.1387\n",
      "Epoch 949/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2079 - f1: 0.7818 - val_loss: 0.5044 - val_f1: 0.1386\n",
      "Epoch 950/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2065 - f1: 0.7859 - val_loss: 0.5082 - val_f1: 0.1385\n",
      "Epoch 951/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2062 - f1: 0.7888 - val_loss: 0.4893 - val_f1: 0.1395\n",
      "Epoch 952/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2057 - f1: 0.7821 - val_loss: 0.5055 - val_f1: 0.1388\n",
      "Epoch 953/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2077 - f1: 0.7827 - val_loss: 0.5058 - val_f1: 0.1394\n",
      "Epoch 954/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2094 - f1: 0.7775 - val_loss: 0.5009 - val_f1: 0.1388\n",
      "Epoch 955/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2077 - f1: 0.7823 - val_loss: 0.5000 - val_f1: 0.1383\n",
      "Epoch 956/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2065 - f1: 0.7826 - val_loss: 0.5013 - val_f1: 0.1391\n",
      "Epoch 957/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2060 - f1: 0.7859 - val_loss: 0.5028 - val_f1: 0.1385\n",
      "Epoch 958/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2083 - f1: 0.7837 - val_loss: 0.5013 - val_f1: 0.1384\n",
      "Epoch 959/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2097 - f1: 0.7820 - val_loss: 0.4941 - val_f1: 0.1394\n",
      "Epoch 960/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2078 - f1: 0.7868 - val_loss: 0.4933 - val_f1: 0.1393\n",
      "Epoch 961/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2073 - f1: 0.7808 - val_loss: 0.5030 - val_f1: 0.1388\n",
      "Epoch 962/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2065 - f1: 0.7864 - val_loss: 0.5131 - val_f1: 0.1382\n",
      "Epoch 963/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2059 - f1: 0.7834 - val_loss: 0.5002 - val_f1: 0.1388\n",
      "Epoch 964/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2093 - f1: 0.7839 - val_loss: 0.5049 - val_f1: 0.1380\n",
      "Epoch 965/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2067 - f1: 0.7839 - val_loss: 0.5104 - val_f1: 0.1385\n",
      "Epoch 966/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2044 - f1: 0.7865 - val_loss: 0.5032 - val_f1: 0.1388\n",
      "Epoch 967/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2071 - f1: 0.7875 - val_loss: 0.5011 - val_f1: 0.1393\n",
      "Epoch 968/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2055 - f1: 0.7869 - val_loss: 0.5026 - val_f1: 0.1387\n",
      "Epoch 969/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2054 - f1: 0.7851 - val_loss: 0.5049 - val_f1: 0.1386\n",
      "Epoch 970/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2031 - f1: 0.7897 - val_loss: 0.5113 - val_f1: 0.1385\n",
      "Epoch 971/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2059 - f1: 0.7823 - val_loss: 0.4983 - val_f1: 0.1390\n",
      "Epoch 972/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2076 - f1: 0.7804 - val_loss: 0.5045 - val_f1: 0.1396\n",
      "Epoch 973/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2057 - f1: 0.7821 - val_loss: 0.5046 - val_f1: 0.1387\n",
      "Epoch 974/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2073 - f1: 0.7837 - val_loss: 0.5088 - val_f1: 0.1386\n",
      "Epoch 975/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2068 - f1: 0.7827 - val_loss: 0.5035 - val_f1: 0.1383\n",
      "Epoch 976/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2081 - f1: 0.7839 - val_loss: 0.4910 - val_f1: 0.1389\n",
      "Epoch 977/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2045 - f1: 0.7860 - val_loss: 0.5078 - val_f1: 0.1389\n",
      "Epoch 978/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2065 - f1: 0.7839 - val_loss: 0.4962 - val_f1: 0.1390\n",
      "Epoch 979/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2074 - f1: 0.7847 - val_loss: 0.4924 - val_f1: 0.1387\n",
      "Epoch 980/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2057 - f1: 0.7826 - val_loss: 0.5083 - val_f1: 0.1385\n",
      "Epoch 981/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2061 - f1: 0.7854 - val_loss: 0.4995 - val_f1: 0.1393\n",
      "Epoch 982/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2052 - f1: 0.7848 - val_loss: 0.4936 - val_f1: 0.1388\n",
      "Epoch 983/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2080 - f1: 0.7821 - val_loss: 0.4998 - val_f1: 0.1383\n",
      "Epoch 984/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2075 - f1: 0.7812 - val_loss: 0.5010 - val_f1: 0.1391\n",
      "Epoch 985/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2073 - f1: 0.7808 - val_loss: 0.5061 - val_f1: 0.1393\n",
      "Epoch 986/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2060 - f1: 0.7839 - val_loss: 0.5026 - val_f1: 0.1385\n",
      "Epoch 987/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2035 - f1: 0.7903 - val_loss: 0.5113 - val_f1: 0.1392\n",
      "Epoch 988/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2044 - f1: 0.7866 - val_loss: 0.5082 - val_f1: 0.1386\n",
      "Epoch 989/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2094 - f1: 0.7780 - val_loss: 0.4994 - val_f1: 0.1387\n",
      "Epoch 990/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.2068 - f1: 0.7848 - val_loss: 0.5077 - val_f1: 0.1390\n",
      "Epoch 991/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2049 - f1: 0.7847 - val_loss: 0.5094 - val_f1: 0.1387\n",
      "Epoch 992/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2034 - f1: 0.7877 - val_loss: 0.5008 - val_f1: 0.1385\n",
      "Epoch 993/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2053 - f1: 0.7880 - val_loss: 0.5100 - val_f1: 0.1393\n",
      "Epoch 994/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2047 - f1: 0.7836 - val_loss: 0.4976 - val_f1: 0.1386\n",
      "Epoch 995/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2059 - f1: 0.7875 - val_loss: 0.4937 - val_f1: 0.1394\n",
      "Epoch 996/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2054 - f1: 0.7826 - val_loss: 0.5060 - val_f1: 0.1391\n",
      "Epoch 997/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2026 - f1: 0.7886 - val_loss: 0.5119 - val_f1: 0.1380\n",
      "Epoch 998/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2062 - f1: 0.7845 - val_loss: 0.5051 - val_f1: 0.1385\n",
      "Epoch 999/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2061 - f1: 0.7851 - val_loss: 0.5059 - val_f1: 0.1393\n",
      "Epoch 1000/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2039 - f1: 0.7874 - val_loss: 0.5150 - val_f1: 0.1395\n",
      "Epoch 1001/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2025 - f1: 0.7901 - val_loss: 0.5067 - val_f1: 0.1387\n",
      "Epoch 1002/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2032 - f1: 0.7871 - val_loss: 0.4993 - val_f1: 0.1384\n",
      "Epoch 1003/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2028 - f1: 0.7881 - val_loss: 0.5063 - val_f1: 0.1391\n",
      "Epoch 1004/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.2031 - f1: 0.7894 - val_loss: 0.5087 - val_f1: 0.1384\n",
      "Epoch 1005/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2036 - f1: 0.7870 - val_loss: 0.4963 - val_f1: 0.1384\n",
      "Epoch 1006/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2061 - f1: 0.7851 - val_loss: 0.4980 - val_f1: 0.1379\n",
      "Epoch 1007/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2063 - f1: 0.7822 - val_loss: 0.4976 - val_f1: 0.1383\n",
      "Epoch 1008/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2049 - f1: 0.7856 - val_loss: 0.5007 - val_f1: 0.1386\n",
      "Epoch 1009/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2075 - f1: 0.7817 - val_loss: 0.5053 - val_f1: 0.1389\n",
      "Epoch 1010/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2060 - f1: 0.7850 - val_loss: 0.5022 - val_f1: 0.1392\n",
      "Epoch 1011/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2036 - f1: 0.7872 - val_loss: 0.5030 - val_f1: 0.1392\n",
      "Epoch 1012/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2054 - f1: 0.7846 - val_loss: 0.4966 - val_f1: 0.1387\n",
      "Epoch 1013/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2050 - f1: 0.7870 - val_loss: 0.4939 - val_f1: 0.1389\n",
      "Epoch 1014/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2051 - f1: 0.7863 - val_loss: 0.4988 - val_f1: 0.1394\n",
      "Epoch 1015/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2040 - f1: 0.7844 - val_loss: 0.5093 - val_f1: 0.1388\n",
      "Epoch 1016/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2073 - f1: 0.7828 - val_loss: 0.5023 - val_f1: 0.1385\n",
      "Epoch 1017/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2025 - f1: 0.7866 - val_loss: 0.4973 - val_f1: 0.1377\n",
      "Epoch 1018/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2057 - f1: 0.7856 - val_loss: 0.5057 - val_f1: 0.1382\n",
      "Epoch 1019/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2039 - f1: 0.7902 - val_loss: 0.5014 - val_f1: 0.1386\n",
      "Epoch 1020/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2041 - f1: 0.7864 - val_loss: 0.4981 - val_f1: 0.1384\n",
      "Epoch 1021/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2053 - f1: 0.7911 - val_loss: 0.5133 - val_f1: 0.1389\n",
      "Epoch 1022/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2061 - f1: 0.7846 - val_loss: 0.5027 - val_f1: 0.1387\n",
      "Epoch 1023/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2053 - f1: 0.7863 - val_loss: 0.5006 - val_f1: 0.1389\n",
      "Epoch 1024/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2061 - f1: 0.7850 - val_loss: 0.5008 - val_f1: 0.1388\n",
      "Epoch 1025/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2031 - f1: 0.7861 - val_loss: 0.5035 - val_f1: 0.1399\n",
      "Epoch 1026/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2033 - f1: 0.7906 - val_loss: 0.5080 - val_f1: 0.1392\n",
      "Epoch 1027/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2058 - f1: 0.7866 - val_loss: 0.5057 - val_f1: 0.1394\n",
      "Epoch 1028/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2060 - f1: 0.7863 - val_loss: 0.4985 - val_f1: 0.1379\n",
      "Epoch 1029/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2065 - f1: 0.7822 - val_loss: 0.5025 - val_f1: 0.1378\n",
      "Epoch 1030/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2030 - f1: 0.7873 - val_loss: 0.5079 - val_f1: 0.1384\n",
      "Epoch 1031/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2050 - f1: 0.7872 - val_loss: 0.4943 - val_f1: 0.1393\n",
      "Epoch 1032/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2040 - f1: 0.7866 - val_loss: 0.5040 - val_f1: 0.1390\n",
      "Epoch 1033/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2032 - f1: 0.7879 - val_loss: 0.5045 - val_f1: 0.1398\n",
      "Epoch 1034/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2042 - f1: 0.7842 - val_loss: 0.5021 - val_f1: 0.1394\n",
      "Epoch 1035/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2042 - f1: 0.7841 - val_loss: 0.5121 - val_f1: 0.1385\n",
      "Epoch 1036/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2031 - f1: 0.7879 - val_loss: 0.5039 - val_f1: 0.1387\n",
      "Epoch 1037/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2017 - f1: 0.7889 - val_loss: 0.5112 - val_f1: 0.1390\n",
      "Epoch 1038/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2041 - f1: 0.7873 - val_loss: 0.5081 - val_f1: 0.1388\n",
      "Epoch 1039/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2065 - f1: 0.7816 - val_loss: 0.5036 - val_f1: 0.1382\n",
      "Epoch 1040/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2041 - f1: 0.7818 - val_loss: 0.5117 - val_f1: 0.1380\n",
      "Epoch 1041/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2028 - f1: 0.7878 - val_loss: 0.5084 - val_f1: 0.1378\n",
      "Epoch 1042/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2055 - f1: 0.7877 - val_loss: 0.4885 - val_f1: 0.1379\n",
      "Epoch 1043/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2044 - f1: 0.7888 - val_loss: 0.5116 - val_f1: 0.1383\n",
      "Epoch 1044/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2047 - f1: 0.7854 - val_loss: 0.5069 - val_f1: 0.1389\n",
      "Epoch 1045/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2028 - f1: 0.7871 - val_loss: 0.5049 - val_f1: 0.1386\n",
      "Epoch 1046/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2047 - f1: 0.7868 - val_loss: 0.5068 - val_f1: 0.1393\n",
      "Epoch 1047/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2013 - f1: 0.7916 - val_loss: 0.5077 - val_f1: 0.1384\n",
      "Epoch 1048/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2025 - f1: 0.7928 - val_loss: 0.4944 - val_f1: 0.1384\n",
      "Epoch 1049/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2030 - f1: 0.7841 - val_loss: 0.5005 - val_f1: 0.1388\n",
      "Epoch 1050/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2008 - f1: 0.7914 - val_loss: 0.5058 - val_f1: 0.1385\n",
      "Epoch 1051/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2048 - f1: 0.7877 - val_loss: 0.4972 - val_f1: 0.1385\n",
      "Epoch 1052/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1996 - f1: 0.7940 - val_loss: 0.5086 - val_f1: 0.1390\n",
      "Epoch 1053/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2015 - f1: 0.7862 - val_loss: 0.5031 - val_f1: 0.1388\n",
      "Epoch 1054/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.2041 - f1: 0.7885 - val_loss: 0.5091 - val_f1: 0.1388\n",
      "Epoch 1055/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2040 - f1: 0.7862 - val_loss: 0.5112 - val_f1: 0.1380\n",
      "Epoch 1056/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2058 - f1: 0.7855 - val_loss: 0.5054 - val_f1: 0.1384\n",
      "Epoch 1057/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2045 - f1: 0.7854 - val_loss: 0.5103 - val_f1: 0.1387\n",
      "Epoch 1058/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2020 - f1: 0.7891 - val_loss: 0.5157 - val_f1: 0.1388\n",
      "Epoch 1059/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2037 - f1: 0.7904 - val_loss: 0.5131 - val_f1: 0.1391\n",
      "Epoch 1060/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2037 - f1: 0.7846 - val_loss: 0.5058 - val_f1: 0.1388\n",
      "Epoch 1061/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2010 - f1: 0.7892 - val_loss: 0.5128 - val_f1: 0.1381\n",
      "Epoch 1062/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2048 - f1: 0.7857 - val_loss: 0.5116 - val_f1: 0.1386\n",
      "Epoch 1063/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2024 - f1: 0.7875 - val_loss: 0.5032 - val_f1: 0.1387\n",
      "Epoch 1064/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2033 - f1: 0.7861 - val_loss: 0.5187 - val_f1: 0.1387\n",
      "Epoch 1065/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2031 - f1: 0.7856 - val_loss: 0.5027 - val_f1: 0.1387\n",
      "Epoch 1066/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2029 - f1: 0.7880 - val_loss: 0.5042 - val_f1: 0.1381\n",
      "Epoch 1067/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2014 - f1: 0.7913 - val_loss: 0.5069 - val_f1: 0.1379\n",
      "Epoch 1068/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2001 - f1: 0.7935 - val_loss: 0.5072 - val_f1: 0.1375\n",
      "Epoch 1069/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2015 - f1: 0.7892 - val_loss: 0.5092 - val_f1: 0.1393\n",
      "Epoch 1070/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1994 - f1: 0.7893 - val_loss: 0.5185 - val_f1: 0.1388\n",
      "Epoch 1071/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1998 - f1: 0.7897 - val_loss: 0.5091 - val_f1: 0.1388\n",
      "Epoch 1072/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2047 - f1: 0.7894 - val_loss: 0.5009 - val_f1: 0.1384\n",
      "Epoch 1073/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2015 - f1: 0.7879 - val_loss: 0.5155 - val_f1: 0.1387\n",
      "Epoch 1074/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2019 - f1: 0.7921 - val_loss: 0.5155 - val_f1: 0.1385\n",
      "Epoch 1075/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2007 - f1: 0.7876 - val_loss: 0.5046 - val_f1: 0.1382\n",
      "Epoch 1076/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2025 - f1: 0.7903 - val_loss: 0.5055 - val_f1: 0.1388\n",
      "Epoch 1077/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1999 - f1: 0.7917 - val_loss: 0.5090 - val_f1: 0.1388\n",
      "Epoch 1078/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.2018 - f1: 0.7896 - val_loss: 0.5016 - val_f1: 0.1383\n",
      "Epoch 1079/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2022 - f1: 0.7931 - val_loss: 0.5024 - val_f1: 0.1382\n",
      "Epoch 1080/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2012 - f1: 0.7886 - val_loss: 0.5042 - val_f1: 0.1388\n",
      "Epoch 1081/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2013 - f1: 0.7883 - val_loss: 0.5186 - val_f1: 0.1380\n",
      "Epoch 1082/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2021 - f1: 0.7869 - val_loss: 0.5067 - val_f1: 0.1387\n",
      "Epoch 1083/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2012 - f1: 0.7882 - val_loss: 0.5057 - val_f1: 0.1389\n",
      "Epoch 1084/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2016 - f1: 0.7893 - val_loss: 0.5045 - val_f1: 0.1389\n",
      "Epoch 1085/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1995 - f1: 0.7942 - val_loss: 0.5148 - val_f1: 0.1394\n",
      "Epoch 1086/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1992 - f1: 0.7963 - val_loss: 0.5195 - val_f1: 0.1391\n",
      "Epoch 1087/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2000 - f1: 0.7932 - val_loss: 0.4996 - val_f1: 0.1391\n",
      "Epoch 1088/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2033 - f1: 0.7869 - val_loss: 0.5077 - val_f1: 0.1385\n",
      "Epoch 1089/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1992 - f1: 0.7900 - val_loss: 0.5028 - val_f1: 0.1394\n",
      "Epoch 1090/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2048 - f1: 0.7856 - val_loss: 0.5040 - val_f1: 0.1381\n",
      "Epoch 1091/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2011 - f1: 0.7883 - val_loss: 0.4997 - val_f1: 0.1383\n",
      "Epoch 1092/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2003 - f1: 0.7918 - val_loss: 0.5085 - val_f1: 0.1382\n",
      "Epoch 1093/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2021 - f1: 0.7906 - val_loss: 0.5073 - val_f1: 0.1389\n",
      "Epoch 1094/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2009 - f1: 0.7914 - val_loss: 0.5061 - val_f1: 0.1389\n",
      "Epoch 1095/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1996 - f1: 0.7960 - val_loss: 0.5040 - val_f1: 0.1395\n",
      "Epoch 1096/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2019 - f1: 0.7879 - val_loss: 0.5076 - val_f1: 0.1387\n",
      "Epoch 1097/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2006 - f1: 0.7898 - val_loss: 0.5169 - val_f1: 0.1386\n",
      "Epoch 1098/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1999 - f1: 0.7908 - val_loss: 0.5088 - val_f1: 0.1379\n",
      "Epoch 1099/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1995 - f1: 0.7923 - val_loss: 0.5128 - val_f1: 0.1382\n",
      "Epoch 1100/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1990 - f1: 0.7945 - val_loss: 0.5160 - val_f1: 0.1389\n",
      "Epoch 1101/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2023 - f1: 0.7887 - val_loss: 0.5075 - val_f1: 0.1389\n",
      "Epoch 1102/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2002 - f1: 0.7933 - val_loss: 0.5034 - val_f1: 0.1391\n",
      "Epoch 1103/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2003 - f1: 0.7903 - val_loss: 0.5184 - val_f1: 0.1378\n",
      "Epoch 1104/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2010 - f1: 0.7910 - val_loss: 0.5021 - val_f1: 0.1386\n",
      "Epoch 1105/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2049 - f1: 0.7858 - val_loss: 0.5109 - val_f1: 0.1384\n",
      "Epoch 1106/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2033 - f1: 0.7875 - val_loss: 0.5153 - val_f1: 0.1383\n",
      "Epoch 1107/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2011 - f1: 0.7910 - val_loss: 0.4988 - val_f1: 0.1387\n",
      "Epoch 1108/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.2016 - f1: 0.7887 - val_loss: 0.4990 - val_f1: 0.1389\n",
      "Epoch 1109/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1985 - f1: 0.7960 - val_loss: 0.5109 - val_f1: 0.1388\n",
      "Epoch 1110/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2021 - f1: 0.7882 - val_loss: 0.5174 - val_f1: 0.1383\n",
      "Epoch 1111/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1998 - f1: 0.7925 - val_loss: 0.5057 - val_f1: 0.1384\n",
      "Epoch 1112/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2043 - f1: 0.7871 - val_loss: 0.5038 - val_f1: 0.1387\n",
      "Epoch 1113/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2002 - f1: 0.7935 - val_loss: 0.5111 - val_f1: 0.1386\n",
      "Epoch 1114/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2012 - f1: 0.7903 - val_loss: 0.5178 - val_f1: 0.1384\n",
      "Epoch 1115/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1997 - f1: 0.7917 - val_loss: 0.5171 - val_f1: 0.1389\n",
      "Epoch 1116/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2008 - f1: 0.7934 - val_loss: 0.5103 - val_f1: 0.1385\n",
      "Epoch 1117/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1983 - f1: 0.7917 - val_loss: 0.5102 - val_f1: 0.1391\n",
      "Epoch 1118/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.2021 - f1: 0.7880 - val_loss: 0.4915 - val_f1: 0.1386\n",
      "Epoch 1119/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1998 - f1: 0.7928 - val_loss: 0.5149 - val_f1: 0.1385\n",
      "Epoch 1120/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1978 - f1: 0.7967 - val_loss: 0.5177 - val_f1: 0.1376\n",
      "Epoch 1121/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1988 - f1: 0.7933 - val_loss: 0.5158 - val_f1: 0.1387\n",
      "Epoch 1122/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2021 - f1: 0.7897 - val_loss: 0.5151 - val_f1: 0.1380\n",
      "Epoch 1123/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2019 - f1: 0.7881 - val_loss: 0.5066 - val_f1: 0.1379\n",
      "Epoch 1124/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1999 - f1: 0.7882 - val_loss: 0.5133 - val_f1: 0.1385\n",
      "Epoch 1125/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2000 - f1: 0.7907 - val_loss: 0.5102 - val_f1: 0.1375\n",
      "Epoch 1126/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2014 - f1: 0.7927 - val_loss: 0.5152 - val_f1: 0.1379\n",
      "Epoch 1127/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2002 - f1: 0.7920 - val_loss: 0.5214 - val_f1: 0.1380\n",
      "Epoch 1128/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2006 - f1: 0.7879 - val_loss: 0.5148 - val_f1: 0.1378\n",
      "Epoch 1129/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2024 - f1: 0.7932 - val_loss: 0.5132 - val_f1: 0.1379\n",
      "Epoch 1130/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.2019 - f1: 0.7906 - val_loss: 0.5031 - val_f1: 0.1389\n",
      "Epoch 1131/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1999 - f1: 0.7913 - val_loss: 0.5131 - val_f1: 0.1384\n",
      "Epoch 1132/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1984 - f1: 0.7917 - val_loss: 0.5053 - val_f1: 0.1384\n",
      "Epoch 1133/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2006 - f1: 0.7846 - val_loss: 0.5107 - val_f1: 0.1386\n",
      "Epoch 1134/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1996 - f1: 0.7921 - val_loss: 0.5095 - val_f1: 0.1378\n",
      "Epoch 1135/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1995 - f1: 0.7922 - val_loss: 0.5119 - val_f1: 0.1385\n",
      "Epoch 1136/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1994 - f1: 0.7892 - val_loss: 0.5189 - val_f1: 0.1381\n",
      "Epoch 1137/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1986 - f1: 0.7919 - val_loss: 0.5102 - val_f1: 0.1388\n",
      "Epoch 1138/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2018 - f1: 0.7903 - val_loss: 0.5067 - val_f1: 0.1388\n",
      "Epoch 1139/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1991 - f1: 0.7929 - val_loss: 0.5126 - val_f1: 0.1380\n",
      "Epoch 1140/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2011 - f1: 0.7874 - val_loss: 0.5104 - val_f1: 0.1381\n",
      "Epoch 1141/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1998 - f1: 0.7891 - val_loss: 0.5159 - val_f1: 0.1378\n",
      "Epoch 1142/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1970 - f1: 0.7969 - val_loss: 0.5220 - val_f1: 0.1390\n",
      "Epoch 1143/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1987 - f1: 0.7911 - val_loss: 0.5044 - val_f1: 0.1371\n",
      "Epoch 1144/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1992 - f1: 0.7902 - val_loss: 0.5026 - val_f1: 0.1375\n",
      "Epoch 1145/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1973 - f1: 0.7933 - val_loss: 0.5131 - val_f1: 0.1382\n",
      "Epoch 1146/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2007 - f1: 0.7875 - val_loss: 0.5063 - val_f1: 0.1382\n",
      "Epoch 1147/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1990 - f1: 0.7941 - val_loss: 0.5124 - val_f1: 0.1381\n",
      "Epoch 1148/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1989 - f1: 0.7942 - val_loss: 0.5154 - val_f1: 0.1371\n",
      "Epoch 1149/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1972 - f1: 0.7958 - val_loss: 0.5028 - val_f1: 0.1381\n",
      "Epoch 1150/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2000 - f1: 0.7929 - val_loss: 0.5079 - val_f1: 0.1384\n",
      "Epoch 1151/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1972 - f1: 0.7954 - val_loss: 0.5159 - val_f1: 0.1379\n",
      "Epoch 1152/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2006 - f1: 0.7943 - val_loss: 0.5067 - val_f1: 0.1386\n",
      "Epoch 1153/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2021 - f1: 0.7885 - val_loss: 0.5058 - val_f1: 0.1378\n",
      "Epoch 1154/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1972 - f1: 0.7951 - val_loss: 0.5182 - val_f1: 0.1376\n",
      "Epoch 1155/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1969 - f1: 0.7969 - val_loss: 0.5027 - val_f1: 0.1385\n",
      "Epoch 1156/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1974 - f1: 0.7918 - val_loss: 0.5075 - val_f1: 0.1381\n",
      "Epoch 1157/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2021 - f1: 0.7881 - val_loss: 0.5111 - val_f1: 0.1384\n",
      "Epoch 1158/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1991 - f1: 0.7913 - val_loss: 0.5097 - val_f1: 0.1384\n",
      "Epoch 1159/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1978 - f1: 0.7951 - val_loss: 0.5103 - val_f1: 0.1385\n",
      "Epoch 1160/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1975 - f1: 0.7962 - val_loss: 0.5176 - val_f1: 0.1381\n",
      "Epoch 1161/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1977 - f1: 0.7959 - val_loss: 0.5151 - val_f1: 0.1382\n",
      "Epoch 1162/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1955 - f1: 0.7959 - val_loss: 0.5237 - val_f1: 0.1385\n",
      "Epoch 1163/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1987 - f1: 0.7947 - val_loss: 0.5238 - val_f1: 0.1377\n",
      "Epoch 1164/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1972 - f1: 0.7934 - val_loss: 0.5076 - val_f1: 0.1389\n",
      "Epoch 1165/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1962 - f1: 0.7966 - val_loss: 0.5175 - val_f1: 0.1379\n",
      "Epoch 1166/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1982 - f1: 0.7954 - val_loss: 0.5109 - val_f1: 0.1381\n",
      "Epoch 1167/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2004 - f1: 0.7938 - val_loss: 0.5156 - val_f1: 0.1389\n",
      "Epoch 1168/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1972 - f1: 0.7949 - val_loss: 0.5241 - val_f1: 0.1385\n",
      "Epoch 1169/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1992 - f1: 0.7920 - val_loss: 0.5134 - val_f1: 0.1387\n",
      "Epoch 1170/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1966 - f1: 0.7961 - val_loss: 0.5200 - val_f1: 0.1372\n",
      "Epoch 1171/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1974 - f1: 0.7972 - val_loss: 0.5114 - val_f1: 0.1376\n",
      "Epoch 1172/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.1993 - f1: 0.7934 - val_loss: 0.5117 - val_f1: 0.1379\n",
      "Epoch 1173/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1969 - f1: 0.7941 - val_loss: 0.5270 - val_f1: 0.1381\n",
      "Epoch 1174/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1971 - f1: 0.7957 - val_loss: 0.5115 - val_f1: 0.1376\n",
      "Epoch 1175/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1977 - f1: 0.7952 - val_loss: 0.5045 - val_f1: 0.1385\n",
      "Epoch 1176/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.2003 - f1: 0.7909 - val_loss: 0.5193 - val_f1: 0.1373\n",
      "Epoch 1177/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1972 - f1: 0.7949 - val_loss: 0.5128 - val_f1: 0.1381\n",
      "Epoch 1178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1978 - f1: 0.7929 - val_loss: 0.5116 - val_f1: 0.1382\n",
      "Epoch 1179/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2003 - f1: 0.7916 - val_loss: 0.5104 - val_f1: 0.1369\n",
      "Epoch 1180/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.1976 - f1: 0.7953 - val_loss: 0.5106 - val_f1: 0.1390\n",
      "Epoch 1181/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1980 - f1: 0.7933 - val_loss: 0.5154 - val_f1: 0.1377\n",
      "Epoch 1182/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1967 - f1: 0.7931 - val_loss: 0.5128 - val_f1: 0.1382\n",
      "Epoch 1183/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1967 - f1: 0.7979 - val_loss: 0.5224 - val_f1: 0.1393\n",
      "Epoch 1184/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2002 - f1: 0.7930 - val_loss: 0.5162 - val_f1: 0.1384\n",
      "Epoch 1185/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1989 - f1: 0.7919 - val_loss: 0.5062 - val_f1: 0.1386\n",
      "Epoch 1186/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1951 - f1: 0.7978 - val_loss: 0.5162 - val_f1: 0.1392\n",
      "Epoch 1187/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1963 - f1: 0.7992 - val_loss: 0.5174 - val_f1: 0.1391\n",
      "Epoch 1188/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1998 - f1: 0.7909 - val_loss: 0.5163 - val_f1: 0.1384\n",
      "Epoch 1189/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1967 - f1: 0.7942 - val_loss: 0.5224 - val_f1: 0.1379\n",
      "Epoch 1190/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.2008 - f1: 0.7904 - val_loss: 0.5155 - val_f1: 0.1382\n",
      "Epoch 1191/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1973 - f1: 0.7949 - val_loss: 0.5011 - val_f1: 0.1387\n",
      "Epoch 1192/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1999 - f1: 0.7925 - val_loss: 0.5113 - val_f1: 0.1380\n",
      "Epoch 1193/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1962 - f1: 0.8008 - val_loss: 0.5210 - val_f1: 0.1386\n",
      "Epoch 1194/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1975 - f1: 0.7916 - val_loss: 0.5123 - val_f1: 0.1377\n",
      "Epoch 1195/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1976 - f1: 0.7968 - val_loss: 0.5191 - val_f1: 0.1381\n",
      "Epoch 1196/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1958 - f1: 0.7961 - val_loss: 0.5164 - val_f1: 0.1383\n",
      "Epoch 1197/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1976 - f1: 0.7925 - val_loss: 0.5172 - val_f1: 0.1387\n",
      "Epoch 1198/2000\n",
      "64440/64440 [==============================] - 4s 65us/step - loss: 0.1980 - f1: 0.7953 - val_loss: 0.5205 - val_f1: 0.1389\n",
      "Epoch 1199/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1952 - f1: 0.7993 - val_loss: 0.5150 - val_f1: 0.1394\n",
      "Epoch 1200/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1963 - f1: 0.7981 - val_loss: 0.5086 - val_f1: 0.1379\n",
      "Epoch 1201/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1988 - f1: 0.7931 - val_loss: 0.5129 - val_f1: 0.1385\n",
      "Epoch 1202/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1982 - f1: 0.7916 - val_loss: 0.5048 - val_f1: 0.1383\n",
      "Epoch 1203/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.2000 - f1: 0.7904 - val_loss: 0.5140 - val_f1: 0.1388\n",
      "Epoch 1204/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1962 - f1: 0.7978 - val_loss: 0.5132 - val_f1: 0.1380\n",
      "Epoch 1205/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1942 - f1: 0.7966 - val_loss: 0.5270 - val_f1: 0.1381\n",
      "Epoch 1206/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1941 - f1: 0.7992 - val_loss: 0.5065 - val_f1: 0.1380\n",
      "Epoch 1207/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1963 - f1: 0.7935 - val_loss: 0.5140 - val_f1: 0.1378\n",
      "Epoch 1208/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1975 - f1: 0.7935 - val_loss: 0.5098 - val_f1: 0.1377\n",
      "Epoch 1209/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1969 - f1: 0.7953 - val_loss: 0.5198 - val_f1: 0.1380\n",
      "Epoch 1210/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1956 - f1: 0.7955 - val_loss: 0.5193 - val_f1: 0.1382\n",
      "Epoch 1211/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1974 - f1: 0.7985 - val_loss: 0.5096 - val_f1: 0.1387\n",
      "Epoch 1212/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1969 - f1: 0.7931 - val_loss: 0.5171 - val_f1: 0.1382\n",
      "Epoch 1213/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1936 - f1: 0.8001 - val_loss: 0.5196 - val_f1: 0.1384\n",
      "Epoch 1214/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1985 - f1: 0.7954 - val_loss: 0.5075 - val_f1: 0.1382\n",
      "Epoch 1215/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1982 - f1: 0.7954 - val_loss: 0.5181 - val_f1: 0.1388\n",
      "Epoch 1216/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1985 - f1: 0.7946 - val_loss: 0.5133 - val_f1: 0.1388\n",
      "Epoch 1217/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1997 - f1: 0.7889 - val_loss: 0.5140 - val_f1: 0.1376\n",
      "Epoch 1218/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1958 - f1: 0.7986 - val_loss: 0.5159 - val_f1: 0.1386\n",
      "Epoch 1219/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1969 - f1: 0.7975 - val_loss: 0.5230 - val_f1: 0.1375\n",
      "Epoch 1220/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1969 - f1: 0.7962 - val_loss: 0.5283 - val_f1: 0.1382\n",
      "Epoch 1221/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1983 - f1: 0.7952 - val_loss: 0.5131 - val_f1: 0.1392\n",
      "Epoch 1222/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1959 - f1: 0.7943 - val_loss: 0.5195 - val_f1: 0.1389\n",
      "Epoch 1223/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1958 - f1: 0.7969 - val_loss: 0.5184 - val_f1: 0.1380\n",
      "Epoch 1224/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1974 - f1: 0.7964 - val_loss: 0.5154 - val_f1: 0.1381\n",
      "Epoch 1225/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1947 - f1: 0.7987 - val_loss: 0.5139 - val_f1: 0.1379\n",
      "Epoch 1226/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1981 - f1: 0.7939 - val_loss: 0.5318 - val_f1: 0.1387\n",
      "Epoch 1227/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1969 - f1: 0.7951 - val_loss: 0.5164 - val_f1: 0.1384\n",
      "Epoch 1228/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1958 - f1: 0.7957 - val_loss: 0.5235 - val_f1: 0.1393\n",
      "Epoch 1229/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1981 - f1: 0.7964 - val_loss: 0.5217 - val_f1: 0.1387\n",
      "Epoch 1230/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1955 - f1: 0.7982 - val_loss: 0.5151 - val_f1: 0.1389\n",
      "Epoch 1231/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1941 - f1: 0.7971 - val_loss: 0.5251 - val_f1: 0.1383\n",
      "Epoch 1232/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1948 - f1: 0.7978 - val_loss: 0.5243 - val_f1: 0.1388\n",
      "Epoch 1233/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1958 - f1: 0.7958 - val_loss: 0.5301 - val_f1: 0.1389\n",
      "Epoch 1234/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1985 - f1: 0.7940 - val_loss: 0.5183 - val_f1: 0.1374\n",
      "Epoch 1235/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1952 - f1: 0.7964 - val_loss: 0.5236 - val_f1: 0.1384\n",
      "Epoch 1236/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1960 - f1: 0.7966 - val_loss: 0.5090 - val_f1: 0.1396\n",
      "Epoch 1237/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1977 - f1: 0.7946 - val_loss: 0.5226 - val_f1: 0.1380\n",
      "Epoch 1238/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1948 - f1: 0.7981 - val_loss: 0.5113 - val_f1: 0.1379\n",
      "Epoch 1239/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1956 - f1: 0.7952 - val_loss: 0.5251 - val_f1: 0.1381\n",
      "Epoch 1240/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1979 - f1: 0.7947 - val_loss: 0.5246 - val_f1: 0.1385\n",
      "Epoch 1241/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1952 - f1: 0.7978 - val_loss: 0.5137 - val_f1: 0.1393\n",
      "Epoch 1242/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1952 - f1: 0.7970 - val_loss: 0.5178 - val_f1: 0.1381\n",
      "Epoch 1243/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1950 - f1: 0.8025 - val_loss: 0.5236 - val_f1: 0.1380\n",
      "Epoch 1244/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1951 - f1: 0.7995 - val_loss: 0.5145 - val_f1: 0.1379\n",
      "Epoch 1245/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1976 - f1: 0.7958 - val_loss: 0.5164 - val_f1: 0.1374\n",
      "Epoch 1246/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1960 - f1: 0.7945 - val_loss: 0.5247 - val_f1: 0.1383\n",
      "Epoch 1247/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1963 - f1: 0.7955 - val_loss: 0.5161 - val_f1: 0.1382\n",
      "Epoch 1248/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1967 - f1: 0.7958 - val_loss: 0.5144 - val_f1: 0.1379\n",
      "Epoch 1249/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1955 - f1: 0.7971 - val_loss: 0.5118 - val_f1: 0.1376\n",
      "Epoch 1250/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1970 - f1: 0.7976 - val_loss: 0.5122 - val_f1: 0.1375\n",
      "Epoch 1251/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1941 - f1: 0.7947 - val_loss: 0.5186 - val_f1: 0.1381\n",
      "Epoch 1252/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1959 - f1: 0.7995 - val_loss: 0.5088 - val_f1: 0.1379\n",
      "Epoch 1253/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1947 - f1: 0.7995 - val_loss: 0.5262 - val_f1: 0.1385\n",
      "Epoch 1254/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1966 - f1: 0.7956 - val_loss: 0.5238 - val_f1: 0.1378\n",
      "Epoch 1255/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1952 - f1: 0.7974 - val_loss: 0.5168 - val_f1: 0.1387\n",
      "Epoch 1256/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1971 - f1: 0.7972 - val_loss: 0.5259 - val_f1: 0.1386\n",
      "Epoch 1257/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1958 - f1: 0.7996 - val_loss: 0.5134 - val_f1: 0.1383\n",
      "Epoch 1258/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1945 - f1: 0.7978 - val_loss: 0.5235 - val_f1: 0.1383\n",
      "Epoch 1259/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1954 - f1: 0.7982 - val_loss: 0.5148 - val_f1: 0.1380\n",
      "Epoch 1260/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1950 - f1: 0.8009 - val_loss: 0.5156 - val_f1: 0.1379\n",
      "Epoch 1261/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1964 - f1: 0.7953 - val_loss: 0.5147 - val_f1: 0.1382\n",
      "Epoch 1262/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1968 - f1: 0.7955 - val_loss: 0.5215 - val_f1: 0.1385\n",
      "Epoch 1263/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1960 - f1: 0.7968 - val_loss: 0.5166 - val_f1: 0.1387\n",
      "Epoch 1264/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1959 - f1: 0.7964 - val_loss: 0.5118 - val_f1: 0.1389\n",
      "Epoch 1265/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1937 - f1: 0.8021 - val_loss: 0.5277 - val_f1: 0.1386\n",
      "Epoch 1266/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1935 - f1: 0.8000 - val_loss: 0.5088 - val_f1: 0.1389\n",
      "Epoch 1267/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.1924 - f1: 0.8012 - val_loss: 0.5145 - val_f1: 0.1389\n",
      "Epoch 1268/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1958 - f1: 0.7965 - val_loss: 0.5192 - val_f1: 0.1387\n",
      "Epoch 1269/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1950 - f1: 0.7982 - val_loss: 0.5232 - val_f1: 0.1388\n",
      "Epoch 1270/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1969 - f1: 0.7979 - val_loss: 0.5261 - val_f1: 0.1379\n",
      "Epoch 1271/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1956 - f1: 0.7968 - val_loss: 0.5113 - val_f1: 0.1379\n",
      "Epoch 1272/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1958 - f1: 0.7992 - val_loss: 0.5088 - val_f1: 0.1379\n",
      "Epoch 1273/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1916 - f1: 0.8044 - val_loss: 0.5193 - val_f1: 0.1381\n",
      "Epoch 1274/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1923 - f1: 0.8020 - val_loss: 0.5208 - val_f1: 0.1386\n",
      "Epoch 1275/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1956 - f1: 0.7989 - val_loss: 0.5036 - val_f1: 0.1381\n",
      "Epoch 1276/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1970 - f1: 0.7956 - val_loss: 0.5168 - val_f1: 0.1385\n",
      "Epoch 1277/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1980 - f1: 0.7950 - val_loss: 0.5128 - val_f1: 0.1380\n",
      "Epoch 1278/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.1938 - f1: 0.7970 - val_loss: 0.5181 - val_f1: 0.1387\n",
      "Epoch 1279/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1941 - f1: 0.8002 - val_loss: 0.5233 - val_f1: 0.1378\n",
      "Epoch 1280/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1932 - f1: 0.8011 - val_loss: 0.5129 - val_f1: 0.1386\n",
      "Epoch 1281/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1931 - f1: 0.8005 - val_loss: 0.5116 - val_f1: 0.1383\n",
      "Epoch 1282/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1955 - f1: 0.7983 - val_loss: 0.5230 - val_f1: 0.1385\n",
      "Epoch 1283/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1927 - f1: 0.8033 - val_loss: 0.5199 - val_f1: 0.1377\n",
      "Epoch 1284/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1963 - f1: 0.7995 - val_loss: 0.5217 - val_f1: 0.1380\n",
      "Epoch 1285/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1935 - f1: 0.7984 - val_loss: 0.5294 - val_f1: 0.1378\n",
      "Epoch 1286/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1946 - f1: 0.7999 - val_loss: 0.5158 - val_f1: 0.1382\n",
      "Epoch 1287/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1953 - f1: 0.7975 - val_loss: 0.5176 - val_f1: 0.1385\n",
      "Epoch 1288/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1929 - f1: 0.7991 - val_loss: 0.5288 - val_f1: 0.1390\n",
      "Epoch 1289/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1936 - f1: 0.8006 - val_loss: 0.5271 - val_f1: 0.1380\n",
      "Epoch 1290/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1971 - f1: 0.7956 - val_loss: 0.5155 - val_f1: 0.1380\n",
      "Epoch 1291/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1955 - f1: 0.7971 - val_loss: 0.5188 - val_f1: 0.1378\n",
      "Epoch 1292/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1960 - f1: 0.7981 - val_loss: 0.5205 - val_f1: 0.1381\n",
      "Epoch 1293/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1945 - f1: 0.8001 - val_loss: 0.5308 - val_f1: 0.1379\n",
      "Epoch 1294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1933 - f1: 0.8009 - val_loss: 0.5177 - val_f1: 0.1380\n",
      "Epoch 1295/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1923 - f1: 0.8026 - val_loss: 0.5281 - val_f1: 0.1370\n",
      "Epoch 1296/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1937 - f1: 0.8030 - val_loss: 0.5177 - val_f1: 0.1378\n",
      "Epoch 1297/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1940 - f1: 0.8013 - val_loss: 0.5298 - val_f1: 0.1388\n",
      "Epoch 1298/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1936 - f1: 0.7988 - val_loss: 0.5222 - val_f1: 0.1382\n",
      "Epoch 1299/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1979 - f1: 0.7924 - val_loss: 0.5176 - val_f1: 0.1384\n",
      "Epoch 1300/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1941 - f1: 0.7926 - val_loss: 0.5272 - val_f1: 0.1389\n",
      "Epoch 1301/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1932 - f1: 0.7996 - val_loss: 0.5284 - val_f1: 0.1383\n",
      "Epoch 1302/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1972 - f1: 0.7947 - val_loss: 0.5221 - val_f1: 0.1380\n",
      "Epoch 1303/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1928 - f1: 0.7980 - val_loss: 0.5198 - val_f1: 0.1377\n",
      "Epoch 1304/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1912 - f1: 0.8011 - val_loss: 0.5287 - val_f1: 0.1381\n",
      "Epoch 1305/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1950 - f1: 0.7985 - val_loss: 0.5200 - val_f1: 0.1379\n",
      "Epoch 1306/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1933 - f1: 0.8022 - val_loss: 0.5238 - val_f1: 0.1369\n",
      "Epoch 1307/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1931 - f1: 0.8000 - val_loss: 0.5263 - val_f1: 0.1386\n",
      "Epoch 1308/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1944 - f1: 0.8011 - val_loss: 0.5237 - val_f1: 0.1370\n",
      "Epoch 1309/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1936 - f1: 0.7999 - val_loss: 0.5154 - val_f1: 0.1374\n",
      "Epoch 1310/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1932 - f1: 0.8070 - val_loss: 0.5219 - val_f1: 0.1367\n",
      "Epoch 1311/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1951 - f1: 0.7974 - val_loss: 0.5225 - val_f1: 0.1372\n",
      "Epoch 1312/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1968 - f1: 0.7943 - val_loss: 0.5245 - val_f1: 0.1374\n",
      "Epoch 1313/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1955 - f1: 0.7984 - val_loss: 0.5229 - val_f1: 0.1369\n",
      "Epoch 1314/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1936 - f1: 0.7989 - val_loss: 0.5191 - val_f1: 0.1378\n",
      "Epoch 1315/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.1920 - f1: 0.8031 - val_loss: 0.5271 - val_f1: 0.1377\n",
      "Epoch 1316/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1937 - f1: 0.8012 - val_loss: 0.5258 - val_f1: 0.1379\n",
      "Epoch 1317/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1976 - f1: 0.7951 - val_loss: 0.5214 - val_f1: 0.1375\n",
      "Epoch 1318/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1942 - f1: 0.7961 - val_loss: 0.5220 - val_f1: 0.1371\n",
      "Epoch 1319/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1967 - f1: 0.7986 - val_loss: 0.5128 - val_f1: 0.1384\n",
      "Epoch 1320/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1942 - f1: 0.7940 - val_loss: 0.5263 - val_f1: 0.1379\n",
      "Epoch 1321/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1952 - f1: 0.7973 - val_loss: 0.5224 - val_f1: 0.1384\n",
      "Epoch 1322/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1961 - f1: 0.7973 - val_loss: 0.5138 - val_f1: 0.1375\n",
      "Epoch 1323/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1920 - f1: 0.8018 - val_loss: 0.5341 - val_f1: 0.1380\n",
      "Epoch 1324/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1953 - f1: 0.7994 - val_loss: 0.5274 - val_f1: 0.1383\n",
      "Epoch 1325/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1925 - f1: 0.8002 - val_loss: 0.5302 - val_f1: 0.1382\n",
      "Epoch 1326/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1931 - f1: 0.7978 - val_loss: 0.5227 - val_f1: 0.1372\n",
      "Epoch 1327/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1934 - f1: 0.8005 - val_loss: 0.5147 - val_f1: 0.1381\n",
      "Epoch 1328/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1915 - f1: 0.7989 - val_loss: 0.5122 - val_f1: 0.1379\n",
      "Epoch 1329/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1919 - f1: 0.8008 - val_loss: 0.5232 - val_f1: 0.1372\n",
      "Epoch 1330/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1938 - f1: 0.7981 - val_loss: 0.5235 - val_f1: 0.1379\n",
      "Epoch 1331/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1932 - f1: 0.8006 - val_loss: 0.5343 - val_f1: 0.1388\n",
      "Epoch 1332/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1935 - f1: 0.8008 - val_loss: 0.5325 - val_f1: 0.1374\n",
      "Epoch 1333/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1924 - f1: 0.7984 - val_loss: 0.5218 - val_f1: 0.1382\n",
      "Epoch 1334/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1930 - f1: 0.8008 - val_loss: 0.5199 - val_f1: 0.1380\n",
      "Epoch 1335/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1911 - f1: 0.8025 - val_loss: 0.5166 - val_f1: 0.1375\n",
      "Epoch 1336/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1920 - f1: 0.8027 - val_loss: 0.5227 - val_f1: 0.1379\n",
      "Epoch 1337/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1924 - f1: 0.8002 - val_loss: 0.5165 - val_f1: 0.1384\n",
      "Epoch 1338/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1919 - f1: 0.8027 - val_loss: 0.5275 - val_f1: 0.1377\n",
      "Epoch 1339/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1924 - f1: 0.8013 - val_loss: 0.5222 - val_f1: 0.1386\n",
      "Epoch 1340/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1915 - f1: 0.8001 - val_loss: 0.5264 - val_f1: 0.1386\n",
      "Epoch 1341/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1934 - f1: 0.8002 - val_loss: 0.5280 - val_f1: 0.1382\n",
      "Epoch 1342/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1936 - f1: 0.8007 - val_loss: 0.5246 - val_f1: 0.1374\n",
      "Epoch 1343/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1908 - f1: 0.8045 - val_loss: 0.5358 - val_f1: 0.1374\n",
      "Epoch 1344/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1928 - f1: 0.8024 - val_loss: 0.5165 - val_f1: 0.1389\n",
      "Epoch 1345/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1920 - f1: 0.8026 - val_loss: 0.5177 - val_f1: 0.1376\n",
      "Epoch 1346/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1928 - f1: 0.8017 - val_loss: 0.5298 - val_f1: 0.1377\n",
      "Epoch 1347/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1897 - f1: 0.8054 - val_loss: 0.5264 - val_f1: 0.1383\n",
      "Epoch 1348/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1926 - f1: 0.8013 - val_loss: 0.5213 - val_f1: 0.1370\n",
      "Epoch 1349/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1930 - f1: 0.7987 - val_loss: 0.5313 - val_f1: 0.1369\n",
      "Epoch 1350/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1925 - f1: 0.8004 - val_loss: 0.5189 - val_f1: 0.1382\n",
      "Epoch 1351/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1936 - f1: 0.7999 - val_loss: 0.5288 - val_f1: 0.1378\n",
      "Epoch 1352/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.1923 - f1: 0.8022 - val_loss: 0.5196 - val_f1: 0.1384\n",
      "Epoch 1353/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1922 - f1: 0.8035 - val_loss: 0.5285 - val_f1: 0.1382\n",
      "Epoch 1354/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1927 - f1: 0.7999 - val_loss: 0.5301 - val_f1: 0.1389\n",
      "Epoch 1355/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1944 - f1: 0.8023 - val_loss: 0.5296 - val_f1: 0.1385\n",
      "Epoch 1356/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1934 - f1: 0.8017 - val_loss: 0.5318 - val_f1: 0.1371\n",
      "Epoch 1357/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1912 - f1: 0.7995 - val_loss: 0.5270 - val_f1: 0.1380\n",
      "Epoch 1358/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1921 - f1: 0.8016 - val_loss: 0.5207 - val_f1: 0.1382\n",
      "Epoch 1359/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1899 - f1: 0.8023 - val_loss: 0.5239 - val_f1: 0.1377\n",
      "Epoch 1360/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1927 - f1: 0.7987 - val_loss: 0.5236 - val_f1: 0.1376\n",
      "Epoch 1361/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1927 - f1: 0.7995 - val_loss: 0.5177 - val_f1: 0.1377\n",
      "Epoch 1362/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1909 - f1: 0.8003 - val_loss: 0.5307 - val_f1: 0.1391\n",
      "Epoch 1363/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1919 - f1: 0.8020 - val_loss: 0.5372 - val_f1: 0.1383\n",
      "Epoch 1364/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1912 - f1: 0.8052 - val_loss: 0.5323 - val_f1: 0.1378\n",
      "Epoch 1365/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1938 - f1: 0.7985 - val_loss: 0.5293 - val_f1: 0.1375\n",
      "Epoch 1366/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1910 - f1: 0.8010 - val_loss: 0.5322 - val_f1: 0.1377\n",
      "Epoch 1367/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1928 - f1: 0.7987 - val_loss: 0.5316 - val_f1: 0.1382\n",
      "Epoch 1368/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1916 - f1: 0.8036 - val_loss: 0.5339 - val_f1: 0.1381\n",
      "Epoch 1369/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1922 - f1: 0.7979 - val_loss: 0.5171 - val_f1: 0.1381\n",
      "Epoch 1370/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1913 - f1: 0.8015 - val_loss: 0.5229 - val_f1: 0.1380\n",
      "Epoch 1371/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1914 - f1: 0.8026 - val_loss: 0.5332 - val_f1: 0.1378\n",
      "Epoch 1372/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1920 - f1: 0.8017 - val_loss: 0.5379 - val_f1: 0.1384\n",
      "Epoch 1373/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1889 - f1: 0.8068 - val_loss: 0.5257 - val_f1: 0.1381\n",
      "Epoch 1374/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1922 - f1: 0.8012 - val_loss: 0.5283 - val_f1: 0.1382\n",
      "Epoch 1375/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1918 - f1: 0.8033 - val_loss: 0.5177 - val_f1: 0.1384\n",
      "Epoch 1376/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1922 - f1: 0.8032 - val_loss: 0.5258 - val_f1: 0.1377\n",
      "Epoch 1377/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1948 - f1: 0.8008 - val_loss: 0.5261 - val_f1: 0.1375\n",
      "Epoch 1378/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1909 - f1: 0.8069 - val_loss: 0.5214 - val_f1: 0.1383\n",
      "Epoch 1379/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1903 - f1: 0.7998 - val_loss: 0.5260 - val_f1: 0.1385\n",
      "Epoch 1380/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1922 - f1: 0.8028 - val_loss: 0.5307 - val_f1: 0.1382\n",
      "Epoch 1381/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1890 - f1: 0.8063 - val_loss: 0.5321 - val_f1: 0.1376\n",
      "Epoch 1382/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1871 - f1: 0.8108 - val_loss: 0.5260 - val_f1: 0.1386\n",
      "Epoch 1383/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1900 - f1: 0.8027 - val_loss: 0.5196 - val_f1: 0.1372\n",
      "Epoch 1384/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1910 - f1: 0.8026 - val_loss: 0.5135 - val_f1: 0.1384\n",
      "Epoch 1385/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1905 - f1: 0.8045 - val_loss: 0.5210 - val_f1: 0.1378\n",
      "Epoch 1386/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1922 - f1: 0.8031 - val_loss: 0.5294 - val_f1: 0.1377\n",
      "Epoch 1387/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1921 - f1: 0.8030 - val_loss: 0.5290 - val_f1: 0.1373\n",
      "Epoch 1388/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1896 - f1: 0.8006 - val_loss: 0.5332 - val_f1: 0.1380\n",
      "Epoch 1389/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1926 - f1: 0.8018 - val_loss: 0.5205 - val_f1: 0.1383\n",
      "Epoch 1390/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1898 - f1: 0.8013 - val_loss: 0.5259 - val_f1: 0.1387\n",
      "Epoch 1391/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1933 - f1: 0.7988 - val_loss: 0.5224 - val_f1: 0.1383\n",
      "Epoch 1392/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1911 - f1: 0.8017 - val_loss: 0.5233 - val_f1: 0.1381\n",
      "Epoch 1393/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1921 - f1: 0.8003 - val_loss: 0.5279 - val_f1: 0.1389\n",
      "Epoch 1394/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1914 - f1: 0.8008 - val_loss: 0.5211 - val_f1: 0.1396\n",
      "Epoch 1395/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1931 - f1: 0.7995 - val_loss: 0.5231 - val_f1: 0.1388\n",
      "Epoch 1396/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1907 - f1: 0.8044 - val_loss: 0.5280 - val_f1: 0.1382\n",
      "Epoch 1397/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1932 - f1: 0.7988 - val_loss: 0.5208 - val_f1: 0.1372\n",
      "Epoch 1398/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1915 - f1: 0.8030 - val_loss: 0.5158 - val_f1: 0.1372\n",
      "Epoch 1399/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1894 - f1: 0.8050 - val_loss: 0.5377 - val_f1: 0.1382\n",
      "Epoch 1400/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1914 - f1: 0.8035 - val_loss: 0.5240 - val_f1: 0.1382\n",
      "Epoch 1401/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1924 - f1: 0.8026 - val_loss: 0.5175 - val_f1: 0.1381\n",
      "Epoch 1402/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1891 - f1: 0.8060 - val_loss: 0.5303 - val_f1: 0.1373\n",
      "Epoch 1403/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1919 - f1: 0.7989 - val_loss: 0.5269 - val_f1: 0.1376\n",
      "Epoch 1404/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1916 - f1: 0.8002 - val_loss: 0.5147 - val_f1: 0.1376\n",
      "Epoch 1405/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1903 - f1: 0.8026 - val_loss: 0.5334 - val_f1: 0.1378\n",
      "Epoch 1406/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1891 - f1: 0.8067 - val_loss: 0.5337 - val_f1: 0.1376\n",
      "Epoch 1407/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1898 - f1: 0.8021 - val_loss: 0.5248 - val_f1: 0.1375\n",
      "Epoch 1408/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1906 - f1: 0.8039 - val_loss: 0.5279 - val_f1: 0.1382\n",
      "Epoch 1409/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1890 - f1: 0.8030 - val_loss: 0.5369 - val_f1: 0.1376\n",
      "Epoch 1410/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1912 - f1: 0.8032 - val_loss: 0.5155 - val_f1: 0.1380\n",
      "Epoch 1411/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.1910 - f1: 0.8015 - val_loss: 0.5225 - val_f1: 0.1375\n",
      "Epoch 1412/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1914 - f1: 0.8016 - val_loss: 0.5395 - val_f1: 0.1371\n",
      "Epoch 1413/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1890 - f1: 0.8064 - val_loss: 0.5216 - val_f1: 0.1383\n",
      "Epoch 1414/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1888 - f1: 0.8074 - val_loss: 0.5272 - val_f1: 0.1377\n",
      "Epoch 1415/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1909 - f1: 0.8053 - val_loss: 0.5187 - val_f1: 0.1368\n",
      "Epoch 1416/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1909 - f1: 0.8035 - val_loss: 0.5253 - val_f1: 0.1375\n",
      "Epoch 1417/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1908 - f1: 0.8063 - val_loss: 0.5214 - val_f1: 0.1379\n",
      "Epoch 1418/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1902 - f1: 0.8025 - val_loss: 0.5220 - val_f1: 0.1381\n",
      "Epoch 1419/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1878 - f1: 0.8075 - val_loss: 0.5320 - val_f1: 0.1377\n",
      "Epoch 1420/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1906 - f1: 0.8040 - val_loss: 0.5336 - val_f1: 0.1380\n",
      "Epoch 1421/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1903 - f1: 0.8046 - val_loss: 0.5264 - val_f1: 0.1395\n",
      "Epoch 1422/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1884 - f1: 0.8058 - val_loss: 0.5174 - val_f1: 0.1384\n",
      "Epoch 1423/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1892 - f1: 0.8053 - val_loss: 0.5382 - val_f1: 0.1383\n",
      "Epoch 1424/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1920 - f1: 0.8030 - val_loss: 0.5162 - val_f1: 0.1382\n",
      "Epoch 1425/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1901 - f1: 0.8003 - val_loss: 0.5279 - val_f1: 0.1382\n",
      "Epoch 1426/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1917 - f1: 0.8056 - val_loss: 0.5244 - val_f1: 0.1381\n",
      "Epoch 1427/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1881 - f1: 0.8088 - val_loss: 0.5399 - val_f1: 0.1387\n",
      "Epoch 1428/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1919 - f1: 0.8048 - val_loss: 0.5222 - val_f1: 0.1382\n",
      "Epoch 1429/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1898 - f1: 0.8038 - val_loss: 0.5370 - val_f1: 0.1372\n",
      "Epoch 1430/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1897 - f1: 0.8043 - val_loss: 0.5339 - val_f1: 0.1379\n",
      "Epoch 1431/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1892 - f1: 0.8040 - val_loss: 0.5328 - val_f1: 0.1386\n",
      "Epoch 1432/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1905 - f1: 0.8016 - val_loss: 0.5139 - val_f1: 0.1389\n",
      "Epoch 1433/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1904 - f1: 0.8067 - val_loss: 0.5305 - val_f1: 0.1381\n",
      "Epoch 1434/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1889 - f1: 0.8075 - val_loss: 0.5259 - val_f1: 0.1383\n",
      "Epoch 1435/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1893 - f1: 0.8045 - val_loss: 0.5261 - val_f1: 0.1374\n",
      "Epoch 1436/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1893 - f1: 0.8059 - val_loss: 0.5116 - val_f1: 0.1383\n",
      "Epoch 1437/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1909 - f1: 0.8065 - val_loss: 0.5164 - val_f1: 0.1380\n",
      "Epoch 1438/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1908 - f1: 0.8002 - val_loss: 0.5310 - val_f1: 0.1377\n",
      "Epoch 1439/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1891 - f1: 0.8057 - val_loss: 0.5263 - val_f1: 0.1388\n",
      "Epoch 1440/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1894 - f1: 0.8043 - val_loss: 0.5313 - val_f1: 0.1381\n",
      "Epoch 1441/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1894 - f1: 0.8067 - val_loss: 0.5300 - val_f1: 0.1378\n",
      "Epoch 1442/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1884 - f1: 0.8047 - val_loss: 0.5391 - val_f1: 0.1382\n",
      "Epoch 1443/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1920 - f1: 0.8013 - val_loss: 0.5158 - val_f1: 0.1384\n",
      "Epoch 1444/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1879 - f1: 0.8061 - val_loss: 0.5293 - val_f1: 0.1381\n",
      "Epoch 1445/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1913 - f1: 0.8042 - val_loss: 0.5271 - val_f1: 0.1385\n",
      "Epoch 1446/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1903 - f1: 0.8021 - val_loss: 0.5342 - val_f1: 0.1387\n",
      "Epoch 1447/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1896 - f1: 0.8040 - val_loss: 0.5242 - val_f1: 0.1379\n",
      "Epoch 1448/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1919 - f1: 0.8020 - val_loss: 0.5235 - val_f1: 0.1386\n",
      "Epoch 1449/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1887 - f1: 0.8037 - val_loss: 0.5189 - val_f1: 0.1371\n",
      "Epoch 1450/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1880 - f1: 0.8053 - val_loss: 0.5274 - val_f1: 0.1384\n",
      "Epoch 1451/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1899 - f1: 0.8017 - val_loss: 0.5305 - val_f1: 0.1378\n",
      "Epoch 1452/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1871 - f1: 0.8075 - val_loss: 0.5328 - val_f1: 0.1371\n",
      "Epoch 1453/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1891 - f1: 0.8050 - val_loss: 0.5321 - val_f1: 0.1376\n",
      "Epoch 1454/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1890 - f1: 0.8033 - val_loss: 0.5392 - val_f1: 0.1377\n",
      "Epoch 1455/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1899 - f1: 0.8011 - val_loss: 0.5321 - val_f1: 0.1372\n",
      "Epoch 1456/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1898 - f1: 0.8055 - val_loss: 0.5208 - val_f1: 0.1379\n",
      "Epoch 1457/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1915 - f1: 0.8048 - val_loss: 0.5235 - val_f1: 0.1378\n",
      "Epoch 1458/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1904 - f1: 0.8050 - val_loss: 0.5184 - val_f1: 0.1382\n",
      "Epoch 1459/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1882 - f1: 0.8052 - val_loss: 0.5287 - val_f1: 0.1384\n",
      "Epoch 1460/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1900 - f1: 0.8045 - val_loss: 0.5268 - val_f1: 0.1379\n",
      "Epoch 1461/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1873 - f1: 0.8087 - val_loss: 0.5254 - val_f1: 0.1394\n",
      "Epoch 1462/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1888 - f1: 0.8038 - val_loss: 0.5243 - val_f1: 0.1384\n",
      "Epoch 1463/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1890 - f1: 0.8022 - val_loss: 0.5306 - val_f1: 0.1389\n",
      "Epoch 1464/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1902 - f1: 0.8044 - val_loss: 0.5178 - val_f1: 0.1381\n",
      "Epoch 1465/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1904 - f1: 0.8036 - val_loss: 0.5436 - val_f1: 0.1379\n",
      "Epoch 1466/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1885 - f1: 0.8069 - val_loss: 0.5310 - val_f1: 0.1373\n",
      "Epoch 1467/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1891 - f1: 0.8012 - val_loss: 0.5188 - val_f1: 0.1387\n",
      "Epoch 1468/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1900 - f1: 0.8035 - val_loss: 0.5150 - val_f1: 0.1372\n",
      "Epoch 1469/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1876 - f1: 0.8062 - val_loss: 0.5224 - val_f1: 0.1378\n",
      "Epoch 1470/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1894 - f1: 0.8014 - val_loss: 0.5297 - val_f1: 0.1375\n",
      "Epoch 1471/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1885 - f1: 0.8032 - val_loss: 0.5316 - val_f1: 0.1368\n",
      "Epoch 1472/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1888 - f1: 0.8069 - val_loss: 0.5326 - val_f1: 0.1379\n",
      "Epoch 1473/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1880 - f1: 0.8081 - val_loss: 0.5226 - val_f1: 0.1387\n",
      "Epoch 1474/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1909 - f1: 0.7983 - val_loss: 0.5297 - val_f1: 0.1385\n",
      "Epoch 1475/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1897 - f1: 0.8044 - val_loss: 0.5292 - val_f1: 0.1385\n",
      "Epoch 1476/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1884 - f1: 0.8042 - val_loss: 0.5247 - val_f1: 0.1375\n",
      "Epoch 1477/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1858 - f1: 0.8049 - val_loss: 0.5267 - val_f1: 0.1376\n",
      "Epoch 1478/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1903 - f1: 0.8036 - val_loss: 0.5284 - val_f1: 0.1377\n",
      "Epoch 1479/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1931 - f1: 0.7985 - val_loss: 0.5289 - val_f1: 0.1381\n",
      "Epoch 1480/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1882 - f1: 0.8091 - val_loss: 0.5266 - val_f1: 0.1380\n",
      "Epoch 1481/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1868 - f1: 0.8073 - val_loss: 0.5338 - val_f1: 0.1386\n",
      "Epoch 1482/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1868 - f1: 0.8062 - val_loss: 0.5316 - val_f1: 0.1370\n",
      "Epoch 1483/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1859 - f1: 0.8089 - val_loss: 0.5296 - val_f1: 0.1379\n",
      "Epoch 1484/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1891 - f1: 0.8024 - val_loss: 0.5365 - val_f1: 0.1380\n",
      "Epoch 1485/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1885 - f1: 0.8062 - val_loss: 0.5264 - val_f1: 0.1375\n",
      "Epoch 1486/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1890 - f1: 0.8078 - val_loss: 0.5343 - val_f1: 0.1367\n",
      "Epoch 1487/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1888 - f1: 0.8065 - val_loss: 0.5212 - val_f1: 0.1374\n",
      "Epoch 1488/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1887 - f1: 0.8047 - val_loss: 0.5262 - val_f1: 0.1371\n",
      "Epoch 1489/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1899 - f1: 0.8063 - val_loss: 0.5305 - val_f1: 0.1374\n",
      "Epoch 1490/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1887 - f1: 0.8040 - val_loss: 0.5256 - val_f1: 0.1384\n",
      "Epoch 1491/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1874 - f1: 0.8072 - val_loss: 0.5306 - val_f1: 0.1375\n",
      "Epoch 1492/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1893 - f1: 0.8075 - val_loss: 0.5221 - val_f1: 0.1375\n",
      "Epoch 1493/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1905 - f1: 0.8038 - val_loss: 0.5246 - val_f1: 0.1372\n",
      "Epoch 1494/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1901 - f1: 0.8041 - val_loss: 0.5256 - val_f1: 0.1383\n",
      "Epoch 1495/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1879 - f1: 0.8093 - val_loss: 0.5165 - val_f1: 0.1386\n",
      "Epoch 1496/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1897 - f1: 0.8063 - val_loss: 0.5183 - val_f1: 0.1378\n",
      "Epoch 1497/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1883 - f1: 0.8082 - val_loss: 0.5235 - val_f1: 0.1380\n",
      "Epoch 1498/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1846 - f1: 0.8084 - val_loss: 0.5377 - val_f1: 0.1382\n",
      "Epoch 1499/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1848 - f1: 0.8116 - val_loss: 0.5347 - val_f1: 0.1385\n",
      "Epoch 1500/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1881 - f1: 0.8042 - val_loss: 0.5243 - val_f1: 0.1381\n",
      "Epoch 1501/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1890 - f1: 0.8029 - val_loss: 0.5356 - val_f1: 0.1367\n",
      "Epoch 1502/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1893 - f1: 0.8046 - val_loss: 0.5254 - val_f1: 0.1374\n",
      "Epoch 1503/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1882 - f1: 0.8078 - val_loss: 0.5274 - val_f1: 0.1376\n",
      "Epoch 1504/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1904 - f1: 0.8017 - val_loss: 0.5243 - val_f1: 0.1374\n",
      "Epoch 1505/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1884 - f1: 0.8095 - val_loss: 0.5161 - val_f1: 0.1371\n",
      "Epoch 1506/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1884 - f1: 0.8067 - val_loss: 0.5133 - val_f1: 0.1371\n",
      "Epoch 1507/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1886 - f1: 0.8038 - val_loss: 0.5390 - val_f1: 0.1376\n",
      "Epoch 1508/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1906 - f1: 0.8000 - val_loss: 0.5242 - val_f1: 0.1376\n",
      "Epoch 1509/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1874 - f1: 0.8069 - val_loss: 0.5329 - val_f1: 0.1378\n",
      "Epoch 1510/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1877 - f1: 0.8057 - val_loss: 0.5344 - val_f1: 0.1372\n",
      "Epoch 1511/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1907 - f1: 0.8028 - val_loss: 0.5177 - val_f1: 0.1378\n",
      "Epoch 1512/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1873 - f1: 0.8077 - val_loss: 0.5283 - val_f1: 0.1381\n",
      "Epoch 1513/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1879 - f1: 0.8054 - val_loss: 0.5246 - val_f1: 0.1374\n",
      "Epoch 1514/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1853 - f1: 0.8064 - val_loss: 0.5323 - val_f1: 0.1374\n",
      "Epoch 1515/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1885 - f1: 0.8072 - val_loss: 0.5339 - val_f1: 0.1388\n",
      "Epoch 1516/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1876 - f1: 0.8058 - val_loss: 0.5327 - val_f1: 0.1384\n",
      "Epoch 1517/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1926 - f1: 0.7989 - val_loss: 0.5316 - val_f1: 0.1371\n",
      "Epoch 1518/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1869 - f1: 0.8047 - val_loss: 0.5284 - val_f1: 0.1385\n",
      "Epoch 1519/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1887 - f1: 0.8043 - val_loss: 0.5288 - val_f1: 0.1374\n",
      "Epoch 1520/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1863 - f1: 0.8090 - val_loss: 0.5381 - val_f1: 0.1383\n",
      "Epoch 1521/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1883 - f1: 0.8037 - val_loss: 0.5219 - val_f1: 0.1382\n",
      "Epoch 1522/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1877 - f1: 0.8085 - val_loss: 0.5177 - val_f1: 0.1382\n",
      "Epoch 1523/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1866 - f1: 0.8065 - val_loss: 0.5280 - val_f1: 0.1386\n",
      "Epoch 1524/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1881 - f1: 0.8044 - val_loss: 0.5284 - val_f1: 0.1383\n",
      "Epoch 1525/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1885 - f1: 0.8069 - val_loss: 0.5193 - val_f1: 0.1385\n",
      "Epoch 1526/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1876 - f1: 0.8038 - val_loss: 0.5259 - val_f1: 0.1386\n",
      "Epoch 1527/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1887 - f1: 0.8052 - val_loss: 0.5195 - val_f1: 0.1382\n",
      "Epoch 1528/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1851 - f1: 0.8117 - val_loss: 0.5262 - val_f1: 0.1395\n",
      "Epoch 1529/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1871 - f1: 0.8089 - val_loss: 0.5305 - val_f1: 0.1380\n",
      "Epoch 1530/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1873 - f1: 0.8074 - val_loss: 0.5370 - val_f1: 0.1391\n",
      "Epoch 1531/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1871 - f1: 0.8073 - val_loss: 0.5197 - val_f1: 0.1378\n",
      "Epoch 1532/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1875 - f1: 0.8071 - val_loss: 0.5193 - val_f1: 0.1379\n",
      "Epoch 1533/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1883 - f1: 0.8069 - val_loss: 0.5390 - val_f1: 0.1381\n",
      "Epoch 1534/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1858 - f1: 0.8076 - val_loss: 0.5405 - val_f1: 0.1377\n",
      "Epoch 1535/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1899 - f1: 0.8035 - val_loss: 0.5201 - val_f1: 0.1387\n",
      "Epoch 1536/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1883 - f1: 0.8062 - val_loss: 0.5237 - val_f1: 0.1381\n",
      "Epoch 1537/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1869 - f1: 0.8086 - val_loss: 0.5341 - val_f1: 0.1386\n",
      "Epoch 1538/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1884 - f1: 0.8061 - val_loss: 0.5239 - val_f1: 0.1383\n",
      "Epoch 1539/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1878 - f1: 0.8069 - val_loss: 0.5339 - val_f1: 0.1378\n",
      "Epoch 1540/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1884 - f1: 0.8027 - val_loss: 0.5328 - val_f1: 0.1382\n",
      "Epoch 1541/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1860 - f1: 0.8068 - val_loss: 0.5425 - val_f1: 0.1389\n",
      "Epoch 1542/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1889 - f1: 0.8007 - val_loss: 0.5416 - val_f1: 0.1377\n",
      "Epoch 1543/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1867 - f1: 0.8048 - val_loss: 0.5389 - val_f1: 0.1377\n",
      "Epoch 1544/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1882 - f1: 0.8083 - val_loss: 0.5339 - val_f1: 0.1385\n",
      "Epoch 1545/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1849 - f1: 0.8125 - val_loss: 0.5260 - val_f1: 0.1390\n",
      "Epoch 1546/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1869 - f1: 0.8097 - val_loss: 0.5203 - val_f1: 0.1377\n",
      "Epoch 1547/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1852 - f1: 0.8112 - val_loss: 0.5472 - val_f1: 0.1370\n",
      "Epoch 1548/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1885 - f1: 0.8069 - val_loss: 0.5183 - val_f1: 0.1383\n",
      "Epoch 1549/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1880 - f1: 0.8066 - val_loss: 0.5236 - val_f1: 0.1391\n",
      "Epoch 1550/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.1860 - f1: 0.8073 - val_loss: 0.5357 - val_f1: 0.1390\n",
      "Epoch 1551/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1886 - f1: 0.8002 - val_loss: 0.5330 - val_f1: 0.1386\n",
      "Epoch 1552/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1871 - f1: 0.8076 - val_loss: 0.5251 - val_f1: 0.1389\n",
      "Epoch 1553/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1882 - f1: 0.8041 - val_loss: 0.5284 - val_f1: 0.1382\n",
      "Epoch 1554/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1878 - f1: 0.8102 - val_loss: 0.5240 - val_f1: 0.1386\n",
      "Epoch 1555/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1851 - f1: 0.8058 - val_loss: 0.5292 - val_f1: 0.1389\n",
      "Epoch 1556/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1861 - f1: 0.8090 - val_loss: 0.5374 - val_f1: 0.1387\n",
      "Epoch 1557/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1871 - f1: 0.8058 - val_loss: 0.5270 - val_f1: 0.1385\n",
      "Epoch 1558/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1829 - f1: 0.8126 - val_loss: 0.5408 - val_f1: 0.1374\n",
      "Epoch 1559/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1877 - f1: 0.8073 - val_loss: 0.5324 - val_f1: 0.1392\n",
      "Epoch 1560/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1886 - f1: 0.8048 - val_loss: 0.5302 - val_f1: 0.1380\n",
      "Epoch 1561/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1866 - f1: 0.8117 - val_loss: 0.5340 - val_f1: 0.1378\n",
      "Epoch 1562/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1861 - f1: 0.8045 - val_loss: 0.5337 - val_f1: 0.1365\n",
      "Epoch 1563/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1853 - f1: 0.8082 - val_loss: 0.5269 - val_f1: 0.1388\n",
      "Epoch 1564/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1869 - f1: 0.8094 - val_loss: 0.5260 - val_f1: 0.1377\n",
      "Epoch 1565/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1874 - f1: 0.8057 - val_loss: 0.5287 - val_f1: 0.1380\n",
      "Epoch 1566/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1875 - f1: 0.8065 - val_loss: 0.5173 - val_f1: 0.1380\n",
      "Epoch 1567/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1872 - f1: 0.8066 - val_loss: 0.5258 - val_f1: 0.1380\n",
      "Epoch 1568/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1877 - f1: 0.8082 - val_loss: 0.5368 - val_f1: 0.1369\n",
      "Epoch 1569/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1873 - f1: 0.8041 - val_loss: 0.5372 - val_f1: 0.1375\n",
      "Epoch 1570/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1859 - f1: 0.8078 - val_loss: 0.5388 - val_f1: 0.1379\n",
      "Epoch 1571/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1858 - f1: 0.8081 - val_loss: 0.5379 - val_f1: 0.1376\n",
      "Epoch 1572/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1859 - f1: 0.8103 - val_loss: 0.5352 - val_f1: 0.1376\n",
      "Epoch 1573/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1865 - f1: 0.8098 - val_loss: 0.5250 - val_f1: 0.1390\n",
      "Epoch 1574/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1881 - f1: 0.8067 - val_loss: 0.5300 - val_f1: 0.1376\n",
      "Epoch 1575/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1861 - f1: 0.8076 - val_loss: 0.5427 - val_f1: 0.1378\n",
      "Epoch 1576/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1844 - f1: 0.8100 - val_loss: 0.5302 - val_f1: 0.1383\n",
      "Epoch 1577/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1877 - f1: 0.8059 - val_loss: 0.5348 - val_f1: 0.1382\n",
      "Epoch 1578/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1853 - f1: 0.8067 - val_loss: 0.5305 - val_f1: 0.1386\n",
      "Epoch 1579/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1889 - f1: 0.8083 - val_loss: 0.5340 - val_f1: 0.1376\n",
      "Epoch 1580/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1858 - f1: 0.8094 - val_loss: 0.5358 - val_f1: 0.1382\n",
      "Epoch 1581/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1882 - f1: 0.8018 - val_loss: 0.5377 - val_f1: 0.1379\n",
      "Epoch 1582/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1875 - f1: 0.8048 - val_loss: 0.5335 - val_f1: 0.1384\n",
      "Epoch 1583/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1875 - f1: 0.8061 - val_loss: 0.5191 - val_f1: 0.1385\n",
      "Epoch 1584/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1860 - f1: 0.8061 - val_loss: 0.5273 - val_f1: 0.1376\n",
      "Epoch 1585/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1869 - f1: 0.8067 - val_loss: 0.5275 - val_f1: 0.1377\n",
      "Epoch 1586/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1857 - f1: 0.8105 - val_loss: 0.5394 - val_f1: 0.1382\n",
      "Epoch 1587/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1845 - f1: 0.8091 - val_loss: 0.5410 - val_f1: 0.1376\n",
      "Epoch 1588/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1859 - f1: 0.8101 - val_loss: 0.5239 - val_f1: 0.1383\n",
      "Epoch 1589/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1856 - f1: 0.8073 - val_loss: 0.5394 - val_f1: 0.1378\n",
      "Epoch 1590/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1889 - f1: 0.8048 - val_loss: 0.5347 - val_f1: 0.1388\n",
      "Epoch 1591/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1840 - f1: 0.8117 - val_loss: 0.5353 - val_f1: 0.1376\n",
      "Epoch 1592/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1877 - f1: 0.8051 - val_loss: 0.5356 - val_f1: 0.1390\n",
      "Epoch 1593/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1851 - f1: 0.8112 - val_loss: 0.5289 - val_f1: 0.1378\n",
      "Epoch 1594/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1882 - f1: 0.8043 - val_loss: 0.5323 - val_f1: 0.1380\n",
      "Epoch 1595/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1861 - f1: 0.8092 - val_loss: 0.5238 - val_f1: 0.1384\n",
      "Epoch 1596/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1852 - f1: 0.8060 - val_loss: 0.5231 - val_f1: 0.1390\n",
      "Epoch 1597/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1845 - f1: 0.8091 - val_loss: 0.5375 - val_f1: 0.1383\n",
      "Epoch 1598/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1856 - f1: 0.8089 - val_loss: 0.5387 - val_f1: 0.1384\n",
      "Epoch 1599/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1859 - f1: 0.8105 - val_loss: 0.5328 - val_f1: 0.1372\n",
      "Epoch 1600/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1877 - f1: 0.8064 - val_loss: 0.5368 - val_f1: 0.1371\n",
      "Epoch 1601/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1872 - f1: 0.8059 - val_loss: 0.5237 - val_f1: 0.1377\n",
      "Epoch 1602/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1868 - f1: 0.8072 - val_loss: 0.5311 - val_f1: 0.1372\n",
      "Epoch 1603/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1821 - f1: 0.8105 - val_loss: 0.5319 - val_f1: 0.1388\n",
      "Epoch 1604/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1856 - f1: 0.8077 - val_loss: 0.5265 - val_f1: 0.1389\n",
      "Epoch 1605/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1847 - f1: 0.8109 - val_loss: 0.5253 - val_f1: 0.1381\n",
      "Epoch 1606/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1872 - f1: 0.8068 - val_loss: 0.5240 - val_f1: 0.1392\n",
      "Epoch 1607/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1877 - f1: 0.8062 - val_loss: 0.5250 - val_f1: 0.1385\n",
      "Epoch 1608/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1863 - f1: 0.8097 - val_loss: 0.5202 - val_f1: 0.1381\n",
      "Epoch 1609/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1853 - f1: 0.8070 - val_loss: 0.5437 - val_f1: 0.1376\n",
      "Epoch 1610/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.1874 - f1: 0.8062 - val_loss: 0.5381 - val_f1: 0.1384\n",
      "Epoch 1611/2000\n",
      "64440/64440 [==============================] - 3s 52us/step - loss: 0.1859 - f1: 0.8082 - val_loss: 0.5394 - val_f1: 0.1375\n",
      "Epoch 1612/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1837 - f1: 0.8126 - val_loss: 0.5365 - val_f1: 0.1371\n",
      "Epoch 1613/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1855 - f1: 0.8108 - val_loss: 0.5295 - val_f1: 0.1383\n",
      "Epoch 1614/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.1871 - f1: 0.8022 - val_loss: 0.5447 - val_f1: 0.1373\n",
      "Epoch 1615/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1851 - f1: 0.8115 - val_loss: 0.5483 - val_f1: 0.1381\n",
      "Epoch 1616/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1846 - f1: 0.8129 - val_loss: 0.5380 - val_f1: 0.1373\n",
      "Epoch 1617/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1871 - f1: 0.8038 - val_loss: 0.5395 - val_f1: 0.1378\n",
      "Epoch 1618/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1864 - f1: 0.8044 - val_loss: 0.5298 - val_f1: 0.1379\n",
      "Epoch 1619/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1881 - f1: 0.8063 - val_loss: 0.5193 - val_f1: 0.1387\n",
      "Epoch 1620/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1883 - f1: 0.8059 - val_loss: 0.5331 - val_f1: 0.1375\n",
      "Epoch 1621/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1868 - f1: 0.8059 - val_loss: 0.5306 - val_f1: 0.1375\n",
      "Epoch 1622/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1865 - f1: 0.8079 - val_loss: 0.5327 - val_f1: 0.1371\n",
      "Epoch 1623/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1816 - f1: 0.8112 - val_loss: 0.5454 - val_f1: 0.1378\n",
      "Epoch 1624/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1870 - f1: 0.8059 - val_loss: 0.5320 - val_f1: 0.1381\n",
      "Epoch 1625/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1841 - f1: 0.8119 - val_loss: 0.5219 - val_f1: 0.1385\n",
      "Epoch 1626/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1843 - f1: 0.8127 - val_loss: 0.5359 - val_f1: 0.1379\n",
      "Epoch 1627/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1874 - f1: 0.8075 - val_loss: 0.5297 - val_f1: 0.1379\n",
      "Epoch 1628/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1850 - f1: 0.8098 - val_loss: 0.5308 - val_f1: 0.1381\n",
      "Epoch 1629/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1858 - f1: 0.8097 - val_loss: 0.5372 - val_f1: 0.1385\n",
      "Epoch 1630/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1861 - f1: 0.8106 - val_loss: 0.5395 - val_f1: 0.1381\n",
      "Epoch 1631/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1846 - f1: 0.8113 - val_loss: 0.5408 - val_f1: 0.1374\n",
      "Epoch 1632/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1882 - f1: 0.8041 - val_loss: 0.5368 - val_f1: 0.1373\n",
      "Epoch 1633/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1863 - f1: 0.8069 - val_loss: 0.5298 - val_f1: 0.1378\n",
      "Epoch 1634/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1854 - f1: 0.8090 - val_loss: 0.5321 - val_f1: 0.1378\n",
      "Epoch 1635/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1865 - f1: 0.8050 - val_loss: 0.5274 - val_f1: 0.1380\n",
      "Epoch 1636/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1884 - f1: 0.8097 - val_loss: 0.5240 - val_f1: 0.1383\n",
      "Epoch 1637/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1847 - f1: 0.8093 - val_loss: 0.5280 - val_f1: 0.1378\n",
      "Epoch 1638/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1847 - f1: 0.8112 - val_loss: 0.5301 - val_f1: 0.1377\n",
      "Epoch 1639/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1849 - f1: 0.8103 - val_loss: 0.5237 - val_f1: 0.1382\n",
      "Epoch 1640/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1877 - f1: 0.8073 - val_loss: 0.5353 - val_f1: 0.1382\n",
      "Epoch 1641/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1848 - f1: 0.8103 - val_loss: 0.5298 - val_f1: 0.1385\n",
      "Epoch 1642/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1851 - f1: 0.8057 - val_loss: 0.5298 - val_f1: 0.1380\n",
      "Epoch 1643/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1834 - f1: 0.8165 - val_loss: 0.5297 - val_f1: 0.1382\n",
      "Epoch 1644/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1836 - f1: 0.8107 - val_loss: 0.5314 - val_f1: 0.1385\n",
      "Epoch 1645/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1851 - f1: 0.8086 - val_loss: 0.5380 - val_f1: 0.1381\n",
      "Epoch 1646/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1850 - f1: 0.8111 - val_loss: 0.5268 - val_f1: 0.1384\n",
      "Epoch 1647/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1854 - f1: 0.8079 - val_loss: 0.5229 - val_f1: 0.1381\n",
      "Epoch 1648/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1861 - f1: 0.8094 - val_loss: 0.5337 - val_f1: 0.1380\n",
      "Epoch 1649/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1836 - f1: 0.8102 - val_loss: 0.5306 - val_f1: 0.1386\n",
      "Epoch 1650/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1869 - f1: 0.8071 - val_loss: 0.5347 - val_f1: 0.1382\n",
      "Epoch 1651/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1857 - f1: 0.8087 - val_loss: 0.5302 - val_f1: 0.1378\n",
      "Epoch 1652/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1838 - f1: 0.8090 - val_loss: 0.5412 - val_f1: 0.1381\n",
      "Epoch 1653/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1838 - f1: 0.8139 - val_loss: 0.5403 - val_f1: 0.1382\n",
      "Epoch 1654/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1845 - f1: 0.8121 - val_loss: 0.5245 - val_f1: 0.1377\n",
      "Epoch 1655/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1830 - f1: 0.8074 - val_loss: 0.5410 - val_f1: 0.1381\n",
      "Epoch 1656/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1806 - f1: 0.8147 - val_loss: 0.5367 - val_f1: 0.1379\n",
      "Epoch 1657/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1840 - f1: 0.8082 - val_loss: 0.5342 - val_f1: 0.1372\n",
      "Epoch 1658/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1867 - f1: 0.8079 - val_loss: 0.5281 - val_f1: 0.1384\n",
      "Epoch 1659/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1853 - f1: 0.8037 - val_loss: 0.5300 - val_f1: 0.1380\n",
      "Epoch 1660/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1860 - f1: 0.8086 - val_loss: 0.5324 - val_f1: 0.1384\n",
      "Epoch 1661/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1830 - f1: 0.8133 - val_loss: 0.5319 - val_f1: 0.1381\n",
      "Epoch 1662/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1844 - f1: 0.8123 - val_loss: 0.5216 - val_f1: 0.1380\n",
      "Epoch 1663/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1861 - f1: 0.8081 - val_loss: 0.5308 - val_f1: 0.1383\n",
      "Epoch 1664/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1868 - f1: 0.8100 - val_loss: 0.5358 - val_f1: 0.1380\n",
      "Epoch 1665/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1861 - f1: 0.8066 - val_loss: 0.5317 - val_f1: 0.1381\n",
      "Epoch 1666/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1852 - f1: 0.8086 - val_loss: 0.5435 - val_f1: 0.1380\n",
      "Epoch 1667/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1833 - f1: 0.8108 - val_loss: 0.5371 - val_f1: 0.1382\n",
      "Epoch 1668/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1852 - f1: 0.8099 - val_loss: 0.5349 - val_f1: 0.1385\n",
      "Epoch 1669/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1849 - f1: 0.8084 - val_loss: 0.5173 - val_f1: 0.1394\n",
      "Epoch 1670/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1826 - f1: 0.8145 - val_loss: 0.5324 - val_f1: 0.1385\n",
      "Epoch 1671/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1833 - f1: 0.8129 - val_loss: 0.5392 - val_f1: 0.1373\n",
      "Epoch 1672/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1857 - f1: 0.8117 - val_loss: 0.5241 - val_f1: 0.1382\n",
      "Epoch 1673/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1823 - f1: 0.8129 - val_loss: 0.5368 - val_f1: 0.1386\n",
      "Epoch 1674/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1821 - f1: 0.8129 - val_loss: 0.5338 - val_f1: 0.1383\n",
      "Epoch 1675/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.1830 - f1: 0.8137 - val_loss: 0.5342 - val_f1: 0.1386\n",
      "Epoch 1676/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.1873 - f1: 0.8053 - val_loss: 0.5251 - val_f1: 0.1387\n",
      "Epoch 1677/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1825 - f1: 0.8119 - val_loss: 0.5554 - val_f1: 0.1375\n",
      "Epoch 1678/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1828 - f1: 0.8105 - val_loss: 0.5283 - val_f1: 0.1384\n",
      "Epoch 1679/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1850 - f1: 0.8099 - val_loss: 0.5344 - val_f1: 0.1380\n",
      "Epoch 1680/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1834 - f1: 0.8101 - val_loss: 0.5300 - val_f1: 0.1382\n",
      "Epoch 1681/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1845 - f1: 0.8114 - val_loss: 0.5294 - val_f1: 0.1382\n",
      "Epoch 1682/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1814 - f1: 0.8130 - val_loss: 0.5279 - val_f1: 0.1380\n",
      "Epoch 1683/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1827 - f1: 0.8121 - val_loss: 0.5412 - val_f1: 0.1380\n",
      "Epoch 1684/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1832 - f1: 0.8114 - val_loss: 0.5328 - val_f1: 0.1387\n",
      "Epoch 1685/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1843 - f1: 0.8102 - val_loss: 0.5345 - val_f1: 0.1383\n",
      "Epoch 1686/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1836 - f1: 0.8104 - val_loss: 0.5353 - val_f1: 0.1380\n",
      "Epoch 1687/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1840 - f1: 0.8124 - val_loss: 0.5307 - val_f1: 0.1379\n",
      "Epoch 1688/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1849 - f1: 0.8100 - val_loss: 0.5361 - val_f1: 0.1373\n",
      "Epoch 1689/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1830 - f1: 0.8123 - val_loss: 0.5263 - val_f1: 0.1372\n",
      "Epoch 1690/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1824 - f1: 0.8133 - val_loss: 0.5345 - val_f1: 0.1375\n",
      "Epoch 1691/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1866 - f1: 0.8093 - val_loss: 0.5275 - val_f1: 0.1375\n",
      "Epoch 1692/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1823 - f1: 0.8146 - val_loss: 0.5333 - val_f1: 0.1380\n",
      "Epoch 1693/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1837 - f1: 0.8090 - val_loss: 0.5366 - val_f1: 0.1379\n",
      "Epoch 1694/2000\n",
      "64440/64440 [==============================] - 4s 64us/step - loss: 0.1845 - f1: 0.8111 - val_loss: 0.5438 - val_f1: 0.1371\n",
      "Epoch 1695/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1869 - f1: 0.8079 - val_loss: 0.5390 - val_f1: 0.1383\n",
      "Epoch 1696/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1860 - f1: 0.8101 - val_loss: 0.5342 - val_f1: 0.1375\n",
      "Epoch 1697/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1838 - f1: 0.8131 - val_loss: 0.5326 - val_f1: 0.1379\n",
      "Epoch 1698/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1865 - f1: 0.8049 - val_loss: 0.5307 - val_f1: 0.1387\n",
      "Epoch 1699/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1858 - f1: 0.8049 - val_loss: 0.5363 - val_f1: 0.1376\n",
      "Epoch 1700/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1842 - f1: 0.8111 - val_loss: 0.5327 - val_f1: 0.1383\n",
      "Epoch 1701/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1820 - f1: 0.8133 - val_loss: 0.5315 - val_f1: 0.1389\n",
      "Epoch 1702/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1823 - f1: 0.8144 - val_loss: 0.5261 - val_f1: 0.1377\n",
      "Epoch 1703/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1861 - f1: 0.8097 - val_loss: 0.5304 - val_f1: 0.1379\n",
      "Epoch 1704/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1856 - f1: 0.8106 - val_loss: 0.5215 - val_f1: 0.1383\n",
      "Epoch 1705/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1850 - f1: 0.8073 - val_loss: 0.5328 - val_f1: 0.1378\n",
      "Epoch 1706/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1843 - f1: 0.8111 - val_loss: 0.5352 - val_f1: 0.1378\n",
      "Epoch 1707/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1851 - f1: 0.8086 - val_loss: 0.5382 - val_f1: 0.1377\n",
      "Epoch 1708/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1826 - f1: 0.8133 - val_loss: 0.5304 - val_f1: 0.1372\n",
      "Epoch 1709/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1822 - f1: 0.8141 - val_loss: 0.5327 - val_f1: 0.1383\n",
      "Epoch 1710/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1824 - f1: 0.8149 - val_loss: 0.5321 - val_f1: 0.1387\n",
      "Epoch 1711/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1852 - f1: 0.8099 - val_loss: 0.5251 - val_f1: 0.1376\n",
      "Epoch 1712/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1825 - f1: 0.8117 - val_loss: 0.5503 - val_f1: 0.1369\n",
      "Epoch 1713/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1813 - f1: 0.8148 - val_loss: 0.5304 - val_f1: 0.1376\n",
      "Epoch 1714/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1846 - f1: 0.8129 - val_loss: 0.5249 - val_f1: 0.1386\n",
      "Epoch 1715/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1815 - f1: 0.8133 - val_loss: 0.5333 - val_f1: 0.1379\n",
      "Epoch 1716/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1824 - f1: 0.8140 - val_loss: 0.5346 - val_f1: 0.1386\n",
      "Epoch 1717/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1831 - f1: 0.8120 - val_loss: 0.5286 - val_f1: 0.1370\n",
      "Epoch 1718/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1830 - f1: 0.8134 - val_loss: 0.5441 - val_f1: 0.1386\n",
      "Epoch 1719/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1835 - f1: 0.8084 - val_loss: 0.5296 - val_f1: 0.1379\n",
      "Epoch 1720/2000\n",
      "64440/64440 [==============================] - 4s 55us/step - loss: 0.1853 - f1: 0.8116 - val_loss: 0.5337 - val_f1: 0.1380\n",
      "Epoch 1721/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1828 - f1: 0.8117 - val_loss: 0.5375 - val_f1: 0.1378\n",
      "Epoch 1722/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1828 - f1: 0.8105 - val_loss: 0.5418 - val_f1: 0.1377\n",
      "Epoch 1723/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1835 - f1: 0.8111 - val_loss: 0.5290 - val_f1: 0.1385\n",
      "Epoch 1724/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1837 - f1: 0.8112 - val_loss: 0.5300 - val_f1: 0.1381\n",
      "Epoch 1725/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1847 - f1: 0.8093 - val_loss: 0.5431 - val_f1: 0.1381\n",
      "Epoch 1726/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1847 - f1: 0.8071 - val_loss: 0.5380 - val_f1: 0.1378\n",
      "Epoch 1727/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1824 - f1: 0.8169 - val_loss: 0.5421 - val_f1: 0.1380\n",
      "Epoch 1728/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1828 - f1: 0.8106 - val_loss: 0.5322 - val_f1: 0.1375\n",
      "Epoch 1729/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1861 - f1: 0.8088 - val_loss: 0.5337 - val_f1: 0.1377\n",
      "Epoch 1730/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1836 - f1: 0.8118 - val_loss: 0.5412 - val_f1: 0.1382\n",
      "Epoch 1731/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1833 - f1: 0.8151 - val_loss: 0.5524 - val_f1: 0.1381\n",
      "Epoch 1732/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1857 - f1: 0.8076 - val_loss: 0.5349 - val_f1: 0.1371\n",
      "Epoch 1733/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1853 - f1: 0.8085 - val_loss: 0.5262 - val_f1: 0.1378\n",
      "Epoch 1734/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1848 - f1: 0.8096 - val_loss: 0.5372 - val_f1: 0.1382\n",
      "Epoch 1735/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1823 - f1: 0.8112 - val_loss: 0.5318 - val_f1: 0.1382\n",
      "Epoch 1736/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1821 - f1: 0.8098 - val_loss: 0.5399 - val_f1: 0.1379\n",
      "Epoch 1737/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1836 - f1: 0.8103 - val_loss: 0.5370 - val_f1: 0.1374\n",
      "Epoch 1738/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1833 - f1: 0.8089 - val_loss: 0.5362 - val_f1: 0.1369\n",
      "Epoch 1739/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1849 - f1: 0.8098 - val_loss: 0.5317 - val_f1: 0.1373\n",
      "Epoch 1740/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1827 - f1: 0.8160 - val_loss: 0.5355 - val_f1: 0.1375\n",
      "Epoch 1741/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1849 - f1: 0.8085 - val_loss: 0.5253 - val_f1: 0.1372\n",
      "Epoch 1742/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1845 - f1: 0.8094 - val_loss: 0.5430 - val_f1: 0.1376\n",
      "Epoch 1743/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1800 - f1: 0.8164 - val_loss: 0.5405 - val_f1: 0.1380\n",
      "Epoch 1744/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1832 - f1: 0.8145 - val_loss: 0.5266 - val_f1: 0.1378\n",
      "Epoch 1745/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1829 - f1: 0.8126 - val_loss: 0.5455 - val_f1: 0.1371\n",
      "Epoch 1746/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1848 - f1: 0.8098 - val_loss: 0.5362 - val_f1: 0.1375\n",
      "Epoch 1747/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1805 - f1: 0.8155 - val_loss: 0.5295 - val_f1: 0.1373\n",
      "Epoch 1748/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1823 - f1: 0.8129 - val_loss: 0.5354 - val_f1: 0.1384\n",
      "Epoch 1749/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1836 - f1: 0.8131 - val_loss: 0.5342 - val_f1: 0.1378\n",
      "Epoch 1750/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1829 - f1: 0.8149 - val_loss: 0.5428 - val_f1: 0.1376\n",
      "Epoch 1751/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1829 - f1: 0.8134 - val_loss: 0.5425 - val_f1: 0.1381\n",
      "Epoch 1752/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1833 - f1: 0.8110 - val_loss: 0.5235 - val_f1: 0.1375\n",
      "Epoch 1753/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1829 - f1: 0.8125 - val_loss: 0.5353 - val_f1: 0.1381\n",
      "Epoch 1754/2000\n",
      "64440/64440 [==============================] - 4s 64us/step - loss: 0.1832 - f1: 0.8115 - val_loss: 0.5359 - val_f1: 0.1379\n",
      "Epoch 1755/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1813 - f1: 0.8141 - val_loss: 0.5351 - val_f1: 0.1384\n",
      "Epoch 1756/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1824 - f1: 0.8159 - val_loss: 0.5284 - val_f1: 0.1386\n",
      "Epoch 1757/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1831 - f1: 0.8113 - val_loss: 0.5353 - val_f1: 0.1372\n",
      "Epoch 1758/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1816 - f1: 0.8134 - val_loss: 0.5374 - val_f1: 0.1388\n",
      "Epoch 1759/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1817 - f1: 0.8141 - val_loss: 0.5285 - val_f1: 0.1384\n",
      "Epoch 1760/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1814 - f1: 0.8115 - val_loss: 0.5250 - val_f1: 0.1385\n",
      "Epoch 1761/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1841 - f1: 0.8104 - val_loss: 0.5425 - val_f1: 0.1377\n",
      "Epoch 1762/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1824 - f1: 0.8111 - val_loss: 0.5267 - val_f1: 0.1377\n",
      "Epoch 1763/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1837 - f1: 0.8127 - val_loss: 0.5347 - val_f1: 0.1383\n",
      "Epoch 1764/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1841 - f1: 0.8085 - val_loss: 0.5278 - val_f1: 0.1381\n",
      "Epoch 1765/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1791 - f1: 0.8155 - val_loss: 0.5386 - val_f1: 0.1380\n",
      "Epoch 1766/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1819 - f1: 0.8131 - val_loss: 0.5218 - val_f1: 0.1372\n",
      "Epoch 1767/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1807 - f1: 0.8169 - val_loss: 0.5390 - val_f1: 0.1375\n",
      "Epoch 1768/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1817 - f1: 0.8126 - val_loss: 0.5352 - val_f1: 0.1390\n",
      "Epoch 1769/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1808 - f1: 0.8131 - val_loss: 0.5350 - val_f1: 0.1385\n",
      "Epoch 1770/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1831 - f1: 0.8126 - val_loss: 0.5329 - val_f1: 0.1376\n",
      "Epoch 1771/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1828 - f1: 0.8094 - val_loss: 0.5355 - val_f1: 0.1372\n",
      "Epoch 1772/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1809 - f1: 0.8203 - val_loss: 0.5403 - val_f1: 0.1379\n",
      "Epoch 1773/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1808 - f1: 0.8157 - val_loss: 0.5520 - val_f1: 0.1381\n",
      "Epoch 1774/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1823 - f1: 0.8126 - val_loss: 0.5269 - val_f1: 0.1388\n",
      "Epoch 1775/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1807 - f1: 0.8154 - val_loss: 0.5428 - val_f1: 0.1387\n",
      "Epoch 1776/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1816 - f1: 0.8144 - val_loss: 0.5367 - val_f1: 0.1388\n",
      "Epoch 1777/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1810 - f1: 0.8143 - val_loss: 0.5285 - val_f1: 0.1386\n",
      "Epoch 1778/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1839 - f1: 0.8111 - val_loss: 0.5319 - val_f1: 0.1383\n",
      "Epoch 1779/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1838 - f1: 0.8041 - val_loss: 0.5331 - val_f1: 0.1380\n",
      "Epoch 1780/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1830 - f1: 0.8142 - val_loss: 0.5277 - val_f1: 0.1383\n",
      "Epoch 1781/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1794 - f1: 0.8124 - val_loss: 0.5506 - val_f1: 0.1379\n",
      "Epoch 1782/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1823 - f1: 0.8120 - val_loss: 0.5355 - val_f1: 0.1379\n",
      "Epoch 1783/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1825 - f1: 0.8118 - val_loss: 0.5402 - val_f1: 0.1394\n",
      "Epoch 1784/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1819 - f1: 0.8154 - val_loss: 0.5249 - val_f1: 0.1383\n",
      "Epoch 1785/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1825 - f1: 0.8139 - val_loss: 0.5186 - val_f1: 0.1382\n",
      "Epoch 1786/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1817 - f1: 0.8138 - val_loss: 0.5494 - val_f1: 0.1382\n",
      "Epoch 1787/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1815 - f1: 0.8131 - val_loss: 0.5243 - val_f1: 0.1385\n",
      "Epoch 1788/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1830 - f1: 0.8126 - val_loss: 0.5370 - val_f1: 0.1374\n",
      "Epoch 1789/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1830 - f1: 0.8160 - val_loss: 0.5481 - val_f1: 0.1372\n",
      "Epoch 1790/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1823 - f1: 0.8115 - val_loss: 0.5342 - val_f1: 0.1372\n",
      "Epoch 1791/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1809 - f1: 0.8133 - val_loss: 0.5414 - val_f1: 0.1383\n",
      "Epoch 1792/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1823 - f1: 0.8152 - val_loss: 0.5236 - val_f1: 0.1385\n",
      "Epoch 1793/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1828 - f1: 0.8109 - val_loss: 0.5459 - val_f1: 0.1383\n",
      "Epoch 1794/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1795 - f1: 0.8179 - val_loss: 0.5441 - val_f1: 0.1382\n",
      "Epoch 1795/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1808 - f1: 0.8148 - val_loss: 0.5328 - val_f1: 0.1376\n",
      "Epoch 1796/2000\n",
      "64440/64440 [==============================] - 4s 69us/step - loss: 0.1830 - f1: 0.8108 - val_loss: 0.5296 - val_f1: 0.1379\n",
      "Epoch 1797/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1840 - f1: 0.8124 - val_loss: 0.5270 - val_f1: 0.1374\n",
      "Epoch 1798/2000\n",
      "64440/64440 [==============================] - 4s 66us/step - loss: 0.1803 - f1: 0.8144 - val_loss: 0.5272 - val_f1: 0.1385\n",
      "Epoch 1799/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1809 - f1: 0.8159 - val_loss: 0.5319 - val_f1: 0.1378\n",
      "Epoch 1800/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1819 - f1: 0.8129 - val_loss: 0.5316 - val_f1: 0.1381\n",
      "Epoch 1801/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1824 - f1: 0.8123 - val_loss: 0.5417 - val_f1: 0.1373\n",
      "Epoch 1802/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1812 - f1: 0.8118 - val_loss: 0.5402 - val_f1: 0.1375\n",
      "Epoch 1803/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1808 - f1: 0.8138 - val_loss: 0.5457 - val_f1: 0.1374\n",
      "Epoch 1804/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1816 - f1: 0.8111 - val_loss: 0.5450 - val_f1: 0.1378\n",
      "Epoch 1805/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1825 - f1: 0.8141 - val_loss: 0.5242 - val_f1: 0.1379\n",
      "Epoch 1806/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1799 - f1: 0.8166 - val_loss: 0.5359 - val_f1: 0.1383\n",
      "Epoch 1807/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1805 - f1: 0.8175 - val_loss: 0.5290 - val_f1: 0.1384\n",
      "Epoch 1808/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1842 - f1: 0.8085 - val_loss: 0.5225 - val_f1: 0.1380\n",
      "Epoch 1809/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1807 - f1: 0.8161 - val_loss: 0.5344 - val_f1: 0.1374\n",
      "Epoch 1810/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1812 - f1: 0.8143 - val_loss: 0.5361 - val_f1: 0.1381\n",
      "Epoch 1811/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1822 - f1: 0.8134 - val_loss: 0.5300 - val_f1: 0.1380\n",
      "Epoch 1812/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1807 - f1: 0.8135 - val_loss: 0.5349 - val_f1: 0.1380\n",
      "Epoch 1813/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1811 - f1: 0.8171 - val_loss: 0.5450 - val_f1: 0.1380\n",
      "Epoch 1814/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1803 - f1: 0.8143 - val_loss: 0.5445 - val_f1: 0.1378\n",
      "Epoch 1815/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1817 - f1: 0.8151 - val_loss: 0.5317 - val_f1: 0.1383\n",
      "Epoch 1816/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1819 - f1: 0.8160 - val_loss: 0.5306 - val_f1: 0.1383\n",
      "Epoch 1817/2000\n",
      "64440/64440 [==============================] - 3s 54us/step - loss: 0.1810 - f1: 0.8173 - val_loss: 0.5362 - val_f1: 0.1382\n",
      "Epoch 1818/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1846 - f1: 0.8082 - val_loss: 0.5376 - val_f1: 0.1391\n",
      "Epoch 1819/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1820 - f1: 0.8116 - val_loss: 0.5366 - val_f1: 0.1387\n",
      "Epoch 1820/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1800 - f1: 0.8160 - val_loss: 0.5442 - val_f1: 0.1380\n",
      "Epoch 1821/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1830 - f1: 0.8121 - val_loss: 0.5378 - val_f1: 0.1386\n",
      "Epoch 1822/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1791 - f1: 0.8196 - val_loss: 0.5429 - val_f1: 0.1374\n",
      "Epoch 1823/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1819 - f1: 0.8124 - val_loss: 0.5483 - val_f1: 0.1369\n",
      "Epoch 1824/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1823 - f1: 0.8147 - val_loss: 0.5430 - val_f1: 0.1378\n",
      "Epoch 1825/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1815 - f1: 0.8124 - val_loss: 0.5381 - val_f1: 0.1384\n",
      "Epoch 1826/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1808 - f1: 0.8130 - val_loss: 0.5393 - val_f1: 0.1381\n",
      "Epoch 1827/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1829 - f1: 0.8126 - val_loss: 0.5330 - val_f1: 0.1374\n",
      "Epoch 1828/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1826 - f1: 0.8128 - val_loss: 0.5453 - val_f1: 0.1372\n",
      "Epoch 1829/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1818 - f1: 0.8133 - val_loss: 0.5301 - val_f1: 0.1379\n",
      "Epoch 1830/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1812 - f1: 0.8150 - val_loss: 0.5490 - val_f1: 0.1382\n",
      "Epoch 1831/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1837 - f1: 0.8093 - val_loss: 0.5392 - val_f1: 0.1377\n",
      "Epoch 1832/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1812 - f1: 0.8131 - val_loss: 0.5426 - val_f1: 0.1379\n",
      "Epoch 1833/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1802 - f1: 0.8132 - val_loss: 0.5415 - val_f1: 0.1379\n",
      "Epoch 1834/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1843 - f1: 0.8104 - val_loss: 0.5287 - val_f1: 0.1373\n",
      "Epoch 1835/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1807 - f1: 0.8159 - val_loss: 0.5477 - val_f1: 0.1381\n",
      "Epoch 1836/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1802 - f1: 0.8170 - val_loss: 0.5417 - val_f1: 0.1375\n",
      "Epoch 1837/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1802 - f1: 0.8159 - val_loss: 0.5412 - val_f1: 0.1374\n",
      "Epoch 1838/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1776 - f1: 0.8176 - val_loss: 0.5376 - val_f1: 0.1379\n",
      "Epoch 1839/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1802 - f1: 0.8144 - val_loss: 0.5363 - val_f1: 0.1377\n",
      "Epoch 1840/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1836 - f1: 0.8112 - val_loss: 0.5418 - val_f1: 0.1383\n",
      "Epoch 1841/2000\n",
      "64440/64440 [==============================] - 4s 66us/step - loss: 0.1810 - f1: 0.8132 - val_loss: 0.5419 - val_f1: 0.1378\n",
      "Epoch 1842/2000\n",
      "64440/64440 [==============================] - 4s 69us/step - loss: 0.1806 - f1: 0.8118 - val_loss: 0.5455 - val_f1: 0.1379\n",
      "Epoch 1843/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1803 - f1: 0.8137 - val_loss: 0.5425 - val_f1: 0.1372\n",
      "Epoch 1844/2000\n",
      "64440/64440 [==============================] - 5s 71us/step - loss: 0.1797 - f1: 0.8165 - val_loss: 0.5395 - val_f1: 0.1372\n",
      "Epoch 1845/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1828 - f1: 0.8118 - val_loss: 0.5354 - val_f1: 0.1372\n",
      "Epoch 1846/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1814 - f1: 0.8126 - val_loss: 0.5352 - val_f1: 0.1388\n",
      "Epoch 1847/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1819 - f1: 0.8178 - val_loss: 0.5308 - val_f1: 0.1387\n",
      "Epoch 1848/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1812 - f1: 0.8137 - val_loss: 0.5396 - val_f1: 0.1386\n",
      "Epoch 1849/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1791 - f1: 0.8175 - val_loss: 0.5282 - val_f1: 0.1377\n",
      "Epoch 1850/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1810 - f1: 0.8116 - val_loss: 0.5443 - val_f1: 0.1382\n",
      "Epoch 1851/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1798 - f1: 0.8150 - val_loss: 0.5485 - val_f1: 0.1381\n",
      "Epoch 1852/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1780 - f1: 0.8174 - val_loss: 0.5364 - val_f1: 0.1378\n",
      "Epoch 1853/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1788 - f1: 0.8151 - val_loss: 0.5449 - val_f1: 0.1382\n",
      "Epoch 1854/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1808 - f1: 0.8124 - val_loss: 0.5448 - val_f1: 0.1372\n",
      "Epoch 1855/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1846 - f1: 0.8116 - val_loss: 0.5400 - val_f1: 0.1377\n",
      "Epoch 1856/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1775 - f1: 0.8164 - val_loss: 0.5357 - val_f1: 0.1378\n",
      "Epoch 1857/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1786 - f1: 0.8199 - val_loss: 0.5465 - val_f1: 0.1381\n",
      "Epoch 1858/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1789 - f1: 0.8163 - val_loss: 0.5372 - val_f1: 0.1388\n",
      "Epoch 1859/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1817 - f1: 0.8131 - val_loss: 0.5365 - val_f1: 0.1386\n",
      "Epoch 1860/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1800 - f1: 0.8190 - val_loss: 0.5383 - val_f1: 0.1379\n",
      "Epoch 1861/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1790 - f1: 0.8173 - val_loss: 0.5471 - val_f1: 0.1384\n",
      "Epoch 1862/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1828 - f1: 0.8117 - val_loss: 0.5368 - val_f1: 0.1377\n",
      "Epoch 1863/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1783 - f1: 0.8154 - val_loss: 0.5316 - val_f1: 0.1377\n",
      "Epoch 1864/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1796 - f1: 0.8168 - val_loss: 0.5320 - val_f1: 0.1373\n",
      "Epoch 1865/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1822 - f1: 0.8132 - val_loss: 0.5440 - val_f1: 0.1377\n",
      "Epoch 1866/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1811 - f1: 0.8137 - val_loss: 0.5387 - val_f1: 0.1380\n",
      "Epoch 1867/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1809 - f1: 0.8164 - val_loss: 0.5514 - val_f1: 0.1376\n",
      "Epoch 1868/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1785 - f1: 0.8153 - val_loss: 0.5341 - val_f1: 0.1381\n",
      "Epoch 1869/2000\n",
      "64440/64440 [==============================] - 4s 63us/step - loss: 0.1812 - f1: 0.8163 - val_loss: 0.5354 - val_f1: 0.1369\n",
      "Epoch 1870/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1813 - f1: 0.8142 - val_loss: 0.5373 - val_f1: 0.1384\n",
      "Epoch 1871/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1805 - f1: 0.8134 - val_loss: 0.5381 - val_f1: 0.1385\n",
      "Epoch 1872/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1801 - f1: 0.8170 - val_loss: 0.5362 - val_f1: 0.1381\n",
      "Epoch 1873/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1788 - f1: 0.8152 - val_loss: 0.5402 - val_f1: 0.1380\n",
      "Epoch 1874/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1813 - f1: 0.8158 - val_loss: 0.5332 - val_f1: 0.1378\n",
      "Epoch 1875/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1827 - f1: 0.8089 - val_loss: 0.5402 - val_f1: 0.1382\n",
      "Epoch 1876/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1825 - f1: 0.8099 - val_loss: 0.5394 - val_f1: 0.1382\n",
      "Epoch 1877/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1816 - f1: 0.8118 - val_loss: 0.5388 - val_f1: 0.1383\n",
      "Epoch 1878/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1812 - f1: 0.8187 - val_loss: 0.5381 - val_f1: 0.1380\n",
      "Epoch 1879/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1807 - f1: 0.8173 - val_loss: 0.5393 - val_f1: 0.1378\n",
      "Epoch 1880/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1830 - f1: 0.8138 - val_loss: 0.5333 - val_f1: 0.1382\n",
      "Epoch 1881/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1804 - f1: 0.8144 - val_loss: 0.5496 - val_f1: 0.1374\n",
      "Epoch 1882/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1816 - f1: 0.8111 - val_loss: 0.5391 - val_f1: 0.1381\n",
      "Epoch 1883/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1833 - f1: 0.8137 - val_loss: 0.5455 - val_f1: 0.1374\n",
      "Epoch 1884/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1790 - f1: 0.8173 - val_loss: 0.5412 - val_f1: 0.1379\n",
      "Epoch 1885/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1789 - f1: 0.8166 - val_loss: 0.5298 - val_f1: 0.1388\n",
      "Epoch 1886/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1790 - f1: 0.8180 - val_loss: 0.5445 - val_f1: 0.1380\n",
      "Epoch 1887/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1799 - f1: 0.8162 - val_loss: 0.5383 - val_f1: 0.1390\n",
      "Epoch 1888/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1778 - f1: 0.8182 - val_loss: 0.5521 - val_f1: 0.1383\n",
      "Epoch 1889/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1787 - f1: 0.8165 - val_loss: 0.5311 - val_f1: 0.1380\n",
      "Epoch 1890/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1788 - f1: 0.8163 - val_loss: 0.5475 - val_f1: 0.1382\n",
      "Epoch 1891/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1794 - f1: 0.8145 - val_loss: 0.5449 - val_f1: 0.1383\n",
      "Epoch 1892/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1798 - f1: 0.8152 - val_loss: 0.5472 - val_f1: 0.1379\n",
      "Epoch 1893/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1800 - f1: 0.8161 - val_loss: 0.5352 - val_f1: 0.1377\n",
      "Epoch 1894/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1815 - f1: 0.8166 - val_loss: 0.5498 - val_f1: 0.1376\n",
      "Epoch 1895/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1811 - f1: 0.8140 - val_loss: 0.5331 - val_f1: 0.1386\n",
      "Epoch 1896/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1785 - f1: 0.8164 - val_loss: 0.5430 - val_f1: 0.1383\n",
      "Epoch 1897/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1812 - f1: 0.8171 - val_loss: 0.5337 - val_f1: 0.1384\n",
      "Epoch 1898/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1812 - f1: 0.8169 - val_loss: 0.5520 - val_f1: 0.1380\n",
      "Epoch 1899/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1790 - f1: 0.8145 - val_loss: 0.5478 - val_f1: 0.1383\n",
      "Epoch 1900/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1823 - f1: 0.8137 - val_loss: 0.5358 - val_f1: 0.1379\n",
      "Epoch 1901/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1797 - f1: 0.8161 - val_loss: 0.5404 - val_f1: 0.1382\n",
      "Epoch 1902/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1834 - f1: 0.8133 - val_loss: 0.5431 - val_f1: 0.1376\n",
      "Epoch 1903/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1804 - f1: 0.8186 - val_loss: 0.5403 - val_f1: 0.1371\n",
      "Epoch 1904/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1826 - f1: 0.8123 - val_loss: 0.5200 - val_f1: 0.1383\n",
      "Epoch 1905/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1794 - f1: 0.8157 - val_loss: 0.5450 - val_f1: 0.1378\n",
      "Epoch 1906/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1802 - f1: 0.8153 - val_loss: 0.5435 - val_f1: 0.1372\n",
      "Epoch 1907/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1799 - f1: 0.8144 - val_loss: 0.5401 - val_f1: 0.1375\n",
      "Epoch 1908/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1801 - f1: 0.8086 - val_loss: 0.5383 - val_f1: 0.1378\n",
      "Epoch 1909/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1783 - f1: 0.8181 - val_loss: 0.5532 - val_f1: 0.1380\n",
      "Epoch 1910/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1813 - f1: 0.8130 - val_loss: 0.5420 - val_f1: 0.1374\n",
      "Epoch 1911/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1801 - f1: 0.8172 - val_loss: 0.5400 - val_f1: 0.1367\n",
      "Epoch 1912/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1802 - f1: 0.8189 - val_loss: 0.5439 - val_f1: 0.1371\n",
      "Epoch 1913/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1791 - f1: 0.8179 - val_loss: 0.5376 - val_f1: 0.1373\n",
      "Epoch 1914/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1816 - f1: 0.8132 - val_loss: 0.5476 - val_f1: 0.1376\n",
      "Epoch 1915/2000\n",
      "64440/64440 [==============================] - 3s 53us/step - loss: 0.1796 - f1: 0.8201 - val_loss: 0.5415 - val_f1: 0.1375\n",
      "Epoch 1916/2000\n",
      "64440/64440 [==============================] - 4s 56us/step - loss: 0.1812 - f1: 0.8134 - val_loss: 0.5496 - val_f1: 0.1377\n",
      "Epoch 1917/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1795 - f1: 0.8149 - val_loss: 0.5379 - val_f1: 0.1374\n",
      "Epoch 1918/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1809 - f1: 0.8160 - val_loss: 0.5343 - val_f1: 0.1375\n",
      "Epoch 1919/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1811 - f1: 0.8122 - val_loss: 0.5323 - val_f1: 0.1379\n",
      "Epoch 1920/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1781 - f1: 0.8210 - val_loss: 0.5541 - val_f1: 0.1380\n",
      "Epoch 1921/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1789 - f1: 0.8169 - val_loss: 0.5440 - val_f1: 0.1377\n",
      "Epoch 1922/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1801 - f1: 0.8117 - val_loss: 0.5377 - val_f1: 0.1375\n",
      "Epoch 1923/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1763 - f1: 0.8226 - val_loss: 0.5526 - val_f1: 0.1376\n",
      "Epoch 1924/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1792 - f1: 0.8162 - val_loss: 0.5417 - val_f1: 0.1377\n",
      "Epoch 1925/2000\n",
      "64440/64440 [==============================] - 5s 70us/step - loss: 0.1782 - f1: 0.8178 - val_loss: 0.5428 - val_f1: 0.1375\n",
      "Epoch 1926/2000\n",
      "64440/64440 [==============================] - 4s 69us/step - loss: 0.1796 - f1: 0.8178 - val_loss: 0.5406 - val_f1: 0.1376\n",
      "Epoch 1927/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1764 - f1: 0.8202 - val_loss: 0.5451 - val_f1: 0.1375\n",
      "Epoch 1928/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1805 - f1: 0.8146 - val_loss: 0.5346 - val_f1: 0.1377\n",
      "Epoch 1929/2000\n",
      "64440/64440 [==============================] - 5s 73us/step - loss: 0.1807 - f1: 0.8169 - val_loss: 0.5394 - val_f1: 0.1374\n",
      "Epoch 1930/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1788 - f1: 0.8157 - val_loss: 0.5488 - val_f1: 0.1369\n",
      "Epoch 1931/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1787 - f1: 0.8170 - val_loss: 0.5429 - val_f1: 0.1372\n",
      "Epoch 1932/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1778 - f1: 0.8179 - val_loss: 0.5407 - val_f1: 0.1374\n",
      "Epoch 1933/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1787 - f1: 0.8184 - val_loss: 0.5399 - val_f1: 0.1378\n",
      "Epoch 1934/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1799 - f1: 0.8148 - val_loss: 0.5348 - val_f1: 0.1377\n",
      "Epoch 1935/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1793 - f1: 0.8160 - val_loss: 0.5428 - val_f1: 0.1380\n",
      "Epoch 1936/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1785 - f1: 0.8169 - val_loss: 0.5494 - val_f1: 0.1375\n",
      "Epoch 1937/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1795 - f1: 0.8155 - val_loss: 0.5461 - val_f1: 0.1381\n",
      "Epoch 1938/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1794 - f1: 0.8154 - val_loss: 0.5516 - val_f1: 0.1377\n",
      "Epoch 1939/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1783 - f1: 0.8163 - val_loss: 0.5457 - val_f1: 0.1371\n",
      "Epoch 1940/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1801 - f1: 0.8164 - val_loss: 0.5390 - val_f1: 0.1383\n",
      "Epoch 1941/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1813 - f1: 0.8133 - val_loss: 0.5378 - val_f1: 0.1388\n",
      "Epoch 1942/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1807 - f1: 0.8138 - val_loss: 0.5298 - val_f1: 0.1379\n",
      "Epoch 1943/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1797 - f1: 0.8135 - val_loss: 0.5432 - val_f1: 0.1382\n",
      "Epoch 1944/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1812 - f1: 0.8158 - val_loss: 0.5368 - val_f1: 0.1373\n",
      "Epoch 1945/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1803 - f1: 0.8143 - val_loss: 0.5432 - val_f1: 0.1378\n",
      "Epoch 1946/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1788 - f1: 0.8148 - val_loss: 0.5386 - val_f1: 0.1381\n",
      "Epoch 1947/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1811 - f1: 0.8143 - val_loss: 0.5468 - val_f1: 0.1372\n",
      "Epoch 1948/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1780 - f1: 0.8197 - val_loss: 0.5469 - val_f1: 0.1389\n",
      "Epoch 1949/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1787 - f1: 0.8189 - val_loss: 0.5373 - val_f1: 0.1380\n",
      "Epoch 1950/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1802 - f1: 0.8171 - val_loss: 0.5428 - val_f1: 0.1380\n",
      "Epoch 1951/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1790 - f1: 0.8131 - val_loss: 0.5263 - val_f1: 0.1378\n",
      "Epoch 1952/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1797 - f1: 0.8172 - val_loss: 0.5381 - val_f1: 0.1382\n",
      "Epoch 1953/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1818 - f1: 0.8150 - val_loss: 0.5361 - val_f1: 0.1375\n",
      "Epoch 1954/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1800 - f1: 0.8142 - val_loss: 0.5363 - val_f1: 0.1384\n",
      "Epoch 1955/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1756 - f1: 0.8234 - val_loss: 0.5470 - val_f1: 0.1384\n",
      "Epoch 1956/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1782 - f1: 0.8162 - val_loss: 0.5416 - val_f1: 0.1385\n",
      "Epoch 1957/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1818 - f1: 0.8082 - val_loss: 0.5334 - val_f1: 0.1380\n",
      "Epoch 1958/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1800 - f1: 0.8144 - val_loss: 0.5436 - val_f1: 0.1379\n",
      "Epoch 1959/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1790 - f1: 0.8171 - val_loss: 0.5308 - val_f1: 0.1386\n",
      "Epoch 1960/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1801 - f1: 0.8137 - val_loss: 0.5343 - val_f1: 0.1380\n",
      "Epoch 1961/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1810 - f1: 0.8169 - val_loss: 0.5285 - val_f1: 0.1377\n",
      "Epoch 1962/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1816 - f1: 0.8170 - val_loss: 0.5315 - val_f1: 0.1384\n",
      "Epoch 1963/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1789 - f1: 0.8183 - val_loss: 0.5396 - val_f1: 0.1374\n",
      "Epoch 1964/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1785 - f1: 0.8165 - val_loss: 0.5416 - val_f1: 0.1377\n",
      "Epoch 1965/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1797 - f1: 0.8160 - val_loss: 0.5468 - val_f1: 0.1379\n",
      "Epoch 1966/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1787 - f1: 0.8185 - val_loss: 0.5454 - val_f1: 0.1380\n",
      "Epoch 1967/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1827 - f1: 0.8128 - val_loss: 0.5426 - val_f1: 0.1375\n",
      "Epoch 1968/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1792 - f1: 0.8154 - val_loss: 0.5326 - val_f1: 0.1377\n",
      "Epoch 1969/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1782 - f1: 0.8186 - val_loss: 0.5467 - val_f1: 0.1385\n",
      "Epoch 1970/2000\n",
      "64440/64440 [==============================] - 4s 65us/step - loss: 0.1786 - f1: 0.8189 - val_loss: 0.5491 - val_f1: 0.1377\n",
      "Epoch 1971/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1782 - f1: 0.8167 - val_loss: 0.5442 - val_f1: 0.1377\n",
      "Epoch 1972/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1795 - f1: 0.8160 - val_loss: 0.5379 - val_f1: 0.1378\n",
      "Epoch 1973/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1772 - f1: 0.8179 - val_loss: 0.5411 - val_f1: 0.1380\n",
      "Epoch 1974/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1812 - f1: 0.8144 - val_loss: 0.5286 - val_f1: 0.1376\n",
      "Epoch 1975/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1816 - f1: 0.8089 - val_loss: 0.5439 - val_f1: 0.1380\n",
      "Epoch 1976/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1791 - f1: 0.8162 - val_loss: 0.5438 - val_f1: 0.1384\n",
      "Epoch 1977/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1776 - f1: 0.8177 - val_loss: 0.5472 - val_f1: 0.1383\n",
      "Epoch 1978/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1788 - f1: 0.8157 - val_loss: 0.5430 - val_f1: 0.1388\n",
      "Epoch 1979/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1788 - f1: 0.8184 - val_loss: 0.5384 - val_f1: 0.1385\n",
      "Epoch 1980/2000\n",
      "64440/64440 [==============================] - 4s 60us/step - loss: 0.1790 - f1: 0.8178 - val_loss: 0.5387 - val_f1: 0.1386\n",
      "Epoch 1981/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1798 - f1: 0.8134 - val_loss: 0.5371 - val_f1: 0.1388\n",
      "Epoch 1982/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1791 - f1: 0.8144 - val_loss: 0.5292 - val_f1: 0.1382\n",
      "Epoch 1983/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1768 - f1: 0.8207 - val_loss: 0.5390 - val_f1: 0.1388\n",
      "Epoch 1984/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1775 - f1: 0.8238 - val_loss: 0.5499 - val_f1: 0.1374\n",
      "Epoch 1985/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1774 - f1: 0.8198 - val_loss: 0.5325 - val_f1: 0.1382\n",
      "Epoch 1986/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1806 - f1: 0.8142 - val_loss: 0.5462 - val_f1: 0.1372\n",
      "Epoch 1987/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1799 - f1: 0.8159 - val_loss: 0.5471 - val_f1: 0.1377\n",
      "Epoch 1988/2000\n",
      "64440/64440 [==============================] - 4s 61us/step - loss: 0.1801 - f1: 0.8173 - val_loss: 0.5499 - val_f1: 0.1378\n",
      "Epoch 1989/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1761 - f1: 0.8221 - val_loss: 0.5393 - val_f1: 0.1387\n",
      "Epoch 1990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1784 - f1: 0.8165 - val_loss: 0.5428 - val_f1: 0.1373\n",
      "Epoch 1991/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1794 - f1: 0.8175 - val_loss: 0.5495 - val_f1: 0.1375\n",
      "Epoch 1992/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1773 - f1: 0.8194 - val_loss: 0.5445 - val_f1: 0.1380\n",
      "Epoch 1993/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1786 - f1: 0.8168 - val_loss: 0.5342 - val_f1: 0.1386\n",
      "Epoch 1994/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1763 - f1: 0.8194 - val_loss: 0.5536 - val_f1: 0.1380\n",
      "Epoch 1995/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1794 - f1: 0.8176 - val_loss: 0.5392 - val_f1: 0.1375\n",
      "Epoch 1996/2000\n",
      "64440/64440 [==============================] - 4s 62us/step - loss: 0.1781 - f1: 0.8166 - val_loss: 0.5395 - val_f1: 0.1378\n",
      "Epoch 1997/2000\n",
      "64440/64440 [==============================] - 4s 59us/step - loss: 0.1774 - f1: 0.8181 - val_loss: 0.5452 - val_f1: 0.1378\n",
      "Epoch 1998/2000\n",
      "64440/64440 [==============================] - 4s 57us/step - loss: 0.1776 - f1: 0.8177 - val_loss: 0.5471 - val_f1: 0.1379\n",
      "Epoch 1999/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1807 - f1: 0.8179 - val_loss: 0.5372 - val_f1: 0.1382\n",
      "Epoch 2000/2000\n",
      "64440/64440 [==============================] - 4s 58us/step - loss: 0.1787 - f1: 0.8142 - val_loss: 0.5489 - val_f1: 0.1381\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEYCAYAAACtEtpmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnWeYFMXWgN9DFiSDSk4mwhJXEZVkIIkggoJ6FcyoiAkU/RS9XnNEvahXDBgQVBRFr1xFBQUVBSSDZJQlSc4Cu5zvR/UwvbMzO7PLzs6G8z5PP9OVuk+HqdNVdeqUqCqGYRiGkRlFEi2AYRiGkfcxZWEYhmFExZSFYRiGERVTFoZhGEZUTFkYhmEYUTFlYRiGYUTFlEUOIyIdRCQljsd/SETei9fxjfyJiHwtIlckWo6Cioi8JyIPefsdRGRRLHkLEqYsQhCR30XkmjDxt4nIrETIlFOIyFQR+VtE9vi2NomWK1ZE5HQR+VJEdojINhH5VUSuPspjxlW5Rzjnq777f1BEDvnCk7JzTFXtpKpjclrWeCIij4jI6Fw4T1sR2S0ipcOkLRCRgVk5nqpOVdXGOSdh/sCURUbeBq4KE3+llxY3RKRoPI/vMUhVj/VtP+fCOY8aT6l9B3wPnAhUBm4CuiZSruygqgMD9x94DPjA9zwyXI+IFMt9KQsOqjoN2ARc7I8XkebAScAHiZArv2HKIiPvAmeLSJ1AhIg0BJoCY73w1SKyxPtaWSUiN0Y6mIg09L7od4jIIhHp4UsbLSKveF/Le4GOYcrXE5HvvXNNBqqEpH8kIhtFZKeI/CAiWf7iEZG6IqL+SsmT+Tpvf4CITBeRZ0Rku4isFpGuvryVROQtEVnvpX/qxVcUkS9EZLMX/4WI1PSVqy4iE71WwgoRuT4TMZ8G3lbVJ1V1izpmq+qlfhlDrktF5ERvv5uILPbu4zoRGSIiZYBJQHXfl311ESkpIiO861nv7ZfM6n3NLiJyoif71SLyJ/C1F3+WiMzw3qW5ItLOV2a6iAzw9q/z3pnnvbyrRKSTL+91vvd3ZeA5e2nnicgaEbnXe27rReRCEekuIsu9Z3W3L38REbnPO84WERknIhVDruMqEUnxjjfMS+sO3A1c4d332V58Te892eadL0Mr33fuUiLynIisFZFNIvKyiJSKkP0dMn4EXgVMVNXt3nWM9/5LO7z3v2GE854nImt84Vbe89gtImOBkr60yuL+34H/wOciUiMkfbSIbPDSP46xXMz3KcdQVdtCNmAycL8v/DjwqS98AdAAEKA9sA9o6aV1AFK8/eLACuA+oARwDrAbOMVLHw3sBM7CKe5SYWT5GXgO9wK288q/50u/BijrpY8A5mZyXVOB68LE1wUUKBYuLzAAOARcDxTFfdGvB8RL/y/u66yid83tvfjKQG+gtCfjRyH38XvgZaAU0BzYDJwbRr7SQBrQMZNrGwBMD4lT4ERvfwPQ1tuvGO55+co9DMwAjgOqAj8B/4pw3rOBHZlsZ0d51x7yP08v7kRP9re8az8GqAVsBTp770oXYAtQ2SszHRjg7V/nPa9rvOd1K7DWd/wLgfq49/ccYD/Q1Es7D0gF/s97ljcBfwHvAcfiPpr+Bmp7+YcAPwI1vOf4BvBuyHW86qW1BA4AJ3npjwCjQ679R+AlX/4tgfcpzL37NzDBe57lgC8zeU51vXtSwwsX9d6J7l64iPcOlfXO/W9glq/8e8BDvnu0xtsvCaQAg7371c87TyBvVaCX9wzLAZ8A433H/Qp437uGEkC7GMvFfJ9yrF6M58Hz6wb8A1jqe4n+BHplkv9T4DZvvwNBZdEW2AgU8eUd63uRRgPvZHLc2t4ft4wv7n1CKhdfWgXvz1k+QvpUnGILVGS/efF1ia4sVvjSSnv5TwCqAYeBijHc1+bAdm+/Fk4BlPWlP05I5eHF1/DOd2omxx5A5sriT+BGoFxIniPPyxe3EujmC3fGqxzi8K49FPo8CVaytX1x/we8FZLvW+AKbz9UWfzuy1fOO16VCDJ8Adzi7Z8H7AGKeuGKXtlWvvzzCFayy/FVUt5zPYD73wSu4wRf+m9AH28/nbIA6uEqWv/7/jTwehiZi+CUVh1fXFtgeSb3eipwt7ffFdc1VSxC3iqe7GW8cCRlcQ6wFu/DyYv7NZA3zHGTgc2+e5VKhP9rJuVivk85uVk3VHg+AaqJyBm4yqQ07usZABHp6nUHbBORHUA3QrqHPKrjvugO++L+wFV+AdZmIkd1XOW6N6R8QI6iIvKE1wWwC1jjJYWTJcBgVa3gbS0zyRfKxsCOqu7zdo/FvfDbVHV7aAERKS0i/xGRPzz5fgAqiBubqe6V2x1ybTVCjwNsxymkalmQN5TeuOf0h9dFk9nAfnV899nbr34U584u/nejDnCZ10Wyw3vvzshEro2+ff/zwutS+sX3/nYi/TuzRVXTvP393u8mX/r+wLFwHzSf+2RagKtkjwtkVtVQWY4lPNW9c4e+7+HeiRNwX/XzfOf+wn/eMPjHI68ExqhqKhz5Lz3lddntwvUIQOb/pYDMKerV2D6Z8Y5bRkReF5E/veN+5ztmLe96d4YeNEq5rNynHMOURRi8ynA87sW6EhinqgcBxPVdfww8AxyvqhVwzV8Jc6j1QC0R8d/n2sA6/+kyEWUDUFFc37q/fIDLgZ64L53yuBYCEWTJjMBL57cWOSHGsmuBSiJSIUzaXcApQGtVLYfrRgvIt94rV9aXP/TeAEeex8+4Cj8Se/3yi0g6+VV1pqr2xFUmnwIfBpLCHGs9rnL2y7U+3EnFWdrsyWRrm4nMmRJSAa3FtSwq+LYyqvp0Vo4pIsfg3u3HCb6/X5P1dyZACnB+iFylQhREJELv/XqgSpj3PcM7gVNeB3FduoHzllfV8pmc7yOgnoi0x/1v3vGlXYX7mDgH91860YuPdl82ADVD4vz/0btxLYHTvf/AOb60tbjrLRfmuJmVy8p9yjFMWUTmbaAvroLyW0GVwH3RbAZSxQ30dspYHIBfcJXY3SJSXEQ64PqLx8UigKr+AcwC/ikiJUTkbK98gLK4Jv9WXEX5WGyXluE8m3Ev2j+8L6xrcGMysZTdgBskflncgHZxCQ68lsV9he4QkUrAg75ya3FjAY97A5VNgWuBSOafdwMDRGSoiFQGEJFmIhK4l/OAxiLS3BvkfChQ0Lt3V4hIeVU9BOzCdYGBq3Qqi4i/khkL3C8iVUWkCjAc1w0R7vqnaXrrstBtWvS7GBPvAr1E5HzvGZUSkY4iktUWT0ncO7wZSBM30HzuUcj1KvCYiNQGEJHjxGfEEYVNQF0REQBVXY173x8TZ2TQHLiaMO+E1/J5HRjhPSfxBn0j/RdR1T24XoO3cd2qc33Jof+lR2O8hulAEREZJCLFROQS3BiC/7j7gO3eezvcJ89a4BtgpIhUCPPfiVQu5vuUk5iyiMwPuMHndao6MxDpdZsMxn2Zbsd93U8MdwCvNdID1z+6BTeYe5Wq/p4FOS4HWgPbcJWt/2voHVzzcx2wGDcom12uB4bi/iyNcRV5rFyJ60P9HTcYersXPwI3QLfFk+1/IeUuw7WG1uMGKh9U1cnhTqCqP+G+rs4BVonINuA1XKsOVV2GG5j+BtePPj3kEFcCa7wm/UDcuBTesxjrHXOHV/k+gvszzsd1q/zmxSUMVV2DG/B8AFfR/4lruWXpP6yqO4A7cPd7G9AH132TXZ7DPddvRWQ37r05LcayH+AU1zYR+dWL64szZ92IawHdp6pTIpS/C/f+/4r7r37tlc2Mt3GtxndC4t/CvYfrgUXE+P6r6gHcc7keVx9cjGu5BngO11LZ6h0zdB7NP7zfZTjleWuM5bJyn3KEgDWLYRiGYUTEWhaGYRhGVExZGIZhGFExZWEYhmFExZSFYRiGEZUC46CsSpUqWrdu3USLYRiGka+YPXv2FlWtGi1fgVEWdevWZdasfO1B3DAMI9cRkT+i57JuKMMwDCMGTFkYhmEYUTFlYRiGYUSlwIxZhOPQoUOkpKTw999/J1oUI49RqlQpatasSfHixRMtimHkCwq0skhJSaFs2bLUrVsXz1eZYaCqbN26lZSUFOrVq5docQwjX1Cgu6H+/vtvKleubIrCSIeIULlyZWtxGkYWKNDKAjBFYYTF3gvDyBoFXlkYhmFE4ttvYcWK6PmMOCsLEekiIktFZIWIDAuTPkBENovIXG+7zpeW5osPu15EfmDjxo3069ePBg0a0KhRI7p168ayZcuyfJxPP/2UxYsX55hcI0aMYN++fdEzhjB8+HC++eabHJMjJ1izZg3vv/9+osUw8iHnnQcnRVsBI5fYvh2WLoXbboOxY2MrM2cOTMyt2jFei3sDRXEL39fHLXAyD2gUkmcA8O8I5fdk5XytWrXSUBYvXpwhLjc5fPiwnnHGGfrKK68ciZszZ47+8MMPWT5W//799aOPPsox2erUqaObN28Om5aamppj58kNpkyZohdccEGWyyX6/TASD7gtEtdfr9quXcb4bdtc2t69WT/n9Omqmza5/aefVn3sMdVrr1WtUiUoD6ju2aP65puZnyOa/LEAzNJY6vRYMmVnA9oAX/nC9wL3huQp0Mri22+/1bZt24ZNC63gbrnlFn3rrbdUVfWee+7Rhg0balJSkt511136448/asWKFbVu3brarFkzXbFihc6ZM0dbt26tSUlJetFFF+m2bdtiluuFF17Q4sWLa5MmTbRDhw6qqlqmTBl94IEH9PTTT9dp06bprFmztF27dtqyZUvt1KmTrl+/XlXTK606dero8OHDtUWLFtqkSRNdsmSJqqr+8ssv2qZNG23evLm2adNGf//9d1VVfeutt7Rnz57avXt3rVu3rr700kv67LPPavPmzbV169a6detWVVVdsWKFdu7cWVu2bKlnn332keP2799fb731Vm3Tpo3Wq1fviBytW7fWcuXKabNmzfS5557T/fv364ABA7RJkybavHlz/e6778Leh0S/H0biCVfZvvee6iWXRE5XVR08OJh2443hj33woKvww53zxBNVp01LrxxCt+eec7+33JK+/OrVqqmpqhdcEMy7bl2WL90nT+KVRR/gdV/4ylDF4CmLDbjlK8cDtXxpqbilLWcAF0U4xw1enlm1a9fOcBPSVQa33abavn3ObrfdlulDeOGFF/T2228PmxZJWWzdulVPPvlkPXz4sKqqbt++XVUztiySkpJ06tSpqqr6wAMP6G1RZAkltGUB6AcffKCqqgcPHtQ2bdroX3/9paqq48aN06uvvjqDHHXq1NEXX3xRVVVHjhyp1157raqq7ty5Uw8dOqSqqpMnT9aLL75YVZ2yaNCgge7atUv/+usvLVeu3JFW1+23367PP/+8qqqec845umzZMlVVnTFjhnbs2PHIufv06aNpaWm6aNEibdCgQdh7+cwzz+iAAQNUVXXJkiVaq1Yt3b9/f4Z7YMoi/7Fnj+qOHdHzLV2q2qVL+MraTzhl4I+LpCwGDkxfsd91V/r0N94Ipi1cqDppkupxx6lu3Ji5ggi3deigeviwUxBvv+3i/vGP9HmSk6Pfk8j3IDZlEc95FuHMTULXcP0cGKuqB0RkIG593HO8tNqqul5E6gPficgCVV2Z7mCqr+HWYSY5OblArA9brlw5SpUqxXXXXccFF1xA9+7dM+TZuXMnO3bsoH379gD079+fSy655KjOW7RoUXr37g3A0qVLWbhwIeeffz4AaWlpVKtWLWy5iy++GIBWrVrxySefHJGvf//+LF++HBHh0KFDR/J37NiRsmXLUrZsWcqXL8+FF14IQFJSEvPnz2fPnj389NNP6a7nwIEDR/YvuugiihQpQqNGjdi0aVNYmaZPn86tt7qljE899VTq1KnDsmXLaNq0abbujZF3qFXL9e1rlH/77bfD//4HL74IQ4dCsaOs6bZvh3XroEkTF05LS5/+7LNw5ZVOrsaN4dprg2lNmkDp0rBvH5xwQtbPPXUqFAkZXX7vvfTh3PChGk9lkQLU8oVr4hZDP4KqbvUFRwFP+tLWe7+rRGQq0AI3BpI9RozIdtHs0rhxY8aPHx82rVixYhw+fPhIOGDzX6xYMX799Ve+/fZbxo0bx7///W++++67LJ87LS2NVq1aAdCjRw8efvjhTPOXKlWKokWLAq612bhxY37++eeo5ylZsiTglE1qaioADzzwAB07dmTChAmsWbOGDh06ZMgPUKRIkSPhIkWKkJqayuHDh6lQoQJz587N9HwBOcMRKd7Ie0yfDm3agPfqRWX79uh5VGHSJLd/332wYwc8+WT6PLt3pz/WoUPw+efQq1cw7tNPg/vt28OCBUEl5b3q6WjePLJM2bAlyXPE0xpqJnCSiNQTkRJAPyDduL2I+D9XewBLvPiKIlLS268CnAXknClQLnHOOedw4MABRo0adSRu5syZfP/999SpU4fFixdz4MABdu7cybfffgvAnj172LlzJ926dWPEiBFHKs2yZcuye/duAMqXL0/FihWZNm0aAO++++6RVkaAokWLMnfuXObOnRtWUfiPF8opp5zC5s2bjyiLQ4cOsWjRopive+fOndSoUQOA0aNHx1wOXMuqXr16fPTRR4Cr+OfNm5dpmdBradeuHWPGjAFg2bJl/Pnnn5xyyilZksOIPz/8AG3bwuOPx5b/iy8yxn37LbRoAQcPBuNCv7r93zyqrlVwzjlQp04w/oknoHdvpzAC+BXHggXut29f14LIQcPEfEPclIWqpgKDgK9wSuBDVV0kIg+LSA8v22ARWSQi84DBuDEMgIbALC9+CvCEqua7xyMiTJgwgcmTJ9OgQQMaN27MQw89RPXq1alVqxaXXnopTZs25YorrqBFixYA7N69m+7du9O0aVPat2/P888/D0C/fv14+umnadGiBStXruTtt99m6NChNG3alLlz5zJ8+PAsyXbDDTfQtWtXOnbsmCGtRIkSjB8/nnvuuYdmzZrRvHlzfvrpp5iPfffdd3Pvvfdy1llnkRbaXo+BMWPG8MYbb9CsWTMaN27MZ599lmn+pk2bUqxYMZo1a8bzzz/PzTffTFpaGklJSfTt25fRo0ena5EYucfate536lTYsCF92nqvnyFQEWfGBx+A12MJOAUxfjwMHAhz50KfPlC/vksLPc+0afDuu27/5JNdl1Rot03g75OSkrkcH37olNEvv0SXucARy8BGftjyojWUkbex9yNnOHRI9Ztv0sctXKj6xRdu8PWZZ9xvjRrOyigpSbVIkeDgbO/e6csuWKB6zjmqffo4i6Hffot9MLhZM9WOHcOnzZsXvfwjj2R9ADqvbNmFPDDAbRhGAWTzZvdbtSp07w7//a8LT58OZ50FX34JF1wQzD9kiPtdtw683sV0pKXBrl3wz3/C5ZdDcnIwLcKQX0Qy67Fs1ix6+fvvz9r5ChOmLAzDiMrSpa5L6dAh6NbNxakGFQXAli3BvFkhLc1ZL731FsyenTPy5ld694aPP856udWrc16WUExZGEYh4eBBZ5VToULWy556asa4nTvThxctghtvhKw68/UPKn//fdZlK0j47TDq1YtNCbRrB3Xrxk2kI5gjQcMoJFxwAVSsCAsXZp5vwwYYPDi6uWeo0vm//4NNmzIqESNIYNrUO+/A8cdnTG/UyP2+9hqsWhX9eE89lXsK1pSFYRQCdu6EgP/HpKTIk9ruuQeqV4eXXoIyZZwVkpF17r8fjjkmY/x//gM//ujMb195xcWdfTb08OxDy5Rxz+b66104MAkwEv7Jf/HGlIVhFBAmTXIzlv188IHrA/ebnYLrktq/340RdOsGIm6i2lNPpc/Xr5/zgmpkjX/9y00GPPlk14oIOECoXh3OPNPt9+oFM2a4+SYBQpX49OnpB91bt3aKpEYNN9GwUqX4Xkc6YjGZyg9bXjWd3bBhg/bt21fr16+vDRs21K5du+rSpUuzfJwJEybookWL4iBhbLRv315nzpypqqpdu3Y94rPKz4MPPqhPP/10bouWbfLC+5FTpKWFN6GMZGZ54YWqxx6bPu6UUxJv/pnILTk5ffjRR1WffTZ7xwrl779Vw7gnO0LPnq7cxx9nTJs/36WNGXN070gkiNF01loWcURV6dWrFx06dGDlypUsXryYxx57LKJPo8zI6fUsjoYvv/ySCtkZJTVylIDLrR9/TO8uY84c90WqEbqawA0q79mTPi6rVkx5haMd3J0/343P/Ppr+vgBA+COO2DjRtc9V6ZM+vTQdSS6dIl8jpIloVSpyOmZLdyYlORMiy+/PHKe3MCURRyZMmUKxYsXZ+DAgUfimjdvTtu2bZk6dWo6J4GDBg064hpj2LBhNGrUiKZNmzJkyBB++uknJk6cyNChQ2nevDkrV65k7ty5nHHGGTRt2pRevXqxPRanOR6TJk3i0ksvPRKeOnXqEYd+N910E8nJyTRu3JgHH3wwbPm6deuyxbOTfPTRRznllFM477zzWOqrbUaNGsVpp51Gs2bN6N2795GFljZt2kSvXr1o1qwZzZo1OzIz/KKLLqJVq1Y0btyY11577chxxo4dS1JSEk2aNOGee+6J+RoLKh984OYjjB4NJUrAH3/AlCnp87Rs6dxoHHdcQkTMFrfckrX8fhcew7xl1apVc/3/4Xj3XVfx16njZmEHqF7dVcbHHJO+wlZ1aSJuIPqJJ5xSefnloKzly0PZsm7/ueeC7kiuu45sE0nBB86TSAqN6ezttzu3ADlJ8+aZ+ydcuHDhEWd+sbJt2zYmTJjA77//joiwY8cOKlSoQI8ePejevTt9+vQBnIuLl156ifbt2zN8+HD++c9/MiJGZ4nnn38+N954I3v37qVMmTJ88MEH9O3bF3CVf6VKlUhLS+Pcc89l/vz5Eb21zp49m3HjxjFnzhxSU1Np2bLlkeu9+OKLud4bpbv//vt54403uPXWWxk8eDDt27dnwoQJpKWlscf7vH3zzTepVKkS+/fv57TTTqN3794cOHCAe+65h9mzZ1OxYkU6derEp59+ykUXXZSle5qTqLqKp08f50k0J4/7zTdQs6azWLr5ZrjsMnee1auDriz69Utfbtky99UZjsC8h/zAv//tKuVYvda0bBncDzj1u+giV5nfeKOzJgqwfDmceCL84x+uUj982N3X8eOdF1s/H30U+bnWrw833eTGetq3dyarxYu7tKuucq27w4czbyVEImAyW7Vq1svmFtayyGP4XZR/8sknlA7z5oZzUf6Df5QsCsWKFaNLly58/vnnpKam8t///peePXsC8OGHH9KyZUtatGjBokWLMu36mjZtGr169aJ06dKUK1eOHgGTDpyibNu2LUlJSYwZM+aII8LvvvuOm266CXDODsuXLw/Aiy++SLNmzTjjjDNYu3Yty5cvZ+bMmXTo0IGqVatSrFgxrrjiiixdZzyYMgX693dur3OSDz6ATp2c6WS1ajBhAlx6qTO1bNDAVUDhKqGBA+Hpp3NWlqMlu4OuDzyQefpTTwWd/5UoEYy/+GKnZAcPduGXXnJdcaNGOSV04onpj1OkSHDQPtTbbZ8+wUmHkTjmGAh40A9YLQUsn7KjKMANiP/vf04B5VUKTcsiAR7K87SL8r59+zJy5EgqVarEaaedRtmyZVm9ejXPPPMMM2fOpGLFigwYMOCIXJGQCP+OAQMG8Omnn9KsWTNGjx7N1KlTIx5j6tSpfPPNN/z888+ULl2aDh068Pfff6OZdboniMAcgnXrYi8zdSo0bBjerh5cf/lll4VP+/LLzI8diy1+dunUCb7+OnL64cOuYn71VVizxn1xgzP3jKbTVZ3n1saN08e3aZO+i2nWLOe07+abXfjGG90YArgKtmJFp1wDDgvBKZLmzTN3GZ6cDB07upbG0fDYY/Dgg+HNZLNC8eLQufPRHSPeWMsijuRlF+UdOnTgt99+Y9SoUUe6oHbt2kWZMmUoX748mzZtYlJgUYAItGvXjgkTJrB//352797N576puLt376ZatWocOnToiLtwgHPPPZdXPAPztLQ0du3axc6dO6lYsSKlS5fm999/Z8aMGQC0bt2a77//ni1btpCWlsbYsWMzXGduk9mX49y5rl87lI4dg33pX34Jobr/xx9zTr6c4r334KuvXMvFj4irmP/6y+0PHuwqff8EPr//pyFDnEnuNdcE415+2f02agTnnw9nnBFMmzzZTewL0KpVUFEAlCvnzFHBmZRmdawjQKlS7jlkplBioUiRo1cU+YZYTKbyw5ZXTWfXrVunl1xyidavX18bNWqk3bp1O7Jk6NChQ/Xkk0/WCy64QHv16qVvvfWWrl+/Xk877TRNSkrSJk2a6OjRo1VVdfr06dqwYUNt3rx5hjW4e/bsmaU1uAPccsstWqZMGd3rWxG+f//+euqpp2q3bt2OyKSa3nTWvyTrI488oieffLKef/75evXVVx8xnX355Ze1bt262r59ex00aJD2799fVVU3btyoPXr00CZNmmizZs30p59+0r///lu7dOmiSUlJ2qdPH23fvr1OmTJFVVXHjBmjTZo00caNG+vQoUOzfI2ZkZ33Y8IEZ8bYo0fGtIDZ5CefuPD48emX1/Tnuf5695uUpPqf/+Seeehjj0XP89BD6a/riSeCaWecEfne/PCD6qBBbj81VdVbUv1IOJJZaTiSklS9VXaNOEOMprOiebCpnx2Sk5N1VoiT+iVLltCwYcMESWTkdbLzfnz2mRtIvfDCjKaT/lbH/v0Zvzjnzj36L9mjYcYMZ2YabWnPdeucJVAAVXc9X3/tJpRl18rq88/d2hKhE/+MxCIis1U1OVq+QjNmYRjZITCsFLoG8uefu0V75s1zfeihPXbhuiYSqSjAKbOACeawYc7Uc+FC53oisDhQy5bpFUWgXOnSTkkeDRdemHEmuZF/MGVhGBF4/3244go3iLptW8b0CBbFCaNYsfBrQ4NTXg0bukp/3z43SeyBB2DvXjcO0KmTUxqhStEwAsT11RCRLiKyVERWiMiwMOkDRGSziMz1tut8af1FZLm39c+uDAWlm83IWaK9F3/+6RQFwPbtTjHs3QsrV+aCcNngs8+CpqOhg7433ujJNeXiAAAgAElEQVQURKBVccwxTimULu3s+kuWDA4aZ9f00yj4xK1lISJFgZHA+UAKMFNEJmrGtbQ/UNVBIWUrAQ8CyYACs72ysU9TBkqVKsXWrVupXLlyRBNPo/ChqmzdupVSmfhfCNjzB1iwAI49Ns6CZYEHH3QzuQPUru3MOFu3dnMARo508TNmwOmnRz/eqac6k9MIk/YNI67dUKcDK1R1FYCIjAN6ArE4OOoMTFbVbV7ZyUAXYGxWBKhZsyYpKSlsDqwDaRRaDh1y4w/Fi7uv6lKlSlGzZk3S0twX9/797uu6f3+4777cl++669yErKuuSh/fvn369QpKlXJzGo4/3s1n2L/fzUIOjIf4vLjQoIFTHrFQrhwcOHBUl2AUcOKpLGoAvqkypADhXt3eItIOWAbcoaprI5StEVpQRG4AbgCoXbt2hgMXL16cevXqZVd+I5/z66/OVUbfvsHulerVgxPqHnoIxo4NTiZbtswt4JMIZVG6tBszSEpylXzTpk4p3HGHmwgYcFWjGpzc53l+CUtKSt7wJ2QUHOKpLML1+4R2FH8OjFXVAyIyEHgbOCfGsqjqa8Br4Exnj05co6Bw8KBTDoGvam/OIQDr1wf3/d04fhYsyP65Gzd2y4tmlcBgeaCF4F9Os2FDN1YSzQ2FnxoZPq0M4+iI5wB3CuB301UTWO/PoKpbVTXQ+B0FtIq1rGGE8sgjzsKnatX0lWVaWvp8777rvLZG4misnGrWDB/fq1dw37+YTQD/DOdQTj456DPI7DWMRBHPlsVM4CQRqQesA/oB6Tyyi0g1Vd3gBXsAS7z9r4DHRKSiF+4E3BtHWY0CQCRHdKHrHYSOC+QkZ57p3GQEqFHDjQV8/LEzbX3mGWdl9csvzrUFON9K0ewvAg7vTFkYiSJuykJVU0VkEK7iLwq8qaqLRORh3PTyicBgEekBpALbgAFe2W0i8i+cwgF4ODDYbRihDB2auUO4lJTckWPSJOcHKmBRtHJl0KpKJH0L5+uvgwrixhujHzvgCjuB3tmNQk6Bdvdh5E8CTukC3tlXr3aO60Ite+bMcQPCgYo00fz1l+sCW7TIDaJ36pR5/oCyiPUvmJISnBdhGDlFrO4+bL6mkeeoUAEqVw6G69cPeibdt895cL36auea4skn4y/PHXekD0+bBrNnB9e0GD4cfvopuHBN48bRFQW4NSxuuCF2OWrWNEVhJA5TFkae49AhCLeMxs6dbkGbH38MDlCHGyzOCt995+YYZNYVNHy4+/rfts1NdjvrrPQrtZUu7dZhyCqXXgr/+U/WyxlGIjDfUEaeZebM9MtjVqiQ8+fo2NEpob17gxX3mDFBVx8QdAoYWO40QGBJzmheXA2jIGDKwkg4X33lVjsLNVk977zI60tnh+OOc+MK4ShTxi2ROWoUXHCBa0msXQvTp0fu+rnlFmft5DeLNYyCig1wGwknMNC7ZIkzM42XK+927dxyn2++GZzX4H/9Dx2CDRucnyXDKCzYALeRp1ixIv1X/eHDrqJeuDAY17Bh/BTFp58GB6BPPNFtoTO4ixc3RWEYkbBuKCNXOOkkVxl//bUbI7joInj4YecML6epXt259ZgwAV580bn76NnTtSzatHHWVMuX5/x5DaMgYy0LI9c4dMgNKAcmlg0fnvOL7YwfD23buv19+5y1U8DSqWJFuOsuW7PBMLKDKQsjoWRnRnLoWhN+RNz8h9KloUOHbItlGEYIpiyMuOP3oJoTrFkT3N+82bVYbr3VhStXhlatnCls6FrShmFkH1MWRo5x6BC89JL7Bdi4EebNg4kTj/7YL76YPvzgg27tiSpVnIO+p55yzvratz/6cxmGkRFTFkaO8corbh3oSy+Fp592bi+aN3df/0dLoOUQWMvqoYecS/IApUrBxRcf/XkMwwiPWUMZOUbAAeCnn7otwKOPZv+Y48c7NxvgXIDk9IC4YRixYX89I9usWOFMUqtVgy++gHtzYMWR1avh2muD4d693cxqcDOp84qHWcMobFjLwsgyjzziPK/++ivs2OHiLrww+8e780745hu3tnTduvD6666bKdBSMQwj8ZiyMLJMpBXpskPr1vDssxnjIy1PahhGYrBuKCMmvv3WTWh7/fWjP1ZgbsU//gE//3z0xzMMI/7EVVmISBcRWSoiK0RkWCb5+oiIikiyF64rIvtFZK63vRpPOY3w3H03vPOO2z/vPLd06SuvHN0xL7sMzj/f7Zcta7OpDSO/ELduKBEpCowEzgdSgJkiMlFVF4fkKwsMBn4JOcRKVY2TWzkjGpMmOfNXgP79g/G//Za9423b5txtAGzfDh9+CMMifj4YhpHXiGfL4nRghaquUtWDwDigZ5h8/wKeAsKsjWbkNnv3ujGEbt2O/lj+eQ8BRRHYnzrVPLwaRn4insqiBrDWF07x4o4gIi2AWqr6RZjy9URkjoh8LyJtw51ARG4QkVkiMmtzTsz8Mrj7bhgyJGeO9d57OXMcwzASTzyVRbje6CNLzYhIEeB54K4w+TYAtVW1BXAn8L6IlMtwMNXXVDVZVZOrBhYrMI6Kl1/OXrljj80YZ3MiDKPgEE9lkQLU8oVrAut94bJAE2CqiKwBzgAmikiyqh5Q1a0AqjobWAmcHEdZCyWHD8Orr8Ibb8DkyS4cC337wuWXB8PXXRd++dOiRd1v5cpHL6thGIklnvMsZgIniUg9YB3QDzhSxajqTqBKICwiU4EhqjpLRKoC21Q1TUTqAycBq+Ioa6FD1XlnnTs3GBeYKR2Nxx93LYm1a93kvKJFnVXT4cPOJUfp0i6fCIwe7RYbMgwjfxO3loWqpgKDgK+AJcCHqrpIRB4WkR5RircD5ovIPGA8MFBVt8VL1sLIrFnpFQXAqFHh8159tXPnAXDccc6ZX9Wqbt0IcMuhglMOxxzjZnOfe66L698fGjTIefkNw8hdRP0r1udjkpOTddasWYkWI0+jmj1HfKNGuRXuTjzRuePwr08xdapbrtQc/BlG/kREZqtqcrR89hcvROzdm7X8N93kfhs1CnYtdeqUPk+HDqYoDKMwYL6hChHhBqEz4+WXnUO/445z4YUL4aSTclwswzDyAfZNWEjYvj3janN+2rULHx9QFOAWMypRImflMgwjf2AtiwKOqjOL7dw583ytW8MPP7j9t96C3bvjL5thGPkHUxYFnJdegttui56vcWP3+5//wIABcRXJMIx8iCmLAsJ337nfc85xZrGffw579jhPsbFw1VVw1lnO4skwDCMUUxYFhMC8hk8+Se/ALxw//QRnnhkMT5ni5kiYojAMIxI2wJ3P2bs3vT+naIqiZk1o08aNZVx2mYtr3z5+8hmGUTAwZZHPufpquOWW2PP7Z1O//TZs2WILEBmGER3rhsqn7N4NK1fCRx/FXubMM92iQwGKFzcnf4ZhxIa1LPIhS5ZAuXLQokVseR991O3fdVf6eROGYRixYi2LfMDBgzB/Pgwf7rqRvv029rKnnuoWNDr1VOjVK34yGoZRsDFlkZoKa9ZAlSpQoUKipQnLnXfCyJGx5X31VRg4MH1csWLRB74NwzAyw7qhtm1zDo/efz/RkkQkVkVRp056fbduXXzkMQyj8GHKIuAyNdZl4nKR55/PmqVSmzbQrJnbP+00qF49PnIZhlH4sG6oPKgsrrgC/vgDfvwx83xz50LTpm7luuRkaNvWLT60e3f4NbENwzCyiymLgLJIS0usHD5i6RF77bVgK+K++9KnmaIwDCOniWs3lIh0EZGlIrJCRIZlkq+PiKiIJPvi7vXKLRWRKD5Tj4KiRd1vHmpZRKNr19jXyzYMw8gJ4qYsRKQoMBLoCjQCLhORRmHylQUGA7/44hoB/YDGQBfgZe94OU8e6ob69FNo1Sp6vqSk+MtiGIbhJ57dUKcDK1R1FYCIjAN6AotD8v0LeAoY4ovrCYxT1QPAahFZ4R3v5xyXMg8oiy1boGrVzPOULu3WmTjhBDeQbRiGkZvEsxuqBrDWF07x4o4gIi2AWqr6RVbLeuVvEJFZIjJr8+bN2ZMyD4xZRFMU3bs7h4GXXupWtCtePHfkMgzDCBBPZRHO6FOPJIoUAZ4H7spq2SMRqq+parKqJleNVuNGIsEti/nzI6cVLerciX/8ce7JYxiGEY54dkOlALV84ZrAel+4LNAEmCpuMsEJwEQR6RFD2ZwjgQPc48fDJZeET1u2zM0VNAzDyAvEU1nMBE4SkXrAOtyA9eWBRFXdCVQJhEVkKjBEVWeJyH7gfRF5DqgOnAT8GhcpA7Pe4qwsVqxwk8VPPx0OHYISJcLnW70a6taNqyiGYRhZJm7KQlVTRWQQ8BVQFHhTVReJyMPALFWdmEnZRSLyIW4wPBW4RVXjM6gg4rY4K4tAK+HgwfCK4tpr4bPPoFq1uIphGIaRLeI6KU9VvwS+DIkbHiFvh5Dwo8CjcRPOT5EicRngVnWr2PXuHYwLVRRffQU1akDjxvD66zkugmEYRo5gvqHAjVvEoWWxahUMGhS5tTB9OnTq5BSFYRhGXiYmZSEi5UXk+YCZqog8KyLl4y1crlGkSI4qi2eecT1bN98cOc+GDXDWWTl2SsMwjLgSa8viTWAXcKm37QLeipdQuU4OK4uhQ93v119nTCtdGv71Lze5zjAMI78Qq7JooKoPquoqb/snUD+eguUqOTRm8fjjmbsUf/llN7nu/vuP+lSGYRi5SqwD3PtF5GxVnQ4gImcB++MnVi6TzZZFaipMngzdukXPa/MmDMPIz8SqLAYC7/jGKbYD/eMjUgIoUQIOHIgp68cfw9q10LcvfPgh3H57+HxVq8LPPztrp5tuytoiRoZhGHmNWJXFLlVtJiLlAFR1lzfZrmBQpYrz5heFk0+G5cvd/h13RM73xx9Qu7bbz2yQ2zAMI78Q65jFx+CUhKru8uLGx0ekBFC1KvgcEaamurEFgFdegfbtXcsgoCgyY926oKIwDMMoKGTashCRU3FrSpQXkYt9SeWAUvEULFc57jhSFy3lw/fdkqYibkJdNLp2hVtvdWawl1/uXHrYuteGYRREonVDnQJ0ByoAF/ridwMFZq225OkjmL2pJlzhwpkpinPPhauugnPOgZo106c1aRI/GQ3DMBJJpspCVT8DPhORNqqa8wsP5QG2b8cpijC88IJbP+Knn+DKK13XVOXKtp6EYRiFj1gHuHuJyCKcuez/gGbA7ar6Xtwky0Uee/gQhx59ihqNK3Lt7Jv5+WcoVy7ohqN5c/dbtmziZDQMw0gksSqLTqp6t4j0wq01cQkwBcj3yqJiRbj3geKwaQOMvB8unUqbDz9MtFiGYRh5ilitoQIdL92Asaq6LU7yJI5HHnG/H33kmhTbCt4lGoZhZJdYlcXnIvI7kAx8KyJVgb/jJ1YCqFAB1qxx+4sXu8GJPXsSKpJhGEZeISZloarDgDZAsqoeAvYCPeMpWEKoUwdmzgyGy5YN7w3QMAyjkBHTmIWIXOXb9ye9k9MCJZzk5PTL2XXuDEOGOC+BxeK6VpRhGEaeJdZuqNN8W1vgIaBHtEIi0kVElorIChEZFiZ9oIgsEJG5IjJdRBp58XVFZL8XP1dEXo35inKC4sWdY8HAYtjPPOPi/i5YPW+GYRixEtOnsqre6g97DgXfzayMiBQFRgLn4yyoZorIRFVd7Mv2vqq+6uXvATwHdPHSVqpq85iuIh6IwOrV8MknwXVRjzkGVq6E+gXHO7thGEYsZHdZ1X1ANIfbpwMrvPUvDgLjCBnn8PmZAigDxOBkI5e5+GI3Ky9AgwZusewYvdQahmEUBGJdVvVzEZnobV8AS4HPohSrAaz1hVO8uNBj3yIiK4GngMG+pHoiMkdEvheRthHkuiGw1OtmnyPAHKdNG+cD5KOPXPj666FUKTe2YRiGUQiI5kjwROB44BlfdCpQFFgX5djhVnDI0HJQ1ZHASBG5HLgft07GBqC2qm4VkVbApyLSOKQlgqq+BrwGkJycHP9WSZ8+MGuWGwQHKFkS9u1z3VOGYRgFmGgtixHAblX93rf9iOuGGhGlbApQyxeuCazPJP844CIAVT2gqlu9/dnASuDkKOfLHVq1gnvvDYZLl4Zp0xInj2EYRi4QTVnUVdX5oZGqOguoG6XsTOAkEaknIiWAfsBEfwYR8Y97XAAs9+KregPkiEh93PjIqijnyz0eeyz9OEa7djBnTuLkMQzDiDPRlEVma1Zk2veiqqnAIOArYAnwoaouEpGHPcsngEEiskhE5gJ3ElyqtR0wX0Tm4RZZGpjnXIy0aQN//RUMt2wJs2cnTh7DMIw4IprJ4g0iMhb4TlVHhcRfi3Mu2DfO8sVMcnKyzpo1K/dPrOrGMj75xIXvuQeeeCL35TAMw8gGIjJbVZOj5ouiLI4HJgAHgcBnczJQAuilqhtzQNYcIWHKAtxCF8ceGwxXr+7WVzUMw8jjxKosMu2GUtVNqnom8E9gjbf9U1Xb5CVFkXDKlHEtjOOPd+H162HGjMTKZBiGkYPE6khwiqq+5G3fxVuofMvGjfDss26/TRuYn8E2wDAMI1+S3RncRiTuvBNO9qx8mzWz7ijDMAoEpiziwdKlwf2aNWHHjsTJYhiGkQOYsogXO3cG9ytWhNTUxMliGIZxlJiyiBflykH37sHwkCGJk8UwDOMoMWURTz75BNq3d/svvAA33ZRYeQzDMLKJKYt4Urw4TJ0KY8e68KuvOqVhGIaRzzBlkRv06+dW2wO4/Xb4zqyPDcPIX5iyyC2uvjq4f+65kJKSOFkMwzCyiCmL3KJSpfRzLmrVipzXMAwjj2HKIjepXt25BQkgAocOJU4ewzCMGDFlkQhWrw7ulygBaWmJk8UwDCMGTFkkgrp1YebMYPj66xMmimEYRiyYskgUyckwdKjbf+stmDcvsfIYhmFkgimLRPLkkzBsmNtv3hweeCCx8hiGYUQgrspCRLqIyFIRWSEiw8KkDxSRBSIyV0Smi0gjX9q9XrmlItI5nnImDBG3nneARx6ByZMTJ49hGEYE4qYsRKQoMBLoCjQCLvMrA4/3VTVJVZsDTwHPeWUbAf2AxkAX4GXveAUPEViwAFq0cOFOnSBRK/4ZhmFEIJ4ti9OBFaq6SlUPAuOAnv4MqrrLFywDBOxKewLjVPWAqq4GVnjHK5g0aQKzZwfDp50GixYlTh7DMIwQ4qksagBrfeEULy4dInKLiKzEtSwGZ7HsDSIyS0Rmbd68OccETwgicPhwMNykCdx3X+LkMQzD8BFPZSFh4jRDhOpIVW0A3APcn8Wyr6lqsqomV61a9aiEzROIwP/+Fww//ritg2EYRp4gnsoiBfD7tKgJrM8k/zjgomyWLTh07px+4aTixeHyy01pGIaRUOKpLGYCJ4lIPREpgRuwnujPICIn+YIXAMu9/YlAPxEpKSL1gJOAX+Moa96iXLn0k/bGjoVp0xInj2EYhZ64KQtVTQUGAV8BS4APVXWRiDwsIj28bINEZJGIzAXuBPp7ZRcBHwKLgf8Bt6hq4fKJkZwM48YFw/fdZ25BDMNIGKKaYSggX5KcnKyzCqLJ6ebNcNxxbj8pCebPT6w8hmEUKERktqomR8tnM7jzOlWrwplnuv0FC9wg+PLlmZcxDMPIYUxZ5AdCxytOPhkWLkyMLIZhFEpMWeQHihRx3VF+8+CkpPSD4IZhGHHElEV+oUoV2LQJJk0Kxp1+unNAaBiGEWdMWeQnRKBLF1jrm9w+bx688076FfgMwzByGFMW+ZEaNeC554Lh/v1dV9Vdd5nSMAwjLpiyyI+IwB13OMXw5pvB+Oeeg8qVEyeXYRgFFlMW+Z2rr4auXYPh7dvh3XcTJ49hGAUSUxYFgc8+S78s61VXQePGiZPHMIwChymLgkDx4tC0afq4xYtdd5UIrFiRGLkMwygwmLIoSOzeDfv3Z4w/6aT0a2UYhmFkEVMWBYljj4VSpdyqezfeCB07BtOKFoUDBxInm2EY+RpTFgWRli3h1Vfhu+/g+uuD8aVKwSmnwB9/JE42wzDyJaYsCjqvvpo+vGwZ1K0L994LW7cmRCTDMPIfpiwKOkWKwO+/wxNPpI9/4gnnQuSXXxIjl2EY+QpTFoWBU06Be+6B11/PmHbGGc5yyjAMIxNMWRQmrr0W/v4bXnghfXzjxs7E9sILYd26xMhmGEaeJq7KQkS6iMhSEVkhIsPCpN8pIotFZL6IfCsidXxpaSIy19smhpY1sknJkjB4cPgV9774AmrWhJUrzceUYRjpiJuyEJGiwEigK9AIuExEGoVkmwMkq2pTYDzwlC9tv6o297YeGDlLUpJTCLt3Z5zQd+KJzinh33+b0jAMA4hvy+J0YIWqrlLVg8A4oKc/g6pOUdV9XnAGUDOO8hjhOPZY+O03uPzy9PHPPw/HHOMGyFNTEyObYRh5hngqixqAb+EFUry4SFwL+Fb2oZSIzBKRGSJyUbgCInKDl2fW5s2bj17iwkrRojBmjGtFfP99xvTixd2YxiWXwL59sHdv7stoGEZCiaeykDBxYfs0ROQfQDLwtC+6tqomA5cDI0SkQYaDqb6mqsmqmlzVv+SokX3atXMr8oVj/HgoU8a1Rmw2uGEUKuKpLFKAWr5wTWB9aCYROQ/4P6CHqh6pgVR1vfe7CpgKtIijrIaf446Dzp3hmmugb9/weUqVgocfNp9ThlFIEI3TAKaIFAOWAecC64CZwOWqusiXpwVuYLuLqi73xVcE9qnqARGpAvwM9FTViBMCkpOTddasWXG5lkLPe+85B4U33BA+/f334bLLclcmwzByBBGZ7fXiZJ4vXsrCE6IbMAIoCrypqo+KyMPALFWdKCLfAEnABq/In6raQ0TOBP4DHMa1fkao6huZncuURS7wxx+wZw80aRI5z65dULZs7slkGMZRkSeURW5iyiIXUXU+p26+OXz688+71sg778Ddd7t83brlroyGYcSEKQsjdyhWDNLSoucbOBBGjnSmuIZh5BliVRb2zzWOjmXL4Mknnd+pF1+MnO/VV52J7mOPwZIlNtnPMPIZ1rIwcpaLL4YJE6Ln69cPxo6NvzyGYWSKtSyMxPDxx65bStW1IEaPDp9v3Dg30a9qVejUyU3027jRHBkaRh6lWKIFMAoYIm4DOPVUtx1/PHTtGj7/li0webKb6Bdg40aYN88pEcMw8gTWsjDiT5cuzilhaqqbxPfyy5nnP+EENynwiitg0CCoX9+5GTEMI2FYy8LIHUqWDO7fdJNb0jU5GSpXhtNPd91Rof693n8/uF+mDDz6KJx3nuvqCqz8N2KEG/+oVi3+12AYhRgb4DbyDrt2Ofci//tfbPlLlnQ+qs49F775Jr6yGUYBxQa4jfxHuXIwaZJbye/tt+G22zLPH3Bm+O230LYt1KnjWhzz5plprmHkMNayMPI2S5fCjBnw9NPwww+u2ypWOneGM8+EBx4IDrobhpEOa1kYBYNTToH+/WHhQqhUyfmnOvdc+Prr6GW/+goefNDNGh87Fi66yE0KTE11A+YbN8ZffsMoIFjLwsi/7N4Nc+e6Lqj33oMrr8z6McqVg3//21levf66UyJXX+0G1IuZ/YdR8DHfUEbhIzARsFEj+PJLuOoqZ3WVXS6+GD75BFavdnNFjjkm52Q1jDyCKQvDCPDbb26eR7lysGiRM7XNKmefDX36uO6wQYOgWbOcl9MwEoApC8OIxMKFUL161gbLw9G2LaxaBSee6MZVpk51i0B16eLSV6+GbdugVaujFtkw4oUpC8OIhqqzklqzxlX2O3bA44/D55/DsGFQt272jiuS3nRXFdaudV1kJ5wATZvmhPSGkSPEqixsBM8ovATMaevWhe+/D8YHFmq66y6oVcvNJP/119iPG/oBFs5st2lTN2P9uuvgxhud5dY112R+PDP/NRJIvJdV7QK8gFtW9XVVfSIk/U7gOiAV2Axco6p/eGn9gfu9rI+o6tuZnctaFkbc2bfPWUlBevckxYo5c9yc4oUX3CD9+efDnDnQooWLnzQp2MVlGDlEwudZiEhRYCTQFWgEXCYijUKyzQGSVbUpMB54yitbCXgQaA2cDjwoIhXjJathxETp0m6g/LrrXCWu6rZDh9zvwYPBvI8/nv3z3HabUxQQVBTgPPdWqAAtW7rWztq1bpykdWv488/sn88wYiCek/JOB1ao6ipVPQiMA3r6M6jqFFUNuBOdAdT09jsDk1V1m6puByYD9kllJJ6SJWHUKKhRI2Na8eKwfbsbQB82zLkjmTXLDaT37w8bNjhniFOmZL+FsHOnU1RXXAG1a0PHjq6LrE4duOEGqFLFtXpEYMgQeOst2LQJZs50v4aRTeI5ZlEDWOsLp+BaCpG4FpiUSdkM/04RuQG4AaB27dpHI6th5AwVKrgNoEQJZwm1ZUsw/b773G+HDu533jxo3twpk6+/dgolu4walT787LMZ81Sq5BTeXXc5E2K/0ps61a0rkpzsBvtnzHAuU7Zscd1s5tm3UBNPZRFuNC7sAImI/ANIBtpnpayqvga8Bm7MIntiGkYCadbMjYWUKuW6shYvhiZNXGth3TrX9bVjh3PL/tFHrsyQIfDMM9k737ZtwWMMGRI9f506zsUKwPz5kJSUvfMa+Z54KosUoJYvXBNYH5pJRM4D/g9or6oHfGU7hJSdGhcpDSPRBGaGizhFAW6NDz99+7qFow4fdgPqDzzgurpWr3Ytgr//dvlq1oSUlJyTLaAowFlwLVrkzH+LF3cD8R07OoUWGD957rmgSbJRsFDVuGw4RbQKqAeUAOYBjUPytABWAieFxFcCVgMVvW01UCmz87Vq1UoNo1By+LDqvHnB8KJFqt9/r7pggWrz5oFheNUXXwzuN2kS3I/XNnasalqa6t69qo8+qrp+veqWLarjx6uuW6e6Z4+T98AB1YoVVceMSX9du3er3nGHK2/EDWCWxlCnxz4GcSsAAAq6SURBVNt0thswAmc6+6aqPioiD3vCTRSRb4AkINBR+6eq9vDKXgN4Hbw8qqpvZXYuM501jAjs2+d8ZNWqFT79t98SN8u8c2cn37Rpbizl5pvhrLPcwPx//+vyPP00DBzouuVOOSUxchZgbAa3YRixc+AALF8e7AYDN/i+e7dbEyQtzVlxzZ8PQ4cmTs4Ad9zh5Grd2nkJPu44p0yuusp12anCX385N/QnnOAW07rlFucQ0kiHKQvDMOLHnDluDGPrVueg8c474ZVXXNrs2TB8eLBlkJdo185Zn339tRtfGTDAuagvW9bNY7njDrcGSvnyLv+qVc4cuVy5hIodT0xZGIaRu7z7rptTEnCXEmD+fDjpJGdKLOJWP3z4YVc5lyoFjzwCCxa4vF27upnqxYu7yY55icsuc+umzJ/vTJBr1HAtrwoVnIHBgQOuNSPiBvuvu8518TVo4JTP1KnOA8BppyX6StJhysIwjPxBWhr8/LP7gj/hBOfN9/HH3ZyPgFnx55/D9dc7U2O/a5Xhw53iyevUr+9aKeBaNC1burk2J57ouv/694d33nHWbuEsyQ4fdr/Tp7v9wDydHMCUhWEYBZPDh6FHDxg8GDp1Csb/8Yeb1Nimjat8zz3XjWF07w4TJ8KIEfDqq7BsWeJkD8epp8Lvv6ePGzvWdX3NmuW6xUJp08bNtSlSBHbtcq2cxo2zdXpTFoZhFE5WrHBdPwBvvOEWrQrMqt+2zXWVffCBWwlx6VK3f9VVzk3KkiWu+6tdO6d4ypVzM9jr1HHlq1U7uln28SSbdbkpC8MwjJxi6VLXLVajhhscf+UVt+Tugw+6td8//tiNt6xZ49ylXHIJ9O4NTz4Z9E4cyv33u/GanMKURWyYsjAMI8+xebMz273jDrc1aOCUyPHHu0H8GTNcV1JgQazdu123WWD9lB9+cAoq0FLatMmZDK9cmf48v/+e7TkopiwMwzDyIwFvxU2bOpNecMpj5kw3VyTAvn3OcqxNG7dMcDYxZWEYhmFEJeGLHxmGYRgFB1MWhmEYRlRMWRiGYRhRMWVhGIZhRMWUhWEYhhEVUxaGYRhGVExZGIZhGFExZWEYhmFEpcBMyhORzcAfUTNGpgqwJYfEyUlMrqxhcmUNkytrFES56qhq1WiZCoyyOFpEZFYssxhzG5Mra5hcWcPkyhqFWS7rhjIMwzCiYsrCMAzDiIopiyCvJVqACJhcWcPkyhomV9YotHLZmIVhGIYRFWtZGIZhGFExZWEYhmFEpdArCxHpIiJLRWSFiAzL5XPXEpEpIrJERBaJyG1e/EMisk5E5npbN1+Zez1Zl4pI5zjKtkZEFnjnn+XFVRKRySKy3Put6MWLiLzoyTVfRFrGSaZTfPdkrojsEpHbE3G/RORNEflLRBb64rJ8f0Skv5d/uYj0j5NcT4vI7965J4hIBS++rojs9923V31lWnnPf4Unu8RBriw/t5z+v0aQ6wOfTGtEZK4Xn5v3K1LdkLh3TFUL7QYUBVYC9YESwDygUS6evxrQ0tsvCywDGgEPAUPC5G/kyVgSqOfJXjROsq0BqoTEPQUM8/aHAU96+92ASYAAZwC/5NKz2wjUScT9AtoBLYGF2b0/QCVglfdb0duvGAe5OgHFvP0nfXLV9ecLOc6vQBtP5klA1zjIlaXnFo//azi5QtKfBYYn4H5FqhsS9o4V9pbF6cAKVV2lqgeBcUDP3Dq5qm5Q1d+8/d3AEqBGJkV6AuNU9YCqrgZW4K4ht+gJvO3tvw1c5It/Rx0zgAoiUi3OspwLrFTVzGbtx+1+qeoPwLYw58vK/ekMTFbVbaq6HZgMdMlpuVT1a1VN9YIzgJqZHcOTrZyq/qyuxnnHdy05JlcmRHpuOf5/zUwur3VwKTA2s2PE6X5FqhsS9o4VdmVRA1jrC6eQeWUdN0SkLtAC+MWLGuQ1J98MNDXJXXkV+FpEZovIDV7c8aq6AdzLDByXALkC9CP9nzjR9wuyfn8Scd+uwX2BBqgnInNE5HsRaevF1fBkyQ25svLccvt+tQU2qepyX1yu36+QuiFh71hhVxbh+hVz3ZZYRI4FPgZuV9VdwCtAA6A5sAHXFIbclfcsVW0JdAVuEZF2meTN1fsoIiWAHsBHXlReuF+ZEUmO3L5v/wekAmO8qA1AbVVtAdwJvC8i5XJRrqw+t9x+npeR/oMk1+9XmLohYtYIMuSYbIVdWaQAtXzhmsD63BRARIrjXoYxqvoJgKpuUtU0VT0MjCLYdZJr8qrqeu/3L2CCJ8OmQPeS9/tXbsvl0RX4TVU3eTIm/H55ZPX+5Jp83sBmd+AKr6sEr5tnq7c/GzcecLInl7+rKi5yZeO55eb9KgZcDHzgkzdX71e4uoEEvmOFXVnMBE4SkXre12o/YGJundzrE30DWKKqz/ni/f39vYCApcZE/r+9+wmxqgzjOP79jUHZPylHJIoiK2gRCDHIFC0iwiIoiBYVwUS2KVq1qpDAXbkLMYiIMtq0ESwoMhhIiIIKa1IhaxJxY6Al/UEIkafF8xw5itczf+69h+r3gcMc3rlz73Pf++c5533PvA88JuliSTcCt5ATa8OO6zJJVzT75ATp/nr85mqKJ4EPWnHN1BUZ08DvzanyiJx1xNd3f7Ustn92AxslXVVDMBurbagk3Q+8ADwUESdb7Wskraj9dWT/HKrY/pQ0Xe/RmdZzGWZci33dxvl5vRf4ISLODC+Ns78GfTfQ53tsOTP2/4WNvIrgR/IoYfOYH/su8pTwe+C72h4A3gP2VfuHwDWtv9lcsR5kmVdcXCCudeSVJnPAgaZfgNXALPBT/by62gW8XnHtA6ZG2GeXAr8Cq1ptY+8vMlkdBU6RR29PL6V/yDmE+dqeGlFc8+S4dfMee6Nu+0i9vnPAXuDB1v1MkV/ePwPbqdUehhzXol+3YX9ezxdXte8AnjnntuPsr0HfDb29x7zch5mZdfq/D0OZmdkCOFmYmVknJwszM+vkZGFmZp2cLMzMrJOThdkCSJqQtFvS9X3HYtYHXzprtgCSbgKui4g9fcdi1gcnC7MOkk6T/+jUeD8iXu0rHrM+OFmYdZD0V0Rc3nccZn3ynIXZEimrqG2V9FVtN1f7DZJma+nt2WaeQ9JaZaW6udrurPZdtRT8gWY5eEkrJO2QtF9Zge35/p6pGVzUdwBm/wIrVaU1yysR0axG+kdEbJA0A7xGruy6nSxE866kTcA2skjNNmBPRDxcC9I1ZyubIuI3SSuBryXtJKuyXRsRtwGoSqGa9cXDUGYdBg1DSToM3BMRh2o56V8iYrWk4+SieKeq/WhETEo6Rk6S/33O/WwhV12FTBL3kQvofQN8DHwEfBq5lLdZLzwMZbY8MWB/0G3OIulucjnsOyJiPfAtcElkCcz1wGfAc8BbwwjWbKmcLMyW59HWzy9r/wuy1gLAE8DntT8LPAtn5iSuBFYBJyLipKRbgen6/SQwERE7gZeB20f9RMwuxMNQZh3Oc+nsJxHxYg1DvUPWGZgAHo+I+aqZ/DYwCRwjawgckbQWeJOsF3KaTBx7gV1kXeSDwBpgC3Ci7rs5oHspItq1s83GysnCbIkqWUxFxPG+YzEbNQ9DmZlZJ59ZmJlZJ59ZmJlZJycLMzPr5GRhZmadnCzMzKyTk4WZmXX6BygIB+61ZiRLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna5.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna5.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[10027   767]\n",
      " [ 1577  1438]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[9989  806]\n",
      " [1614 1401]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEYCAYAAADYs6SAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XecVNX5x/HPd1mqVAuKIIIIKqgoKtiDiiiWQGyxoyFqEntiEkWjxthSLVFjSDSCMSqW2MWOUX6CAqJCVBYEFVADAgoCUnx+f5wzeBl2dmZgd2ZneN687ou5555777mzM8+ccovMDOecc7mpKHYBnHOulHjQdM65PHjQdM65PHjQdM65PHjQdM65PHjQdM65PHjQdM65PHjQdM7lTNJoST8sdjmKqd4HTUkzJS2VtDgxbRmXDZP0vqRvJJ2W4/ZaS7pT0qeSFkmaKumXdXoQdUjSLpImSFoS/9+lhryjJS1LvI/vJ5YdIOkdSQslfS7p35Lap63fT9JESV9J+ljScYllFtNT2/57YtnTaX+/5ZLeSdv2+ZJmxG28K6lbYtmJkj6Myx6RtHFMbyzpjrhskaQ3JQ3IcOxXxDL2S6TdFcuSLFuDuKyRpAfj588k9U3b3gGSXpL0haSZGfZZ0zGdG5d9KWm8pH1z3XZcNjeu+5akgdXtv5r1TojHo7T0Skn/k3RELtupYftXSloR/xap79YtktrlsY36H5TNrF5PwEygX4ZlZwMHAeOB03Lc3j+AkUAbwo/G9sAxtVzmygK9N42AD4ELgcbAeXG+UYb8o4EfZli2ObBlfN0Y+B3wWGJ5d+B/wACgEtgE6JJYbsC2OZZ7NHB5Yv6HwNtxHwK6ABvHZT2ARcD+QHPgX8B9cdlGwJVAp/i3PCLm7ZS2vy7AO8Cc5GcJuAu4uob39gJgX+AToG/a8t7AKcCZwMxq1q/pmPoAXwG7xWU/BuYCDXLc9s6pz1jc1iKgXQ7vexNgYTXHcgTwWS6f2yyfoSuBf8bXDePf7sH4vmctX7bt15ep6AXI4U2cSYagmcjzKrkHzcnAoBqW9wCeA+bHD9LQmN4YuDF+AObE143jsr7ALOCXwKfA3YkP46T4Qf0/YOdafm/6A7MBJdI+Ag7NkD+nD2Q81uuA/ybS/gX8poZ1cgqahAC3Cugc5yuAj4GDMuS/FvhXYr4LsBxokSH/28DRaWlPA4elf5aoIWimrT8rPdAklvVLD2w5HNP3gdcT8xvF969dtm1Xs63ewDKgd46fmWHAnWlpI4E/xddtgCcIQXxBfN0hl88QiaCZSGsAvAX8Idv2gWviZ2MZsBi4JabfFN/PL4EJwH61+T3Kd6r3zfM6MBa4RtLpkromF0hqATwPjAK2BLYFXoiLLwX2BHYBehI+rJclVt8C2BjYGjhTUi/gTuAsQq3sr8BjkhpXVyhJb8emcXXTbRmOpQfwtsVPVvR2TM/kOknzJI2ppsnZUdJCYClwEaG2mbJnzPOOpE8k/TPVTE74j0K3x8OSOmXY/6nAK2Y2I853iNOOsck/Q9KvJaU+mz0IXzoAzGw6IWh2I42kzWP6lETascByM3sqQ3l+Imm+QtfG0Rny5CvbMT0NNJDUJ3YH/IDw4/pprjuQ9ISkZcA4QiAbH9M7xs9MxwyrDgeOkdQ05m8FHAmMiMsrCK2xrYGOhM/CLbmWK52ZrQIeBfbLtn0zuxR4BTjHzJqb2TlxnTcI37uNCT/eD0hqsq5lWm/FjNg5/jLOJPzqLIzTI9Xkyaem2RQYSvjFWgFMAwbEZScAb2ZYbzpwWGL+EGItgFDTXA40SSz/C2k1M+B94Du1+N78ithUTaTdA1yZIX8foAWhJjmY0KzrUk2+jQm15j0Tacvj36IboZn8EHBPYvn+hCZta8KXYDLVNPfi+31aYn5vQi3rybhuJ2AqcEZc/gLwo7RtzGbtJmZDwg/eXxNpzYEqvq3VzmTNmmYvwg9aJaEmugjYp5oy51vTzHZMip/BFcBKYB6wRy7bruaYBwAX5vm5qQJOjK/PAN6qIe8uwILE/GjyqGnG9B8BVeu7/USeBUDP2voe5TuVSk1zkJm1jtOg9dmQmS01s2vNbDfCF2Yk4ZdrY2ArQnCszpaE/sKUD2NaylwzW5aY3xr4WbLGGLefXGd9LQZapqW1JHz512Jm48xskZl9bWbDgTGEYJGebz6hRvKopMqYvBT4h5lNNbPFhGbzYYl1/mNmy81sIXA+0BnYIbndONixBaGfK2Vp/P93ZrbQzGYSauWpbWc9xliDu5sQ2M9J5Ps1oatkBtUws4lm9rmZrbRQE70HOKq6vHnKdkw/JNQuexB+aE4GnlAc4MyVma0ws6eBQyR9N49VRxBq/BD6ToenFkhqJumvcXDtS+A/QOvUANk6ak/o7lqn7Uv6WRxI+yJ+j1oBm65HedZLqQTNOmFmXxK+/BsRvuQfE/rMqjOHEAhTOsa01ZtLy/8xcE0i2Lc2s2Zmdm91G5c0JW0UNzndnqFMU4Cd00ZDdybRPM3CCLWe6lQCbfk2YL3N2seY77YHAw/HoJvyPiHYZdr2FEJ3CACStiHUlKfGeQF3EAayjjazFYl1DwLOi10GnxJ+tEYq89kSNb0f+ch2TD2Bx+MP0DdmNoow2LT3Ou6vksyf2+qMAA6StBeh2+VfiWU/A7YD+phZS0ILAtbxfYk/aEcSmt25bN/S1t+P0Oo5DmhjZq2BL9a1PLWiWFXcXCdqHj1vRBgRHENoZjQBKrJs71fAHol1LyVU95sTmq6fEEZNG8f5PnG9qwmDOZsRfuVeJQ4iEAeC0vazOyFw9iH8gTcCDifDAMY6vjep0fPzY3nPIcPoOaGZeEg85krgJMII7nZx+VGED3NFPMaRwMTE+j8AZgDbAM3i8tSAVw9CM6tBfB9vJASOhon1mxK6Vw6spmwjCAMCLQh9ge8BQxLb/pLQJ7YR8E8SXRLA7YR+6ubVbHcTQs02NX0MHJvKCxwTy1tBGFRbRKIZHt/TJoTmef/4WnFZRZwfEN/zJsn3PcsxDSYE/W3iZ+NgYAmwfbZtE872GBDfz4aEWupyoFeen52XCN+tJ9PSf0foc21C6Kb5NyGQpUbrR5P76PkOwP2Evtotc9z+fcC1iW0eRqicbEH4vF9OGCyqcXC4TmNSsXacxx93ZqY3KP4BLW3qm2V7lxH6274kNBlGA3snlu9I6EdbEP/YF8f0JsDNhKD6SXzdJC7rS1rQjOmHEjqxF8Z1HqAWg2bcx66E/tmlwERg18SyocDT8fVmsSyLYnnGAgcn8p5LCIpfxeO+D9g6bV+/Jox6ziU0h9vE9AMJQfIrwmlJjwBd09Y9gRAAVM0xtIz7W0QIbJez5hkBJxLOCviKMKiQOnVn6/g3T422pqaTcvksEWo/X8TPwlvA8dXkT/98dUr8zdOXjc7lmAiB8qp4TIuAd4FTEutm3DYhEI1L/B3fAL6XWLdjfA86ZvncnBa3+/209C0J34nFhMB+FvkFzRVx3a8Ifae3Ae3z2P5eMX0B4TvWgNCS+JLwHfpF+t+x0FPqj+iccy4HG3SfpnPO5assg6bWvmwvNQ0tdtmcc6XNm+fOOZeHyuxZXDpVNjU1alHsYmxwdt0h00Uuri5NnDhhnpltVhvbatBya7OVS7Pms6VznzGzQ2tjn7XNg+Y6UKMWNN7uuOwZXa0aM26dr+Zz66FpQ32YPVdubOXSnL47yybdWrST17PxoOmcKxwJKtbn4qLi86DpnCsslfb4swdN51xhqXhXQNYGD5rOuQLy5rlzzuVOePPcOedyJ2+eO+dcXrx57pxzuZI3z51zLmfCa5rOOZc7r2k651x+KnwgyDnncuPNc+ecy4c3z51zLj9+nqZzzuXI73LknHN58ua5c87lwZvnzjmXK2+eO+dc7vwuR845lw+vaTrnXH68pumcc3nwgSDnnMuRn6fpnHP5kdc0nXMuN8KDpnPO5U5Cfms455zLndc0nXMuDx40nXMuV8Kb5845lyshr2k651w+Kir8iiDnnMuZ1zSdcy5XilMJ86DpnCsYIW+eO+dcPrx57pxz+SjtmElp15Odc6VFYfQ825R1M9KFkqZImizpXklNJHWWNE5SlaT7JTWKeRvH+WlxeafEdi6J6e9LOiSXQ/Cg6ZwrKElZpyzrtwfOA3Y3sx2BBsDxwG+BG8ysK7AAGBJXGQIsMLNtgRtiPiR1j+v1AA4FbpOU9b51HjSdcwWTOrl9fYJmVAk0lVQJNAM+AQ4EHozLhwOD4uuBcZ64/CCFnQwE7jOzr81sBjAN6J1txx40nXOFEy+jzDYBm0oan5jOTG3CzGYDfwA+IgTLL4AJwEIzWxmzzQLax9ftgY/juitj/k2S6dWsk5EPBDnnCirHmuQ8M9s9w/ptCLXEzsBC4AFgQDVZLbVKhmWZ0mvkNc0ycPYJfRn/wFAmPHgp55zYF4CdurVn9PCf8cbIoTx441m02KgJAJWVFfztqlN4Y+RQ3nzoMi76Qf8at+Nyc/ONN9CrZw9222VHTj35BJYtW8bMGTPYb+8+7LhDV04+8fssX758df4HHxjJrjt3p1fPHgw+5cQilrzwcqxp1qQfMMPM5prZCuBhYG+gdWyuA3QA5sTXs4CtAOLyVsD8ZHo162TkQbPEde/SjtOP2pv9Tvk9vb9/HQP235EuHTfjL5efyGU3P8oex13LYy+9xYWDDwLg6H69aNyokj2Ou5a9T/otPzx6Hzq22zjjdlx2s2fP5rZbb2bM2PFMmDSZVatW8cD993Hp0F9y7vkXMvndKtq0bsNdd94BwLSqKv7w2+t48eUxTHxrCr//441FPoLCqoU+zY+APSU1i32TBwH/BV4Cjol5BgOPxtePxXni8hfNzGL68XF0vTPQFXg9287rLGhK6iRpqaRJcX5mIn1yWt4rJV1UV2VJ29fQtPlUubpImiRpcSHKUVu277wFr78zk6XLVrBq1Te8MmEaAw/oSdet2/LqhGkAvDj2PQYdtAsAhtGsSSMaNKigaeNGLF+xikVfLcu4HZeblStXsnTp0vD/kiVs0a4dL7/0IkcdHb7DJ50ymMcfewSAO+/4G2f9+GzatGkDQNu2bYtW7kLLJWBmC5pmNo4woDMReIcQx4YBvwR+Kmkaoc/yjrjKHcAmMf2nwMVxO1OAkYSAOwo428xWZTuGuq5pTjezXep4H/kaWl2imdXHsmY1Zfoc9u21LRu32oimTRpy6L496LBFG/47/ROO6LsTAEcd3IsOm4cv6MPPv8mSZcuZ8dw1TH36Km4c8QILvlyScTsuu/bt23PBhRfRbZuOdN6qHS1btmLXXrvRqnVrKitDa7F9hw7MmTMbgKqqqVRVTeWA/fdh/3325NlnRhWz+AVXG+dpmtkVZra9me1oZqfEEfAPzKy3mW1rZsea2dcx77I4v21c/kFiO9eYWRcz287Mns6l/IUcCJqbSyZJuwC3E04jmA78wMwWSBoNjAMOAFoDQ8zslXhe1fVAX6AxcKuZ/VVSO+B+oCXhOH8MHE44TWESMMXMTsqjXGcCYQSvYfNcVimI92d8xh/veo4n/nIOXy39mrenzmblylWcdeU9/PEXx3DJGQN48uV3WL4i/IDu0aMTq1Z9wzb9L6VNi2Y8f+eFvDjuvYzbcdktWLCAJx5/lHerZtC6dWtOPP5Ynh219vdPcdxh1cqVTJtWxbMvjGb2rFkcdMB+TJg0mdatWxe66MVR4lcEFSxomtkeidkuqWZ7tAXhFAKAEcC5ZvaypKuAK4AL4rJKM+st6bCY3o9w4uoXZraHpMbAGEnPAkcBz5jZNTGwNotB9pxkjTKtXDWVfxihCUBFs7ZZR9gKafgjrzH8kdcA+PU5RzL7s4VMnfkZR/7kVgC27diWAfv1AOC4Abvz7P/9l5Urv2HugsW8NukDduvekZmzP692Oy67F194nk6dOrPZZqEPeNCgoxj72v/xxcKFrFy5ksrKSmbPmkW7LbcEoH37DvTusycNGzakU+fOdOu2HdOqqth9j5w+iiWv1K89L9ZA0HQz2yU1EWqWSGoFtDazl2O+4cD+ifUejv9PADrF1/2BU2MQHkfoy+gKvAGcLulKYCczW1SHx1NUm7UJNd+ttmjDwAN7MnLU+NVpkrj4jEP424OvAjDr0/n03WM7AJo1aUTvnTvx/szPMm7HZbfVVh15/fWxLFmyBDPjpRdfYPsdurN/3wN4+KFwrvU9dw/niCMHAnDkwEG8PPolAObNm0dV1VQ6b7NN0cpfSBJUVCjrVJ+V2nmaX8f/V/Ft2UWomT6TnlnS/oQm+d2Sfm9mIwpTzMK69w8/ZOPWG7Fi5SouuH4kCxct5ewT+nLW98PvzaMvTmLEo2MBuP3+/zDs1ycz4cFLkeDuR8cyuWpOxu247Hr36cP3jjqGvXr3orKykp49d2XIGWcy4LDDOeWk4/n1FZfRc5ddOe0H4aq+g/sfwvPPPcuuO3enQUUDrr3+92yyySZFPopCKf3HXSiMvNfBhsNF8U/Ea0NrTI+1wcVm9gdJbwHnxKb0lUArM7sw9mleZGbjJW0KjDezTrGv8TDgWDNbIakbMBvYFJhtZislXQB0MrMLJC0A2sbzu6or92Izq7HTsqJZW2u83XF5vydu/Sx445ZiF2GD1LShJmQ60TxfTbboZh1PvTlrvqrfD6i1fda2+ljTHAzcLqkZ8AFwepb8fyc01SfGc7bmEq457Qv8XNIKYDFwasw/DHhb0sQ4EOScK5TYPC9lBQ+aZjYT2DEt7crE60nAntWs1zfxeh6xT9PMviGcRpR+KtFwvr1IP7mdXxLO53LOFZgo/aBZlwNBq4BWaaPk9Vbq5Hbgs2KXxbly5gNBGZjZx6x5XWe9ZmbTgZI7ud25kqIwgl7K6mOfpnOuTInSP0/Tg6ZzroDqf/M7Gw+azrmC8pqmc87lyvs0nXMud+VwypEHTedcQXnz3Dnn8lDiMdODpnOucOSXUTrnXD5K/y5HHjSdcwXlNU3nnMuVn3LknHO588sonXMuT948d865PHhN0znnclXOfZqSWta0opl9WfvFcc6VM5X5XY6mAMaaj3ZPzRvQsQ7L5ZwrUxUlXtXMGDTNrGTuuu6cKx0lHjNze0aQpOMlDY2vO0jarW6L5ZwrRxI0qFDWqT7LGjQl3QIcAJwSk5YAt9dloZxz5UtS1qk+y2X0fG8z6yXpTQAzmy+pUR2XyzlXhkQZ92kmrJBUQRj8QdImwDd1WirnXNmq563vrHLp07wVeAjYTNKvgVeB39ZpqZxz5SmHpnl9b55nDZpmNgK4DPgDMB841szuq+uCOefKj6i9gSBJrSU9KOk9Se9K2kvSxpKek1QV/28T80rSzZKmSXpbUq/EdgbH/FWSBmfbb06j50ADYAWwPI91nHNuLVL2KUc3AaPMbHugJ/AucDHwgpl1BV6I8wADgK5xOhP4SyiLNgauAPoAvYErUoE2k1xGzy8F7gW2BDoA/5J0Sc6H5ZxzCbXRPI9XLO4P3AFgZsvNbCEwEBgesw0HBsXXA4ERFowFWktqBxwCPGdm881sAfAccGhN+85lIOhkYDczWxILew0wAbguh3Wdc2611HmaOdhU0vjE/DAzG5aY3waYC/xDUk9CTDof2NzMPgEws08ktY352wMfJ9afFdMypWeUS9D8MC1fJfBBDus559xacmx9zzOz3WtYXgn0As41s3GSbuLbpniuu02/TDyZXuOOq9+DdENceQkwRdIzcb4/YQTdOefyVkuj47OAWWY2Ls4/SAian0lqF2uZ7YD/JfInLw3vAMyJ6X3T0kfXtOOaapqT4/9TgCcT6WNr2qBzzmUi1c5lkmb2qaSPJW1nZu8DBwH/jdNg4Pr4/6NxlceAcyTdRxj0+SIG1meAaxODP/2BGsdsarphxx3rc1DOOVedWjwN81zgnniF4gfA6YTB7ZGShgAfAcfGvE8BhwHTCK3n02H1FY6/Ad6I+a4ys/k17TRrn6akLsA1QHegSSrdzLrlfGjOOce352nWBjObBFTX73lQNXkNODvDdu4E7sx1v7mcc3kX8A/C8Q4ARgJ+crtzbp2U/RVBQDMzewbAzKab2WWEux4551zelMNUn+VyytHXCqF/uqQfAbOBtlnWcc65teRxnma9lUvQvBBoDpxH6NtsBfygLgvlnCtf9b35nU3WoJk4D2oR396I2Dnn1kmJx8waT27/NzWcGW9mR9VJiZxzZau2ztMspppqmrcUrBQlZqfttuLpl/5U7GJscBYtXVHsIrhaULbNczN7oZAFcc5tGEr93pK5DAQ551ytqM2T24vFg6ZzrqBKPGbmHjQlNTazr+uyMM658lYO52nmcuf23pLeAarifE9Jf67zkjnnylItPu6iKHLpk70ZOAL4HMDM3sIvo3TOrYPUc8+zTfVZLs3zCjP7MO00gVV1VB7nXJlrUL9jYla5BM2PJfUGTFIDwj3sptZtsZxz5UglUJPMJpeg+WNCE70j8BnwfExzzrm8lXjMzOna8/8BxxegLM65MiegssRHz3O5c/vfqOYadDM7s05K5Jwra2Vf0yQ0x1OaAN9jzecEO+dcbrQBnNxuZvcn5yXdDTxXZyVyzpUtAQ1KvKq5LpdRdga2ru2COOc2DGVf05S0gG/7NCuA+YSHsjvnXN7K9tZwAPHZQD0JzwUC+CY+CtM55/IWrj0vdinWT43FjwHy32a2Kk4eMJ1z66XUL6PMJea/LqlXnZfEOVf2wv00s0/1WU3PCKo0s5XAvsAZkqYDXxGO28zMA6lzLk+iot4/2bxmNfVpvg70AgYVqCzOuTInyvvkdgGY2fQClcU5V+5U3pdRbibpp5kWmpk/jtE5l5dyr2k2AJpDiXdAOOfqlfo+Op5NTUHzEzO7qmAlcc6VvXAZZbFLsX6y9mk651ytUelfEVTTGVEHFawUzrkNhnKYctqO1EDSm5KeiPOdJY2TVCXpfkmNYnrjOD8tLu+U2MYlMf19SYfkst+MQdPM5udYduecy0nqLkfZphydD7ybmP8tcIOZdQUWAENi+hBggZltC9wQ8yGpO+EG6z2AQ4Hb4iN9alTPz713zpWb2niEr6QOwOHA3+O8gAOBB2OW4Xx7jvnAOE9cflDMPxC4z8y+NrMZwDSgd7Z9r8ut4Zxzbp2InGuSm0oan5gfZmbDEvM3Ar8AWsT5TYCF8SpGgFlA+/i6PfHG6Wa2UtIXMX97YGxim8l1MvKg6ZwrqBwHguaZ2e4Z1j8C+J+ZTZDUN5VcTVbLsqymdTLyoOmcK6haGDvfB/iupMMIj+BpSah5tk7cM6MDMCfmnwVsBcySVAm0ItwXOJWeklwnI+/TdM4VjLT+A0FmdomZdTCzToSBnBfN7CTgJeCYmG0w8Gh8/VicJy5/Md7m8jHg+Di63hnoSrjnRo28pumcK6g6PE/zl8B9kq4G3gTuiOl3AHdLmkaoYR4PYGZTJI0E/gusBM42s1XZduJB0zlXULUZMs1sNDA6vv6Aaka/zWwZcGyG9a8Brslnnx40nXMFs6E+jdI559ZZicdMD5rOuUISKvHbWnjQdM4VjDfPnXMuHzleJlmfedB0zhVUOd+E2DnnapWAEn9EkAdN51xhlfpAkF9GWeJ+es6Z7Ny1Awfutesa6XcOu5X99tiRA/bahasvvwSA+fM/55gj+9O1w8Zc+vPzq93eaScctda23NrO/8kZdN+mPfv32WWtZbfe/CfatmzE55/PA8DMGPrzC+ndcwe+s1cv3p705uq83//eEWy71WacdOyG86TsCinrVJ950Cxxx51wCvc8+PgaaWNeGc0zTz3O869O4KXXJvGjcy8EoEnjJvxi6BX86qrrq93WU48/wkYbNa/zMpeD4086lfsefmKt9NmzPublF1+gw1YdV6e98OwoPpg+jXGT/ssfb/oLv7jwnNXLzj7/p9w67B8FKXN9kGqeZ5vqs4IHTUmdJC2VNCnOz0xPT0yN6mD/fRO3xz9N0pXx9YWSPpJ0S23vsy7tuc9+tG7TZo20EXcO4+wLfk7jxo0B2HSztgA022gjeu+1D42bNFlrO18tXsywW2/i/IsuqftCl4G9qnnfAX51yUVc/ptr17i++umnHue4E05CErv37sMXXyzks08/AWD/vgfSvHmLtbZTvpTTv/qsWDXN6Wa2drsmpiem5cmF8bZOdcLMbgAur6vtF9IH06p4/bUxHNFvX44+vB+TJo7Pus7vrr2Ss865gKbNmhaghOVp1FOP065de3bcqeca6Z/OmcOWHb69A9mW7TvwyZysdyArTznUMr2mmd3cmhZKulLSMEnPAiNijfQVSRPjtHfMt7oGGedvkXRafH2opPckvQocldj8UmBxLoWUdKak8ZLGfz5vXp6HWFirVq7ki4ULePy5V7jsquv40eknEu6EVb3J77zFzA+mM+CIgQUsZXlZsmQJN/7+en556RVrLavuvS/1JzKuq9A8L+0+zaKPnpvZHonZLqlmOzDGzM6Or3cD9jWzpZKaAQeb2TJJXYF7gWrv8AwgqQnwN8LzQ6YB9yf2fX+m9aop5zBgGEDPXXfLenfnYmrXvj0DjhyEJHbdbQ8qKiqY//k8Ntl0s2rzT3h9LO+89SZ9du7GylUr+Xzu/zjmiIN58InnClzy0jVzxnQ++nAmB+wTPopzZs+i3359GPXSGNq1b8+cWR+vzjtn9iy2aNeuWEUtuvodErOrDzXNpGTz/OxE+mNmtjS+bgj8TdI7wANA9yzb3B6YYWZV8caj/6z9Ytcvhxz2Xcb8ZzQA06dNZfnyFWy8yaYZ8w8echYT353JuLen8sjTL7JNl64eMPPUvcdO/PeD2UyYXMWEyVVs2b4Dz78yjs0334JDBxzByHvvwcwY//o4WrZsxeZbbMBBU8o61WdFr2nm6KvE6wuBz4CehKC/LKavZM0fgeRoR72uGa6Pnww5hdfG/If5n89jtx7bcNHFv+L4k0/jZ+ecyYF77UrDRo248S9/X/1B7LNzNxYv+pLlK5Yz6qnHufehJ+m2/Q5FPorSc9bpJzPm1fC+99y+M78YejknnXp6tXn7HTKA558dRe+eO9CsWVNuuu3vq5cdecgvoFNdAAAPSElEQVQBTJv6Pl99tZie23fmhlv+yoH9+hfqMIqinsfErEolaCa1AmaZ2TeSBgOp5xR/CHSX1JgQMA8CXgXeAzpL6mJm04ETilHounLbHXdXm/7nYXdVmz7u7ak1bm+rjp148bU3a8zj4K//qLnBMmFy1erXkvjtn26uNt/jz7xUq+UqBaUeNOtb8zwXtwGDJY0FuhFroWb2MTASeBu4h3C7+9Rdm88EnowDQR8Wo9DOudCfWeqnHNWbmqaZzQR2rCb9yrT5KmDnRNIliWW/IDwLOX0bowh9m865YiqDuxwVo6a5CmiVGCWvFyRdSAjAXxa7LM6VMyn7VJ8VvKYZm9FbZc1YYPHk9huKXQ7nylv9b35nU2+a5865DUN9r0lm40HTOVcwwoOmc87lxZvnzjmXB69pOudcrkpgdDwbD5rOuYLy5rlzzuXIH6zmnHP58qDpnHO58+a5c87lwZvnzjmXjxIPmqV4azjnXImqrVvDSdpK0kuS3pU0RdL5MX1jSc9Jqor/t4npknSzpGmS3pbUK7GtwTF/VbxHb408aDrnCqf2nka5EviZme0A7AmcLak7cDHwgpl1BV6I8wADgK5xOhP4C4QgC1wB9AF6A1ekAm0mHjSdc4WlHKYszOwTM5sYXy8C3gXaAwOB4THbcGBQfD0QGGHBWKC1pHbAIcBzZjbfzBYAzwGH1rRv79N0zhVQzreG21TS+MT8sPhE2LW3KHUCdgXGAZub2ScQAquktjFbe+DjxGqzYlqm9Iw8aDrnCiaPk9vnmVnGR3Ov3p7UHHgIuMDMvqzhSZbVLbAa0jPy5rlzrrBqoXkOIKkhIWDeY2YPx+TPYrOb+P//Yvos1rz5eQdgTg3pGXnQdM4VVIWUdcpGoUp5B/Cumf0psegxIDUCPhh4NJF+ahxF3xP4IjbjnwH6S2oTB4D6x7SMvHnunCuoWjpNcx/gFOCdxPPGhgLXAyMlDQE+Ao6Ny54CDgOmAUuA0wHMbL6k3wBvxHxXmdn8mnbsQdM5Vzi1dGs4M3uVzPH3oGryG3B2hm3dCdyZ6749aDrnCiY87qK0LwnyoOmcK6jSDpkeNJ1zBVbiFU0Pms65wvLmuXPO5aG0Q6YHTedcAckfrOacc/nx5rlzzuWhtEOmB03nXEHldplkfeZB0zlXMOHk9mKXYv34DTuccy4PXtN0zhWUN8+dcy5XfsqRc87lLo97DNdbHjSdcwXl52k651weSjxmetB0zhVWicdMD5rOucIq9ea5wl3gXT4kzQU+LHY51tGmwLxiF2IDVMrv+9ZmtlltbEjSKMJ7kc08Mzu0NvZZ2zxobmAkjc/ledKudvn7Xj78iiDnnMuDB03nnMuDB80Nz7BiF2AD5e97mfA+Teecy4PXNJ1zLg8eNJ1zLg8eNJ1zLg8eNDcwkvxv7tx68C/QBkRSczP7xgNnYUk6T1L/YpfD1Q7/8mwgJD0KzJTU3gNn4UgaCvwEOEbSgGKXx60//+JsACR1BCYBfwFe88BZUI8ABwOvAUd54Cx9fpejMidpLzN7DbgizjcExknqY2azJVWY2TfFLWX5kfR9oLWZ/TXOvwQ0Bb4nCTN7uqgFdOvMaxplTNLWwDOSTk6lmdnFwHBC4PQaZ91ZAXSRNATAzGYCjxFq/N/zGmfp8ppmmYo1yA8lHQDcL2kyMNnMVprZpfGehuMk9TazOV7jrB2SzgUamtmfJH0NrEotM7NZkh6Ls0dJkpk9VZSCunXmQbMMSdrZzN6Os18Cu5vZwriswsy+iYGzAfB6KnAWrcBlQlJj4D3gJ5IWmtmdiWWyYJakJ4HFwNGSFpnZK8Uqs8ufN8vK0wmSHpP0IHBsesBMNcdjU/0hYJQk/wFdD5IamNnXwKvA68APU03zVJbUCzP7MObZB5hb0IK69eY37CgjySa2pDnAMjPbJs43MrPl8bUIf/tvJN0CPGJmzxet4GUi/hg9C0wEtgTaAM+a2U2p5Ym/z77AYjObVKzyunXjQbNMxJrOqjg63g3YCTgbmGtmR8U8srQ/eDzhfXHhS1x+JB0InGlmx0tqBfQELgYeTDbVXWnz5nkZiDWYVYmazs5mdp+Z7Qe0lfRIzPpnSWs8csED5rpT4glhkpoAy4HdJLU0sy+Atwh9yhdI6lekYrpa5kGzDMRmtggnUv/HzO6VVCmpoZntCzSV9BrQwszGF7e05SNVa5f0M+AYM3uV0Ef8Z0ktYuCcD1zu3R/lwzv/S1hac7sZ8D9grKRjgYFAa0n3m9khknYys3eqWc/lqZrTsyqBfSUtA/4JnAq8IekjQvfII3E9f9/LgPdplqhUH2Z83RL4CvgZ8F1gHGEUtyXQxcwuT6znX9xaEGv2/czsuTh/DqEvebSZPSxpZ6BRqmbv73v58JpmCUrrw7wbWAJMAZ4A7jCzz2O+EYTm4Wr+xa01+wNXSdrMzP5lZrdIugK4XFJTwuDP11BtzdSVMO/TLEGJPsx7CLXKEcBvgJZm9rmk9pLuIrQkLoA1By1c/uKFAKuZ2cvAn4ATJZ0Uk39D+AEjFTDjaw+YZcRrmqWrPfAR8CRwA3ClmY2V1IZwtck9iaaj13TWQ+J0rgrgOmAB8IqZPRB/i86Nd5LqDrxoZvcUsbiujnlNs0Sk13QIV5JsRGiSjzazP8Y8w4FtEgFTHjDXTyJgPk74QVoCPC3pIDN7ALgE6Ap8aGaXgdfsy5nXNEtAWh/mDwj9lI8AY4DtgUnxjka/JYzWvpla1/sw111aDf1I4A3gj4T3/gHgKUkDzWyUpHFmtrKa9VyZ8dHzei7RNBShVmmEE6ZbEr7IpxOuYd6YUNNZ3YfpAXPdJa7TbwBcDfwN+AT4MzDLzK6U9E/gRMLFBJPjev6+lzmvadZziYB5AfCWmQ0FiAM9jwODzOxOSW3MbEFc5jWd9ZR4/34LLDCzDwAkfQJMj8umAeelAmZczwNmmfM+zXpKa94YuAehWb69pE0BzOw0wsnsb8U7FKXuZOR9mOtB0u8kbRVf/wjYG/i/OF9JqOV/R9JEYEszuyUu8+/SBsKb5/VQ2onrzc1ssaRtgL8D9wL3mdmiuHyImd1RxOKWDUk3Ad3N7OA4vw/wI8Kg221mNi3eEGU7oIOZjYr5vEm+AfGgWc9ozXte3gs0AFYS+tQ+IATOBwmnFH2ZWM+/uOtB0n2EO64fHef7EQbadgMGAfOAh8ysKm097wrZwHiToh5JNa1jwPwXMBv4OXAf4VzMrYHzCI+E3S25rgfMdRcHe1on5n8IXAo0jjfheALYDDhN0mbJdT1gbnh8IKiekHQC0ETSiDj4sxC42cIDuWYoPErhFDMbIukYM3u/qAUuE5JONbMRkr4L3CFpKvA5MMDiHe/NbHS89dvGZuZ3Wt/AeU2zHoj9ZB0JN609LiY3Am5JZHsXaCGpSSpg+gnUteICSTdbuKv9mYTLUhfbt48IaQhgZqPM7F8xzd/3DZgHzXrAzFYANxGeG/NdSQcTBiCWSnpa0k7AZcCnZrYssZ43ydeRpKckHQXsBfSWdLiZLSV0fcyR9O/YXbKimuvO/X3fgHnQLCJJ56a+kDEYtiXcPecY4HDCidPTgMHAHDM7L67nNZ31IKkHcDChz/JrYB8zexIgnpVwDuHUotExbVWGTbkNkPdpFkkMlgOAAwjPwD4NOBo4EOgd/19hZuemreejtevJzKZIGghcLanSzO6G0BQ3sxVmtkjh+eXHF7ekrj7yoFkEicGHQYTBh/cJ15MfbmbzFZ4k2QI4VtI8Mxsb1/MT12uJmT0VK+zXS1puZvfHpnjq+eRfAsPAT+dya/LzNIsgXk3yqpmdp3DD2mHAFqmTqmOeZsBeZvZCscq5IZB0GHA9cI2Z3R/TvDbvMvI+zQLKdfABwMyWpAKm92HWHTN7ivCY3UsVbyZs3z6b3N93txavaRZIHHyYBJxq4WmRqy+VjMtbEE4x6mRm3ylWOTdUscZ5NXA7sImZXVfkIrl6yvs0C8QHH+q32McpwmWqg4tdHld/eU2zwDL0oa010OCDD8UhqZWF55U7Vy2vaRZY2qgtcdTW0gcfPGAWhwdMl40HzSJIC5yVZnZPcvDBA6Zz9ZcHzSJJBM6rJW1EHHzwgOlc/eZBs4h88MG50uMDQfWADz44Vzo8aDrnXB78iiDnnMuDB03nnMuDB02XkaRVkiZJmizpgXgTkXXdVl9JT8TX35V0cQ15W0v6yTrs40pJF+WanpbnLknH5LGvTpImZ8/pyo0HTVeTpWa2i5ntCCwn3E1+NQV5f4bM7DEzu76GLK0JNzFxrt7xoOly9QqwbaxhvSvpNmAisJWk/pJekzQx1kibA0g6VNJ7kl4FjkptSNJpkm6JrzePd3d6K057Ey4z7RJrub+P+X4u6Q1Jb0v6dWJbl0p6X9LzhOeR10jSGXE7b0l6KK323E/SK5KmSjoi5m8g6feJfZ+1vm+kK20eNF1WkioJd5l/JyZtB4wws12BrwjPL+pnZr2A8cBPFZ7e+DfgSGA/YIsMm78ZeNnMegK9gCmEW7VNj7Xcn0vqD3Ql3NF+F2A3SftL2o1wg5NdCUF5jxwO52Ez2yPu711gSGJZJ+A7hEeN3B6PYQjwhZntEbd/hqTOOezHlSk/ud3VpKmkSfH1K8AdwJbAh6m7yQN7At2BMfEKp0bAa8D2wAwzqwKQ9E/C0x7THQicCqufxfOFpDZpefrH6c0435wQRFsA/zazJXEfj+VwTDtKuprQBdAceCaxbGS8nLVK0gfxGPoDOyf6O1vFfU/NYV+uDHnQdDVZama7JBNiYPwqmQQ8Z2YnpOXbBaitk4AFXGdmf03bxwXrsI+7gEFm9pbCc5n6Jpalb8vivs81s2RwRVKnPPfryoQ3z936GgvsI2lbCI/pkNQNeA/oLKlLzHdChvVfAH4c120gqSWwiFCLTHkG+EGir7S9pLbAf4DvSWoab+J8ZA7lbQF8ovA885PSlh0rqSKWeRvg/bjvH8f8SOoW7xXgNlBe03TrxczmxhrbvZIax+TLzGyqpDOBJyXNA14FdqxmE+cDwyQNAVYBPzaz1ySNiaf0PB37NXcAXos13cXAyWY2UdL9hDvif0joQsjmV8C4mP8d1gzO7wMvA5sDPzKzZZL+TujrnBjvEzAXGJTbu+PKkV9G6ZxzefDmuXPO5cGDpnPO5cGDpnPO5cGDpnPO5cGDpnPO5cGDpnPO5cGDpnPO5eH/ARUdodOV+/+2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[50203   169]\n",
      " [ 1277 12791]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna5.predict(x_data,y_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
