{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "2  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   \n",
       "3  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275   \n",
       "4  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "2   8.2675  14.7222   0.3965  \n",
       "3  10.2922  17.9697  -8.9996  \n",
       "4   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', sep = ',')\n",
    "X = df.loc[:,'var_0':'var_199']\n",
    "Y = df.loc[:,'target']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_index = np.where(Y==1)\n",
    "honest_index = np.where(Y==0)\n",
    "fraud = X.loc[fraud_index]\n",
    "honest = X.loc[honest_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "yh = Y.loc[honest_index]\n",
    "yf = Y.loc[fraud_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_train, h_test, hy_train, hy_test = train_test_split(honest, yh,test_size=0.3,\n",
    "                                                      random_state=30)\n",
    "h_test, h_val, hy_test, hy_val = train_test_split(h_test, hy_test,test_size=0.5,\n",
    "                                                  random_state=30)\n",
    "\n",
    "\n",
    "f_train, f_test, fy_train, fy_test = train_test_split(fraud, yf,test_size=0.3,\n",
    "                                                      random_state=30)\n",
    "f_test, f_val, fy_test, fy_val = train_test_split(f_test, fy_test,test_size=0.5,\n",
    "                                                  random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.951592266135911"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_train)/len(f_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = pd.concat([f_train, f_train, f_train], ignore_index=False)\n",
    "fy_train = pd.concat([fy_train, fy_train, fy_train], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9838640887119703"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h_train)/len(f_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.concat([h_train,f_train],ignore_index = True)\n",
    "x_test = pd.concat([h_test,f_test],ignore_index = True)\n",
    "x_val = pd.concat([h_val,f_val],ignore_index = True)\n",
    "\n",
    "y_train = pd.concat([hy_train,fy_train],ignore_index = True)\n",
    "y_test = pd.concat([hy_test,fy_test],ignore_index = True)\n",
    "y_val = pd.concat([hy_val,fy_val],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanx = x_train.mean(axis = 0)\n",
    "stdx = x_train.std(axis = 0)\n",
    "x_train_norm = (x_train - meanx)/stdx\n",
    "x_val_norm = (x_val - meanx)/stdx\n",
    "x_test_norm = (x_test - meanx)/stdx\n",
    "x_train_norm=np.asarray(x_train_norm)\n",
    "x_test_norm=np.asarray(x_test_norm)\n",
    "x_val_norm=np.asarray(x_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from keras.backend import binary_crossentropy\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "from keras.backend import mean\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "y_val = np.asarray(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class new_rna:\n",
    "    def build_model(self,data_shape,units_list,activation_list,dropout_list):\n",
    "        self.model = models.Sequential()\n",
    "        if len(dropout_list)<0:\n",
    "            my_init = keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=1)\n",
    "            for i in range(len(units_list)):\n",
    "                if i == 0:\n",
    "                    self.model.add(layers.Dense(units=units_list[i], \n",
    "                                                activation=activation_list[i], \n",
    "                                                kernel_initializer = my_init,\n",
    "                                                input_shape=data_shape))\n",
    "                else:\n",
    "                    self.model.add(layers.Dense(units=units_list[i], \n",
    "                                                activation=activation_list[i]))\n",
    "        else:\n",
    "            my_init = keras.initializers.RandomUniform(minval=-0.05, \n",
    "                                                       maxval=0.05, \n",
    "                                                       seed=1)\n",
    "            for i in range(len(units_list)):\n",
    "                if i == 0:\n",
    "                    self.model.add(layers.Dense(units=units_list[i], \n",
    "                                                activation=activation_list[i],\n",
    "                                                kernel_initializer = my_init,\n",
    "                                                input_shape=data_shape))\n",
    "                else:\n",
    "                    self.model.add(layers.Dropout(dropout_list[i-1]))\n",
    "                    self.model.add(layers.Dense(units=units_list[i], \n",
    "                                                activation=activation_list[i]))\n",
    "        self.model.summary()\n",
    "           \n",
    "    def train(self,x_train,y_train,x_val,y_val,batch_size,epochs,loss,metric):\n",
    "        mom = optimizers.SGD(lr=0.001, decay=0, momentum=0.9, nesterov=True)\n",
    "        self.model.compile(loss = [loss],metrics = [metric], optimizer = mom)\n",
    "        history = self.model.fit(x_train,y_train,batch_size = batch_size,epochs = epochs,validation_data = (x_val,y_val))\n",
    "        self.history_dict = history.history\n",
    "        self.aux_train = 1\n",
    "        \n",
    "    def plot(self):\n",
    "        if (self.aux_train == 1):\n",
    "            self.aux_plt = 1\n",
    "            cost = self.history_dict['loss']\n",
    "            metric = self.history_dict['f1']\n",
    "            val_cost = self.history_dict['val_loss']\n",
    "            val_metric = self.history_dict['val_f1']\n",
    "            aux_epocas = range(1,len(cost)+1)\n",
    "            plt.plot(aux_epocas,cost,'b',label = 'Custo - treinamento', color = 'red')\n",
    "            plt.plot(aux_epocas,val_cost,'b',label = 'Custo - validacao', color = 'blue')\n",
    "            plt.title(' Valor da Funcao Custo = Treinamento e Validacao')\n",
    "            plt.xlabel('Ã‰pocas')\n",
    "            plt.ylabel('Custo')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            plt.plot(aux_epocas, metric,'b',label = 'metrica - treinamento',color = 'red')\n",
    "            plt.plot(aux_epocas, val_metric,'b',label = 'metrica - validacao', color = 'blue')\n",
    "            plt.title('Valor da mÃ©trica â€“ treinamento e validaÃ§Ã£o')\n",
    "            plt.xlabel('Ã‰pocas')\n",
    "            plt.ylabel('Acertividade')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print('Train before plot')\n",
    "\n",
    "    def predict(self,x_data,y_data):\n",
    "        if (self.aux_plt == 1):\n",
    "            class_names = np.array([['Honest'],['Fraud']])\n",
    "            subtitle = ['Test', 'Val', 'Train']\n",
    "            for i in range(len(x_data)):\n",
    "                y_hat = self.model.predict(x_data[i])\n",
    "                yy_hat = np.round(y_hat)\n",
    "                yy_hat = yy_hat.astype(int)\n",
    "                yy_hat = np.ravel(yy_hat)\n",
    "                f1 = f1_score(y_data[i],yy_hat)\n",
    "                plot_confusion_matrix(np.int_(y_data[i]), np.int_(yy_hat), classes=class_names,\n",
    "                                      title='F1_Score = {0}: {1} Data'.format(f1, subtitle[i]))\n",
    "                plt.show()\n",
    "            K.clear_session()\n",
    "        else:\n",
    "            print('Train before predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shape = (200,)\n",
    "\n",
    "loss = 'binary_crossentropy'\n",
    "metric = f1\n",
    "batch_size = 32\n",
    "epochs = 2000\n",
    "\n",
    "x_data = [x_test_norm,x_val_norm,x_train_norm]\n",
    "y_data = [y_test,y_val,y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list0 = [50,1]\n",
    "activation_list0 = ['tanh','sigmoid']\n",
    "dropout_list0 = [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Elvemage\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Elvemage\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,101\n",
      "Trainable params: 10,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna0 = new_rna()\n",
    "rna0.build_model(data_shape,n_list0,activation_list0,dropout_list0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Elvemage\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 168135 samples, validate on 30001 samples\n",
      "Epoch 1/2000\n",
      "168135/168135 [==============================] - 7s 44us/step - loss: 0.4026 - f1: 0.5736 - val_loss: 0.2845 - val_f1: 0.0691\n",
      "Epoch 2/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.3889 - f1: 0.5879 - val_loss: 0.2801 - val_f1: 0.0682\n",
      "Epoch 3/2000\n",
      "168135/168135 [==============================] - 7s 41us/step - loss: 0.3869 - f1: 0.5885 - val_loss: 0.2853 - val_f1: 0.0700\n",
      "Epoch 4/2000\n",
      "168135/168135 [==============================] - 7s 39us/step - loss: 0.3861 - f1: 0.5920 - val_loss: 0.2813 - val_f1: 0.0696\n",
      "Epoch 5/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.3852 - f1: 0.5930 - val_loss: 0.2828 - val_f1: 0.0697\n",
      "Epoch 6/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.3847 - f1: 0.5922 - val_loss: 0.2832 - val_f1: 0.0699\n",
      "Epoch 7/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.3842 - f1: 0.5979 - val_loss: 0.2825 - val_f1: 0.0698\n",
      "Epoch 8/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3838 - f1: 0.5950 - val_loss: 0.2845 - val_f1: 0.0709\n",
      "Epoch 9/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3836 - f1: 0.5949 - val_loss: 0.2818 - val_f1: 0.0694\n",
      "Epoch 10/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3833 - f1: 0.5963 - val_loss: 0.2827 - val_f1: 0.0698\n",
      "Epoch 11/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3828 - f1: 0.5970 - val_loss: 0.2835 - val_f1: 0.0703\n",
      "Epoch 12/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3824 - f1: 0.5957 - val_loss: 0.2832 - val_f1: 0.0707\n",
      "Epoch 13/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3829 - f1: 0.5946 - val_loss: 0.2789 - val_f1: 0.0690\n",
      "Epoch 14/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3823 - f1: 0.5964 - val_loss: 0.2795 - val_f1: 0.0694\n",
      "Epoch 15/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3818 - f1: 0.5967 - val_loss: 0.2821 - val_f1: 0.0704\n",
      "Epoch 16/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3820 - f1: 0.5979 - val_loss: 0.2779 - val_f1: 0.0688\n",
      "Epoch 17/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3814 - f1: 0.5972 - val_loss: 0.2800 - val_f1: 0.0695\n",
      "Epoch 18/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3811 - f1: 0.6000 - val_loss: 0.2780 - val_f1: 0.0688\n",
      "Epoch 19/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3806 - f1: 0.5972 - val_loss: 0.2797 - val_f1: 0.0699\n",
      "Epoch 20/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3807 - f1: 0.5978 - val_loss: 0.2807 - val_f1: 0.0698\n",
      "Epoch 21/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3806 - f1: 0.5965 - val_loss: 0.2809 - val_f1: 0.0698\n",
      "Epoch 22/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3800 - f1: 0.5986 - val_loss: 0.2787 - val_f1: 0.0694\n",
      "Epoch 23/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3792 - f1: 0.5988 - val_loss: 0.2793 - val_f1: 0.0695\n",
      "Epoch 24/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3790 - f1: 0.5979 - val_loss: 0.2803 - val_f1: 0.0695\n",
      "Epoch 25/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3784 - f1: 0.5979 - val_loss: 0.2776 - val_f1: 0.0692\n",
      "Epoch 26/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3784 - f1: 0.5990 - val_loss: 0.2782 - val_f1: 0.0694\n",
      "Epoch 27/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3779 - f1: 0.6018 - val_loss: 0.2798 - val_f1: 0.0693\n",
      "Epoch 28/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3772 - f1: 0.5977 - val_loss: 0.2791 - val_f1: 0.0689\n",
      "Epoch 29/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3767 - f1: 0.6019 - val_loss: 0.2782 - val_f1: 0.0697\n",
      "Epoch 30/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3762 - f1: 0.6023 - val_loss: 0.2793 - val_f1: 0.0692\n",
      "Epoch 31/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3758 - f1: 0.6022 - val_loss: 0.2781 - val_f1: 0.0694\n",
      "Epoch 32/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3752 - f1: 0.6017 - val_loss: 0.2782 - val_f1: 0.0691\n",
      "Epoch 33/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3751 - f1: 0.5997 - val_loss: 0.2802 - val_f1: 0.0700\n",
      "Epoch 34/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3744 - f1: 0.6033 - val_loss: 0.2806 - val_f1: 0.0695\n",
      "Epoch 35/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3732 - f1: 0.6051 - val_loss: 0.2758 - val_f1: 0.0684\n",
      "Epoch 36/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3730 - f1: 0.6035 - val_loss: 0.2786 - val_f1: 0.0697\n",
      "Epoch 37/2000\n",
      "168135/168135 [==============================] - 12s 70us/step - loss: 0.3724 - f1: 0.6048 - val_loss: 0.2771 - val_f1: 0.0686\n",
      "Epoch 38/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3725 - f1: 0.6028 - val_loss: 0.2772 - val_f1: 0.0695\n",
      "Epoch 39/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3714 - f1: 0.6059 - val_loss: 0.2766 - val_f1: 0.0689\n",
      "Epoch 40/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3711 - f1: 0.6053 - val_loss: 0.2759 - val_f1: 0.0686\n",
      "Epoch 41/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3697 - f1: 0.6077 - val_loss: 0.2765 - val_f1: 0.0688\n",
      "Epoch 42/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3695 - f1: 0.6075 - val_loss: 0.2779 - val_f1: 0.0691\n",
      "Epoch 43/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3689 - f1: 0.6089 - val_loss: 0.2772 - val_f1: 0.0689\n",
      "Epoch 44/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3683 - f1: 0.6070 - val_loss: 0.2763 - val_f1: 0.0690\n",
      "Epoch 45/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3674 - f1: 0.6128 - val_loss: 0.2789 - val_f1: 0.0693\n",
      "Epoch 46/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3678 - f1: 0.6090 - val_loss: 0.2774 - val_f1: 0.0690\n",
      "Epoch 47/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3662 - f1: 0.6141 - val_loss: 0.2746 - val_f1: 0.0685\n",
      "Epoch 48/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3659 - f1: 0.6113 - val_loss: 0.2795 - val_f1: 0.0692\n",
      "Epoch 49/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3657 - f1: 0.6126 - val_loss: 0.2762 - val_f1: 0.0685\n",
      "Epoch 50/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3655 - f1: 0.6147 - val_loss: 0.2731 - val_f1: 0.0679\n",
      "Epoch 51/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3643 - f1: 0.6136 - val_loss: 0.2771 - val_f1: 0.0688\n",
      "Epoch 52/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3631 - f1: 0.6166 - val_loss: 0.2740 - val_f1: 0.0683\n",
      "Epoch 53/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3633 - f1: 0.6144 - val_loss: 0.2730 - val_f1: 0.0679\n",
      "Epoch 54/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3628 - f1: 0.6159 - val_loss: 0.2779 - val_f1: 0.0692\n",
      "Epoch 55/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3618 - f1: 0.6217 - val_loss: 0.2738 - val_f1: 0.0681\n",
      "Epoch 56/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3614 - f1: 0.6183 - val_loss: 0.2746 - val_f1: 0.0686\n",
      "Epoch 57/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3607 - f1: 0.6198 - val_loss: 0.2725 - val_f1: 0.0679\n",
      "Epoch 58/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3592 - f1: 0.6220 - val_loss: 0.2738 - val_f1: 0.0687\n",
      "Epoch 59/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3596 - f1: 0.6240 - val_loss: 0.2739 - val_f1: 0.0685\n",
      "Epoch 60/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3591 - f1: 0.6213 - val_loss: 0.2718 - val_f1: 0.0675\n",
      "Epoch 61/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3574 - f1: 0.6228 - val_loss: 0.2761 - val_f1: 0.0687\n",
      "Epoch 62/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3572 - f1: 0.6246 - val_loss: 0.2733 - val_f1: 0.0684\n",
      "Epoch 63/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3567 - f1: 0.6229 - val_loss: 0.2734 - val_f1: 0.0678\n",
      "Epoch 64/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3565 - f1: 0.6238 - val_loss: 0.2722 - val_f1: 0.0678\n",
      "Epoch 65/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3544 - f1: 0.6269 - val_loss: 0.2760 - val_f1: 0.0688\n",
      "Epoch 66/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3556 - f1: 0.6281 - val_loss: 0.2735 - val_f1: 0.0683\n",
      "Epoch 67/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3545 - f1: 0.6282 - val_loss: 0.2741 - val_f1: 0.0683\n",
      "Epoch 68/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3533 - f1: 0.6285 - val_loss: 0.2733 - val_f1: 0.0682\n",
      "Epoch 69/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3543 - f1: 0.6295 - val_loss: 0.2736 - val_f1: 0.0681\n",
      "Epoch 70/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3538 - f1: 0.6301 - val_loss: 0.2743 - val_f1: 0.0686\n",
      "Epoch 71/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3518 - f1: 0.6332 - val_loss: 0.2733 - val_f1: 0.0680\n",
      "Epoch 72/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3519 - f1: 0.6332 - val_loss: 0.2713 - val_f1: 0.0679\n",
      "Epoch 73/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3511 - f1: 0.6330 - val_loss: 0.2736 - val_f1: 0.0683\n",
      "Epoch 74/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3515 - f1: 0.6332 - val_loss: 0.2739 - val_f1: 0.0682\n",
      "Epoch 75/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3501 - f1: 0.6345 - val_loss: 0.2717 - val_f1: 0.0677\n",
      "Epoch 76/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3501 - f1: 0.6344 - val_loss: 0.2736 - val_f1: 0.0682\n",
      "Epoch 77/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3492 - f1: 0.6367 - val_loss: 0.2705 - val_f1: 0.0675\n",
      "Epoch 78/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3487 - f1: 0.6353 - val_loss: 0.2709 - val_f1: 0.0676\n",
      "Epoch 79/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3486 - f1: 0.6356 - val_loss: 0.2743 - val_f1: 0.0683\n",
      "Epoch 80/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3475 - f1: 0.6387 - val_loss: 0.2711 - val_f1: 0.0675\n",
      "Epoch 81/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3470 - f1: 0.6373 - val_loss: 0.2741 - val_f1: 0.0683\n",
      "Epoch 82/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3467 - f1: 0.6401 - val_loss: 0.2753 - val_f1: 0.0683\n",
      "Epoch 83/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3462 - f1: 0.6386 - val_loss: 0.2748 - val_f1: 0.0681\n",
      "Epoch 84/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3456 - f1: 0.6420 - val_loss: 0.2717 - val_f1: 0.0677\n",
      "Epoch 85/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3455 - f1: 0.6413 - val_loss: 0.2731 - val_f1: 0.0680\n",
      "Epoch 86/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3451 - f1: 0.6412 - val_loss: 0.2703 - val_f1: 0.0668\n",
      "Epoch 87/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3450 - f1: 0.6442 - val_loss: 0.2713 - val_f1: 0.0678\n",
      "Epoch 88/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3449 - f1: 0.6412 - val_loss: 0.2755 - val_f1: 0.0684\n",
      "Epoch 89/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3438 - f1: 0.6426 - val_loss: 0.2719 - val_f1: 0.0676\n",
      "Epoch 90/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3436 - f1: 0.6419 - val_loss: 0.2729 - val_f1: 0.0674\n",
      "Epoch 91/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3424 - f1: 0.6473 - val_loss: 0.2720 - val_f1: 0.0676\n",
      "Epoch 92/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3431 - f1: 0.6440 - val_loss: 0.2726 - val_f1: 0.0681\n",
      "Epoch 93/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.3418 - f1: 0.6461 - val_loss: 0.2720 - val_f1: 0.0677\n",
      "Epoch 94/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3421 - f1: 0.6466 - val_loss: 0.2727 - val_f1: 0.0676\n",
      "Epoch 95/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3414 - f1: 0.6454 - val_loss: 0.2724 - val_f1: 0.0678\n",
      "Epoch 96/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3410 - f1: 0.6472 - val_loss: 0.2714 - val_f1: 0.0674\n",
      "Epoch 97/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3407 - f1: 0.6475 - val_loss: 0.2714 - val_f1: 0.0676\n",
      "Epoch 98/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3391 - f1: 0.6481 - val_loss: 0.2727 - val_f1: 0.0678\n",
      "Epoch 99/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3397 - f1: 0.6502 - val_loss: 0.2718 - val_f1: 0.0676\n",
      "Epoch 100/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3382 - f1: 0.6510 - val_loss: 0.2725 - val_f1: 0.0677\n",
      "Epoch 101/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3385 - f1: 0.6532 - val_loss: 0.2705 - val_f1: 0.0670\n",
      "Epoch 102/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3377 - f1: 0.6509 - val_loss: 0.2731 - val_f1: 0.0674\n",
      "Epoch 103/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3376 - f1: 0.6533 - val_loss: 0.2727 - val_f1: 0.0676\n",
      "Epoch 104/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3388 - f1: 0.6503 - val_loss: 0.2714 - val_f1: 0.0673\n",
      "Epoch 105/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3377 - f1: 0.6501 - val_loss: 0.2714 - val_f1: 0.0678\n",
      "Epoch 106/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3357 - f1: 0.6554 - val_loss: 0.2716 - val_f1: 0.0673\n",
      "Epoch 107/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3362 - f1: 0.6536 - val_loss: 0.2747 - val_f1: 0.0681\n",
      "Epoch 108/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3365 - f1: 0.6517 - val_loss: 0.2707 - val_f1: 0.0672\n",
      "Epoch 109/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3350 - f1: 0.6538 - val_loss: 0.2727 - val_f1: 0.0675\n",
      "Epoch 110/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3363 - f1: 0.6537 - val_loss: 0.2717 - val_f1: 0.0671\n",
      "Epoch 111/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3355 - f1: 0.6554 - val_loss: 0.2745 - val_f1: 0.0680\n",
      "Epoch 112/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3356 - f1: 0.6563 - val_loss: 0.2717 - val_f1: 0.0674\n",
      "Epoch 113/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3355 - f1: 0.6563 - val_loss: 0.2730 - val_f1: 0.0674\n",
      "Epoch 114/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3332 - f1: 0.6583 - val_loss: 0.2719 - val_f1: 0.0677\n",
      "Epoch 115/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3343 - f1: 0.6553 - val_loss: 0.2731 - val_f1: 0.0677\n",
      "Epoch 116/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3333 - f1: 0.6591 - val_loss: 0.2729 - val_f1: 0.0673\n",
      "Epoch 117/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3333 - f1: 0.6609 - val_loss: 0.2712 - val_f1: 0.0674\n",
      "Epoch 118/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3335 - f1: 0.6578 - val_loss: 0.2712 - val_f1: 0.0673\n",
      "Epoch 119/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3327 - f1: 0.6587 - val_loss: 0.2720 - val_f1: 0.0673\n",
      "Epoch 120/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3339 - f1: 0.6613 - val_loss: 0.2694 - val_f1: 0.0666\n",
      "Epoch 121/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3332 - f1: 0.6593 - val_loss: 0.2717 - val_f1: 0.0675\n",
      "Epoch 122/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3314 - f1: 0.6599 - val_loss: 0.2706 - val_f1: 0.0666\n",
      "Epoch 123/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3327 - f1: 0.6587 - val_loss: 0.2717 - val_f1: 0.0672\n",
      "Epoch 124/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3321 - f1: 0.6592 - val_loss: 0.2733 - val_f1: 0.0672\n",
      "Epoch 125/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3312 - f1: 0.6601 - val_loss: 0.2739 - val_f1: 0.0674\n",
      "Epoch 126/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3311 - f1: 0.6620 - val_loss: 0.2715 - val_f1: 0.0668\n",
      "Epoch 127/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3307 - f1: 0.6607 - val_loss: 0.2722 - val_f1: 0.0673\n",
      "Epoch 128/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3303 - f1: 0.6605 - val_loss: 0.2705 - val_f1: 0.0665\n",
      "Epoch 129/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3298 - f1: 0.6630 - val_loss: 0.2725 - val_f1: 0.0675\n",
      "Epoch 130/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3304 - f1: 0.6625 - val_loss: 0.2711 - val_f1: 0.0669\n",
      "Epoch 131/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3300 - f1: 0.6637 - val_loss: 0.2703 - val_f1: 0.0667\n",
      "Epoch 132/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3304 - f1: 0.6613 - val_loss: 0.2725 - val_f1: 0.0674\n",
      "Epoch 133/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3301 - f1: 0.6626 - val_loss: 0.2718 - val_f1: 0.0669\n",
      "Epoch 134/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3289 - f1: 0.6637 - val_loss: 0.2742 - val_f1: 0.0674\n",
      "Epoch 135/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3288 - f1: 0.6617 - val_loss: 0.2722 - val_f1: 0.0673\n",
      "Epoch 136/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3292 - f1: 0.6659 - val_loss: 0.2733 - val_f1: 0.0675\n",
      "Epoch 137/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3284 - f1: 0.6657 - val_loss: 0.2718 - val_f1: 0.0668\n",
      "Epoch 138/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3277 - f1: 0.6651 - val_loss: 0.2700 - val_f1: 0.0664\n",
      "Epoch 139/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3278 - f1: 0.6660 - val_loss: 0.2735 - val_f1: 0.0674\n",
      "Epoch 140/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3283 - f1: 0.6673 - val_loss: 0.2714 - val_f1: 0.0666\n",
      "Epoch 141/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3267 - f1: 0.6650 - val_loss: 0.2718 - val_f1: 0.0666\n",
      "Epoch 142/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3261 - f1: 0.6698 - val_loss: 0.2716 - val_f1: 0.0666\n",
      "Epoch 143/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3268 - f1: 0.6665 - val_loss: 0.2717 - val_f1: 0.0668\n",
      "Epoch 144/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3265 - f1: 0.6675 - val_loss: 0.2729 - val_f1: 0.0670\n",
      "Epoch 145/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3260 - f1: 0.6675 - val_loss: 0.2727 - val_f1: 0.0667\n",
      "Epoch 146/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3268 - f1: 0.6640 - val_loss: 0.2726 - val_f1: 0.0672\n",
      "Epoch 147/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3254 - f1: 0.6656 - val_loss: 0.2736 - val_f1: 0.0668\n",
      "Epoch 148/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3273 - f1: 0.6680 - val_loss: 0.2723 - val_f1: 0.0669\n",
      "Epoch 149/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3248 - f1: 0.6688 - val_loss: 0.2727 - val_f1: 0.0670\n",
      "Epoch 150/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3263 - f1: 0.6687 - val_loss: 0.2724 - val_f1: 0.0670\n",
      "Epoch 151/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3249 - f1: 0.6708 - val_loss: 0.2735 - val_f1: 0.0675\n",
      "Epoch 152/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3255 - f1: 0.6675 - val_loss: 0.2727 - val_f1: 0.0671\n",
      "Epoch 153/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3247 - f1: 0.6697 - val_loss: 0.2723 - val_f1: 0.0672\n",
      "Epoch 154/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3250 - f1: 0.6708 - val_loss: 0.2716 - val_f1: 0.0667\n",
      "Epoch 155/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3252 - f1: 0.6685 - val_loss: 0.2727 - val_f1: 0.0666\n",
      "Epoch 156/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3233 - f1: 0.6705 - val_loss: 0.2716 - val_f1: 0.0666\n",
      "Epoch 157/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3234 - f1: 0.6716 - val_loss: 0.2729 - val_f1: 0.0670\n",
      "Epoch 158/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3249 - f1: 0.6689 - val_loss: 0.2708 - val_f1: 0.0666\n",
      "Epoch 159/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3224 - f1: 0.6717 - val_loss: 0.2743 - val_f1: 0.0671\n",
      "Epoch 160/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3233 - f1: 0.6710 - val_loss: 0.2735 - val_f1: 0.0673\n",
      "Epoch 161/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3240 - f1: 0.6729 - val_loss: 0.2727 - val_f1: 0.0669\n",
      "Epoch 162/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3232 - f1: 0.6699 - val_loss: 0.2722 - val_f1: 0.0666\n",
      "Epoch 163/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3227 - f1: 0.6715 - val_loss: 0.2729 - val_f1: 0.0668\n",
      "Epoch 164/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3232 - f1: 0.6712 - val_loss: 0.2715 - val_f1: 0.0665\n",
      "Epoch 165/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3218 - f1: 0.6750 - val_loss: 0.2717 - val_f1: 0.0666\n",
      "Epoch 166/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3219 - f1: 0.6707 - val_loss: 0.2734 - val_f1: 0.0669\n",
      "Epoch 167/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3217 - f1: 0.6747 - val_loss: 0.2716 - val_f1: 0.0664\n",
      "Epoch 168/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3220 - f1: 0.6730 - val_loss: 0.2725 - val_f1: 0.0665\n",
      "Epoch 169/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3220 - f1: 0.6727 - val_loss: 0.2714 - val_f1: 0.0664\n",
      "Epoch 170/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3217 - f1: 0.6764 - val_loss: 0.2732 - val_f1: 0.0669\n",
      "Epoch 171/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3209 - f1: 0.6734 - val_loss: 0.2740 - val_f1: 0.0672\n",
      "Epoch 172/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3204 - f1: 0.6754 - val_loss: 0.2720 - val_f1: 0.0664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3208 - f1: 0.6745 - val_loss: 0.2708 - val_f1: 0.0662\n",
      "Epoch 174/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3209 - f1: 0.6750 - val_loss: 0.2729 - val_f1: 0.0669\n",
      "Epoch 175/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3198 - f1: 0.6753 - val_loss: 0.2738 - val_f1: 0.0671\n",
      "Epoch 176/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3198 - f1: 0.6789 - val_loss: 0.2741 - val_f1: 0.0672\n",
      "Epoch 177/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3209 - f1: 0.6726 - val_loss: 0.2730 - val_f1: 0.0667\n",
      "Epoch 178/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3200 - f1: 0.6763 - val_loss: 0.2730 - val_f1: 0.0671\n",
      "Epoch 179/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3199 - f1: 0.6768 - val_loss: 0.2723 - val_f1: 0.0667\n",
      "Epoch 180/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3202 - f1: 0.6780 - val_loss: 0.2717 - val_f1: 0.0663\n",
      "Epoch 181/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3193 - f1: 0.6759 - val_loss: 0.2722 - val_f1: 0.0668\n",
      "Epoch 182/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3193 - f1: 0.6744 - val_loss: 0.2723 - val_f1: 0.0665\n",
      "Epoch 183/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3186 - f1: 0.6761 - val_loss: 0.2750 - val_f1: 0.0673\n",
      "Epoch 184/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3192 - f1: 0.6765 - val_loss: 0.2743 - val_f1: 0.0670\n",
      "Epoch 185/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3178 - f1: 0.6784 - val_loss: 0.2729 - val_f1: 0.0666\n",
      "Epoch 186/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3198 - f1: 0.6758 - val_loss: 0.2721 - val_f1: 0.0664\n",
      "Epoch 187/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3185 - f1: 0.6778 - val_loss: 0.2745 - val_f1: 0.0671\n",
      "Epoch 188/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3181 - f1: 0.6800 - val_loss: 0.2707 - val_f1: 0.0658\n",
      "Epoch 189/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3190 - f1: 0.6780 - val_loss: 0.2731 - val_f1: 0.0668\n",
      "Epoch 190/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3174 - f1: 0.6805 - val_loss: 0.2745 - val_f1: 0.0668\n",
      "Epoch 191/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3181 - f1: 0.6772 - val_loss: 0.2736 - val_f1: 0.0666\n",
      "Epoch 192/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3170 - f1: 0.6813 - val_loss: 0.2736 - val_f1: 0.0667\n",
      "Epoch 193/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3184 - f1: 0.6770 - val_loss: 0.2726 - val_f1: 0.0665\n",
      "Epoch 194/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3165 - f1: 0.6802 - val_loss: 0.2732 - val_f1: 0.0665\n",
      "Epoch 195/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3172 - f1: 0.6791 - val_loss: 0.2739 - val_f1: 0.0666\n",
      "Epoch 196/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3179 - f1: 0.6820 - val_loss: 0.2731 - val_f1: 0.0663\n",
      "Epoch 197/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3167 - f1: 0.6817 - val_loss: 0.2737 - val_f1: 0.0667\n",
      "Epoch 198/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3171 - f1: 0.6802 - val_loss: 0.2727 - val_f1: 0.0664\n",
      "Epoch 199/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3160 - f1: 0.6799 - val_loss: 0.2744 - val_f1: 0.0669\n",
      "Epoch 200/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3169 - f1: 0.6794 - val_loss: 0.2717 - val_f1: 0.0659\n",
      "Epoch 201/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3157 - f1: 0.6800 - val_loss: 0.2722 - val_f1: 0.0663\n",
      "Epoch 202/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3164 - f1: 0.6814 - val_loss: 0.2745 - val_f1: 0.0667\n",
      "Epoch 203/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3176 - f1: 0.6786 - val_loss: 0.2743 - val_f1: 0.0664\n",
      "Epoch 204/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3153 - f1: 0.6820 - val_loss: 0.2725 - val_f1: 0.0664\n",
      "Epoch 205/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3162 - f1: 0.6834 - val_loss: 0.2732 - val_f1: 0.0663\n",
      "Epoch 206/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3151 - f1: 0.6820 - val_loss: 0.2753 - val_f1: 0.0672\n",
      "Epoch 207/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3154 - f1: 0.6824 - val_loss: 0.2728 - val_f1: 0.0665\n",
      "Epoch 208/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3157 - f1: 0.6844 - val_loss: 0.2725 - val_f1: 0.0664\n",
      "Epoch 209/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3153 - f1: 0.6809 - val_loss: 0.2731 - val_f1: 0.0663\n",
      "Epoch 210/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3148 - f1: 0.6831 - val_loss: 0.2740 - val_f1: 0.0669\n",
      "Epoch 211/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3158 - f1: 0.6814 - val_loss: 0.2748 - val_f1: 0.0668\n",
      "Epoch 212/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3146 - f1: 0.6819 - val_loss: 0.2743 - val_f1: 0.0667\n",
      "Epoch 213/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3142 - f1: 0.6843 - val_loss: 0.2746 - val_f1: 0.0668\n",
      "Epoch 214/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3146 - f1: 0.6841 - val_loss: 0.2742 - val_f1: 0.0669\n",
      "Epoch 215/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3144 - f1: 0.6852 - val_loss: 0.2718 - val_f1: 0.0662\n",
      "Epoch 216/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3146 - f1: 0.6827 - val_loss: 0.2731 - val_f1: 0.0663\n",
      "Epoch 217/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3154 - f1: 0.6838 - val_loss: 0.2731 - val_f1: 0.0664\n",
      "Epoch 218/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3139 - f1: 0.6833 - val_loss: 0.2738 - val_f1: 0.0666\n",
      "Epoch 219/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3138 - f1: 0.6826 - val_loss: 0.2737 - val_f1: 0.0666\n",
      "Epoch 220/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3128 - f1: 0.6866 - val_loss: 0.2735 - val_f1: 0.0667\n",
      "Epoch 221/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3129 - f1: 0.6850 - val_loss: 0.2743 - val_f1: 0.0669\n",
      "Epoch 222/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3141 - f1: 0.6833 - val_loss: 0.2738 - val_f1: 0.0666\n",
      "Epoch 223/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3135 - f1: 0.6854 - val_loss: 0.2713 - val_f1: 0.0659\n",
      "Epoch 224/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3134 - f1: 0.6839 - val_loss: 0.2733 - val_f1: 0.0660\n",
      "Epoch 225/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3134 - f1: 0.6843 - val_loss: 0.2727 - val_f1: 0.0660\n",
      "Epoch 226/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3127 - f1: 0.6827 - val_loss: 0.2754 - val_f1: 0.0666\n",
      "Epoch 227/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3131 - f1: 0.6830 - val_loss: 0.2732 - val_f1: 0.0662\n",
      "Epoch 228/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3128 - f1: 0.6830 - val_loss: 0.2736 - val_f1: 0.0664\n",
      "Epoch 229/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3130 - f1: 0.6855 - val_loss: 0.2739 - val_f1: 0.0666\n",
      "Epoch 230/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3133 - f1: 0.6835 - val_loss: 0.2741 - val_f1: 0.0663\n",
      "Epoch 231/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3112 - f1: 0.6880 - val_loss: 0.2735 - val_f1: 0.0663\n",
      "Epoch 232/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3120 - f1: 0.6878 - val_loss: 0.2724 - val_f1: 0.0658\n",
      "Epoch 233/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3126 - f1: 0.6863 - val_loss: 0.2752 - val_f1: 0.0667\n",
      "Epoch 234/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3124 - f1: 0.6872 - val_loss: 0.2736 - val_f1: 0.0662\n",
      "Epoch 235/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3112 - f1: 0.6913 - val_loss: 0.2735 - val_f1: 0.0663\n",
      "Epoch 236/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3114 - f1: 0.6875 - val_loss: 0.2728 - val_f1: 0.0659\n",
      "Epoch 237/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3116 - f1: 0.6886 - val_loss: 0.2743 - val_f1: 0.0667\n",
      "Epoch 238/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3106 - f1: 0.6879 - val_loss: 0.2741 - val_f1: 0.0664\n",
      "Epoch 239/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3106 - f1: 0.6853 - val_loss: 0.2753 - val_f1: 0.0665\n",
      "Epoch 240/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3105 - f1: 0.6890 - val_loss: 0.2715 - val_f1: 0.0657\n",
      "Epoch 241/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3125 - f1: 0.6869 - val_loss: 0.2732 - val_f1: 0.0660\n",
      "Epoch 242/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3110 - f1: 0.6877 - val_loss: 0.2722 - val_f1: 0.0659\n",
      "Epoch 243/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3112 - f1: 0.6873 - val_loss: 0.2739 - val_f1: 0.0661\n",
      "Epoch 244/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3123 - f1: 0.6851 - val_loss: 0.2749 - val_f1: 0.0664\n",
      "Epoch 245/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3111 - f1: 0.6886 - val_loss: 0.2746 - val_f1: 0.0667\n",
      "Epoch 246/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3114 - f1: 0.6870 - val_loss: 0.2755 - val_f1: 0.0666\n",
      "Epoch 247/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3104 - f1: 0.6885 - val_loss: 0.2750 - val_f1: 0.0667\n",
      "Epoch 248/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3110 - f1: 0.6892 - val_loss: 0.2761 - val_f1: 0.0668\n",
      "Epoch 249/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3108 - f1: 0.6882 - val_loss: 0.2746 - val_f1: 0.0663\n",
      "Epoch 250/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3111 - f1: 0.6855 - val_loss: 0.2737 - val_f1: 0.0663\n",
      "Epoch 251/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3105 - f1: 0.6891 - val_loss: 0.2749 - val_f1: 0.0665\n",
      "Epoch 252/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3098 - f1: 0.6897 - val_loss: 0.2733 - val_f1: 0.0657\n",
      "Epoch 253/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3105 - f1: 0.6865 - val_loss: 0.2750 - val_f1: 0.0668\n",
      "Epoch 254/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3097 - f1: 0.6893 - val_loss: 0.2754 - val_f1: 0.0666\n",
      "Epoch 255/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3106 - f1: 0.6902 - val_loss: 0.2727 - val_f1: 0.0659\n",
      "Epoch 256/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3100 - f1: 0.6882 - val_loss: 0.2765 - val_f1: 0.0668\n",
      "Epoch 257/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3101 - f1: 0.6902 - val_loss: 0.2750 - val_f1: 0.0662\n",
      "Epoch 258/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3104 - f1: 0.6888 - val_loss: 0.2754 - val_f1: 0.0668\n",
      "Epoch 259/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3106 - f1: 0.6895 - val_loss: 0.2761 - val_f1: 0.0665\n",
      "Epoch 260/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3082 - f1: 0.6916 - val_loss: 0.2739 - val_f1: 0.0660\n",
      "Epoch 261/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3093 - f1: 0.6908 - val_loss: 0.2757 - val_f1: 0.0663\n",
      "Epoch 262/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3091 - f1: 0.6886 - val_loss: 0.2750 - val_f1: 0.0666\n",
      "Epoch 263/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3102 - f1: 0.6864 - val_loss: 0.2761 - val_f1: 0.0664\n",
      "Epoch 264/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3086 - f1: 0.6907 - val_loss: 0.2743 - val_f1: 0.0660\n",
      "Epoch 265/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3090 - f1: 0.6914 - val_loss: 0.2739 - val_f1: 0.0661\n",
      "Epoch 266/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3092 - f1: 0.6886 - val_loss: 0.2744 - val_f1: 0.0660\n",
      "Epoch 267/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3083 - f1: 0.6879 - val_loss: 0.2771 - val_f1: 0.0672\n",
      "Epoch 268/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3083 - f1: 0.6902 - val_loss: 0.2742 - val_f1: 0.0661\n",
      "Epoch 269/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3087 - f1: 0.6913 - val_loss: 0.2749 - val_f1: 0.0664\n",
      "Epoch 270/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3088 - f1: 0.6879 - val_loss: 0.2745 - val_f1: 0.0661\n",
      "Epoch 271/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3079 - f1: 0.6912 - val_loss: 0.2749 - val_f1: 0.0662\n",
      "Epoch 272/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3095 - f1: 0.6880 - val_loss: 0.2749 - val_f1: 0.0661\n",
      "Epoch 273/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3072 - f1: 0.6941 - val_loss: 0.2749 - val_f1: 0.0663\n",
      "Epoch 274/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3078 - f1: 0.6929 - val_loss: 0.2758 - val_f1: 0.0664\n",
      "Epoch 275/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3073 - f1: 0.6918 - val_loss: 0.2755 - val_f1: 0.0662\n",
      "Epoch 276/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3089 - f1: 0.6908 - val_loss: 0.2747 - val_f1: 0.0664\n",
      "Epoch 277/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3087 - f1: 0.6895 - val_loss: 0.2739 - val_f1: 0.0660\n",
      "Epoch 278/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3078 - f1: 0.6929 - val_loss: 0.2732 - val_f1: 0.0657\n",
      "Epoch 279/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3070 - f1: 0.6901 - val_loss: 0.2748 - val_f1: 0.0662\n",
      "Epoch 280/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3081 - f1: 0.6915 - val_loss: 0.2743 - val_f1: 0.0660\n",
      "Epoch 281/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3084 - f1: 0.6932 - val_loss: 0.2750 - val_f1: 0.0661\n",
      "Epoch 282/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3091 - f1: 0.6914 - val_loss: 0.2740 - val_f1: 0.0660\n",
      "Epoch 283/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3073 - f1: 0.6940 - val_loss: 0.2741 - val_f1: 0.0660\n",
      "Epoch 284/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3079 - f1: 0.6895 - val_loss: 0.2753 - val_f1: 0.0667\n",
      "Epoch 285/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3070 - f1: 0.6933 - val_loss: 0.2754 - val_f1: 0.0664\n",
      "Epoch 286/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3069 - f1: 0.6947 - val_loss: 0.2753 - val_f1: 0.0665\n",
      "Epoch 287/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3057 - f1: 0.6966 - val_loss: 0.2761 - val_f1: 0.0666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3078 - f1: 0.6918 - val_loss: 0.2750 - val_f1: 0.0667\n",
      "Epoch 289/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3071 - f1: 0.6911 - val_loss: 0.2754 - val_f1: 0.0662\n",
      "Epoch 290/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3082 - f1: 0.6912 - val_loss: 0.2767 - val_f1: 0.0666\n",
      "Epoch 291/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3049 - f1: 0.6947 - val_loss: 0.2764 - val_f1: 0.0665\n",
      "Epoch 292/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3064 - f1: 0.6937 - val_loss: 0.2761 - val_f1: 0.0663\n",
      "Epoch 293/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3069 - f1: 0.6922 - val_loss: 0.2755 - val_f1: 0.0661\n",
      "Epoch 294/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3064 - f1: 0.6932 - val_loss: 0.2747 - val_f1: 0.0661\n",
      "Epoch 295/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3081 - f1: 0.6926 - val_loss: 0.2758 - val_f1: 0.0664\n",
      "Epoch 296/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3067 - f1: 0.6912 - val_loss: 0.2753 - val_f1: 0.0663\n",
      "Epoch 297/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3063 - f1: 0.6946 - val_loss: 0.2760 - val_f1: 0.0664\n",
      "Epoch 298/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3061 - f1: 0.6949 - val_loss: 0.2750 - val_f1: 0.0662\n",
      "Epoch 299/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3057 - f1: 0.6942 - val_loss: 0.2768 - val_f1: 0.0666\n",
      "Epoch 300/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3061 - f1: 0.6940 - val_loss: 0.2755 - val_f1: 0.0657\n",
      "Epoch 301/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3061 - f1: 0.6949 - val_loss: 0.2754 - val_f1: 0.0659\n",
      "Epoch 302/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3052 - f1: 0.6969 - val_loss: 0.2755 - val_f1: 0.0663\n",
      "Epoch 303/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3064 - f1: 0.6927 - val_loss: 0.2753 - val_f1: 0.0661\n",
      "Epoch 304/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3058 - f1: 0.6938 - val_loss: 0.2754 - val_f1: 0.0662\n",
      "Epoch 305/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3053 - f1: 0.6940 - val_loss: 0.2769 - val_f1: 0.0666\n",
      "Epoch 306/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3054 - f1: 0.6967 - val_loss: 0.2750 - val_f1: 0.0662\n",
      "Epoch 307/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3055 - f1: 0.6964 - val_loss: 0.2749 - val_f1: 0.0660\n",
      "Epoch 308/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3052 - f1: 0.6952 - val_loss: 0.2765 - val_f1: 0.0666\n",
      "Epoch 309/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3053 - f1: 0.6977 - val_loss: 0.2759 - val_f1: 0.0664\n",
      "Epoch 310/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3052 - f1: 0.6951 - val_loss: 0.2752 - val_f1: 0.0665\n",
      "Epoch 311/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3060 - f1: 0.6962 - val_loss: 0.2745 - val_f1: 0.0660\n",
      "Epoch 312/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3054 - f1: 0.6951 - val_loss: 0.2757 - val_f1: 0.0665\n",
      "Epoch 313/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3058 - f1: 0.6951 - val_loss: 0.2754 - val_f1: 0.0661\n",
      "Epoch 314/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3052 - f1: 0.6950 - val_loss: 0.2768 - val_f1: 0.0664\n",
      "Epoch 315/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3050 - f1: 0.6963 - val_loss: 0.2766 - val_f1: 0.0666\n",
      "Epoch 316/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3038 - f1: 0.6990 - val_loss: 0.2743 - val_f1: 0.0659\n",
      "Epoch 317/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3051 - f1: 0.6967 - val_loss: 0.2756 - val_f1: 0.0662\n",
      "Epoch 318/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3043 - f1: 0.6959 - val_loss: 0.2743 - val_f1: 0.0659\n",
      "Epoch 319/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3037 - f1: 0.6968 - val_loss: 0.2778 - val_f1: 0.0664\n",
      "Epoch 320/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3039 - f1: 0.6970 - val_loss: 0.2749 - val_f1: 0.0659\n",
      "Epoch 321/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3037 - f1: 0.6968 - val_loss: 0.2762 - val_f1: 0.0662\n",
      "Epoch 322/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3047 - f1: 0.6965 - val_loss: 0.2761 - val_f1: 0.0664\n",
      "Epoch 323/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3046 - f1: 0.6951 - val_loss: 0.2751 - val_f1: 0.0660\n",
      "Epoch 324/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3050 - f1: 0.6961 - val_loss: 0.2758 - val_f1: 0.0660\n",
      "Epoch 325/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3034 - f1: 0.6966 - val_loss: 0.2762 - val_f1: 0.0661\n",
      "Epoch 326/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3035 - f1: 0.6989 - val_loss: 0.2761 - val_f1: 0.0661\n",
      "Epoch 327/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3043 - f1: 0.6973 - val_loss: 0.2778 - val_f1: 0.0669\n",
      "Epoch 328/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3025 - f1: 0.6969 - val_loss: 0.2763 - val_f1: 0.0662\n",
      "Epoch 329/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3031 - f1: 0.6983 - val_loss: 0.2761 - val_f1: 0.0661\n",
      "Epoch 330/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3039 - f1: 0.6978 - val_loss: 0.2751 - val_f1: 0.0660\n",
      "Epoch 331/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3037 - f1: 0.6956 - val_loss: 0.2767 - val_f1: 0.0666\n",
      "Epoch 332/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3031 - f1: 0.6980 - val_loss: 0.2753 - val_f1: 0.0660\n",
      "Epoch 333/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3043 - f1: 0.6971 - val_loss: 0.2762 - val_f1: 0.0664\n",
      "Epoch 334/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3030 - f1: 0.6997 - val_loss: 0.2764 - val_f1: 0.0662\n",
      "Epoch 335/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3033 - f1: 0.6980 - val_loss: 0.2758 - val_f1: 0.0658\n",
      "Epoch 336/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3026 - f1: 0.6973 - val_loss: 0.2746 - val_f1: 0.0655\n",
      "Epoch 337/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3035 - f1: 0.6978 - val_loss: 0.2747 - val_f1: 0.0657\n",
      "Epoch 338/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3022 - f1: 0.6979 - val_loss: 0.2763 - val_f1: 0.0660\n",
      "Epoch 339/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3045 - f1: 0.6954 - val_loss: 0.2765 - val_f1: 0.0659\n",
      "Epoch 340/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3033 - f1: 0.6973 - val_loss: 0.2764 - val_f1: 0.0661\n",
      "Epoch 341/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3020 - f1: 0.7018 - val_loss: 0.2760 - val_f1: 0.0658\n",
      "Epoch 342/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3044 - f1: 0.6974 - val_loss: 0.2765 - val_f1: 0.0661\n",
      "Epoch 343/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3026 - f1: 0.6999 - val_loss: 0.2755 - val_f1: 0.0658\n",
      "Epoch 344/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3029 - f1: 0.6980 - val_loss: 0.2756 - val_f1: 0.0659\n",
      "Epoch 345/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3020 - f1: 0.7000 - val_loss: 0.2769 - val_f1: 0.0663\n",
      "Epoch 346/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3026 - f1: 0.6990 - val_loss: 0.2765 - val_f1: 0.0659\n",
      "Epoch 347/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3029 - f1: 0.6977 - val_loss: 0.2766 - val_f1: 0.0660\n",
      "Epoch 348/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3030 - f1: 0.6984 - val_loss: 0.2762 - val_f1: 0.0658\n",
      "Epoch 349/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3024 - f1: 0.6991 - val_loss: 0.2765 - val_f1: 0.0659\n",
      "Epoch 350/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3033 - f1: 0.6971 - val_loss: 0.2763 - val_f1: 0.0659\n",
      "Epoch 351/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3028 - f1: 0.6983 - val_loss: 0.2764 - val_f1: 0.0658\n",
      "Epoch 352/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3026 - f1: 0.6994 - val_loss: 0.2745 - val_f1: 0.0655\n",
      "Epoch 353/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3023 - f1: 0.6998 - val_loss: 0.2757 - val_f1: 0.0656\n",
      "Epoch 354/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3021 - f1: 0.6989 - val_loss: 0.2775 - val_f1: 0.0661\n",
      "Epoch 355/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3025 - f1: 0.7015 - val_loss: 0.2754 - val_f1: 0.0657\n",
      "Epoch 356/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3016 - f1: 0.7000 - val_loss: 0.2759 - val_f1: 0.0656\n",
      "Epoch 357/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3028 - f1: 0.6986 - val_loss: 0.2758 - val_f1: 0.0655\n",
      "Epoch 358/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3032 - f1: 0.7025 - val_loss: 0.2751 - val_f1: 0.0656\n",
      "Epoch 359/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3026 - f1: 0.6953 - val_loss: 0.2757 - val_f1: 0.0658\n",
      "Epoch 360/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3009 - f1: 0.6983 - val_loss: 0.2770 - val_f1: 0.0661\n",
      "Epoch 361/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3013 - f1: 0.6981 - val_loss: 0.2767 - val_f1: 0.0659\n",
      "Epoch 362/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3010 - f1: 0.7008 - val_loss: 0.2769 - val_f1: 0.0660\n",
      "Epoch 363/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3004 - f1: 0.6997 - val_loss: 0.2759 - val_f1: 0.0657\n",
      "Epoch 364/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3022 - f1: 0.6991 - val_loss: 0.2762 - val_f1: 0.0656\n",
      "Epoch 365/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3024 - f1: 0.7000 - val_loss: 0.2756 - val_f1: 0.0657\n",
      "Epoch 366/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3009 - f1: 0.6994 - val_loss: 0.2754 - val_f1: 0.0654\n",
      "Epoch 367/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3012 - f1: 0.7011 - val_loss: 0.2770 - val_f1: 0.0660\n",
      "Epoch 368/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3014 - f1: 0.6991 - val_loss: 0.2783 - val_f1: 0.0663\n",
      "Epoch 369/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3008 - f1: 0.7022 - val_loss: 0.2772 - val_f1: 0.0662\n",
      "Epoch 370/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3020 - f1: 0.7001 - val_loss: 0.2768 - val_f1: 0.0659\n",
      "Epoch 371/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2998 - f1: 0.7019 - val_loss: 0.2759 - val_f1: 0.0655\n",
      "Epoch 372/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3002 - f1: 0.7014 - val_loss: 0.2768 - val_f1: 0.0657\n",
      "Epoch 373/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3015 - f1: 0.6998 - val_loss: 0.2767 - val_f1: 0.0658\n",
      "Epoch 374/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3016 - f1: 0.6993 - val_loss: 0.2755 - val_f1: 0.0655\n",
      "Epoch 375/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3017 - f1: 0.7003 - val_loss: 0.2765 - val_f1: 0.0656\n",
      "Epoch 376/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3004 - f1: 0.6987 - val_loss: 0.2778 - val_f1: 0.0661\n",
      "Epoch 377/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3017 - f1: 0.7005 - val_loss: 0.2767 - val_f1: 0.0657\n",
      "Epoch 378/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3006 - f1: 0.6994 - val_loss: 0.2774 - val_f1: 0.0661\n",
      "Epoch 379/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3011 - f1: 0.7020 - val_loss: 0.2752 - val_f1: 0.0655\n",
      "Epoch 380/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3009 - f1: 0.7022 - val_loss: 0.2774 - val_f1: 0.0658\n",
      "Epoch 381/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2999 - f1: 0.7013 - val_loss: 0.2778 - val_f1: 0.0658\n",
      "Epoch 382/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3006 - f1: 0.7020 - val_loss: 0.2782 - val_f1: 0.0660\n",
      "Epoch 383/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2998 - f1: 0.7037 - val_loss: 0.2769 - val_f1: 0.0658\n",
      "Epoch 384/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2995 - f1: 0.7032 - val_loss: 0.2762 - val_f1: 0.0654\n",
      "Epoch 385/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3011 - f1: 0.7019 - val_loss: 0.2778 - val_f1: 0.0660\n",
      "Epoch 386/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3014 - f1: 0.7009 - val_loss: 0.2765 - val_f1: 0.0655\n",
      "Epoch 387/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3012 - f1: 0.6980 - val_loss: 0.2761 - val_f1: 0.0653\n",
      "Epoch 388/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.3000 - f1: 0.7012 - val_loss: 0.2760 - val_f1: 0.0653\n",
      "Epoch 389/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2998 - f1: 0.7032 - val_loss: 0.2764 - val_f1: 0.0655\n",
      "Epoch 390/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2999 - f1: 0.7027 - val_loss: 0.2763 - val_f1: 0.0654\n",
      "Epoch 391/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2996 - f1: 0.7016 - val_loss: 0.2776 - val_f1: 0.0658\n",
      "Epoch 392/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3016 - f1: 0.6996 - val_loss: 0.2770 - val_f1: 0.0655\n",
      "Epoch 393/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3000 - f1: 0.7022 - val_loss: 0.2777 - val_f1: 0.0657\n",
      "Epoch 394/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2991 - f1: 0.7036 - val_loss: 0.2774 - val_f1: 0.0657\n",
      "Epoch 395/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2995 - f1: 0.7018 - val_loss: 0.2776 - val_f1: 0.0661\n",
      "Epoch 396/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2994 - f1: 0.7018 - val_loss: 0.2767 - val_f1: 0.0656\n",
      "Epoch 397/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3011 - f1: 0.6996 - val_loss: 0.2770 - val_f1: 0.0655\n",
      "Epoch 398/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2976 - f1: 0.7029 - val_loss: 0.2780 - val_f1: 0.0655\n",
      "Epoch 399/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2994 - f1: 0.7035 - val_loss: 0.2785 - val_f1: 0.0659\n",
      "Epoch 400/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2993 - f1: 0.7030 - val_loss: 0.2775 - val_f1: 0.0658\n",
      "Epoch 401/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2991 - f1: 0.7048 - val_loss: 0.2773 - val_f1: 0.0654\n",
      "Epoch 402/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2984 - f1: 0.7039 - val_loss: 0.2760 - val_f1: 0.0654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2981 - f1: 0.7048 - val_loss: 0.2764 - val_f1: 0.0653\n",
      "Epoch 404/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2984 - f1: 0.7040 - val_loss: 0.2775 - val_f1: 0.0655\n",
      "Epoch 405/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2993 - f1: 0.7020 - val_loss: 0.2782 - val_f1: 0.0656\n",
      "Epoch 406/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2998 - f1: 0.7044 - val_loss: 0.2777 - val_f1: 0.0655\n",
      "Epoch 407/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2991 - f1: 0.7011 - val_loss: 0.2769 - val_f1: 0.0653\n",
      "Epoch 408/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2993 - f1: 0.7019 - val_loss: 0.2774 - val_f1: 0.0656\n",
      "Epoch 409/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2986 - f1: 0.7046 - val_loss: 0.2763 - val_f1: 0.0650\n",
      "Epoch 410/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2982 - f1: 0.7035 - val_loss: 0.2779 - val_f1: 0.0657\n",
      "Epoch 411/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2982 - f1: 0.7056 - val_loss: 0.2766 - val_f1: 0.0653\n",
      "Epoch 412/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2992 - f1: 0.7010 - val_loss: 0.2773 - val_f1: 0.0654\n",
      "Epoch 413/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2980 - f1: 0.7034 - val_loss: 0.2763 - val_f1: 0.0654\n",
      "Epoch 414/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2975 - f1: 0.7036 - val_loss: 0.2793 - val_f1: 0.0660\n",
      "Epoch 415/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2990 - f1: 0.7046 - val_loss: 0.2780 - val_f1: 0.0656\n",
      "Epoch 416/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2986 - f1: 0.7045 - val_loss: 0.2773 - val_f1: 0.0656\n",
      "Epoch 417/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2969 - f1: 0.7053 - val_loss: 0.2798 - val_f1: 0.0658\n",
      "Epoch 418/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2987 - f1: 0.7044 - val_loss: 0.2777 - val_f1: 0.0655\n",
      "Epoch 419/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2981 - f1: 0.7049 - val_loss: 0.2779 - val_f1: 0.0657\n",
      "Epoch 420/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2967 - f1: 0.7057 - val_loss: 0.2773 - val_f1: 0.0654\n",
      "Epoch 421/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2982 - f1: 0.7037 - val_loss: 0.2781 - val_f1: 0.0656\n",
      "Epoch 422/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2974 - f1: 0.7058 - val_loss: 0.2768 - val_f1: 0.0652\n",
      "Epoch 423/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2983 - f1: 0.7064 - val_loss: 0.2790 - val_f1: 0.0656\n",
      "Epoch 424/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2973 - f1: 0.7051 - val_loss: 0.2773 - val_f1: 0.0654\n",
      "Epoch 425/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2974 - f1: 0.7063 - val_loss: 0.2768 - val_f1: 0.0651\n",
      "Epoch 426/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2972 - f1: 0.7032 - val_loss: 0.2772 - val_f1: 0.0655\n",
      "Epoch 427/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2985 - f1: 0.7044 - val_loss: 0.2774 - val_f1: 0.0651\n",
      "Epoch 428/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2976 - f1: 0.7052 - val_loss: 0.2770 - val_f1: 0.0653\n",
      "Epoch 429/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2989 - f1: 0.7021 - val_loss: 0.2783 - val_f1: 0.0654\n",
      "Epoch 430/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2974 - f1: 0.7048 - val_loss: 0.2766 - val_f1: 0.0648\n",
      "Epoch 431/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2970 - f1: 0.7056 - val_loss: 0.2777 - val_f1: 0.0653\n",
      "Epoch 432/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2968 - f1: 0.7063 - val_loss: 0.2759 - val_f1: 0.0650\n",
      "Epoch 433/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2982 - f1: 0.7033 - val_loss: 0.2770 - val_f1: 0.0654\n",
      "Epoch 434/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2974 - f1: 0.7036 - val_loss: 0.2776 - val_f1: 0.0652\n",
      "Epoch 435/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2965 - f1: 0.7062 - val_loss: 0.2772 - val_f1: 0.0652\n",
      "Epoch 436/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2981 - f1: 0.7048 - val_loss: 0.2760 - val_f1: 0.0649\n",
      "Epoch 437/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2961 - f1: 0.7085 - val_loss: 0.2784 - val_f1: 0.0654\n",
      "Epoch 438/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2978 - f1: 0.7057 - val_loss: 0.2780 - val_f1: 0.0654\n",
      "Epoch 439/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2972 - f1: 0.7031 - val_loss: 0.2767 - val_f1: 0.0652\n",
      "Epoch 440/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2966 - f1: 0.7062 - val_loss: 0.2790 - val_f1: 0.0656\n",
      "Epoch 441/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2965 - f1: 0.7080 - val_loss: 0.2781 - val_f1: 0.0656\n",
      "Epoch 442/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2967 - f1: 0.7062 - val_loss: 0.2793 - val_f1: 0.0658\n",
      "Epoch 443/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2979 - f1: 0.7058 - val_loss: 0.2773 - val_f1: 0.0652\n",
      "Epoch 444/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2975 - f1: 0.7049 - val_loss: 0.2785 - val_f1: 0.0656\n",
      "Epoch 445/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2972 - f1: 0.7083 - val_loss: 0.2770 - val_f1: 0.0653\n",
      "Epoch 446/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2960 - f1: 0.7065 - val_loss: 0.2772 - val_f1: 0.0652\n",
      "Epoch 447/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2965 - f1: 0.7061 - val_loss: 0.2778 - val_f1: 0.0650\n",
      "Epoch 448/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2974 - f1: 0.7058 - val_loss: 0.2773 - val_f1: 0.0652\n",
      "Epoch 449/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2974 - f1: 0.7075 - val_loss: 0.2776 - val_f1: 0.0650\n",
      "Epoch 450/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2965 - f1: 0.7060 - val_loss: 0.2783 - val_f1: 0.0651\n",
      "Epoch 451/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2964 - f1: 0.7083 - val_loss: 0.2778 - val_f1: 0.0650\n",
      "Epoch 452/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2977 - f1: 0.7065 - val_loss: 0.2772 - val_f1: 0.0649\n",
      "Epoch 453/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2961 - f1: 0.7062 - val_loss: 0.2782 - val_f1: 0.0651\n",
      "Epoch 454/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2943 - f1: 0.7078 - val_loss: 0.2786 - val_f1: 0.0656\n",
      "Epoch 455/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2970 - f1: 0.7058 - val_loss: 0.2789 - val_f1: 0.0654\n",
      "Epoch 456/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2962 - f1: 0.7047 - val_loss: 0.2776 - val_f1: 0.0650\n",
      "Epoch 457/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2968 - f1: 0.7051 - val_loss: 0.2772 - val_f1: 0.0651\n",
      "Epoch 458/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2960 - f1: 0.7086 - val_loss: 0.2786 - val_f1: 0.0653\n",
      "Epoch 459/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2958 - f1: 0.7076 - val_loss: 0.2784 - val_f1: 0.0653\n",
      "Epoch 460/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2966 - f1: 0.7066 - val_loss: 0.2794 - val_f1: 0.0655\n",
      "Epoch 461/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2959 - f1: 0.7069 - val_loss: 0.2780 - val_f1: 0.0650\n",
      "Epoch 462/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2958 - f1: 0.7098 - val_loss: 0.2781 - val_f1: 0.0653\n",
      "Epoch 463/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2969 - f1: 0.7051 - val_loss: 0.2779 - val_f1: 0.0653\n",
      "Epoch 464/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2949 - f1: 0.7087 - val_loss: 0.2785 - val_f1: 0.0652\n",
      "Epoch 465/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2963 - f1: 0.7083 - val_loss: 0.2773 - val_f1: 0.0648\n",
      "Epoch 466/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2969 - f1: 0.7064 - val_loss: 0.2774 - val_f1: 0.0652\n",
      "Epoch 467/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2951 - f1: 0.7090 - val_loss: 0.2783 - val_f1: 0.0651\n",
      "Epoch 468/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2963 - f1: 0.7062 - val_loss: 0.2789 - val_f1: 0.0654\n",
      "Epoch 469/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2954 - f1: 0.7065 - val_loss: 0.2779 - val_f1: 0.0651\n",
      "Epoch 470/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2963 - f1: 0.7072 - val_loss: 0.2780 - val_f1: 0.0650\n",
      "Epoch 471/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2959 - f1: 0.7082 - val_loss: 0.2785 - val_f1: 0.0652\n",
      "Epoch 472/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2951 - f1: 0.7085 - val_loss: 0.2784 - val_f1: 0.0654\n",
      "Epoch 473/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2953 - f1: 0.7064 - val_loss: 0.2785 - val_f1: 0.0652\n",
      "Epoch 474/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2952 - f1: 0.7078 - val_loss: 0.2791 - val_f1: 0.0653\n",
      "Epoch 475/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2952 - f1: 0.7078 - val_loss: 0.2792 - val_f1: 0.0656\n",
      "Epoch 476/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2954 - f1: 0.7072 - val_loss: 0.2782 - val_f1: 0.0652\n",
      "Epoch 477/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2951 - f1: 0.7055 - val_loss: 0.2786 - val_f1: 0.0652\n",
      "Epoch 478/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2959 - f1: 0.7083 - val_loss: 0.2788 - val_f1: 0.0653\n",
      "Epoch 479/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2938 - f1: 0.7100 - val_loss: 0.2790 - val_f1: 0.0651\n",
      "Epoch 480/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2949 - f1: 0.7083 - val_loss: 0.2775 - val_f1: 0.0654\n",
      "Epoch 481/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2968 - f1: 0.7068 - val_loss: 0.2773 - val_f1: 0.0650\n",
      "Epoch 482/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2945 - f1: 0.7086 - val_loss: 0.2781 - val_f1: 0.0653\n",
      "Epoch 483/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2951 - f1: 0.7094 - val_loss: 0.2782 - val_f1: 0.0651\n",
      "Epoch 484/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2952 - f1: 0.7074 - val_loss: 0.2778 - val_f1: 0.0650\n",
      "Epoch 485/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2950 - f1: 0.7090 - val_loss: 0.2779 - val_f1: 0.0649\n",
      "Epoch 486/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2943 - f1: 0.7099 - val_loss: 0.2794 - val_f1: 0.0654\n",
      "Epoch 487/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2954 - f1: 0.7081 - val_loss: 0.2775 - val_f1: 0.0652\n",
      "Epoch 488/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2959 - f1: 0.7087 - val_loss: 0.2782 - val_f1: 0.0652\n",
      "Epoch 489/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2944 - f1: 0.7088 - val_loss: 0.2789 - val_f1: 0.0654\n",
      "Epoch 490/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2961 - f1: 0.7065 - val_loss: 0.2788 - val_f1: 0.0654\n",
      "Epoch 491/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2955 - f1: 0.7052 - val_loss: 0.2784 - val_f1: 0.0649\n",
      "Epoch 492/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2952 - f1: 0.7095 - val_loss: 0.2773 - val_f1: 0.0648\n",
      "Epoch 493/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2954 - f1: 0.7048 - val_loss: 0.2782 - val_f1: 0.0651\n",
      "Epoch 494/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2958 - f1: 0.7101 - val_loss: 0.2778 - val_f1: 0.0651\n",
      "Epoch 495/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2953 - f1: 0.7088 - val_loss: 0.2773 - val_f1: 0.0649\n",
      "Epoch 496/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2948 - f1: 0.7099 - val_loss: 0.2794 - val_f1: 0.0651\n",
      "Epoch 497/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2951 - f1: 0.7075 - val_loss: 0.2786 - val_f1: 0.0652\n",
      "Epoch 498/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2939 - f1: 0.7104 - val_loss: 0.2785 - val_f1: 0.0653\n",
      "Epoch 499/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2938 - f1: 0.7117 - val_loss: 0.2796 - val_f1: 0.0655\n",
      "Epoch 500/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2948 - f1: 0.7086 - val_loss: 0.2783 - val_f1: 0.0653\n",
      "Epoch 501/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2951 - f1: 0.7094 - val_loss: 0.2785 - val_f1: 0.0653\n",
      "Epoch 502/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2937 - f1: 0.7095 - val_loss: 0.2789 - val_f1: 0.0653\n",
      "Epoch 503/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2937 - f1: 0.7122 - val_loss: 0.2782 - val_f1: 0.0651\n",
      "Epoch 504/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2942 - f1: 0.7109 - val_loss: 0.2777 - val_f1: 0.0651\n",
      "Epoch 505/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2941 - f1: 0.7083 - val_loss: 0.2775 - val_f1: 0.0648\n",
      "Epoch 506/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2945 - f1: 0.7075 - val_loss: 0.2777 - val_f1: 0.0650\n",
      "Epoch 507/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2939 - f1: 0.7093 - val_loss: 0.2787 - val_f1: 0.0653\n",
      "Epoch 508/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2947 - f1: 0.7090 - val_loss: 0.2797 - val_f1: 0.0652\n",
      "Epoch 509/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2941 - f1: 0.7114 - val_loss: 0.2782 - val_f1: 0.0652\n",
      "Epoch 510/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2947 - f1: 0.7101 - val_loss: 0.2781 - val_f1: 0.0651\n",
      "Epoch 511/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2951 - f1: 0.7067 - val_loss: 0.2778 - val_f1: 0.0648\n",
      "Epoch 512/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2949 - f1: 0.7071 - val_loss: 0.2787 - val_f1: 0.0651\n",
      "Epoch 513/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2946 - f1: 0.7102 - val_loss: 0.2796 - val_f1: 0.0653\n",
      "Epoch 514/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2958 - f1: 0.7073 - val_loss: 0.2796 - val_f1: 0.0653\n",
      "Epoch 515/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2943 - f1: 0.7080 - val_loss: 0.2790 - val_f1: 0.0652\n",
      "Epoch 516/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2945 - f1: 0.7096 - val_loss: 0.2793 - val_f1: 0.0655\n",
      "Epoch 517/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2941 - f1: 0.7091 - val_loss: 0.2790 - val_f1: 0.0653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2937 - f1: 0.7094 - val_loss: 0.2788 - val_f1: 0.0653\n",
      "Epoch 519/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2946 - f1: 0.7093 - val_loss: 0.2790 - val_f1: 0.0652\n",
      "Epoch 520/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2941 - f1: 0.7105 - val_loss: 0.2789 - val_f1: 0.0652\n",
      "Epoch 521/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2945 - f1: 0.7086 - val_loss: 0.2791 - val_f1: 0.0656\n",
      "Epoch 522/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2942 - f1: 0.7102 - val_loss: 0.2787 - val_f1: 0.0650\n",
      "Epoch 523/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2956 - f1: 0.7080 - val_loss: 0.2790 - val_f1: 0.0652\n",
      "Epoch 524/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2934 - f1: 0.7105 - val_loss: 0.2784 - val_f1: 0.0649\n",
      "Epoch 525/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2937 - f1: 0.7104 - val_loss: 0.2778 - val_f1: 0.0646\n",
      "Epoch 526/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2940 - f1: 0.7089 - val_loss: 0.2808 - val_f1: 0.0656\n",
      "Epoch 527/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2951 - f1: 0.7092 - val_loss: 0.2783 - val_f1: 0.0652\n",
      "Epoch 528/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2934 - f1: 0.7080 - val_loss: 0.2799 - val_f1: 0.0651\n",
      "Epoch 529/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2938 - f1: 0.7097 - val_loss: 0.2788 - val_f1: 0.0653\n",
      "Epoch 530/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2927 - f1: 0.7125 - val_loss: 0.2789 - val_f1: 0.0650\n",
      "Epoch 531/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2932 - f1: 0.7117 - val_loss: 0.2786 - val_f1: 0.0649\n",
      "Epoch 532/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2932 - f1: 0.7105 - val_loss: 0.2790 - val_f1: 0.0650\n",
      "Epoch 533/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2932 - f1: 0.7115 - val_loss: 0.2789 - val_f1: 0.0652\n",
      "Epoch 534/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2928 - f1: 0.7101 - val_loss: 0.2805 - val_f1: 0.0653\n",
      "Epoch 535/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2924 - f1: 0.7119 - val_loss: 0.2809 - val_f1: 0.0656\n",
      "Epoch 536/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2941 - f1: 0.7103 - val_loss: 0.2781 - val_f1: 0.0647\n",
      "Epoch 537/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2931 - f1: 0.7110 - val_loss: 0.2787 - val_f1: 0.0649\n",
      "Epoch 538/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2933 - f1: 0.7105 - val_loss: 0.2779 - val_f1: 0.0649\n",
      "Epoch 539/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2923 - f1: 0.7098 - val_loss: 0.2785 - val_f1: 0.0648\n",
      "Epoch 540/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2928 - f1: 0.7124 - val_loss: 0.2793 - val_f1: 0.0649\n",
      "Epoch 541/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2943 - f1: 0.7109 - val_loss: 0.2771 - val_f1: 0.0647\n",
      "Epoch 542/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2931 - f1: 0.7098 - val_loss: 0.2802 - val_f1: 0.0656\n",
      "Epoch 543/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2927 - f1: 0.7127 - val_loss: 0.2777 - val_f1: 0.0645\n",
      "Epoch 544/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2927 - f1: 0.7105 - val_loss: 0.2785 - val_f1: 0.0649\n",
      "Epoch 545/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2919 - f1: 0.7117 - val_loss: 0.2788 - val_f1: 0.0650\n",
      "Epoch 546/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2928 - f1: 0.7126 - val_loss: 0.2786 - val_f1: 0.0649\n",
      "Epoch 547/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2933 - f1: 0.7109 - val_loss: 0.2779 - val_f1: 0.0647\n",
      "Epoch 548/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2942 - f1: 0.7095 - val_loss: 0.2778 - val_f1: 0.0648\n",
      "Epoch 549/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2919 - f1: 0.7128 - val_loss: 0.2792 - val_f1: 0.0652\n",
      "Epoch 550/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2931 - f1: 0.7085 - val_loss: 0.2787 - val_f1: 0.0650\n",
      "Epoch 551/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2928 - f1: 0.7102 - val_loss: 0.2792 - val_f1: 0.0652\n",
      "Epoch 552/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2919 - f1: 0.7115 - val_loss: 0.2784 - val_f1: 0.0648\n",
      "Epoch 553/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2919 - f1: 0.7129 - val_loss: 0.2805 - val_f1: 0.0656\n",
      "Epoch 554/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2928 - f1: 0.7138 - val_loss: 0.2785 - val_f1: 0.0649\n",
      "Epoch 555/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2923 - f1: 0.7119 - val_loss: 0.2777 - val_f1: 0.0649\n",
      "Epoch 556/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2934 - f1: 0.7099 - val_loss: 0.2780 - val_f1: 0.0649\n",
      "Epoch 557/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2920 - f1: 0.7099 - val_loss: 0.2785 - val_f1: 0.0649\n",
      "Epoch 558/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2920 - f1: 0.7112 - val_loss: 0.2798 - val_f1: 0.0653\n",
      "Epoch 559/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2911 - f1: 0.7135 - val_loss: 0.2805 - val_f1: 0.0656\n",
      "Epoch 560/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2920 - f1: 0.7109 - val_loss: 0.2789 - val_f1: 0.0653\n",
      "Epoch 561/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2910 - f1: 0.7116 - val_loss: 0.2805 - val_f1: 0.0653\n",
      "Epoch 562/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2922 - f1: 0.7110 - val_loss: 0.2781 - val_f1: 0.0650\n",
      "Epoch 563/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2914 - f1: 0.7127 - val_loss: 0.2795 - val_f1: 0.0650\n",
      "Epoch 564/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2927 - f1: 0.7093 - val_loss: 0.2786 - val_f1: 0.0647\n",
      "Epoch 565/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2915 - f1: 0.7122 - val_loss: 0.2801 - val_f1: 0.0651\n",
      "Epoch 566/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2935 - f1: 0.7099 - val_loss: 0.2785 - val_f1: 0.0648\n",
      "Epoch 567/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2911 - f1: 0.7140 - val_loss: 0.2779 - val_f1: 0.0645\n",
      "Epoch 568/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2928 - f1: 0.7111 - val_loss: 0.2775 - val_f1: 0.0648\n",
      "Epoch 569/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2913 - f1: 0.7129 - val_loss: 0.2804 - val_f1: 0.0654\n",
      "Epoch 570/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2922 - f1: 0.7128 - val_loss: 0.2790 - val_f1: 0.0650\n",
      "Epoch 571/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2921 - f1: 0.7127 - val_loss: 0.2787 - val_f1: 0.0649\n",
      "Epoch 572/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2914 - f1: 0.7102 - val_loss: 0.2791 - val_f1: 0.0649\n",
      "Epoch 573/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2915 - f1: 0.7131 - val_loss: 0.2794 - val_f1: 0.0652\n",
      "Epoch 574/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2920 - f1: 0.7139 - val_loss: 0.2794 - val_f1: 0.0652\n",
      "Epoch 575/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2909 - f1: 0.7140 - val_loss: 0.2798 - val_f1: 0.0650\n",
      "Epoch 576/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2919 - f1: 0.7110 - val_loss: 0.2788 - val_f1: 0.0646\n",
      "Epoch 577/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2912 - f1: 0.7111 - val_loss: 0.2787 - val_f1: 0.0646\n",
      "Epoch 578/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2913 - f1: 0.7104 - val_loss: 0.2793 - val_f1: 0.0648\n",
      "Epoch 579/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2923 - f1: 0.7129 - val_loss: 0.2786 - val_f1: 0.0645\n",
      "Epoch 580/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2929 - f1: 0.7123 - val_loss: 0.2789 - val_f1: 0.0651\n",
      "Epoch 581/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2913 - f1: 0.7124 - val_loss: 0.2795 - val_f1: 0.0649\n",
      "Epoch 582/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2925 - f1: 0.7121 - val_loss: 0.2802 - val_f1: 0.0650\n",
      "Epoch 583/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2905 - f1: 0.7138 - val_loss: 0.2800 - val_f1: 0.0652\n",
      "Epoch 584/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2913 - f1: 0.7121 - val_loss: 0.2798 - val_f1: 0.0650\n",
      "Epoch 585/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2895 - f1: 0.7152 - val_loss: 0.2798 - val_f1: 0.0648\n",
      "Epoch 586/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2917 - f1: 0.7113 - val_loss: 0.2799 - val_f1: 0.0650\n",
      "Epoch 587/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2901 - f1: 0.7130 - val_loss: 0.2801 - val_f1: 0.0650\n",
      "Epoch 588/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2901 - f1: 0.7116 - val_loss: 0.2801 - val_f1: 0.0649\n",
      "Epoch 589/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2903 - f1: 0.7133 - val_loss: 0.2811 - val_f1: 0.0655\n",
      "Epoch 590/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2909 - f1: 0.7155 - val_loss: 0.2790 - val_f1: 0.0647\n",
      "Epoch 591/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2903 - f1: 0.7137 - val_loss: 0.2805 - val_f1: 0.0653\n",
      "Epoch 592/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2921 - f1: 0.7118 - val_loss: 0.2796 - val_f1: 0.0649\n",
      "Epoch 593/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2913 - f1: 0.7124 - val_loss: 0.2797 - val_f1: 0.0648\n",
      "Epoch 594/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2913 - f1: 0.7124 - val_loss: 0.2793 - val_f1: 0.0651\n",
      "Epoch 595/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2913 - f1: 0.7128 - val_loss: 0.2785 - val_f1: 0.0644\n",
      "Epoch 596/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2901 - f1: 0.7135 - val_loss: 0.2787 - val_f1: 0.0645\n",
      "Epoch 597/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2928 - f1: 0.7110 - val_loss: 0.2794 - val_f1: 0.0647\n",
      "Epoch 598/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2899 - f1: 0.7150 - val_loss: 0.2788 - val_f1: 0.0646\n",
      "Epoch 599/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2908 - f1: 0.7167 - val_loss: 0.2792 - val_f1: 0.0647\n",
      "Epoch 600/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2909 - f1: 0.7145 - val_loss: 0.2804 - val_f1: 0.0651\n",
      "Epoch 601/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2913 - f1: 0.7129 - val_loss: 0.2797 - val_f1: 0.0652\n",
      "Epoch 602/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2908 - f1: 0.7143 - val_loss: 0.2803 - val_f1: 0.0653\n",
      "Epoch 603/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2915 - f1: 0.7134 - val_loss: 0.2779 - val_f1: 0.0644\n",
      "Epoch 604/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2895 - f1: 0.7134 - val_loss: 0.2790 - val_f1: 0.0647\n",
      "Epoch 605/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2904 - f1: 0.7147 - val_loss: 0.2785 - val_f1: 0.0643\n",
      "Epoch 606/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2910 - f1: 0.7124 - val_loss: 0.2801 - val_f1: 0.0649\n",
      "Epoch 607/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2906 - f1: 0.7122 - val_loss: 0.2796 - val_f1: 0.0647\n",
      "Epoch 608/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2903 - f1: 0.7148 - val_loss: 0.2799 - val_f1: 0.0647\n",
      "Epoch 609/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2902 - f1: 0.7149 - val_loss: 0.2801 - val_f1: 0.0649\n",
      "Epoch 610/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2900 - f1: 0.7138 - val_loss: 0.2805 - val_f1: 0.0650\n",
      "Epoch 611/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2905 - f1: 0.7137 - val_loss: 0.2799 - val_f1: 0.0652\n",
      "Epoch 612/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2897 - f1: 0.7136 - val_loss: 0.2789 - val_f1: 0.0645\n",
      "Epoch 613/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2897 - f1: 0.7148 - val_loss: 0.2789 - val_f1: 0.0645\n",
      "Epoch 614/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2909 - f1: 0.7145 - val_loss: 0.2798 - val_f1: 0.0648\n",
      "Epoch 615/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2891 - f1: 0.7157 - val_loss: 0.2793 - val_f1: 0.0646\n",
      "Epoch 616/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2906 - f1: 0.7157 - val_loss: 0.2789 - val_f1: 0.0643\n",
      "Epoch 617/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2917 - f1: 0.7137 - val_loss: 0.2796 - val_f1: 0.0652\n",
      "Epoch 618/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2900 - f1: 0.7136 - val_loss: 0.2805 - val_f1: 0.0651\n",
      "Epoch 619/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2907 - f1: 0.7140 - val_loss: 0.2780 - val_f1: 0.0642\n",
      "Epoch 620/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2905 - f1: 0.7122 - val_loss: 0.2810 - val_f1: 0.0655\n",
      "Epoch 621/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2903 - f1: 0.7134 - val_loss: 0.2788 - val_f1: 0.0645\n",
      "Epoch 622/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2892 - f1: 0.7158 - val_loss: 0.2795 - val_f1: 0.0644\n",
      "Epoch 623/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2910 - f1: 0.7131 - val_loss: 0.2800 - val_f1: 0.0651\n",
      "Epoch 624/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2896 - f1: 0.7171 - val_loss: 0.2812 - val_f1: 0.0650\n",
      "Epoch 625/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2892 - f1: 0.7144 - val_loss: 0.2803 - val_f1: 0.0647\n",
      "Epoch 626/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2903 - f1: 0.7156 - val_loss: 0.2794 - val_f1: 0.0647\n",
      "Epoch 627/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2900 - f1: 0.7144 - val_loss: 0.2805 - val_f1: 0.0651\n",
      "Epoch 628/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2914 - f1: 0.7112 - val_loss: 0.2805 - val_f1: 0.0648\n",
      "Epoch 629/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2897 - f1: 0.7139 - val_loss: 0.2789 - val_f1: 0.0642\n",
      "Epoch 630/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2904 - f1: 0.7141 - val_loss: 0.2796 - val_f1: 0.0648\n",
      "Epoch 631/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2898 - f1: 0.7137 - val_loss: 0.2795 - val_f1: 0.0646\n",
      "Epoch 632/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2897 - f1: 0.7131 - val_loss: 0.2794 - val_f1: 0.0647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2906 - f1: 0.7150 - val_loss: 0.2799 - val_f1: 0.0648\n",
      "Epoch 634/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2909 - f1: 0.7131 - val_loss: 0.2796 - val_f1: 0.0648\n",
      "Epoch 635/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2894 - f1: 0.7154 - val_loss: 0.2791 - val_f1: 0.0645\n",
      "Epoch 636/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2894 - f1: 0.7162 - val_loss: 0.2799 - val_f1: 0.0647\n",
      "Epoch 637/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2904 - f1: 0.7139 - val_loss: 0.2794 - val_f1: 0.0646\n",
      "Epoch 638/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2898 - f1: 0.7145 - val_loss: 0.2800 - val_f1: 0.0648\n",
      "Epoch 639/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2894 - f1: 0.7155 - val_loss: 0.2802 - val_f1: 0.0648\n",
      "Epoch 640/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2894 - f1: 0.7156 - val_loss: 0.2795 - val_f1: 0.0647\n",
      "Epoch 641/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2897 - f1: 0.7150 - val_loss: 0.2786 - val_f1: 0.0640\n",
      "Epoch 642/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2905 - f1: 0.7137 - val_loss: 0.2800 - val_f1: 0.0649\n",
      "Epoch 643/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2889 - f1: 0.7157 - val_loss: 0.2800 - val_f1: 0.0647\n",
      "Epoch 644/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2887 - f1: 0.7169 - val_loss: 0.2805 - val_f1: 0.0649\n",
      "Epoch 645/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2893 - f1: 0.7163 - val_loss: 0.2795 - val_f1: 0.0644\n",
      "Epoch 646/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2887 - f1: 0.7159 - val_loss: 0.2805 - val_f1: 0.0645\n",
      "Epoch 647/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2894 - f1: 0.7156 - val_loss: 0.2801 - val_f1: 0.0645\n",
      "Epoch 648/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2884 - f1: 0.7177 - val_loss: 0.2806 - val_f1: 0.0649\n",
      "Epoch 649/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2896 - f1: 0.7146 - val_loss: 0.2804 - val_f1: 0.0649\n",
      "Epoch 650/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2893 - f1: 0.7151 - val_loss: 0.2800 - val_f1: 0.0649\n",
      "Epoch 651/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2885 - f1: 0.7158 - val_loss: 0.2794 - val_f1: 0.0647\n",
      "Epoch 652/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2888 - f1: 0.7154 - val_loss: 0.2794 - val_f1: 0.0644\n",
      "Epoch 653/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2891 - f1: 0.7161 - val_loss: 0.2798 - val_f1: 0.0644\n",
      "Epoch 654/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2902 - f1: 0.7134 - val_loss: 0.2794 - val_f1: 0.0644\n",
      "Epoch 655/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2894 - f1: 0.7143 - val_loss: 0.2803 - val_f1: 0.0648\n",
      "Epoch 656/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2901 - f1: 0.7162 - val_loss: 0.2804 - val_f1: 0.0648\n",
      "Epoch 657/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2874 - f1: 0.7168 - val_loss: 0.2815 - val_f1: 0.0649\n",
      "Epoch 658/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2895 - f1: 0.7158 - val_loss: 0.2808 - val_f1: 0.0648\n",
      "Epoch 659/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2886 - f1: 0.7166 - val_loss: 0.2798 - val_f1: 0.0643\n",
      "Epoch 660/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2878 - f1: 0.7160 - val_loss: 0.2796 - val_f1: 0.0643\n",
      "Epoch 661/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2901 - f1: 0.7147 - val_loss: 0.2786 - val_f1: 0.0639\n",
      "Epoch 662/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2878 - f1: 0.7184 - val_loss: 0.2800 - val_f1: 0.0643\n",
      "Epoch 663/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2895 - f1: 0.7138 - val_loss: 0.2795 - val_f1: 0.0642\n",
      "Epoch 664/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2909 - f1: 0.7135 - val_loss: 0.2806 - val_f1: 0.0649\n",
      "Epoch 665/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2874 - f1: 0.7195 - val_loss: 0.2804 - val_f1: 0.0646\n",
      "Epoch 666/2000\n",
      "168135/168135 [==============================] - 11s 62us/step - loss: 0.2894 - f1: 0.7150 - val_loss: 0.2808 - val_f1: 0.0646\n",
      "Epoch 667/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2885 - f1: 0.7167 - val_loss: 0.2808 - val_f1: 0.0646\n",
      "Epoch 668/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2891 - f1: 0.7173 - val_loss: 0.2797 - val_f1: 0.0647\n",
      "Epoch 669/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2878 - f1: 0.7176 - val_loss: 0.2811 - val_f1: 0.0647\n",
      "Epoch 670/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2884 - f1: 0.7164 - val_loss: 0.2804 - val_f1: 0.0647\n",
      "Epoch 671/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2893 - f1: 0.7142 - val_loss: 0.2798 - val_f1: 0.0648\n",
      "Epoch 672/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2884 - f1: 0.7166 - val_loss: 0.2818 - val_f1: 0.0650\n",
      "Epoch 673/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2891 - f1: 0.7162 - val_loss: 0.2799 - val_f1: 0.0645\n",
      "Epoch 674/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2896 - f1: 0.7141 - val_loss: 0.2802 - val_f1: 0.0644\n",
      "Epoch 675/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2897 - f1: 0.7150 - val_loss: 0.2799 - val_f1: 0.0645\n",
      "Epoch 676/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2883 - f1: 0.7176 - val_loss: 0.2795 - val_f1: 0.0641\n",
      "Epoch 677/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2882 - f1: 0.7172 - val_loss: 0.2803 - val_f1: 0.0647\n",
      "Epoch 678/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2893 - f1: 0.7137 - val_loss: 0.2817 - val_f1: 0.0651\n",
      "Epoch 679/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2901 - f1: 0.7139 - val_loss: 0.2820 - val_f1: 0.0652\n",
      "Epoch 680/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2874 - f1: 0.7162 - val_loss: 0.2790 - val_f1: 0.0639\n",
      "Epoch 681/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2891 - f1: 0.7155 - val_loss: 0.2796 - val_f1: 0.0643\n",
      "Epoch 682/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2890 - f1: 0.7168 - val_loss: 0.2794 - val_f1: 0.0645\n",
      "Epoch 683/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2887 - f1: 0.7164 - val_loss: 0.2798 - val_f1: 0.0641\n",
      "Epoch 684/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2888 - f1: 0.7146 - val_loss: 0.2802 - val_f1: 0.0644\n",
      "Epoch 685/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2881 - f1: 0.7165 - val_loss: 0.2798 - val_f1: 0.0646\n",
      "Epoch 686/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2884 - f1: 0.7155 - val_loss: 0.2805 - val_f1: 0.0649\n",
      "Epoch 687/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2884 - f1: 0.7189 - val_loss: 0.2787 - val_f1: 0.0644\n",
      "Epoch 688/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2880 - f1: 0.7181 - val_loss: 0.2813 - val_f1: 0.0648\n",
      "Epoch 689/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2871 - f1: 0.7187 - val_loss: 0.2809 - val_f1: 0.0649\n",
      "Epoch 690/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2868 - f1: 0.7188 - val_loss: 0.2815 - val_f1: 0.0649\n",
      "Epoch 691/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2876 - f1: 0.7162 - val_loss: 0.2806 - val_f1: 0.0644\n",
      "Epoch 692/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2874 - f1: 0.7160 - val_loss: 0.2815 - val_f1: 0.0647\n",
      "Epoch 693/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2883 - f1: 0.7135 - val_loss: 0.2807 - val_f1: 0.0646\n",
      "Epoch 694/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2883 - f1: 0.7174 - val_loss: 0.2803 - val_f1: 0.0645\n",
      "Epoch 695/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2867 - f1: 0.7207 - val_loss: 0.2789 - val_f1: 0.0641\n",
      "Epoch 696/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2886 - f1: 0.7166 - val_loss: 0.2802 - val_f1: 0.0647\n",
      "Epoch 697/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2873 - f1: 0.7189 - val_loss: 0.2804 - val_f1: 0.0644\n",
      "Epoch 698/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2880 - f1: 0.7172 - val_loss: 0.2804 - val_f1: 0.0646\n",
      "Epoch 699/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2885 - f1: 0.7179 - val_loss: 0.2808 - val_f1: 0.0650\n",
      "Epoch 700/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2877 - f1: 0.7175 - val_loss: 0.2805 - val_f1: 0.0648\n",
      "Epoch 701/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2883 - f1: 0.7178 - val_loss: 0.2809 - val_f1: 0.0647\n",
      "Epoch 702/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2886 - f1: 0.7154 - val_loss: 0.2812 - val_f1: 0.0651\n",
      "Epoch 703/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2881 - f1: 0.7167 - val_loss: 0.2800 - val_f1: 0.0646\n",
      "Epoch 704/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2879 - f1: 0.7167 - val_loss: 0.2807 - val_f1: 0.0647\n",
      "Epoch 705/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2881 - f1: 0.7154 - val_loss: 0.2819 - val_f1: 0.0650\n",
      "Epoch 706/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2879 - f1: 0.7187 - val_loss: 0.2796 - val_f1: 0.0646\n",
      "Epoch 707/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2879 - f1: 0.7167 - val_loss: 0.2792 - val_f1: 0.0642\n",
      "Epoch 708/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2882 - f1: 0.7148 - val_loss: 0.2805 - val_f1: 0.0647\n",
      "Epoch 709/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2864 - f1: 0.7188 - val_loss: 0.2809 - val_f1: 0.0648\n",
      "Epoch 710/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2858 - f1: 0.7193 - val_loss: 0.2806 - val_f1: 0.0647\n",
      "Epoch 711/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2877 - f1: 0.7161 - val_loss: 0.2807 - val_f1: 0.0645\n",
      "Epoch 712/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2864 - f1: 0.7186 - val_loss: 0.2811 - val_f1: 0.0648\n",
      "Epoch 713/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2859 - f1: 0.7218 - val_loss: 0.2805 - val_f1: 0.0644\n",
      "Epoch 714/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2884 - f1: 0.7168 - val_loss: 0.2809 - val_f1: 0.0646\n",
      "Epoch 715/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2856 - f1: 0.7211 - val_loss: 0.2807 - val_f1: 0.0644\n",
      "Epoch 716/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2886 - f1: 0.7177 - val_loss: 0.2819 - val_f1: 0.0650\n",
      "Epoch 717/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2883 - f1: 0.7192 - val_loss: 0.2804 - val_f1: 0.0644\n",
      "Epoch 718/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2875 - f1: 0.7170 - val_loss: 0.2798 - val_f1: 0.0644\n",
      "Epoch 719/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2875 - f1: 0.7167 - val_loss: 0.2818 - val_f1: 0.0651\n",
      "Epoch 720/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2883 - f1: 0.7177 - val_loss: 0.2797 - val_f1: 0.0642\n",
      "Epoch 721/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2877 - f1: 0.7205 - val_loss: 0.2812 - val_f1: 0.0649\n",
      "Epoch 722/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2876 - f1: 0.7190 - val_loss: 0.2807 - val_f1: 0.0646\n",
      "Epoch 723/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2881 - f1: 0.7167 - val_loss: 0.2804 - val_f1: 0.0645\n",
      "Epoch 724/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2869 - f1: 0.7203 - val_loss: 0.2795 - val_f1: 0.0642\n",
      "Epoch 725/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2879 - f1: 0.7189 - val_loss: 0.2813 - val_f1: 0.0647\n",
      "Epoch 726/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2865 - f1: 0.7181 - val_loss: 0.2812 - val_f1: 0.0647\n",
      "Epoch 727/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2884 - f1: 0.7177 - val_loss: 0.2819 - val_f1: 0.0647\n",
      "Epoch 728/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2879 - f1: 0.7163 - val_loss: 0.2805 - val_f1: 0.0646\n",
      "Epoch 729/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2866 - f1: 0.7175 - val_loss: 0.2807 - val_f1: 0.0645\n",
      "Epoch 730/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2874 - f1: 0.7175 - val_loss: 0.2804 - val_f1: 0.0646\n",
      "Epoch 731/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2873 - f1: 0.7184 - val_loss: 0.2805 - val_f1: 0.0646\n",
      "Epoch 732/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2882 - f1: 0.7151 - val_loss: 0.2810 - val_f1: 0.0646\n",
      "Epoch 733/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2876 - f1: 0.7158 - val_loss: 0.2804 - val_f1: 0.0646\n",
      "Epoch 734/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2875 - f1: 0.7176 - val_loss: 0.2799 - val_f1: 0.0646\n",
      "Epoch 735/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2881 - f1: 0.7156 - val_loss: 0.2795 - val_f1: 0.0646\n",
      "Epoch 736/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2875 - f1: 0.7174 - val_loss: 0.2799 - val_f1: 0.0643\n",
      "Epoch 737/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2877 - f1: 0.7172 - val_loss: 0.2795 - val_f1: 0.0642\n",
      "Epoch 738/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2873 - f1: 0.7180 - val_loss: 0.2811 - val_f1: 0.0648\n",
      "Epoch 739/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2853 - f1: 0.7207 - val_loss: 0.2807 - val_f1: 0.0646\n",
      "Epoch 740/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2875 - f1: 0.7152 - val_loss: 0.2815 - val_f1: 0.0647\n",
      "Epoch 741/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2875 - f1: 0.7189 - val_loss: 0.2809 - val_f1: 0.0648\n",
      "Epoch 742/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2884 - f1: 0.7180 - val_loss: 0.2789 - val_f1: 0.0641\n",
      "Epoch 743/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2882 - f1: 0.7158 - val_loss: 0.2798 - val_f1: 0.0645\n",
      "Epoch 744/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2862 - f1: 0.7182 - val_loss: 0.2810 - val_f1: 0.0647\n",
      "Epoch 745/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2867 - f1: 0.7184 - val_loss: 0.2809 - val_f1: 0.0645\n",
      "Epoch 746/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2866 - f1: 0.7205 - val_loss: 0.2813 - val_f1: 0.0647\n",
      "Epoch 747/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2869 - f1: 0.7197 - val_loss: 0.2801 - val_f1: 0.0644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 748/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2864 - f1: 0.7195 - val_loss: 0.2804 - val_f1: 0.0642\n",
      "Epoch 749/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2865 - f1: 0.7180 - val_loss: 0.2814 - val_f1: 0.0651\n",
      "Epoch 750/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2868 - f1: 0.7191 - val_loss: 0.2801 - val_f1: 0.0643\n",
      "Epoch 751/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2860 - f1: 0.7194 - val_loss: 0.2817 - val_f1: 0.0647\n",
      "Epoch 752/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2856 - f1: 0.7187 - val_loss: 0.2799 - val_f1: 0.0641\n",
      "Epoch 753/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2862 - f1: 0.7222 - val_loss: 0.2817 - val_f1: 0.0648\n",
      "Epoch 754/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2871 - f1: 0.7198 - val_loss: 0.2804 - val_f1: 0.0643\n",
      "Epoch 755/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2862 - f1: 0.7202 - val_loss: 0.2806 - val_f1: 0.0646\n",
      "Epoch 756/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2869 - f1: 0.7166 - val_loss: 0.2805 - val_f1: 0.0642\n",
      "Epoch 757/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2860 - f1: 0.7195 - val_loss: 0.2817 - val_f1: 0.0646\n",
      "Epoch 758/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2868 - f1: 0.7184 - val_loss: 0.2816 - val_f1: 0.0650\n",
      "Epoch 759/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2860 - f1: 0.7193 - val_loss: 0.2805 - val_f1: 0.0645\n",
      "Epoch 760/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2857 - f1: 0.7149 - val_loss: 0.2818 - val_f1: 0.0646\n",
      "Epoch 761/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2874 - f1: 0.7183 - val_loss: 0.2807 - val_f1: 0.0648\n",
      "Epoch 762/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2865 - f1: 0.7169 - val_loss: 0.2804 - val_f1: 0.0644\n",
      "Epoch 763/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2863 - f1: 0.7211 - val_loss: 0.2809 - val_f1: 0.0645\n",
      "Epoch 764/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2856 - f1: 0.7190 - val_loss: 0.2815 - val_f1: 0.0648\n",
      "Epoch 765/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2859 - f1: 0.7198 - val_loss: 0.2817 - val_f1: 0.0649\n",
      "Epoch 766/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2863 - f1: 0.7189 - val_loss: 0.2807 - val_f1: 0.0642\n",
      "Epoch 767/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2863 - f1: 0.7188 - val_loss: 0.2814 - val_f1: 0.0646\n",
      "Epoch 768/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2862 - f1: 0.7200 - val_loss: 0.2805 - val_f1: 0.0644\n",
      "Epoch 769/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2859 - f1: 0.7195 - val_loss: 0.2805 - val_f1: 0.0646\n",
      "Epoch 770/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2863 - f1: 0.7181 - val_loss: 0.2802 - val_f1: 0.0644\n",
      "Epoch 771/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2861 - f1: 0.7207 - val_loss: 0.2812 - val_f1: 0.0646\n",
      "Epoch 772/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2867 - f1: 0.7196 - val_loss: 0.2808 - val_f1: 0.0642\n",
      "Epoch 773/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2859 - f1: 0.7195 - val_loss: 0.2824 - val_f1: 0.0651\n",
      "Epoch 774/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2855 - f1: 0.7205 - val_loss: 0.2811 - val_f1: 0.0646\n",
      "Epoch 775/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2852 - f1: 0.7214 - val_loss: 0.2803 - val_f1: 0.0641\n",
      "Epoch 776/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2854 - f1: 0.7174 - val_loss: 0.2811 - val_f1: 0.0645\n",
      "Epoch 777/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2861 - f1: 0.7185 - val_loss: 0.2811 - val_f1: 0.0646\n",
      "Epoch 778/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2863 - f1: 0.7213 - val_loss: 0.2806 - val_f1: 0.0645\n",
      "Epoch 779/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2866 - f1: 0.7179 - val_loss: 0.2812 - val_f1: 0.0647\n",
      "Epoch 780/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2861 - f1: 0.7191 - val_loss: 0.2813 - val_f1: 0.0644\n",
      "Epoch 781/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2860 - f1: 0.7182 - val_loss: 0.2809 - val_f1: 0.0641\n",
      "Epoch 782/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2866 - f1: 0.7195 - val_loss: 0.2801 - val_f1: 0.0640\n",
      "Epoch 783/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2853 - f1: 0.7197 - val_loss: 0.2804 - val_f1: 0.0644\n",
      "Epoch 784/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2857 - f1: 0.7176 - val_loss: 0.2804 - val_f1: 0.0645\n",
      "Epoch 785/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2856 - f1: 0.7185 - val_loss: 0.2804 - val_f1: 0.0644\n",
      "Epoch 786/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2859 - f1: 0.7181 - val_loss: 0.2808 - val_f1: 0.0642\n",
      "Epoch 787/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2853 - f1: 0.7209 - val_loss: 0.2811 - val_f1: 0.0643\n",
      "Epoch 788/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2856 - f1: 0.7206 - val_loss: 0.2814 - val_f1: 0.0648\n",
      "Epoch 789/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2851 - f1: 0.7200 - val_loss: 0.2810 - val_f1: 0.0644\n",
      "Epoch 790/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2868 - f1: 0.7173 - val_loss: 0.2818 - val_f1: 0.0647\n",
      "Epoch 791/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2871 - f1: 0.7180 - val_loss: 0.2804 - val_f1: 0.0646\n",
      "Epoch 792/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2856 - f1: 0.7202 - val_loss: 0.2817 - val_f1: 0.0648\n",
      "Epoch 793/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2856 - f1: 0.7215 - val_loss: 0.2812 - val_f1: 0.0645\n",
      "Epoch 794/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2858 - f1: 0.7208 - val_loss: 0.2813 - val_f1: 0.0646\n",
      "Epoch 795/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2865 - f1: 0.7176 - val_loss: 0.2804 - val_f1: 0.0644\n",
      "Epoch 796/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2858 - f1: 0.7215 - val_loss: 0.2809 - val_f1: 0.0647\n",
      "Epoch 797/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2857 - f1: 0.7198 - val_loss: 0.2821 - val_f1: 0.0647\n",
      "Epoch 798/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2851 - f1: 0.7207 - val_loss: 0.2813 - val_f1: 0.0645\n",
      "Epoch 799/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2846 - f1: 0.7225 - val_loss: 0.2806 - val_f1: 0.0642\n",
      "Epoch 800/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2860 - f1: 0.7197 - val_loss: 0.2821 - val_f1: 0.0646\n",
      "Epoch 801/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2856 - f1: 0.7219 - val_loss: 0.2805 - val_f1: 0.0643\n",
      "Epoch 802/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2857 - f1: 0.7185 - val_loss: 0.2815 - val_f1: 0.0649\n",
      "Epoch 803/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2849 - f1: 0.7196 - val_loss: 0.2820 - val_f1: 0.0646\n",
      "Epoch 804/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2854 - f1: 0.7196 - val_loss: 0.2805 - val_f1: 0.0643\n",
      "Epoch 805/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2849 - f1: 0.7217 - val_loss: 0.2807 - val_f1: 0.0645\n",
      "Epoch 806/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2851 - f1: 0.7214 - val_loss: 0.2818 - val_f1: 0.0645\n",
      "Epoch 807/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2858 - f1: 0.7201 - val_loss: 0.2808 - val_f1: 0.0642\n",
      "Epoch 808/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2847 - f1: 0.7222 - val_loss: 0.2815 - val_f1: 0.0644\n",
      "Epoch 809/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2850 - f1: 0.7210 - val_loss: 0.2807 - val_f1: 0.0645\n",
      "Epoch 810/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2851 - f1: 0.7226 - val_loss: 0.2805 - val_f1: 0.0646\n",
      "Epoch 811/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2849 - f1: 0.7208 - val_loss: 0.2810 - val_f1: 0.0643\n",
      "Epoch 812/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2856 - f1: 0.7209 - val_loss: 0.2809 - val_f1: 0.0641\n",
      "Epoch 813/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2855 - f1: 0.7214 - val_loss: 0.2823 - val_f1: 0.0648\n",
      "Epoch 814/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2850 - f1: 0.7206 - val_loss: 0.2836 - val_f1: 0.0650\n",
      "Epoch 815/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2850 - f1: 0.7200 - val_loss: 0.2814 - val_f1: 0.0644\n",
      "Epoch 816/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2844 - f1: 0.7208 - val_loss: 0.2809 - val_f1: 0.0645\n",
      "Epoch 817/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2862 - f1: 0.7196 - val_loss: 0.2821 - val_f1: 0.0650\n",
      "Epoch 818/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2863 - f1: 0.7171 - val_loss: 0.2818 - val_f1: 0.0649\n",
      "Epoch 819/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2850 - f1: 0.7225 - val_loss: 0.2809 - val_f1: 0.0644\n",
      "Epoch 820/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2844 - f1: 0.7202 - val_loss: 0.2816 - val_f1: 0.0646\n",
      "Epoch 821/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2847 - f1: 0.7233 - val_loss: 0.2812 - val_f1: 0.0644\n",
      "Epoch 822/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2859 - f1: 0.7187 - val_loss: 0.2802 - val_f1: 0.0641\n",
      "Epoch 823/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2838 - f1: 0.7195 - val_loss: 0.2819 - val_f1: 0.0646\n",
      "Epoch 824/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2846 - f1: 0.7217 - val_loss: 0.2806 - val_f1: 0.0642\n",
      "Epoch 825/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2856 - f1: 0.7220 - val_loss: 0.2826 - val_f1: 0.0648\n",
      "Epoch 826/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2846 - f1: 0.7210 - val_loss: 0.2812 - val_f1: 0.0645\n",
      "Epoch 827/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2859 - f1: 0.7208 - val_loss: 0.2802 - val_f1: 0.0642\n",
      "Epoch 828/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2832 - f1: 0.7221 - val_loss: 0.2813 - val_f1: 0.0644\n",
      "Epoch 829/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2846 - f1: 0.7224 - val_loss: 0.2820 - val_f1: 0.0644\n",
      "Epoch 830/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2843 - f1: 0.7228 - val_loss: 0.2806 - val_f1: 0.0642\n",
      "Epoch 831/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2850 - f1: 0.7196 - val_loss: 0.2813 - val_f1: 0.0646\n",
      "Epoch 832/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2845 - f1: 0.7186 - val_loss: 0.2816 - val_f1: 0.0645\n",
      "Epoch 833/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2842 - f1: 0.7204 - val_loss: 0.2823 - val_f1: 0.0643\n",
      "Epoch 834/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2843 - f1: 0.7207 - val_loss: 0.2820 - val_f1: 0.0644\n",
      "Epoch 835/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2838 - f1: 0.7234 - val_loss: 0.2825 - val_f1: 0.0648\n",
      "Epoch 836/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2854 - f1: 0.7223 - val_loss: 0.2808 - val_f1: 0.0644\n",
      "Epoch 837/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2854 - f1: 0.7184 - val_loss: 0.2814 - val_f1: 0.0644\n",
      "Epoch 838/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2842 - f1: 0.7211 - val_loss: 0.2829 - val_f1: 0.0648\n",
      "Epoch 839/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2842 - f1: 0.7214 - val_loss: 0.2823 - val_f1: 0.0645\n",
      "Epoch 840/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2844 - f1: 0.7214 - val_loss: 0.2815 - val_f1: 0.0643\n",
      "Epoch 841/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2850 - f1: 0.7193 - val_loss: 0.2808 - val_f1: 0.0641\n",
      "Epoch 842/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2845 - f1: 0.7226 - val_loss: 0.2811 - val_f1: 0.0643\n",
      "Epoch 843/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2848 - f1: 0.7237 - val_loss: 0.2815 - val_f1: 0.0645\n",
      "Epoch 844/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2846 - f1: 0.7212 - val_loss: 0.2816 - val_f1: 0.0646\n",
      "Epoch 845/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2839 - f1: 0.7221 - val_loss: 0.2815 - val_f1: 0.0643\n",
      "Epoch 846/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2845 - f1: 0.7203 - val_loss: 0.2805 - val_f1: 0.0645\n",
      "Epoch 847/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2836 - f1: 0.7223 - val_loss: 0.2810 - val_f1: 0.0643\n",
      "Epoch 848/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2851 - f1: 0.7194 - val_loss: 0.2812 - val_f1: 0.0644\n",
      "Epoch 849/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2847 - f1: 0.7223 - val_loss: 0.2813 - val_f1: 0.0641\n",
      "Epoch 850/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2859 - f1: 0.7190 - val_loss: 0.2823 - val_f1: 0.0644\n",
      "Epoch 851/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2828 - f1: 0.7263 - val_loss: 0.2818 - val_f1: 0.0646\n",
      "Epoch 852/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2844 - f1: 0.7211 - val_loss: 0.2822 - val_f1: 0.0649\n",
      "Epoch 853/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2847 - f1: 0.7199 - val_loss: 0.2826 - val_f1: 0.0645\n",
      "Epoch 854/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2835 - f1: 0.7226 - val_loss: 0.2811 - val_f1: 0.0642\n",
      "Epoch 855/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2844 - f1: 0.7202 - val_loss: 0.2820 - val_f1: 0.0644\n",
      "Epoch 856/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2843 - f1: 0.7219 - val_loss: 0.2820 - val_f1: 0.0646\n",
      "Epoch 857/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2841 - f1: 0.7199 - val_loss: 0.2813 - val_f1: 0.0645\n",
      "Epoch 858/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2840 - f1: 0.7223 - val_loss: 0.2817 - val_f1: 0.0642\n",
      "Epoch 859/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2850 - f1: 0.7190 - val_loss: 0.2824 - val_f1: 0.0645\n",
      "Epoch 860/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2843 - f1: 0.7226 - val_loss: 0.2804 - val_f1: 0.0642\n",
      "Epoch 861/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2840 - f1: 0.7209 - val_loss: 0.2819 - val_f1: 0.0646\n",
      "Epoch 862/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2835 - f1: 0.7238 - val_loss: 0.2830 - val_f1: 0.0649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 863/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2848 - f1: 0.7216 - val_loss: 0.2815 - val_f1: 0.0643\n",
      "Epoch 864/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2835 - f1: 0.7229 - val_loss: 0.2813 - val_f1: 0.0642\n",
      "Epoch 865/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2825 - f1: 0.7230 - val_loss: 0.2823 - val_f1: 0.0647\n",
      "Epoch 866/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2849 - f1: 0.7210 - val_loss: 0.2807 - val_f1: 0.0642\n",
      "Epoch 867/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2841 - f1: 0.7226 - val_loss: 0.2823 - val_f1: 0.0645\n",
      "Epoch 868/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2842 - f1: 0.7197 - val_loss: 0.2813 - val_f1: 0.0642\n",
      "Epoch 869/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2844 - f1: 0.7222 - val_loss: 0.2825 - val_f1: 0.0647\n",
      "Epoch 870/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2837 - f1: 0.7220 - val_loss: 0.2815 - val_f1: 0.0643\n",
      "Epoch 871/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2848 - f1: 0.7223 - val_loss: 0.2823 - val_f1: 0.0646\n",
      "Epoch 872/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2850 - f1: 0.7215 - val_loss: 0.2812 - val_f1: 0.0643\n",
      "Epoch 873/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2851 - f1: 0.7226 - val_loss: 0.2818 - val_f1: 0.0644\n",
      "Epoch 874/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2834 - f1: 0.7233 - val_loss: 0.2828 - val_f1: 0.0646\n",
      "Epoch 875/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2835 - f1: 0.7250 - val_loss: 0.2808 - val_f1: 0.0641\n",
      "Epoch 876/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2835 - f1: 0.7241 - val_loss: 0.2812 - val_f1: 0.0646\n",
      "Epoch 877/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2831 - f1: 0.7228 - val_loss: 0.2823 - val_f1: 0.0645\n",
      "Epoch 878/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2828 - f1: 0.7219 - val_loss: 0.2817 - val_f1: 0.0646\n",
      "Epoch 879/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2840 - f1: 0.7229 - val_loss: 0.2808 - val_f1: 0.0643\n",
      "Epoch 880/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2847 - f1: 0.7208 - val_loss: 0.2815 - val_f1: 0.0644\n",
      "Epoch 881/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2823 - f1: 0.7246 - val_loss: 0.2814 - val_f1: 0.0643\n",
      "Epoch 882/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2837 - f1: 0.7228 - val_loss: 0.2825 - val_f1: 0.0644\n",
      "Epoch 883/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2843 - f1: 0.7201 - val_loss: 0.2812 - val_f1: 0.0643\n",
      "Epoch 884/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2827 - f1: 0.7228 - val_loss: 0.2829 - val_f1: 0.0648\n",
      "Epoch 885/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2830 - f1: 0.7231 - val_loss: 0.2820 - val_f1: 0.0644\n",
      "Epoch 886/2000\n",
      "168135/168135 [==============================] - 9s 52us/step - loss: 0.2825 - f1: 0.7232 - val_loss: 0.2824 - val_f1: 0.0646\n",
      "Epoch 887/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2816 - f1: 0.7247 - val_loss: 0.2824 - val_f1: 0.0645\n",
      "Epoch 888/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2835 - f1: 0.7224 - val_loss: 0.2810 - val_f1: 0.0641\n",
      "Epoch 889/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2837 - f1: 0.7234 - val_loss: 0.2806 - val_f1: 0.0641\n",
      "Epoch 890/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2836 - f1: 0.7234 - val_loss: 0.2816 - val_f1: 0.0643\n",
      "Epoch 891/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2845 - f1: 0.7211 - val_loss: 0.2813 - val_f1: 0.0640\n",
      "Epoch 892/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2846 - f1: 0.7206 - val_loss: 0.2810 - val_f1: 0.0642\n",
      "Epoch 893/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2836 - f1: 0.7206 - val_loss: 0.2812 - val_f1: 0.0640\n",
      "Epoch 894/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2833 - f1: 0.7241 - val_loss: 0.2815 - val_f1: 0.0644\n",
      "Epoch 895/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2834 - f1: 0.7233 - val_loss: 0.2821 - val_f1: 0.0644\n",
      "Epoch 896/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2840 - f1: 0.7207 - val_loss: 0.2825 - val_f1: 0.0646\n",
      "Epoch 897/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2830 - f1: 0.7234 - val_loss: 0.2817 - val_f1: 0.0646\n",
      "Epoch 898/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2834 - f1: 0.7228 - val_loss: 0.2820 - val_f1: 0.0646\n",
      "Epoch 899/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2839 - f1: 0.7232 - val_loss: 0.2809 - val_f1: 0.0640\n",
      "Epoch 900/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2835 - f1: 0.7215 - val_loss: 0.2817 - val_f1: 0.0645\n",
      "Epoch 901/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2843 - f1: 0.7206 - val_loss: 0.2809 - val_f1: 0.0646\n",
      "Epoch 902/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2838 - f1: 0.7230 - val_loss: 0.2812 - val_f1: 0.0644\n",
      "Epoch 903/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2824 - f1: 0.7243 - val_loss: 0.2827 - val_f1: 0.0647\n",
      "Epoch 904/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2831 - f1: 0.7240 - val_loss: 0.2819 - val_f1: 0.0642\n",
      "Epoch 905/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2836 - f1: 0.7212 - val_loss: 0.2822 - val_f1: 0.0644\n",
      "Epoch 906/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2845 - f1: 0.7201 - val_loss: 0.2827 - val_f1: 0.0648\n",
      "Epoch 907/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2848 - f1: 0.7219 - val_loss: 0.2819 - val_f1: 0.0645\n",
      "Epoch 908/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2827 - f1: 0.7247 - val_loss: 0.2816 - val_f1: 0.0643\n",
      "Epoch 909/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2845 - f1: 0.7182 - val_loss: 0.2823 - val_f1: 0.0644\n",
      "Epoch 910/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2830 - f1: 0.7252 - val_loss: 0.2815 - val_f1: 0.0644\n",
      "Epoch 911/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2843 - f1: 0.7226 - val_loss: 0.2826 - val_f1: 0.0648\n",
      "Epoch 912/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2824 - f1: 0.7260 - val_loss: 0.2818 - val_f1: 0.0645\n",
      "Epoch 913/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2823 - f1: 0.7245 - val_loss: 0.2817 - val_f1: 0.0645\n",
      "Epoch 914/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2824 - f1: 0.7245 - val_loss: 0.2808 - val_f1: 0.0641\n",
      "Epoch 915/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2825 - f1: 0.7236 - val_loss: 0.2817 - val_f1: 0.0644\n",
      "Epoch 916/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2828 - f1: 0.7235 - val_loss: 0.2820 - val_f1: 0.0644\n",
      "Epoch 917/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2825 - f1: 0.7244 - val_loss: 0.2815 - val_f1: 0.0640\n",
      "Epoch 918/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2836 - f1: 0.7241 - val_loss: 0.2825 - val_f1: 0.0647\n",
      "Epoch 919/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2831 - f1: 0.7227 - val_loss: 0.2828 - val_f1: 0.0647\n",
      "Epoch 920/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2839 - f1: 0.7220 - val_loss: 0.2824 - val_f1: 0.0647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 921/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2832 - f1: 0.7233 - val_loss: 0.2815 - val_f1: 0.0644\n",
      "Epoch 922/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2833 - f1: 0.7195 - val_loss: 0.2814 - val_f1: 0.0642\n",
      "Epoch 923/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2840 - f1: 0.7203 - val_loss: 0.2820 - val_f1: 0.0644\n",
      "Epoch 924/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2831 - f1: 0.7219 - val_loss: 0.2830 - val_f1: 0.0648\n",
      "Epoch 925/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2823 - f1: 0.7256 - val_loss: 0.2813 - val_f1: 0.0642\n",
      "Epoch 926/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2821 - f1: 0.7236 - val_loss: 0.2835 - val_f1: 0.0647\n",
      "Epoch 927/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2847 - f1: 0.7239 - val_loss: 0.2823 - val_f1: 0.0647\n",
      "Epoch 928/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2826 - f1: 0.7234 - val_loss: 0.2828 - val_f1: 0.0646\n",
      "Epoch 929/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2820 - f1: 0.7262 - val_loss: 0.2811 - val_f1: 0.0641\n",
      "Epoch 930/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2830 - f1: 0.7236 - val_loss: 0.2817 - val_f1: 0.0643\n",
      "Epoch 931/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2836 - f1: 0.7219 - val_loss: 0.2827 - val_f1: 0.0649\n",
      "Epoch 932/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2832 - f1: 0.7215 - val_loss: 0.2819 - val_f1: 0.0645\n",
      "Epoch 933/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2812 - f1: 0.7241 - val_loss: 0.2818 - val_f1: 0.0643\n",
      "Epoch 934/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2837 - f1: 0.7219 - val_loss: 0.2824 - val_f1: 0.0643\n",
      "Epoch 935/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2841 - f1: 0.7218 - val_loss: 0.2826 - val_f1: 0.0646\n",
      "Epoch 936/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2830 - f1: 0.7239 - val_loss: 0.2809 - val_f1: 0.0639\n",
      "Epoch 937/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2833 - f1: 0.7227 - val_loss: 0.2820 - val_f1: 0.0644\n",
      "Epoch 938/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2827 - f1: 0.7219 - val_loss: 0.2819 - val_f1: 0.0644\n",
      "Epoch 939/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2832 - f1: 0.7225 - val_loss: 0.2808 - val_f1: 0.0642\n",
      "Epoch 940/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2821 - f1: 0.7237 - val_loss: 0.2827 - val_f1: 0.0646\n",
      "Epoch 941/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2823 - f1: 0.7255 - val_loss: 0.2813 - val_f1: 0.0644\n",
      "Epoch 942/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2835 - f1: 0.7242 - val_loss: 0.2815 - val_f1: 0.0643\n",
      "Epoch 943/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2812 - f1: 0.7261 - val_loss: 0.2824 - val_f1: 0.0648\n",
      "Epoch 944/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2839 - f1: 0.7232 - val_loss: 0.2826 - val_f1: 0.0644\n",
      "Epoch 945/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2823 - f1: 0.7226 - val_loss: 0.2818 - val_f1: 0.0642\n",
      "Epoch 946/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2822 - f1: 0.7240 - val_loss: 0.2820 - val_f1: 0.0643\n",
      "Epoch 947/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2831 - f1: 0.7240 - val_loss: 0.2819 - val_f1: 0.0642\n",
      "Epoch 948/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2821 - f1: 0.7244 - val_loss: 0.2826 - val_f1: 0.0646\n",
      "Epoch 949/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2830 - f1: 0.7242 - val_loss: 0.2816 - val_f1: 0.0642\n",
      "Epoch 950/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2804 - f1: 0.7274 - val_loss: 0.2827 - val_f1: 0.0644\n",
      "Epoch 951/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2813 - f1: 0.7260 - val_loss: 0.2824 - val_f1: 0.0644\n",
      "Epoch 952/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2818 - f1: 0.7245 - val_loss: 0.2830 - val_f1: 0.0648\n",
      "Epoch 953/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2822 - f1: 0.7248 - val_loss: 0.2829 - val_f1: 0.0644\n",
      "Epoch 954/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2829 - f1: 0.7244 - val_loss: 0.2823 - val_f1: 0.0641\n",
      "Epoch 955/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2821 - f1: 0.7251 - val_loss: 0.2822 - val_f1: 0.0643\n",
      "Epoch 956/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2823 - f1: 0.7228 - val_loss: 0.2822 - val_f1: 0.0645\n",
      "Epoch 957/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2823 - f1: 0.7255 - val_loss: 0.2823 - val_f1: 0.0643\n",
      "Epoch 958/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2833 - f1: 0.7231 - val_loss: 0.2822 - val_f1: 0.0644\n",
      "Epoch 959/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2821 - f1: 0.7255 - val_loss: 0.2816 - val_f1: 0.0639\n",
      "Epoch 960/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2823 - f1: 0.7256 - val_loss: 0.2815 - val_f1: 0.0642\n",
      "Epoch 961/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2824 - f1: 0.7242 - val_loss: 0.2830 - val_f1: 0.0647\n",
      "Epoch 962/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2829 - f1: 0.7238 - val_loss: 0.2822 - val_f1: 0.0646\n",
      "Epoch 963/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2830 - f1: 0.7245 - val_loss: 0.2831 - val_f1: 0.0648\n",
      "Epoch 964/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2827 - f1: 0.7239 - val_loss: 0.2825 - val_f1: 0.0644\n",
      "Epoch 965/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2823 - f1: 0.7233 - val_loss: 0.2828 - val_f1: 0.0647\n",
      "Epoch 966/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2834 - f1: 0.7228 - val_loss: 0.2816 - val_f1: 0.0644\n",
      "Epoch 967/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2824 - f1: 0.7231 - val_loss: 0.2817 - val_f1: 0.0642\n",
      "Epoch 968/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2829 - f1: 0.7219 - val_loss: 0.2820 - val_f1: 0.0641\n",
      "Epoch 969/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2827 - f1: 0.7254 - val_loss: 0.2826 - val_f1: 0.0645\n",
      "Epoch 970/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2813 - f1: 0.7250 - val_loss: 0.2827 - val_f1: 0.0642\n",
      "Epoch 971/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2807 - f1: 0.7250 - val_loss: 0.2834 - val_f1: 0.0643\n",
      "Epoch 972/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2836 - f1: 0.7203 - val_loss: 0.2818 - val_f1: 0.0641\n",
      "Epoch 973/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2839 - f1: 0.7242 - val_loss: 0.2818 - val_f1: 0.0644\n",
      "Epoch 974/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2838 - f1: 0.7235 - val_loss: 0.2816 - val_f1: 0.0641\n",
      "Epoch 975/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2819 - f1: 0.7264 - val_loss: 0.2821 - val_f1: 0.0641\n",
      "Epoch 976/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2824 - f1: 0.7245 - val_loss: 0.2810 - val_f1: 0.0642\n",
      "Epoch 977/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2813 - f1: 0.7254 - val_loss: 0.2817 - val_f1: 0.0644\n",
      "Epoch 978/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2827 - f1: 0.7223 - val_loss: 0.2826 - val_f1: 0.0641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 979/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2818 - f1: 0.7260 - val_loss: 0.2818 - val_f1: 0.0642\n",
      "Epoch 980/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2814 - f1: 0.7259 - val_loss: 0.2808 - val_f1: 0.0641\n",
      "Epoch 981/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2816 - f1: 0.7238 - val_loss: 0.2826 - val_f1: 0.0645\n",
      "Epoch 982/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2823 - f1: 0.7237 - val_loss: 0.2827 - val_f1: 0.0642\n",
      "Epoch 983/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2825 - f1: 0.7237 - val_loss: 0.2820 - val_f1: 0.0642\n",
      "Epoch 984/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2835 - f1: 0.7238 - val_loss: 0.2824 - val_f1: 0.0643\n",
      "Epoch 985/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2808 - f1: 0.7254 - val_loss: 0.2828 - val_f1: 0.0644\n",
      "Epoch 986/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2819 - f1: 0.7237 - val_loss: 0.2816 - val_f1: 0.0640\n",
      "Epoch 987/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2819 - f1: 0.7243 - val_loss: 0.2819 - val_f1: 0.0642\n",
      "Epoch 988/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2813 - f1: 0.7248 - val_loss: 0.2825 - val_f1: 0.0641\n",
      "Epoch 989/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2830 - f1: 0.7238 - val_loss: 0.2823 - val_f1: 0.0644\n",
      "Epoch 990/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2810 - f1: 0.7263 - val_loss: 0.2819 - val_f1: 0.0642\n",
      "Epoch 991/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2817 - f1: 0.7254 - val_loss: 0.2836 - val_f1: 0.0648\n",
      "Epoch 992/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2816 - f1: 0.7268 - val_loss: 0.2825 - val_f1: 0.0641\n",
      "Epoch 993/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2821 - f1: 0.7251 - val_loss: 0.2827 - val_f1: 0.0642\n",
      "Epoch 994/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2812 - f1: 0.7288 - val_loss: 0.2832 - val_f1: 0.0646\n",
      "Epoch 995/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2814 - f1: 0.7259 - val_loss: 0.2815 - val_f1: 0.0643\n",
      "Epoch 996/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2819 - f1: 0.7239 - val_loss: 0.2824 - val_f1: 0.0642\n",
      "Epoch 997/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2824 - f1: 0.7245 - val_loss: 0.2825 - val_f1: 0.0642\n",
      "Epoch 998/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2825 - f1: 0.7241 - val_loss: 0.2826 - val_f1: 0.0644\n",
      "Epoch 999/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2809 - f1: 0.7241 - val_loss: 0.2832 - val_f1: 0.0643\n",
      "Epoch 1000/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2814 - f1: 0.7270 - val_loss: 0.2834 - val_f1: 0.0643\n",
      "Epoch 1001/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2811 - f1: 0.7267 - val_loss: 0.2821 - val_f1: 0.0641\n",
      "Epoch 1002/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2821 - f1: 0.7260 - val_loss: 0.2812 - val_f1: 0.0641\n",
      "Epoch 1003/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2813 - f1: 0.7262 - val_loss: 0.2830 - val_f1: 0.0647\n",
      "Epoch 1004/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2822 - f1: 0.7267 - val_loss: 0.2821 - val_f1: 0.0643\n",
      "Epoch 1005/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2829 - f1: 0.7229 - val_loss: 0.2819 - val_f1: 0.0643\n",
      "Epoch 1006/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2827 - f1: 0.7235 - val_loss: 0.2816 - val_f1: 0.0640\n",
      "Epoch 1007/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2814 - f1: 0.7234 - val_loss: 0.2816 - val_f1: 0.0643\n",
      "Epoch 1008/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2803 - f1: 0.7250 - val_loss: 0.2838 - val_f1: 0.0648\n",
      "Epoch 1009/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2809 - f1: 0.7271 - val_loss: 0.2817 - val_f1: 0.0638\n",
      "Epoch 1010/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2804 - f1: 0.7261 - val_loss: 0.2829 - val_f1: 0.0645\n",
      "Epoch 1011/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2819 - f1: 0.7240 - val_loss: 0.2829 - val_f1: 0.0645\n",
      "Epoch 1012/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2824 - f1: 0.7234 - val_loss: 0.2813 - val_f1: 0.0640\n",
      "Epoch 1013/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2804 - f1: 0.7250 - val_loss: 0.2829 - val_f1: 0.0642\n",
      "Epoch 1014/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2806 - f1: 0.7235 - val_loss: 0.2823 - val_f1: 0.0639\n",
      "Epoch 1015/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2810 - f1: 0.7250 - val_loss: 0.2828 - val_f1: 0.0644\n",
      "Epoch 1016/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2812 - f1: 0.7265 - val_loss: 0.2818 - val_f1: 0.0638\n",
      "Epoch 1017/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2817 - f1: 0.7267 - val_loss: 0.2827 - val_f1: 0.0646\n",
      "Epoch 1018/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2811 - f1: 0.7260 - val_loss: 0.2815 - val_f1: 0.0641\n",
      "Epoch 1019/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2800 - f1: 0.7261 - val_loss: 0.2835 - val_f1: 0.0644\n",
      "Epoch 1020/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2813 - f1: 0.7238 - val_loss: 0.2830 - val_f1: 0.0643\n",
      "Epoch 1021/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2803 - f1: 0.7269 - val_loss: 0.2823 - val_f1: 0.0642\n",
      "Epoch 1022/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2803 - f1: 0.7247 - val_loss: 0.2826 - val_f1: 0.0639\n",
      "Epoch 1023/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2817 - f1: 0.7274 - val_loss: 0.2812 - val_f1: 0.0638\n",
      "Epoch 1024/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2805 - f1: 0.7288 - val_loss: 0.2825 - val_f1: 0.0645\n",
      "Epoch 1025/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2810 - f1: 0.7257 - val_loss: 0.2815 - val_f1: 0.0641\n",
      "Epoch 1026/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2807 - f1: 0.7272 - val_loss: 0.2815 - val_f1: 0.0640\n",
      "Epoch 1027/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2808 - f1: 0.7279 - val_loss: 0.2815 - val_f1: 0.0639\n",
      "Epoch 1028/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2806 - f1: 0.7282 - val_loss: 0.2813 - val_f1: 0.0639\n",
      "Epoch 1029/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2805 - f1: 0.7277 - val_loss: 0.2816 - val_f1: 0.0639\n",
      "Epoch 1030/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2816 - f1: 0.7236 - val_loss: 0.2821 - val_f1: 0.0643\n",
      "Epoch 1031/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2809 - f1: 0.7252 - val_loss: 0.2827 - val_f1: 0.0640\n",
      "Epoch 1032/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2815 - f1: 0.7253 - val_loss: 0.2830 - val_f1: 0.0642\n",
      "Epoch 1033/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2803 - f1: 0.7266 - val_loss: 0.2823 - val_f1: 0.0640\n",
      "Epoch 1034/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2806 - f1: 0.7273 - val_loss: 0.2826 - val_f1: 0.0640\n",
      "Epoch 1035/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2806 - f1: 0.7274 - val_loss: 0.2835 - val_f1: 0.0639\n",
      "Epoch 1036/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2814 - f1: 0.7252 - val_loss: 0.2831 - val_f1: 0.0647\n",
      "Epoch 1037/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2810 - f1: 0.7257 - val_loss: 0.2824 - val_f1: 0.0642\n",
      "Epoch 1038/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2811 - f1: 0.7269 - val_loss: 0.2825 - val_f1: 0.0645\n",
      "Epoch 1039/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2805 - f1: 0.7250 - val_loss: 0.2833 - val_f1: 0.0646\n",
      "Epoch 1040/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2808 - f1: 0.7250 - val_loss: 0.2823 - val_f1: 0.0641\n",
      "Epoch 1041/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2815 - f1: 0.7228 - val_loss: 0.2828 - val_f1: 0.0645\n",
      "Epoch 1042/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2799 - f1: 0.7264 - val_loss: 0.2826 - val_f1: 0.0641\n",
      "Epoch 1043/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2806 - f1: 0.7256 - val_loss: 0.2825 - val_f1: 0.0643\n",
      "Epoch 1044/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2801 - f1: 0.7282 - val_loss: 0.2820 - val_f1: 0.0638\n",
      "Epoch 1045/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2812 - f1: 0.7257 - val_loss: 0.2820 - val_f1: 0.0642\n",
      "Epoch 1046/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2809 - f1: 0.7252 - val_loss: 0.2832 - val_f1: 0.0644\n",
      "Epoch 1047/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2813 - f1: 0.7258 - val_loss: 0.2819 - val_f1: 0.0641\n",
      "Epoch 1048/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2802 - f1: 0.7263 - val_loss: 0.2818 - val_f1: 0.0640\n",
      "Epoch 1049/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2800 - f1: 0.7274 - val_loss: 0.2819 - val_f1: 0.0642\n",
      "Epoch 1050/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2810 - f1: 0.7249 - val_loss: 0.2818 - val_f1: 0.0640\n",
      "Epoch 1051/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2815 - f1: 0.7239 - val_loss: 0.2819 - val_f1: 0.0641\n",
      "Epoch 1052/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2812 - f1: 0.7242 - val_loss: 0.2829 - val_f1: 0.0642\n",
      "Epoch 1053/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2813 - f1: 0.7272 - val_loss: 0.2812 - val_f1: 0.0640\n",
      "Epoch 1054/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2811 - f1: 0.7240 - val_loss: 0.2839 - val_f1: 0.0650\n",
      "Epoch 1055/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2809 - f1: 0.7265 - val_loss: 0.2825 - val_f1: 0.0641\n",
      "Epoch 1056/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2812 - f1: 0.7257 - val_loss: 0.2829 - val_f1: 0.0643\n",
      "Epoch 1057/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2807 - f1: 0.7256 - val_loss: 0.2817 - val_f1: 0.0641\n",
      "Epoch 1058/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2802 - f1: 0.7265 - val_loss: 0.2824 - val_f1: 0.0644\n",
      "Epoch 1059/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2810 - f1: 0.7252 - val_loss: 0.2824 - val_f1: 0.0643\n",
      "Epoch 1060/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2799 - f1: 0.7287 - val_loss: 0.2822 - val_f1: 0.0640\n",
      "Epoch 1061/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2802 - f1: 0.7245 - val_loss: 0.2831 - val_f1: 0.0645\n",
      "Epoch 1062/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2799 - f1: 0.7255 - val_loss: 0.2835 - val_f1: 0.0644\n",
      "Epoch 1063/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2799 - f1: 0.7277 - val_loss: 0.2824 - val_f1: 0.0641\n",
      "Epoch 1064/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2798 - f1: 0.7264 - val_loss: 0.2828 - val_f1: 0.0644\n",
      "Epoch 1065/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2807 - f1: 0.7252 - val_loss: 0.2811 - val_f1: 0.0638\n",
      "Epoch 1066/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2803 - f1: 0.7246 - val_loss: 0.2834 - val_f1: 0.0648\n",
      "Epoch 1067/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2821 - f1: 0.7263 - val_loss: 0.2841 - val_f1: 0.0645\n",
      "Epoch 1068/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2816 - f1: 0.7259 - val_loss: 0.2832 - val_f1: 0.0645\n",
      "Epoch 1069/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2803 - f1: 0.7277 - val_loss: 0.2840 - val_f1: 0.0645\n",
      "Epoch 1070/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2810 - f1: 0.7266 - val_loss: 0.2828 - val_f1: 0.0642\n",
      "Epoch 1071/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2814 - f1: 0.7248 - val_loss: 0.2828 - val_f1: 0.0644\n",
      "Epoch 1072/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2802 - f1: 0.7262 - val_loss: 0.2828 - val_f1: 0.0641\n",
      "Epoch 1073/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2811 - f1: 0.7243 - val_loss: 0.2825 - val_f1: 0.0645\n",
      "Epoch 1074/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2795 - f1: 0.7275 - val_loss: 0.2829 - val_f1: 0.0641\n",
      "Epoch 1075/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2810 - f1: 0.7248 - val_loss: 0.2827 - val_f1: 0.0642\n",
      "Epoch 1076/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2806 - f1: 0.7268 - val_loss: 0.2824 - val_f1: 0.0643\n",
      "Epoch 1077/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2802 - f1: 0.7250 - val_loss: 0.2827 - val_f1: 0.0640\n",
      "Epoch 1078/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2790 - f1: 0.7292 - val_loss: 0.2834 - val_f1: 0.0645\n",
      "Epoch 1079/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2803 - f1: 0.7259 - val_loss: 0.2818 - val_f1: 0.0639\n",
      "Epoch 1080/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2802 - f1: 0.7283 - val_loss: 0.2835 - val_f1: 0.0642\n",
      "Epoch 1081/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2809 - f1: 0.7266 - val_loss: 0.2823 - val_f1: 0.0641\n",
      "Epoch 1082/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2803 - f1: 0.7261 - val_loss: 0.2825 - val_f1: 0.0641\n",
      "Epoch 1083/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2798 - f1: 0.7264 - val_loss: 0.2825 - val_f1: 0.0643\n",
      "Epoch 1084/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2803 - f1: 0.7278 - val_loss: 0.2824 - val_f1: 0.0638\n",
      "Epoch 1085/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2803 - f1: 0.7268 - val_loss: 0.2819 - val_f1: 0.0638\n",
      "Epoch 1086/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2807 - f1: 0.7253 - val_loss: 0.2823 - val_f1: 0.0640\n",
      "Epoch 1087/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2787 - f1: 0.7271 - val_loss: 0.2827 - val_f1: 0.0645\n",
      "Epoch 1088/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2796 - f1: 0.7287 - val_loss: 0.2823 - val_f1: 0.0640\n",
      "Epoch 1089/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2796 - f1: 0.7256 - val_loss: 0.2825 - val_f1: 0.0639\n",
      "Epoch 1090/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2802 - f1: 0.7276 - val_loss: 0.2828 - val_f1: 0.0644\n",
      "Epoch 1091/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2796 - f1: 0.7282 - val_loss: 0.2824 - val_f1: 0.0639\n",
      "Epoch 1092/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2806 - f1: 0.7276 - val_loss: 0.2829 - val_f1: 0.0644\n",
      "Epoch 1093/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2807 - f1: 0.7249 - val_loss: 0.2822 - val_f1: 0.0641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1094/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2791 - f1: 0.7278 - val_loss: 0.2823 - val_f1: 0.0638\n",
      "Epoch 1095/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2806 - f1: 0.7277 - val_loss: 0.2823 - val_f1: 0.0643\n",
      "Epoch 1096/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2825 - f1: 0.7227 - val_loss: 0.2813 - val_f1: 0.0640\n",
      "Epoch 1097/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2798 - f1: 0.7272 - val_loss: 0.2830 - val_f1: 0.0644\n",
      "Epoch 1098/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2814 - f1: 0.7254 - val_loss: 0.2830 - val_f1: 0.0644\n",
      "Epoch 1099/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2808 - f1: 0.7248 - val_loss: 0.2833 - val_f1: 0.0648\n",
      "Epoch 1100/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2801 - f1: 0.7265 - val_loss: 0.2836 - val_f1: 0.0648\n",
      "Epoch 1101/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2791 - f1: 0.7277 - val_loss: 0.2818 - val_f1: 0.0642\n",
      "Epoch 1102/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2804 - f1: 0.7259 - val_loss: 0.2825 - val_f1: 0.0643\n",
      "Epoch 1103/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2796 - f1: 0.7275 - val_loss: 0.2833 - val_f1: 0.0648\n",
      "Epoch 1104/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2790 - f1: 0.7279 - val_loss: 0.2830 - val_f1: 0.0644\n",
      "Epoch 1105/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2800 - f1: 0.7251 - val_loss: 0.2831 - val_f1: 0.0644\n",
      "Epoch 1106/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2794 - f1: 0.7271 - val_loss: 0.2817 - val_f1: 0.0635\n",
      "Epoch 1107/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2805 - f1: 0.7293 - val_loss: 0.2812 - val_f1: 0.0636\n",
      "Epoch 1108/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2799 - f1: 0.7264 - val_loss: 0.2826 - val_f1: 0.0642\n",
      "Epoch 1109/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2792 - f1: 0.7293 - val_loss: 0.2816 - val_f1: 0.0639\n",
      "Epoch 1110/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2811 - f1: 0.7249 - val_loss: 0.2826 - val_f1: 0.0643\n",
      "Epoch 1111/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2788 - f1: 0.7299 - val_loss: 0.2835 - val_f1: 0.0647\n",
      "Epoch 1112/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2795 - f1: 0.7272 - val_loss: 0.2823 - val_f1: 0.0642\n",
      "Epoch 1113/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2795 - f1: 0.7271 - val_loss: 0.2830 - val_f1: 0.0641\n",
      "Epoch 1114/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2798 - f1: 0.7258 - val_loss: 0.2824 - val_f1: 0.0639\n",
      "Epoch 1115/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2802 - f1: 0.7287 - val_loss: 0.2816 - val_f1: 0.0638\n",
      "Epoch 1116/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2797 - f1: 0.7264 - val_loss: 0.2826 - val_f1: 0.0642\n",
      "Epoch 1117/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2791 - f1: 0.7280 - val_loss: 0.2831 - val_f1: 0.0641\n",
      "Epoch 1118/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2792 - f1: 0.7269 - val_loss: 0.2833 - val_f1: 0.0643\n",
      "Epoch 1119/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2797 - f1: 0.7289 - val_loss: 0.2818 - val_f1: 0.0638\n",
      "Epoch 1120/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2792 - f1: 0.7259 - val_loss: 0.2836 - val_f1: 0.0642\n",
      "Epoch 1121/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2805 - f1: 0.7266 - val_loss: 0.2827 - val_f1: 0.0640\n",
      "Epoch 1122/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2798 - f1: 0.7299 - val_loss: 0.2822 - val_f1: 0.0641\n",
      "Epoch 1123/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2804 - f1: 0.7272 - val_loss: 0.2824 - val_f1: 0.0639\n",
      "Epoch 1124/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2797 - f1: 0.7270 - val_loss: 0.2824 - val_f1: 0.0639\n",
      "Epoch 1125/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2793 - f1: 0.7287 - val_loss: 0.2825 - val_f1: 0.0639\n",
      "Epoch 1126/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2792 - f1: 0.7262 - val_loss: 0.2828 - val_f1: 0.0641\n",
      "Epoch 1127/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2808 - f1: 0.7242 - val_loss: 0.2828 - val_f1: 0.0645\n",
      "Epoch 1128/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2805 - f1: 0.7281 - val_loss: 0.2827 - val_f1: 0.0642\n",
      "Epoch 1129/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2795 - f1: 0.7287 - val_loss: 0.2829 - val_f1: 0.0638\n",
      "Epoch 1130/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2789 - f1: 0.7283 - val_loss: 0.2835 - val_f1: 0.0645\n",
      "Epoch 1131/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2790 - f1: 0.7263 - val_loss: 0.2829 - val_f1: 0.0642\n",
      "Epoch 1132/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2793 - f1: 0.7285 - val_loss: 0.2835 - val_f1: 0.0642\n",
      "Epoch 1133/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2796 - f1: 0.7277 - val_loss: 0.2831 - val_f1: 0.0642\n",
      "Epoch 1134/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2789 - f1: 0.7287 - val_loss: 0.2825 - val_f1: 0.0640\n",
      "Epoch 1135/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2798 - f1: 0.7288 - val_loss: 0.2834 - val_f1: 0.0644\n",
      "Epoch 1136/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2790 - f1: 0.7296 - val_loss: 0.2828 - val_f1: 0.0642\n",
      "Epoch 1137/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2794 - f1: 0.7280 - val_loss: 0.2825 - val_f1: 0.0642\n",
      "Epoch 1138/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2792 - f1: 0.7286 - val_loss: 0.2824 - val_f1: 0.0642\n",
      "Epoch 1139/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2811 - f1: 0.7268 - val_loss: 0.2814 - val_f1: 0.0639\n",
      "Epoch 1140/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2797 - f1: 0.7276 - val_loss: 0.2832 - val_f1: 0.0645\n",
      "Epoch 1141/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2795 - f1: 0.7292 - val_loss: 0.2827 - val_f1: 0.0644\n",
      "Epoch 1142/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2792 - f1: 0.7281 - val_loss: 0.2832 - val_f1: 0.0642\n",
      "Epoch 1143/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2794 - f1: 0.7267 - val_loss: 0.2829 - val_f1: 0.0639\n",
      "Epoch 1144/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2807 - f1: 0.7270 - val_loss: 0.2816 - val_f1: 0.0637\n",
      "Epoch 1145/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2803 - f1: 0.7253 - val_loss: 0.2825 - val_f1: 0.0641\n",
      "Epoch 1146/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2796 - f1: 0.7273 - val_loss: 0.2810 - val_f1: 0.0634\n",
      "Epoch 1147/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2798 - f1: 0.7272 - val_loss: 0.2830 - val_f1: 0.0644\n",
      "Epoch 1148/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2788 - f1: 0.7287 - val_loss: 0.2831 - val_f1: 0.0644\n",
      "Epoch 1149/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2789 - f1: 0.7288 - val_loss: 0.2830 - val_f1: 0.0641\n",
      "Epoch 1150/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2793 - f1: 0.7281 - val_loss: 0.2824 - val_f1: 0.0643\n",
      "Epoch 1151/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2785 - f1: 0.7302 - val_loss: 0.2822 - val_f1: 0.0639\n",
      "Epoch 1152/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2783 - f1: 0.7302 - val_loss: 0.2838 - val_f1: 0.0646\n",
      "Epoch 1153/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2789 - f1: 0.7293 - val_loss: 0.2829 - val_f1: 0.0642\n",
      "Epoch 1154/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2787 - f1: 0.7314 - val_loss: 0.2820 - val_f1: 0.0638\n",
      "Epoch 1155/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2782 - f1: 0.7296 - val_loss: 0.2823 - val_f1: 0.0639\n",
      "Epoch 1156/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2791 - f1: 0.7280 - val_loss: 0.2826 - val_f1: 0.0641\n",
      "Epoch 1157/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2792 - f1: 0.7274 - val_loss: 0.2832 - val_f1: 0.0645\n",
      "Epoch 1158/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2792 - f1: 0.7280 - val_loss: 0.2821 - val_f1: 0.0638\n",
      "Epoch 1159/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2793 - f1: 0.7284 - val_loss: 0.2820 - val_f1: 0.0639\n",
      "Epoch 1160/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2791 - f1: 0.7283 - val_loss: 0.2825 - val_f1: 0.0643\n",
      "Epoch 1161/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2785 - f1: 0.7286 - val_loss: 0.2834 - val_f1: 0.0641\n",
      "Epoch 1162/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2800 - f1: 0.7257 - val_loss: 0.2820 - val_f1: 0.0637\n",
      "Epoch 1163/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2786 - f1: 0.7269 - val_loss: 0.2833 - val_f1: 0.0644\n",
      "Epoch 1164/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2800 - f1: 0.7264 - val_loss: 0.2827 - val_f1: 0.0641\n",
      "Epoch 1165/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2788 - f1: 0.7264 - val_loss: 0.2833 - val_f1: 0.0643\n",
      "Epoch 1166/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2789 - f1: 0.7280 - val_loss: 0.2828 - val_f1: 0.0639\n",
      "Epoch 1167/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2796 - f1: 0.7262 - val_loss: 0.2833 - val_f1: 0.0644\n",
      "Epoch 1168/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2790 - f1: 0.7311 - val_loss: 0.2825 - val_f1: 0.0640\n",
      "Epoch 1169/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2797 - f1: 0.7268 - val_loss: 0.2833 - val_f1: 0.0644\n",
      "Epoch 1170/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2791 - f1: 0.7275 - val_loss: 0.2823 - val_f1: 0.0642\n",
      "Epoch 1171/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2794 - f1: 0.7279 - val_loss: 0.2827 - val_f1: 0.0641\n",
      "Epoch 1172/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2806 - f1: 0.7266 - val_loss: 0.2814 - val_f1: 0.0635\n",
      "Epoch 1173/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2793 - f1: 0.7275 - val_loss: 0.2821 - val_f1: 0.0638\n",
      "Epoch 1174/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2789 - f1: 0.7295 - val_loss: 0.2821 - val_f1: 0.0640\n",
      "Epoch 1175/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2781 - f1: 0.7298 - val_loss: 0.2831 - val_f1: 0.0642\n",
      "Epoch 1176/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2779 - f1: 0.7312 - val_loss: 0.2828 - val_f1: 0.0638\n",
      "Epoch 1177/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2774 - f1: 0.7297 - val_loss: 0.2831 - val_f1: 0.0639\n",
      "Epoch 1178/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2785 - f1: 0.7266 - val_loss: 0.2819 - val_f1: 0.0638\n",
      "Epoch 1179/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2787 - f1: 0.7280 - val_loss: 0.2830 - val_f1: 0.0641\n",
      "Epoch 1180/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2798 - f1: 0.7280 - val_loss: 0.2820 - val_f1: 0.0636\n",
      "Epoch 1181/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2804 - f1: 0.7257 - val_loss: 0.2824 - val_f1: 0.0641\n",
      "Epoch 1182/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2798 - f1: 0.7271 - val_loss: 0.2818 - val_f1: 0.0640\n",
      "Epoch 1183/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2783 - f1: 0.7282 - val_loss: 0.2833 - val_f1: 0.0641\n",
      "Epoch 1184/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2788 - f1: 0.7292 - val_loss: 0.2822 - val_f1: 0.0642\n",
      "Epoch 1185/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2798 - f1: 0.7267 - val_loss: 0.2834 - val_f1: 0.0645\n",
      "Epoch 1186/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2800 - f1: 0.7260 - val_loss: 0.2832 - val_f1: 0.0643\n",
      "Epoch 1187/2000\n",
      "168135/168135 [==============================] - 6s 34us/step - loss: 0.2797 - f1: 0.7262 - val_loss: 0.2831 - val_f1: 0.0644\n",
      "Epoch 1188/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2781 - f1: 0.7278 - val_loss: 0.2831 - val_f1: 0.0643\n",
      "Epoch 1189/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2788 - f1: 0.7296 - val_loss: 0.2823 - val_f1: 0.0640\n",
      "Epoch 1190/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2780 - f1: 0.7285 - val_loss: 0.2833 - val_f1: 0.0642\n",
      "Epoch 1191/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2780 - f1: 0.7275 - val_loss: 0.2836 - val_f1: 0.0645\n",
      "Epoch 1192/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2788 - f1: 0.7280 - val_loss: 0.2833 - val_f1: 0.0642\n",
      "Epoch 1193/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2781 - f1: 0.7274 - val_loss: 0.2829 - val_f1: 0.0640\n",
      "Epoch 1194/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2779 - f1: 0.7300 - val_loss: 0.2842 - val_f1: 0.0646\n",
      "Epoch 1195/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2785 - f1: 0.7276 - val_loss: 0.2824 - val_f1: 0.0641\n",
      "Epoch 1196/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2788 - f1: 0.7294 - val_loss: 0.2827 - val_f1: 0.0641\n",
      "Epoch 1197/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2775 - f1: 0.7275 - val_loss: 0.2840 - val_f1: 0.0647\n",
      "Epoch 1198/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2792 - f1: 0.7315 - val_loss: 0.2810 - val_f1: 0.0634\n",
      "Epoch 1199/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2801 - f1: 0.7271 - val_loss: 0.2823 - val_f1: 0.0642\n",
      "Epoch 1200/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2799 - f1: 0.7282 - val_loss: 0.2820 - val_f1: 0.0639\n",
      "Epoch 1201/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2790 - f1: 0.7300 - val_loss: 0.2821 - val_f1: 0.0637\n",
      "Epoch 1202/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2775 - f1: 0.7292 - val_loss: 0.2821 - val_f1: 0.0638\n",
      "Epoch 1203/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2783 - f1: 0.7295 - val_loss: 0.2826 - val_f1: 0.0640\n",
      "Epoch 1204/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2790 - f1: 0.7276 - val_loss: 0.2822 - val_f1: 0.0637\n",
      "Epoch 1205/2000\n",
      "168135/168135 [==============================] - 6s 34us/step - loss: 0.2792 - f1: 0.7300 - val_loss: 0.2808 - val_f1: 0.0635\n",
      "Epoch 1206/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2794 - f1: 0.7264 - val_loss: 0.2831 - val_f1: 0.0640\n",
      "Epoch 1207/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2778 - f1: 0.7307 - val_loss: 0.2823 - val_f1: 0.0638\n",
      "Epoch 1208/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2775 - f1: 0.7325 - val_loss: 0.2817 - val_f1: 0.0634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1209/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2786 - f1: 0.7286 - val_loss: 0.2827 - val_f1: 0.0641\n",
      "Epoch 1210/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2798 - f1: 0.7295 - val_loss: 0.2825 - val_f1: 0.0641\n",
      "Epoch 1211/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2792 - f1: 0.7293 - val_loss: 0.2825 - val_f1: 0.0638\n",
      "Epoch 1212/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2790 - f1: 0.7282 - val_loss: 0.2826 - val_f1: 0.0639\n",
      "Epoch 1213/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2794 - f1: 0.7290 - val_loss: 0.2810 - val_f1: 0.0637\n",
      "Epoch 1214/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2782 - f1: 0.7314 - val_loss: 0.2824 - val_f1: 0.0642\n",
      "Epoch 1215/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2778 - f1: 0.7281 - val_loss: 0.2815 - val_f1: 0.0637\n",
      "Epoch 1216/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2790 - f1: 0.7289 - val_loss: 0.2827 - val_f1: 0.0641\n",
      "Epoch 1217/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2783 - f1: 0.7285 - val_loss: 0.2839 - val_f1: 0.0642\n",
      "Epoch 1218/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2786 - f1: 0.7304 - val_loss: 0.2828 - val_f1: 0.0640\n",
      "Epoch 1219/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2787 - f1: 0.7279 - val_loss: 0.2825 - val_f1: 0.0640\n",
      "Epoch 1220/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2794 - f1: 0.7292 - val_loss: 0.2825 - val_f1: 0.0638\n",
      "Epoch 1221/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2782 - f1: 0.7292 - val_loss: 0.2834 - val_f1: 0.0640\n",
      "Epoch 1222/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2799 - f1: 0.7271 - val_loss: 0.2822 - val_f1: 0.0638\n",
      "Epoch 1223/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2780 - f1: 0.7298 - val_loss: 0.2842 - val_f1: 0.0645\n",
      "Epoch 1224/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2808 - f1: 0.7262 - val_loss: 0.2826 - val_f1: 0.0641\n",
      "Epoch 1225/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2777 - f1: 0.7285 - val_loss: 0.2833 - val_f1: 0.0642\n",
      "Epoch 1226/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2778 - f1: 0.7295 - val_loss: 0.2833 - val_f1: 0.0641\n",
      "Epoch 1227/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2787 - f1: 0.7293 - val_loss: 0.2825 - val_f1: 0.0639\n",
      "Epoch 1228/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2787 - f1: 0.7269 - val_loss: 0.2826 - val_f1: 0.0639\n",
      "Epoch 1229/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2782 - f1: 0.7287 - val_loss: 0.2833 - val_f1: 0.0641\n",
      "Epoch 1230/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2774 - f1: 0.7317 - val_loss: 0.2828 - val_f1: 0.0641\n",
      "Epoch 1231/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2771 - f1: 0.7314 - val_loss: 0.2834 - val_f1: 0.0641\n",
      "Epoch 1232/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2786 - f1: 0.7291 - val_loss: 0.2821 - val_f1: 0.0637\n",
      "Epoch 1233/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2789 - f1: 0.7285 - val_loss: 0.2834 - val_f1: 0.0643\n",
      "Epoch 1234/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2774 - f1: 0.7293 - val_loss: 0.2828 - val_f1: 0.0640\n",
      "Epoch 1235/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2796 - f1: 0.7298 - val_loss: 0.2827 - val_f1: 0.0640\n",
      "Epoch 1236/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2783 - f1: 0.7276 - val_loss: 0.2833 - val_f1: 0.0641\n",
      "Epoch 1237/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2766 - f1: 0.7313 - val_loss: 0.2832 - val_f1: 0.0642\n",
      "Epoch 1238/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2781 - f1: 0.7289 - val_loss: 0.2826 - val_f1: 0.0640\n",
      "Epoch 1239/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2786 - f1: 0.7269 - val_loss: 0.2822 - val_f1: 0.0638\n",
      "Epoch 1240/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2788 - f1: 0.7283 - val_loss: 0.2835 - val_f1: 0.0643\n",
      "Epoch 1241/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2776 - f1: 0.7301 - val_loss: 0.2830 - val_f1: 0.0642\n",
      "Epoch 1242/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2773 - f1: 0.7297 - val_loss: 0.2825 - val_f1: 0.0636\n",
      "Epoch 1243/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2773 - f1: 0.7298 - val_loss: 0.2830 - val_f1: 0.0641\n",
      "Epoch 1244/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2775 - f1: 0.7310 - val_loss: 0.2816 - val_f1: 0.0634\n",
      "Epoch 1245/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2769 - f1: 0.7291 - val_loss: 0.2836 - val_f1: 0.0642\n",
      "Epoch 1246/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2764 - f1: 0.7332 - val_loss: 0.2835 - val_f1: 0.0640\n",
      "Epoch 1247/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2774 - f1: 0.7297 - val_loss: 0.2832 - val_f1: 0.0640\n",
      "Epoch 1248/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2778 - f1: 0.7280 - val_loss: 0.2835 - val_f1: 0.0641\n",
      "Epoch 1249/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2781 - f1: 0.7300 - val_loss: 0.2830 - val_f1: 0.0638\n",
      "Epoch 1250/2000\n",
      "168135/168135 [==============================] - 6s 34us/step - loss: 0.2763 - f1: 0.7296 - val_loss: 0.2825 - val_f1: 0.0636\n",
      "Epoch 1251/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2782 - f1: 0.7300 - val_loss: 0.2829 - val_f1: 0.0640\n",
      "Epoch 1252/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2773 - f1: 0.7306 - val_loss: 0.2836 - val_f1: 0.0643\n",
      "Epoch 1253/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2768 - f1: 0.7299 - val_loss: 0.2827 - val_f1: 0.0640\n",
      "Epoch 1254/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2785 - f1: 0.7304 - val_loss: 0.2832 - val_f1: 0.0640\n",
      "Epoch 1255/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2790 - f1: 0.7277 - val_loss: 0.2830 - val_f1: 0.0639\n",
      "Epoch 1256/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2774 - f1: 0.7280 - val_loss: 0.2821 - val_f1: 0.0639\n",
      "Epoch 1257/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2788 - f1: 0.7261 - val_loss: 0.2839 - val_f1: 0.0643\n",
      "Epoch 1258/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2781 - f1: 0.7297 - val_loss: 0.2816 - val_f1: 0.0638\n",
      "Epoch 1259/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2784 - f1: 0.7283 - val_loss: 0.2830 - val_f1: 0.0640\n",
      "Epoch 1260/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2763 - f1: 0.7308 - val_loss: 0.2836 - val_f1: 0.0642\n",
      "Epoch 1261/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2774 - f1: 0.7295 - val_loss: 0.2827 - val_f1: 0.0640\n",
      "Epoch 1262/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2775 - f1: 0.7310 - val_loss: 0.2836 - val_f1: 0.0641\n",
      "Epoch 1263/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2786 - f1: 0.7282 - val_loss: 0.2823 - val_f1: 0.0638\n",
      "Epoch 1264/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2786 - f1: 0.7277 - val_loss: 0.2828 - val_f1: 0.0638\n",
      "Epoch 1265/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2783 - f1: 0.7270 - val_loss: 0.2830 - val_f1: 0.0641\n",
      "Epoch 1266/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2789 - f1: 0.7303 - val_loss: 0.2826 - val_f1: 0.0637\n",
      "Epoch 1267/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2775 - f1: 0.7318 - val_loss: 0.2830 - val_f1: 0.0641\n",
      "Epoch 1268/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2779 - f1: 0.7274 - val_loss: 0.2832 - val_f1: 0.0641\n",
      "Epoch 1269/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2777 - f1: 0.7299 - val_loss: 0.2835 - val_f1: 0.0639\n",
      "Epoch 1270/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2772 - f1: 0.7302 - val_loss: 0.2842 - val_f1: 0.0643\n",
      "Epoch 1271/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2784 - f1: 0.7282 - val_loss: 0.2837 - val_f1: 0.0643\n",
      "Epoch 1272/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2765 - f1: 0.7318 - val_loss: 0.2825 - val_f1: 0.0635\n",
      "Epoch 1273/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2782 - f1: 0.7287 - val_loss: 0.2822 - val_f1: 0.0640\n",
      "Epoch 1274/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2783 - f1: 0.7287 - val_loss: 0.2819 - val_f1: 0.0637\n",
      "Epoch 1275/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2766 - f1: 0.7321 - val_loss: 0.2826 - val_f1: 0.0639\n",
      "Epoch 1276/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2784 - f1: 0.7284 - val_loss: 0.2827 - val_f1: 0.0636\n",
      "Epoch 1277/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2774 - f1: 0.7288 - val_loss: 0.2833 - val_f1: 0.0643\n",
      "Epoch 1278/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2785 - f1: 0.7301 - val_loss: 0.2836 - val_f1: 0.0642\n",
      "Epoch 1279/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2765 - f1: 0.7299 - val_loss: 0.2838 - val_f1: 0.0644\n",
      "Epoch 1280/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2765 - f1: 0.7317 - val_loss: 0.2829 - val_f1: 0.0638\n",
      "Epoch 1281/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2773 - f1: 0.7307 - val_loss: 0.2829 - val_f1: 0.0637\n",
      "Epoch 1282/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2780 - f1: 0.7264 - val_loss: 0.2833 - val_f1: 0.0641\n",
      "Epoch 1283/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2777 - f1: 0.7304 - val_loss: 0.2833 - val_f1: 0.0643\n",
      "Epoch 1284/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2781 - f1: 0.7296 - val_loss: 0.2830 - val_f1: 0.0638\n",
      "Epoch 1285/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2772 - f1: 0.7322 - val_loss: 0.2827 - val_f1: 0.0637\n",
      "Epoch 1286/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2790 - f1: 0.7262 - val_loss: 0.2824 - val_f1: 0.0638\n",
      "Epoch 1287/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2778 - f1: 0.7296 - val_loss: 0.2835 - val_f1: 0.0644\n",
      "Epoch 1288/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2773 - f1: 0.7292 - val_loss: 0.2825 - val_f1: 0.0638\n",
      "Epoch 1289/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2785 - f1: 0.7307 - val_loss: 0.2823 - val_f1: 0.0638\n",
      "Epoch 1290/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2791 - f1: 0.7284 - val_loss: 0.2821 - val_f1: 0.0637\n",
      "Epoch 1291/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2783 - f1: 0.7287 - val_loss: 0.2827 - val_f1: 0.0639\n",
      "Epoch 1292/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2784 - f1: 0.7278 - val_loss: 0.2828 - val_f1: 0.0638\n",
      "Epoch 1293/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2775 - f1: 0.7302 - val_loss: 0.2827 - val_f1: 0.0638\n",
      "Epoch 1294/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2772 - f1: 0.7298 - val_loss: 0.2836 - val_f1: 0.0640\n",
      "Epoch 1295/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2777 - f1: 0.7296 - val_loss: 0.2833 - val_f1: 0.0637\n",
      "Epoch 1296/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2779 - f1: 0.7299 - val_loss: 0.2835 - val_f1: 0.0641\n",
      "Epoch 1297/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2774 - f1: 0.7274 - val_loss: 0.2837 - val_f1: 0.0643\n",
      "Epoch 1298/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2771 - f1: 0.7296 - val_loss: 0.2832 - val_f1: 0.0640\n",
      "Epoch 1299/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2766 - f1: 0.7306 - val_loss: 0.2834 - val_f1: 0.0640\n",
      "Epoch 1300/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2788 - f1: 0.7288 - val_loss: 0.2842 - val_f1: 0.0646\n",
      "Epoch 1301/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2801 - f1: 0.7282 - val_loss: 0.2824 - val_f1: 0.0640\n",
      "Epoch 1302/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2765 - f1: 0.7288 - val_loss: 0.2838 - val_f1: 0.0645\n",
      "Epoch 1303/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2767 - f1: 0.7311 - val_loss: 0.2824 - val_f1: 0.0636\n",
      "Epoch 1304/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2768 - f1: 0.7288 - val_loss: 0.2823 - val_f1: 0.0636\n",
      "Epoch 1305/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2776 - f1: 0.7306 - val_loss: 0.2835 - val_f1: 0.0642\n",
      "Epoch 1306/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2788 - f1: 0.7285 - val_loss: 0.2821 - val_f1: 0.0638\n",
      "Epoch 1307/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2782 - f1: 0.7306 - val_loss: 0.2827 - val_f1: 0.0640\n",
      "Epoch 1308/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2759 - f1: 0.7346 - val_loss: 0.2832 - val_f1: 0.0639\n",
      "Epoch 1309/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2773 - f1: 0.7312 - val_loss: 0.2833 - val_f1: 0.0644\n",
      "Epoch 1310/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2759 - f1: 0.7337 - val_loss: 0.2836 - val_f1: 0.0644\n",
      "Epoch 1311/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2767 - f1: 0.7310 - val_loss: 0.2832 - val_f1: 0.0641\n",
      "Epoch 1312/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2778 - f1: 0.7306 - val_loss: 0.2828 - val_f1: 0.0639\n",
      "Epoch 1313/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2770 - f1: 0.7333 - val_loss: 0.2823 - val_f1: 0.0638\n",
      "Epoch 1314/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2765 - f1: 0.7315 - val_loss: 0.2821 - val_f1: 0.0638\n",
      "Epoch 1315/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2777 - f1: 0.7310 - val_loss: 0.2821 - val_f1: 0.0638\n",
      "Epoch 1316/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2765 - f1: 0.7294 - val_loss: 0.2833 - val_f1: 0.0643\n",
      "Epoch 1317/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2758 - f1: 0.7342 - val_loss: 0.2839 - val_f1: 0.0644\n",
      "Epoch 1318/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2777 - f1: 0.7285 - val_loss: 0.2830 - val_f1: 0.0641\n",
      "Epoch 1319/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2780 - f1: 0.7300 - val_loss: 0.2829 - val_f1: 0.0639\n",
      "Epoch 1320/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2764 - f1: 0.7316 - val_loss: 0.2827 - val_f1: 0.0638\n",
      "Epoch 1321/2000\n",
      "168135/168135 [==============================] - 7s 40us/step - loss: 0.2767 - f1: 0.7308 - val_loss: 0.2815 - val_f1: 0.0634\n",
      "Epoch 1322/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2775 - f1: 0.7301 - val_loss: 0.2828 - val_f1: 0.0638\n",
      "Epoch 1323/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2782 - f1: 0.7286 - val_loss: 0.2824 - val_f1: 0.0638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1324/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2762 - f1: 0.7339 - val_loss: 0.2824 - val_f1: 0.0633\n",
      "Epoch 1325/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2782 - f1: 0.7284 - val_loss: 0.2816 - val_f1: 0.0636\n",
      "Epoch 1326/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2772 - f1: 0.7301 - val_loss: 0.2831 - val_f1: 0.0641\n",
      "Epoch 1327/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2767 - f1: 0.7316 - val_loss: 0.2832 - val_f1: 0.0641\n",
      "Epoch 1328/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2766 - f1: 0.7309 - val_loss: 0.2829 - val_f1: 0.0639\n",
      "Epoch 1329/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2767 - f1: 0.7309 - val_loss: 0.2833 - val_f1: 0.0640\n",
      "Epoch 1330/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2789 - f1: 0.7299 - val_loss: 0.2826 - val_f1: 0.0640\n",
      "Epoch 1331/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2771 - f1: 0.7302 - val_loss: 0.2827 - val_f1: 0.0641\n",
      "Epoch 1332/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2769 - f1: 0.7292 - val_loss: 0.2833 - val_f1: 0.0640\n",
      "Epoch 1333/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2769 - f1: 0.7308 - val_loss: 0.2833 - val_f1: 0.0641\n",
      "Epoch 1334/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2784 - f1: 0.7310 - val_loss: 0.2826 - val_f1: 0.0637\n",
      "Epoch 1335/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2773 - f1: 0.7301 - val_loss: 0.2824 - val_f1: 0.0637\n",
      "Epoch 1336/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2769 - f1: 0.7317 - val_loss: 0.2839 - val_f1: 0.0643\n",
      "Epoch 1337/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2761 - f1: 0.7317 - val_loss: 0.2823 - val_f1: 0.0637\n",
      "Epoch 1338/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2775 - f1: 0.7287 - val_loss: 0.2826 - val_f1: 0.0639\n",
      "Epoch 1339/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2776 - f1: 0.7296 - val_loss: 0.2818 - val_f1: 0.0635\n",
      "Epoch 1340/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2762 - f1: 0.7305 - val_loss: 0.2832 - val_f1: 0.0641\n",
      "Epoch 1341/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2768 - f1: 0.7319 - val_loss: 0.2832 - val_f1: 0.0641\n",
      "Epoch 1342/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2768 - f1: 0.7320 - val_loss: 0.2833 - val_f1: 0.0641\n",
      "Epoch 1343/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2761 - f1: 0.7311 - val_loss: 0.2828 - val_f1: 0.0637\n",
      "Epoch 1344/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2777 - f1: 0.7285 - val_loss: 0.2838 - val_f1: 0.0647\n",
      "Epoch 1345/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2759 - f1: 0.7323 - val_loss: 0.2831 - val_f1: 0.0638\n",
      "Epoch 1346/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2763 - f1: 0.7328 - val_loss: 0.2824 - val_f1: 0.0634\n",
      "Epoch 1347/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2764 - f1: 0.7339 - val_loss: 0.2838 - val_f1: 0.0640\n",
      "Epoch 1348/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2767 - f1: 0.7333 - val_loss: 0.2831 - val_f1: 0.0639\n",
      "Epoch 1349/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2774 - f1: 0.7336 - val_loss: 0.2832 - val_f1: 0.0642\n",
      "Epoch 1350/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2764 - f1: 0.7310 - val_loss: 0.2832 - val_f1: 0.0642\n",
      "Epoch 1351/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2758 - f1: 0.7345 - val_loss: 0.2836 - val_f1: 0.0645\n",
      "Epoch 1352/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2772 - f1: 0.7330 - val_loss: 0.2825 - val_f1: 0.0637\n",
      "Epoch 1353/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2781 - f1: 0.7278 - val_loss: 0.2817 - val_f1: 0.0635\n",
      "Epoch 1354/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2767 - f1: 0.7309 - val_loss: 0.2832 - val_f1: 0.0639\n",
      "Epoch 1355/2000\n",
      "168135/168135 [==============================] - 6s 39us/step - loss: 0.2750 - f1: 0.7344 - val_loss: 0.2832 - val_f1: 0.0640\n",
      "Epoch 1356/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2781 - f1: 0.7281 - val_loss: 0.2828 - val_f1: 0.0639\n",
      "Epoch 1357/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2761 - f1: 0.7300 - val_loss: 0.2830 - val_f1: 0.0639\n",
      "Epoch 1358/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2761 - f1: 0.7323 - val_loss: 0.2830 - val_f1: 0.0640\n",
      "Epoch 1359/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2769 - f1: 0.7302 - val_loss: 0.2840 - val_f1: 0.0641\n",
      "Epoch 1360/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2772 - f1: 0.7298 - val_loss: 0.2835 - val_f1: 0.0643\n",
      "Epoch 1361/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2768 - f1: 0.7316 - val_loss: 0.2826 - val_f1: 0.0637\n",
      "Epoch 1362/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2757 - f1: 0.7333 - val_loss: 0.2828 - val_f1: 0.0636\n",
      "Epoch 1363/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2755 - f1: 0.7326 - val_loss: 0.2843 - val_f1: 0.0642\n",
      "Epoch 1364/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2773 - f1: 0.7318 - val_loss: 0.2831 - val_f1: 0.0637\n",
      "Epoch 1365/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2761 - f1: 0.7311 - val_loss: 0.2836 - val_f1: 0.0641\n",
      "Epoch 1366/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2767 - f1: 0.7315 - val_loss: 0.2831 - val_f1: 0.0639\n",
      "Epoch 1367/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2770 - f1: 0.7307 - val_loss: 0.2825 - val_f1: 0.0638\n",
      "Epoch 1368/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2760 - f1: 0.7336 - val_loss: 0.2823 - val_f1: 0.0637\n",
      "Epoch 1369/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2769 - f1: 0.7303 - val_loss: 0.2836 - val_f1: 0.0641\n",
      "Epoch 1370/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2767 - f1: 0.7302 - val_loss: 0.2829 - val_f1: 0.0639\n",
      "Epoch 1371/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2770 - f1: 0.7297 - val_loss: 0.2828 - val_f1: 0.0642\n",
      "Epoch 1372/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2768 - f1: 0.7300 - val_loss: 0.2839 - val_f1: 0.0641\n",
      "Epoch 1373/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2757 - f1: 0.7326 - val_loss: 0.2841 - val_f1: 0.0643\n",
      "Epoch 1374/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2781 - f1: 0.7294 - val_loss: 0.2823 - val_f1: 0.0638\n",
      "Epoch 1375/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2761 - f1: 0.7305 - val_loss: 0.2844 - val_f1: 0.0643\n",
      "Epoch 1376/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2766 - f1: 0.7297 - val_loss: 0.2832 - val_f1: 0.0637\n",
      "Epoch 1377/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2767 - f1: 0.7327 - val_loss: 0.2825 - val_f1: 0.0635\n",
      "Epoch 1378/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2772 - f1: 0.7322 - val_loss: 0.2823 - val_f1: 0.0638\n",
      "Epoch 1379/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2756 - f1: 0.7338 - val_loss: 0.2826 - val_f1: 0.0638\n",
      "Epoch 1380/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2766 - f1: 0.7295 - val_loss: 0.2839 - val_f1: 0.0642\n",
      "Epoch 1381/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2759 - f1: 0.7325 - val_loss: 0.2842 - val_f1: 0.0641\n",
      "Epoch 1382/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2764 - f1: 0.7287 - val_loss: 0.2833 - val_f1: 0.0640\n",
      "Epoch 1383/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2769 - f1: 0.7323 - val_loss: 0.2826 - val_f1: 0.0635\n",
      "Epoch 1384/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2762 - f1: 0.7309 - val_loss: 0.2826 - val_f1: 0.0636\n",
      "Epoch 1385/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2756 - f1: 0.7345 - val_loss: 0.2832 - val_f1: 0.0638\n",
      "Epoch 1386/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2763 - f1: 0.7318 - val_loss: 0.2832 - val_f1: 0.0638\n",
      "Epoch 1387/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2771 - f1: 0.7309 - val_loss: 0.2834 - val_f1: 0.0637\n",
      "Epoch 1388/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2762 - f1: 0.7316 - val_loss: 0.2837 - val_f1: 0.0640\n",
      "Epoch 1389/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2782 - f1: 0.7297 - val_loss: 0.2818 - val_f1: 0.0635\n",
      "Epoch 1390/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2760 - f1: 0.7334 - val_loss: 0.2829 - val_f1: 0.0636\n",
      "Epoch 1391/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2739 - f1: 0.7345 - val_loss: 0.2829 - val_f1: 0.0634\n",
      "Epoch 1392/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2782 - f1: 0.7297 - val_loss: 0.2824 - val_f1: 0.0637\n",
      "Epoch 1393/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2768 - f1: 0.7318 - val_loss: 0.2839 - val_f1: 0.0639\n",
      "Epoch 1394/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2769 - f1: 0.7307 - val_loss: 0.2843 - val_f1: 0.0644\n",
      "Epoch 1395/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2770 - f1: 0.7301 - val_loss: 0.2839 - val_f1: 0.0642\n",
      "Epoch 1396/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2768 - f1: 0.7313 - val_loss: 0.2826 - val_f1: 0.0637\n",
      "Epoch 1397/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2762 - f1: 0.7316 - val_loss: 0.2839 - val_f1: 0.0639\n",
      "Epoch 1398/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2758 - f1: 0.7324 - val_loss: 0.2834 - val_f1: 0.0638\n",
      "Epoch 1399/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2770 - f1: 0.7303 - val_loss: 0.2833 - val_f1: 0.0639\n",
      "Epoch 1400/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2784 - f1: 0.7276 - val_loss: 0.2833 - val_f1: 0.0641\n",
      "Epoch 1401/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2764 - f1: 0.7320 - val_loss: 0.2820 - val_f1: 0.0633\n",
      "Epoch 1402/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2766 - f1: 0.7310 - val_loss: 0.2818 - val_f1: 0.0634\n",
      "Epoch 1403/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2754 - f1: 0.7328 - val_loss: 0.2830 - val_f1: 0.0639\n",
      "Epoch 1404/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2749 - f1: 0.7332 - val_loss: 0.2832 - val_f1: 0.0637\n",
      "Epoch 1405/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2749 - f1: 0.7353 - val_loss: 0.2833 - val_f1: 0.0639\n",
      "Epoch 1406/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2772 - f1: 0.7308 - val_loss: 0.2823 - val_f1: 0.0635\n",
      "Epoch 1407/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2755 - f1: 0.7328 - val_loss: 0.2846 - val_f1: 0.0646\n",
      "Epoch 1408/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2771 - f1: 0.7307 - val_loss: 0.2837 - val_f1: 0.0641\n",
      "Epoch 1409/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2751 - f1: 0.7334 - val_loss: 0.2832 - val_f1: 0.0640\n",
      "Epoch 1410/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2769 - f1: 0.7311 - val_loss: 0.2822 - val_f1: 0.0636\n",
      "Epoch 1411/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2739 - f1: 0.7320 - val_loss: 0.2839 - val_f1: 0.0638\n",
      "Epoch 1412/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2768 - f1: 0.7304 - val_loss: 0.2842 - val_f1: 0.0640\n",
      "Epoch 1413/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2767 - f1: 0.7332 - val_loss: 0.2823 - val_f1: 0.0636\n",
      "Epoch 1414/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2767 - f1: 0.7322 - val_loss: 0.2837 - val_f1: 0.0639\n",
      "Epoch 1415/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2764 - f1: 0.7304 - val_loss: 0.2834 - val_f1: 0.0643\n",
      "Epoch 1416/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2770 - f1: 0.7315 - val_loss: 0.2831 - val_f1: 0.0637\n",
      "Epoch 1417/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2761 - f1: 0.7302 - val_loss: 0.2839 - val_f1: 0.0641\n",
      "Epoch 1418/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2758 - f1: 0.7330 - val_loss: 0.2841 - val_f1: 0.0642\n",
      "Epoch 1419/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2759 - f1: 0.7295 - val_loss: 0.2832 - val_f1: 0.0639\n",
      "Epoch 1420/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2770 - f1: 0.7310 - val_loss: 0.2842 - val_f1: 0.0643\n",
      "Epoch 1421/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2767 - f1: 0.7315 - val_loss: 0.2825 - val_f1: 0.0637\n",
      "Epoch 1422/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2773 - f1: 0.7302 - val_loss: 0.2831 - val_f1: 0.0637\n",
      "Epoch 1423/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2759 - f1: 0.7317 - val_loss: 0.2832 - val_f1: 0.0638\n",
      "Epoch 1424/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2768 - f1: 0.7318 - val_loss: 0.2832 - val_f1: 0.0637\n",
      "Epoch 1425/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2757 - f1: 0.7326 - val_loss: 0.2836 - val_f1: 0.0640\n",
      "Epoch 1426/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2774 - f1: 0.7301 - val_loss: 0.2836 - val_f1: 0.0641\n",
      "Epoch 1427/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2752 - f1: 0.7307 - val_loss: 0.2842 - val_f1: 0.0641\n",
      "Epoch 1428/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2760 - f1: 0.7336 - val_loss: 0.2833 - val_f1: 0.0638\n",
      "Epoch 1429/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2767 - f1: 0.7306 - val_loss: 0.2828 - val_f1: 0.0637\n",
      "Epoch 1430/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2770 - f1: 0.7288 - val_loss: 0.2824 - val_f1: 0.0635\n",
      "Epoch 1431/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2763 - f1: 0.7313 - val_loss: 0.2821 - val_f1: 0.0634\n",
      "Epoch 1432/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2754 - f1: 0.7340 - val_loss: 0.2830 - val_f1: 0.0639\n",
      "Epoch 1433/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2766 - f1: 0.7301 - val_loss: 0.2837 - val_f1: 0.0642\n",
      "Epoch 1434/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2765 - f1: 0.7309 - val_loss: 0.2831 - val_f1: 0.0639\n",
      "Epoch 1435/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2758 - f1: 0.7331 - val_loss: 0.2836 - val_f1: 0.0641\n",
      "Epoch 1436/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2767 - f1: 0.7279 - val_loss: 0.2835 - val_f1: 0.0641\n",
      "Epoch 1437/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2750 - f1: 0.7318 - val_loss: 0.2837 - val_f1: 0.0641\n",
      "Epoch 1438/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2755 - f1: 0.7320 - val_loss: 0.2830 - val_f1: 0.0638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1439/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2752 - f1: 0.7326 - val_loss: 0.2839 - val_f1: 0.0641\n",
      "Epoch 1440/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2771 - f1: 0.7310 - val_loss: 0.2839 - val_f1: 0.0643\n",
      "Epoch 1441/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2762 - f1: 0.7319 - val_loss: 0.2827 - val_f1: 0.0638\n",
      "Epoch 1442/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2758 - f1: 0.7333 - val_loss: 0.2836 - val_f1: 0.0638\n",
      "Epoch 1443/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2769 - f1: 0.7337 - val_loss: 0.2836 - val_f1: 0.0643\n",
      "Epoch 1444/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2753 - f1: 0.7336 - val_loss: 0.2833 - val_f1: 0.0640\n",
      "Epoch 1445/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2747 - f1: 0.7317 - val_loss: 0.2831 - val_f1: 0.0639\n",
      "Epoch 1446/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2753 - f1: 0.7345 - val_loss: 0.2825 - val_f1: 0.0636\n",
      "Epoch 1447/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2761 - f1: 0.7288 - val_loss: 0.2845 - val_f1: 0.0643\n",
      "Epoch 1448/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2769 - f1: 0.7297 - val_loss: 0.2828 - val_f1: 0.0639\n",
      "Epoch 1449/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2768 - f1: 0.7300 - val_loss: 0.2848 - val_f1: 0.0643\n",
      "Epoch 1450/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2772 - f1: 0.7314 - val_loss: 0.2833 - val_f1: 0.0637\n",
      "Epoch 1451/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2747 - f1: 0.7338 - val_loss: 0.2836 - val_f1: 0.0638\n",
      "Epoch 1452/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2773 - f1: 0.7330 - val_loss: 0.2837 - val_f1: 0.0642\n",
      "Epoch 1453/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2772 - f1: 0.7302 - val_loss: 0.2830 - val_f1: 0.0637\n",
      "Epoch 1454/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2775 - f1: 0.7319 - val_loss: 0.2825 - val_f1: 0.0636\n",
      "Epoch 1455/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2748 - f1: 0.7343 - val_loss: 0.2837 - val_f1: 0.0641\n",
      "Epoch 1456/2000\n",
      "168135/168135 [==============================] - 6s 34us/step - loss: 0.2755 - f1: 0.7354 - val_loss: 0.2832 - val_f1: 0.0637\n",
      "Epoch 1457/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2766 - f1: 0.7290 - val_loss: 0.2844 - val_f1: 0.0644\n",
      "Epoch 1458/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2759 - f1: 0.7323 - val_loss: 0.2831 - val_f1: 0.0637\n",
      "Epoch 1459/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2752 - f1: 0.7316 - val_loss: 0.2846 - val_f1: 0.0640\n",
      "Epoch 1460/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2753 - f1: 0.7328 - val_loss: 0.2840 - val_f1: 0.0641\n",
      "Epoch 1461/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2752 - f1: 0.7341 - val_loss: 0.2846 - val_f1: 0.0641\n",
      "Epoch 1462/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2751 - f1: 0.7345 - val_loss: 0.2838 - val_f1: 0.0640\n",
      "Epoch 1463/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2753 - f1: 0.7341 - val_loss: 0.2841 - val_f1: 0.0641\n",
      "Epoch 1464/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2765 - f1: 0.7312 - val_loss: 0.2845 - val_f1: 0.0642\n",
      "Epoch 1465/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2762 - f1: 0.7328 - val_loss: 0.2839 - val_f1: 0.0638\n",
      "Epoch 1466/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2746 - f1: 0.7332 - val_loss: 0.2848 - val_f1: 0.0643\n",
      "Epoch 1467/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2759 - f1: 0.7306 - val_loss: 0.2838 - val_f1: 0.0640\n",
      "Epoch 1468/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2754 - f1: 0.7324 - val_loss: 0.2824 - val_f1: 0.0636\n",
      "Epoch 1469/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2758 - f1: 0.7315 - val_loss: 0.2847 - val_f1: 0.0643\n",
      "Epoch 1470/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2749 - f1: 0.7330 - val_loss: 0.2840 - val_f1: 0.0640\n",
      "Epoch 1471/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2766 - f1: 0.7306 - val_loss: 0.2828 - val_f1: 0.0638\n",
      "Epoch 1472/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2750 - f1: 0.7336 - val_loss: 0.2841 - val_f1: 0.0643\n",
      "Epoch 1473/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2759 - f1: 0.7311 - val_loss: 0.2838 - val_f1: 0.0641\n",
      "Epoch 1474/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2747 - f1: 0.7332 - val_loss: 0.2838 - val_f1: 0.0642\n",
      "Epoch 1475/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2762 - f1: 0.7325 - val_loss: 0.2843 - val_f1: 0.0642\n",
      "Epoch 1476/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2746 - f1: 0.7349 - val_loss: 0.2834 - val_f1: 0.0639\n",
      "Epoch 1477/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2746 - f1: 0.7342 - val_loss: 0.2827 - val_f1: 0.0634\n",
      "Epoch 1478/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2759 - f1: 0.7292 - val_loss: 0.2828 - val_f1: 0.0635\n",
      "Epoch 1479/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2745 - f1: 0.7334 - val_loss: 0.2845 - val_f1: 0.0640\n",
      "Epoch 1480/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2770 - f1: 0.7307 - val_loss: 0.2839 - val_f1: 0.0643\n",
      "Epoch 1481/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2756 - f1: 0.7320 - val_loss: 0.2823 - val_f1: 0.0635\n",
      "Epoch 1482/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2757 - f1: 0.7329 - val_loss: 0.2824 - val_f1: 0.0636\n",
      "Epoch 1483/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2752 - f1: 0.7319 - val_loss: 0.2836 - val_f1: 0.0639\n",
      "Epoch 1484/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2757 - f1: 0.7334 - val_loss: 0.2844 - val_f1: 0.0641\n",
      "Epoch 1485/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2767 - f1: 0.7317 - val_loss: 0.2827 - val_f1: 0.0637\n",
      "Epoch 1486/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2751 - f1: 0.7317 - val_loss: 0.2835 - val_f1: 0.0642\n",
      "Epoch 1487/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2747 - f1: 0.7342 - val_loss: 0.2845 - val_f1: 0.0642\n",
      "Epoch 1488/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2747 - f1: 0.7348 - val_loss: 0.2847 - val_f1: 0.0642\n",
      "Epoch 1489/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2752 - f1: 0.7324 - val_loss: 0.2840 - val_f1: 0.0641\n",
      "Epoch 1490/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2760 - f1: 0.7312 - val_loss: 0.2833 - val_f1: 0.0638\n",
      "Epoch 1491/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2755 - f1: 0.7342 - val_loss: 0.2849 - val_f1: 0.0643\n",
      "Epoch 1492/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2759 - f1: 0.7310 - val_loss: 0.2831 - val_f1: 0.0639\n",
      "Epoch 1493/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2765 - f1: 0.7320 - val_loss: 0.2831 - val_f1: 0.0639\n",
      "Epoch 1494/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2755 - f1: 0.7332 - val_loss: 0.2839 - val_f1: 0.0644\n",
      "Epoch 1495/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2762 - f1: 0.7324 - val_loss: 0.2832 - val_f1: 0.0638\n",
      "Epoch 1496/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2752 - f1: 0.7317 - val_loss: 0.2838 - val_f1: 0.0641\n",
      "Epoch 1497/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2759 - f1: 0.7315 - val_loss: 0.2835 - val_f1: 0.0641\n",
      "Epoch 1498/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2756 - f1: 0.7312 - val_loss: 0.2844 - val_f1: 0.0640\n",
      "Epoch 1499/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2753 - f1: 0.7338 - val_loss: 0.2825 - val_f1: 0.0634\n",
      "Epoch 1500/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2741 - f1: 0.7331 - val_loss: 0.2826 - val_f1: 0.0635\n",
      "Epoch 1501/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2753 - f1: 0.7335 - val_loss: 0.2832 - val_f1: 0.0639\n",
      "Epoch 1502/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2763 - f1: 0.7309 - val_loss: 0.2835 - val_f1: 0.0641\n",
      "Epoch 1503/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2739 - f1: 0.7347 - val_loss: 0.2841 - val_f1: 0.0638\n",
      "Epoch 1504/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2746 - f1: 0.7333 - val_loss: 0.2829 - val_f1: 0.0640\n",
      "Epoch 1505/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2744 - f1: 0.7360 - val_loss: 0.2846 - val_f1: 0.0643\n",
      "Epoch 1506/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2754 - f1: 0.7319 - val_loss: 0.2845 - val_f1: 0.0642\n",
      "Epoch 1507/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2752 - f1: 0.7319 - val_loss: 0.2837 - val_f1: 0.0640\n",
      "Epoch 1508/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2751 - f1: 0.7339 - val_loss: 0.2830 - val_f1: 0.0639\n",
      "Epoch 1509/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2754 - f1: 0.7326 - val_loss: 0.2834 - val_f1: 0.0637\n",
      "Epoch 1510/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2746 - f1: 0.7329 - val_loss: 0.2848 - val_f1: 0.0645\n",
      "Epoch 1511/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2745 - f1: 0.7333 - val_loss: 0.2837 - val_f1: 0.0640\n",
      "Epoch 1512/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2748 - f1: 0.7345 - val_loss: 0.2830 - val_f1: 0.0638\n",
      "Epoch 1513/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2754 - f1: 0.7319 - val_loss: 0.2829 - val_f1: 0.0636\n",
      "Epoch 1514/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2745 - f1: 0.7347 - val_loss: 0.2829 - val_f1: 0.0639\n",
      "Epoch 1515/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2761 - f1: 0.7315 - val_loss: 0.2830 - val_f1: 0.0641\n",
      "Epoch 1516/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2758 - f1: 0.7311 - val_loss: 0.2830 - val_f1: 0.0640\n",
      "Epoch 1517/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2747 - f1: 0.7325 - val_loss: 0.2829 - val_f1: 0.0636\n",
      "Epoch 1518/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2747 - f1: 0.7344 - val_loss: 0.2839 - val_f1: 0.0642\n",
      "Epoch 1519/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2754 - f1: 0.7327 - val_loss: 0.2835 - val_f1: 0.0637\n",
      "Epoch 1520/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2757 - f1: 0.7308 - val_loss: 0.2835 - val_f1: 0.0640\n",
      "Epoch 1521/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2748 - f1: 0.7329 - val_loss: 0.2836 - val_f1: 0.0638\n",
      "Epoch 1522/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2748 - f1: 0.7354 - val_loss: 0.2825 - val_f1: 0.0634\n",
      "Epoch 1523/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2762 - f1: 0.7310 - val_loss: 0.2838 - val_f1: 0.0640\n",
      "Epoch 1524/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2755 - f1: 0.7313 - val_loss: 0.2844 - val_f1: 0.0644\n",
      "Epoch 1525/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2740 - f1: 0.7344 - val_loss: 0.2835 - val_f1: 0.0637\n",
      "Epoch 1526/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2768 - f1: 0.7304 - val_loss: 0.2837 - val_f1: 0.0640\n",
      "Epoch 1527/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2749 - f1: 0.7342 - val_loss: 0.2835 - val_f1: 0.0638\n",
      "Epoch 1528/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2748 - f1: 0.7350 - val_loss: 0.2836 - val_f1: 0.0640\n",
      "Epoch 1529/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2757 - f1: 0.7314 - val_loss: 0.2834 - val_f1: 0.0638\n",
      "Epoch 1530/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2740 - f1: 0.7351 - val_loss: 0.2840 - val_f1: 0.0640\n",
      "Epoch 1531/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2746 - f1: 0.7336 - val_loss: 0.2836 - val_f1: 0.0640\n",
      "Epoch 1532/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2750 - f1: 0.7323 - val_loss: 0.2837 - val_f1: 0.0641\n",
      "Epoch 1533/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2756 - f1: 0.7328 - val_loss: 0.2834 - val_f1: 0.0637\n",
      "Epoch 1534/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2763 - f1: 0.7321 - val_loss: 0.2837 - val_f1: 0.0640\n",
      "Epoch 1535/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2746 - f1: 0.7326 - val_loss: 0.2829 - val_f1: 0.0637\n",
      "Epoch 1536/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2757 - f1: 0.7319 - val_loss: 0.2832 - val_f1: 0.0636\n",
      "Epoch 1537/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2756 - f1: 0.7301 - val_loss: 0.2841 - val_f1: 0.0641\n",
      "Epoch 1538/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2746 - f1: 0.7340 - val_loss: 0.2841 - val_f1: 0.0640\n",
      "Epoch 1539/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2753 - f1: 0.7325 - val_loss: 0.2836 - val_f1: 0.0644\n",
      "Epoch 1540/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2751 - f1: 0.7328 - val_loss: 0.2840 - val_f1: 0.0638\n",
      "Epoch 1541/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2756 - f1: 0.7324 - val_loss: 0.2844 - val_f1: 0.0641\n",
      "Epoch 1542/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2763 - f1: 0.7311 - val_loss: 0.2831 - val_f1: 0.0635\n",
      "Epoch 1543/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2760 - f1: 0.7329 - val_loss: 0.2832 - val_f1: 0.0636\n",
      "Epoch 1544/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2736 - f1: 0.7343 - val_loss: 0.2831 - val_f1: 0.0638\n",
      "Epoch 1545/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2749 - f1: 0.7333 - val_loss: 0.2835 - val_f1: 0.0639\n",
      "Epoch 1546/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2764 - f1: 0.7324 - val_loss: 0.2837 - val_f1: 0.0643\n",
      "Epoch 1547/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2754 - f1: 0.7305 - val_loss: 0.2840 - val_f1: 0.0642\n",
      "Epoch 1548/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2748 - f1: 0.7330 - val_loss: 0.2845 - val_f1: 0.0642\n",
      "Epoch 1549/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2743 - f1: 0.7338 - val_loss: 0.2847 - val_f1: 0.0641\n",
      "Epoch 1550/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2759 - f1: 0.7336 - val_loss: 0.2828 - val_f1: 0.0637\n",
      "Epoch 1551/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2740 - f1: 0.7358 - val_loss: 0.2833 - val_f1: 0.0637\n",
      "Epoch 1552/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2738 - f1: 0.7332 - val_loss: 0.2838 - val_f1: 0.0639\n",
      "Epoch 1553/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2748 - f1: 0.7331 - val_loss: 0.2834 - val_f1: 0.0639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1554/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2754 - f1: 0.7333 - val_loss: 0.2833 - val_f1: 0.0638\n",
      "Epoch 1555/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2737 - f1: 0.7380 - val_loss: 0.2833 - val_f1: 0.0639\n",
      "Epoch 1556/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2754 - f1: 0.7335 - val_loss: 0.2830 - val_f1: 0.0636\n",
      "Epoch 1557/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2755 - f1: 0.7324 - val_loss: 0.2834 - val_f1: 0.0638\n",
      "Epoch 1558/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2736 - f1: 0.7337 - val_loss: 0.2843 - val_f1: 0.0642\n",
      "Epoch 1559/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2743 - f1: 0.7346 - val_loss: 0.2836 - val_f1: 0.0639\n",
      "Epoch 1560/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2753 - f1: 0.7319 - val_loss: 0.2846 - val_f1: 0.0642\n",
      "Epoch 1561/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2750 - f1: 0.7354 - val_loss: 0.2831 - val_f1: 0.0636\n",
      "Epoch 1562/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2739 - f1: 0.7353 - val_loss: 0.2836 - val_f1: 0.0637\n",
      "Epoch 1563/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2737 - f1: 0.7348 - val_loss: 0.2838 - val_f1: 0.0638\n",
      "Epoch 1564/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2732 - f1: 0.7333 - val_loss: 0.2839 - val_f1: 0.0635\n",
      "Epoch 1565/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2749 - f1: 0.7343 - val_loss: 0.2836 - val_f1: 0.0639\n",
      "Epoch 1566/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2757 - f1: 0.7322 - val_loss: 0.2836 - val_f1: 0.0640\n",
      "Epoch 1567/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2742 - f1: 0.7342 - val_loss: 0.2837 - val_f1: 0.0638\n",
      "Epoch 1568/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7361 - val_loss: 0.2840 - val_f1: 0.0637\n",
      "Epoch 1569/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2738 - f1: 0.7333 - val_loss: 0.2842 - val_f1: 0.0641\n",
      "Epoch 1570/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2744 - f1: 0.7336 - val_loss: 0.2842 - val_f1: 0.0642\n",
      "Epoch 1571/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2748 - f1: 0.7346 - val_loss: 0.2826 - val_f1: 0.0636\n",
      "Epoch 1572/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2749 - f1: 0.7335 - val_loss: 0.2837 - val_f1: 0.0634\n",
      "Epoch 1573/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2745 - f1: 0.7317 - val_loss: 0.2836 - val_f1: 0.0638\n",
      "Epoch 1574/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2735 - f1: 0.7365 - val_loss: 0.2851 - val_f1: 0.0644\n",
      "Epoch 1575/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2751 - f1: 0.7350 - val_loss: 0.2841 - val_f1: 0.0642\n",
      "Epoch 1576/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2743 - f1: 0.7355 - val_loss: 0.2837 - val_f1: 0.0638\n",
      "Epoch 1577/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2745 - f1: 0.7335 - val_loss: 0.2833 - val_f1: 0.0637\n",
      "Epoch 1578/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2749 - f1: 0.7326 - val_loss: 0.2835 - val_f1: 0.0637\n",
      "Epoch 1579/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2742 - f1: 0.7346 - val_loss: 0.2838 - val_f1: 0.0641\n",
      "Epoch 1580/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2750 - f1: 0.7344 - val_loss: 0.2841 - val_f1: 0.0638\n",
      "Epoch 1581/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2741 - f1: 0.7352 - val_loss: 0.2842 - val_f1: 0.0642\n",
      "Epoch 1582/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2749 - f1: 0.7319 - val_loss: 0.2824 - val_f1: 0.0633\n",
      "Epoch 1583/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2744 - f1: 0.7320 - val_loss: 0.2848 - val_f1: 0.0641\n",
      "Epoch 1584/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7377 - val_loss: 0.2833 - val_f1: 0.0641\n",
      "Epoch 1585/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2744 - f1: 0.7344 - val_loss: 0.2832 - val_f1: 0.0637\n",
      "Epoch 1586/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2734 - f1: 0.7330 - val_loss: 0.2843 - val_f1: 0.0637\n",
      "Epoch 1587/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2732 - f1: 0.7350 - val_loss: 0.2848 - val_f1: 0.0640\n",
      "Epoch 1588/2000\n",
      "168135/168135 [==============================] - 6s 34us/step - loss: 0.2746 - f1: 0.7331 - val_loss: 0.2840 - val_f1: 0.0640\n",
      "Epoch 1589/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2748 - f1: 0.7320 - val_loss: 0.2842 - val_f1: 0.0640\n",
      "Epoch 1590/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2751 - f1: 0.7350 - val_loss: 0.2840 - val_f1: 0.0640\n",
      "Epoch 1591/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2750 - f1: 0.7337 - val_loss: 0.2840 - val_f1: 0.0641\n",
      "Epoch 1592/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2760 - f1: 0.7348 - val_loss: 0.2824 - val_f1: 0.0635\n",
      "Epoch 1593/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2744 - f1: 0.7344 - val_loss: 0.2837 - val_f1: 0.0635\n",
      "Epoch 1594/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2758 - f1: 0.7326 - val_loss: 0.2832 - val_f1: 0.0638\n",
      "Epoch 1595/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2744 - f1: 0.7350 - val_loss: 0.2832 - val_f1: 0.0638\n",
      "Epoch 1596/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2736 - f1: 0.7363 - val_loss: 0.2835 - val_f1: 0.0639\n",
      "Epoch 1597/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2738 - f1: 0.7340 - val_loss: 0.2833 - val_f1: 0.0638\n",
      "Epoch 1598/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2739 - f1: 0.7358 - val_loss: 0.2833 - val_f1: 0.0636\n",
      "Epoch 1599/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2745 - f1: 0.7342 - val_loss: 0.2828 - val_f1: 0.0638\n",
      "Epoch 1600/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2743 - f1: 0.7348 - val_loss: 0.2840 - val_f1: 0.0641\n",
      "Epoch 1601/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2739 - f1: 0.7331 - val_loss: 0.2844 - val_f1: 0.0644\n",
      "Epoch 1602/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7362 - val_loss: 0.2835 - val_f1: 0.0636\n",
      "Epoch 1603/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2741 - f1: 0.7355 - val_loss: 0.2840 - val_f1: 0.0641\n",
      "Epoch 1604/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2745 - f1: 0.7350 - val_loss: 0.2835 - val_f1: 0.0638\n",
      "Epoch 1605/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2747 - f1: 0.7364 - val_loss: 0.2837 - val_f1: 0.0640\n",
      "Epoch 1606/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2749 - f1: 0.7339 - val_loss: 0.2830 - val_f1: 0.0636\n",
      "Epoch 1607/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2756 - f1: 0.7317 - val_loss: 0.2847 - val_f1: 0.0643\n",
      "Epoch 1608/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2753 - f1: 0.7328 - val_loss: 0.2840 - val_f1: 0.0642\n",
      "Epoch 1609/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2750 - f1: 0.7336 - val_loss: 0.2839 - val_f1: 0.0644\n",
      "Epoch 1610/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2749 - f1: 0.7346 - val_loss: 0.2826 - val_f1: 0.0634\n",
      "Epoch 1611/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2739 - f1: 0.7332 - val_loss: 0.2841 - val_f1: 0.0639\n",
      "Epoch 1612/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2748 - f1: 0.7333 - val_loss: 0.2830 - val_f1: 0.0637\n",
      "Epoch 1613/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2743 - f1: 0.7334 - val_loss: 0.2842 - val_f1: 0.0644\n",
      "Epoch 1614/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2745 - f1: 0.7347 - val_loss: 0.2839 - val_f1: 0.0638\n",
      "Epoch 1615/2000\n",
      "168135/168135 [==============================] - 7s 39us/step - loss: 0.2748 - f1: 0.7337 - val_loss: 0.2849 - val_f1: 0.0645\n",
      "Epoch 1616/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2727 - f1: 0.7354 - val_loss: 0.2839 - val_f1: 0.0642\n",
      "Epoch 1617/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2743 - f1: 0.7346 - val_loss: 0.2844 - val_f1: 0.0644\n",
      "Epoch 1618/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2759 - f1: 0.7334 - val_loss: 0.2822 - val_f1: 0.0636\n",
      "Epoch 1619/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2738 - f1: 0.7349 - val_loss: 0.2836 - val_f1: 0.0640\n",
      "Epoch 1620/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2729 - f1: 0.7380 - val_loss: 0.2834 - val_f1: 0.0637\n",
      "Epoch 1621/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2741 - f1: 0.7346 - val_loss: 0.2843 - val_f1: 0.0643\n",
      "Epoch 1622/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2721 - f1: 0.7384 - val_loss: 0.2839 - val_f1: 0.0644\n",
      "Epoch 1623/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2734 - f1: 0.7367 - val_loss: 0.2844 - val_f1: 0.0639\n",
      "Epoch 1624/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2755 - f1: 0.7332 - val_loss: 0.2830 - val_f1: 0.0638\n",
      "Epoch 1625/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2722 - f1: 0.7364 - val_loss: 0.2840 - val_f1: 0.0642\n",
      "Epoch 1626/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2726 - f1: 0.7340 - val_loss: 0.2847 - val_f1: 0.0645\n",
      "Epoch 1627/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2737 - f1: 0.7351 - val_loss: 0.2845 - val_f1: 0.0645\n",
      "Epoch 1628/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2733 - f1: 0.7366 - val_loss: 0.2833 - val_f1: 0.0640\n",
      "Epoch 1629/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2737 - f1: 0.7371 - val_loss: 0.2840 - val_f1: 0.0642\n",
      "Epoch 1630/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2759 - f1: 0.7322 - val_loss: 0.2844 - val_f1: 0.0643\n",
      "Epoch 1631/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2739 - f1: 0.7344 - val_loss: 0.2825 - val_f1: 0.0633\n",
      "Epoch 1632/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2740 - f1: 0.7343 - val_loss: 0.2835 - val_f1: 0.0642\n",
      "Epoch 1633/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2741 - f1: 0.7351 - val_loss: 0.2832 - val_f1: 0.0639\n",
      "Epoch 1634/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2731 - f1: 0.7354 - val_loss: 0.2830 - val_f1: 0.0636\n",
      "Epoch 1635/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2732 - f1: 0.7365 - val_loss: 0.2841 - val_f1: 0.0641\n",
      "Epoch 1636/2000\n",
      "168135/168135 [==============================] - 6s 33us/step - loss: 0.2739 - f1: 0.7361 - val_loss: 0.2837 - val_f1: 0.0641\n",
      "Epoch 1637/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2741 - f1: 0.7360 - val_loss: 0.2837 - val_f1: 0.0640\n",
      "Epoch 1638/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2735 - f1: 0.7343 - val_loss: 0.2839 - val_f1: 0.0637\n",
      "Epoch 1639/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2737 - f1: 0.7339 - val_loss: 0.2833 - val_f1: 0.0639\n",
      "Epoch 1640/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2746 - f1: 0.7325 - val_loss: 0.2831 - val_f1: 0.0637\n",
      "Epoch 1641/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2736 - f1: 0.7363 - val_loss: 0.2839 - val_f1: 0.0637\n",
      "Epoch 1642/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2730 - f1: 0.7358 - val_loss: 0.2838 - val_f1: 0.0637\n",
      "Epoch 1643/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2766 - f1: 0.7294 - val_loss: 0.2837 - val_f1: 0.0641\n",
      "Epoch 1644/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2744 - f1: 0.7309 - val_loss: 0.2836 - val_f1: 0.0639\n",
      "Epoch 1645/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2738 - f1: 0.7348 - val_loss: 0.2838 - val_f1: 0.0636\n",
      "Epoch 1646/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2721 - f1: 0.7362 - val_loss: 0.2849 - val_f1: 0.0641\n",
      "Epoch 1647/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2750 - f1: 0.7330 - val_loss: 0.2839 - val_f1: 0.0642\n",
      "Epoch 1648/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2733 - f1: 0.7347 - val_loss: 0.2842 - val_f1: 0.0640\n",
      "Epoch 1649/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2745 - f1: 0.7335 - val_loss: 0.2834 - val_f1: 0.0638\n",
      "Epoch 1650/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2740 - f1: 0.7336 - val_loss: 0.2838 - val_f1: 0.0639\n",
      "Epoch 1651/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2737 - f1: 0.7357 - val_loss: 0.2835 - val_f1: 0.0637\n",
      "Epoch 1652/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2717 - f1: 0.7380 - val_loss: 0.2848 - val_f1: 0.0643\n",
      "Epoch 1653/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2744 - f1: 0.7343 - val_loss: 0.2850 - val_f1: 0.0641\n",
      "Epoch 1654/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2738 - f1: 0.7349 - val_loss: 0.2838 - val_f1: 0.0640\n",
      "Epoch 1655/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2736 - f1: 0.7347 - val_loss: 0.2846 - val_f1: 0.0641\n",
      "Epoch 1656/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2732 - f1: 0.7363 - val_loss: 0.2834 - val_f1: 0.0635\n",
      "Epoch 1657/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2733 - f1: 0.7348 - val_loss: 0.2840 - val_f1: 0.0641\n",
      "Epoch 1658/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2734 - f1: 0.7365 - val_loss: 0.2839 - val_f1: 0.0636\n",
      "Epoch 1659/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2738 - f1: 0.7338 - val_loss: 0.2847 - val_f1: 0.0641\n",
      "Epoch 1660/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2728 - f1: 0.7357 - val_loss: 0.2848 - val_f1: 0.0642\n",
      "Epoch 1661/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2748 - f1: 0.7342 - val_loss: 0.2841 - val_f1: 0.0636\n",
      "Epoch 1662/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2745 - f1: 0.7361 - val_loss: 0.2826 - val_f1: 0.0636\n",
      "Epoch 1663/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2739 - f1: 0.7356 - val_loss: 0.2838 - val_f1: 0.0636\n",
      "Epoch 1664/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2744 - f1: 0.7339 - val_loss: 0.2841 - val_f1: 0.0639\n",
      "Epoch 1665/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2721 - f1: 0.7370 - val_loss: 0.2834 - val_f1: 0.0637\n",
      "Epoch 1666/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2740 - f1: 0.7345 - val_loss: 0.2844 - val_f1: 0.0640\n",
      "Epoch 1667/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2734 - f1: 0.7363 - val_loss: 0.2836 - val_f1: 0.0639\n",
      "Epoch 1668/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2733 - f1: 0.7340 - val_loss: 0.2851 - val_f1: 0.0642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1669/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2741 - f1: 0.7330 - val_loss: 0.2844 - val_f1: 0.0642\n",
      "Epoch 1670/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2751 - f1: 0.7335 - val_loss: 0.2829 - val_f1: 0.0637\n",
      "Epoch 1671/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2733 - f1: 0.7358 - val_loss: 0.2847 - val_f1: 0.0644\n",
      "Epoch 1672/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2734 - f1: 0.7372 - val_loss: 0.2844 - val_f1: 0.0643\n",
      "Epoch 1673/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2731 - f1: 0.7339 - val_loss: 0.2835 - val_f1: 0.0638\n",
      "Epoch 1674/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2727 - f1: 0.7355 - val_loss: 0.2834 - val_f1: 0.0636\n",
      "Epoch 1675/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2735 - f1: 0.7362 - val_loss: 0.2846 - val_f1: 0.0643\n",
      "Epoch 1676/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2738 - f1: 0.7352 - val_loss: 0.2841 - val_f1: 0.0641\n",
      "Epoch 1677/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7349 - val_loss: 0.2846 - val_f1: 0.0640\n",
      "Epoch 1678/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2726 - f1: 0.7374 - val_loss: 0.2837 - val_f1: 0.0636\n",
      "Epoch 1679/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2726 - f1: 0.7377 - val_loss: 0.2836 - val_f1: 0.0635\n",
      "Epoch 1680/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2736 - f1: 0.7361 - val_loss: 0.2843 - val_f1: 0.0640\n",
      "Epoch 1681/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2728 - f1: 0.7352 - val_loss: 0.2843 - val_f1: 0.0639\n",
      "Epoch 1682/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2735 - f1: 0.7339 - val_loss: 0.2846 - val_f1: 0.0639\n",
      "Epoch 1683/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2733 - f1: 0.7359 - val_loss: 0.2848 - val_f1: 0.0642\n",
      "Epoch 1684/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2731 - f1: 0.7353 - val_loss: 0.2842 - val_f1: 0.0639\n",
      "Epoch 1685/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2749 - f1: 0.7334 - val_loss: 0.2842 - val_f1: 0.0641\n",
      "Epoch 1686/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2739 - f1: 0.7339 - val_loss: 0.2838 - val_f1: 0.0641\n",
      "Epoch 1687/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2742 - f1: 0.7341 - val_loss: 0.2844 - val_f1: 0.0641\n",
      "Epoch 1688/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2730 - f1: 0.7350 - val_loss: 0.2843 - val_f1: 0.0641\n",
      "Epoch 1689/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2723 - f1: 0.7350 - val_loss: 0.2855 - val_f1: 0.0641\n",
      "Epoch 1690/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7363 - val_loss: 0.2840 - val_f1: 0.0642\n",
      "Epoch 1691/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2744 - f1: 0.7337 - val_loss: 0.2849 - val_f1: 0.0642\n",
      "Epoch 1692/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2735 - f1: 0.7361 - val_loss: 0.2847 - val_f1: 0.0641\n",
      "Epoch 1693/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2743 - f1: 0.7349 - val_loss: 0.2832 - val_f1: 0.0637\n",
      "Epoch 1694/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2724 - f1: 0.7352 - val_loss: 0.2847 - val_f1: 0.0640\n",
      "Epoch 1695/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2741 - f1: 0.7358 - val_loss: 0.2841 - val_f1: 0.0639\n",
      "Epoch 1696/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7362 - val_loss: 0.2841 - val_f1: 0.0635\n",
      "Epoch 1697/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2723 - f1: 0.7363 - val_loss: 0.2834 - val_f1: 0.0636\n",
      "Epoch 1698/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2730 - f1: 0.7341 - val_loss: 0.2838 - val_f1: 0.0640\n",
      "Epoch 1699/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2729 - f1: 0.7368 - val_loss: 0.2835 - val_f1: 0.0638\n",
      "Epoch 1700/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2739 - f1: 0.7345 - val_loss: 0.2843 - val_f1: 0.0642\n",
      "Epoch 1701/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2728 - f1: 0.7353 - val_loss: 0.2850 - val_f1: 0.0643\n",
      "Epoch 1702/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2734 - f1: 0.7378 - val_loss: 0.2837 - val_f1: 0.0637\n",
      "Epoch 1703/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2744 - f1: 0.7357 - val_loss: 0.2839 - val_f1: 0.0639\n",
      "Epoch 1704/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2732 - f1: 0.7366 - val_loss: 0.2842 - val_f1: 0.0639\n",
      "Epoch 1705/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2726 - f1: 0.7349 - val_loss: 0.2845 - val_f1: 0.0640\n",
      "Epoch 1706/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2723 - f1: 0.7371 - val_loss: 0.2848 - val_f1: 0.0639\n",
      "Epoch 1707/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2729 - f1: 0.7367 - val_loss: 0.2850 - val_f1: 0.0642\n",
      "Epoch 1708/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2735 - f1: 0.7339 - val_loss: 0.2832 - val_f1: 0.0637\n",
      "Epoch 1709/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2731 - f1: 0.7346 - val_loss: 0.2844 - val_f1: 0.0641\n",
      "Epoch 1710/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2735 - f1: 0.7327 - val_loss: 0.2837 - val_f1: 0.0639\n",
      "Epoch 1711/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2730 - f1: 0.7369 - val_loss: 0.2843 - val_f1: 0.0643\n",
      "Epoch 1712/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2748 - f1: 0.7344 - val_loss: 0.2832 - val_f1: 0.0638\n",
      "Epoch 1713/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2726 - f1: 0.7371 - val_loss: 0.2849 - val_f1: 0.0642\n",
      "Epoch 1714/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2741 - f1: 0.7345 - val_loss: 0.2835 - val_f1: 0.0638\n",
      "Epoch 1715/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2738 - f1: 0.7354 - val_loss: 0.2839 - val_f1: 0.0642\n",
      "Epoch 1716/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2720 - f1: 0.7384 - val_loss: 0.2846 - val_f1: 0.0638\n",
      "Epoch 1717/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2731 - f1: 0.7374 - val_loss: 0.2836 - val_f1: 0.0640\n",
      "Epoch 1718/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2736 - f1: 0.7372 - val_loss: 0.2840 - val_f1: 0.0640\n",
      "Epoch 1719/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2728 - f1: 0.7361 - val_loss: 0.2845 - val_f1: 0.0641\n",
      "Epoch 1720/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2741 - f1: 0.7339 - val_loss: 0.2843 - val_f1: 0.0642\n",
      "Epoch 1721/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2722 - f1: 0.7370 - val_loss: 0.2841 - val_f1: 0.0637\n",
      "Epoch 1722/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2726 - f1: 0.7349 - val_loss: 0.2840 - val_f1: 0.0636\n",
      "Epoch 1723/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2726 - f1: 0.7374 - val_loss: 0.2839 - val_f1: 0.0639\n",
      "Epoch 1724/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2715 - f1: 0.7369 - val_loss: 0.2856 - val_f1: 0.0643\n",
      "Epoch 1725/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2728 - f1: 0.7364 - val_loss: 0.2846 - val_f1: 0.0643\n",
      "Epoch 1726/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2722 - f1: 0.7371 - val_loss: 0.2845 - val_f1: 0.0639\n",
      "Epoch 1727/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2744 - f1: 0.7362 - val_loss: 0.2844 - val_f1: 0.0643\n",
      "Epoch 1728/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2731 - f1: 0.7373 - val_loss: 0.2834 - val_f1: 0.0636\n",
      "Epoch 1729/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2720 - f1: 0.7387 - val_loss: 0.2846 - val_f1: 0.0639\n",
      "Epoch 1730/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2736 - f1: 0.7375 - val_loss: 0.2848 - val_f1: 0.0643\n",
      "Epoch 1731/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2739 - f1: 0.7370 - val_loss: 0.2842 - val_f1: 0.0638\n",
      "Epoch 1732/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2734 - f1: 0.7372 - val_loss: 0.2841 - val_f1: 0.0640\n",
      "Epoch 1733/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2740 - f1: 0.7341 - val_loss: 0.2842 - val_f1: 0.0642\n",
      "Epoch 1734/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2723 - f1: 0.7365 - val_loss: 0.2853 - val_f1: 0.0644\n",
      "Epoch 1735/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2731 - f1: 0.7348 - val_loss: 0.2843 - val_f1: 0.0640\n",
      "Epoch 1736/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2726 - f1: 0.7369 - val_loss: 0.2841 - val_f1: 0.0639\n",
      "Epoch 1737/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2720 - f1: 0.7369 - val_loss: 0.2846 - val_f1: 0.0639\n",
      "Epoch 1738/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2728 - f1: 0.7351 - val_loss: 0.2849 - val_f1: 0.0641\n",
      "Epoch 1739/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2738 - f1: 0.7362 - val_loss: 0.2834 - val_f1: 0.0638\n",
      "Epoch 1740/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2745 - f1: 0.7325 - val_loss: 0.2839 - val_f1: 0.0642\n",
      "Epoch 1741/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2730 - f1: 0.7372 - val_loss: 0.2834 - val_f1: 0.0635\n",
      "Epoch 1742/2000\n",
      "168135/168135 [==============================] - 6s 33us/step - loss: 0.2722 - f1: 0.7376 - val_loss: 0.2835 - val_f1: 0.0635\n",
      "Epoch 1743/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2724 - f1: 0.7373 - val_loss: 0.2837 - val_f1: 0.0636\n",
      "Epoch 1744/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2729 - f1: 0.7358 - val_loss: 0.2835 - val_f1: 0.0636\n",
      "Epoch 1745/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2731 - f1: 0.7375 - val_loss: 0.2845 - val_f1: 0.0643\n",
      "Epoch 1746/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2730 - f1: 0.7339 - val_loss: 0.2844 - val_f1: 0.0640\n",
      "Epoch 1747/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2719 - f1: 0.7371 - val_loss: 0.2849 - val_f1: 0.0640\n",
      "Epoch 1748/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2728 - f1: 0.7370 - val_loss: 0.2850 - val_f1: 0.0643\n",
      "Epoch 1749/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2741 - f1: 0.7331 - val_loss: 0.2834 - val_f1: 0.0636\n",
      "Epoch 1750/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2740 - f1: 0.7355 - val_loss: 0.2840 - val_f1: 0.0640\n",
      "Epoch 1751/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2728 - f1: 0.7349 - val_loss: 0.2853 - val_f1: 0.0642\n",
      "Epoch 1752/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2722 - f1: 0.7344 - val_loss: 0.2837 - val_f1: 0.0637\n",
      "Epoch 1753/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2736 - f1: 0.7348 - val_loss: 0.2848 - val_f1: 0.0642\n",
      "Epoch 1754/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2721 - f1: 0.7364 - val_loss: 0.2834 - val_f1: 0.0636\n",
      "Epoch 1755/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2727 - f1: 0.7342 - val_loss: 0.2845 - val_f1: 0.0639\n",
      "Epoch 1756/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2738 - f1: 0.7347 - val_loss: 0.2841 - val_f1: 0.0642\n",
      "Epoch 1757/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2717 - f1: 0.7368 - val_loss: 0.2850 - val_f1: 0.0641\n",
      "Epoch 1758/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2735 - f1: 0.7341 - val_loss: 0.2840 - val_f1: 0.0639\n",
      "Epoch 1759/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2733 - f1: 0.7341 - val_loss: 0.2837 - val_f1: 0.0637\n",
      "Epoch 1760/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2737 - f1: 0.7359 - val_loss: 0.2827 - val_f1: 0.0633\n",
      "Epoch 1761/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2726 - f1: 0.7364 - val_loss: 0.2831 - val_f1: 0.0637\n",
      "Epoch 1762/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2729 - f1: 0.7352 - val_loss: 0.2853 - val_f1: 0.0643\n",
      "Epoch 1763/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2728 - f1: 0.7373 - val_loss: 0.2846 - val_f1: 0.0641\n",
      "Epoch 1764/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2723 - f1: 0.7375 - val_loss: 0.2839 - val_f1: 0.0637\n",
      "Epoch 1765/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2721 - f1: 0.7396 - val_loss: 0.2849 - val_f1: 0.0639\n",
      "Epoch 1766/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2731 - f1: 0.7344 - val_loss: 0.2836 - val_f1: 0.0639\n",
      "Epoch 1767/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2725 - f1: 0.7359 - val_loss: 0.2847 - val_f1: 0.0641\n",
      "Epoch 1768/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2735 - f1: 0.7337 - val_loss: 0.2849 - val_f1: 0.0642\n",
      "Epoch 1769/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2734 - f1: 0.7367 - val_loss: 0.2852 - val_f1: 0.0645\n",
      "Epoch 1770/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2740 - f1: 0.7351 - val_loss: 0.2836 - val_f1: 0.0638\n",
      "Epoch 1771/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2741 - f1: 0.7343 - val_loss: 0.2857 - val_f1: 0.0648\n",
      "Epoch 1772/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2721 - f1: 0.7365 - val_loss: 0.2845 - val_f1: 0.0638\n",
      "Epoch 1773/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2742 - f1: 0.7336 - val_loss: 0.2855 - val_f1: 0.0644\n",
      "Epoch 1774/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2740 - f1: 0.7349 - val_loss: 0.2839 - val_f1: 0.0641\n",
      "Epoch 1775/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2729 - f1: 0.7356 - val_loss: 0.2840 - val_f1: 0.0637\n",
      "Epoch 1776/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2733 - f1: 0.7355 - val_loss: 0.2843 - val_f1: 0.0639\n",
      "Epoch 1777/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2719 - f1: 0.7381 - val_loss: 0.2848 - val_f1: 0.0644\n",
      "Epoch 1778/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2721 - f1: 0.7387 - val_loss: 0.2836 - val_f1: 0.0638\n",
      "Epoch 1779/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2725 - f1: 0.7350 - val_loss: 0.2839 - val_f1: 0.0638\n",
      "Epoch 1780/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2721 - f1: 0.7349 - val_loss: 0.2841 - val_f1: 0.0638\n",
      "Epoch 1781/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2740 - f1: 0.7347 - val_loss: 0.2845 - val_f1: 0.0640\n",
      "Epoch 1782/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2736 - f1: 0.7354 - val_loss: 0.2841 - val_f1: 0.0640\n",
      "Epoch 1783/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2719 - f1: 0.7363 - val_loss: 0.2846 - val_f1: 0.0640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1784/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2715 - f1: 0.7364 - val_loss: 0.2850 - val_f1: 0.0643\n",
      "Epoch 1785/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2723 - f1: 0.7373 - val_loss: 0.2834 - val_f1: 0.0634\n",
      "Epoch 1786/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2728 - f1: 0.7329 - val_loss: 0.2833 - val_f1: 0.0635\n",
      "Epoch 1787/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2725 - f1: 0.7344 - val_loss: 0.2847 - val_f1: 0.0644\n",
      "Epoch 1788/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2731 - f1: 0.7338 - val_loss: 0.2850 - val_f1: 0.0642\n",
      "Epoch 1789/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2729 - f1: 0.7360 - val_loss: 0.2841 - val_f1: 0.0640\n",
      "Epoch 1790/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2722 - f1: 0.7340 - val_loss: 0.2852 - val_f1: 0.0643\n",
      "Epoch 1791/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2731 - f1: 0.7369 - val_loss: 0.2840 - val_f1: 0.0638\n",
      "Epoch 1792/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2729 - f1: 0.7345 - val_loss: 0.2834 - val_f1: 0.0637\n",
      "Epoch 1793/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2727 - f1: 0.7351 - val_loss: 0.2842 - val_f1: 0.0639\n",
      "Epoch 1794/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2724 - f1: 0.7358 - val_loss: 0.2835 - val_f1: 0.0636\n",
      "Epoch 1795/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2735 - f1: 0.7347 - val_loss: 0.2848 - val_f1: 0.0642\n",
      "Epoch 1796/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2720 - f1: 0.7381 - val_loss: 0.2842 - val_f1: 0.0640\n",
      "Epoch 1797/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2735 - f1: 0.7351 - val_loss: 0.2840 - val_f1: 0.0641\n",
      "Epoch 1798/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2735 - f1: 0.7357 - val_loss: 0.2834 - val_f1: 0.0635\n",
      "Epoch 1799/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2736 - f1: 0.7337 - val_loss: 0.2845 - val_f1: 0.0642\n",
      "Epoch 1800/2000\n",
      "168135/168135 [==============================] - 6s 34us/step - loss: 0.2730 - f1: 0.7366 - val_loss: 0.2842 - val_f1: 0.0638\n",
      "Epoch 1801/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2728 - f1: 0.7372 - val_loss: 0.2841 - val_f1: 0.0637\n",
      "Epoch 1802/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7348 - val_loss: 0.2852 - val_f1: 0.0643\n",
      "Epoch 1803/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2713 - f1: 0.7378 - val_loss: 0.2842 - val_f1: 0.0637\n",
      "Epoch 1804/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2723 - f1: 0.7360 - val_loss: 0.2854 - val_f1: 0.0640\n",
      "Epoch 1805/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2725 - f1: 0.7349 - val_loss: 0.2850 - val_f1: 0.0642\n",
      "Epoch 1806/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2730 - f1: 0.7370 - val_loss: 0.2841 - val_f1: 0.0637\n",
      "Epoch 1807/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2721 - f1: 0.7371 - val_loss: 0.2837 - val_f1: 0.0639\n",
      "Epoch 1808/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7347 - val_loss: 0.2833 - val_f1: 0.0634\n",
      "Epoch 1809/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2725 - f1: 0.7341 - val_loss: 0.2849 - val_f1: 0.0642\n",
      "Epoch 1810/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2725 - f1: 0.7375 - val_loss: 0.2849 - val_f1: 0.0642\n",
      "Epoch 1811/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2736 - f1: 0.7353 - val_loss: 0.2841 - val_f1: 0.0638\n",
      "Epoch 1812/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2722 - f1: 0.7373 - val_loss: 0.2841 - val_f1: 0.0640\n",
      "Epoch 1813/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2721 - f1: 0.7369 - val_loss: 0.2841 - val_f1: 0.0635\n",
      "Epoch 1814/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2734 - f1: 0.7362 - val_loss: 0.2834 - val_f1: 0.0636\n",
      "Epoch 1815/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2725 - f1: 0.7360 - val_loss: 0.2838 - val_f1: 0.0639\n",
      "Epoch 1816/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2724 - f1: 0.7358 - val_loss: 0.2847 - val_f1: 0.0640\n",
      "Epoch 1817/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2720 - f1: 0.7388 - val_loss: 0.2854 - val_f1: 0.0642\n",
      "Epoch 1818/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2725 - f1: 0.7349 - val_loss: 0.2847 - val_f1: 0.0641\n",
      "Epoch 1819/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2719 - f1: 0.7378 - val_loss: 0.2850 - val_f1: 0.0645\n",
      "Epoch 1820/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2722 - f1: 0.7342 - val_loss: 0.2845 - val_f1: 0.0640\n",
      "Epoch 1821/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2728 - f1: 0.7371 - val_loss: 0.2836 - val_f1: 0.0635\n",
      "Epoch 1822/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2733 - f1: 0.7345 - val_loss: 0.2853 - val_f1: 0.0643\n",
      "Epoch 1823/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2733 - f1: 0.7349 - val_loss: 0.2846 - val_f1: 0.0643\n",
      "Epoch 1824/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2712 - f1: 0.7386 - val_loss: 0.2844 - val_f1: 0.0635\n",
      "Epoch 1825/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2732 - f1: 0.7354 - val_loss: 0.2839 - val_f1: 0.0637\n",
      "Epoch 1826/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2726 - f1: 0.7353 - val_loss: 0.2844 - val_f1: 0.0638\n",
      "Epoch 1827/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2726 - f1: 0.7358 - val_loss: 0.2857 - val_f1: 0.0644\n",
      "Epoch 1828/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7360 - val_loss: 0.2837 - val_f1: 0.0636\n",
      "Epoch 1829/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2728 - f1: 0.7366 - val_loss: 0.2837 - val_f1: 0.0640\n",
      "Epoch 1830/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2726 - f1: 0.7378 - val_loss: 0.2845 - val_f1: 0.0639\n",
      "Epoch 1831/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2731 - f1: 0.7360 - val_loss: 0.2848 - val_f1: 0.0640\n",
      "Epoch 1832/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2728 - f1: 0.7375 - val_loss: 0.2840 - val_f1: 0.0638\n",
      "Epoch 1833/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2722 - f1: 0.7366 - val_loss: 0.2849 - val_f1: 0.0640\n",
      "Epoch 1834/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7350 - val_loss: 0.2850 - val_f1: 0.0641\n",
      "Epoch 1835/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2728 - f1: 0.7346 - val_loss: 0.2848 - val_f1: 0.0640\n",
      "Epoch 1836/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2719 - f1: 0.7360 - val_loss: 0.2849 - val_f1: 0.0642\n",
      "Epoch 1837/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2730 - f1: 0.7349 - val_loss: 0.2838 - val_f1: 0.0638\n",
      "Epoch 1838/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2728 - f1: 0.7334 - val_loss: 0.2844 - val_f1: 0.0639\n",
      "Epoch 1839/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2713 - f1: 0.7361 - val_loss: 0.2851 - val_f1: 0.0643\n",
      "Epoch 1840/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2721 - f1: 0.7388 - val_loss: 0.2842 - val_f1: 0.0640\n",
      "Epoch 1841/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2735 - f1: 0.7372 - val_loss: 0.2838 - val_f1: 0.0637\n",
      "Epoch 1842/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2721 - f1: 0.7390 - val_loss: 0.2843 - val_f1: 0.0639\n",
      "Epoch 1843/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2709 - f1: 0.7359 - val_loss: 0.2844 - val_f1: 0.0637\n",
      "Epoch 1844/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2709 - f1: 0.7380 - val_loss: 0.2850 - val_f1: 0.0639\n",
      "Epoch 1845/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2716 - f1: 0.7363 - val_loss: 0.2855 - val_f1: 0.0641\n",
      "Epoch 1846/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2728 - f1: 0.7359 - val_loss: 0.2841 - val_f1: 0.0636\n",
      "Epoch 1847/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2727 - f1: 0.7348 - val_loss: 0.2848 - val_f1: 0.0641\n",
      "Epoch 1848/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2725 - f1: 0.7369 - val_loss: 0.2844 - val_f1: 0.0639\n",
      "Epoch 1849/2000\n",
      "168135/168135 [==============================] - 6s 34us/step - loss: 0.2720 - f1: 0.7365 - val_loss: 0.2848 - val_f1: 0.0640\n",
      "Epoch 1850/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2724 - f1: 0.7372 - val_loss: 0.2846 - val_f1: 0.0639\n",
      "Epoch 1851/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2708 - f1: 0.7366 - val_loss: 0.2850 - val_f1: 0.0640\n",
      "Epoch 1852/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2720 - f1: 0.7371 - val_loss: 0.2846 - val_f1: 0.0638\n",
      "Epoch 1853/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2720 - f1: 0.7339 - val_loss: 0.2863 - val_f1: 0.0649\n",
      "Epoch 1854/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2721 - f1: 0.7379 - val_loss: 0.2837 - val_f1: 0.0638\n",
      "Epoch 1855/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2730 - f1: 0.7340 - val_loss: 0.2852 - val_f1: 0.0644\n",
      "Epoch 1856/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2717 - f1: 0.7378 - val_loss: 0.2839 - val_f1: 0.0637\n",
      "Epoch 1857/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2717 - f1: 0.7394 - val_loss: 0.2842 - val_f1: 0.0638\n",
      "Epoch 1858/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2722 - f1: 0.7362 - val_loss: 0.2839 - val_f1: 0.0638\n",
      "Epoch 1859/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2727 - f1: 0.7361 - val_loss: 0.2841 - val_f1: 0.0637\n",
      "Epoch 1860/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2725 - f1: 0.7365 - val_loss: 0.2843 - val_f1: 0.0640\n",
      "Epoch 1861/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2719 - f1: 0.7363 - val_loss: 0.2850 - val_f1: 0.0640\n",
      "Epoch 1862/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2720 - f1: 0.7367 - val_loss: 0.2848 - val_f1: 0.0642\n",
      "Epoch 1863/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2718 - f1: 0.7378 - val_loss: 0.2842 - val_f1: 0.0637\n",
      "Epoch 1864/2000\n",
      "168135/168135 [==============================] - 6s 33us/step - loss: 0.2740 - f1: 0.7338 - val_loss: 0.2846 - val_f1: 0.0641\n",
      "Epoch 1865/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2721 - f1: 0.7373 - val_loss: 0.2837 - val_f1: 0.0636\n",
      "Epoch 1866/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2712 - f1: 0.7373 - val_loss: 0.2848 - val_f1: 0.0640\n",
      "Epoch 1867/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2721 - f1: 0.7372 - val_loss: 0.2835 - val_f1: 0.0635\n",
      "Epoch 1868/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2734 - f1: 0.7357 - val_loss: 0.2843 - val_f1: 0.0641\n",
      "Epoch 1869/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2729 - f1: 0.7342 - val_loss: 0.2837 - val_f1: 0.0637\n",
      "Epoch 1870/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2730 - f1: 0.7319 - val_loss: 0.2849 - val_f1: 0.0639\n",
      "Epoch 1871/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2722 - f1: 0.7365 - val_loss: 0.2846 - val_f1: 0.0639\n",
      "Epoch 1872/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2711 - f1: 0.7400 - val_loss: 0.2850 - val_f1: 0.0640\n",
      "Epoch 1873/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2727 - f1: 0.7343 - val_loss: 0.2851 - val_f1: 0.0640\n",
      "Epoch 1874/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2714 - f1: 0.7370 - val_loss: 0.2870 - val_f1: 0.0649\n",
      "Epoch 1875/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2716 - f1: 0.7383 - val_loss: 0.2846 - val_f1: 0.0640\n",
      "Epoch 1876/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2717 - f1: 0.7358 - val_loss: 0.2836 - val_f1: 0.0637\n",
      "Epoch 1877/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2714 - f1: 0.7375 - val_loss: 0.2840 - val_f1: 0.0637\n",
      "Epoch 1878/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2735 - f1: 0.7346 - val_loss: 0.2847 - val_f1: 0.0641\n",
      "Epoch 1879/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2724 - f1: 0.7368 - val_loss: 0.2857 - val_f1: 0.0642\n",
      "Epoch 1880/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2729 - f1: 0.7357 - val_loss: 0.2854 - val_f1: 0.0646\n",
      "Epoch 1881/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2713 - f1: 0.7397 - val_loss: 0.2853 - val_f1: 0.0641\n",
      "Epoch 1882/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2719 - f1: 0.7386 - val_loss: 0.2846 - val_f1: 0.0641\n",
      "Epoch 1883/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2711 - f1: 0.7395 - val_loss: 0.2842 - val_f1: 0.0638\n",
      "Epoch 1884/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2725 - f1: 0.7378 - val_loss: 0.2842 - val_f1: 0.0640\n",
      "Epoch 1885/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2713 - f1: 0.7376 - val_loss: 0.2851 - val_f1: 0.0640\n",
      "Epoch 1886/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2709 - f1: 0.7392 - val_loss: 0.2847 - val_f1: 0.0638\n",
      "Epoch 1887/2000\n",
      "168135/168135 [==============================] - 6s 33us/step - loss: 0.2733 - f1: 0.7366 - val_loss: 0.2844 - val_f1: 0.0639\n",
      "Epoch 1888/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2709 - f1: 0.7411 - val_loss: 0.2846 - val_f1: 0.0639\n",
      "Epoch 1889/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2708 - f1: 0.7370 - val_loss: 0.2845 - val_f1: 0.0640\n",
      "Epoch 1890/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2725 - f1: 0.7372 - val_loss: 0.2843 - val_f1: 0.0636\n",
      "Epoch 1891/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2721 - f1: 0.7349 - val_loss: 0.2854 - val_f1: 0.0642\n",
      "Epoch 1892/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2732 - f1: 0.7388 - val_loss: 0.2836 - val_f1: 0.0637\n",
      "Epoch 1893/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2724 - f1: 0.7346 - val_loss: 0.2839 - val_f1: 0.0640\n",
      "Epoch 1894/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2711 - f1: 0.7381 - val_loss: 0.2841 - val_f1: 0.0635\n",
      "Epoch 1895/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2707 - f1: 0.7384 - val_loss: 0.2853 - val_f1: 0.0641\n",
      "Epoch 1896/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2709 - f1: 0.7387 - val_loss: 0.2841 - val_f1: 0.0636\n",
      "Epoch 1897/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2719 - f1: 0.7372 - val_loss: 0.2854 - val_f1: 0.0643\n",
      "Epoch 1898/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2722 - f1: 0.7369 - val_loss: 0.2851 - val_f1: 0.0642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1899/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2720 - f1: 0.7379 - val_loss: 0.2845 - val_f1: 0.0638\n",
      "Epoch 1900/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2702 - f1: 0.7389 - val_loss: 0.2852 - val_f1: 0.0640\n",
      "Epoch 1901/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2706 - f1: 0.7394 - val_loss: 0.2856 - val_f1: 0.0641\n",
      "Epoch 1902/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2706 - f1: 0.7372 - val_loss: 0.2848 - val_f1: 0.0638\n",
      "Epoch 1903/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2720 - f1: 0.7376 - val_loss: 0.2838 - val_f1: 0.0635\n",
      "Epoch 1904/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2715 - f1: 0.7370 - val_loss: 0.2844 - val_f1: 0.0639\n",
      "Epoch 1905/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2719 - f1: 0.7373 - val_loss: 0.2856 - val_f1: 0.0643\n",
      "Epoch 1906/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2723 - f1: 0.7374 - val_loss: 0.2837 - val_f1: 0.0638\n",
      "Epoch 1907/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2726 - f1: 0.7346 - val_loss: 0.2843 - val_f1: 0.0638\n",
      "Epoch 1908/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2735 - f1: 0.7355 - val_loss: 0.2845 - val_f1: 0.0641\n",
      "Epoch 1909/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2713 - f1: 0.7379 - val_loss: 0.2848 - val_f1: 0.0641\n",
      "Epoch 1910/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2727 - f1: 0.7334 - val_loss: 0.2839 - val_f1: 0.0637\n",
      "Epoch 1911/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2708 - f1: 0.7357 - val_loss: 0.2855 - val_f1: 0.0642\n",
      "Epoch 1912/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2720 - f1: 0.7377 - val_loss: 0.2846 - val_f1: 0.0640\n",
      "Epoch 1913/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2719 - f1: 0.7350 - val_loss: 0.2852 - val_f1: 0.0643\n",
      "Epoch 1914/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2718 - f1: 0.7370 - val_loss: 0.2843 - val_f1: 0.0638\n",
      "Epoch 1915/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2723 - f1: 0.7351 - val_loss: 0.2848 - val_f1: 0.0638\n",
      "Epoch 1916/2000\n",
      "168135/168135 [==============================] - 6s 35us/step - loss: 0.2734 - f1: 0.7359 - val_loss: 0.2838 - val_f1: 0.0637\n",
      "Epoch 1917/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2714 - f1: 0.7395 - val_loss: 0.2842 - val_f1: 0.0639\n",
      "Epoch 1918/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2723 - f1: 0.7359 - val_loss: 0.2845 - val_f1: 0.0637\n",
      "Epoch 1919/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2714 - f1: 0.7349 - val_loss: 0.2849 - val_f1: 0.0639\n",
      "Epoch 1920/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2724 - f1: 0.7378 - val_loss: 0.2851 - val_f1: 0.0639\n",
      "Epoch 1921/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2721 - f1: 0.7373 - val_loss: 0.2845 - val_f1: 0.0640\n",
      "Epoch 1922/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2727 - f1: 0.7350 - val_loss: 0.2848 - val_f1: 0.0642\n",
      "Epoch 1923/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2703 - f1: 0.7373 - val_loss: 0.2852 - val_f1: 0.0640\n",
      "Epoch 1924/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2724 - f1: 0.7386 - val_loss: 0.2842 - val_f1: 0.0639\n",
      "Epoch 1925/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2716 - f1: 0.7390 - val_loss: 0.2849 - val_f1: 0.0637\n",
      "Epoch 1926/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2713 - f1: 0.7385 - val_loss: 0.2838 - val_f1: 0.0636\n",
      "Epoch 1927/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2727 - f1: 0.7366 - val_loss: 0.2844 - val_f1: 0.0637\n",
      "Epoch 1928/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2702 - f1: 0.7381 - val_loss: 0.2847 - val_f1: 0.0638\n",
      "Epoch 1929/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2723 - f1: 0.7359 - val_loss: 0.2851 - val_f1: 0.0639\n",
      "Epoch 1930/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2719 - f1: 0.7354 - val_loss: 0.2849 - val_f1: 0.0642\n",
      "Epoch 1931/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2722 - f1: 0.7359 - val_loss: 0.2844 - val_f1: 0.0637\n",
      "Epoch 1932/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2704 - f1: 0.7404 - val_loss: 0.2851 - val_f1: 0.0635\n",
      "Epoch 1933/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2710 - f1: 0.7391 - val_loss: 0.2841 - val_f1: 0.0634\n",
      "Epoch 1934/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2720 - f1: 0.7351 - val_loss: 0.2857 - val_f1: 0.0643\n",
      "Epoch 1935/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2721 - f1: 0.7360 - val_loss: 0.2843 - val_f1: 0.0638\n",
      "Epoch 1936/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2711 - f1: 0.7373 - val_loss: 0.2835 - val_f1: 0.0636\n",
      "Epoch 1937/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2719 - f1: 0.7368 - val_loss: 0.2851 - val_f1: 0.0641\n",
      "Epoch 1938/2000\n",
      "168135/168135 [==============================] - 6s 37us/step - loss: 0.2713 - f1: 0.7377 - val_loss: 0.2848 - val_f1: 0.0639\n",
      "Epoch 1939/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2707 - f1: 0.7355 - val_loss: 0.2851 - val_f1: 0.0642\n",
      "Epoch 1940/2000\n",
      "168135/168135 [==============================] - 7s 39us/step - loss: 0.2733 - f1: 0.7353 - val_loss: 0.2845 - val_f1: 0.0640\n",
      "Epoch 1941/2000\n",
      "168135/168135 [==============================] - 7s 44us/step - loss: 0.2703 - f1: 0.7408 - val_loss: 0.2850 - val_f1: 0.0640\n",
      "Epoch 1942/2000\n",
      "168135/168135 [==============================] - 8s 45us/step - loss: 0.2713 - f1: 0.7377 - val_loss: 0.2853 - val_f1: 0.0639\n",
      "Epoch 1943/2000\n",
      "168135/168135 [==============================] - 7s 43us/step - loss: 0.2716 - f1: 0.7377 - val_loss: 0.2843 - val_f1: 0.0639\n",
      "Epoch 1944/2000\n",
      "168135/168135 [==============================] - 6s 36us/step - loss: 0.2711 - f1: 0.7386 - val_loss: 0.2842 - val_f1: 0.0640\n",
      "Epoch 1945/2000\n",
      "168135/168135 [==============================] - 6s 38us/step - loss: 0.2703 - f1: 0.7399 - val_loss: 0.2845 - val_f1: 0.0637\n",
      "Epoch 1946/2000\n",
      "168135/168135 [==============================] - 7s 40us/step - loss: 0.2720 - f1: 0.7377 - val_loss: 0.2843 - val_f1: 0.0640\n",
      "Epoch 1947/2000\n",
      "168135/168135 [==============================] - 7s 42us/step - loss: 0.2708 - f1: 0.7380 - val_loss: 0.2850 - val_f1: 0.0640\n",
      "Epoch 1948/2000\n",
      "168135/168135 [==============================] - 7s 42us/step - loss: 0.2714 - f1: 0.7372 - val_loss: 0.2852 - val_f1: 0.0642\n",
      "Epoch 1949/2000\n",
      "168135/168135 [==============================] - 12s 70us/step - loss: 0.2712 - f1: 0.7383 - val_loss: 0.2850 - val_f1: 0.0637\n",
      "Epoch 1950/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2715 - f1: 0.7381 - val_loss: 0.2846 - val_f1: 0.0635\n",
      "Epoch 1951/2000\n",
      "168135/168135 [==============================] - 12s 72us/step - loss: 0.2713 - f1: 0.7369 - val_loss: 0.2855 - val_f1: 0.0642\n",
      "Epoch 1952/2000\n",
      "168135/168135 [==============================] - 12s 73us/step - loss: 0.2715 - f1: 0.7387 - val_loss: 0.2832 - val_f1: 0.0631\n",
      "Epoch 1953/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2721 - f1: 0.7350 - val_loss: 0.2846 - val_f1: 0.0639\n",
      "Epoch 1954/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2709 - f1: 0.7391 - val_loss: 0.2836 - val_f1: 0.0634\n",
      "Epoch 1955/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2722 - f1: 0.7389 - val_loss: 0.2846 - val_f1: 0.0639\n",
      "Epoch 1956/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2693 - f1: 0.7405 - val_loss: 0.2844 - val_f1: 0.0636\n",
      "Epoch 1957/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2714 - f1: 0.7388 - val_loss: 0.2846 - val_f1: 0.0638\n",
      "Epoch 1958/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2713 - f1: 0.7386 - val_loss: 0.2853 - val_f1: 0.0642\n",
      "Epoch 1959/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2715 - f1: 0.7381 - val_loss: 0.2848 - val_f1: 0.0638\n",
      "Epoch 1960/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2713 - f1: 0.7401 - val_loss: 0.2846 - val_f1: 0.0638\n",
      "Epoch 1961/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2703 - f1: 0.7377 - val_loss: 0.2861 - val_f1: 0.0642\n",
      "Epoch 1962/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2717 - f1: 0.7370 - val_loss: 0.2844 - val_f1: 0.0639\n",
      "Epoch 1963/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2712 - f1: 0.7383 - val_loss: 0.2846 - val_f1: 0.0639\n",
      "Epoch 1964/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2726 - f1: 0.7358 - val_loss: 0.2843 - val_f1: 0.0639\n",
      "Epoch 1965/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2717 - f1: 0.7357 - val_loss: 0.2840 - val_f1: 0.0637\n",
      "Epoch 1966/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2714 - f1: 0.7392 - val_loss: 0.2847 - val_f1: 0.0640\n",
      "Epoch 1967/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2722 - f1: 0.7362 - val_loss: 0.2837 - val_f1: 0.0637\n",
      "Epoch 1968/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2729 - f1: 0.7363 - val_loss: 0.2846 - val_f1: 0.0641\n",
      "Epoch 1969/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2716 - f1: 0.7371 - val_loss: 0.2855 - val_f1: 0.0641\n",
      "Epoch 1970/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2702 - f1: 0.7414 - val_loss: 0.2844 - val_f1: 0.0637\n",
      "Epoch 1971/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2727 - f1: 0.7373 - val_loss: 0.2841 - val_f1: 0.0637\n",
      "Epoch 1972/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2705 - f1: 0.7384 - val_loss: 0.2849 - val_f1: 0.0641\n",
      "Epoch 1973/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2719 - f1: 0.7372 - val_loss: 0.2842 - val_f1: 0.0640\n",
      "Epoch 1974/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2714 - f1: 0.7351 - val_loss: 0.2846 - val_f1: 0.0638\n",
      "Epoch 1975/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2710 - f1: 0.7378 - val_loss: 0.2847 - val_f1: 0.0637\n",
      "Epoch 1976/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2731 - f1: 0.7332 - val_loss: 0.2854 - val_f1: 0.0644\n",
      "Epoch 1977/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2725 - f1: 0.7365 - val_loss: 0.2842 - val_f1: 0.0636\n",
      "Epoch 1978/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2714 - f1: 0.7367 - val_loss: 0.2851 - val_f1: 0.0643\n",
      "Epoch 1979/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2723 - f1: 0.7364 - val_loss: 0.2856 - val_f1: 0.0642\n",
      "Epoch 1980/2000\n",
      "168135/168135 [==============================] - 9s 53us/step - loss: 0.2717 - f1: 0.7383 - val_loss: 0.2852 - val_f1: 0.0639\n",
      "Epoch 1981/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2717 - f1: 0.7362 - val_loss: 0.2849 - val_f1: 0.0639\n",
      "Epoch 1982/2000\n",
      "168135/168135 [==============================] - 9s 53us/step - loss: 0.2709 - f1: 0.7388 - val_loss: 0.2843 - val_f1: 0.0636\n",
      "Epoch 1983/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2710 - f1: 0.7393 - val_loss: 0.2849 - val_f1: 0.0638\n",
      "Epoch 1984/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2719 - f1: 0.7374 - val_loss: 0.2846 - val_f1: 0.0643\n",
      "Epoch 1985/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2718 - f1: 0.7378 - val_loss: 0.2846 - val_f1: 0.0641\n",
      "Epoch 1986/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2708 - f1: 0.7377 - val_loss: 0.2862 - val_f1: 0.0643\n",
      "Epoch 1987/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2710 - f1: 0.7386 - val_loss: 0.2852 - val_f1: 0.0640\n",
      "Epoch 1988/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2716 - f1: 0.7373 - val_loss: 0.2847 - val_f1: 0.0639\n",
      "Epoch 1989/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2711 - f1: 0.7397 - val_loss: 0.2842 - val_f1: 0.0638\n",
      "Epoch 1990/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2689 - f1: 0.7395 - val_loss: 0.2846 - val_f1: 0.0635\n",
      "Epoch 1991/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2724 - f1: 0.7363 - val_loss: 0.2844 - val_f1: 0.0639\n",
      "Epoch 1992/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2720 - f1: 0.7387 - val_loss: 0.2842 - val_f1: 0.0636\n",
      "Epoch 1993/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2708 - f1: 0.7374 - val_loss: 0.2843 - val_f1: 0.0636\n",
      "Epoch 1994/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2717 - f1: 0.7383 - val_loss: 0.2852 - val_f1: 0.0639\n",
      "Epoch 1995/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2719 - f1: 0.7378 - val_loss: 0.2853 - val_f1: 0.0643\n",
      "Epoch 1996/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2707 - f1: 0.7382 - val_loss: 0.2850 - val_f1: 0.0640\n",
      "Epoch 1997/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2714 - f1: 0.7369 - val_loss: 0.2860 - val_f1: 0.0644\n",
      "Epoch 1998/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2700 - f1: 0.7383 - val_loss: 0.2843 - val_f1: 0.0636\n",
      "Epoch 1999/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2699 - f1: 0.7413 - val_loss: 0.2853 - val_f1: 0.0641\n",
      "Epoch 2000/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2701 - f1: 0.7394 - val_loss: 0.2853 - val_f1: 0.0640\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna0.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna0.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[25232  1753]\n",
      " [ 1632  1383]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[25214  1772]\n",
      " [ 1595  1420]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[121125   4806]\n",
      " [  9252  32952]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna0.predict(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list1 = [100,1]\n",
    "activation_list1 = ['tanh','sigmoid']\n",
    "dropout_list1 = [0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 20,201\n",
      "Trainable params: 20,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna1 = new_rna()\n",
    "rna1.build_model(data_shape,n_list1,activation_list1,dropout_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168135 samples, validate on 30001 samples\n",
      "Epoch 1/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.4028 - f1: 0.5719 - val_loss: 0.2805 - val_f1: 0.0687\n",
      "Epoch 2/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3886 - f1: 0.5866 - val_loss: 0.2813 - val_f1: 0.0688\n",
      "Epoch 3/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3870 - f1: 0.5888 - val_loss: 0.2800 - val_f1: 0.0687\n",
      "Epoch 4/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3853 - f1: 0.5916 - val_loss: 0.2807 - val_f1: 0.0687\n",
      "Epoch 5/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3851 - f1: 0.5934 - val_loss: 0.2812 - val_f1: 0.0695\n",
      "Epoch 6/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3844 - f1: 0.5909 - val_loss: 0.2813 - val_f1: 0.0692\n",
      "Epoch 7/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3837 - f1: 0.5947 - val_loss: 0.2815 - val_f1: 0.0701\n",
      "Epoch 8/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3836 - f1: 0.5936 - val_loss: 0.2809 - val_f1: 0.0692\n",
      "Epoch 9/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3829 - f1: 0.5955 - val_loss: 0.2802 - val_f1: 0.0694\n",
      "Epoch 10/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3829 - f1: 0.5937 - val_loss: 0.2807 - val_f1: 0.0691\n",
      "Epoch 11/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3824 - f1: 0.5969 - val_loss: 0.2788 - val_f1: 0.0693\n",
      "Epoch 12/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3820 - f1: 0.5966 - val_loss: 0.2800 - val_f1: 0.0695\n",
      "Epoch 13/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3819 - f1: 0.5962 - val_loss: 0.2812 - val_f1: 0.0697\n",
      "Epoch 14/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3816 - f1: 0.5955 - val_loss: 0.2820 - val_f1: 0.0697\n",
      "Epoch 15/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3813 - f1: 0.5969 - val_loss: 0.2790 - val_f1: 0.0688\n",
      "Epoch 16/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3809 - f1: 0.5963 - val_loss: 0.2823 - val_f1: 0.0699\n",
      "Epoch 17/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3803 - f1: 0.5983 - val_loss: 0.2803 - val_f1: 0.0699\n",
      "Epoch 18/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3805 - f1: 0.5951 - val_loss: 0.2818 - val_f1: 0.0692\n",
      "Epoch 19/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3800 - f1: 0.5991 - val_loss: 0.2779 - val_f1: 0.0686\n",
      "Epoch 20/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3799 - f1: 0.5982 - val_loss: 0.2797 - val_f1: 0.0694\n",
      "Epoch 21/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3792 - f1: 0.6019 - val_loss: 0.2773 - val_f1: 0.0690\n",
      "Epoch 22/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3789 - f1: 0.5971 - val_loss: 0.2791 - val_f1: 0.0695\n",
      "Epoch 23/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3788 - f1: 0.5982 - val_loss: 0.2792 - val_f1: 0.0695\n",
      "Epoch 24/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3783 - f1: 0.5995 - val_loss: 0.2795 - val_f1: 0.0692\n",
      "Epoch 25/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3777 - f1: 0.5999 - val_loss: 0.2800 - val_f1: 0.0691\n",
      "Epoch 26/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3772 - f1: 0.6003 - val_loss: 0.2787 - val_f1: 0.0691\n",
      "Epoch 27/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3773 - f1: 0.5999 - val_loss: 0.2789 - val_f1: 0.0694\n",
      "Epoch 28/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3763 - f1: 0.6004 - val_loss: 0.2798 - val_f1: 0.0697\n",
      "Epoch 29/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3766 - f1: 0.6010 - val_loss: 0.2799 - val_f1: 0.0694\n",
      "Epoch 30/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3758 - f1: 0.6011 - val_loss: 0.2781 - val_f1: 0.0689\n",
      "Epoch 31/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3747 - f1: 0.6039 - val_loss: 0.2776 - val_f1: 0.0689\n",
      "Epoch 32/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3742 - f1: 0.6049 - val_loss: 0.2803 - val_f1: 0.0701\n",
      "Epoch 33/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3740 - f1: 0.6047 - val_loss: 0.2779 - val_f1: 0.0694\n",
      "Epoch 34/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3731 - f1: 0.6052 - val_loss: 0.2758 - val_f1: 0.0688\n",
      "Epoch 35/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3726 - f1: 0.6036 - val_loss: 0.2783 - val_f1: 0.0690\n",
      "Epoch 36/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3715 - f1: 0.6050 - val_loss: 0.2774 - val_f1: 0.0692\n",
      "Epoch 37/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.3707 - f1: 0.6080 - val_loss: 0.2758 - val_f1: 0.0688\n",
      "Epoch 38/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3704 - f1: 0.6066 - val_loss: 0.2781 - val_f1: 0.0692\n",
      "Epoch 39/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3698 - f1: 0.6093 - val_loss: 0.2765 - val_f1: 0.0685\n",
      "Epoch 40/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3685 - f1: 0.6097 - val_loss: 0.2767 - val_f1: 0.0685\n",
      "Epoch 41/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3679 - f1: 0.6127 - val_loss: 0.2738 - val_f1: 0.0683\n",
      "Epoch 42/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3672 - f1: 0.6127 - val_loss: 0.2733 - val_f1: 0.0684\n",
      "Epoch 43/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3655 - f1: 0.6155 - val_loss: 0.2774 - val_f1: 0.0686\n",
      "Epoch 44/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3652 - f1: 0.6149 - val_loss: 0.2765 - val_f1: 0.0687\n",
      "Epoch 45/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3646 - f1: 0.6163 - val_loss: 0.2744 - val_f1: 0.0681\n",
      "Epoch 46/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3627 - f1: 0.6153 - val_loss: 0.2774 - val_f1: 0.0692\n",
      "Epoch 47/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3633 - f1: 0.6164 - val_loss: 0.2752 - val_f1: 0.0686\n",
      "Epoch 48/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3606 - f1: 0.6203 - val_loss: 0.2732 - val_f1: 0.0684\n",
      "Epoch 49/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3603 - f1: 0.6201 - val_loss: 0.2742 - val_f1: 0.0682\n",
      "Epoch 50/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3596 - f1: 0.6219 - val_loss: 0.2733 - val_f1: 0.0678\n",
      "Epoch 51/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3591 - f1: 0.6219 - val_loss: 0.2729 - val_f1: 0.0676\n",
      "Epoch 52/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3579 - f1: 0.6257 - val_loss: 0.2758 - val_f1: 0.0683\n",
      "Epoch 53/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3556 - f1: 0.6274 - val_loss: 0.2766 - val_f1: 0.0689\n",
      "Epoch 54/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3555 - f1: 0.6299 - val_loss: 0.2707 - val_f1: 0.0667\n",
      "Epoch 55/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3539 - f1: 0.6281 - val_loss: 0.2730 - val_f1: 0.0680\n",
      "Epoch 56/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3533 - f1: 0.6312 - val_loss: 0.2726 - val_f1: 0.0677\n",
      "Epoch 57/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3516 - f1: 0.6331 - val_loss: 0.2707 - val_f1: 0.0671\n",
      "Epoch 58/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3515 - f1: 0.6303 - val_loss: 0.2734 - val_f1: 0.0680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3504 - f1: 0.6331 - val_loss: 0.2720 - val_f1: 0.0672\n",
      "Epoch 60/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.3490 - f1: 0.6334 - val_loss: 0.2736 - val_f1: 0.0681\n",
      "Epoch 61/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.3487 - f1: 0.6354 - val_loss: 0.2711 - val_f1: 0.0667\n",
      "Epoch 62/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3468 - f1: 0.6392 - val_loss: 0.2713 - val_f1: 0.0668\n",
      "Epoch 63/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.3458 - f1: 0.6413 - val_loss: 0.2720 - val_f1: 0.0672\n",
      "Epoch 64/2000\n",
      "168135/168135 [==============================] - 16s 96us/step - loss: 0.3445 - f1: 0.6425 - val_loss: 0.2674 - val_f1: 0.0660\n",
      "Epoch 65/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3442 - f1: 0.6424 - val_loss: 0.2718 - val_f1: 0.0670\n",
      "Epoch 66/2000\n",
      "168135/168135 [==============================] - 12s 70us/step - loss: 0.3431 - f1: 0.6445 - val_loss: 0.2731 - val_f1: 0.0679\n",
      "Epoch 67/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3422 - f1: 0.6472 - val_loss: 0.2700 - val_f1: 0.0669\n",
      "Epoch 68/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3416 - f1: 0.6488 - val_loss: 0.2717 - val_f1: 0.0668\n",
      "Epoch 69/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3408 - f1: 0.6462 - val_loss: 0.2704 - val_f1: 0.0668\n",
      "Epoch 70/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3397 - f1: 0.6485 - val_loss: 0.2693 - val_f1: 0.0662\n",
      "Epoch 71/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3381 - f1: 0.6527 - val_loss: 0.2717 - val_f1: 0.0668\n",
      "Epoch 72/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3367 - f1: 0.6512 - val_loss: 0.2703 - val_f1: 0.0670\n",
      "Epoch 73/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3363 - f1: 0.6545 - val_loss: 0.2664 - val_f1: 0.0663\n",
      "Epoch 74/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3357 - f1: 0.6554 - val_loss: 0.2725 - val_f1: 0.0669\n",
      "Epoch 75/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3335 - f1: 0.6569 - val_loss: 0.2702 - val_f1: 0.0671\n",
      "Epoch 76/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3331 - f1: 0.6567 - val_loss: 0.2670 - val_f1: 0.0657\n",
      "Epoch 77/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3328 - f1: 0.6599 - val_loss: 0.2691 - val_f1: 0.0668\n",
      "Epoch 78/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3315 - f1: 0.6588 - val_loss: 0.2701 - val_f1: 0.0669\n",
      "Epoch 79/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3304 - f1: 0.6622 - val_loss: 0.2699 - val_f1: 0.0670\n",
      "Epoch 80/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3295 - f1: 0.6621 - val_loss: 0.2688 - val_f1: 0.0661\n",
      "Epoch 81/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3292 - f1: 0.6642 - val_loss: 0.2701 - val_f1: 0.0669\n",
      "Epoch 82/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3279 - f1: 0.6650 - val_loss: 0.2690 - val_f1: 0.0665\n",
      "Epoch 83/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3260 - f1: 0.6684 - val_loss: 0.2666 - val_f1: 0.0658\n",
      "Epoch 84/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3258 - f1: 0.6710 - val_loss: 0.2700 - val_f1: 0.0666\n",
      "Epoch 85/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3257 - f1: 0.6674 - val_loss: 0.2667 - val_f1: 0.0650\n",
      "Epoch 86/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3242 - f1: 0.6716 - val_loss: 0.2674 - val_f1: 0.0658\n",
      "Epoch 87/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3229 - f1: 0.6717 - val_loss: 0.2676 - val_f1: 0.0657\n",
      "Epoch 88/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3228 - f1: 0.6721 - val_loss: 0.2677 - val_f1: 0.0659\n",
      "Epoch 89/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3215 - f1: 0.6734 - val_loss: 0.2679 - val_f1: 0.0657\n",
      "Epoch 90/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3210 - f1: 0.6732 - val_loss: 0.2701 - val_f1: 0.0662\n",
      "Epoch 91/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3204 - f1: 0.6768 - val_loss: 0.2679 - val_f1: 0.0658\n",
      "Epoch 92/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3189 - f1: 0.6804 - val_loss: 0.2688 - val_f1: 0.0658\n",
      "Epoch 93/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3177 - f1: 0.6807 - val_loss: 0.2681 - val_f1: 0.0660\n",
      "Epoch 94/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.3164 - f1: 0.6803 - val_loss: 0.2685 - val_f1: 0.0654\n",
      "Epoch 95/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3172 - f1: 0.6792 - val_loss: 0.2680 - val_f1: 0.0652\n",
      "Epoch 96/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3150 - f1: 0.6828 - val_loss: 0.2681 - val_f1: 0.0657\n",
      "Epoch 97/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3146 - f1: 0.6847 - val_loss: 0.2696 - val_f1: 0.0661\n",
      "Epoch 98/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3137 - f1: 0.6833 - val_loss: 0.2681 - val_f1: 0.0655\n",
      "Epoch 99/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3140 - f1: 0.6860 - val_loss: 0.2664 - val_f1: 0.0647\n",
      "Epoch 100/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.3126 - f1: 0.6851 - val_loss: 0.2696 - val_f1: 0.0653\n",
      "Epoch 101/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3132 - f1: 0.6841 - val_loss: 0.2681 - val_f1: 0.0654\n",
      "Epoch 102/2000\n",
      "168135/168135 [==============================] - 12s 69us/step - loss: 0.3107 - f1: 0.6878 - val_loss: 0.2688 - val_f1: 0.0652\n",
      "Epoch 103/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3101 - f1: 0.6876 - val_loss: 0.2682 - val_f1: 0.0655\n",
      "Epoch 104/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3075 - f1: 0.6909 - val_loss: 0.2691 - val_f1: 0.0653\n",
      "Epoch 105/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3094 - f1: 0.6892 - val_loss: 0.2678 - val_f1: 0.0647\n",
      "Epoch 106/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3071 - f1: 0.6909 - val_loss: 0.2681 - val_f1: 0.0649\n",
      "Epoch 107/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3087 - f1: 0.6903 - val_loss: 0.2698 - val_f1: 0.0649\n",
      "Epoch 108/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3067 - f1: 0.6935 - val_loss: 0.2686 - val_f1: 0.0644\n",
      "Epoch 109/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3067 - f1: 0.6938 - val_loss: 0.2691 - val_f1: 0.0652\n",
      "Epoch 110/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.3056 - f1: 0.6958 - val_loss: 0.2690 - val_f1: 0.0649\n",
      "Epoch 111/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3058 - f1: 0.6952 - val_loss: 0.2690 - val_f1: 0.0651\n",
      "Epoch 112/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3043 - f1: 0.6964 - val_loss: 0.2689 - val_f1: 0.0645\n",
      "Epoch 113/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3041 - f1: 0.6976 - val_loss: 0.2688 - val_f1: 0.0646\n",
      "Epoch 114/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3035 - f1: 0.6962 - val_loss: 0.2684 - val_f1: 0.0644\n",
      "Epoch 115/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.3044 - f1: 0.6960 - val_loss: 0.2687 - val_f1: 0.0645\n",
      "Epoch 116/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.3014 - f1: 0.6997 - val_loss: 0.2681 - val_f1: 0.0649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3004 - f1: 0.7002 - val_loss: 0.2711 - val_f1: 0.0655\n",
      "Epoch 118/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.3006 - f1: 0.6994 - val_loss: 0.2692 - val_f1: 0.0649\n",
      "Epoch 119/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3004 - f1: 0.7009 - val_loss: 0.2704 - val_f1: 0.0649\n",
      "Epoch 120/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.3003 - f1: 0.6995 - val_loss: 0.2693 - val_f1: 0.0642\n",
      "Epoch 121/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2988 - f1: 0.7014 - val_loss: 0.2679 - val_f1: 0.0640\n",
      "Epoch 122/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2978 - f1: 0.7052 - val_loss: 0.2689 - val_f1: 0.0642\n",
      "Epoch 123/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2971 - f1: 0.7050 - val_loss: 0.2679 - val_f1: 0.0639\n",
      "Epoch 124/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2969 - f1: 0.7060 - val_loss: 0.2684 - val_f1: 0.0642\n",
      "Epoch 125/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2963 - f1: 0.7029 - val_loss: 0.2701 - val_f1: 0.0645\n",
      "Epoch 126/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2949 - f1: 0.7077 - val_loss: 0.2697 - val_f1: 0.0641\n",
      "Epoch 127/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2951 - f1: 0.7092 - val_loss: 0.2699 - val_f1: 0.0643\n",
      "Epoch 128/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2952 - f1: 0.7070 - val_loss: 0.2691 - val_f1: 0.0640\n",
      "Epoch 129/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2950 - f1: 0.7092 - val_loss: 0.2700 - val_f1: 0.0642\n",
      "Epoch 130/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2937 - f1: 0.7101 - val_loss: 0.2706 - val_f1: 0.0642\n",
      "Epoch 131/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2940 - f1: 0.7089 - val_loss: 0.2694 - val_f1: 0.0642\n",
      "Epoch 132/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2918 - f1: 0.7113 - val_loss: 0.2705 - val_f1: 0.0642\n",
      "Epoch 133/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2918 - f1: 0.7131 - val_loss: 0.2692 - val_f1: 0.0639\n",
      "Epoch 134/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2935 - f1: 0.7098 - val_loss: 0.2703 - val_f1: 0.0644\n",
      "Epoch 135/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2898 - f1: 0.7141 - val_loss: 0.2710 - val_f1: 0.0644\n",
      "Epoch 136/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2906 - f1: 0.7128 - val_loss: 0.2706 - val_f1: 0.0644\n",
      "Epoch 137/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2908 - f1: 0.7136 - val_loss: 0.2690 - val_f1: 0.0637\n",
      "Epoch 138/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2903 - f1: 0.7139 - val_loss: 0.2694 - val_f1: 0.0635\n",
      "Epoch 139/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2905 - f1: 0.7128 - val_loss: 0.2691 - val_f1: 0.0635\n",
      "Epoch 140/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2900 - f1: 0.7146 - val_loss: 0.2701 - val_f1: 0.0639\n",
      "Epoch 141/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2896 - f1: 0.7161 - val_loss: 0.2703 - val_f1: 0.0640\n",
      "Epoch 142/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2884 - f1: 0.7171 - val_loss: 0.2691 - val_f1: 0.0633\n",
      "Epoch 143/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2874 - f1: 0.7160 - val_loss: 0.2698 - val_f1: 0.0636\n",
      "Epoch 144/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2860 - f1: 0.7196 - val_loss: 0.2710 - val_f1: 0.0639\n",
      "Epoch 145/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2863 - f1: 0.7196 - val_loss: 0.2702 - val_f1: 0.0635\n",
      "Epoch 146/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2875 - f1: 0.7172 - val_loss: 0.2730 - val_f1: 0.0638\n",
      "Epoch 147/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2859 - f1: 0.7180 - val_loss: 0.2720 - val_f1: 0.0635\n",
      "Epoch 148/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2857 - f1: 0.7189 - val_loss: 0.2714 - val_f1: 0.0637\n",
      "Epoch 149/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2832 - f1: 0.7216 - val_loss: 0.2712 - val_f1: 0.0636\n",
      "Epoch 150/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2842 - f1: 0.7233 - val_loss: 0.2697 - val_f1: 0.0633\n",
      "Epoch 151/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2832 - f1: 0.7220 - val_loss: 0.2728 - val_f1: 0.0640\n",
      "Epoch 152/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2840 - f1: 0.7204 - val_loss: 0.2714 - val_f1: 0.0637\n",
      "Epoch 153/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2822 - f1: 0.7247 - val_loss: 0.2722 - val_f1: 0.0633\n",
      "Epoch 154/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2826 - f1: 0.7235 - val_loss: 0.2725 - val_f1: 0.0633\n",
      "Epoch 155/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2829 - f1: 0.7229 - val_loss: 0.2718 - val_f1: 0.0635\n",
      "Epoch 156/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2818 - f1: 0.7235 - val_loss: 0.2721 - val_f1: 0.0634\n",
      "Epoch 157/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2805 - f1: 0.7275 - val_loss: 0.2721 - val_f1: 0.0636\n",
      "Epoch 158/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2824 - f1: 0.7223 - val_loss: 0.2723 - val_f1: 0.0633\n",
      "Epoch 159/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2797 - f1: 0.7274 - val_loss: 0.2739 - val_f1: 0.0637\n",
      "Epoch 160/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2789 - f1: 0.7273 - val_loss: 0.2727 - val_f1: 0.0632\n",
      "Epoch 161/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2801 - f1: 0.7262 - val_loss: 0.2724 - val_f1: 0.0632\n",
      "Epoch 162/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2800 - f1: 0.7251 - val_loss: 0.2718 - val_f1: 0.0624\n",
      "Epoch 163/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2793 - f1: 0.7286 - val_loss: 0.2724 - val_f1: 0.0628\n",
      "Epoch 164/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2797 - f1: 0.7275 - val_loss: 0.2739 - val_f1: 0.0634\n",
      "Epoch 165/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2792 - f1: 0.7261 - val_loss: 0.2729 - val_f1: 0.0631\n",
      "Epoch 166/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2776 - f1: 0.7284 - val_loss: 0.2714 - val_f1: 0.0625\n",
      "Epoch 167/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2777 - f1: 0.7295 - val_loss: 0.2721 - val_f1: 0.0626\n",
      "Epoch 168/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2760 - f1: 0.7304 - val_loss: 0.2730 - val_f1: 0.0627\n",
      "Epoch 169/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2781 - f1: 0.7284 - val_loss: 0.2730 - val_f1: 0.0629\n",
      "Epoch 170/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2751 - f1: 0.7307 - val_loss: 0.2719 - val_f1: 0.0621\n",
      "Epoch 171/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2777 - f1: 0.7300 - val_loss: 0.2744 - val_f1: 0.0633\n",
      "Epoch 172/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2757 - f1: 0.7296 - val_loss: 0.2744 - val_f1: 0.0632\n",
      "Epoch 173/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2768 - f1: 0.7315 - val_loss: 0.2737 - val_f1: 0.0630\n",
      "Epoch 174/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2752 - f1: 0.7311 - val_loss: 0.2746 - val_f1: 0.0634\n",
      "Epoch 175/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2754 - f1: 0.7327 - val_loss: 0.2734 - val_f1: 0.0627\n",
      "Epoch 176/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2733 - f1: 0.7346 - val_loss: 0.2741 - val_f1: 0.0627\n",
      "Epoch 177/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2729 - f1: 0.7340 - val_loss: 0.2745 - val_f1: 0.0631\n",
      "Epoch 178/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2733 - f1: 0.7348 - val_loss: 0.2735 - val_f1: 0.0623\n",
      "Epoch 179/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2719 - f1: 0.7366 - val_loss: 0.2742 - val_f1: 0.0628\n",
      "Epoch 180/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2730 - f1: 0.7348 - val_loss: 0.2741 - val_f1: 0.0629\n",
      "Epoch 181/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2742 - f1: 0.7316 - val_loss: 0.2738 - val_f1: 0.0624\n",
      "Epoch 182/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2731 - f1: 0.7358 - val_loss: 0.2750 - val_f1: 0.0626\n",
      "Epoch 183/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2740 - f1: 0.7310 - val_loss: 0.2752 - val_f1: 0.0632\n",
      "Epoch 184/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2719 - f1: 0.7363 - val_loss: 0.2730 - val_f1: 0.0622\n",
      "Epoch 185/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2723 - f1: 0.7348 - val_loss: 0.2731 - val_f1: 0.0620\n",
      "Epoch 186/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2727 - f1: 0.7333 - val_loss: 0.2765 - val_f1: 0.0632\n",
      "Epoch 187/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2722 - f1: 0.7349 - val_loss: 0.2742 - val_f1: 0.0628\n",
      "Epoch 188/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2693 - f1: 0.7408 - val_loss: 0.2749 - val_f1: 0.0629\n",
      "Epoch 189/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2708 - f1: 0.7377 - val_loss: 0.2749 - val_f1: 0.0625\n",
      "Epoch 190/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2697 - f1: 0.7389 - val_loss: 0.2746 - val_f1: 0.0625\n",
      "Epoch 191/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2696 - f1: 0.7376 - val_loss: 0.2753 - val_f1: 0.0628\n",
      "Epoch 192/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2687 - f1: 0.7374 - val_loss: 0.2760 - val_f1: 0.0632\n",
      "Epoch 193/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2689 - f1: 0.7365 - val_loss: 0.2754 - val_f1: 0.0624\n",
      "Epoch 194/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2690 - f1: 0.7408 - val_loss: 0.2752 - val_f1: 0.0623\n",
      "Epoch 195/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2691 - f1: 0.7389 - val_loss: 0.2758 - val_f1: 0.0626\n",
      "Epoch 196/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2681 - f1: 0.7399 - val_loss: 0.2755 - val_f1: 0.0629\n",
      "Epoch 197/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2695 - f1: 0.7395 - val_loss: 0.2767 - val_f1: 0.0628\n",
      "Epoch 198/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2676 - f1: 0.7409 - val_loss: 0.2764 - val_f1: 0.0623\n",
      "Epoch 199/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2683 - f1: 0.7407 - val_loss: 0.2769 - val_f1: 0.0629\n",
      "Epoch 200/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2667 - f1: 0.7425 - val_loss: 0.2752 - val_f1: 0.0618\n",
      "Epoch 201/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2675 - f1: 0.7383 - val_loss: 0.2763 - val_f1: 0.0624\n",
      "Epoch 202/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2670 - f1: 0.7403 - val_loss: 0.2755 - val_f1: 0.0624\n",
      "Epoch 203/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2678 - f1: 0.7401 - val_loss: 0.2761 - val_f1: 0.0626\n",
      "Epoch 204/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2663 - f1: 0.7420 - val_loss: 0.2764 - val_f1: 0.0628\n",
      "Epoch 205/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2671 - f1: 0.7403 - val_loss: 0.2746 - val_f1: 0.0618\n",
      "Epoch 206/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2662 - f1: 0.7410 - val_loss: 0.2763 - val_f1: 0.0627\n",
      "Epoch 207/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2659 - f1: 0.7411 - val_loss: 0.2768 - val_f1: 0.0627\n",
      "Epoch 208/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2658 - f1: 0.7439 - val_loss: 0.2751 - val_f1: 0.0619\n",
      "Epoch 209/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2646 - f1: 0.7446 - val_loss: 0.2770 - val_f1: 0.0629\n",
      "Epoch 210/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2648 - f1: 0.7433 - val_loss: 0.2769 - val_f1: 0.0622\n",
      "Epoch 211/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2639 - f1: 0.7445 - val_loss: 0.2761 - val_f1: 0.0622\n",
      "Epoch 212/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2628 - f1: 0.7484 - val_loss: 0.2766 - val_f1: 0.0624\n",
      "Epoch 213/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2653 - f1: 0.7437 - val_loss: 0.2764 - val_f1: 0.0621\n",
      "Epoch 214/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2631 - f1: 0.7451 - val_loss: 0.2770 - val_f1: 0.0623\n",
      "Epoch 215/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2643 - f1: 0.7440 - val_loss: 0.2769 - val_f1: 0.0621\n",
      "Epoch 216/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2632 - f1: 0.7463 - val_loss: 0.2766 - val_f1: 0.0620\n",
      "Epoch 217/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2635 - f1: 0.7459 - val_loss: 0.2768 - val_f1: 0.0621\n",
      "Epoch 218/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2625 - f1: 0.7456 - val_loss: 0.2771 - val_f1: 0.0623\n",
      "Epoch 219/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2649 - f1: 0.7423 - val_loss: 0.2778 - val_f1: 0.0625\n",
      "Epoch 220/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2623 - f1: 0.7468 - val_loss: 0.2778 - val_f1: 0.0626\n",
      "Epoch 221/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2635 - f1: 0.7448 - val_loss: 0.2764 - val_f1: 0.0623\n",
      "Epoch 222/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2621 - f1: 0.7479 - val_loss: 0.2776 - val_f1: 0.0621\n",
      "Epoch 223/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2608 - f1: 0.7486 - val_loss: 0.2766 - val_f1: 0.0617\n",
      "Epoch 224/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2600 - f1: 0.7501 - val_loss: 0.2772 - val_f1: 0.0618\n",
      "Epoch 225/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2617 - f1: 0.7483 - val_loss: 0.2776 - val_f1: 0.0623\n",
      "Epoch 226/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2623 - f1: 0.7441 - val_loss: 0.2775 - val_f1: 0.0622\n",
      "Epoch 227/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2602 - f1: 0.7503 - val_loss: 0.2773 - val_f1: 0.0619\n",
      "Epoch 228/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2593 - f1: 0.7503 - val_loss: 0.2783 - val_f1: 0.0620\n",
      "Epoch 229/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2597 - f1: 0.7495 - val_loss: 0.2783 - val_f1: 0.0618\n",
      "Epoch 230/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2606 - f1: 0.7486 - val_loss: 0.2776 - val_f1: 0.0619\n",
      "Epoch 231/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2603 - f1: 0.7499 - val_loss: 0.2790 - val_f1: 0.0620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2603 - f1: 0.7493 - val_loss: 0.2772 - val_f1: 0.0616\n",
      "Epoch 233/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2602 - f1: 0.7501 - val_loss: 0.2786 - val_f1: 0.0622\n",
      "Epoch 234/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2580 - f1: 0.7535 - val_loss: 0.2788 - val_f1: 0.0624\n",
      "Epoch 235/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2602 - f1: 0.7493 - val_loss: 0.2779 - val_f1: 0.0620\n",
      "Epoch 236/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2592 - f1: 0.7498 - val_loss: 0.2787 - val_f1: 0.0622\n",
      "Epoch 237/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2594 - f1: 0.7511 - val_loss: 0.2784 - val_f1: 0.0619\n",
      "Epoch 238/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2585 - f1: 0.7497 - val_loss: 0.2789 - val_f1: 0.0617\n",
      "Epoch 239/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2598 - f1: 0.7494 - val_loss: 0.2772 - val_f1: 0.0611\n",
      "Epoch 240/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2590 - f1: 0.7499 - val_loss: 0.2783 - val_f1: 0.0617\n",
      "Epoch 241/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2574 - f1: 0.7508 - val_loss: 0.2788 - val_f1: 0.0622\n",
      "Epoch 242/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2587 - f1: 0.7521 - val_loss: 0.2797 - val_f1: 0.0622\n",
      "Epoch 243/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2567 - f1: 0.7537 - val_loss: 0.2794 - val_f1: 0.0620\n",
      "Epoch 244/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2574 - f1: 0.7523 - val_loss: 0.2788 - val_f1: 0.0617\n",
      "Epoch 245/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2580 - f1: 0.7518 - val_loss: 0.2795 - val_f1: 0.0623\n",
      "Epoch 246/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2567 - f1: 0.7542 - val_loss: 0.2779 - val_f1: 0.0613\n",
      "Epoch 247/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2568 - f1: 0.7523 - val_loss: 0.2793 - val_f1: 0.0620\n",
      "Epoch 248/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2553 - f1: 0.7537 - val_loss: 0.2794 - val_f1: 0.0620\n",
      "Epoch 249/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2557 - f1: 0.7530 - val_loss: 0.2806 - val_f1: 0.0626\n",
      "Epoch 250/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2573 - f1: 0.7529 - val_loss: 0.2803 - val_f1: 0.0623\n",
      "Epoch 251/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2553 - f1: 0.7554 - val_loss: 0.2798 - val_f1: 0.0621\n",
      "Epoch 252/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2550 - f1: 0.7558 - val_loss: 0.2797 - val_f1: 0.0618\n",
      "Epoch 253/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2558 - f1: 0.7562 - val_loss: 0.2801 - val_f1: 0.0619\n",
      "Epoch 254/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2547 - f1: 0.7540 - val_loss: 0.2797 - val_f1: 0.0619\n",
      "Epoch 255/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2546 - f1: 0.7534 - val_loss: 0.2803 - val_f1: 0.0623\n",
      "Epoch 256/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2552 - f1: 0.7540 - val_loss: 0.2791 - val_f1: 0.0613\n",
      "Epoch 257/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2540 - f1: 0.7548 - val_loss: 0.2815 - val_f1: 0.0623\n",
      "Epoch 258/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2542 - f1: 0.7583 - val_loss: 0.2795 - val_f1: 0.0618\n",
      "Epoch 259/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2537 - f1: 0.7572 - val_loss: 0.2803 - val_f1: 0.0610\n",
      "Epoch 260/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2533 - f1: 0.7561 - val_loss: 0.2804 - val_f1: 0.0612\n",
      "Epoch 261/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2547 - f1: 0.7533 - val_loss: 0.2801 - val_f1: 0.0613\n",
      "Epoch 262/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2552 - f1: 0.7560 - val_loss: 0.2804 - val_f1: 0.0618\n",
      "Epoch 263/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2544 - f1: 0.7560 - val_loss: 0.2786 - val_f1: 0.0609\n",
      "Epoch 264/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2549 - f1: 0.7549 - val_loss: 0.2794 - val_f1: 0.0609\n",
      "Epoch 265/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2539 - f1: 0.7570 - val_loss: 0.2799 - val_f1: 0.0608\n",
      "Epoch 266/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2524 - f1: 0.7570 - val_loss: 0.2795 - val_f1: 0.0611\n",
      "Epoch 267/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2531 - f1: 0.7575 - val_loss: 0.2802 - val_f1: 0.0614\n",
      "Epoch 268/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2528 - f1: 0.7549 - val_loss: 0.2802 - val_f1: 0.0611\n",
      "Epoch 269/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2527 - f1: 0.7573 - val_loss: 0.2809 - val_f1: 0.0619\n",
      "Epoch 270/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2539 - f1: 0.7572 - val_loss: 0.2796 - val_f1: 0.0610\n",
      "Epoch 271/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2516 - f1: 0.7583 - val_loss: 0.2792 - val_f1: 0.0610\n",
      "Epoch 272/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2528 - f1: 0.7581 - val_loss: 0.2808 - val_f1: 0.0614\n",
      "Epoch 273/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2519 - f1: 0.7564 - val_loss: 0.2806 - val_f1: 0.0615\n",
      "Epoch 274/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2507 - f1: 0.7608 - val_loss: 0.2806 - val_f1: 0.0614\n",
      "Epoch 275/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2506 - f1: 0.7623 - val_loss: 0.2812 - val_f1: 0.0618\n",
      "Epoch 276/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2524 - f1: 0.7577 - val_loss: 0.2807 - val_f1: 0.0612\n",
      "Epoch 277/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2513 - f1: 0.7592 - val_loss: 0.2808 - val_f1: 0.0614\n",
      "Epoch 278/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2519 - f1: 0.7584 - val_loss: 0.2798 - val_f1: 0.0607\n",
      "Epoch 279/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2500 - f1: 0.7621 - val_loss: 0.2813 - val_f1: 0.0616\n",
      "Epoch 280/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2495 - f1: 0.7633 - val_loss: 0.2809 - val_f1: 0.0611\n",
      "Epoch 281/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2493 - f1: 0.7618 - val_loss: 0.2830 - val_f1: 0.0616\n",
      "Epoch 282/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2500 - f1: 0.7617 - val_loss: 0.2806 - val_f1: 0.0608\n",
      "Epoch 283/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2505 - f1: 0.7621 - val_loss: 0.2816 - val_f1: 0.0614\n",
      "Epoch 284/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2513 - f1: 0.7611 - val_loss: 0.2808 - val_f1: 0.0616\n",
      "Epoch 285/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2492 - f1: 0.7626 - val_loss: 0.2809 - val_f1: 0.0615\n",
      "Epoch 286/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2488 - f1: 0.7605 - val_loss: 0.2817 - val_f1: 0.0614\n",
      "Epoch 287/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2495 - f1: 0.7609 - val_loss: 0.2829 - val_f1: 0.0620\n",
      "Epoch 288/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2490 - f1: 0.7607 - val_loss: 0.2812 - val_f1: 0.0609\n",
      "Epoch 289/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2495 - f1: 0.7630 - val_loss: 0.2810 - val_f1: 0.0617\n",
      "Epoch 290/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2496 - f1: 0.7618 - val_loss: 0.2822 - val_f1: 0.0620\n",
      "Epoch 291/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2506 - f1: 0.7594 - val_loss: 0.2809 - val_f1: 0.0611\n",
      "Epoch 292/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2492 - f1: 0.7623 - val_loss: 0.2821 - val_f1: 0.0617\n",
      "Epoch 293/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2480 - f1: 0.7642 - val_loss: 0.2815 - val_f1: 0.0614\n",
      "Epoch 294/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2503 - f1: 0.7619 - val_loss: 0.2808 - val_f1: 0.0613\n",
      "Epoch 295/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2489 - f1: 0.7598 - val_loss: 0.2820 - val_f1: 0.0615\n",
      "Epoch 296/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2488 - f1: 0.7623 - val_loss: 0.2814 - val_f1: 0.0614\n",
      "Epoch 297/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2495 - f1: 0.7595 - val_loss: 0.2813 - val_f1: 0.0611\n",
      "Epoch 298/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2487 - f1: 0.7612 - val_loss: 0.2808 - val_f1: 0.0611\n",
      "Epoch 299/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2477 - f1: 0.7640 - val_loss: 0.2825 - val_f1: 0.0613\n",
      "Epoch 300/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2460 - f1: 0.7627 - val_loss: 0.2820 - val_f1: 0.0612\n",
      "Epoch 301/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2488 - f1: 0.7618 - val_loss: 0.2822 - val_f1: 0.0614\n",
      "Epoch 302/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2485 - f1: 0.7644 - val_loss: 0.2815 - val_f1: 0.0615\n",
      "Epoch 303/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2461 - f1: 0.7648 - val_loss: 0.2815 - val_f1: 0.0614\n",
      "Epoch 304/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2468 - f1: 0.7650 - val_loss: 0.2819 - val_f1: 0.0615\n",
      "Epoch 305/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2470 - f1: 0.7637 - val_loss: 0.2823 - val_f1: 0.0612\n",
      "Epoch 306/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2482 - f1: 0.7624 - val_loss: 0.2809 - val_f1: 0.0609\n",
      "Epoch 307/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2456 - f1: 0.7661 - val_loss: 0.2814 - val_f1: 0.0607\n",
      "Epoch 308/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2488 - f1: 0.7629 - val_loss: 0.2833 - val_f1: 0.0618\n",
      "Epoch 309/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2476 - f1: 0.7639 - val_loss: 0.2817 - val_f1: 0.0617\n",
      "Epoch 310/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2463 - f1: 0.7651 - val_loss: 0.2824 - val_f1: 0.0615\n",
      "Epoch 311/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2470 - f1: 0.7630 - val_loss: 0.2835 - val_f1: 0.0618\n",
      "Epoch 312/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2466 - f1: 0.7633 - val_loss: 0.2828 - val_f1: 0.0611\n",
      "Epoch 313/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2462 - f1: 0.7636 - val_loss: 0.2815 - val_f1: 0.0600\n",
      "Epoch 314/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2453 - f1: 0.7660 - val_loss: 0.2823 - val_f1: 0.0609\n",
      "Epoch 315/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2463 - f1: 0.7633 - val_loss: 0.2818 - val_f1: 0.0607\n",
      "Epoch 316/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2477 - f1: 0.7634 - val_loss: 0.2821 - val_f1: 0.0615\n",
      "Epoch 317/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2444 - f1: 0.7684 - val_loss: 0.2831 - val_f1: 0.0614\n",
      "Epoch 318/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2444 - f1: 0.7668 - val_loss: 0.2833 - val_f1: 0.0610\n",
      "Epoch 319/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2455 - f1: 0.7666 - val_loss: 0.2827 - val_f1: 0.0610\n",
      "Epoch 320/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2455 - f1: 0.7651 - val_loss: 0.2820 - val_f1: 0.0607\n",
      "Epoch 321/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2434 - f1: 0.7700 - val_loss: 0.2827 - val_f1: 0.0614\n",
      "Epoch 322/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2458 - f1: 0.7655 - val_loss: 0.2827 - val_f1: 0.0613\n",
      "Epoch 323/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2451 - f1: 0.7663 - val_loss: 0.2825 - val_f1: 0.0614\n",
      "Epoch 324/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2449 - f1: 0.7691 - val_loss: 0.2837 - val_f1: 0.0616\n",
      "Epoch 325/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2437 - f1: 0.7701 - val_loss: 0.2831 - val_f1: 0.0609\n",
      "Epoch 326/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2446 - f1: 0.7673 - val_loss: 0.2823 - val_f1: 0.0607\n",
      "Epoch 327/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2439 - f1: 0.7681 - val_loss: 0.2832 - val_f1: 0.0615\n",
      "Epoch 328/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2434 - f1: 0.7705 - val_loss: 0.2824 - val_f1: 0.0604\n",
      "Epoch 329/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2448 - f1: 0.7670 - val_loss: 0.2825 - val_f1: 0.0607\n",
      "Epoch 330/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2431 - f1: 0.7663 - val_loss: 0.2843 - val_f1: 0.0612\n",
      "Epoch 331/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2435 - f1: 0.7683 - val_loss: 0.2831 - val_f1: 0.0611\n",
      "Epoch 332/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2421 - f1: 0.7683 - val_loss: 0.2828 - val_f1: 0.0607\n",
      "Epoch 333/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2422 - f1: 0.7699 - val_loss: 0.2834 - val_f1: 0.0603\n",
      "Epoch 334/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2430 - f1: 0.7688 - val_loss: 0.2834 - val_f1: 0.0609\n",
      "Epoch 335/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2425 - f1: 0.7690 - val_loss: 0.2846 - val_f1: 0.0612\n",
      "Epoch 336/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2433 - f1: 0.7686 - val_loss: 0.2831 - val_f1: 0.0606\n",
      "Epoch 337/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2423 - f1: 0.7712 - val_loss: 0.2834 - val_f1: 0.0609\n",
      "Epoch 338/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2436 - f1: 0.7699 - val_loss: 0.2836 - val_f1: 0.0609\n",
      "Epoch 339/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2421 - f1: 0.7692 - val_loss: 0.2835 - val_f1: 0.0604\n",
      "Epoch 340/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2430 - f1: 0.7707 - val_loss: 0.2838 - val_f1: 0.0612\n",
      "Epoch 341/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2430 - f1: 0.7703 - val_loss: 0.2815 - val_f1: 0.0605\n",
      "Epoch 342/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2430 - f1: 0.7695 - val_loss: 0.2839 - val_f1: 0.0614\n",
      "Epoch 343/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2424 - f1: 0.7712 - val_loss: 0.2836 - val_f1: 0.0611\n",
      "Epoch 344/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2421 - f1: 0.7705 - val_loss: 0.2841 - val_f1: 0.0613\n",
      "Epoch 345/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2415 - f1: 0.7713 - val_loss: 0.2841 - val_f1: 0.0611\n",
      "Epoch 346/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2420 - f1: 0.7714 - val_loss: 0.2843 - val_f1: 0.0611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2426 - f1: 0.7698 - val_loss: 0.2842 - val_f1: 0.0612\n",
      "Epoch 348/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2442 - f1: 0.7663 - val_loss: 0.2846 - val_f1: 0.0614\n",
      "Epoch 349/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2430 - f1: 0.7686 - val_loss: 0.2823 - val_f1: 0.0604\n",
      "Epoch 350/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2421 - f1: 0.7693 - val_loss: 0.2837 - val_f1: 0.0608\n",
      "Epoch 351/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2415 - f1: 0.7692 - val_loss: 0.2846 - val_f1: 0.0612\n",
      "Epoch 352/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2416 - f1: 0.7695 - val_loss: 0.2840 - val_f1: 0.0611\n",
      "Epoch 353/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2400 - f1: 0.7718 - val_loss: 0.2835 - val_f1: 0.0605\n",
      "Epoch 354/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2406 - f1: 0.7721 - val_loss: 0.2852 - val_f1: 0.0613\n",
      "Epoch 355/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2414 - f1: 0.7723 - val_loss: 0.2849 - val_f1: 0.0614\n",
      "Epoch 356/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2427 - f1: 0.7687 - val_loss: 0.2850 - val_f1: 0.0610\n",
      "Epoch 357/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2417 - f1: 0.7700 - val_loss: 0.2839 - val_f1: 0.0607\n",
      "Epoch 358/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2397 - f1: 0.7720 - val_loss: 0.2847 - val_f1: 0.0613\n",
      "Epoch 359/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2399 - f1: 0.7723 - val_loss: 0.2836 - val_f1: 0.0607\n",
      "Epoch 360/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2400 - f1: 0.7709 - val_loss: 0.2840 - val_f1: 0.0605\n",
      "Epoch 361/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2408 - f1: 0.7705 - val_loss: 0.2852 - val_f1: 0.0614\n",
      "Epoch 362/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2400 - f1: 0.7737 - val_loss: 0.2840 - val_f1: 0.0612\n",
      "Epoch 363/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2416 - f1: 0.7703 - val_loss: 0.2843 - val_f1: 0.0609\n",
      "Epoch 364/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2405 - f1: 0.7727 - val_loss: 0.2840 - val_f1: 0.0603\n",
      "Epoch 365/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2392 - f1: 0.7743 - val_loss: 0.2846 - val_f1: 0.0609\n",
      "Epoch 366/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2384 - f1: 0.7754 - val_loss: 0.2843 - val_f1: 0.0607\n",
      "Epoch 367/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2391 - f1: 0.7721 - val_loss: 0.2859 - val_f1: 0.0610\n",
      "Epoch 368/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2420 - f1: 0.7720 - val_loss: 0.2844 - val_f1: 0.0608\n",
      "Epoch 369/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2401 - f1: 0.7737 - val_loss: 0.2845 - val_f1: 0.0605\n",
      "Epoch 370/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2384 - f1: 0.7749 - val_loss: 0.2844 - val_f1: 0.0602\n",
      "Epoch 371/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2393 - f1: 0.7728 - val_loss: 0.2857 - val_f1: 0.0611\n",
      "Epoch 372/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2390 - f1: 0.7739 - val_loss: 0.2856 - val_f1: 0.0610\n",
      "Epoch 373/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2394 - f1: 0.7724 - val_loss: 0.2854 - val_f1: 0.0610\n",
      "Epoch 374/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2383 - f1: 0.7755 - val_loss: 0.2848 - val_f1: 0.0609\n",
      "Epoch 375/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2399 - f1: 0.7717 - val_loss: 0.2853 - val_f1: 0.0612\n",
      "Epoch 376/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2390 - f1: 0.7742 - val_loss: 0.2853 - val_f1: 0.0610\n",
      "Epoch 377/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2388 - f1: 0.7741 - val_loss: 0.2857 - val_f1: 0.0609\n",
      "Epoch 378/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2392 - f1: 0.7714 - val_loss: 0.2860 - val_f1: 0.0611\n",
      "Epoch 379/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2390 - f1: 0.7742 - val_loss: 0.2847 - val_f1: 0.0606\n",
      "Epoch 380/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2367 - f1: 0.7763 - val_loss: 0.2854 - val_f1: 0.0602\n",
      "Epoch 381/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2372 - f1: 0.7749 - val_loss: 0.2864 - val_f1: 0.0608\n",
      "Epoch 382/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2381 - f1: 0.7746 - val_loss: 0.2860 - val_f1: 0.0610\n",
      "Epoch 383/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2382 - f1: 0.7750 - val_loss: 0.2866 - val_f1: 0.0611\n",
      "Epoch 384/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2364 - f1: 0.7756 - val_loss: 0.2860 - val_f1: 0.0615\n",
      "Epoch 385/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2379 - f1: 0.7747 - val_loss: 0.2868 - val_f1: 0.0614\n",
      "Epoch 386/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2380 - f1: 0.7755 - val_loss: 0.2854 - val_f1: 0.0608\n",
      "Epoch 387/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2392 - f1: 0.7732 - val_loss: 0.2845 - val_f1: 0.0606\n",
      "Epoch 388/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2367 - f1: 0.7756 - val_loss: 0.2864 - val_f1: 0.0607\n",
      "Epoch 389/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2365 - f1: 0.7761 - val_loss: 0.2859 - val_f1: 0.0611\n",
      "Epoch 390/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2359 - f1: 0.7767 - val_loss: 0.2870 - val_f1: 0.0610\n",
      "Epoch 391/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2359 - f1: 0.7775 - val_loss: 0.2860 - val_f1: 0.0602\n",
      "Epoch 392/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2372 - f1: 0.7747 - val_loss: 0.2862 - val_f1: 0.0609\n",
      "Epoch 393/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2372 - f1: 0.7754 - val_loss: 0.2861 - val_f1: 0.0611\n",
      "Epoch 394/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2367 - f1: 0.7754 - val_loss: 0.2862 - val_f1: 0.0610\n",
      "Epoch 395/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2378 - f1: 0.7750 - val_loss: 0.2859 - val_f1: 0.0608\n",
      "Epoch 396/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2377 - f1: 0.7762 - val_loss: 0.2853 - val_f1: 0.0606\n",
      "Epoch 397/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2355 - f1: 0.7756 - val_loss: 0.2868 - val_f1: 0.0616\n",
      "Epoch 398/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2370 - f1: 0.7780 - val_loss: 0.2857 - val_f1: 0.0607\n",
      "Epoch 399/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2372 - f1: 0.7759 - val_loss: 0.2868 - val_f1: 0.0608\n",
      "Epoch 400/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2366 - f1: 0.7775 - val_loss: 0.2868 - val_f1: 0.0608\n",
      "Epoch 401/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2357 - f1: 0.7771 - val_loss: 0.2866 - val_f1: 0.0608\n",
      "Epoch 402/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2376 - f1: 0.7747 - val_loss: 0.2857 - val_f1: 0.0611\n",
      "Epoch 403/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2373 - f1: 0.7745 - val_loss: 0.2860 - val_f1: 0.0609\n",
      "Epoch 404/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2358 - f1: 0.7786 - val_loss: 0.2864 - val_f1: 0.0608\n",
      "Epoch 405/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2349 - f1: 0.7773 - val_loss: 0.2857 - val_f1: 0.0600\n",
      "Epoch 406/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2357 - f1: 0.7781 - val_loss: 0.2865 - val_f1: 0.0610\n",
      "Epoch 407/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2355 - f1: 0.7780 - val_loss: 0.2868 - val_f1: 0.0611\n",
      "Epoch 408/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2350 - f1: 0.7780 - val_loss: 0.2861 - val_f1: 0.0608\n",
      "Epoch 409/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2353 - f1: 0.7793 - val_loss: 0.2868 - val_f1: 0.0610\n",
      "Epoch 410/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2343 - f1: 0.7783 - val_loss: 0.2870 - val_f1: 0.0609\n",
      "Epoch 411/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2339 - f1: 0.7782 - val_loss: 0.2864 - val_f1: 0.0609\n",
      "Epoch 412/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2359 - f1: 0.7771 - val_loss: 0.2860 - val_f1: 0.0602\n",
      "Epoch 413/2000\n",
      "168135/168135 [==============================] - 12s 69us/step - loss: 0.2353 - f1: 0.7755 - val_loss: 0.2866 - val_f1: 0.0609\n",
      "Epoch 414/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2353 - f1: 0.7759 - val_loss: 0.2867 - val_f1: 0.0610\n",
      "Epoch 415/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2347 - f1: 0.7783 - val_loss: 0.2867 - val_f1: 0.0603\n",
      "Epoch 416/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2348 - f1: 0.7791 - val_loss: 0.2858 - val_f1: 0.0603\n",
      "Epoch 417/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2340 - f1: 0.7795 - val_loss: 0.2872 - val_f1: 0.0610\n",
      "Epoch 418/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2358 - f1: 0.7774 - val_loss: 0.2869 - val_f1: 0.0609\n",
      "Epoch 419/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2352 - f1: 0.7779 - val_loss: 0.2874 - val_f1: 0.0607\n",
      "Epoch 420/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2340 - f1: 0.7785 - val_loss: 0.2870 - val_f1: 0.0607\n",
      "Epoch 421/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2338 - f1: 0.7809 - val_loss: 0.2870 - val_f1: 0.0606\n",
      "Epoch 422/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2334 - f1: 0.7798 - val_loss: 0.2866 - val_f1: 0.0602\n",
      "Epoch 423/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2346 - f1: 0.7782 - val_loss: 0.2872 - val_f1: 0.0610\n",
      "Epoch 424/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2321 - f1: 0.7819 - val_loss: 0.2880 - val_f1: 0.0608\n",
      "Epoch 425/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2347 - f1: 0.7799 - val_loss: 0.2864 - val_f1: 0.0600\n",
      "Epoch 426/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2339 - f1: 0.7786 - val_loss: 0.2870 - val_f1: 0.0607\n",
      "Epoch 427/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2368 - f1: 0.7761 - val_loss: 0.2872 - val_f1: 0.0610\n",
      "Epoch 428/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2334 - f1: 0.7796 - val_loss: 0.2870 - val_f1: 0.0605\n",
      "Epoch 429/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2326 - f1: 0.7813 - val_loss: 0.2879 - val_f1: 0.0610\n",
      "Epoch 430/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2332 - f1: 0.7787 - val_loss: 0.2874 - val_f1: 0.0602\n",
      "Epoch 431/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2317 - f1: 0.7821 - val_loss: 0.2877 - val_f1: 0.0606\n",
      "Epoch 432/2000\n",
      "168135/168135 [==============================] - 12s 68us/step - loss: 0.2329 - f1: 0.7788 - val_loss: 0.2879 - val_f1: 0.0607\n",
      "Epoch 433/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2349 - f1: 0.7793 - val_loss: 0.2866 - val_f1: 0.0603\n",
      "Epoch 434/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2342 - f1: 0.7786 - val_loss: 0.2881 - val_f1: 0.0604\n",
      "Epoch 435/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2337 - f1: 0.7783 - val_loss: 0.2871 - val_f1: 0.0598\n",
      "Epoch 436/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2322 - f1: 0.7799 - val_loss: 0.2868 - val_f1: 0.0603\n",
      "Epoch 437/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2328 - f1: 0.7805 - val_loss: 0.2883 - val_f1: 0.0608\n",
      "Epoch 438/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2327 - f1: 0.7805 - val_loss: 0.2872 - val_f1: 0.0605\n",
      "Epoch 439/2000\n",
      "168135/168135 [==============================] - 12s 72us/step - loss: 0.2332 - f1: 0.7787 - val_loss: 0.2874 - val_f1: 0.0603\n",
      "Epoch 440/2000\n",
      "168135/168135 [==============================] - 12s 74us/step - loss: 0.2338 - f1: 0.7795 - val_loss: 0.2888 - val_f1: 0.0611\n",
      "Epoch 441/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2329 - f1: 0.7817 - val_loss: 0.2872 - val_f1: 0.0603\n",
      "Epoch 442/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2340 - f1: 0.7781 - val_loss: 0.2881 - val_f1: 0.0603\n",
      "Epoch 443/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2329 - f1: 0.7786 - val_loss: 0.2869 - val_f1: 0.0603\n",
      "Epoch 444/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2332 - f1: 0.7793 - val_loss: 0.2874 - val_f1: 0.0604\n",
      "Epoch 445/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2310 - f1: 0.7829 - val_loss: 0.2888 - val_f1: 0.0607\n",
      "Epoch 446/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2323 - f1: 0.7824 - val_loss: 0.2882 - val_f1: 0.0605\n",
      "Epoch 447/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2317 - f1: 0.7825 - val_loss: 0.2879 - val_f1: 0.0602\n",
      "Epoch 448/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2324 - f1: 0.7815 - val_loss: 0.2878 - val_f1: 0.0602\n",
      "Epoch 449/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2315 - f1: 0.7815 - val_loss: 0.2874 - val_f1: 0.0596\n",
      "Epoch 450/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2325 - f1: 0.7826 - val_loss: 0.2886 - val_f1: 0.0606\n",
      "Epoch 451/2000\n",
      "168135/168135 [==============================] - 12s 73us/step - loss: 0.2338 - f1: 0.7789 - val_loss: 0.2881 - val_f1: 0.0607\n",
      "Epoch 452/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2303 - f1: 0.7829 - val_loss: 0.2886 - val_f1: 0.0608\n",
      "Epoch 453/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2311 - f1: 0.7816 - val_loss: 0.2877 - val_f1: 0.0597\n",
      "Epoch 454/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2311 - f1: 0.7815 - val_loss: 0.2886 - val_f1: 0.0602\n",
      "Epoch 455/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2327 - f1: 0.7791 - val_loss: 0.2884 - val_f1: 0.0604\n",
      "Epoch 456/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2316 - f1: 0.7829 - val_loss: 0.2879 - val_f1: 0.0605\n",
      "Epoch 457/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2324 - f1: 0.7816 - val_loss: 0.2885 - val_f1: 0.0606\n",
      "Epoch 458/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2314 - f1: 0.7824 - val_loss: 0.2891 - val_f1: 0.0608\n",
      "Epoch 459/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2315 - f1: 0.7797 - val_loss: 0.2885 - val_f1: 0.0605\n",
      "Epoch 460/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2329 - f1: 0.7802 - val_loss: 0.2881 - val_f1: 0.0608\n",
      "Epoch 461/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2309 - f1: 0.7833 - val_loss: 0.2885 - val_f1: 0.0606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2335 - f1: 0.7803 - val_loss: 0.2870 - val_f1: 0.0600\n",
      "Epoch 463/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2306 - f1: 0.7828 - val_loss: 0.2889 - val_f1: 0.0604\n",
      "Epoch 464/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2317 - f1: 0.7809 - val_loss: 0.2888 - val_f1: 0.0607\n",
      "Epoch 465/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2310 - f1: 0.7846 - val_loss: 0.2890 - val_f1: 0.0612\n",
      "Epoch 466/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2315 - f1: 0.7802 - val_loss: 0.2879 - val_f1: 0.0602\n",
      "Epoch 467/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2298 - f1: 0.7847 - val_loss: 0.2889 - val_f1: 0.0607\n",
      "Epoch 468/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2314 - f1: 0.7824 - val_loss: 0.2893 - val_f1: 0.0605\n",
      "Epoch 469/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2304 - f1: 0.7836 - val_loss: 0.2885 - val_f1: 0.0604\n",
      "Epoch 470/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2287 - f1: 0.7847 - val_loss: 0.2884 - val_f1: 0.0604\n",
      "Epoch 471/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2305 - f1: 0.7832 - val_loss: 0.2892 - val_f1: 0.0604\n",
      "Epoch 472/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2307 - f1: 0.7853 - val_loss: 0.2888 - val_f1: 0.0604\n",
      "Epoch 473/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2318 - f1: 0.7825 - val_loss: 0.2894 - val_f1: 0.0608\n",
      "Epoch 474/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2311 - f1: 0.7823 - val_loss: 0.2896 - val_f1: 0.0608\n",
      "Epoch 475/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2303 - f1: 0.7824 - val_loss: 0.2896 - val_f1: 0.0608\n",
      "Epoch 476/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2295 - f1: 0.7850 - val_loss: 0.2896 - val_f1: 0.0606\n",
      "Epoch 477/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2295 - f1: 0.7852 - val_loss: 0.2905 - val_f1: 0.0609\n",
      "Epoch 478/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2293 - f1: 0.7840 - val_loss: 0.2891 - val_f1: 0.0600\n",
      "Epoch 479/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2307 - f1: 0.7826 - val_loss: 0.2901 - val_f1: 0.0608\n",
      "Epoch 480/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2301 - f1: 0.7847 - val_loss: 0.2892 - val_f1: 0.0604\n",
      "Epoch 481/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2304 - f1: 0.7836 - val_loss: 0.2886 - val_f1: 0.0602\n",
      "Epoch 482/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2308 - f1: 0.7838 - val_loss: 0.2884 - val_f1: 0.0603\n",
      "Epoch 483/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2302 - f1: 0.7825 - val_loss: 0.2888 - val_f1: 0.0603\n",
      "Epoch 484/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2290 - f1: 0.7857 - val_loss: 0.2890 - val_f1: 0.0599\n",
      "Epoch 485/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2302 - f1: 0.7816 - val_loss: 0.2897 - val_f1: 0.0604\n",
      "Epoch 486/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2288 - f1: 0.7863 - val_loss: 0.2903 - val_f1: 0.0604\n",
      "Epoch 487/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2303 - f1: 0.7842 - val_loss: 0.2888 - val_f1: 0.0596\n",
      "Epoch 488/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2297 - f1: 0.7826 - val_loss: 0.2899 - val_f1: 0.0607\n",
      "Epoch 489/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2285 - f1: 0.7864 - val_loss: 0.2896 - val_f1: 0.0603\n",
      "Epoch 490/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2291 - f1: 0.7849 - val_loss: 0.2902 - val_f1: 0.0604\n",
      "Epoch 491/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2287 - f1: 0.7835 - val_loss: 0.2908 - val_f1: 0.0605\n",
      "Epoch 492/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2300 - f1: 0.7829 - val_loss: 0.2902 - val_f1: 0.0608\n",
      "Epoch 493/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2289 - f1: 0.7846 - val_loss: 0.2906 - val_f1: 0.0608\n",
      "Epoch 494/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2296 - f1: 0.7825 - val_loss: 0.2895 - val_f1: 0.0601\n",
      "Epoch 495/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2278 - f1: 0.7871 - val_loss: 0.2908 - val_f1: 0.0607\n",
      "Epoch 496/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2275 - f1: 0.7881 - val_loss: 0.2900 - val_f1: 0.0600\n",
      "Epoch 497/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2298 - f1: 0.7830 - val_loss: 0.2904 - val_f1: 0.0610\n",
      "Epoch 498/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2292 - f1: 0.7835 - val_loss: 0.2898 - val_f1: 0.0596\n",
      "Epoch 499/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2287 - f1: 0.7835 - val_loss: 0.2907 - val_f1: 0.0605\n",
      "Epoch 500/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2276 - f1: 0.7855 - val_loss: 0.2900 - val_f1: 0.0601\n",
      "Epoch 501/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2294 - f1: 0.7850 - val_loss: 0.2904 - val_f1: 0.0603\n",
      "Epoch 502/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2273 - f1: 0.7873 - val_loss: 0.2906 - val_f1: 0.0606\n",
      "Epoch 503/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2269 - f1: 0.7858 - val_loss: 0.2908 - val_f1: 0.0603\n",
      "Epoch 504/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2271 - f1: 0.7885 - val_loss: 0.2905 - val_f1: 0.0602\n",
      "Epoch 505/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2288 - f1: 0.7844 - val_loss: 0.2908 - val_f1: 0.0612\n",
      "Epoch 506/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2271 - f1: 0.7890 - val_loss: 0.2904 - val_f1: 0.0605\n",
      "Epoch 507/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2265 - f1: 0.7878 - val_loss: 0.2910 - val_f1: 0.0603\n",
      "Epoch 508/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2266 - f1: 0.7876 - val_loss: 0.2913 - val_f1: 0.0604\n",
      "Epoch 509/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2269 - f1: 0.7873 - val_loss: 0.2906 - val_f1: 0.0601\n",
      "Epoch 510/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2294 - f1: 0.7846 - val_loss: 0.2903 - val_f1: 0.0603\n",
      "Epoch 511/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2279 - f1: 0.7882 - val_loss: 0.2914 - val_f1: 0.0609\n",
      "Epoch 512/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2275 - f1: 0.7864 - val_loss: 0.2905 - val_f1: 0.0598\n",
      "Epoch 513/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2280 - f1: 0.7860 - val_loss: 0.2908 - val_f1: 0.0610\n",
      "Epoch 514/2000\n",
      "168135/168135 [==============================] - 12s 68us/step - loss: 0.2302 - f1: 0.7839 - val_loss: 0.2900 - val_f1: 0.0604\n",
      "Epoch 515/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2288 - f1: 0.7852 - val_loss: 0.2902 - val_f1: 0.0605\n",
      "Epoch 516/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2265 - f1: 0.7880 - val_loss: 0.2904 - val_f1: 0.0600\n",
      "Epoch 517/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2273 - f1: 0.7845 - val_loss: 0.2903 - val_f1: 0.0601\n",
      "Epoch 518/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2270 - f1: 0.7872 - val_loss: 0.2911 - val_f1: 0.0604\n",
      "Epoch 519/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2266 - f1: 0.7888 - val_loss: 0.2903 - val_f1: 0.0600\n",
      "Epoch 520/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2271 - f1: 0.7871 - val_loss: 0.2902 - val_f1: 0.0598\n",
      "Epoch 521/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2270 - f1: 0.7861 - val_loss: 0.2909 - val_f1: 0.0600\n",
      "Epoch 522/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2271 - f1: 0.7844 - val_loss: 0.2904 - val_f1: 0.0603\n",
      "Epoch 523/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2262 - f1: 0.7890 - val_loss: 0.2918 - val_f1: 0.0609\n",
      "Epoch 524/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2278 - f1: 0.7841 - val_loss: 0.2916 - val_f1: 0.0607\n",
      "Epoch 525/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2267 - f1: 0.7876 - val_loss: 0.2913 - val_f1: 0.0606\n",
      "Epoch 526/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2280 - f1: 0.7852 - val_loss: 0.2905 - val_f1: 0.0601\n",
      "Epoch 527/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2281 - f1: 0.7861 - val_loss: 0.2900 - val_f1: 0.0602\n",
      "Epoch 528/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2274 - f1: 0.7863 - val_loss: 0.2907 - val_f1: 0.0605\n",
      "Epoch 529/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2261 - f1: 0.7877 - val_loss: 0.2912 - val_f1: 0.0605\n",
      "Epoch 530/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2270 - f1: 0.7869 - val_loss: 0.2914 - val_f1: 0.0601\n",
      "Epoch 531/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2267 - f1: 0.7896 - val_loss: 0.2914 - val_f1: 0.0601\n",
      "Epoch 532/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2268 - f1: 0.7856 - val_loss: 0.2909 - val_f1: 0.0599\n",
      "Epoch 533/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2276 - f1: 0.7854 - val_loss: 0.2908 - val_f1: 0.0602\n",
      "Epoch 534/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2262 - f1: 0.7871 - val_loss: 0.2915 - val_f1: 0.0610\n",
      "Epoch 535/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2247 - f1: 0.7894 - val_loss: 0.2907 - val_f1: 0.0600\n",
      "Epoch 536/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2261 - f1: 0.7873 - val_loss: 0.2915 - val_f1: 0.0603\n",
      "Epoch 537/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2265 - f1: 0.7872 - val_loss: 0.2897 - val_f1: 0.0592\n",
      "Epoch 538/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2274 - f1: 0.7832 - val_loss: 0.2910 - val_f1: 0.0606\n",
      "Epoch 539/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2263 - f1: 0.7877 - val_loss: 0.2916 - val_f1: 0.0605\n",
      "Epoch 540/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2252 - f1: 0.7897 - val_loss: 0.2909 - val_f1: 0.0601\n",
      "Epoch 541/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2255 - f1: 0.7886 - val_loss: 0.2919 - val_f1: 0.0604\n",
      "Epoch 542/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2245 - f1: 0.7898 - val_loss: 0.2914 - val_f1: 0.0602\n",
      "Epoch 543/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2279 - f1: 0.7864 - val_loss: 0.2917 - val_f1: 0.0606\n",
      "Epoch 544/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2252 - f1: 0.7908 - val_loss: 0.2924 - val_f1: 0.0606\n",
      "Epoch 545/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2262 - f1: 0.7889 - val_loss: 0.2904 - val_f1: 0.0601\n",
      "Epoch 546/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2260 - f1: 0.7877 - val_loss: 0.2913 - val_f1: 0.0605\n",
      "Epoch 547/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2260 - f1: 0.7886 - val_loss: 0.2908 - val_f1: 0.0601\n",
      "Epoch 548/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2254 - f1: 0.7887 - val_loss: 0.2913 - val_f1: 0.0602\n",
      "Epoch 549/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2272 - f1: 0.7890 - val_loss: 0.2906 - val_f1: 0.0603\n",
      "Epoch 550/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2257 - f1: 0.7888 - val_loss: 0.2908 - val_f1: 0.0604\n",
      "Epoch 551/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2262 - f1: 0.7847 - val_loss: 0.2917 - val_f1: 0.0599\n",
      "Epoch 552/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2242 - f1: 0.7896 - val_loss: 0.2910 - val_f1: 0.0593\n",
      "Epoch 553/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2251 - f1: 0.7882 - val_loss: 0.2902 - val_f1: 0.0601\n",
      "Epoch 554/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2260 - f1: 0.7869 - val_loss: 0.2916 - val_f1: 0.0605\n",
      "Epoch 555/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2257 - f1: 0.7895 - val_loss: 0.2915 - val_f1: 0.0602\n",
      "Epoch 556/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2254 - f1: 0.7888 - val_loss: 0.2921 - val_f1: 0.0601\n",
      "Epoch 557/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2256 - f1: 0.7882 - val_loss: 0.2923 - val_f1: 0.0605\n",
      "Epoch 558/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2242 - f1: 0.7901 - val_loss: 0.2916 - val_f1: 0.0602\n",
      "Epoch 559/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2243 - f1: 0.7900 - val_loss: 0.2915 - val_f1: 0.0603\n",
      "Epoch 560/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2253 - f1: 0.7882 - val_loss: 0.2916 - val_f1: 0.0601\n",
      "Epoch 561/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2237 - f1: 0.7905 - val_loss: 0.2931 - val_f1: 0.0612\n",
      "Epoch 562/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2253 - f1: 0.7879 - val_loss: 0.2924 - val_f1: 0.0602\n",
      "Epoch 563/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2237 - f1: 0.7926 - val_loss: 0.2925 - val_f1: 0.0608\n",
      "Epoch 564/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2241 - f1: 0.7918 - val_loss: 0.2919 - val_f1: 0.0599\n",
      "Epoch 565/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2258 - f1: 0.7874 - val_loss: 0.2915 - val_f1: 0.0606\n",
      "Epoch 566/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2256 - f1: 0.7894 - val_loss: 0.2916 - val_f1: 0.0607\n",
      "Epoch 567/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2234 - f1: 0.7893 - val_loss: 0.2926 - val_f1: 0.0603\n",
      "Epoch 568/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2237 - f1: 0.7913 - val_loss: 0.2923 - val_f1: 0.0603\n",
      "Epoch 569/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2231 - f1: 0.7907 - val_loss: 0.2925 - val_f1: 0.0602\n",
      "Epoch 570/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2237 - f1: 0.7898 - val_loss: 0.2923 - val_f1: 0.0600\n",
      "Epoch 571/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2228 - f1: 0.7908 - val_loss: 0.2929 - val_f1: 0.0602\n",
      "Epoch 572/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2230 - f1: 0.7898 - val_loss: 0.2933 - val_f1: 0.0602\n",
      "Epoch 573/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2262 - f1: 0.7872 - val_loss: 0.2917 - val_f1: 0.0606\n",
      "Epoch 574/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2259 - f1: 0.7892 - val_loss: 0.2917 - val_f1: 0.0601\n",
      "Epoch 575/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2253 - f1: 0.7873 - val_loss: 0.2923 - val_f1: 0.0606\n",
      "Epoch 576/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2245 - f1: 0.7895 - val_loss: 0.2924 - val_f1: 0.0601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2228 - f1: 0.7897 - val_loss: 0.2933 - val_f1: 0.0605\n",
      "Epoch 578/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2227 - f1: 0.7924 - val_loss: 0.2929 - val_f1: 0.0598\n",
      "Epoch 579/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2240 - f1: 0.7897 - val_loss: 0.2925 - val_f1: 0.0599\n",
      "Epoch 580/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2242 - f1: 0.7899 - val_loss: 0.2927 - val_f1: 0.0609\n",
      "Epoch 581/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2253 - f1: 0.7885 - val_loss: 0.2931 - val_f1: 0.0608\n",
      "Epoch 582/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2219 - f1: 0.7916 - val_loss: 0.2928 - val_f1: 0.0603\n",
      "Epoch 583/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2248 - f1: 0.7896 - val_loss: 0.2923 - val_f1: 0.0605\n",
      "Epoch 584/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2230 - f1: 0.7917 - val_loss: 0.2922 - val_f1: 0.0601\n",
      "Epoch 585/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2226 - f1: 0.7920 - val_loss: 0.2931 - val_f1: 0.0603\n",
      "Epoch 586/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2237 - f1: 0.7925 - val_loss: 0.2934 - val_f1: 0.0601\n",
      "Epoch 587/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2219 - f1: 0.7914 - val_loss: 0.2920 - val_f1: 0.0604\n",
      "Epoch 588/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2222 - f1: 0.7923 - val_loss: 0.2930 - val_f1: 0.0603\n",
      "Epoch 589/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2218 - f1: 0.7930 - val_loss: 0.2930 - val_f1: 0.0599\n",
      "Epoch 590/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2216 - f1: 0.7927 - val_loss: 0.2932 - val_f1: 0.0601\n",
      "Epoch 591/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2231 - f1: 0.7913 - val_loss: 0.2935 - val_f1: 0.0605\n",
      "Epoch 592/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2229 - f1: 0.7936 - val_loss: 0.2932 - val_f1: 0.0600\n",
      "Epoch 593/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2226 - f1: 0.7913 - val_loss: 0.2934 - val_f1: 0.0604\n",
      "Epoch 594/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2228 - f1: 0.7923 - val_loss: 0.2942 - val_f1: 0.0603\n",
      "Epoch 595/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2240 - f1: 0.7923 - val_loss: 0.2927 - val_f1: 0.0603\n",
      "Epoch 596/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2214 - f1: 0.7939 - val_loss: 0.2942 - val_f1: 0.0609\n",
      "Epoch 597/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2232 - f1: 0.7899 - val_loss: 0.2930 - val_f1: 0.0600\n",
      "Epoch 598/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2207 - f1: 0.7932 - val_loss: 0.2937 - val_f1: 0.0607\n",
      "Epoch 599/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2224 - f1: 0.7911 - val_loss: 0.2934 - val_f1: 0.0606\n",
      "Epoch 600/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2214 - f1: 0.7942 - val_loss: 0.2939 - val_f1: 0.0597\n",
      "Epoch 601/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2216 - f1: 0.7934 - val_loss: 0.2931 - val_f1: 0.0596\n",
      "Epoch 602/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2228 - f1: 0.7897 - val_loss: 0.2929 - val_f1: 0.0606\n",
      "Epoch 603/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2221 - f1: 0.7943 - val_loss: 0.2925 - val_f1: 0.0599\n",
      "Epoch 604/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2221 - f1: 0.7925 - val_loss: 0.2931 - val_f1: 0.0601\n",
      "Epoch 605/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2239 - f1: 0.7902 - val_loss: 0.2923 - val_f1: 0.0600\n",
      "Epoch 606/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2225 - f1: 0.7912 - val_loss: 0.2933 - val_f1: 0.0602\n",
      "Epoch 607/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2204 - f1: 0.7953 - val_loss: 0.2939 - val_f1: 0.0600\n",
      "Epoch 608/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2238 - f1: 0.7904 - val_loss: 0.2931 - val_f1: 0.0608\n",
      "Epoch 609/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2230 - f1: 0.7903 - val_loss: 0.2925 - val_f1: 0.0601\n",
      "Epoch 610/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2218 - f1: 0.7934 - val_loss: 0.2931 - val_f1: 0.0602\n",
      "Epoch 611/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2222 - f1: 0.7924 - val_loss: 0.2926 - val_f1: 0.0598\n",
      "Epoch 612/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2207 - f1: 0.7962 - val_loss: 0.2933 - val_f1: 0.0605\n",
      "Epoch 613/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2232 - f1: 0.7916 - val_loss: 0.2932 - val_f1: 0.0602\n",
      "Epoch 614/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2224 - f1: 0.7907 - val_loss: 0.2927 - val_f1: 0.0599\n",
      "Epoch 615/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2218 - f1: 0.7931 - val_loss: 0.2929 - val_f1: 0.0600\n",
      "Epoch 616/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2216 - f1: 0.7909 - val_loss: 0.2928 - val_f1: 0.0601\n",
      "Epoch 617/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2234 - f1: 0.7907 - val_loss: 0.2940 - val_f1: 0.0611\n",
      "Epoch 618/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2204 - f1: 0.7938 - val_loss: 0.2933 - val_f1: 0.0599\n",
      "Epoch 619/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2226 - f1: 0.7919 - val_loss: 0.2932 - val_f1: 0.0599\n",
      "Epoch 620/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2244 - f1: 0.7894 - val_loss: 0.2925 - val_f1: 0.0599\n",
      "Epoch 621/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2226 - f1: 0.7911 - val_loss: 0.2926 - val_f1: 0.0601\n",
      "Epoch 622/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2220 - f1: 0.7916 - val_loss: 0.2925 - val_f1: 0.0603\n",
      "Epoch 623/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2206 - f1: 0.7926 - val_loss: 0.2936 - val_f1: 0.0595\n",
      "Epoch 624/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2193 - f1: 0.7942 - val_loss: 0.2926 - val_f1: 0.0600\n",
      "Epoch 625/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2228 - f1: 0.7907 - val_loss: 0.2934 - val_f1: 0.0601\n",
      "Epoch 626/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2206 - f1: 0.7956 - val_loss: 0.2944 - val_f1: 0.0600\n",
      "Epoch 627/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2212 - f1: 0.7930 - val_loss: 0.2946 - val_f1: 0.0604\n",
      "Epoch 628/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2217 - f1: 0.7930 - val_loss: 0.2942 - val_f1: 0.0600\n",
      "Epoch 629/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2221 - f1: 0.7920 - val_loss: 0.2932 - val_f1: 0.0598\n",
      "Epoch 630/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2202 - f1: 0.7943 - val_loss: 0.2941 - val_f1: 0.0601\n",
      "Epoch 631/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2192 - f1: 0.7959 - val_loss: 0.2940 - val_f1: 0.0597\n",
      "Epoch 632/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2221 - f1: 0.7932 - val_loss: 0.2948 - val_f1: 0.0604\n",
      "Epoch 633/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2197 - f1: 0.7946 - val_loss: 0.2942 - val_f1: 0.0598\n",
      "Epoch 634/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2217 - f1: 0.7934 - val_loss: 0.2933 - val_f1: 0.0595\n",
      "Epoch 635/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2208 - f1: 0.7943 - val_loss: 0.2937 - val_f1: 0.0599\n",
      "Epoch 636/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2217 - f1: 0.7950 - val_loss: 0.2944 - val_f1: 0.0602\n",
      "Epoch 637/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2204 - f1: 0.7958 - val_loss: 0.2941 - val_f1: 0.0602\n",
      "Epoch 638/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2235 - f1: 0.7903 - val_loss: 0.2936 - val_f1: 0.0599\n",
      "Epoch 639/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2200 - f1: 0.7931 - val_loss: 0.2939 - val_f1: 0.0599\n",
      "Epoch 640/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2211 - f1: 0.7927 - val_loss: 0.2935 - val_f1: 0.0595\n",
      "Epoch 641/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2208 - f1: 0.7939 - val_loss: 0.2938 - val_f1: 0.0594\n",
      "Epoch 642/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2207 - f1: 0.7943 - val_loss: 0.2942 - val_f1: 0.0604\n",
      "Epoch 643/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2188 - f1: 0.7954 - val_loss: 0.2942 - val_f1: 0.0600\n",
      "Epoch 644/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2204 - f1: 0.7944 - val_loss: 0.2944 - val_f1: 0.0597\n",
      "Epoch 645/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2201 - f1: 0.7965 - val_loss: 0.2941 - val_f1: 0.0605\n",
      "Epoch 646/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2208 - f1: 0.7954 - val_loss: 0.2945 - val_f1: 0.0598\n",
      "Epoch 647/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2209 - f1: 0.7929 - val_loss: 0.2943 - val_f1: 0.0600\n",
      "Epoch 648/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2212 - f1: 0.7937 - val_loss: 0.2944 - val_f1: 0.0605\n",
      "Epoch 649/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2202 - f1: 0.7956 - val_loss: 0.2947 - val_f1: 0.0602\n",
      "Epoch 650/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2195 - f1: 0.7958 - val_loss: 0.2949 - val_f1: 0.0602\n",
      "Epoch 651/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2195 - f1: 0.7952 - val_loss: 0.2954 - val_f1: 0.0606\n",
      "Epoch 652/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2192 - f1: 0.7959 - val_loss: 0.2947 - val_f1: 0.0600\n",
      "Epoch 653/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2200 - f1: 0.7939 - val_loss: 0.2948 - val_f1: 0.0597\n",
      "Epoch 654/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2190 - f1: 0.7963 - val_loss: 0.2949 - val_f1: 0.0605\n",
      "Epoch 655/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2202 - f1: 0.7956 - val_loss: 0.2944 - val_f1: 0.0597\n",
      "Epoch 656/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2184 - f1: 0.7961 - val_loss: 0.2946 - val_f1: 0.0602\n",
      "Epoch 657/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2193 - f1: 0.7938 - val_loss: 0.2947 - val_f1: 0.0606\n",
      "Epoch 658/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2199 - f1: 0.7949 - val_loss: 0.2949 - val_f1: 0.0603\n",
      "Epoch 659/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2199 - f1: 0.7960 - val_loss: 0.2948 - val_f1: 0.0602\n",
      "Epoch 660/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2180 - f1: 0.7967 - val_loss: 0.2950 - val_f1: 0.0600\n",
      "Epoch 661/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2183 - f1: 0.7973 - val_loss: 0.2954 - val_f1: 0.0602\n",
      "Epoch 662/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2212 - f1: 0.7921 - val_loss: 0.2940 - val_f1: 0.0599\n",
      "Epoch 663/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2179 - f1: 0.7962 - val_loss: 0.2937 - val_f1: 0.0593\n",
      "Epoch 664/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2200 - f1: 0.7935 - val_loss: 0.2942 - val_f1: 0.0600\n",
      "Epoch 665/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2187 - f1: 0.7941 - val_loss: 0.2948 - val_f1: 0.0600\n",
      "Epoch 666/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2185 - f1: 0.7989 - val_loss: 0.2949 - val_f1: 0.0599\n",
      "Epoch 667/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2183 - f1: 0.7962 - val_loss: 0.2952 - val_f1: 0.0602\n",
      "Epoch 668/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2183 - f1: 0.7974 - val_loss: 0.2949 - val_f1: 0.0598\n",
      "Epoch 669/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2187 - f1: 0.7965 - val_loss: 0.2948 - val_f1: 0.0596\n",
      "Epoch 670/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2182 - f1: 0.7967 - val_loss: 0.2958 - val_f1: 0.0600\n",
      "Epoch 671/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2198 - f1: 0.7964 - val_loss: 0.2954 - val_f1: 0.0600\n",
      "Epoch 672/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2187 - f1: 0.7953 - val_loss: 0.2959 - val_f1: 0.0597\n",
      "Epoch 673/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2184 - f1: 0.7959 - val_loss: 0.2961 - val_f1: 0.0601\n",
      "Epoch 674/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2193 - f1: 0.7947 - val_loss: 0.2951 - val_f1: 0.0594\n",
      "Epoch 675/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2205 - f1: 0.7954 - val_loss: 0.2954 - val_f1: 0.0604\n",
      "Epoch 676/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2180 - f1: 0.7963 - val_loss: 0.2956 - val_f1: 0.0598\n",
      "Epoch 677/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2184 - f1: 0.7965 - val_loss: 0.2951 - val_f1: 0.0605\n",
      "Epoch 678/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2183 - f1: 0.7969 - val_loss: 0.2953 - val_f1: 0.0595\n",
      "Epoch 679/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2187 - f1: 0.7944 - val_loss: 0.2949 - val_f1: 0.0599\n",
      "Epoch 680/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2185 - f1: 0.7961 - val_loss: 0.2961 - val_f1: 0.0598\n",
      "Epoch 681/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2174 - f1: 0.7994 - val_loss: 0.2961 - val_f1: 0.0601\n",
      "Epoch 682/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2192 - f1: 0.7942 - val_loss: 0.2952 - val_f1: 0.0602\n",
      "Epoch 683/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2178 - f1: 0.7965 - val_loss: 0.2951 - val_f1: 0.0601\n",
      "Epoch 684/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2182 - f1: 0.7970 - val_loss: 0.2952 - val_f1: 0.0597\n",
      "Epoch 685/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2188 - f1: 0.7943 - val_loss: 0.2962 - val_f1: 0.0604\n",
      "Epoch 686/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2203 - f1: 0.7948 - val_loss: 0.2953 - val_f1: 0.0602\n",
      "Epoch 687/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2191 - f1: 0.7963 - val_loss: 0.2947 - val_f1: 0.0594\n",
      "Epoch 688/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2187 - f1: 0.7990 - val_loss: 0.2951 - val_f1: 0.0594\n",
      "Epoch 689/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2179 - f1: 0.7958 - val_loss: 0.2959 - val_f1: 0.0598\n",
      "Epoch 690/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2178 - f1: 0.7976 - val_loss: 0.2956 - val_f1: 0.0602\n",
      "Epoch 691/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2193 - f1: 0.7956 - val_loss: 0.2960 - val_f1: 0.0607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2188 - f1: 0.7945 - val_loss: 0.2952 - val_f1: 0.0605\n",
      "Epoch 693/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2181 - f1: 0.7972 - val_loss: 0.2954 - val_f1: 0.0602\n",
      "Epoch 694/2000\n",
      "168135/168135 [==============================] - 11s 62us/step - loss: 0.2167 - f1: 0.7971 - val_loss: 0.2949 - val_f1: 0.0597\n",
      "Epoch 695/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2182 - f1: 0.7969 - val_loss: 0.2953 - val_f1: 0.0597\n",
      "Epoch 696/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2169 - f1: 0.7974 - val_loss: 0.2960 - val_f1: 0.0603\n",
      "Epoch 697/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2179 - f1: 0.7976 - val_loss: 0.2950 - val_f1: 0.0595\n",
      "Epoch 698/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2167 - f1: 0.7977 - val_loss: 0.2960 - val_f1: 0.0599\n",
      "Epoch 699/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2184 - f1: 0.7961 - val_loss: 0.2953 - val_f1: 0.0604\n",
      "Epoch 700/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2179 - f1: 0.7951 - val_loss: 0.2954 - val_f1: 0.0601\n",
      "Epoch 701/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2189 - f1: 0.7958 - val_loss: 0.2951 - val_f1: 0.0597\n",
      "Epoch 702/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2162 - f1: 0.8000 - val_loss: 0.2959 - val_f1: 0.0602\n",
      "Epoch 703/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2187 - f1: 0.7974 - val_loss: 0.2953 - val_f1: 0.0603\n",
      "Epoch 704/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2173 - f1: 0.7980 - val_loss: 0.2959 - val_f1: 0.0599\n",
      "Epoch 705/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2177 - f1: 0.7978 - val_loss: 0.2956 - val_f1: 0.0602\n",
      "Epoch 706/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2185 - f1: 0.7969 - val_loss: 0.2957 - val_f1: 0.0597\n",
      "Epoch 707/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2178 - f1: 0.7980 - val_loss: 0.2956 - val_f1: 0.0600\n",
      "Epoch 708/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2182 - f1: 0.7965 - val_loss: 0.2957 - val_f1: 0.0602\n",
      "Epoch 709/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2168 - f1: 0.7980 - val_loss: 0.2960 - val_f1: 0.0597\n",
      "Epoch 710/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2173 - f1: 0.7984 - val_loss: 0.2967 - val_f1: 0.0605\n",
      "Epoch 711/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2164 - f1: 0.7969 - val_loss: 0.2960 - val_f1: 0.0603\n",
      "Epoch 712/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2177 - f1: 0.7965 - val_loss: 0.2959 - val_f1: 0.0609\n",
      "Epoch 713/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2180 - f1: 0.7964 - val_loss: 0.2961 - val_f1: 0.0596\n",
      "Epoch 714/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2177 - f1: 0.7942 - val_loss: 0.2960 - val_f1: 0.0602\n",
      "Epoch 715/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2175 - f1: 0.7991 - val_loss: 0.2957 - val_f1: 0.0603\n",
      "Epoch 716/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2154 - f1: 0.7998 - val_loss: 0.2960 - val_f1: 0.0596\n",
      "Epoch 717/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2178 - f1: 0.7976 - val_loss: 0.2957 - val_f1: 0.0600\n",
      "Epoch 718/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2168 - f1: 0.7971 - val_loss: 0.2965 - val_f1: 0.0599\n",
      "Epoch 719/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2166 - f1: 0.7976 - val_loss: 0.2966 - val_f1: 0.0600\n",
      "Epoch 720/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2169 - f1: 0.7972 - val_loss: 0.2959 - val_f1: 0.0602\n",
      "Epoch 721/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2145 - f1: 0.8014 - val_loss: 0.2969 - val_f1: 0.0596\n",
      "Epoch 722/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2173 - f1: 0.7982 - val_loss: 0.2965 - val_f1: 0.0600\n",
      "Epoch 723/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2154 - f1: 0.7995 - val_loss: 0.2966 - val_f1: 0.0599\n",
      "Epoch 724/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2166 - f1: 0.7974 - val_loss: 0.2962 - val_f1: 0.0602\n",
      "Epoch 725/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2153 - f1: 0.7998 - val_loss: 0.2969 - val_f1: 0.0598\n",
      "Epoch 726/2000\n",
      "168135/168135 [==============================] - 12s 69us/step - loss: 0.2176 - f1: 0.7988 - val_loss: 0.2960 - val_f1: 0.0600\n",
      "Epoch 727/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2153 - f1: 0.8000 - val_loss: 0.2970 - val_f1: 0.0596\n",
      "Epoch 728/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2167 - f1: 0.7979 - val_loss: 0.2966 - val_f1: 0.0604\n",
      "Epoch 729/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2155 - f1: 0.7976 - val_loss: 0.2966 - val_f1: 0.0603\n",
      "Epoch 730/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2172 - f1: 0.7993 - val_loss: 0.2962 - val_f1: 0.0595\n",
      "Epoch 731/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2170 - f1: 0.7988 - val_loss: 0.2959 - val_f1: 0.0601\n",
      "Epoch 732/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2166 - f1: 0.7971 - val_loss: 0.2960 - val_f1: 0.0602\n",
      "Epoch 733/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2163 - f1: 0.7997 - val_loss: 0.2959 - val_f1: 0.0597\n",
      "Epoch 734/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2167 - f1: 0.7986 - val_loss: 0.2974 - val_f1: 0.0606\n",
      "Epoch 735/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2162 - f1: 0.7991 - val_loss: 0.2961 - val_f1: 0.0600\n",
      "Epoch 736/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2184 - f1: 0.7966 - val_loss: 0.2953 - val_f1: 0.0594\n",
      "Epoch 737/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2155 - f1: 0.7997 - val_loss: 0.2962 - val_f1: 0.0596\n",
      "Epoch 738/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2152 - f1: 0.7983 - val_loss: 0.2977 - val_f1: 0.0602\n",
      "Epoch 739/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2164 - f1: 0.8002 - val_loss: 0.2963 - val_f1: 0.0602\n",
      "Epoch 740/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2161 - f1: 0.7969 - val_loss: 0.2970 - val_f1: 0.0604\n",
      "Epoch 741/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2155 - f1: 0.7997 - val_loss: 0.2976 - val_f1: 0.0605\n",
      "Epoch 742/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2157 - f1: 0.7987 - val_loss: 0.2968 - val_f1: 0.0596\n",
      "Epoch 743/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2157 - f1: 0.7979 - val_loss: 0.2962 - val_f1: 0.0598\n",
      "Epoch 744/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2150 - f1: 0.8014 - val_loss: 0.2968 - val_f1: 0.0591\n",
      "Epoch 745/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2154 - f1: 0.8007 - val_loss: 0.2969 - val_f1: 0.0599\n",
      "Epoch 746/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2164 - f1: 0.8001 - val_loss: 0.2956 - val_f1: 0.0595\n",
      "Epoch 747/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2172 - f1: 0.7976 - val_loss: 0.2972 - val_f1: 0.0602\n",
      "Epoch 748/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2143 - f1: 0.7994 - val_loss: 0.2966 - val_f1: 0.0599\n",
      "Epoch 749/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2165 - f1: 0.7981 - val_loss: 0.2965 - val_f1: 0.0600\n",
      "Epoch 750/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2160 - f1: 0.7990 - val_loss: 0.2967 - val_f1: 0.0599\n",
      "Epoch 751/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2159 - f1: 0.7976 - val_loss: 0.2965 - val_f1: 0.0603\n",
      "Epoch 752/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2143 - f1: 0.7998 - val_loss: 0.2970 - val_f1: 0.0596\n",
      "Epoch 753/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2156 - f1: 0.8011 - val_loss: 0.2975 - val_f1: 0.0598\n",
      "Epoch 754/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2147 - f1: 0.8023 - val_loss: 0.2968 - val_f1: 0.0598\n",
      "Epoch 755/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2161 - f1: 0.7986 - val_loss: 0.2963 - val_f1: 0.0595\n",
      "Epoch 756/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2153 - f1: 0.7978 - val_loss: 0.2973 - val_f1: 0.0601\n",
      "Epoch 757/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2156 - f1: 0.7999 - val_loss: 0.2966 - val_f1: 0.0600\n",
      "Epoch 758/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2148 - f1: 0.8013 - val_loss: 0.2974 - val_f1: 0.0602\n",
      "Epoch 759/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2157 - f1: 0.8002 - val_loss: 0.2976 - val_f1: 0.0603\n",
      "Epoch 760/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2146 - f1: 0.8002 - val_loss: 0.2980 - val_f1: 0.0600\n",
      "Epoch 761/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2155 - f1: 0.8006 - val_loss: 0.2978 - val_f1: 0.0601\n",
      "Epoch 762/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2154 - f1: 0.7993 - val_loss: 0.2977 - val_f1: 0.0598\n",
      "Epoch 763/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2153 - f1: 0.7999 - val_loss: 0.2975 - val_f1: 0.0598\n",
      "Epoch 764/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2162 - f1: 0.7991 - val_loss: 0.2976 - val_f1: 0.0607\n",
      "Epoch 765/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2146 - f1: 0.8013 - val_loss: 0.2967 - val_f1: 0.0596\n",
      "Epoch 766/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2150 - f1: 0.8010 - val_loss: 0.2971 - val_f1: 0.0597\n",
      "Epoch 767/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2143 - f1: 0.8007 - val_loss: 0.2978 - val_f1: 0.0605\n",
      "Epoch 768/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2156 - f1: 0.7994 - val_loss: 0.2972 - val_f1: 0.0601\n",
      "Epoch 769/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2147 - f1: 0.8018 - val_loss: 0.2974 - val_f1: 0.0594\n",
      "Epoch 770/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2141 - f1: 0.8010 - val_loss: 0.2979 - val_f1: 0.0598\n",
      "Epoch 771/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2155 - f1: 0.8005 - val_loss: 0.2969 - val_f1: 0.0596\n",
      "Epoch 772/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2153 - f1: 0.8008 - val_loss: 0.2964 - val_f1: 0.0599\n",
      "Epoch 773/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2151 - f1: 0.8004 - val_loss: 0.2970 - val_f1: 0.0596\n",
      "Epoch 774/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2130 - f1: 0.8031 - val_loss: 0.2978 - val_f1: 0.0592\n",
      "Epoch 775/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2140 - f1: 0.8015 - val_loss: 0.2981 - val_f1: 0.0605\n",
      "Epoch 776/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2138 - f1: 0.8010 - val_loss: 0.2986 - val_f1: 0.0601\n",
      "Epoch 777/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2155 - f1: 0.7994 - val_loss: 0.2979 - val_f1: 0.0595\n",
      "Epoch 778/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2151 - f1: 0.8012 - val_loss: 0.2970 - val_f1: 0.0600\n",
      "Epoch 779/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2162 - f1: 0.7995 - val_loss: 0.2968 - val_f1: 0.0595\n",
      "Epoch 780/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2153 - f1: 0.7996 - val_loss: 0.2969 - val_f1: 0.0602\n",
      "Epoch 781/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2146 - f1: 0.8009 - val_loss: 0.2971 - val_f1: 0.0596\n",
      "Epoch 782/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2138 - f1: 0.8026 - val_loss: 0.2973 - val_f1: 0.0598\n",
      "Epoch 783/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2134 - f1: 0.8020 - val_loss: 0.2980 - val_f1: 0.0600\n",
      "Epoch 784/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2150 - f1: 0.8006 - val_loss: 0.2978 - val_f1: 0.0599\n",
      "Epoch 785/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2136 - f1: 0.8042 - val_loss: 0.2967 - val_f1: 0.0596\n",
      "Epoch 786/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2165 - f1: 0.7989 - val_loss: 0.2965 - val_f1: 0.0601\n",
      "Epoch 787/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2144 - f1: 0.7997 - val_loss: 0.2975 - val_f1: 0.0601\n",
      "Epoch 788/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2136 - f1: 0.8024 - val_loss: 0.2971 - val_f1: 0.0593\n",
      "Epoch 789/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2143 - f1: 0.8016 - val_loss: 0.2973 - val_f1: 0.0595\n",
      "Epoch 790/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2149 - f1: 0.8007 - val_loss: 0.2962 - val_f1: 0.0596\n",
      "Epoch 791/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2140 - f1: 0.8019 - val_loss: 0.2979 - val_f1: 0.0599\n",
      "Epoch 792/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2147 - f1: 0.7999 - val_loss: 0.2976 - val_f1: 0.0600\n",
      "Epoch 793/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2124 - f1: 0.8021 - val_loss: 0.2977 - val_f1: 0.0595\n",
      "Epoch 794/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2137 - f1: 0.8005 - val_loss: 0.2982 - val_f1: 0.0599\n",
      "Epoch 795/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2145 - f1: 0.7996 - val_loss: 0.2979 - val_f1: 0.0598\n",
      "Epoch 796/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2142 - f1: 0.8015 - val_loss: 0.2984 - val_f1: 0.0599\n",
      "Epoch 797/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2138 - f1: 0.8008 - val_loss: 0.2987 - val_f1: 0.0605\n",
      "Epoch 798/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2139 - f1: 0.8011 - val_loss: 0.2982 - val_f1: 0.0602\n",
      "Epoch 799/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2149 - f1: 0.8001 - val_loss: 0.2979 - val_f1: 0.0599\n",
      "Epoch 800/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2151 - f1: 0.7998 - val_loss: 0.2969 - val_f1: 0.0595\n",
      "Epoch 801/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2150 - f1: 0.8006 - val_loss: 0.2968 - val_f1: 0.0595\n",
      "Epoch 802/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2126 - f1: 0.8000 - val_loss: 0.2984 - val_f1: 0.0600\n",
      "Epoch 803/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2154 - f1: 0.8009 - val_loss: 0.2970 - val_f1: 0.0599\n",
      "Epoch 804/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2133 - f1: 0.8007 - val_loss: 0.2978 - val_f1: 0.0599\n",
      "Epoch 805/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2119 - f1: 0.8030 - val_loss: 0.2984 - val_f1: 0.0596\n",
      "Epoch 806/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2138 - f1: 0.8014 - val_loss: 0.2978 - val_f1: 0.0596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 807/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2154 - f1: 0.8019 - val_loss: 0.2982 - val_f1: 0.0604\n",
      "Epoch 808/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2145 - f1: 0.8004 - val_loss: 0.2982 - val_f1: 0.0597\n",
      "Epoch 809/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2127 - f1: 0.8028 - val_loss: 0.2978 - val_f1: 0.0598\n",
      "Epoch 810/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2133 - f1: 0.8035 - val_loss: 0.2977 - val_f1: 0.0598\n",
      "Epoch 811/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2127 - f1: 0.8023 - val_loss: 0.2988 - val_f1: 0.0598\n",
      "Epoch 812/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2134 - f1: 0.8014 - val_loss: 0.2980 - val_f1: 0.0597\n",
      "Epoch 813/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2131 - f1: 0.8028 - val_loss: 0.2986 - val_f1: 0.0596\n",
      "Epoch 814/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2144 - f1: 0.8000 - val_loss: 0.2984 - val_f1: 0.0597\n",
      "Epoch 815/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2150 - f1: 0.8004 - val_loss: 0.2977 - val_f1: 0.0593\n",
      "Epoch 816/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2136 - f1: 0.8019 - val_loss: 0.2977 - val_f1: 0.0594\n",
      "Epoch 817/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2131 - f1: 0.8017 - val_loss: 0.2985 - val_f1: 0.0595\n",
      "Epoch 818/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2123 - f1: 0.8042 - val_loss: 0.2990 - val_f1: 0.0596\n",
      "Epoch 819/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2122 - f1: 0.8023 - val_loss: 0.2984 - val_f1: 0.0601\n",
      "Epoch 820/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2122 - f1: 0.8023 - val_loss: 0.2988 - val_f1: 0.0596\n",
      "Epoch 821/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2133 - f1: 0.8029 - val_loss: 0.2983 - val_f1: 0.0598\n",
      "Epoch 822/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2122 - f1: 0.8035 - val_loss: 0.2988 - val_f1: 0.0599\n",
      "Epoch 823/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2122 - f1: 0.8038 - val_loss: 0.2996 - val_f1: 0.0599\n",
      "Epoch 824/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2114 - f1: 0.8029 - val_loss: 0.2993 - val_f1: 0.0597\n",
      "Epoch 825/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2155 - f1: 0.8016 - val_loss: 0.2980 - val_f1: 0.0598\n",
      "Epoch 826/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2128 - f1: 0.8036 - val_loss: 0.2986 - val_f1: 0.0602\n",
      "Epoch 827/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2108 - f1: 0.8040 - val_loss: 0.2997 - val_f1: 0.0601\n",
      "Epoch 828/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2123 - f1: 0.8038 - val_loss: 0.2991 - val_f1: 0.0600\n",
      "Epoch 829/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2135 - f1: 0.8026 - val_loss: 0.2985 - val_f1: 0.0603\n",
      "Epoch 830/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2117 - f1: 0.8042 - val_loss: 0.2994 - val_f1: 0.0603\n",
      "Epoch 831/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2140 - f1: 0.8016 - val_loss: 0.2986 - val_f1: 0.0600\n",
      "Epoch 832/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2118 - f1: 0.8048 - val_loss: 0.2987 - val_f1: 0.0601\n",
      "Epoch 833/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2126 - f1: 0.8027 - val_loss: 0.2995 - val_f1: 0.0600\n",
      "Epoch 834/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2119 - f1: 0.8028 - val_loss: 0.2994 - val_f1: 0.0602\n",
      "Epoch 835/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2141 - f1: 0.8030 - val_loss: 0.2977 - val_f1: 0.0594\n",
      "Epoch 836/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2123 - f1: 0.8028 - val_loss: 0.2979 - val_f1: 0.0599\n",
      "Epoch 837/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2138 - f1: 0.8008 - val_loss: 0.2984 - val_f1: 0.0601\n",
      "Epoch 838/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2127 - f1: 0.8038 - val_loss: 0.2983 - val_f1: 0.0599\n",
      "Epoch 839/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2122 - f1: 0.8029 - val_loss: 0.2993 - val_f1: 0.0596\n",
      "Epoch 840/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2131 - f1: 0.8014 - val_loss: 0.2992 - val_f1: 0.0600\n",
      "Epoch 841/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2112 - f1: 0.8025 - val_loss: 0.3000 - val_f1: 0.0601\n",
      "Epoch 842/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2113 - f1: 0.8048 - val_loss: 0.2998 - val_f1: 0.0599\n",
      "Epoch 843/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2136 - f1: 0.8014 - val_loss: 0.2984 - val_f1: 0.0599\n",
      "Epoch 844/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2123 - f1: 0.8029 - val_loss: 0.2989 - val_f1: 0.0597\n",
      "Epoch 845/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2121 - f1: 0.8021 - val_loss: 0.2992 - val_f1: 0.0601\n",
      "Epoch 846/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2120 - f1: 0.8042 - val_loss: 0.2984 - val_f1: 0.0599\n",
      "Epoch 847/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2126 - f1: 0.8017 - val_loss: 0.2989 - val_f1: 0.0605\n",
      "Epoch 848/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2121 - f1: 0.8052 - val_loss: 0.2990 - val_f1: 0.0600\n",
      "Epoch 849/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2122 - f1: 0.8033 - val_loss: 0.2989 - val_f1: 0.0595\n",
      "Epoch 850/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2096 - f1: 0.8045 - val_loss: 0.2991 - val_f1: 0.0599\n",
      "Epoch 851/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2136 - f1: 0.8004 - val_loss: 0.2988 - val_f1: 0.0600\n",
      "Epoch 852/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2116 - f1: 0.8046 - val_loss: 0.2999 - val_f1: 0.0605\n",
      "Epoch 853/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2111 - f1: 0.8045 - val_loss: 0.3008 - val_f1: 0.0601\n",
      "Epoch 854/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2114 - f1: 0.8025 - val_loss: 0.2992 - val_f1: 0.0598\n",
      "Epoch 855/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2113 - f1: 0.8028 - val_loss: 0.2988 - val_f1: 0.0598\n",
      "Epoch 856/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2126 - f1: 0.8045 - val_loss: 0.2994 - val_f1: 0.0602\n",
      "Epoch 857/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2109 - f1: 0.8052 - val_loss: 0.2985 - val_f1: 0.0597\n",
      "Epoch 858/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2113 - f1: 0.8045 - val_loss: 0.2991 - val_f1: 0.0598\n",
      "Epoch 859/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2121 - f1: 0.8052 - val_loss: 0.2992 - val_f1: 0.0598\n",
      "Epoch 860/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2106 - f1: 0.8046 - val_loss: 0.2992 - val_f1: 0.0599\n",
      "Epoch 861/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2125 - f1: 0.8038 - val_loss: 0.2990 - val_f1: 0.0599\n",
      "Epoch 862/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2123 - f1: 0.8039 - val_loss: 0.2989 - val_f1: 0.0594\n",
      "Epoch 863/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2136 - f1: 0.8019 - val_loss: 0.2988 - val_f1: 0.0597\n",
      "Epoch 864/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2119 - f1: 0.8043 - val_loss: 0.2983 - val_f1: 0.0602\n",
      "Epoch 865/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2124 - f1: 0.8039 - val_loss: 0.2995 - val_f1: 0.0607\n",
      "Epoch 866/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2113 - f1: 0.8028 - val_loss: 0.2995 - val_f1: 0.0602\n",
      "Epoch 867/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2105 - f1: 0.8040 - val_loss: 0.3003 - val_f1: 0.0601\n",
      "Epoch 868/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2113 - f1: 0.8061 - val_loss: 0.2993 - val_f1: 0.0593\n",
      "Epoch 869/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2117 - f1: 0.8037 - val_loss: 0.2997 - val_f1: 0.0596\n",
      "Epoch 870/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2107 - f1: 0.8031 - val_loss: 0.2993 - val_f1: 0.0601\n",
      "Epoch 871/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2112 - f1: 0.8024 - val_loss: 0.2998 - val_f1: 0.0598\n",
      "Epoch 872/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2108 - f1: 0.8047 - val_loss: 0.2992 - val_f1: 0.0600\n",
      "Epoch 873/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2115 - f1: 0.8040 - val_loss: 0.3001 - val_f1: 0.0601\n",
      "Epoch 874/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2099 - f1: 0.8046 - val_loss: 0.2998 - val_f1: 0.0592\n",
      "Epoch 875/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2095 - f1: 0.8059 - val_loss: 0.3007 - val_f1: 0.0601\n",
      "Epoch 876/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2107 - f1: 0.8048 - val_loss: 0.2999 - val_f1: 0.0595\n",
      "Epoch 877/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2109 - f1: 0.8038 - val_loss: 0.2995 - val_f1: 0.0596\n",
      "Epoch 878/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2109 - f1: 0.8042 - val_loss: 0.3002 - val_f1: 0.0596\n",
      "Epoch 879/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2110 - f1: 0.8033 - val_loss: 0.2999 - val_f1: 0.0602\n",
      "Epoch 880/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2124 - f1: 0.8028 - val_loss: 0.2987 - val_f1: 0.0597\n",
      "Epoch 881/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2101 - f1: 0.8067 - val_loss: 0.2987 - val_f1: 0.0593\n",
      "Epoch 882/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2106 - f1: 0.8050 - val_loss: 0.2994 - val_f1: 0.0598\n",
      "Epoch 883/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2109 - f1: 0.8033 - val_loss: 0.2998 - val_f1: 0.0602\n",
      "Epoch 884/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2116 - f1: 0.8055 - val_loss: 0.2998 - val_f1: 0.0603\n",
      "Epoch 885/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2111 - f1: 0.8044 - val_loss: 0.3003 - val_f1: 0.0597\n",
      "Epoch 886/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2105 - f1: 0.8042 - val_loss: 0.3003 - val_f1: 0.0601\n",
      "Epoch 887/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2097 - f1: 0.8051 - val_loss: 0.3002 - val_f1: 0.0599\n",
      "Epoch 888/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2117 - f1: 0.8044 - val_loss: 0.3001 - val_f1: 0.0597\n",
      "Epoch 889/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2107 - f1: 0.8036 - val_loss: 0.3000 - val_f1: 0.0598\n",
      "Epoch 890/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2106 - f1: 0.8041 - val_loss: 0.3001 - val_f1: 0.0604\n",
      "Epoch 891/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2117 - f1: 0.8031 - val_loss: 0.3000 - val_f1: 0.0599\n",
      "Epoch 892/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2111 - f1: 0.8038 - val_loss: 0.2995 - val_f1: 0.0596\n",
      "Epoch 893/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2091 - f1: 0.8058 - val_loss: 0.3004 - val_f1: 0.0598\n",
      "Epoch 894/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2126 - f1: 0.8041 - val_loss: 0.2991 - val_f1: 0.0594\n",
      "Epoch 895/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2111 - f1: 0.8034 - val_loss: 0.2994 - val_f1: 0.0595\n",
      "Epoch 896/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2111 - f1: 0.8022 - val_loss: 0.2999 - val_f1: 0.0607\n",
      "Epoch 897/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2110 - f1: 0.8040 - val_loss: 0.2989 - val_f1: 0.0596\n",
      "Epoch 898/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2117 - f1: 0.8053 - val_loss: 0.2999 - val_f1: 0.0598\n",
      "Epoch 899/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2101 - f1: 0.8070 - val_loss: 0.2998 - val_f1: 0.0601\n",
      "Epoch 900/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2091 - f1: 0.8069 - val_loss: 0.3006 - val_f1: 0.0596\n",
      "Epoch 901/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2111 - f1: 0.8039 - val_loss: 0.3004 - val_f1: 0.0596\n",
      "Epoch 902/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2104 - f1: 0.8040 - val_loss: 0.3005 - val_f1: 0.0594\n",
      "Epoch 903/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2095 - f1: 0.8063 - val_loss: 0.3007 - val_f1: 0.0592\n",
      "Epoch 904/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2099 - f1: 0.8055 - val_loss: 0.3006 - val_f1: 0.0594\n",
      "Epoch 905/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2110 - f1: 0.8036 - val_loss: 0.3004 - val_f1: 0.0598\n",
      "Epoch 906/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2120 - f1: 0.8033 - val_loss: 0.2994 - val_f1: 0.0595\n",
      "Epoch 907/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2097 - f1: 0.8063 - val_loss: 0.3001 - val_f1: 0.0601\n",
      "Epoch 908/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2091 - f1: 0.8061 - val_loss: 0.3010 - val_f1: 0.0599\n",
      "Epoch 909/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2110 - f1: 0.8039 - val_loss: 0.3008 - val_f1: 0.0597\n",
      "Epoch 910/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2123 - f1: 0.8035 - val_loss: 0.2995 - val_f1: 0.0590\n",
      "Epoch 911/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2087 - f1: 0.8076 - val_loss: 0.3007 - val_f1: 0.0594\n",
      "Epoch 912/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2103 - f1: 0.8064 - val_loss: 0.3007 - val_f1: 0.0599\n",
      "Epoch 913/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2085 - f1: 0.8060 - val_loss: 0.3003 - val_f1: 0.0595\n",
      "Epoch 914/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2115 - f1: 0.8032 - val_loss: 0.3011 - val_f1: 0.0600\n",
      "Epoch 915/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2109 - f1: 0.8067 - val_loss: 0.3005 - val_f1: 0.0596\n",
      "Epoch 916/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2105 - f1: 0.8051 - val_loss: 0.2997 - val_f1: 0.0593\n",
      "Epoch 917/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2092 - f1: 0.8055 - val_loss: 0.2997 - val_f1: 0.0593\n",
      "Epoch 918/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2104 - f1: 0.8039 - val_loss: 0.3009 - val_f1: 0.0602\n",
      "Epoch 919/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2094 - f1: 0.8073 - val_loss: 0.3009 - val_f1: 0.0595\n",
      "Epoch 920/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2112 - f1: 0.8049 - val_loss: 0.3005 - val_f1: 0.0599\n",
      "Epoch 921/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2098 - f1: 0.8045 - val_loss: 0.3001 - val_f1: 0.0597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2091 - f1: 0.8046 - val_loss: 0.3010 - val_f1: 0.0595\n",
      "Epoch 923/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2091 - f1: 0.8065 - val_loss: 0.3010 - val_f1: 0.0595\n",
      "Epoch 924/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2108 - f1: 0.8039 - val_loss: 0.3003 - val_f1: 0.0600\n",
      "Epoch 925/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2099 - f1: 0.8064 - val_loss: 0.3005 - val_f1: 0.0596\n",
      "Epoch 926/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2109 - f1: 0.8033 - val_loss: 0.2996 - val_f1: 0.0594\n",
      "Epoch 927/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2096 - f1: 0.8052 - val_loss: 0.3003 - val_f1: 0.0596\n",
      "Epoch 928/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2113 - f1: 0.8044 - val_loss: 0.3001 - val_f1: 0.0598\n",
      "Epoch 929/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2088 - f1: 0.8073 - val_loss: 0.3005 - val_f1: 0.0595\n",
      "Epoch 930/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2101 - f1: 0.8025 - val_loss: 0.3004 - val_f1: 0.0597\n",
      "Epoch 931/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2100 - f1: 0.8051 - val_loss: 0.3003 - val_f1: 0.0599\n",
      "Epoch 932/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2106 - f1: 0.8036 - val_loss: 0.3002 - val_f1: 0.0597\n",
      "Epoch 933/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2097 - f1: 0.8080 - val_loss: 0.3004 - val_f1: 0.0595\n",
      "Epoch 934/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2088 - f1: 0.8086 - val_loss: 0.3004 - val_f1: 0.0593\n",
      "Epoch 935/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2083 - f1: 0.8066 - val_loss: 0.3010 - val_f1: 0.0596\n",
      "Epoch 936/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2097 - f1: 0.8061 - val_loss: 0.3013 - val_f1: 0.0598\n",
      "Epoch 937/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2095 - f1: 0.8063 - val_loss: 0.3016 - val_f1: 0.0604\n",
      "Epoch 938/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2088 - f1: 0.8068 - val_loss: 0.3018 - val_f1: 0.0603\n",
      "Epoch 939/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2092 - f1: 0.8070 - val_loss: 0.3015 - val_f1: 0.0601\n",
      "Epoch 940/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2101 - f1: 0.8064 - val_loss: 0.3006 - val_f1: 0.0596\n",
      "Epoch 941/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2106 - f1: 0.8047 - val_loss: 0.3008 - val_f1: 0.0599\n",
      "Epoch 942/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2101 - f1: 0.8064 - val_loss: 0.3008 - val_f1: 0.0594\n",
      "Epoch 943/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2106 - f1: 0.8047 - val_loss: 0.3001 - val_f1: 0.0596\n",
      "Epoch 944/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2075 - f1: 0.8077 - val_loss: 0.3018 - val_f1: 0.0600\n",
      "Epoch 945/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2093 - f1: 0.8051 - val_loss: 0.3009 - val_f1: 0.0599\n",
      "Epoch 946/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2098 - f1: 0.8050 - val_loss: 0.3017 - val_f1: 0.0600\n",
      "Epoch 947/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2087 - f1: 0.8088 - val_loss: 0.3013 - val_f1: 0.0600\n",
      "Epoch 948/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2084 - f1: 0.8087 - val_loss: 0.3028 - val_f1: 0.0600\n",
      "Epoch 949/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2098 - f1: 0.8065 - val_loss: 0.3012 - val_f1: 0.0597\n",
      "Epoch 950/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2091 - f1: 0.8057 - val_loss: 0.3020 - val_f1: 0.0599\n",
      "Epoch 951/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2089 - f1: 0.8072 - val_loss: 0.3020 - val_f1: 0.0595\n",
      "Epoch 952/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2079 - f1: 0.8068 - val_loss: 0.3012 - val_f1: 0.0594\n",
      "Epoch 953/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2087 - f1: 0.8082 - val_loss: 0.3007 - val_f1: 0.0590\n",
      "Epoch 954/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2113 - f1: 0.8052 - val_loss: 0.3003 - val_f1: 0.0595\n",
      "Epoch 955/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2095 - f1: 0.8067 - val_loss: 0.3005 - val_f1: 0.0591\n",
      "Epoch 956/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2084 - f1: 0.8077 - val_loss: 0.3013 - val_f1: 0.0590\n",
      "Epoch 957/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2086 - f1: 0.8073 - val_loss: 0.3015 - val_f1: 0.0595\n",
      "Epoch 958/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2085 - f1: 0.8067 - val_loss: 0.3018 - val_f1: 0.0598\n",
      "Epoch 959/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2085 - f1: 0.8081 - val_loss: 0.3016 - val_f1: 0.0601\n",
      "Epoch 960/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2087 - f1: 0.8085 - val_loss: 0.3018 - val_f1: 0.0600\n",
      "Epoch 961/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2071 - f1: 0.8086 - val_loss: 0.3025 - val_f1: 0.0600\n",
      "Epoch 962/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2096 - f1: 0.8062 - val_loss: 0.3015 - val_f1: 0.0598\n",
      "Epoch 963/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2086 - f1: 0.8065 - val_loss: 0.3017 - val_f1: 0.0601\n",
      "Epoch 964/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2089 - f1: 0.8070 - val_loss: 0.3011 - val_f1: 0.0596\n",
      "Epoch 965/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2083 - f1: 0.8088 - val_loss: 0.3015 - val_f1: 0.0593\n",
      "Epoch 966/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2079 - f1: 0.8084 - val_loss: 0.3007 - val_f1: 0.0595\n",
      "Epoch 967/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2081 - f1: 0.8066 - val_loss: 0.3018 - val_f1: 0.0594\n",
      "Epoch 968/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2082 - f1: 0.8064 - val_loss: 0.3010 - val_f1: 0.0595\n",
      "Epoch 969/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2088 - f1: 0.8066 - val_loss: 0.3009 - val_f1: 0.0594\n",
      "Epoch 970/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2075 - f1: 0.8071 - val_loss: 0.3017 - val_f1: 0.0599\n",
      "Epoch 971/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2089 - f1: 0.8067 - val_loss: 0.3012 - val_f1: 0.0595\n",
      "Epoch 972/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2083 - f1: 0.8077 - val_loss: 0.3013 - val_f1: 0.0593\n",
      "Epoch 973/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2083 - f1: 0.8071 - val_loss: 0.3019 - val_f1: 0.0597\n",
      "Epoch 974/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2089 - f1: 0.8055 - val_loss: 0.3015 - val_f1: 0.0596\n",
      "Epoch 975/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2082 - f1: 0.8067 - val_loss: 0.3009 - val_f1: 0.0592\n",
      "Epoch 976/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2106 - f1: 0.8045 - val_loss: 0.3012 - val_f1: 0.0595\n",
      "Epoch 977/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2075 - f1: 0.8087 - val_loss: 0.3017 - val_f1: 0.0597\n",
      "Epoch 978/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2093 - f1: 0.8075 - val_loss: 0.3015 - val_f1: 0.0596\n",
      "Epoch 979/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2098 - f1: 0.8042 - val_loss: 0.3010 - val_f1: 0.0594\n",
      "Epoch 980/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2068 - f1: 0.8106 - val_loss: 0.3017 - val_f1: 0.0592\n",
      "Epoch 981/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2076 - f1: 0.8095 - val_loss: 0.3020 - val_f1: 0.0596\n",
      "Epoch 982/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2081 - f1: 0.8076 - val_loss: 0.3017 - val_f1: 0.0598\n",
      "Epoch 983/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2097 - f1: 0.8064 - val_loss: 0.3009 - val_f1: 0.0596\n",
      "Epoch 984/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2090 - f1: 0.8050 - val_loss: 0.3018 - val_f1: 0.0598\n",
      "Epoch 985/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2087 - f1: 0.8077 - val_loss: 0.3018 - val_f1: 0.0593\n",
      "Epoch 986/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2088 - f1: 0.8080 - val_loss: 0.3013 - val_f1: 0.0597\n",
      "Epoch 987/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2076 - f1: 0.8095 - val_loss: 0.3015 - val_f1: 0.0594\n",
      "Epoch 988/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2069 - f1: 0.8085 - val_loss: 0.3022 - val_f1: 0.0595\n",
      "Epoch 989/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2087 - f1: 0.8083 - val_loss: 0.3026 - val_f1: 0.0597\n",
      "Epoch 990/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2069 - f1: 0.8084 - val_loss: 0.3017 - val_f1: 0.0592\n",
      "Epoch 991/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2065 - f1: 0.8078 - val_loss: 0.3025 - val_f1: 0.0596\n",
      "Epoch 992/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2076 - f1: 0.8082 - val_loss: 0.3023 - val_f1: 0.0595\n",
      "Epoch 993/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2076 - f1: 0.8084 - val_loss: 0.3020 - val_f1: 0.0594\n",
      "Epoch 994/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2086 - f1: 0.8062 - val_loss: 0.3023 - val_f1: 0.0599\n",
      "Epoch 995/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2080 - f1: 0.8084 - val_loss: 0.3021 - val_f1: 0.0597\n",
      "Epoch 996/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2092 - f1: 0.8071 - val_loss: 0.3020 - val_f1: 0.0598\n",
      "Epoch 997/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2077 - f1: 0.8072 - val_loss: 0.3020 - val_f1: 0.0594\n",
      "Epoch 998/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2077 - f1: 0.8087 - val_loss: 0.3016 - val_f1: 0.0591\n",
      "Epoch 999/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2080 - f1: 0.8075 - val_loss: 0.3018 - val_f1: 0.0596\n",
      "Epoch 1000/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2080 - f1: 0.8065 - val_loss: 0.3016 - val_f1: 0.0594\n",
      "Epoch 1001/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2076 - f1: 0.8095 - val_loss: 0.3020 - val_f1: 0.0592\n",
      "Epoch 1002/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2075 - f1: 0.8077 - val_loss: 0.3025 - val_f1: 0.0598\n",
      "Epoch 1003/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2086 - f1: 0.8073 - val_loss: 0.3011 - val_f1: 0.0594\n",
      "Epoch 1004/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2069 - f1: 0.8085 - val_loss: 0.3017 - val_f1: 0.0589\n",
      "Epoch 1005/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2083 - f1: 0.8073 - val_loss: 0.3014 - val_f1: 0.0591\n",
      "Epoch 1006/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2080 - f1: 0.8080 - val_loss: 0.3020 - val_f1: 0.0598\n",
      "Epoch 1007/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2076 - f1: 0.8084 - val_loss: 0.3021 - val_f1: 0.0587\n",
      "Epoch 1008/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2073 - f1: 0.8094 - val_loss: 0.3018 - val_f1: 0.0588\n",
      "Epoch 1009/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2088 - f1: 0.8073 - val_loss: 0.3022 - val_f1: 0.0598\n",
      "Epoch 1010/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2079 - f1: 0.8095 - val_loss: 0.3008 - val_f1: 0.0591\n",
      "Epoch 1011/2000\n",
      "168135/168135 [==============================] - 12s 71us/step - loss: 0.2075 - f1: 0.8079 - val_loss: 0.3030 - val_f1: 0.0595\n",
      "Epoch 1012/2000\n",
      "168135/168135 [==============================] - 12s 72us/step - loss: 0.2079 - f1: 0.8054 - val_loss: 0.3019 - val_f1: 0.0591\n",
      "Epoch 1013/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2079 - f1: 0.8080 - val_loss: 0.3015 - val_f1: 0.0592\n",
      "Epoch 1014/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2074 - f1: 0.8090 - val_loss: 0.3030 - val_f1: 0.0603\n",
      "Epoch 1015/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2085 - f1: 0.8063 - val_loss: 0.3023 - val_f1: 0.0592\n",
      "Epoch 1016/2000\n",
      "168135/168135 [==============================] - 12s 72us/step - loss: 0.2078 - f1: 0.8074 - val_loss: 0.3017 - val_f1: 0.0594\n",
      "Epoch 1017/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2077 - f1: 0.8082 - val_loss: 0.3024 - val_f1: 0.0589\n",
      "Epoch 1018/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2066 - f1: 0.8116 - val_loss: 0.3028 - val_f1: 0.0590\n",
      "Epoch 1019/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2094 - f1: 0.8080 - val_loss: 0.3021 - val_f1: 0.0594\n",
      "Epoch 1020/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2057 - f1: 0.8113 - val_loss: 0.3028 - val_f1: 0.0594\n",
      "Epoch 1021/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2070 - f1: 0.8087 - val_loss: 0.3028 - val_f1: 0.0597\n",
      "Epoch 1022/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2071 - f1: 0.8087 - val_loss: 0.3029 - val_f1: 0.0591\n",
      "Epoch 1023/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2064 - f1: 0.8090 - val_loss: 0.3025 - val_f1: 0.0584\n",
      "Epoch 1024/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2068 - f1: 0.8057 - val_loss: 0.3027 - val_f1: 0.0601\n",
      "Epoch 1025/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2076 - f1: 0.8076 - val_loss: 0.3027 - val_f1: 0.0591\n",
      "Epoch 1026/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2082 - f1: 0.8064 - val_loss: 0.3027 - val_f1: 0.0596\n",
      "Epoch 1027/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2080 - f1: 0.8084 - val_loss: 0.3020 - val_f1: 0.0594\n",
      "Epoch 1028/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2078 - f1: 0.8064 - val_loss: 0.3022 - val_f1: 0.0589\n",
      "Epoch 1029/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2067 - f1: 0.8103 - val_loss: 0.3024 - val_f1: 0.0588\n",
      "Epoch 1030/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2077 - f1: 0.8077 - val_loss: 0.3018 - val_f1: 0.0590\n",
      "Epoch 1031/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2058 - f1: 0.8088 - val_loss: 0.3025 - val_f1: 0.0596\n",
      "Epoch 1055/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2055 - f1: 0.8092 - val_loss: 0.3034 - val_f1: 0.0593\n",
      "Epoch 1056/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2061 - f1: 0.8105 - val_loss: 0.3041 - val_f1: 0.0597\n",
      "Epoch 1057/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2064 - f1: 0.8076 - val_loss: 0.3036 - val_f1: 0.0595\n",
      "Epoch 1058/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2062 - f1: 0.8092 - val_loss: 0.3037 - val_f1: 0.0594\n",
      "Epoch 1059/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2063 - f1: 0.8096 - val_loss: 0.3031 - val_f1: 0.0588\n",
      "Epoch 1060/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2052 - f1: 0.8105 - val_loss: 0.3028 - val_f1: 0.0592\n",
      "Epoch 1061/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2059 - f1: 0.8086 - val_loss: 0.3043 - val_f1: 0.0598\n",
      "Epoch 1062/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2055 - f1: 0.8121 - val_loss: 0.3035 - val_f1: 0.0595\n",
      "Epoch 1063/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2080 - f1: 0.8084 - val_loss: 0.3033 - val_f1: 0.0592\n",
      "Epoch 1064/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2071 - f1: 0.8077 - val_loss: 0.3028 - val_f1: 0.0595\n",
      "Epoch 1065/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2063 - f1: 0.8096 - val_loss: 0.3023 - val_f1: 0.0590\n",
      "Epoch 1066/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2060 - f1: 0.8108 - val_loss: 0.3027 - val_f1: 0.0595\n",
      "Epoch 1067/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2073 - f1: 0.8077 - val_loss: 0.3027 - val_f1: 0.0592\n",
      "Epoch 1076/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2071 - f1: 0.8083 - val_loss: 0.3021 - val_f1: 0.0588\n",
      "Epoch 1077/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2050 - f1: 0.8111 - val_loss: 0.3034 - val_f1: 0.0589\n",
      "Epoch 1078/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2056 - f1: 0.8110 - val_loss: 0.3026 - val_f1: 0.0591\n",
      "Epoch 1079/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2044 - f1: 0.8123 - val_loss: 0.3033 - val_f1: 0.0590\n",
      "Epoch 1080/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2045 - f1: 0.8116 - val_loss: 0.3037 - val_f1: 0.0592\n",
      "Epoch 1081/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2073 - f1: 0.8091 - val_loss: 0.3030 - val_f1: 0.0590\n",
      "Epoch 1082/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2072 - f1: 0.8107 - val_loss: 0.3026 - val_f1: 0.0591\n",
      "Epoch 1083/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2053 - f1: 0.8098 - val_loss: 0.3030 - val_f1: 0.0598\n",
      "Epoch 1084/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2053 - f1: 0.8108 - val_loss: 0.3033 - val_f1: 0.0594\n",
      "Epoch 1085/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2054 - f1: 0.8105 - val_loss: 0.3030 - val_f1: 0.0591\n",
      "Epoch 1086/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2052 - f1: 0.8107 - val_loss: 0.3040 - val_f1: 0.0597\n",
      "Epoch 1087/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2055 - f1: 0.8092 - val_loss: 0.3040 - val_f1: 0.0589\n",
      "Epoch 1088/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2070 - f1: 0.8085 - val_loss: 0.3036 - val_f1: 0.0598\n",
      "Epoch 1089/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2065 - f1: 0.8102 - val_loss: 0.3032 - val_f1: 0.0594\n",
      "Epoch 1090/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2057 - f1: 0.8098 - val_loss: 0.3028 - val_f1: 0.0595\n",
      "Epoch 1091/2000\n",
      "122912/168135 [====================>.........] - ETA: 2s - loss: 0.2033 - f1: 0.8128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2038 - f1: 0.8127 - val_loss: 0.3043 - val_f1: 0.0590\n",
      "Epoch 1098/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2056 - f1: 0.8087 - val_loss: 0.3050 - val_f1: 0.0596\n",
      "Epoch 1112/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2042 - f1: 0.8116 - val_loss: 0.3045 - val_f1: 0.0596\n",
      "Epoch 1113/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2050 - f1: 0.8113 - val_loss: 0.3042 - val_f1: 0.0597\n",
      "Epoch 1114/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2049 - f1: 0.8104 - val_loss: 0.3041 - val_f1: 0.0591\n",
      "Epoch 1115/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2041 - f1: 0.8114 - val_loss: 0.3055 - val_f1: 0.0598\n",
      "Epoch 1116/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2047 - f1: 0.8110 - val_loss: 0.3042 - val_f1: 0.0596\n",
      "Epoch 1117/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2054 - f1: 0.8118 - val_loss: 0.3044 - val_f1: 0.0598\n",
      "Epoch 1118/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2042 - f1: 0.8127 - val_loss: 0.3036 - val_f1: 0.0592\n",
      "Epoch 1119/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2057 - f1: 0.8099 - val_loss: 0.3036 - val_f1: 0.0599\n",
      "Epoch 1120/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2044 - f1: 0.8139 - val_loss: 0.3040 - val_f1: 0.0586\n",
      "Epoch 1121/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2039 - f1: 0.8129 - val_loss: 0.3042 - val_f1: 0.0593\n",
      "Epoch 1122/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2046 - f1: 0.8100 - val_loss: 0.3038 - val_f1: 0.0594\n",
      "Epoch 1123/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2058 - f1: 0.8090 - val_loss: 0.3045 - val_f1: 0.0595\n",
      "Epoch 1124/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2049 - f1: 0.8110 - val_loss: 0.3046 - val_f1: 0.0592\n",
      "Epoch 1125/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2041 - f1: 0.8118 - val_loss: 0.3046 - val_f1: 0.0593\n",
      "Epoch 1126/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2045 - f1: 0.8122 - val_loss: 0.3039 - val_f1: 0.0592\n",
      "Epoch 1127/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2051 - f1: 0.8128 - val_loss: 0.3034 - val_f1: 0.0589\n",
      "Epoch 1147/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2043 - f1: 0.8110 - val_loss: 0.3049 - val_f1: 0.0598\n",
      "Epoch 1148/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2036 - f1: 0.8118 - val_loss: 0.3043 - val_f1: 0.0589\n",
      "Epoch 1149/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2048 - f1: 0.8107 - val_loss: 0.3041 - val_f1: 0.0590\n",
      "Epoch 1150/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2052 - f1: 0.8099 - val_loss: 0.3035 - val_f1: 0.0589\n",
      "Epoch 1151/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2036 - f1: 0.8120 - val_loss: 0.3037 - val_f1: 0.0587\n",
      "Epoch 1152/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2048 - f1: 0.8103 - val_loss: 0.3039 - val_f1: 0.0593\n",
      "Epoch 1153/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2039 - f1: 0.8122 - val_loss: 0.3050 - val_f1: 0.0597\n",
      "Epoch 1154/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2037 - f1: 0.8123 - val_loss: 0.3045 - val_f1: 0.0596\n",
      "Epoch 1155/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2035 - f1: 0.8123 - val_loss: 0.3040 - val_f1: 0.0587\n",
      "Epoch 1156/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2037 - f1: 0.8129 - val_loss: 0.3048 - val_f1: 0.0588\n",
      "Epoch 1157/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2034 - f1: 0.8125 - val_loss: 0.3053 - val_f1: 0.0593\n",
      "Epoch 1158/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2050 - f1: 0.8096 - val_loss: 0.3050 - val_f1: 0.0597\n",
      "Epoch 1159/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2056 - f1: 0.8095 - val_loss: 0.3038 - val_f1: 0.0591\n",
      "Epoch 1160/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2054 - f1: 0.8124 - val_loss: 0.3031 - val_f1: 0.0592\n",
      "Epoch 1161/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2050 - f1: 0.8101 - val_loss: 0.3039 - val_f1: 0.0597\n",
      "Epoch 1162/2000\n",
      " 67392/168135 [===========>..................] - ETA: 5s - loss: 0.2052 - f1: 0.8094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2040 - f1: 0.8126 - val_loss: 0.3037 - val_f1: 0.0595\n",
      "Epoch 1168/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2028 - f1: 0.8132 - val_loss: 0.3041 - val_f1: 0.0586\n",
      "Epoch 1169/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2021 - f1: 0.8129 - val_loss: 0.3048 - val_f1: 0.0595\n",
      "Epoch 1170/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2044 - f1: 0.8118 - val_loss: 0.3043 - val_f1: 0.0596\n",
      "Epoch 1171/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2038 - f1: 0.8117 - val_loss: 0.3036 - val_f1: 0.0590\n",
      "Epoch 1172/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2040 - f1: 0.8122 - val_loss: 0.3040 - val_f1: 0.0596\n",
      "Epoch 1173/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2034 - f1: 0.8127 - val_loss: 0.3042 - val_f1: 0.0593\n",
      "Epoch 1174/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2021 - f1: 0.8132 - val_loss: 0.3048 - val_f1: 0.0593\n",
      "Epoch 1175/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2042 - f1: 0.8107 - val_loss: 0.3033 - val_f1: 0.0597\n",
      "Epoch 1176/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2039 - f1: 0.8135 - val_loss: 0.3047 - val_f1: 0.0593\n",
      "Epoch 1186/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2028 - f1: 0.8135 - val_loss: 0.3055 - val_f1: 0.0591\n",
      "Epoch 1187/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2015 - f1: 0.8151 - val_loss: 0.3052 - val_f1: 0.0596\n",
      "Epoch 1188/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2025 - f1: 0.8137 - val_loss: 0.3054 - val_f1: 0.0593\n",
      "Epoch 1189/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2029 - f1: 0.8125 - val_loss: 0.3052 - val_f1: 0.0592\n",
      "Epoch 1190/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2045 - f1: 0.8113 - val_loss: 0.3043 - val_f1: 0.0600\n",
      "Epoch 1191/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2051 - f1: 0.8117 - val_loss: 0.3044 - val_f1: 0.0591\n",
      "Epoch 1192/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2049 - f1: 0.8117 - val_loss: 0.3044 - val_f1: 0.0595\n",
      "Epoch 1193/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2030 - f1: 0.8145 - val_loss: 0.3050 - val_f1: 0.0593\n",
      "Epoch 1194/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2033 - f1: 0.8121 - val_loss: 0.3049 - val_f1: 0.0589\n",
      "Epoch 1195/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2017 - f1: 0.8129 - val_loss: 0.3064 - val_f1: 0.0597\n",
      "Epoch 1196/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2040 - f1: 0.8124 - val_loss: 0.3046 - val_f1: 0.0594\n",
      "Epoch 1197/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2037 - f1: 0.8102 - val_loss: 0.3052 - val_f1: 0.0597\n",
      "Epoch 1198/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2035 - f1: 0.8128 - val_loss: 0.3050 - val_f1: 0.0593\n",
      "Epoch 1199/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2038 - f1: 0.8134 - val_loss: 0.3048 - val_f1: 0.0592\n",
      "Epoch 1200/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2040 - f1: 0.8122 - val_loss: 0.3041 - val_f1: 0.0590\n",
      "Epoch 1201/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2028 - f1: 0.8128 - val_loss: 0.3054 - val_f1: 0.0596\n",
      "Epoch 1202/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2022 - f1: 0.8124 - val_loss: 0.3056 - val_f1: 0.0594\n",
      "Epoch 1203/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2019 - f1: 0.8130 - val_loss: 0.3055 - val_f1: 0.0599\n",
      "Epoch 1204/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2035 - f1: 0.8120 - val_loss: 0.3052 - val_f1: 0.0590\n",
      "Epoch 1205/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2033 - f1: 0.8134 - val_loss: 0.3051 - val_f1: 0.0593\n",
      "Epoch 1206/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2027 - f1: 0.8131 - val_loss: 0.3049 - val_f1: 0.0590\n",
      "Epoch 1207/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2016 - f1: 0.8133 - val_loss: 0.3064 - val_f1: 0.0593\n",
      "Epoch 1208/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2033 - f1: 0.8114 - val_loss: 0.3055 - val_f1: 0.0586\n",
      "Epoch 1209/2000\n",
      " 58336/168135 [=========>....................] - ETA: 5s - loss: 0.2025 - f1: 0.8100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2025 - f1: 0.8126 - val_loss: 0.3057 - val_f1: 0.0594\n",
      "Epoch 1215/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2038 - f1: 0.8136 - val_loss: 0.3050 - val_f1: 0.0594\n",
      "Epoch 1233/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2025 - f1: 0.8131 - val_loss: 0.3052 - val_f1: 0.0591\n",
      "Epoch 1234/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2020 - f1: 0.8144 - val_loss: 0.3060 - val_f1: 0.0596\n",
      "Epoch 1235/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2028 - f1: 0.8150 - val_loss: 0.3048 - val_f1: 0.0591\n",
      "Epoch 1236/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2024 - f1: 0.8151 - val_loss: 0.3050 - val_f1: 0.0589\n",
      "Epoch 1237/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2032 - f1: 0.8141 - val_loss: 0.3044 - val_f1: 0.0589\n",
      "Epoch 1238/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2034 - f1: 0.8145 - val_loss: 0.3043 - val_f1: 0.0587\n",
      "Epoch 1239/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2027 - f1: 0.8129 - val_loss: 0.3055 - val_f1: 0.0592\n",
      "Epoch 1240/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2022 - f1: 0.8136 - val_loss: 0.3051 - val_f1: 0.0590\n",
      "Epoch 1241/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2029 - f1: 0.8126 - val_loss: 0.3053 - val_f1: 0.0585\n",
      "Epoch 1242/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2011 - f1: 0.8153 - val_loss: 0.3060 - val_f1: 0.0594\n",
      "Epoch 1243/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2027 - f1: 0.8138 - val_loss: 0.3053 - val_f1: 0.0588\n",
      "Epoch 1244/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2031 - f1: 0.8122 - val_loss: 0.3055 - val_f1: 0.0592\n",
      "Epoch 1245/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2016 - f1: 0.8137 - val_loss: 0.3063 - val_f1: 0.0596\n",
      "Epoch 1246/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2033 - f1: 0.8118 - val_loss: 0.3044 - val_f1: 0.0588\n",
      "Epoch 1247/2000\n",
      "161760/168135 [===========================>..] - ETA: 0s - loss: 0.2002 - f1: 0.8163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2011 - f1: 0.8162 - val_loss: 0.3066 - val_f1: 0.0591\n",
      "Epoch 1282/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2019 - f1: 0.8143 - val_loss: 0.3066 - val_f1: 0.0592\n",
      "Epoch 1283/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2031 - f1: 0.8138 - val_loss: 0.3051 - val_f1: 0.0587\n",
      "Epoch 1284/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2009 - f1: 0.8156 - val_loss: 0.3059 - val_f1: 0.0593\n",
      "Epoch 1285/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2027 - f1: 0.8127 - val_loss: 0.3055 - val_f1: 0.0592\n",
      "Epoch 1286/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2015 - f1: 0.8137 - val_loss: 0.3057 - val_f1: 0.0586\n",
      "Epoch 1287/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2013 - f1: 0.8140 - val_loss: 0.3061 - val_f1: 0.0596\n",
      "Epoch 1288/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2007 - f1: 0.8150 - val_loss: 0.3055 - val_f1: 0.0592\n",
      "Epoch 1289/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1998 - f1: 0.8162 - val_loss: 0.3068 - val_f1: 0.0586\n",
      "Epoch 1290/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2026 - f1: 0.8137 - val_loss: 0.3067 - val_f1: 0.0594\n",
      "Epoch 1291/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2014 - f1: 0.8145 - val_loss: 0.3054 - val_f1: 0.0589\n",
      "Epoch 1292/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2028 - f1: 0.8122 - val_loss: 0.3053 - val_f1: 0.0591\n",
      "Epoch 1293/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2008 - f1: 0.8140 - val_loss: 0.3062 - val_f1: 0.0596\n",
      "Epoch 1294/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2009 - f1: 0.8168 - val_loss: 0.3062 - val_f1: 0.0585\n",
      "Epoch 1295/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2016 - f1: 0.8154 - val_loss: 0.3064 - val_f1: 0.0588\n",
      "Epoch 1296/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2022 - f1: 0.8144 - val_loss: 0.3053 - val_f1: 0.0594\n",
      "Epoch 1297/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2023 - f1: 0.8141 - val_loss: 0.3062 - val_f1: 0.0593\n",
      "Epoch 1298/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2019 - f1: 0.8142 - val_loss: 0.3055 - val_f1: 0.0593\n",
      "Epoch 1299/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2007 - f1: 0.8164 - val_loss: 0.3059 - val_f1: 0.0588\n",
      "Epoch 1300/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2016 - f1: 0.8135 - val_loss: 0.3062 - val_f1: 0.0591\n",
      "Epoch 1301/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2021 - f1: 0.8128 - val_loss: 0.3056 - val_f1: 0.0593\n",
      "Epoch 1302/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2014 - f1: 0.8155 - val_loss: 0.3062 - val_f1: 0.0591\n",
      "Epoch 1303/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2006 - f1: 0.8166 - val_loss: 0.3064 - val_f1: 0.0593\n",
      "Epoch 1304/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2011 - f1: 0.8149 - val_loss: 0.3051 - val_f1: 0.0589\n",
      "Epoch 1305/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2005 - f1: 0.8156 - val_loss: 0.3063 - val_f1: 0.0595\n",
      "Epoch 1306/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2020 - f1: 0.8150 - val_loss: 0.3053 - val_f1: 0.0585\n",
      "Epoch 1307/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2002 - f1: 0.8172 - val_loss: 0.3059 - val_f1: 0.0583\n",
      "Epoch 1308/2000\n",
      "168135/168135 [==============================] - 12s 71us/step - loss: 0.1998 - f1: 0.8173 - val_loss: 0.3072 - val_f1: 0.0595\n",
      "Epoch 1309/2000\n",
      "168135/168135 [==============================] - 12s 72us/step - loss: 0.2013 - f1: 0.8147 - val_loss: 0.3066 - val_f1: 0.0585\n",
      "Epoch 1310/2000\n",
      "168135/168135 [==============================] - 12s 73us/step - loss: 0.2002 - f1: 0.8152 - val_loss: 0.3065 - val_f1: 0.0588\n",
      "Epoch 1311/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2018 - f1: 0.8140 - val_loss: 0.3070 - val_f1: 0.0591\n",
      "Epoch 1312/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2015 - f1: 0.8142 - val_loss: 0.3063 - val_f1: 0.0592\n",
      "Epoch 1313/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2014 - f1: 0.8137 - val_loss: 0.3062 - val_f1: 0.0585\n",
      "Epoch 1314/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2012 - f1: 0.8167 - val_loss: 0.3054 - val_f1: 0.0589\n",
      "Epoch 1315/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2009 - f1: 0.8168 - val_loss: 0.3067 - val_f1: 0.0586\n",
      "Epoch 1316/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2015 - f1: 0.8139 - val_loss: 0.3066 - val_f1: 0.0591\n",
      "Epoch 1317/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2010 - f1: 0.8131 - val_loss: 0.3062 - val_f1: 0.0594\n",
      "Epoch 1318/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2002 - f1: 0.8162 - val_loss: 0.3073 - val_f1: 0.0594\n",
      "Epoch 1319/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2001 - f1: 0.8180 - val_loss: 0.3072 - val_f1: 0.0585\n",
      "Epoch 1320/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2001 - f1: 0.8141 - val_loss: 0.3070 - val_f1: 0.0589\n",
      "Epoch 1321/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2011 - f1: 0.8160 - val_loss: 0.3069 - val_f1: 0.0586\n",
      "Epoch 1322/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1992 - f1: 0.8162 - val_loss: 0.3069 - val_f1: 0.0589\n",
      "Epoch 1323/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2011 - f1: 0.8149 - val_loss: 0.3063 - val_f1: 0.0589\n",
      "Epoch 1324/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2003 - f1: 0.8171 - val_loss: 0.3066 - val_f1: 0.0594\n",
      "Epoch 1325/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2002 - f1: 0.8159 - val_loss: 0.3064 - val_f1: 0.0584\n",
      "Epoch 1326/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2010 - f1: 0.8154 - val_loss: 0.3066 - val_f1: 0.0590\n",
      "Epoch 1327/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2011 - f1: 0.8153 - val_loss: 0.3065 - val_f1: 0.0588\n",
      "Epoch 1328/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2017 - f1: 0.8129 - val_loss: 0.3060 - val_f1: 0.0588\n",
      "Epoch 1329/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2010 - f1: 0.8172 - val_loss: 0.3057 - val_f1: 0.0587\n",
      "Epoch 1330/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2016 - f1: 0.8127 - val_loss: 0.3058 - val_f1: 0.0594\n",
      "Epoch 1331/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2010 - f1: 0.8160 - val_loss: 0.3060 - val_f1: 0.0588\n",
      "Epoch 1332/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2004 - f1: 0.8161 - val_loss: 0.3056 - val_f1: 0.0587\n",
      "Epoch 1333/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2013 - f1: 0.8150 - val_loss: 0.3062 - val_f1: 0.0585\n",
      "Epoch 1334/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2020 - f1: 0.8140 - val_loss: 0.3055 - val_f1: 0.0587\n",
      "Epoch 1335/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.1990 - f1: 0.8175 - val_loss: 0.3058 - val_f1: 0.0587\n",
      "Epoch 1336/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1996 - f1: 0.8177 - val_loss: 0.3065 - val_f1: 0.0580\n",
      "Epoch 1337/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2007 - f1: 0.8140 - val_loss: 0.3064 - val_f1: 0.0592\n",
      "Epoch 1338/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2006 - f1: 0.8159 - val_loss: 0.3057 - val_f1: 0.0593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1339/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2015 - f1: 0.8151 - val_loss: 0.3065 - val_f1: 0.0590\n",
      "Epoch 1340/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2015 - f1: 0.8146 - val_loss: 0.3065 - val_f1: 0.0591\n",
      "Epoch 1341/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1994 - f1: 0.8159 - val_loss: 0.3069 - val_f1: 0.0582\n",
      "Epoch 1342/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2005 - f1: 0.8143 - val_loss: 0.3071 - val_f1: 0.0589\n",
      "Epoch 1343/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2010 - f1: 0.8164 - val_loss: 0.3071 - val_f1: 0.0595\n",
      "Epoch 1344/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1995 - f1: 0.8163 - val_loss: 0.3071 - val_f1: 0.0595\n",
      "Epoch 1345/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1999 - f1: 0.8170 - val_loss: 0.3076 - val_f1: 0.0594\n",
      "Epoch 1346/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2022 - f1: 0.8141 - val_loss: 0.3064 - val_f1: 0.0591\n",
      "Epoch 1347/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1988 - f1: 0.8184 - val_loss: 0.3072 - val_f1: 0.0590\n",
      "Epoch 1348/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2008 - f1: 0.8145 - val_loss: 0.3072 - val_f1: 0.0590\n",
      "Epoch 1349/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.1985 - f1: 0.8185 - val_loss: 0.3077 - val_f1: 0.0592\n",
      "Epoch 1350/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2011 - f1: 0.8170 - val_loss: 0.3063 - val_f1: 0.0584\n",
      "Epoch 1351/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2006 - f1: 0.8154 - val_loss: 0.3072 - val_f1: 0.0591\n",
      "Epoch 1352/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2012 - f1: 0.8130 - val_loss: 0.3063 - val_f1: 0.0596\n",
      "Epoch 1353/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2016 - f1: 0.8150 - val_loss: 0.3059 - val_f1: 0.0592\n",
      "Epoch 1354/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2014 - f1: 0.8148 - val_loss: 0.3065 - val_f1: 0.0589\n",
      "Epoch 1355/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1985 - f1: 0.8176 - val_loss: 0.3071 - val_f1: 0.0591\n",
      "Epoch 1356/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2005 - f1: 0.8163 - val_loss: 0.3069 - val_f1: 0.0591\n",
      "Epoch 1357/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2011 - f1: 0.8147 - val_loss: 0.3055 - val_f1: 0.0589\n",
      "Epoch 1358/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2004 - f1: 0.8158 - val_loss: 0.3060 - val_f1: 0.0590\n",
      "Epoch 1359/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1987 - f1: 0.8187 - val_loss: 0.3071 - val_f1: 0.0588\n",
      "Epoch 1360/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1986 - f1: 0.8170 - val_loss: 0.3070 - val_f1: 0.0587\n",
      "Epoch 1361/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2000 - f1: 0.8180 - val_loss: 0.3070 - val_f1: 0.0587\n",
      "Epoch 1362/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1994 - f1: 0.8174 - val_loss: 0.3071 - val_f1: 0.0589\n",
      "Epoch 1363/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1985 - f1: 0.8183 - val_loss: 0.3067 - val_f1: 0.0589\n",
      "Epoch 1364/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1998 - f1: 0.8152 - val_loss: 0.3075 - val_f1: 0.0592\n",
      "Epoch 1365/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2002 - f1: 0.8166 - val_loss: 0.3073 - val_f1: 0.0586\n",
      "Epoch 1366/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2001 - f1: 0.8143 - val_loss: 0.3078 - val_f1: 0.0589\n",
      "Epoch 1367/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1995 - f1: 0.8171 - val_loss: 0.3073 - val_f1: 0.0592\n",
      "Epoch 1368/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1992 - f1: 0.8154 - val_loss: 0.3078 - val_f1: 0.0590\n",
      "Epoch 1369/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1986 - f1: 0.8178 - val_loss: 0.3083 - val_f1: 0.0593\n",
      "Epoch 1370/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1987 - f1: 0.8173 - val_loss: 0.3088 - val_f1: 0.0590\n",
      "Epoch 1371/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1998 - f1: 0.8188 - val_loss: 0.3076 - val_f1: 0.0590\n",
      "Epoch 1372/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1991 - f1: 0.8184 - val_loss: 0.3079 - val_f1: 0.0590\n",
      "Epoch 1373/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1998 - f1: 0.8155 - val_loss: 0.3074 - val_f1: 0.0592\n",
      "Epoch 1374/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1991 - f1: 0.8150 - val_loss: 0.3081 - val_f1: 0.0590\n",
      "Epoch 1375/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1990 - f1: 0.8174 - val_loss: 0.3077 - val_f1: 0.0590\n",
      "Epoch 1376/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2003 - f1: 0.8149 - val_loss: 0.3071 - val_f1: 0.0589\n",
      "Epoch 1377/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2001 - f1: 0.8158 - val_loss: 0.3078 - val_f1: 0.0589\n",
      "Epoch 1378/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1994 - f1: 0.8169 - val_loss: 0.3070 - val_f1: 0.0588\n",
      "Epoch 1379/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1987 - f1: 0.8174 - val_loss: 0.3079 - val_f1: 0.0595\n",
      "Epoch 1380/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2003 - f1: 0.8163 - val_loss: 0.3073 - val_f1: 0.0591\n",
      "Epoch 1381/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1996 - f1: 0.8170 - val_loss: 0.3079 - val_f1: 0.0592\n",
      "Epoch 1382/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2012 - f1: 0.8156 - val_loss: 0.3060 - val_f1: 0.0584\n",
      "Epoch 1383/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1975 - f1: 0.8179 - val_loss: 0.3086 - val_f1: 0.0588\n",
      "Epoch 1497/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1981 - f1: 0.8181 - val_loss: 0.3077 - val_f1: 0.0588\n",
      "Epoch 1498/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1990 - f1: 0.8173 - val_loss: 0.3078 - val_f1: 0.0594\n",
      "Epoch 1499/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1981 - f1: 0.8167 - val_loss: 0.3081 - val_f1: 0.0589\n",
      "Epoch 1500/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.1980 - f1: 0.8196 - val_loss: 0.3088 - val_f1: 0.0587\n",
      "Epoch 1501/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1979 - f1: 0.8184 - val_loss: 0.3076 - val_f1: 0.0590\n",
      "Epoch 1502/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.1966 - f1: 0.8207 - val_loss: 0.3084 - val_f1: 0.0591\n",
      "Epoch 1503/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1972 - f1: 0.8185 - val_loss: 0.3088 - val_f1: 0.0585\n",
      "Epoch 1504/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1988 - f1: 0.8190 - val_loss: 0.3071 - val_f1: 0.0583\n",
      "Epoch 1505/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1978 - f1: 0.8174 - val_loss: 0.3083 - val_f1: 0.0589\n",
      "Epoch 1506/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1962 - f1: 0.8214 - val_loss: 0.3087 - val_f1: 0.0590\n",
      "Epoch 1507/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1980 - f1: 0.8186 - val_loss: 0.3072 - val_f1: 0.0588\n",
      "Epoch 1508/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1980 - f1: 0.8178 - val_loss: 0.3085 - val_f1: 0.0595\n",
      "Epoch 1509/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1977 - f1: 0.8192 - val_loss: 0.3086 - val_f1: 0.0587\n",
      "Epoch 1510/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1976 - f1: 0.8190 - val_loss: 0.3084 - val_f1: 0.0589\n",
      "Epoch 1521/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1975 - f1: 0.8185 - val_loss: 0.3088 - val_f1: 0.0587\n",
      "Epoch 1522/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1974 - f1: 0.8160 - val_loss: 0.3088 - val_f1: 0.0594\n",
      "Epoch 1523/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1986 - f1: 0.8195 - val_loss: 0.3086 - val_f1: 0.0584\n",
      "Epoch 1524/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1966 - f1: 0.8189 - val_loss: 0.3087 - val_f1: 0.0597\n",
      "Epoch 1525/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1968 - f1: 0.8203 - val_loss: 0.3082 - val_f1: 0.0591\n",
      "Epoch 1526/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.1974 - f1: 0.8171 - val_loss: 0.3085 - val_f1: 0.0590\n",
      "Epoch 1527/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1977 - f1: 0.8176 - val_loss: 0.3078 - val_f1: 0.0589\n",
      "Epoch 1528/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1990 - f1: 0.8166 - val_loss: 0.3077 - val_f1: 0.0594\n",
      "Epoch 1529/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1970 - f1: 0.8197 - val_loss: 0.3086 - val_f1: 0.0586\n",
      "Epoch 1530/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1980 - f1: 0.8185 - val_loss: 0.3081 - val_f1: 0.0588\n",
      "Epoch 1531/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.1959 - f1: 0.8201 - val_loss: 0.3091 - val_f1: 0.0587\n",
      "Epoch 1532/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1975 - f1: 0.8174 - val_loss: 0.3090 - val_f1: 0.0594\n",
      "Epoch 1565/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.1975 - f1: 0.8181 - val_loss: 0.3080 - val_f1: 0.0591\n",
      "Epoch 1566/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1978 - f1: 0.8198 - val_loss: 0.3083 - val_f1: 0.0588\n",
      "Epoch 1567/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.1980 - f1: 0.8180 - val_loss: 0.3081 - val_f1: 0.0586\n",
      "Epoch 1568/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1961 - f1: 0.8182 - val_loss: 0.3089 - val_f1: 0.0586\n",
      "Epoch 1569/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1966 - f1: 0.8199 - val_loss: 0.3085 - val_f1: 0.0582\n",
      "Epoch 1570/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1961 - f1: 0.8200 - val_loss: 0.3087 - val_f1: 0.0586\n",
      "Epoch 1571/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1972 - f1: 0.8213 - val_loss: 0.3087 - val_f1: 0.0589\n",
      "Epoch 1572/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1977 - f1: 0.8198 - val_loss: 0.3093 - val_f1: 0.0589\n",
      "Epoch 1573/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1959 - f1: 0.8204 - val_loss: 0.3089 - val_f1: 0.0586\n",
      "Epoch 1574/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1965 - f1: 0.8182 - val_loss: 0.3091 - val_f1: 0.0589\n",
      "Epoch 1575/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1958 - f1: 0.8186 - val_loss: 0.3091 - val_f1: 0.0595\n",
      "Epoch 1576/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1963 - f1: 0.8214 - val_loss: 0.3091 - val_f1: 0.0591\n",
      "Epoch 1596/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1961 - f1: 0.8188 - val_loss: 0.3091 - val_f1: 0.0583\n",
      "Epoch 1597/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1979 - f1: 0.8189 - val_loss: 0.3088 - val_f1: 0.0584\n",
      "Epoch 1598/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.1964 - f1: 0.8219 - val_loss: 0.3089 - val_f1: 0.0590\n",
      "Epoch 1599/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1965 - f1: 0.8193 - val_loss: 0.3082 - val_f1: 0.0585\n",
      "Epoch 1600/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1961 - f1: 0.8212 - val_loss: 0.3088 - val_f1: 0.0584\n",
      "Epoch 1601/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1963 - f1: 0.8200 - val_loss: 0.3096 - val_f1: 0.0587\n",
      "Epoch 1602/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1966 - f1: 0.8199 - val_loss: 0.3088 - val_f1: 0.0590\n",
      "Epoch 1603/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1950 - f1: 0.8215 - val_loss: 0.3092 - val_f1: 0.0586\n",
      "Epoch 1604/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1966 - f1: 0.8202 - val_loss: 0.3096 - val_f1: 0.0587\n",
      "Epoch 1605/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.1954 - f1: 0.8212 - val_loss: 0.3096 - val_f1: 0.0588\n",
      "Epoch 1606/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1955 - f1: 0.8197 - val_loss: 0.3092 - val_f1: 0.0585\n",
      "Epoch 1607/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1958 - f1: 0.8192 - val_loss: 0.3090 - val_f1: 0.0591\n",
      "Epoch 1608/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1956 - f1: 0.8216 - val_loss: 0.3089 - val_f1: 0.0588\n",
      "Epoch 1609/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1968 - f1: 0.8199 - val_loss: 0.3090 - val_f1: 0.0587\n",
      "Epoch 1610/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1966 - f1: 0.8200 - val_loss: 0.3085 - val_f1: 0.0583\n",
      "Epoch 1611/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.1968 - f1: 0.8204 - val_loss: 0.3080 - val_f1: 0.0582\n",
      "Epoch 1634/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1960 - f1: 0.8200 - val_loss: 0.3088 - val_f1: 0.0589\n",
      "Epoch 1635/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1970 - f1: 0.8189 - val_loss: 0.3089 - val_f1: 0.0588\n",
      "Epoch 1636/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.1948 - f1: 0.8221 - val_loss: 0.3098 - val_f1: 0.0589\n",
      "Epoch 1637/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1974 - f1: 0.8186 - val_loss: 0.3085 - val_f1: 0.0585\n",
      "Epoch 1638/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1946 - f1: 0.8214 - val_loss: 0.3097 - val_f1: 0.0585\n",
      "Epoch 1639/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1959 - f1: 0.8218 - val_loss: 0.3100 - val_f1: 0.0588\n",
      "Epoch 1640/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.1960 - f1: 0.8195 - val_loss: 0.3095 - val_f1: 0.0583\n",
      "Epoch 1641/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.1948 - f1: 0.8205 - val_loss: 0.3099 - val_f1: 0.0583\n",
      "Epoch 1642/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1960 - f1: 0.8202 - val_loss: 0.3092 - val_f1: 0.0591\n",
      "Epoch 1643/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.1969 - f1: 0.8203 - val_loss: 0.3083 - val_f1: 0.0586\n",
      "Epoch 1644/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1958 - f1: 0.8212 - val_loss: 0.3087 - val_f1: 0.0584\n",
      "Epoch 1645/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1954 - f1: 0.8203 - val_loss: 0.3091 - val_f1: 0.0590\n",
      "Epoch 1646/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1950 - f1: 0.8232 - val_loss: 0.3101 - val_f1: 0.0584\n",
      "Epoch 1647/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1933 - f1: 0.8236 - val_loss: 0.3114 - val_f1: 0.0589\n",
      "Epoch 1648/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1959 - f1: 0.8211 - val_loss: 0.3092 - val_f1: 0.0582\n",
      "Epoch 1649/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1953 - f1: 0.8210 - val_loss: 0.3096 - val_f1: 0.0588\n",
      "Epoch 1650/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1938 - f1: 0.8240 - val_loss: 0.3105 - val_f1: 0.0586\n",
      "Epoch 1651/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1942 - f1: 0.8232 - val_loss: 0.3103 - val_f1: 0.0589\n",
      "Epoch 1652/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1958 - f1: 0.8202 - val_loss: 0.3106 - val_f1: 0.0588\n",
      "Epoch 1653/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1953 - f1: 0.8212 - val_loss: 0.3097 - val_f1: 0.0588\n",
      "Epoch 1654/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1953 - f1: 0.8214 - val_loss: 0.3108 - val_f1: 0.0586\n",
      "Epoch 1655/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1945 - f1: 0.8215 - val_loss: 0.3099 - val_f1: 0.0585\n",
      "Epoch 1656/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1960 - f1: 0.8205 - val_loss: 0.3088 - val_f1: 0.0588\n",
      "Epoch 1657/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1967 - f1: 0.8193 - val_loss: 0.3096 - val_f1: 0.0585\n",
      "Epoch 1658/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1953 - f1: 0.8211 - val_loss: 0.3090 - val_f1: 0.0582\n",
      "Epoch 1659/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1963 - f1: 0.8206 - val_loss: 0.3100 - val_f1: 0.0586\n",
      "Epoch 1660/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1954 - f1: 0.8222 - val_loss: 0.3103 - val_f1: 0.0584\n",
      "Epoch 1661/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1951 - f1: 0.8197 - val_loss: 0.3102 - val_f1: 0.0581\n",
      "Epoch 1662/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1961 - f1: 0.8206 - val_loss: 0.3088 - val_f1: 0.0580\n",
      "Epoch 1663/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1958 - f1: 0.8213 - val_loss: 0.3091 - val_f1: 0.0586\n",
      "Epoch 1664/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1956 - f1: 0.8196 - val_loss: 0.3099 - val_f1: 0.0587\n",
      "Epoch 1665/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1953 - f1: 0.8210 - val_loss: 0.3098 - val_f1: 0.0581\n",
      "Epoch 1666/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1955 - f1: 0.8209 - val_loss: 0.3093 - val_f1: 0.0585\n",
      "Epoch 1667/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1968 - f1: 0.8206 - val_loss: 0.3092 - val_f1: 0.0589\n",
      "Epoch 1668/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1953 - f1: 0.8210 - val_loss: 0.3100 - val_f1: 0.0589\n",
      "Epoch 1669/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1946 - f1: 0.8217 - val_loss: 0.3107 - val_f1: 0.0590\n",
      "Epoch 1670/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1942 - f1: 0.8237 - val_loss: 0.3101 - val_f1: 0.0582\n",
      "Epoch 1671/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1957 - f1: 0.8201 - val_loss: 0.3103 - val_f1: 0.0591\n",
      "Epoch 1672/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1952 - f1: 0.8226 - val_loss: 0.3099 - val_f1: 0.0583\n",
      "Epoch 1673/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1953 - f1: 0.8227 - val_loss: 0.3105 - val_f1: 0.0592\n",
      "Epoch 1674/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1949 - f1: 0.8232 - val_loss: 0.3103 - val_f1: 0.0590\n",
      "Epoch 1675/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1948 - f1: 0.8215 - val_loss: 0.3109 - val_f1: 0.0593\n",
      "Epoch 1676/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1940 - f1: 0.8231 - val_loss: 0.3107 - val_f1: 0.0593\n",
      "Epoch 1677/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1942 - f1: 0.8225 - val_loss: 0.3097 - val_f1: 0.0586\n",
      "Epoch 1678/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1958 - f1: 0.8196 - val_loss: 0.3095 - val_f1: 0.0589\n",
      "Epoch 1679/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1944 - f1: 0.8229 - val_loss: 0.3102 - val_f1: 0.0586\n",
      "Epoch 1680/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1961 - f1: 0.8207 - val_loss: 0.3105 - val_f1: 0.0591\n",
      "Epoch 1681/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1948 - f1: 0.8209 - val_loss: 0.3105 - val_f1: 0.0583\n",
      "Epoch 1682/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1962 - f1: 0.8207 - val_loss: 0.3091 - val_f1: 0.0587\n",
      "Epoch 1683/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1954 - f1: 0.8213 - val_loss: 0.3093 - val_f1: 0.0585\n",
      "Epoch 1684/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1942 - f1: 0.8231 - val_loss: 0.3099 - val_f1: 0.0585\n",
      "Epoch 1685/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1958 - f1: 0.8211 - val_loss: 0.3099 - val_f1: 0.0593\n",
      "Epoch 1686/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1951 - f1: 0.8223 - val_loss: 0.3098 - val_f1: 0.0589\n",
      "Epoch 1687/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1948 - f1: 0.8214 - val_loss: 0.3103 - val_f1: 0.0593\n",
      "Epoch 1688/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1949 - f1: 0.8213 - val_loss: 0.3109 - val_f1: 0.0585\n",
      "Epoch 1689/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1927 - f1: 0.8215 - val_loss: 0.3111 - val_f1: 0.0590\n",
      "Epoch 1690/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1937 - f1: 0.8234 - val_loss: 0.3108 - val_f1: 0.0584\n",
      "Epoch 1691/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1959 - f1: 0.8227 - val_loss: 0.3106 - val_f1: 0.0587\n",
      "Epoch 1692/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1949 - f1: 0.8235 - val_loss: 0.3099 - val_f1: 0.0585\n",
      "Epoch 1693/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1963 - f1: 0.8207 - val_loss: 0.3097 - val_f1: 0.0587\n",
      "Epoch 1694/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1951 - f1: 0.8208 - val_loss: 0.3098 - val_f1: 0.0584\n",
      "Epoch 1695/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1946 - f1: 0.8214 - val_loss: 0.3098 - val_f1: 0.0586\n",
      "Epoch 1696/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1943 - f1: 0.8216 - val_loss: 0.3100 - val_f1: 0.0585\n",
      "Epoch 1697/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1954 - f1: 0.8217 - val_loss: 0.3097 - val_f1: 0.0586\n",
      "Epoch 1698/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1938 - f1: 0.8230 - val_loss: 0.3099 - val_f1: 0.0585\n",
      "Epoch 1699/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1951 - f1: 0.8229 - val_loss: 0.3104 - val_f1: 0.0587\n",
      "Epoch 1700/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1936 - f1: 0.8251 - val_loss: 0.3104 - val_f1: 0.0585\n",
      "Epoch 1701/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1933 - f1: 0.8220 - val_loss: 0.3107 - val_f1: 0.0585\n",
      "Epoch 1702/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1949 - f1: 0.8223 - val_loss: 0.3097 - val_f1: 0.0589\n",
      "Epoch 1703/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1934 - f1: 0.8233 - val_loss: 0.3110 - val_f1: 0.0587\n",
      "Epoch 1704/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1931 - f1: 0.8232 - val_loss: 0.3111 - val_f1: 0.0590\n",
      "Epoch 1705/2000\n",
      "168135/168135 [==============================] - 11s 62us/step - loss: 0.1959 - f1: 0.8207 - val_loss: 0.3104 - val_f1: 0.0587\n",
      "Epoch 1706/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1952 - f1: 0.8213 - val_loss: 0.3099 - val_f1: 0.0585\n",
      "Epoch 1707/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1932 - f1: 0.8241 - val_loss: 0.3106 - val_f1: 0.0590\n",
      "Epoch 1708/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1947 - f1: 0.8225 - val_loss: 0.3106 - val_f1: 0.0590\n",
      "Epoch 1709/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1950 - f1: 0.8221 - val_loss: 0.3100 - val_f1: 0.0583\n",
      "Epoch 1710/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1935 - f1: 0.8240 - val_loss: 0.3112 - val_f1: 0.0585\n",
      "Epoch 1711/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1961 - f1: 0.8211 - val_loss: 0.3088 - val_f1: 0.0591\n",
      "Epoch 1712/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1946 - f1: 0.8228 - val_loss: 0.3097 - val_f1: 0.0588\n",
      "Epoch 1713/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1941 - f1: 0.8235 - val_loss: 0.3101 - val_f1: 0.0585\n",
      "Epoch 1714/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1945 - f1: 0.8208 - val_loss: 0.3098 - val_f1: 0.0587\n",
      "Epoch 1715/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1951 - f1: 0.8208 - val_loss: 0.3100 - val_f1: 0.0585\n",
      "Epoch 1716/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1971 - f1: 0.8196 - val_loss: 0.3093 - val_f1: 0.0585\n",
      "Epoch 1717/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1933 - f1: 0.8242 - val_loss: 0.3107 - val_f1: 0.0583\n",
      "Epoch 1718/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1950 - f1: 0.8208 - val_loss: 0.3104 - val_f1: 0.0585\n",
      "Epoch 1719/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1940 - f1: 0.8230 - val_loss: 0.3111 - val_f1: 0.0581\n",
      "Epoch 1720/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1947 - f1: 0.8228 - val_loss: 0.3113 - val_f1: 0.0587\n",
      "Epoch 1721/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1950 - f1: 0.8214 - val_loss: 0.3090 - val_f1: 0.0584\n",
      "Epoch 1722/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1956 - f1: 0.8193 - val_loss: 0.3097 - val_f1: 0.0585\n",
      "Epoch 1723/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1961 - f1: 0.8214 - val_loss: 0.3092 - val_f1: 0.0588\n",
      "Epoch 1724/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1943 - f1: 0.8231 - val_loss: 0.3103 - val_f1: 0.0593\n",
      "Epoch 1725/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1954 - f1: 0.8212 - val_loss: 0.3091 - val_f1: 0.0585\n",
      "Epoch 1726/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1953 - f1: 0.8201 - val_loss: 0.3095 - val_f1: 0.0592\n",
      "Epoch 1727/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1936 - f1: 0.8225 - val_loss: 0.3098 - val_f1: 0.0583\n",
      "Epoch 1728/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1961 - f1: 0.8202 - val_loss: 0.3106 - val_f1: 0.0591\n",
      "Epoch 1729/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1954 - f1: 0.8207 - val_loss: 0.3093 - val_f1: 0.0581\n",
      "Epoch 1730/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1964 - f1: 0.8192 - val_loss: 0.3096 - val_f1: 0.0590\n",
      "Epoch 1731/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1946 - f1: 0.8209 - val_loss: 0.3098 - val_f1: 0.0588\n",
      "Epoch 1732/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1933 - f1: 0.8240 - val_loss: 0.3106 - val_f1: 0.0585\n",
      "Epoch 1733/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1953 - f1: 0.8226 - val_loss: 0.3101 - val_f1: 0.0584\n",
      "Epoch 1734/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1962 - f1: 0.8201 - val_loss: 0.3097 - val_f1: 0.0588\n",
      "Epoch 1735/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1948 - f1: 0.8213 - val_loss: 0.3103 - val_f1: 0.0587\n",
      "Epoch 1736/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1946 - f1: 0.8225 - val_loss: 0.3107 - val_f1: 0.0587\n",
      "Epoch 1737/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1948 - f1: 0.8225 - val_loss: 0.3093 - val_f1: 0.0589\n",
      "Epoch 1738/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1931 - f1: 0.8231 - val_loss: 0.3100 - val_f1: 0.0589\n",
      "Epoch 1739/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1925 - f1: 0.8252 - val_loss: 0.3111 - val_f1: 0.0591\n",
      "Epoch 1740/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1949 - f1: 0.8218 - val_loss: 0.3105 - val_f1: 0.0588\n",
      "Epoch 1741/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1948 - f1: 0.8224 - val_loss: 0.3107 - val_f1: 0.0594\n",
      "Epoch 1742/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1943 - f1: 0.8211 - val_loss: 0.3102 - val_f1: 0.0586\n",
      "Epoch 1743/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1947 - f1: 0.8222 - val_loss: 0.3097 - val_f1: 0.0583\n",
      "Epoch 1744/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1948 - f1: 0.8218 - val_loss: 0.3098 - val_f1: 0.0587\n",
      "Epoch 1745/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1947 - f1: 0.8204 - val_loss: 0.3106 - val_f1: 0.0588\n",
      "Epoch 1746/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1940 - f1: 0.8216 - val_loss: 0.3106 - val_f1: 0.0588\n",
      "Epoch 1747/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1939 - f1: 0.8227 - val_loss: 0.3104 - val_f1: 0.0587\n",
      "Epoch 1748/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1964 - f1: 0.8210 - val_loss: 0.3093 - val_f1: 0.0586\n",
      "Epoch 1749/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1944 - f1: 0.8231 - val_loss: 0.3099 - val_f1: 0.0587\n",
      "Epoch 1750/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1937 - f1: 0.8222 - val_loss: 0.3110 - val_f1: 0.0587\n",
      "Epoch 1751/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1951 - f1: 0.8202 - val_loss: 0.3104 - val_f1: 0.0580\n",
      "Epoch 1752/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1939 - f1: 0.8233 - val_loss: 0.3110 - val_f1: 0.0586\n",
      "Epoch 1753/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1964 - f1: 0.8203 - val_loss: 0.3102 - val_f1: 0.0586\n",
      "Epoch 1754/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1944 - f1: 0.8226 - val_loss: 0.3097 - val_f1: 0.0586\n",
      "Epoch 1755/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1942 - f1: 0.8231 - val_loss: 0.3095 - val_f1: 0.0582\n",
      "Epoch 1756/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1940 - f1: 0.8235 - val_loss: 0.3097 - val_f1: 0.0590\n",
      "Epoch 1757/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.1943 - f1: 0.8233 - val_loss: 0.3101 - val_f1: 0.0585\n",
      "Epoch 1758/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1938 - f1: 0.8218 - val_loss: 0.3102 - val_f1: 0.0585\n",
      "Epoch 1759/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1934 - f1: 0.8239 - val_loss: 0.3101 - val_f1: 0.0585\n",
      "Epoch 1760/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1955 - f1: 0.8200 - val_loss: 0.3101 - val_f1: 0.0586\n",
      "Epoch 1761/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1940 - f1: 0.8230 - val_loss: 0.3110 - val_f1: 0.0582\n",
      "Epoch 1762/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1950 - f1: 0.8228 - val_loss: 0.3100 - val_f1: 0.0589\n",
      "Epoch 1763/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1950 - f1: 0.8190 - val_loss: 0.3101 - val_f1: 0.0591\n",
      "Epoch 1764/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1919 - f1: 0.8235 - val_loss: 0.3113 - val_f1: 0.0586\n",
      "Epoch 1765/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1951 - f1: 0.8205 - val_loss: 0.3105 - val_f1: 0.0584\n",
      "Epoch 1766/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1933 - f1: 0.8240 - val_loss: 0.3113 - val_f1: 0.0580\n",
      "Epoch 1767/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1944 - f1: 0.8203 - val_loss: 0.3104 - val_f1: 0.0588\n",
      "Epoch 1768/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1938 - f1: 0.8241 - val_loss: 0.3105 - val_f1: 0.0586\n",
      "Epoch 1769/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1947 - f1: 0.8217 - val_loss: 0.3108 - val_f1: 0.0594\n",
      "Epoch 1770/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1945 - f1: 0.8220 - val_loss: 0.3105 - val_f1: 0.0584\n",
      "Epoch 1771/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1949 - f1: 0.8216 - val_loss: 0.3098 - val_f1: 0.0590\n",
      "Epoch 1772/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1957 - f1: 0.8203 - val_loss: 0.3094 - val_f1: 0.0588\n",
      "Epoch 1773/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1931 - f1: 0.8233 - val_loss: 0.3111 - val_f1: 0.0584\n",
      "Epoch 1774/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1925 - f1: 0.8235 - val_loss: 0.3113 - val_f1: 0.0585\n",
      "Epoch 1775/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1953 - f1: 0.8224 - val_loss: 0.3104 - val_f1: 0.0580\n",
      "Epoch 1776/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1940 - f1: 0.8219 - val_loss: 0.3102 - val_f1: 0.0586\n",
      "Epoch 1777/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1944 - f1: 0.8217 - val_loss: 0.3098 - val_f1: 0.0585\n",
      "Epoch 1778/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1946 - f1: 0.8224 - val_loss: 0.3106 - val_f1: 0.0585\n",
      "Epoch 1779/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1937 - f1: 0.8230 - val_loss: 0.3101 - val_f1: 0.0582\n",
      "Epoch 1780/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.1924 - f1: 0.8222 - val_loss: 0.3106 - val_f1: 0.0584\n",
      "Epoch 1781/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1932 - f1: 0.8229 - val_loss: 0.3111 - val_f1: 0.0586\n",
      "Epoch 1782/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1937 - f1: 0.8214 - val_loss: 0.3110 - val_f1: 0.0583\n",
      "Epoch 1783/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1947 - f1: 0.8216 - val_loss: 0.3105 - val_f1: 0.0588\n",
      "Epoch 1784/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1936 - f1: 0.8255 - val_loss: 0.3102 - val_f1: 0.0588\n",
      "Epoch 1785/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1932 - f1: 0.8243 - val_loss: 0.3110 - val_f1: 0.0586\n",
      "Epoch 1786/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1933 - f1: 0.8251 - val_loss: 0.3103 - val_f1: 0.0582\n",
      "Epoch 1787/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1956 - f1: 0.8226 - val_loss: 0.3102 - val_f1: 0.0588\n",
      "Epoch 1788/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1938 - f1: 0.8239 - val_loss: 0.3106 - val_f1: 0.0584\n",
      "Epoch 1789/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1935 - f1: 0.8235 - val_loss: 0.3101 - val_f1: 0.0586\n",
      "Epoch 1790/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1918 - f1: 0.8239 - val_loss: 0.3107 - val_f1: 0.0587\n",
      "Epoch 1791/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1948 - f1: 0.8205 - val_loss: 0.3100 - val_f1: 0.0586\n",
      "Epoch 1792/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1936 - f1: 0.8227 - val_loss: 0.3109 - val_f1: 0.0587\n",
      "Epoch 1793/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1921 - f1: 0.8221 - val_loss: 0.3114 - val_f1: 0.0588\n",
      "Epoch 1794/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1948 - f1: 0.8199 - val_loss: 0.3105 - val_f1: 0.0590\n",
      "Epoch 1795/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.1935 - f1: 0.8239 - val_loss: 0.3103 - val_f1: 0.0587\n",
      "Epoch 1796/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.1952 - f1: 0.8232 - val_loss: 0.3108 - val_f1: 0.0587\n",
      "Epoch 1797/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1939 - f1: 0.8235 - val_loss: 0.3100 - val_f1: 0.0586\n",
      "Epoch 1798/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1955 - f1: 0.8214 - val_loss: 0.3095 - val_f1: 0.0586\n",
      "Epoch 1799/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1948 - f1: 0.8225 - val_loss: 0.3098 - val_f1: 0.0588\n",
      "Epoch 1800/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1941 - f1: 0.8227 - val_loss: 0.3104 - val_f1: 0.0589\n",
      "Epoch 1801/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1940 - f1: 0.8232 - val_loss: 0.3101 - val_f1: 0.0591\n",
      "Epoch 1802/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1926 - f1: 0.8228 - val_loss: 0.3109 - val_f1: 0.0586\n",
      "Epoch 1803/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1943 - f1: 0.8239 - val_loss: 0.3098 - val_f1: 0.0588\n",
      "Epoch 1804/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1938 - f1: 0.8219 - val_loss: 0.3099 - val_f1: 0.0585\n",
      "Epoch 1805/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1931 - f1: 0.8246 - val_loss: 0.3103 - val_f1: 0.0583\n",
      "Epoch 1806/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1936 - f1: 0.8221 - val_loss: 0.3105 - val_f1: 0.0584\n",
      "Epoch 1807/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1946 - f1: 0.8228 - val_loss: 0.3105 - val_f1: 0.0587\n",
      "Epoch 1808/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1933 - f1: 0.8238 - val_loss: 0.3105 - val_f1: 0.0587\n",
      "Epoch 1809/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1924 - f1: 0.8238 - val_loss: 0.3118 - val_f1: 0.0584\n",
      "Epoch 1810/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1937 - f1: 0.8237 - val_loss: 0.3109 - val_f1: 0.0587\n",
      "Epoch 1811/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.1940 - f1: 0.8239 - val_loss: 0.3109 - val_f1: 0.0588\n",
      "Epoch 1812/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1948 - f1: 0.8226 - val_loss: 0.3101 - val_f1: 0.0588\n",
      "Epoch 1813/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1925 - f1: 0.8230 - val_loss: 0.3106 - val_f1: 0.0583\n",
      "Epoch 1814/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1940 - f1: 0.8230 - val_loss: 0.3107 - val_f1: 0.0587\n",
      "Epoch 1815/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1937 - f1: 0.8227 - val_loss: 0.3106 - val_f1: 0.0590\n",
      "Epoch 1816/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1935 - f1: 0.8241 - val_loss: 0.3106 - val_f1: 0.0586\n",
      "Epoch 1817/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1922 - f1: 0.8228 - val_loss: 0.3114 - val_f1: 0.0585\n",
      "Epoch 1818/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1941 - f1: 0.8229 - val_loss: 0.3110 - val_f1: 0.0587\n",
      "Epoch 1819/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.1937 - f1: 0.8219 - val_loss: 0.3112 - val_f1: 0.0589\n",
      "Epoch 1820/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1930 - f1: 0.8235 - val_loss: 0.3106 - val_f1: 0.0588\n",
      "Epoch 1821/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1928 - f1: 0.8240 - val_loss: 0.3113 - val_f1: 0.0590\n",
      "Epoch 1822/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1961 - f1: 0.8215 - val_loss: 0.3100 - val_f1: 0.0590\n",
      "Epoch 1823/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1942 - f1: 0.8228 - val_loss: 0.3102 - val_f1: 0.0590\n",
      "Epoch 1824/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1921 - f1: 0.8230 - val_loss: 0.3118 - val_f1: 0.0589\n",
      "Epoch 1825/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1931 - f1: 0.8230 - val_loss: 0.3118 - val_f1: 0.0591\n",
      "Epoch 1826/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1918 - f1: 0.8242 - val_loss: 0.3116 - val_f1: 0.0586\n",
      "Epoch 1827/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1929 - f1: 0.8239 - val_loss: 0.3112 - val_f1: 0.0587\n",
      "Epoch 1828/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1935 - f1: 0.8221 - val_loss: 0.3115 - val_f1: 0.0587\n",
      "Epoch 1829/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1922 - f1: 0.8219 - val_loss: 0.3109 - val_f1: 0.0588\n",
      "Epoch 1830/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1935 - f1: 0.8236 - val_loss: 0.3107 - val_f1: 0.0586\n",
      "Epoch 1831/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1944 - f1: 0.8239 - val_loss: 0.3100 - val_f1: 0.0585\n",
      "Epoch 1832/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1921 - f1: 0.8230 - val_loss: 0.3117 - val_f1: 0.0593\n",
      "Epoch 1833/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1933 - f1: 0.8236 - val_loss: 0.3107 - val_f1: 0.0587\n",
      "Epoch 1834/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1928 - f1: 0.8266 - val_loss: 0.3110 - val_f1: 0.0587\n",
      "Epoch 1835/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1936 - f1: 0.8221 - val_loss: 0.3111 - val_f1: 0.0585\n",
      "Epoch 1836/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1936 - f1: 0.8241 - val_loss: 0.3101 - val_f1: 0.0587\n",
      "Epoch 1837/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1926 - f1: 0.8249 - val_loss: 0.3121 - val_f1: 0.0589\n",
      "Epoch 1838/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1932 - f1: 0.8248 - val_loss: 0.3114 - val_f1: 0.0585\n",
      "Epoch 1839/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1929 - f1: 0.8234 - val_loss: 0.3106 - val_f1: 0.0587\n",
      "Epoch 1840/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1946 - f1: 0.8209 - val_loss: 0.3108 - val_f1: 0.0587\n",
      "Epoch 1841/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1945 - f1: 0.8229 - val_loss: 0.3094 - val_f1: 0.0584\n",
      "Epoch 1842/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1932 - f1: 0.8226 - val_loss: 0.3115 - val_f1: 0.0586\n",
      "Epoch 1843/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1917 - f1: 0.8245 - val_loss: 0.3116 - val_f1: 0.0583\n",
      "Epoch 1844/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1932 - f1: 0.8231 - val_loss: 0.3109 - val_f1: 0.0587\n",
      "Epoch 1845/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1937 - f1: 0.8235 - val_loss: 0.3111 - val_f1: 0.0590\n",
      "Epoch 1846/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1917 - f1: 0.8237 - val_loss: 0.3110 - val_f1: 0.0585\n",
      "Epoch 1847/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1924 - f1: 0.8236 - val_loss: 0.3119 - val_f1: 0.0591\n",
      "Epoch 1848/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1923 - f1: 0.8246 - val_loss: 0.3114 - val_f1: 0.0587\n",
      "Epoch 1849/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1926 - f1: 0.8228 - val_loss: 0.3113 - val_f1: 0.0584\n",
      "Epoch 1850/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1922 - f1: 0.8247 - val_loss: 0.3120 - val_f1: 0.0586\n",
      "Epoch 1851/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1926 - f1: 0.8253 - val_loss: 0.3114 - val_f1: 0.0583\n",
      "Epoch 1852/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1927 - f1: 0.8237 - val_loss: 0.3112 - val_f1: 0.0586\n",
      "Epoch 1853/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1927 - f1: 0.8237 - val_loss: 0.3106 - val_f1: 0.0589\n",
      "Epoch 1854/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1930 - f1: 0.8232 - val_loss: 0.3110 - val_f1: 0.0590\n",
      "Epoch 1855/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1941 - f1: 0.8243 - val_loss: 0.3108 - val_f1: 0.0586\n",
      "Epoch 1856/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1914 - f1: 0.8253 - val_loss: 0.3114 - val_f1: 0.0587\n",
      "Epoch 1857/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1923 - f1: 0.8229 - val_loss: 0.3109 - val_f1: 0.0587\n",
      "Epoch 1858/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1938 - f1: 0.8241 - val_loss: 0.3106 - val_f1: 0.0584\n",
      "Epoch 1859/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1934 - f1: 0.8244 - val_loss: 0.3104 - val_f1: 0.0588\n",
      "Epoch 1860/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1929 - f1: 0.8240 - val_loss: 0.3109 - val_f1: 0.0585\n",
      "Epoch 1861/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1924 - f1: 0.8243 - val_loss: 0.3116 - val_f1: 0.0588\n",
      "Epoch 1862/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1942 - f1: 0.8208 - val_loss: 0.3114 - val_f1: 0.0593\n",
      "Epoch 1863/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1930 - f1: 0.8236 - val_loss: 0.3107 - val_f1: 0.0579\n",
      "Epoch 1864/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1930 - f1: 0.8228 - val_loss: 0.3107 - val_f1: 0.0587\n",
      "Epoch 1865/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1911 - f1: 0.8266 - val_loss: 0.3118 - val_f1: 0.0586\n",
      "Epoch 1866/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1936 - f1: 0.8235 - val_loss: 0.3111 - val_f1: 0.0583\n",
      "Epoch 1867/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1928 - f1: 0.8244 - val_loss: 0.3108 - val_f1: 0.0583\n",
      "Epoch 1868/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1921 - f1: 0.8243 - val_loss: 0.3112 - val_f1: 0.0579\n",
      "Epoch 1869/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1919 - f1: 0.8255 - val_loss: 0.3113 - val_f1: 0.0584\n",
      "Epoch 1870/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1923 - f1: 0.8239 - val_loss: 0.3114 - val_f1: 0.0586\n",
      "Epoch 1871/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1946 - f1: 0.8236 - val_loss: 0.3110 - val_f1: 0.0587\n",
      "Epoch 1872/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1910 - f1: 0.8251 - val_loss: 0.3119 - val_f1: 0.0584\n",
      "Epoch 1873/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1922 - f1: 0.8241 - val_loss: 0.3115 - val_f1: 0.0583\n",
      "Epoch 1874/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1930 - f1: 0.8234 - val_loss: 0.3110 - val_f1: 0.0586\n",
      "Epoch 1875/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1925 - f1: 0.8223 - val_loss: 0.3104 - val_f1: 0.0581\n",
      "Epoch 1876/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.1923 - f1: 0.8247 - val_loss: 0.3111 - val_f1: 0.0587\n",
      "Epoch 1877/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1936 - f1: 0.8234 - val_loss: 0.3107 - val_f1: 0.0587\n",
      "Epoch 1878/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1918 - f1: 0.8232 - val_loss: 0.3118 - val_f1: 0.0586\n",
      "Epoch 1879/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1928 - f1: 0.8265 - val_loss: 0.3106 - val_f1: 0.0582\n",
      "Epoch 1880/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1934 - f1: 0.8232 - val_loss: 0.3105 - val_f1: 0.0590\n",
      "Epoch 1881/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1936 - f1: 0.8222 - val_loss: 0.3110 - val_f1: 0.0586\n",
      "Epoch 1882/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1930 - f1: 0.8248 - val_loss: 0.3102 - val_f1: 0.0590\n",
      "Epoch 1883/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1936 - f1: 0.8231 - val_loss: 0.3097 - val_f1: 0.0588\n",
      "Epoch 1884/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1932 - f1: 0.8237 - val_loss: 0.3106 - val_f1: 0.0587\n",
      "Epoch 1885/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1911 - f1: 0.8234 - val_loss: 0.3114 - val_f1: 0.0589\n",
      "Epoch 1886/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1917 - f1: 0.8247 - val_loss: 0.3130 - val_f1: 0.0582\n",
      "Epoch 1887/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1916 - f1: 0.8267 - val_loss: 0.3114 - val_f1: 0.0584\n",
      "Epoch 1888/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1930 - f1: 0.8240 - val_loss: 0.3122 - val_f1: 0.0587\n",
      "Epoch 1889/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1927 - f1: 0.8254 - val_loss: 0.3122 - val_f1: 0.0590\n",
      "Epoch 1890/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1940 - f1: 0.8219 - val_loss: 0.3110 - val_f1: 0.0591\n",
      "Epoch 1891/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1922 - f1: 0.8253 - val_loss: 0.3113 - val_f1: 0.0582\n",
      "Epoch 1892/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1943 - f1: 0.8220 - val_loss: 0.3105 - val_f1: 0.0582\n",
      "Epoch 1893/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1920 - f1: 0.8248 - val_loss: 0.3113 - val_f1: 0.0591\n",
      "Epoch 1894/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1932 - f1: 0.8240 - val_loss: 0.3110 - val_f1: 0.0590\n",
      "Epoch 1895/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1938 - f1: 0.8241 - val_loss: 0.3105 - val_f1: 0.0585\n",
      "Epoch 1896/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1922 - f1: 0.8249 - val_loss: 0.3119 - val_f1: 0.0587\n",
      "Epoch 1897/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1912 - f1: 0.8267 - val_loss: 0.3119 - val_f1: 0.0584\n",
      "Epoch 1898/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1894 - f1: 0.8279 - val_loss: 0.3130 - val_f1: 0.0590\n",
      "Epoch 1899/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1916 - f1: 0.8255 - val_loss: 0.3121 - val_f1: 0.0584\n",
      "Epoch 1900/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1916 - f1: 0.8238 - val_loss: 0.3127 - val_f1: 0.0587\n",
      "Epoch 1901/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1935 - f1: 0.8258 - val_loss: 0.3112 - val_f1: 0.0586\n",
      "Epoch 1902/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1926 - f1: 0.8235 - val_loss: 0.3117 - val_f1: 0.0584\n",
      "Epoch 1903/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1930 - f1: 0.8243 - val_loss: 0.3113 - val_f1: 0.0588\n",
      "Epoch 1904/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1936 - f1: 0.8220 - val_loss: 0.3108 - val_f1: 0.0593\n",
      "Epoch 1905/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1928 - f1: 0.8243 - val_loss: 0.3106 - val_f1: 0.0589\n",
      "Epoch 1906/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1936 - f1: 0.8252 - val_loss: 0.3105 - val_f1: 0.0581\n",
      "Epoch 1907/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1924 - f1: 0.8220 - val_loss: 0.3117 - val_f1: 0.0585\n",
      "Epoch 1908/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1918 - f1: 0.8253 - val_loss: 0.3113 - val_f1: 0.0585\n",
      "Epoch 1909/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1927 - f1: 0.8248 - val_loss: 0.3119 - val_f1: 0.0590\n",
      "Epoch 1910/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1920 - f1: 0.8253 - val_loss: 0.3122 - val_f1: 0.0589\n",
      "Epoch 1911/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1925 - f1: 0.8243 - val_loss: 0.3111 - val_f1: 0.0586\n",
      "Epoch 1912/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1913 - f1: 0.8258 - val_loss: 0.3123 - val_f1: 0.0587\n",
      "Epoch 1913/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1926 - f1: 0.8259 - val_loss: 0.3113 - val_f1: 0.0582\n",
      "Epoch 1914/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1934 - f1: 0.8224 - val_loss: 0.3105 - val_f1: 0.0585\n",
      "Epoch 1915/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1904 - f1: 0.8255 - val_loss: 0.3125 - val_f1: 0.0584\n",
      "Epoch 1916/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1935 - f1: 0.8222 - val_loss: 0.3110 - val_f1: 0.0590\n",
      "Epoch 1917/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1932 - f1: 0.8224 - val_loss: 0.3117 - val_f1: 0.0586\n",
      "Epoch 1918/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1928 - f1: 0.8239 - val_loss: 0.3115 - val_f1: 0.0592\n",
      "Epoch 1919/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1920 - f1: 0.8253 - val_loss: 0.3121 - val_f1: 0.0588\n",
      "Epoch 1920/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1910 - f1: 0.8259 - val_loss: 0.3120 - val_f1: 0.0587\n",
      "Epoch 1921/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1920 - f1: 0.8248 - val_loss: 0.3116 - val_f1: 0.0588\n",
      "Epoch 1922/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1912 - f1: 0.8240 - val_loss: 0.3119 - val_f1: 0.0589\n",
      "Epoch 1923/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1924 - f1: 0.8248 - val_loss: 0.3111 - val_f1: 0.0587\n",
      "Epoch 1924/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1916 - f1: 0.8264 - val_loss: 0.3117 - val_f1: 0.0583\n",
      "Epoch 1925/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1933 - f1: 0.8225 - val_loss: 0.3108 - val_f1: 0.0583\n",
      "Epoch 1926/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1924 - f1: 0.8243 - val_loss: 0.3118 - val_f1: 0.0580\n",
      "Epoch 1927/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.1908 - f1: 0.8259 - val_loss: 0.3120 - val_f1: 0.0584\n",
      "Epoch 1928/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1933 - f1: 0.8244 - val_loss: 0.3113 - val_f1: 0.0585\n",
      "Epoch 1929/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1925 - f1: 0.8254 - val_loss: 0.3114 - val_f1: 0.0592\n",
      "Epoch 1930/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1928 - f1: 0.8233 - val_loss: 0.3113 - val_f1: 0.0584\n",
      "Epoch 1931/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1916 - f1: 0.8243 - val_loss: 0.3115 - val_f1: 0.0587\n",
      "Epoch 1932/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1919 - f1: 0.8248 - val_loss: 0.3122 - val_f1: 0.0590\n",
      "Epoch 1933/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1930 - f1: 0.8225 - val_loss: 0.3115 - val_f1: 0.0588\n",
      "Epoch 1934/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1915 - f1: 0.8251 - val_loss: 0.3117 - val_f1: 0.0588\n",
      "Epoch 1935/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1931 - f1: 0.8248 - val_loss: 0.3110 - val_f1: 0.0583\n",
      "Epoch 1936/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1926 - f1: 0.8236 - val_loss: 0.3104 - val_f1: 0.0586\n",
      "Epoch 1937/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1922 - f1: 0.8240 - val_loss: 0.3114 - val_f1: 0.0590\n",
      "Epoch 1938/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1929 - f1: 0.8243 - val_loss: 0.3113 - val_f1: 0.0582\n",
      "Epoch 1939/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1921 - f1: 0.8243 - val_loss: 0.3122 - val_f1: 0.0589\n",
      "Epoch 1940/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1909 - f1: 0.8251 - val_loss: 0.3114 - val_f1: 0.0588\n",
      "Epoch 1941/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1921 - f1: 0.8251 - val_loss: 0.3120 - val_f1: 0.0587\n",
      "Epoch 1942/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1916 - f1: 0.8249 - val_loss: 0.3114 - val_f1: 0.0585\n",
      "Epoch 1943/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1912 - f1: 0.8261 - val_loss: 0.3118 - val_f1: 0.0588\n",
      "Epoch 1944/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1916 - f1: 0.8258 - val_loss: 0.3126 - val_f1: 0.0587\n",
      "Epoch 1945/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1916 - f1: 0.8253 - val_loss: 0.3113 - val_f1: 0.0586\n",
      "Epoch 1946/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1934 - f1: 0.8223 - val_loss: 0.3113 - val_f1: 0.0583\n",
      "Epoch 1947/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1916 - f1: 0.8263 - val_loss: 0.3114 - val_f1: 0.0588\n",
      "Epoch 1948/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1908 - f1: 0.8273 - val_loss: 0.3115 - val_f1: 0.0585\n",
      "Epoch 1949/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1911 - f1: 0.8250 - val_loss: 0.3120 - val_f1: 0.0582\n",
      "Epoch 1950/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1925 - f1: 0.8240 - val_loss: 0.3118 - val_f1: 0.0584\n",
      "Epoch 1951/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1915 - f1: 0.8250 - val_loss: 0.3124 - val_f1: 0.0592\n",
      "Epoch 1952/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1903 - f1: 0.8274 - val_loss: 0.3130 - val_f1: 0.0584\n",
      "Epoch 1953/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1925 - f1: 0.8241 - val_loss: 0.3112 - val_f1: 0.0585\n",
      "Epoch 1954/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1917 - f1: 0.8256 - val_loss: 0.3116 - val_f1: 0.0585\n",
      "Epoch 1955/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1917 - f1: 0.8237 - val_loss: 0.3127 - val_f1: 0.0588\n",
      "Epoch 1956/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1897 - f1: 0.8277 - val_loss: 0.3127 - val_f1: 0.0587\n",
      "Epoch 1957/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1893 - f1: 0.8264 - val_loss: 0.3134 - val_f1: 0.0586\n",
      "Epoch 1958/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1922 - f1: 0.8231 - val_loss: 0.3118 - val_f1: 0.0588\n",
      "Epoch 1959/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1916 - f1: 0.8262 - val_loss: 0.3123 - val_f1: 0.0582\n",
      "Epoch 1960/2000\n",
      "168135/168135 [==============================] - 11s 62us/step - loss: 0.1909 - f1: 0.8260 - val_loss: 0.3125 - val_f1: 0.0584\n",
      "Epoch 1961/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1921 - f1: 0.8246 - val_loss: 0.3126 - val_f1: 0.0587\n",
      "Epoch 1962/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1936 - f1: 0.8238 - val_loss: 0.3121 - val_f1: 0.0587\n",
      "Epoch 1963/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1914 - f1: 0.8237 - val_loss: 0.3111 - val_f1: 0.0584\n",
      "Epoch 1964/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1916 - f1: 0.8252 - val_loss: 0.3112 - val_f1: 0.0584\n",
      "Epoch 1965/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1921 - f1: 0.8252 - val_loss: 0.3114 - val_f1: 0.0590\n",
      "Epoch 1966/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1921 - f1: 0.8246 - val_loss: 0.3113 - val_f1: 0.0584\n",
      "Epoch 1967/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1926 - f1: 0.8244 - val_loss: 0.3108 - val_f1: 0.0587\n",
      "Epoch 1968/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1925 - f1: 0.8242 - val_loss: 0.3114 - val_f1: 0.0588\n",
      "Epoch 1969/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1924 - f1: 0.8234 - val_loss: 0.3107 - val_f1: 0.0592\n",
      "Epoch 1970/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1900 - f1: 0.8263 - val_loss: 0.3122 - val_f1: 0.0588\n",
      "Epoch 1971/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1919 - f1: 0.8260 - val_loss: 0.3130 - val_f1: 0.0586\n",
      "Epoch 1972/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1930 - f1: 0.8244 - val_loss: 0.3125 - val_f1: 0.0584\n",
      "Epoch 1973/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1921 - f1: 0.8237 - val_loss: 0.3111 - val_f1: 0.0587\n",
      "Epoch 1974/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1907 - f1: 0.8254 - val_loss: 0.3121 - val_f1: 0.0590\n",
      "Epoch 1975/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1915 - f1: 0.8252 - val_loss: 0.3120 - val_f1: 0.0585\n",
      "Epoch 1976/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1924 - f1: 0.8243 - val_loss: 0.3120 - val_f1: 0.0591\n",
      "Epoch 1977/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1917 - f1: 0.8261 - val_loss: 0.3114 - val_f1: 0.0584\n",
      "Epoch 1978/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1909 - f1: 0.8241 - val_loss: 0.3127 - val_f1: 0.0586\n",
      "Epoch 1979/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1921 - f1: 0.8243 - val_loss: 0.3117 - val_f1: 0.0586\n",
      "Epoch 1980/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1899 - f1: 0.8272 - val_loss: 0.3118 - val_f1: 0.0580\n",
      "Epoch 1981/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1921 - f1: 0.8232 - val_loss: 0.3129 - val_f1: 0.0591\n",
      "Epoch 1982/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1903 - f1: 0.8278 - val_loss: 0.3120 - val_f1: 0.0584\n",
      "Epoch 1983/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1911 - f1: 0.8248 - val_loss: 0.3120 - val_f1: 0.0584\n",
      "Epoch 1984/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1928 - f1: 0.8236 - val_loss: 0.3119 - val_f1: 0.0587\n",
      "Epoch 1985/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1917 - f1: 0.8246 - val_loss: 0.3110 - val_f1: 0.0583\n",
      "Epoch 1986/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1918 - f1: 0.8237 - val_loss: 0.3117 - val_f1: 0.0581\n",
      "Epoch 1987/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1923 - f1: 0.8253 - val_loss: 0.3121 - val_f1: 0.0583\n",
      "Epoch 1988/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1911 - f1: 0.8248 - val_loss: 0.3114 - val_f1: 0.0584\n",
      "Epoch 1989/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1928 - f1: 0.8243 - val_loss: 0.3118 - val_f1: 0.0590\n",
      "Epoch 1990/2000\n",
      "168135/168135 [==============================] - 11s 62us/step - loss: 0.1898 - f1: 0.8271 - val_loss: 0.3124 - val_f1: 0.0582\n",
      "Epoch 1991/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1919 - f1: 0.8241 - val_loss: 0.3120 - val_f1: 0.0586\n",
      "Epoch 1992/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1901 - f1: 0.8275 - val_loss: 0.3121 - val_f1: 0.0586\n",
      "Epoch 1993/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.1909 - f1: 0.8254 - val_loss: 0.3125 - val_f1: 0.0586\n",
      "Epoch 1994/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.1895 - f1: 0.8280 - val_loss: 0.3135 - val_f1: 0.0587\n",
      "Epoch 1995/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1932 - f1: 0.8215 - val_loss: 0.3123 - val_f1: 0.0588\n",
      "Epoch 1996/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1918 - f1: 0.8246 - val_loss: 0.3116 - val_f1: 0.0589\n",
      "Epoch 1997/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1910 - f1: 0.8257 - val_loss: 0.3125 - val_f1: 0.0591\n",
      "Epoch 1998/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1911 - f1: 0.8234 - val_loss: 0.3125 - val_f1: 0.0585\n",
      "Epoch 1999/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1908 - f1: 0.8264 - val_loss: 0.3125 - val_f1: 0.0585\n",
      "Epoch 2000/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1909 - f1: 0.8256 - val_loss: 0.3117 - val_f1: 0.0589\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna1.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[25519  1466]\n",
      " [ 1813  1202]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[25517  1469]\n",
      " [ 1757  1258]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[123905   2026]\n",
      " [  2157  40047]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna1.predict(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list2 = [50,50,1]\n",
    "activation_list2 = ['tanh','tanh','sigmoid']\n",
    "dropout_list2 = [0.3,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 12,651\n",
      "Trainable params: 12,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna2 = new_rna()\n",
    "rna2.build_model(data_shape,n_list2,activation_list2,dropout_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168135 samples, validate on 30001 samples\n",
      "Epoch 1/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.4100 - f1: 0.5619 - val_loss: 0.2791 - val_f1: 0.0692\n",
      "Epoch 2/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3928 - f1: 0.5861 - val_loss: 0.2817 - val_f1: 0.0709\n",
      "Epoch 3/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3905 - f1: 0.5905 - val_loss: 0.2793 - val_f1: 0.0708\n",
      "Epoch 4/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3891 - f1: 0.5945 - val_loss: 0.2811 - val_f1: 0.0707\n",
      "Epoch 5/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3876 - f1: 0.5967 - val_loss: 0.2813 - val_f1: 0.0709\n",
      "Epoch 6/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3874 - f1: 0.5986 - val_loss: 0.2820 - val_f1: 0.0711\n",
      "Epoch 7/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.3865 - f1: 0.5959 - val_loss: 0.2816 - val_f1: 0.0707\n",
      "Epoch 8/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3862 - f1: 0.5980 - val_loss: 0.2780 - val_f1: 0.0696\n",
      "Epoch 9/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3852 - f1: 0.5978 - val_loss: 0.2809 - val_f1: 0.0717\n",
      "Epoch 10/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3852 - f1: 0.5979 - val_loss: 0.2810 - val_f1: 0.0709\n",
      "Epoch 11/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3851 - f1: 0.5976 - val_loss: 0.2774 - val_f1: 0.0706\n",
      "Epoch 12/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3848 - f1: 0.5967 - val_loss: 0.2796 - val_f1: 0.0701\n",
      "Epoch 13/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3841 - f1: 0.5971 - val_loss: 0.2795 - val_f1: 0.0708\n",
      "Epoch 14/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3833 - f1: 0.5995 - val_loss: 0.2813 - val_f1: 0.0704\n",
      "Epoch 15/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3835 - f1: 0.5975 - val_loss: 0.2775 - val_f1: 0.0704\n",
      "Epoch 16/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3825 - f1: 0.6010 - val_loss: 0.2799 - val_f1: 0.0702\n",
      "Epoch 17/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3825 - f1: 0.5992 - val_loss: 0.2788 - val_f1: 0.0700\n",
      "Epoch 18/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3817 - f1: 0.5989 - val_loss: 0.2811 - val_f1: 0.0703\n",
      "Epoch 19/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3818 - f1: 0.6001 - val_loss: 0.2802 - val_f1: 0.0705\n",
      "Epoch 20/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3808 - f1: 0.5990 - val_loss: 0.2802 - val_f1: 0.0708\n",
      "Epoch 21/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3809 - f1: 0.5994 - val_loss: 0.2762 - val_f1: 0.0700\n",
      "Epoch 22/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3807 - f1: 0.5991 - val_loss: 0.2804 - val_f1: 0.0709\n",
      "Epoch 23/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3797 - f1: 0.6000 - val_loss: 0.2795 - val_f1: 0.0705\n",
      "Epoch 24/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3790 - f1: 0.6025 - val_loss: 0.2791 - val_f1: 0.0703\n",
      "Epoch 25/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3791 - f1: 0.6018 - val_loss: 0.2786 - val_f1: 0.0700\n",
      "Epoch 26/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3785 - f1: 0.6001 - val_loss: 0.2805 - val_f1: 0.0700\n",
      "Epoch 27/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3777 - f1: 0.6014 - val_loss: 0.2773 - val_f1: 0.0699\n",
      "Epoch 28/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3777 - f1: 0.6005 - val_loss: 0.2798 - val_f1: 0.0700\n",
      "Epoch 29/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3772 - f1: 0.6037 - val_loss: 0.2766 - val_f1: 0.0696\n",
      "Epoch 30/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3766 - f1: 0.6026 - val_loss: 0.2772 - val_f1: 0.0699\n",
      "Epoch 31/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3763 - f1: 0.6026 - val_loss: 0.2773 - val_f1: 0.0698\n",
      "Epoch 32/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3761 - f1: 0.6040 - val_loss: 0.2769 - val_f1: 0.0695\n",
      "Epoch 33/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3756 - f1: 0.6035 - val_loss: 0.2770 - val_f1: 0.0696\n",
      "Epoch 34/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3756 - f1: 0.6051 - val_loss: 0.2772 - val_f1: 0.0700\n",
      "Epoch 35/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3745 - f1: 0.6046 - val_loss: 0.2754 - val_f1: 0.0693\n",
      "Epoch 36/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3736 - f1: 0.6040 - val_loss: 0.2773 - val_f1: 0.0699\n",
      "Epoch 37/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3734 - f1: 0.6060 - val_loss: 0.2773 - val_f1: 0.0696\n",
      "Epoch 38/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3732 - f1: 0.6054 - val_loss: 0.2780 - val_f1: 0.0696\n",
      "Epoch 39/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.3726 - f1: 0.6068 - val_loss: 0.2779 - val_f1: 0.0698\n",
      "Epoch 40/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3728 - f1: 0.6075 - val_loss: 0.2762 - val_f1: 0.0690\n",
      "Epoch 41/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3718 - f1: 0.6060 - val_loss: 0.2775 - val_f1: 0.0698\n",
      "Epoch 42/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3720 - f1: 0.6067 - val_loss: 0.2769 - val_f1: 0.0694\n",
      "Epoch 43/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.3706 - f1: 0.6099 - val_loss: 0.2754 - val_f1: 0.0694\n",
      "Epoch 44/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3704 - f1: 0.6089 - val_loss: 0.2770 - val_f1: 0.0697\n",
      "Epoch 45/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3699 - f1: 0.6098 - val_loss: 0.2765 - val_f1: 0.0697\n",
      "Epoch 46/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3695 - f1: 0.6087 - val_loss: 0.2791 - val_f1: 0.0694\n",
      "Epoch 47/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.3697 - f1: 0.6087 - val_loss: 0.2754 - val_f1: 0.0688\n",
      "Epoch 48/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3679 - f1: 0.6131 - val_loss: 0.2768 - val_f1: 0.0695\n",
      "Epoch 49/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3683 - f1: 0.6129 - val_loss: 0.2763 - val_f1: 0.0692\n",
      "Epoch 50/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3679 - f1: 0.6111 - val_loss: 0.2753 - val_f1: 0.0690\n",
      "Epoch 51/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3676 - f1: 0.6104 - val_loss: 0.2755 - val_f1: 0.0692\n",
      "Epoch 52/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.3666 - f1: 0.6115 - val_loss: 0.2770 - val_f1: 0.0693\n",
      "Epoch 53/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3660 - f1: 0.6132 - val_loss: 0.2762 - val_f1: 0.0691\n",
      "Epoch 54/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3655 - f1: 0.6132 - val_loss: 0.2763 - val_f1: 0.0689\n",
      "Epoch 55/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.3652 - f1: 0.6175 - val_loss: 0.2730 - val_f1: 0.0687\n",
      "Epoch 56/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.3643 - f1: 0.6177 - val_loss: 0.2753 - val_f1: 0.0688\n",
      "Epoch 57/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3644 - f1: 0.6188 - val_loss: 0.2753 - val_f1: 0.0691\n",
      "Epoch 58/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3633 - f1: 0.6175 - val_loss: 0.2748 - val_f1: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3632 - f1: 0.6199 - val_loss: 0.2739 - val_f1: 0.0687\n",
      "Epoch 60/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3627 - f1: 0.6206 - val_loss: 0.2753 - val_f1: 0.0689\n",
      "Epoch 61/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3625 - f1: 0.6191 - val_loss: 0.2743 - val_f1: 0.0682\n",
      "Epoch 62/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3627 - f1: 0.6191 - val_loss: 0.2735 - val_f1: 0.0685\n",
      "Epoch 63/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3623 - f1: 0.6207 - val_loss: 0.2760 - val_f1: 0.0690\n",
      "Epoch 64/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.3615 - f1: 0.6215 - val_loss: 0.2744 - val_f1: 0.0689\n",
      "Epoch 65/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3608 - f1: 0.6220 - val_loss: 0.2753 - val_f1: 0.0690\n",
      "Epoch 66/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3600 - f1: 0.6226 - val_loss: 0.2728 - val_f1: 0.0684\n",
      "Epoch 67/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3602 - f1: 0.6224 - val_loss: 0.2753 - val_f1: 0.0685\n",
      "Epoch 68/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3601 - f1: 0.6232 - val_loss: 0.2751 - val_f1: 0.0689\n",
      "Epoch 69/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3589 - f1: 0.6244 - val_loss: 0.2743 - val_f1: 0.0689\n",
      "Epoch 70/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.3588 - f1: 0.6247 - val_loss: 0.2751 - val_f1: 0.0688\n",
      "Epoch 71/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3586 - f1: 0.6262 - val_loss: 0.2732 - val_f1: 0.0684\n",
      "Epoch 72/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3577 - f1: 0.6270 - val_loss: 0.2743 - val_f1: 0.0688\n",
      "Epoch 73/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3572 - f1: 0.6270 - val_loss: 0.2744 - val_f1: 0.0682\n",
      "Epoch 74/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3574 - f1: 0.6250 - val_loss: 0.2725 - val_f1: 0.0688\n",
      "Epoch 75/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3569 - f1: 0.6296 - val_loss: 0.2734 - val_f1: 0.0684\n",
      "Epoch 76/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.3563 - f1: 0.6308 - val_loss: 0.2774 - val_f1: 0.0692\n",
      "Epoch 77/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3566 - f1: 0.6287 - val_loss: 0.2750 - val_f1: 0.0687\n",
      "Epoch 78/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3559 - f1: 0.6319 - val_loss: 0.2715 - val_f1: 0.0680\n",
      "Epoch 79/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3558 - f1: 0.6309 - val_loss: 0.2722 - val_f1: 0.0681\n",
      "Epoch 80/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3534 - f1: 0.6363 - val_loss: 0.2750 - val_f1: 0.0685\n",
      "Epoch 81/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3537 - f1: 0.6324 - val_loss: 0.2736 - val_f1: 0.0681\n",
      "Epoch 82/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3532 - f1: 0.6350 - val_loss: 0.2762 - val_f1: 0.0691\n",
      "Epoch 83/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3540 - f1: 0.6338 - val_loss: 0.2743 - val_f1: 0.0686\n",
      "Epoch 84/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3530 - f1: 0.6353 - val_loss: 0.2720 - val_f1: 0.0677\n",
      "Epoch 85/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3525 - f1: 0.6347 - val_loss: 0.2724 - val_f1: 0.0680\n",
      "Epoch 86/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3527 - f1: 0.6347 - val_loss: 0.2724 - val_f1: 0.0675\n",
      "Epoch 87/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3524 - f1: 0.6347 - val_loss: 0.2737 - val_f1: 0.0682\n",
      "Epoch 88/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3515 - f1: 0.6365 - val_loss: 0.2727 - val_f1: 0.0680\n",
      "Epoch 89/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3512 - f1: 0.6370 - val_loss: 0.2715 - val_f1: 0.0676\n",
      "Epoch 90/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3508 - f1: 0.6368 - val_loss: 0.2728 - val_f1: 0.0681\n",
      "Epoch 91/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3509 - f1: 0.6355 - val_loss: 0.2743 - val_f1: 0.0681\n",
      "Epoch 92/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3492 - f1: 0.6382 - val_loss: 0.2746 - val_f1: 0.0680\n",
      "Epoch 93/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3498 - f1: 0.6388 - val_loss: 0.2727 - val_f1: 0.0677\n",
      "Epoch 94/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3490 - f1: 0.6383 - val_loss: 0.2746 - val_f1: 0.0681\n",
      "Epoch 95/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3488 - f1: 0.6412 - val_loss: 0.2736 - val_f1: 0.0680\n",
      "Epoch 96/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3475 - f1: 0.6442 - val_loss: 0.2715 - val_f1: 0.0676\n",
      "Epoch 97/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3484 - f1: 0.6410 - val_loss: 0.2743 - val_f1: 0.0682\n",
      "Epoch 98/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3484 - f1: 0.6403 - val_loss: 0.2716 - val_f1: 0.0677\n",
      "Epoch 99/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3470 - f1: 0.6427 - val_loss: 0.2723 - val_f1: 0.0672\n",
      "Epoch 100/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3470 - f1: 0.6464 - val_loss: 0.2721 - val_f1: 0.0677\n",
      "Epoch 101/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3470 - f1: 0.6430 - val_loss: 0.2734 - val_f1: 0.0680\n",
      "Epoch 102/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3468 - f1: 0.6443 - val_loss: 0.2729 - val_f1: 0.0678\n",
      "Epoch 103/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3457 - f1: 0.6450 - val_loss: 0.2745 - val_f1: 0.0681\n",
      "Epoch 104/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3456 - f1: 0.6482 - val_loss: 0.2731 - val_f1: 0.0679\n",
      "Epoch 105/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3452 - f1: 0.6462 - val_loss: 0.2736 - val_f1: 0.0679\n",
      "Epoch 106/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3456 - f1: 0.6458 - val_loss: 0.2731 - val_f1: 0.0675\n",
      "Epoch 107/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3434 - f1: 0.6495 - val_loss: 0.2732 - val_f1: 0.0677\n",
      "Epoch 108/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3438 - f1: 0.6501 - val_loss: 0.2744 - val_f1: 0.0679\n",
      "Epoch 109/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3450 - f1: 0.6483 - val_loss: 0.2729 - val_f1: 0.0676\n",
      "Epoch 110/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3439 - f1: 0.6485 - val_loss: 0.2760 - val_f1: 0.0686\n",
      "Epoch 111/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3439 - f1: 0.6486 - val_loss: 0.2733 - val_f1: 0.0677\n",
      "Epoch 112/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3433 - f1: 0.6510 - val_loss: 0.2740 - val_f1: 0.0677\n",
      "Epoch 113/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3423 - f1: 0.6508 - val_loss: 0.2737 - val_f1: 0.0678\n",
      "Epoch 114/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3418 - f1: 0.6500 - val_loss: 0.2723 - val_f1: 0.0674\n",
      "Epoch 115/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3431 - f1: 0.6515 - val_loss: 0.2717 - val_f1: 0.0673\n",
      "Epoch 116/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3422 - f1: 0.6491 - val_loss: 0.2724 - val_f1: 0.0673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3408 - f1: 0.6527 - val_loss: 0.2744 - val_f1: 0.0675\n",
      "Epoch 118/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3406 - f1: 0.6524 - val_loss: 0.2724 - val_f1: 0.0674\n",
      "Epoch 119/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.3407 - f1: 0.6540 - val_loss: 0.2727 - val_f1: 0.0674\n",
      "Epoch 120/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3409 - f1: 0.6519 - val_loss: 0.2744 - val_f1: 0.0677\n",
      "Epoch 121/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3391 - f1: 0.6553 - val_loss: 0.2739 - val_f1: 0.0677\n",
      "Epoch 122/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3394 - f1: 0.6537 - val_loss: 0.2712 - val_f1: 0.0671\n",
      "Epoch 123/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3393 - f1: 0.6582 - val_loss: 0.2738 - val_f1: 0.0676\n",
      "Epoch 124/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3403 - f1: 0.6533 - val_loss: 0.2728 - val_f1: 0.0671\n",
      "Epoch 125/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3389 - f1: 0.6573 - val_loss: 0.2735 - val_f1: 0.0676\n",
      "Epoch 126/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3387 - f1: 0.6561 - val_loss: 0.2723 - val_f1: 0.0673\n",
      "Epoch 127/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3388 - f1: 0.6585 - val_loss: 0.2725 - val_f1: 0.0672\n",
      "Epoch 128/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3393 - f1: 0.6544 - val_loss: 0.2741 - val_f1: 0.0675\n",
      "Epoch 129/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3374 - f1: 0.6571 - val_loss: 0.2745 - val_f1: 0.0675\n",
      "Epoch 130/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3369 - f1: 0.6596 - val_loss: 0.2729 - val_f1: 0.0673\n",
      "Epoch 131/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3383 - f1: 0.6595 - val_loss: 0.2726 - val_f1: 0.0668\n",
      "Epoch 132/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3371 - f1: 0.6563 - val_loss: 0.2752 - val_f1: 0.0677\n",
      "Epoch 133/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3367 - f1: 0.6583 - val_loss: 0.2746 - val_f1: 0.0676\n",
      "Epoch 134/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3361 - f1: 0.6602 - val_loss: 0.2725 - val_f1: 0.0670\n",
      "Epoch 135/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3372 - f1: 0.6597 - val_loss: 0.2729 - val_f1: 0.0671\n",
      "Epoch 136/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3362 - f1: 0.6599 - val_loss: 0.2750 - val_f1: 0.0675\n",
      "Epoch 137/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3347 - f1: 0.6639 - val_loss: 0.2735 - val_f1: 0.0671\n",
      "Epoch 138/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3361 - f1: 0.6592 - val_loss: 0.2729 - val_f1: 0.0671\n",
      "Epoch 139/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3362 - f1: 0.6599 - val_loss: 0.2714 - val_f1: 0.0669\n",
      "Epoch 140/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3359 - f1: 0.6613 - val_loss: 0.2729 - val_f1: 0.0670\n",
      "Epoch 141/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3349 - f1: 0.6628 - val_loss: 0.2712 - val_f1: 0.0664\n",
      "Epoch 142/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3360 - f1: 0.6595 - val_loss: 0.2739 - val_f1: 0.0675\n",
      "Epoch 143/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3349 - f1: 0.6626 - val_loss: 0.2729 - val_f1: 0.0672\n",
      "Epoch 144/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3351 - f1: 0.6627 - val_loss: 0.2738 - val_f1: 0.0674\n",
      "Epoch 145/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3337 - f1: 0.6622 - val_loss: 0.2720 - val_f1: 0.0672\n",
      "Epoch 146/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3336 - f1: 0.6643 - val_loss: 0.2740 - val_f1: 0.0672\n",
      "Epoch 147/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3335 - f1: 0.6643 - val_loss: 0.2746 - val_f1: 0.0674\n",
      "Epoch 148/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3335 - f1: 0.6636 - val_loss: 0.2738 - val_f1: 0.0670\n",
      "Epoch 149/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3337 - f1: 0.6629 - val_loss: 0.2741 - val_f1: 0.0672\n",
      "Epoch 150/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3322 - f1: 0.6643 - val_loss: 0.2734 - val_f1: 0.0670\n",
      "Epoch 151/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3331 - f1: 0.6636 - val_loss: 0.2736 - val_f1: 0.0672\n",
      "Epoch 152/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3325 - f1: 0.6647 - val_loss: 0.2734 - val_f1: 0.0673\n",
      "Epoch 153/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3328 - f1: 0.6670 - val_loss: 0.2746 - val_f1: 0.0676\n",
      "Epoch 154/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3314 - f1: 0.6673 - val_loss: 0.2765 - val_f1: 0.0678\n",
      "Epoch 155/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3322 - f1: 0.6644 - val_loss: 0.2744 - val_f1: 0.0673\n",
      "Epoch 156/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3320 - f1: 0.6664 - val_loss: 0.2766 - val_f1: 0.0677\n",
      "Epoch 157/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3317 - f1: 0.6661 - val_loss: 0.2724 - val_f1: 0.0666\n",
      "Epoch 158/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3311 - f1: 0.6667 - val_loss: 0.2750 - val_f1: 0.0674\n",
      "Epoch 159/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3317 - f1: 0.6673 - val_loss: 0.2749 - val_f1: 0.0673\n",
      "Epoch 160/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3304 - f1: 0.6654 - val_loss: 0.2745 - val_f1: 0.0673\n",
      "Epoch 161/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3294 - f1: 0.6696 - val_loss: 0.2741 - val_f1: 0.0670\n",
      "Epoch 162/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3306 - f1: 0.6682 - val_loss: 0.2751 - val_f1: 0.0674\n",
      "Epoch 163/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3296 - f1: 0.6729 - val_loss: 0.2718 - val_f1: 0.0665\n",
      "Epoch 164/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3289 - f1: 0.6698 - val_loss: 0.2725 - val_f1: 0.0665\n",
      "Epoch 165/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3297 - f1: 0.6678 - val_loss: 0.2741 - val_f1: 0.0671\n",
      "Epoch 166/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3296 - f1: 0.6714 - val_loss: 0.2727 - val_f1: 0.0670\n",
      "Epoch 167/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3296 - f1: 0.6692 - val_loss: 0.2743 - val_f1: 0.0673\n",
      "Epoch 168/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3291 - f1: 0.6697 - val_loss: 0.2741 - val_f1: 0.0671\n",
      "Epoch 169/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3289 - f1: 0.6719 - val_loss: 0.2717 - val_f1: 0.0661\n",
      "Epoch 170/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3296 - f1: 0.6710 - val_loss: 0.2737 - val_f1: 0.0668\n",
      "Epoch 171/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3296 - f1: 0.6682 - val_loss: 0.2742 - val_f1: 0.0671\n",
      "Epoch 172/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3272 - f1: 0.6739 - val_loss: 0.2757 - val_f1: 0.0674\n",
      "Epoch 173/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3281 - f1: 0.6708 - val_loss: 0.2743 - val_f1: 0.0670\n",
      "Epoch 174/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3282 - f1: 0.6702 - val_loss: 0.2747 - val_f1: 0.0672\n",
      "Epoch 175/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3270 - f1: 0.6745 - val_loss: 0.2744 - val_f1: 0.0671\n",
      "Epoch 176/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3271 - f1: 0.6730 - val_loss: 0.2741 - val_f1: 0.0670\n",
      "Epoch 177/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3272 - f1: 0.6731 - val_loss: 0.2733 - val_f1: 0.0667\n",
      "Epoch 178/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3268 - f1: 0.6740 - val_loss: 0.2750 - val_f1: 0.0673\n",
      "Epoch 179/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3269 - f1: 0.6728 - val_loss: 0.2747 - val_f1: 0.0671\n",
      "Epoch 180/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3274 - f1: 0.6720 - val_loss: 0.2745 - val_f1: 0.0671\n",
      "Epoch 181/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3281 - f1: 0.6725 - val_loss: 0.2731 - val_f1: 0.0669\n",
      "Epoch 182/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3268 - f1: 0.6755 - val_loss: 0.2743 - val_f1: 0.0670\n",
      "Epoch 183/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3265 - f1: 0.6732 - val_loss: 0.2734 - val_f1: 0.0669\n",
      "Epoch 184/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3263 - f1: 0.6746 - val_loss: 0.2732 - val_f1: 0.0669\n",
      "Epoch 185/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3258 - f1: 0.6740 - val_loss: 0.2765 - val_f1: 0.0674\n",
      "Epoch 186/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3263 - f1: 0.6745 - val_loss: 0.2742 - val_f1: 0.0669\n",
      "Epoch 187/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3260 - f1: 0.6743 - val_loss: 0.2743 - val_f1: 0.0667\n",
      "Epoch 188/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3246 - f1: 0.6779 - val_loss: 0.2750 - val_f1: 0.0667\n",
      "Epoch 189/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3250 - f1: 0.6773 - val_loss: 0.2740 - val_f1: 0.0670\n",
      "Epoch 190/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3250 - f1: 0.6788 - val_loss: 0.2749 - val_f1: 0.0667\n",
      "Epoch 191/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.3255 - f1: 0.6778 - val_loss: 0.2744 - val_f1: 0.0671\n",
      "Epoch 192/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3255 - f1: 0.6776 - val_loss: 0.2756 - val_f1: 0.0671\n",
      "Epoch 193/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3250 - f1: 0.6764 - val_loss: 0.2748 - val_f1: 0.0670\n",
      "Epoch 194/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3247 - f1: 0.6782 - val_loss: 0.2752 - val_f1: 0.0670\n",
      "Epoch 195/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3240 - f1: 0.6770 - val_loss: 0.2733 - val_f1: 0.0666\n",
      "Epoch 196/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3249 - f1: 0.6758 - val_loss: 0.2746 - val_f1: 0.0669\n",
      "Epoch 197/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3236 - f1: 0.6800 - val_loss: 0.2762 - val_f1: 0.0672\n",
      "Epoch 198/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3248 - f1: 0.6775 - val_loss: 0.2739 - val_f1: 0.0667\n",
      "Epoch 199/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3243 - f1: 0.6772 - val_loss: 0.2760 - val_f1: 0.0673\n",
      "Epoch 200/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3229 - f1: 0.6804 - val_loss: 0.2759 - val_f1: 0.0671\n",
      "Epoch 201/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3229 - f1: 0.6787 - val_loss: 0.2764 - val_f1: 0.0676\n",
      "Epoch 202/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3228 - f1: 0.6810 - val_loss: 0.2748 - val_f1: 0.0670\n",
      "Epoch 203/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3235 - f1: 0.6801 - val_loss: 0.2752 - val_f1: 0.0671\n",
      "Epoch 204/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3229 - f1: 0.6797 - val_loss: 0.2760 - val_f1: 0.0671\n",
      "Epoch 205/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3229 - f1: 0.6794 - val_loss: 0.2760 - val_f1: 0.0672\n",
      "Epoch 206/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3218 - f1: 0.6828 - val_loss: 0.2751 - val_f1: 0.0670\n",
      "Epoch 207/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3226 - f1: 0.6797 - val_loss: 0.2757 - val_f1: 0.0671\n",
      "Epoch 208/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3243 - f1: 0.6766 - val_loss: 0.2758 - val_f1: 0.0669\n",
      "Epoch 209/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3230 - f1: 0.6808 - val_loss: 0.2745 - val_f1: 0.0669\n",
      "Epoch 210/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3224 - f1: 0.6798 - val_loss: 0.2757 - val_f1: 0.0671\n",
      "Epoch 211/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3219 - f1: 0.6799 - val_loss: 0.2763 - val_f1: 0.0672\n",
      "Epoch 212/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3229 - f1: 0.6783 - val_loss: 0.2762 - val_f1: 0.0673\n",
      "Epoch 213/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3222 - f1: 0.6824 - val_loss: 0.2772 - val_f1: 0.0674\n",
      "Epoch 214/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3220 - f1: 0.6808 - val_loss: 0.2775 - val_f1: 0.0676\n",
      "Epoch 215/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3227 - f1: 0.6801 - val_loss: 0.2773 - val_f1: 0.0675\n",
      "Epoch 216/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.3203 - f1: 0.6816 - val_loss: 0.2761 - val_f1: 0.0673\n",
      "Epoch 217/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3210 - f1: 0.6825 - val_loss: 0.2762 - val_f1: 0.0671\n",
      "Epoch 218/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3220 - f1: 0.6819 - val_loss: 0.2756 - val_f1: 0.0669\n",
      "Epoch 219/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3213 - f1: 0.6829 - val_loss: 0.2764 - val_f1: 0.0673\n",
      "Epoch 220/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3205 - f1: 0.6828 - val_loss: 0.2741 - val_f1: 0.0663\n",
      "Epoch 221/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3207 - f1: 0.6820 - val_loss: 0.2755 - val_f1: 0.0671\n",
      "Epoch 222/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3212 - f1: 0.6832 - val_loss: 0.2748 - val_f1: 0.0667\n",
      "Epoch 223/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3201 - f1: 0.6832 - val_loss: 0.2753 - val_f1: 0.0669\n",
      "Epoch 224/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3206 - f1: 0.6839 - val_loss: 0.2744 - val_f1: 0.0665\n",
      "Epoch 225/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3200 - f1: 0.6846 - val_loss: 0.2764 - val_f1: 0.0670\n",
      "Epoch 226/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3191 - f1: 0.6865 - val_loss: 0.2744 - val_f1: 0.0666\n",
      "Epoch 227/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3195 - f1: 0.6852 - val_loss: 0.2781 - val_f1: 0.0673\n",
      "Epoch 228/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3185 - f1: 0.6849 - val_loss: 0.2760 - val_f1: 0.0667\n",
      "Epoch 229/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3186 - f1: 0.6840 - val_loss: 0.2765 - val_f1: 0.0668\n",
      "Epoch 230/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3189 - f1: 0.6861 - val_loss: 0.2777 - val_f1: 0.0671\n",
      "Epoch 231/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3193 - f1: 0.6819 - val_loss: 0.2774 - val_f1: 0.0669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.3186 - f1: 0.6859 - val_loss: 0.2749 - val_f1: 0.0666\n",
      "Epoch 233/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3188 - f1: 0.6842 - val_loss: 0.2751 - val_f1: 0.0667\n",
      "Epoch 234/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3192 - f1: 0.6849 - val_loss: 0.2755 - val_f1: 0.0666\n",
      "Epoch 235/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3196 - f1: 0.6862 - val_loss: 0.2766 - val_f1: 0.0667\n",
      "Epoch 236/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3184 - f1: 0.6881 - val_loss: 0.2767 - val_f1: 0.0668\n",
      "Epoch 237/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3188 - f1: 0.6854 - val_loss: 0.2742 - val_f1: 0.0661\n",
      "Epoch 238/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.3195 - f1: 0.6837 - val_loss: 0.2754 - val_f1: 0.0669\n",
      "Epoch 239/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3178 - f1: 0.6886 - val_loss: 0.2766 - val_f1: 0.0670\n",
      "Epoch 240/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3183 - f1: 0.6868 - val_loss: 0.2760 - val_f1: 0.0671\n",
      "Epoch 241/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3168 - f1: 0.6883 - val_loss: 0.2760 - val_f1: 0.0669\n",
      "Epoch 242/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3180 - f1: 0.6878 - val_loss: 0.2763 - val_f1: 0.0670\n",
      "Epoch 243/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3190 - f1: 0.6888 - val_loss: 0.2742 - val_f1: 0.0667\n",
      "Epoch 244/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3181 - f1: 0.6864 - val_loss: 0.2790 - val_f1: 0.0674\n",
      "Epoch 245/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3180 - f1: 0.6868 - val_loss: 0.2782 - val_f1: 0.0671\n",
      "Epoch 246/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3184 - f1: 0.6860 - val_loss: 0.2757 - val_f1: 0.0667\n",
      "Epoch 247/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3175 - f1: 0.6869 - val_loss: 0.2740 - val_f1: 0.0663\n",
      "Epoch 248/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3182 - f1: 0.6872 - val_loss: 0.2752 - val_f1: 0.0664\n",
      "Epoch 249/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3179 - f1: 0.6873 - val_loss: 0.2749 - val_f1: 0.0662\n",
      "Epoch 250/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3184 - f1: 0.6868 - val_loss: 0.2763 - val_f1: 0.0669\n",
      "Epoch 251/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3173 - f1: 0.6857 - val_loss: 0.2768 - val_f1: 0.0667\n",
      "Epoch 252/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3177 - f1: 0.6874 - val_loss: 0.2769 - val_f1: 0.0669\n",
      "Epoch 253/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3171 - f1: 0.6874 - val_loss: 0.2765 - val_f1: 0.0668\n",
      "Epoch 254/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3173 - f1: 0.6886 - val_loss: 0.2753 - val_f1: 0.0664\n",
      "Epoch 255/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3168 - f1: 0.6887 - val_loss: 0.2759 - val_f1: 0.0665\n",
      "Epoch 256/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3160 - f1: 0.6928 - val_loss: 0.2782 - val_f1: 0.0670\n",
      "Epoch 257/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3169 - f1: 0.6880 - val_loss: 0.2763 - val_f1: 0.0665\n",
      "Epoch 258/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3166 - f1: 0.6915 - val_loss: 0.2746 - val_f1: 0.0664\n",
      "Epoch 259/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3166 - f1: 0.6890 - val_loss: 0.2765 - val_f1: 0.0666\n",
      "Epoch 260/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3161 - f1: 0.6888 - val_loss: 0.2772 - val_f1: 0.0669\n",
      "Epoch 261/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3153 - f1: 0.6916 - val_loss: 0.2765 - val_f1: 0.0664\n",
      "Epoch 262/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3163 - f1: 0.6896 - val_loss: 0.2762 - val_f1: 0.0665\n",
      "Epoch 263/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3157 - f1: 0.6913 - val_loss: 0.2789 - val_f1: 0.0672\n",
      "Epoch 264/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3157 - f1: 0.6896 - val_loss: 0.2765 - val_f1: 0.0664\n",
      "Epoch 265/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3159 - f1: 0.6905 - val_loss: 0.2763 - val_f1: 0.0666\n",
      "Epoch 266/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3159 - f1: 0.6914 - val_loss: 0.2762 - val_f1: 0.0663\n",
      "Epoch 267/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3156 - f1: 0.6916 - val_loss: 0.2760 - val_f1: 0.0665\n",
      "Epoch 268/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3154 - f1: 0.6901 - val_loss: 0.2780 - val_f1: 0.0671\n",
      "Epoch 269/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3156 - f1: 0.6898 - val_loss: 0.2767 - val_f1: 0.0665\n",
      "Epoch 270/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3161 - f1: 0.6893 - val_loss: 0.2751 - val_f1: 0.0663\n",
      "Epoch 271/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3152 - f1: 0.6896 - val_loss: 0.2768 - val_f1: 0.0666\n",
      "Epoch 272/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3150 - f1: 0.6922 - val_loss: 0.2772 - val_f1: 0.0670\n",
      "Epoch 273/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3155 - f1: 0.6908 - val_loss: 0.2785 - val_f1: 0.0669\n",
      "Epoch 274/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.3156 - f1: 0.6898 - val_loss: 0.2793 - val_f1: 0.0672\n",
      "Epoch 275/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3152 - f1: 0.6908 - val_loss: 0.2777 - val_f1: 0.0672\n",
      "Epoch 276/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3140 - f1: 0.6943 - val_loss: 0.2804 - val_f1: 0.0676\n",
      "Epoch 277/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3155 - f1: 0.6901 - val_loss: 0.2751 - val_f1: 0.0663\n",
      "Epoch 278/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3132 - f1: 0.6948 - val_loss: 0.2760 - val_f1: 0.0664\n",
      "Epoch 279/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3135 - f1: 0.6941 - val_loss: 0.2757 - val_f1: 0.0665\n",
      "Epoch 280/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3134 - f1: 0.6937 - val_loss: 0.2763 - val_f1: 0.0667\n",
      "Epoch 281/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3140 - f1: 0.6936 - val_loss: 0.2776 - val_f1: 0.0671\n",
      "Epoch 282/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3143 - f1: 0.6901 - val_loss: 0.2802 - val_f1: 0.0675\n",
      "Epoch 283/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3137 - f1: 0.6924 - val_loss: 0.2769 - val_f1: 0.0668\n",
      "Epoch 284/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3139 - f1: 0.6953 - val_loss: 0.2775 - val_f1: 0.0669\n",
      "Epoch 285/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3139 - f1: 0.6924 - val_loss: 0.2764 - val_f1: 0.0667\n",
      "Epoch 286/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3119 - f1: 0.6982 - val_loss: 0.2787 - val_f1: 0.0667\n",
      "Epoch 287/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3130 - f1: 0.6951 - val_loss: 0.2784 - val_f1: 0.0666\n",
      "Epoch 288/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3124 - f1: 0.6947 - val_loss: 0.2769 - val_f1: 0.0661\n",
      "Epoch 289/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.3153 - f1: 0.6913 - val_loss: 0.2776 - val_f1: 0.0666\n",
      "Epoch 290/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3148 - f1: 0.6932 - val_loss: 0.2788 - val_f1: 0.0669\n",
      "Epoch 291/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3130 - f1: 0.6940 - val_loss: 0.2801 - val_f1: 0.0672\n",
      "Epoch 292/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3128 - f1: 0.6915 - val_loss: 0.2780 - val_f1: 0.0665\n",
      "Epoch 293/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3121 - f1: 0.6952 - val_loss: 0.2785 - val_f1: 0.0666\n",
      "Epoch 294/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3131 - f1: 0.6944 - val_loss: 0.2808 - val_f1: 0.0673\n",
      "Epoch 295/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3127 - f1: 0.6958 - val_loss: 0.2793 - val_f1: 0.0668\n",
      "Epoch 296/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3134 - f1: 0.6940 - val_loss: 0.2757 - val_f1: 0.0664\n",
      "Epoch 297/2000\n",
      "168135/168135 [==============================] - 12s 73us/step - loss: 0.3120 - f1: 0.6967 - val_loss: 0.2769 - val_f1: 0.0666\n",
      "Epoch 298/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.3118 - f1: 0.6936 - val_loss: 0.2796 - val_f1: 0.0670\n",
      "Epoch 299/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3135 - f1: 0.6948 - val_loss: 0.2778 - val_f1: 0.0666\n",
      "Epoch 300/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3120 - f1: 0.6935 - val_loss: 0.2806 - val_f1: 0.0675\n",
      "Epoch 301/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3119 - f1: 0.6969 - val_loss: 0.2757 - val_f1: 0.0662\n",
      "Epoch 302/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3120 - f1: 0.6965 - val_loss: 0.2790 - val_f1: 0.0669\n",
      "Epoch 303/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3108 - f1: 0.6980 - val_loss: 0.2785 - val_f1: 0.0670\n",
      "Epoch 304/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3117 - f1: 0.6967 - val_loss: 0.2786 - val_f1: 0.0670\n",
      "Epoch 305/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3115 - f1: 0.6952 - val_loss: 0.2787 - val_f1: 0.0672\n",
      "Epoch 306/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3108 - f1: 0.6983 - val_loss: 0.2788 - val_f1: 0.0667\n",
      "Epoch 307/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3117 - f1: 0.6934 - val_loss: 0.2774 - val_f1: 0.0664\n",
      "Epoch 308/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3110 - f1: 0.6972 - val_loss: 0.2768 - val_f1: 0.0662\n",
      "Epoch 309/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3108 - f1: 0.6967 - val_loss: 0.2781 - val_f1: 0.0668\n",
      "Epoch 310/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3112 - f1: 0.6977 - val_loss: 0.2777 - val_f1: 0.0666\n",
      "Epoch 311/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3103 - f1: 0.6974 - val_loss: 0.2808 - val_f1: 0.0672\n",
      "Epoch 312/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3112 - f1: 0.6977 - val_loss: 0.2771 - val_f1: 0.0663\n",
      "Epoch 313/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3118 - f1: 0.6966 - val_loss: 0.2794 - val_f1: 0.0667\n",
      "Epoch 314/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3113 - f1: 0.6983 - val_loss: 0.2778 - val_f1: 0.0665\n",
      "Epoch 315/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3099 - f1: 0.6979 - val_loss: 0.2790 - val_f1: 0.0666\n",
      "Epoch 316/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3114 - f1: 0.6987 - val_loss: 0.2785 - val_f1: 0.0667\n",
      "Epoch 317/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3115 - f1: 0.6945 - val_loss: 0.2772 - val_f1: 0.0667\n",
      "Epoch 318/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3116 - f1: 0.6967 - val_loss: 0.2799 - val_f1: 0.0669\n",
      "Epoch 319/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3105 - f1: 0.6966 - val_loss: 0.2782 - val_f1: 0.0666\n",
      "Epoch 320/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3109 - f1: 0.6986 - val_loss: 0.2766 - val_f1: 0.0661\n",
      "Epoch 321/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3099 - f1: 0.6998 - val_loss: 0.2772 - val_f1: 0.0665\n",
      "Epoch 322/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3108 - f1: 0.6983 - val_loss: 0.2792 - val_f1: 0.0666\n",
      "Epoch 323/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3105 - f1: 0.6983 - val_loss: 0.2787 - val_f1: 0.0666\n",
      "Epoch 324/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3100 - f1: 0.7012 - val_loss: 0.2787 - val_f1: 0.0663\n",
      "Epoch 325/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3096 - f1: 0.6983 - val_loss: 0.2778 - val_f1: 0.0663\n",
      "Epoch 326/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3115 - f1: 0.6955 - val_loss: 0.2768 - val_f1: 0.0664\n",
      "Epoch 327/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3094 - f1: 0.6978 - val_loss: 0.2786 - val_f1: 0.0665\n",
      "Epoch 328/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3105 - f1: 0.6991 - val_loss: 0.2789 - val_f1: 0.0667\n",
      "Epoch 329/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3105 - f1: 0.6989 - val_loss: 0.2781 - val_f1: 0.0665\n",
      "Epoch 330/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3099 - f1: 0.6988 - val_loss: 0.2758 - val_f1: 0.0660\n",
      "Epoch 331/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3111 - f1: 0.6961 - val_loss: 0.2799 - val_f1: 0.0671\n",
      "Epoch 332/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3087 - f1: 0.7032 - val_loss: 0.2809 - val_f1: 0.0672\n",
      "Epoch 333/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3091 - f1: 0.6987 - val_loss: 0.2783 - val_f1: 0.0664\n",
      "Epoch 334/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3095 - f1: 0.7007 - val_loss: 0.2762 - val_f1: 0.0659\n",
      "Epoch 335/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3091 - f1: 0.6999 - val_loss: 0.2776 - val_f1: 0.0663\n",
      "Epoch 336/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3099 - f1: 0.7006 - val_loss: 0.2784 - val_f1: 0.0665\n",
      "Epoch 337/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3083 - f1: 0.7023 - val_loss: 0.2804 - val_f1: 0.0670\n",
      "Epoch 338/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3093 - f1: 0.7004 - val_loss: 0.2794 - val_f1: 0.0667\n",
      "Epoch 339/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3097 - f1: 0.6989 - val_loss: 0.2794 - val_f1: 0.0669\n",
      "Epoch 340/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3092 - f1: 0.7008 - val_loss: 0.2808 - val_f1: 0.0670\n",
      "Epoch 341/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3077 - f1: 0.7019 - val_loss: 0.2807 - val_f1: 0.0672\n",
      "Epoch 342/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3082 - f1: 0.7016 - val_loss: 0.2802 - val_f1: 0.0670\n",
      "Epoch 343/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3088 - f1: 0.6998 - val_loss: 0.2804 - val_f1: 0.0669\n",
      "Epoch 344/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3084 - f1: 0.6991 - val_loss: 0.2782 - val_f1: 0.0665\n",
      "Epoch 345/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3086 - f1: 0.7007 - val_loss: 0.2781 - val_f1: 0.0662\n",
      "Epoch 346/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3092 - f1: 0.6997 - val_loss: 0.2787 - val_f1: 0.0665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3104 - f1: 0.6981 - val_loss: 0.2793 - val_f1: 0.0667\n",
      "Epoch 348/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3078 - f1: 0.7012 - val_loss: 0.2817 - val_f1: 0.0673\n",
      "Epoch 349/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3087 - f1: 0.7000 - val_loss: 0.2815 - val_f1: 0.0669\n",
      "Epoch 350/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3082 - f1: 0.7020 - val_loss: 0.2785 - val_f1: 0.0664\n",
      "Epoch 351/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3088 - f1: 0.7006 - val_loss: 0.2815 - val_f1: 0.0671\n",
      "Epoch 352/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3086 - f1: 0.6992 - val_loss: 0.2802 - val_f1: 0.0667\n",
      "Epoch 353/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3082 - f1: 0.7016 - val_loss: 0.2794 - val_f1: 0.0667\n",
      "Epoch 354/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3087 - f1: 0.7003 - val_loss: 0.2784 - val_f1: 0.0664\n",
      "Epoch 355/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.3074 - f1: 0.7032 - val_loss: 0.2798 - val_f1: 0.0666\n",
      "Epoch 356/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3086 - f1: 0.7009 - val_loss: 0.2776 - val_f1: 0.0659\n",
      "Epoch 357/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3072 - f1: 0.7019 - val_loss: 0.2801 - val_f1: 0.0666\n",
      "Epoch 358/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3084 - f1: 0.7010 - val_loss: 0.2789 - val_f1: 0.0666\n",
      "Epoch 359/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3067 - f1: 0.7052 - val_loss: 0.2796 - val_f1: 0.0666\n",
      "Epoch 360/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3092 - f1: 0.7032 - val_loss: 0.2792 - val_f1: 0.0666\n",
      "Epoch 361/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3075 - f1: 0.7035 - val_loss: 0.2770 - val_f1: 0.0659\n",
      "Epoch 362/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3062 - f1: 0.7031 - val_loss: 0.2817 - val_f1: 0.0668\n",
      "Epoch 363/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3080 - f1: 0.7046 - val_loss: 0.2816 - val_f1: 0.0671\n",
      "Epoch 364/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3079 - f1: 0.7018 - val_loss: 0.2779 - val_f1: 0.0662\n",
      "Epoch 365/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3070 - f1: 0.7017 - val_loss: 0.2796 - val_f1: 0.0668\n",
      "Epoch 366/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3081 - f1: 0.7022 - val_loss: 0.2803 - val_f1: 0.0666\n",
      "Epoch 367/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3071 - f1: 0.7033 - val_loss: 0.2804 - val_f1: 0.0668\n",
      "Epoch 368/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3069 - f1: 0.7049 - val_loss: 0.2761 - val_f1: 0.0659\n",
      "Epoch 369/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3066 - f1: 0.7053 - val_loss: 0.2790 - val_f1: 0.0663\n",
      "Epoch 370/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3086 - f1: 0.7000 - val_loss: 0.2769 - val_f1: 0.0661\n",
      "Epoch 371/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3075 - f1: 0.7031 - val_loss: 0.2781 - val_f1: 0.0665\n",
      "Epoch 372/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3067 - f1: 0.7056 - val_loss: 0.2814 - val_f1: 0.0669\n",
      "Epoch 373/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3064 - f1: 0.7029 - val_loss: 0.2809 - val_f1: 0.0670\n",
      "Epoch 374/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3072 - f1: 0.7055 - val_loss: 0.2797 - val_f1: 0.0667\n",
      "Epoch 375/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3062 - f1: 0.7041 - val_loss: 0.2802 - val_f1: 0.0666\n",
      "Epoch 376/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3069 - f1: 0.7036 - val_loss: 0.2789 - val_f1: 0.0664\n",
      "Epoch 377/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3071 - f1: 0.7035 - val_loss: 0.2784 - val_f1: 0.0664\n",
      "Epoch 378/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3058 - f1: 0.7057 - val_loss: 0.2818 - val_f1: 0.0670\n",
      "Epoch 379/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3074 - f1: 0.7008 - val_loss: 0.2797 - val_f1: 0.0667\n",
      "Epoch 380/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3075 - f1: 0.7037 - val_loss: 0.2788 - val_f1: 0.0667\n",
      "Epoch 381/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3060 - f1: 0.7043 - val_loss: 0.2823 - val_f1: 0.0674\n",
      "Epoch 382/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3066 - f1: 0.7063 - val_loss: 0.2777 - val_f1: 0.0663\n",
      "Epoch 383/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3069 - f1: 0.7027 - val_loss: 0.2807 - val_f1: 0.0671\n",
      "Epoch 384/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3053 - f1: 0.7052 - val_loss: 0.2797 - val_f1: 0.0666\n",
      "Epoch 385/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3055 - f1: 0.7050 - val_loss: 0.2817 - val_f1: 0.0671\n",
      "Epoch 386/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3065 - f1: 0.7037 - val_loss: 0.2793 - val_f1: 0.0668\n",
      "Epoch 387/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3053 - f1: 0.7043 - val_loss: 0.2783 - val_f1: 0.0662\n",
      "Epoch 388/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3070 - f1: 0.7031 - val_loss: 0.2794 - val_f1: 0.0666\n",
      "Epoch 389/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3049 - f1: 0.7072 - val_loss: 0.2823 - val_f1: 0.0672\n",
      "Epoch 390/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3056 - f1: 0.7056 - val_loss: 0.2814 - val_f1: 0.0670\n",
      "Epoch 391/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3047 - f1: 0.7059 - val_loss: 0.2822 - val_f1: 0.0670\n",
      "Epoch 392/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3050 - f1: 0.7052 - val_loss: 0.2784 - val_f1: 0.0665\n",
      "Epoch 393/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3077 - f1: 0.6997 - val_loss: 0.2801 - val_f1: 0.0667\n",
      "Epoch 394/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3044 - f1: 0.7061 - val_loss: 0.2804 - val_f1: 0.0668\n",
      "Epoch 395/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3052 - f1: 0.7042 - val_loss: 0.2799 - val_f1: 0.0669\n",
      "Epoch 396/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3054 - f1: 0.7047 - val_loss: 0.2801 - val_f1: 0.0668\n",
      "Epoch 397/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3053 - f1: 0.7041 - val_loss: 0.2807 - val_f1: 0.0672\n",
      "Epoch 398/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3054 - f1: 0.7055 - val_loss: 0.2782 - val_f1: 0.0663\n",
      "Epoch 399/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3067 - f1: 0.7028 - val_loss: 0.2803 - val_f1: 0.0668\n",
      "Epoch 400/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3046 - f1: 0.7049 - val_loss: 0.2805 - val_f1: 0.0666\n",
      "Epoch 401/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3032 - f1: 0.7086 - val_loss: 0.2804 - val_f1: 0.0668\n",
      "Epoch 402/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3056 - f1: 0.7066 - val_loss: 0.2795 - val_f1: 0.0665\n",
      "Epoch 403/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3048 - f1: 0.7070 - val_loss: 0.2792 - val_f1: 0.0664\n",
      "Epoch 404/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3051 - f1: 0.7089 - val_loss: 0.2798 - val_f1: 0.0669\n",
      "Epoch 405/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3050 - f1: 0.7029 - val_loss: 0.2774 - val_f1: 0.0663\n",
      "Epoch 406/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3045 - f1: 0.7048 - val_loss: 0.2814 - val_f1: 0.0669\n",
      "Epoch 407/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3057 - f1: 0.7061 - val_loss: 0.2821 - val_f1: 0.0673\n",
      "Epoch 408/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3033 - f1: 0.7105 - val_loss: 0.2784 - val_f1: 0.0666\n",
      "Epoch 409/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3051 - f1: 0.7044 - val_loss: 0.2806 - val_f1: 0.0667\n",
      "Epoch 410/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3042 - f1: 0.7068 - val_loss: 0.2775 - val_f1: 0.0663\n",
      "Epoch 411/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3045 - f1: 0.7076 - val_loss: 0.2806 - val_f1: 0.0671\n",
      "Epoch 412/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3038 - f1: 0.7054 - val_loss: 0.2810 - val_f1: 0.0672\n",
      "Epoch 413/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3049 - f1: 0.7068 - val_loss: 0.2809 - val_f1: 0.0669\n",
      "Epoch 414/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.3035 - f1: 0.7068 - val_loss: 0.2767 - val_f1: 0.0658\n",
      "Epoch 415/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3028 - f1: 0.7078 - val_loss: 0.2824 - val_f1: 0.0668\n",
      "Epoch 416/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3041 - f1: 0.7058 - val_loss: 0.2807 - val_f1: 0.0669\n",
      "Epoch 417/2000\n",
      "168135/168135 [==============================] - 12s 74us/step - loss: 0.3043 - f1: 0.7069 - val_loss: 0.2809 - val_f1: 0.0667\n",
      "Epoch 418/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3029 - f1: 0.7086 - val_loss: 0.2805 - val_f1: 0.0663\n",
      "Epoch 419/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3037 - f1: 0.7075 - val_loss: 0.2805 - val_f1: 0.0670\n",
      "Epoch 420/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3045 - f1: 0.7083 - val_loss: 0.2789 - val_f1: 0.0665\n",
      "Epoch 421/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3042 - f1: 0.7046 - val_loss: 0.2808 - val_f1: 0.0669\n",
      "Epoch 422/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3032 - f1: 0.7076 - val_loss: 0.2779 - val_f1: 0.0662\n",
      "Epoch 423/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3027 - f1: 0.7088 - val_loss: 0.2810 - val_f1: 0.0665\n",
      "Epoch 424/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3043 - f1: 0.7049 - val_loss: 0.2839 - val_f1: 0.0671\n",
      "Epoch 425/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3035 - f1: 0.7085 - val_loss: 0.2819 - val_f1: 0.0669\n",
      "Epoch 426/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3039 - f1: 0.7072 - val_loss: 0.2809 - val_f1: 0.0667\n",
      "Epoch 427/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3041 - f1: 0.7086 - val_loss: 0.2814 - val_f1: 0.0668\n",
      "Epoch 428/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3040 - f1: 0.7091 - val_loss: 0.2821 - val_f1: 0.0671\n",
      "Epoch 429/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3047 - f1: 0.7050 - val_loss: 0.2809 - val_f1: 0.0672\n",
      "Epoch 430/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3038 - f1: 0.7080 - val_loss: 0.2806 - val_f1: 0.0664\n",
      "Epoch 431/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3035 - f1: 0.7073 - val_loss: 0.2840 - val_f1: 0.0672\n",
      "Epoch 432/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3028 - f1: 0.7081 - val_loss: 0.2788 - val_f1: 0.0662\n",
      "Epoch 433/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3038 - f1: 0.7082 - val_loss: 0.2837 - val_f1: 0.0675\n",
      "Epoch 434/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3045 - f1: 0.7052 - val_loss: 0.2823 - val_f1: 0.0671\n",
      "Epoch 435/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3042 - f1: 0.7084 - val_loss: 0.2837 - val_f1: 0.0674\n",
      "Epoch 436/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3035 - f1: 0.7082 - val_loss: 0.2791 - val_f1: 0.0666\n",
      "Epoch 437/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3029 - f1: 0.7077 - val_loss: 0.2812 - val_f1: 0.0667\n",
      "Epoch 438/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3037 - f1: 0.7066 - val_loss: 0.2805 - val_f1: 0.0664\n",
      "Epoch 439/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3041 - f1: 0.7095 - val_loss: 0.2823 - val_f1: 0.0668\n",
      "Epoch 440/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3035 - f1: 0.7071 - val_loss: 0.2799 - val_f1: 0.0666\n",
      "Epoch 441/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3022 - f1: 0.7086 - val_loss: 0.2815 - val_f1: 0.0667\n",
      "Epoch 442/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3042 - f1: 0.7052 - val_loss: 0.2800 - val_f1: 0.0665\n",
      "Epoch 443/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3031 - f1: 0.7077 - val_loss: 0.2832 - val_f1: 0.0670\n",
      "Epoch 444/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3028 - f1: 0.7087 - val_loss: 0.2827 - val_f1: 0.0669\n",
      "Epoch 445/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3019 - f1: 0.7129 - val_loss: 0.2823 - val_f1: 0.0669\n",
      "Epoch 446/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3031 - f1: 0.7071 - val_loss: 0.2850 - val_f1: 0.0673\n",
      "Epoch 447/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3031 - f1: 0.7110 - val_loss: 0.2804 - val_f1: 0.0667\n",
      "Epoch 448/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3025 - f1: 0.7085 - val_loss: 0.2791 - val_f1: 0.0665\n",
      "Epoch 449/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3015 - f1: 0.7106 - val_loss: 0.2801 - val_f1: 0.0663\n",
      "Epoch 450/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3022 - f1: 0.7079 - val_loss: 0.2826 - val_f1: 0.0672\n",
      "Epoch 451/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3032 - f1: 0.7091 - val_loss: 0.2806 - val_f1: 0.0665\n",
      "Epoch 452/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3026 - f1: 0.7105 - val_loss: 0.2832 - val_f1: 0.0672\n",
      "Epoch 453/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3014 - f1: 0.7107 - val_loss: 0.2799 - val_f1: 0.0666\n",
      "Epoch 454/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3032 - f1: 0.7098 - val_loss: 0.2807 - val_f1: 0.0666\n",
      "Epoch 455/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3037 - f1: 0.7089 - val_loss: 0.2819 - val_f1: 0.0671\n",
      "Epoch 456/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3017 - f1: 0.7105 - val_loss: 0.2798 - val_f1: 0.0666\n",
      "Epoch 457/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3027 - f1: 0.7076 - val_loss: 0.2808 - val_f1: 0.0667\n",
      "Epoch 458/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3021 - f1: 0.7102 - val_loss: 0.2825 - val_f1: 0.0670\n",
      "Epoch 459/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3024 - f1: 0.7107 - val_loss: 0.2795 - val_f1: 0.0665\n",
      "Epoch 460/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3021 - f1: 0.7096 - val_loss: 0.2815 - val_f1: 0.0670\n",
      "Epoch 461/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3015 - f1: 0.7094 - val_loss: 0.2809 - val_f1: 0.0666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3000 - f1: 0.7120 - val_loss: 0.2811 - val_f1: 0.0668\n",
      "Epoch 463/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.3021 - f1: 0.7111 - val_loss: 0.2754 - val_f1: 0.0656\n",
      "Epoch 464/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3022 - f1: 0.7112 - val_loss: 0.2809 - val_f1: 0.0665\n",
      "Epoch 465/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3006 - f1: 0.7121 - val_loss: 0.2833 - val_f1: 0.0672\n",
      "Epoch 466/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3031 - f1: 0.7088 - val_loss: 0.2830 - val_f1: 0.0670\n",
      "Epoch 467/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3022 - f1: 0.7088 - val_loss: 0.2836 - val_f1: 0.0670\n",
      "Epoch 468/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3025 - f1: 0.7097 - val_loss: 0.2803 - val_f1: 0.0664\n",
      "Epoch 469/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3023 - f1: 0.7088 - val_loss: 0.2804 - val_f1: 0.0666\n",
      "Epoch 470/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3018 - f1: 0.7097 - val_loss: 0.2807 - val_f1: 0.0665\n",
      "Epoch 471/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3014 - f1: 0.7101 - val_loss: 0.2831 - val_f1: 0.0672\n",
      "Epoch 472/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3012 - f1: 0.7114 - val_loss: 0.2808 - val_f1: 0.0663\n",
      "Epoch 473/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3018 - f1: 0.7115 - val_loss: 0.2837 - val_f1: 0.0669\n",
      "Epoch 474/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3030 - f1: 0.7086 - val_loss: 0.2824 - val_f1: 0.0669\n",
      "Epoch 475/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3003 - f1: 0.7132 - val_loss: 0.2813 - val_f1: 0.0666\n",
      "Epoch 476/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3011 - f1: 0.7128 - val_loss: 0.2825 - val_f1: 0.0671\n",
      "Epoch 477/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2999 - f1: 0.7130 - val_loss: 0.2817 - val_f1: 0.0665\n",
      "Epoch 478/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3021 - f1: 0.7087 - val_loss: 0.2832 - val_f1: 0.0670\n",
      "Epoch 479/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3001 - f1: 0.7118 - val_loss: 0.2807 - val_f1: 0.0662\n",
      "Epoch 480/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3007 - f1: 0.7129 - val_loss: 0.2822 - val_f1: 0.0668\n",
      "Epoch 481/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3011 - f1: 0.7109 - val_loss: 0.2786 - val_f1: 0.0658\n",
      "Epoch 482/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3005 - f1: 0.7121 - val_loss: 0.2786 - val_f1: 0.0658\n",
      "Epoch 483/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3008 - f1: 0.7113 - val_loss: 0.2838 - val_f1: 0.0666\n",
      "Epoch 484/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3019 - f1: 0.7103 - val_loss: 0.2808 - val_f1: 0.0663\n",
      "Epoch 485/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3006 - f1: 0.7111 - val_loss: 0.2785 - val_f1: 0.0659\n",
      "Epoch 486/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3002 - f1: 0.7115 - val_loss: 0.2791 - val_f1: 0.0660\n",
      "Epoch 487/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3005 - f1: 0.7124 - val_loss: 0.2809 - val_f1: 0.0662\n",
      "Epoch 488/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3006 - f1: 0.7137 - val_loss: 0.2788 - val_f1: 0.0663\n",
      "Epoch 489/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3014 - f1: 0.7096 - val_loss: 0.2846 - val_f1: 0.0670\n",
      "Epoch 490/2000\n",
      "168135/168135 [==============================] - 12s 74us/step - loss: 0.3001 - f1: 0.7108 - val_loss: 0.2851 - val_f1: 0.0669\n",
      "Epoch 491/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3011 - f1: 0.7122 - val_loss: 0.2802 - val_f1: 0.0660\n",
      "Epoch 492/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3006 - f1: 0.7104 - val_loss: 0.2812 - val_f1: 0.0664\n",
      "Epoch 493/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.3018 - f1: 0.7116 - val_loss: 0.2815 - val_f1: 0.0664\n",
      "Epoch 494/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3001 - f1: 0.7126 - val_loss: 0.2824 - val_f1: 0.0664\n",
      "Epoch 495/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3014 - f1: 0.7116 - val_loss: 0.2771 - val_f1: 0.0656\n",
      "Epoch 496/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2998 - f1: 0.7118 - val_loss: 0.2824 - val_f1: 0.0664\n",
      "Epoch 497/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3011 - f1: 0.7113 - val_loss: 0.2806 - val_f1: 0.0663\n",
      "Epoch 498/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3000 - f1: 0.7135 - val_loss: 0.2807 - val_f1: 0.0663\n",
      "Epoch 499/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3000 - f1: 0.7112 - val_loss: 0.2799 - val_f1: 0.0658\n",
      "Epoch 500/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3002 - f1: 0.7126 - val_loss: 0.2793 - val_f1: 0.0658\n",
      "Epoch 501/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3007 - f1: 0.7129 - val_loss: 0.2795 - val_f1: 0.0661\n",
      "Epoch 502/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2997 - f1: 0.7142 - val_loss: 0.2827 - val_f1: 0.0669\n",
      "Epoch 503/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3009 - f1: 0.7116 - val_loss: 0.2833 - val_f1: 0.0670\n",
      "Epoch 504/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2990 - f1: 0.7129 - val_loss: 0.2794 - val_f1: 0.0662\n",
      "Epoch 505/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3004 - f1: 0.7112 - val_loss: 0.2801 - val_f1: 0.0663\n",
      "Epoch 506/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3010 - f1: 0.7110 - val_loss: 0.2821 - val_f1: 0.0668\n",
      "Epoch 507/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2991 - f1: 0.7149 - val_loss: 0.2853 - val_f1: 0.0674\n",
      "Epoch 508/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3006 - f1: 0.7124 - val_loss: 0.2850 - val_f1: 0.0672\n",
      "Epoch 509/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2996 - f1: 0.7134 - val_loss: 0.2799 - val_f1: 0.0661\n",
      "Epoch 510/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2990 - f1: 0.7140 - val_loss: 0.2821 - val_f1: 0.0665\n",
      "Epoch 511/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3001 - f1: 0.7129 - val_loss: 0.2820 - val_f1: 0.0667\n",
      "Epoch 512/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2994 - f1: 0.7143 - val_loss: 0.2830 - val_f1: 0.0672\n",
      "Epoch 513/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3001 - f1: 0.7111 - val_loss: 0.2808 - val_f1: 0.0663\n",
      "Epoch 514/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2999 - f1: 0.7127 - val_loss: 0.2828 - val_f1: 0.0668\n",
      "Epoch 515/2000\n",
      "168135/168135 [==============================] - 12s 74us/step - loss: 0.3007 - f1: 0.7106 - val_loss: 0.2843 - val_f1: 0.0669\n",
      "Epoch 516/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2993 - f1: 0.7146 - val_loss: 0.2827 - val_f1: 0.0667\n",
      "Epoch 517/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2984 - f1: 0.7141 - val_loss: 0.2803 - val_f1: 0.0661\n",
      "Epoch 518/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2998 - f1: 0.7140 - val_loss: 0.2818 - val_f1: 0.0663\n",
      "Epoch 519/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2997 - f1: 0.7137 - val_loss: 0.2819 - val_f1: 0.0665\n",
      "Epoch 520/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3002 - f1: 0.7130 - val_loss: 0.2843 - val_f1: 0.0671\n",
      "Epoch 521/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2990 - f1: 0.7152 - val_loss: 0.2826 - val_f1: 0.0667\n",
      "Epoch 522/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2998 - f1: 0.7128 - val_loss: 0.2818 - val_f1: 0.0666\n",
      "Epoch 523/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2996 - f1: 0.7156 - val_loss: 0.2814 - val_f1: 0.0666\n",
      "Epoch 524/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2997 - f1: 0.7116 - val_loss: 0.2821 - val_f1: 0.0665\n",
      "Epoch 525/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2976 - f1: 0.7181 - val_loss: 0.2820 - val_f1: 0.0665\n",
      "Epoch 526/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2993 - f1: 0.7139 - val_loss: 0.2832 - val_f1: 0.0666\n",
      "Epoch 527/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3007 - f1: 0.7111 - val_loss: 0.2802 - val_f1: 0.0665\n",
      "Epoch 528/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2990 - f1: 0.7155 - val_loss: 0.2824 - val_f1: 0.0670\n",
      "Epoch 529/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2994 - f1: 0.7128 - val_loss: 0.2811 - val_f1: 0.0666\n",
      "Epoch 530/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2984 - f1: 0.7119 - val_loss: 0.2838 - val_f1: 0.0671\n",
      "Epoch 531/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2993 - f1: 0.7120 - val_loss: 0.2822 - val_f1: 0.0665\n",
      "Epoch 532/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2993 - f1: 0.7139 - val_loss: 0.2820 - val_f1: 0.0665\n",
      "Epoch 533/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2981 - f1: 0.7155 - val_loss: 0.2852 - val_f1: 0.0669\n",
      "Epoch 534/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2983 - f1: 0.7158 - val_loss: 0.2839 - val_f1: 0.0669\n",
      "Epoch 535/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2998 - f1: 0.7133 - val_loss: 0.2818 - val_f1: 0.0663\n",
      "Epoch 536/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2991 - f1: 0.7129 - val_loss: 0.2829 - val_f1: 0.0669\n",
      "Epoch 537/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2979 - f1: 0.7153 - val_loss: 0.2808 - val_f1: 0.0667\n",
      "Epoch 538/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2976 - f1: 0.7177 - val_loss: 0.2795 - val_f1: 0.0658\n",
      "Epoch 539/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2977 - f1: 0.7172 - val_loss: 0.2849 - val_f1: 0.0669\n",
      "Epoch 540/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2975 - f1: 0.7153 - val_loss: 0.2843 - val_f1: 0.0674\n",
      "Epoch 541/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2996 - f1: 0.7117 - val_loss: 0.2798 - val_f1: 0.0663\n",
      "Epoch 542/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2970 - f1: 0.7146 - val_loss: 0.2826 - val_f1: 0.0668\n",
      "Epoch 543/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2990 - f1: 0.7123 - val_loss: 0.2826 - val_f1: 0.0667\n",
      "Epoch 544/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2982 - f1: 0.7163 - val_loss: 0.2847 - val_f1: 0.0670\n",
      "Epoch 545/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2993 - f1: 0.7160 - val_loss: 0.2818 - val_f1: 0.0664\n",
      "Epoch 546/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2981 - f1: 0.7134 - val_loss: 0.2793 - val_f1: 0.0656\n",
      "Epoch 547/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2984 - f1: 0.7142 - val_loss: 0.2792 - val_f1: 0.0658\n",
      "Epoch 548/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2993 - f1: 0.7132 - val_loss: 0.2833 - val_f1: 0.0669\n",
      "Epoch 549/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2978 - f1: 0.7173 - val_loss: 0.2847 - val_f1: 0.0669\n",
      "Epoch 550/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2987 - f1: 0.7118 - val_loss: 0.2789 - val_f1: 0.0660\n",
      "Epoch 551/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2973 - f1: 0.7175 - val_loss: 0.2836 - val_f1: 0.0670\n",
      "Epoch 552/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2980 - f1: 0.7159 - val_loss: 0.2820 - val_f1: 0.0666\n",
      "Epoch 553/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2975 - f1: 0.7168 - val_loss: 0.2808 - val_f1: 0.0659\n",
      "Epoch 554/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2974 - f1: 0.7162 - val_loss: 0.2837 - val_f1: 0.0670\n",
      "Epoch 555/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2987 - f1: 0.7136 - val_loss: 0.2823 - val_f1: 0.0663\n",
      "Epoch 556/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2986 - f1: 0.7132 - val_loss: 0.2817 - val_f1: 0.0664\n",
      "Epoch 557/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2972 - f1: 0.7145 - val_loss: 0.2821 - val_f1: 0.0666\n",
      "Epoch 558/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2980 - f1: 0.7158 - val_loss: 0.2819 - val_f1: 0.0663\n",
      "Epoch 559/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2975 - f1: 0.7159 - val_loss: 0.2810 - val_f1: 0.0661\n",
      "Epoch 560/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2977 - f1: 0.7132 - val_loss: 0.2799 - val_f1: 0.0660\n",
      "Epoch 561/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2978 - f1: 0.7154 - val_loss: 0.2823 - val_f1: 0.0665\n",
      "Epoch 562/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2983 - f1: 0.7147 - val_loss: 0.2844 - val_f1: 0.0668\n",
      "Epoch 563/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2976 - f1: 0.7152 - val_loss: 0.2850 - val_f1: 0.0669\n",
      "Epoch 564/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2967 - f1: 0.7157 - val_loss: 0.2807 - val_f1: 0.0662\n",
      "Epoch 565/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2966 - f1: 0.7167 - val_loss: 0.2828 - val_f1: 0.0665\n",
      "Epoch 566/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2958 - f1: 0.7186 - val_loss: 0.2852 - val_f1: 0.0668\n",
      "Epoch 567/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2979 - f1: 0.7182 - val_loss: 0.2820 - val_f1: 0.0663\n",
      "Epoch 568/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2969 - f1: 0.7160 - val_loss: 0.2813 - val_f1: 0.0661\n",
      "Epoch 569/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2968 - f1: 0.7169 - val_loss: 0.2815 - val_f1: 0.0664\n",
      "Epoch 570/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2968 - f1: 0.7175 - val_loss: 0.2825 - val_f1: 0.0667\n",
      "Epoch 571/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2961 - f1: 0.7175 - val_loss: 0.2812 - val_f1: 0.0663\n",
      "Epoch 572/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2983 - f1: 0.7162 - val_loss: 0.2812 - val_f1: 0.0665\n",
      "Epoch 573/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2975 - f1: 0.7182 - val_loss: 0.2797 - val_f1: 0.0659\n",
      "Epoch 574/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2978 - f1: 0.7129 - val_loss: 0.2813 - val_f1: 0.0662\n",
      "Epoch 575/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2974 - f1: 0.7146 - val_loss: 0.2861 - val_f1: 0.0671\n",
      "Epoch 576/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2983 - f1: 0.7125 - val_loss: 0.2823 - val_f1: 0.0664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2959 - f1: 0.7180 - val_loss: 0.2822 - val_f1: 0.0663\n",
      "Epoch 578/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2975 - f1: 0.7172 - val_loss: 0.2809 - val_f1: 0.0663\n",
      "Epoch 579/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2969 - f1: 0.7143 - val_loss: 0.2796 - val_f1: 0.0660\n",
      "Epoch 580/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2974 - f1: 0.7155 - val_loss: 0.2854 - val_f1: 0.0671\n",
      "Epoch 581/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2970 - f1: 0.7173 - val_loss: 0.2827 - val_f1: 0.0661\n",
      "Epoch 582/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2977 - f1: 0.7156 - val_loss: 0.2832 - val_f1: 0.0669\n",
      "Epoch 583/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2972 - f1: 0.7163 - val_loss: 0.2835 - val_f1: 0.0668\n",
      "Epoch 584/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2969 - f1: 0.7189 - val_loss: 0.2836 - val_f1: 0.0667\n",
      "Epoch 585/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2975 - f1: 0.7152 - val_loss: 0.2856 - val_f1: 0.0670\n",
      "Epoch 586/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2962 - f1: 0.7168 - val_loss: 0.2819 - val_f1: 0.0664\n",
      "Epoch 587/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2974 - f1: 0.7175 - val_loss: 0.2870 - val_f1: 0.0675\n",
      "Epoch 588/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2962 - f1: 0.7190 - val_loss: 0.2842 - val_f1: 0.0669\n",
      "Epoch 589/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2977 - f1: 0.7171 - val_loss: 0.2792 - val_f1: 0.0658\n",
      "Epoch 590/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2985 - f1: 0.7149 - val_loss: 0.2801 - val_f1: 0.0658\n",
      "Epoch 591/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2969 - f1: 0.7160 - val_loss: 0.2809 - val_f1: 0.0660\n",
      "Epoch 592/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2973 - f1: 0.7182 - val_loss: 0.2849 - val_f1: 0.0672\n",
      "Epoch 593/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2963 - f1: 0.7183 - val_loss: 0.2826 - val_f1: 0.0666\n",
      "Epoch 594/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2961 - f1: 0.7156 - val_loss: 0.2820 - val_f1: 0.0664\n",
      "Epoch 595/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2967 - f1: 0.7154 - val_loss: 0.2794 - val_f1: 0.0656\n",
      "Epoch 596/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2959 - f1: 0.7180 - val_loss: 0.2822 - val_f1: 0.0659\n",
      "Epoch 597/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2962 - f1: 0.7176 - val_loss: 0.2832 - val_f1: 0.0661\n",
      "Epoch 598/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2968 - f1: 0.7191 - val_loss: 0.2826 - val_f1: 0.0664\n",
      "Epoch 599/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2962 - f1: 0.7172 - val_loss: 0.2818 - val_f1: 0.0661\n",
      "Epoch 600/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2963 - f1: 0.7169 - val_loss: 0.2834 - val_f1: 0.0667\n",
      "Epoch 601/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2966 - f1: 0.7177 - val_loss: 0.2830 - val_f1: 0.0664\n",
      "Epoch 602/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2969 - f1: 0.7167 - val_loss: 0.2827 - val_f1: 0.0660\n",
      "Epoch 603/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2972 - f1: 0.7155 - val_loss: 0.2832 - val_f1: 0.0670\n",
      "Epoch 604/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2978 - f1: 0.7162 - val_loss: 0.2830 - val_f1: 0.0664\n",
      "Epoch 605/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2952 - f1: 0.7191 - val_loss: 0.2821 - val_f1: 0.0661\n",
      "Epoch 606/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2955 - f1: 0.7210 - val_loss: 0.2846 - val_f1: 0.0665\n",
      "Epoch 607/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2963 - f1: 0.7180 - val_loss: 0.2839 - val_f1: 0.0668\n",
      "Epoch 608/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2956 - f1: 0.7178 - val_loss: 0.2811 - val_f1: 0.0661\n",
      "Epoch 609/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2978 - f1: 0.7139 - val_loss: 0.2835 - val_f1: 0.0663\n",
      "Epoch 610/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2967 - f1: 0.7166 - val_loss: 0.2834 - val_f1: 0.0663\n",
      "Epoch 611/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2966 - f1: 0.7171 - val_loss: 0.2830 - val_f1: 0.0664\n",
      "Epoch 612/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2957 - f1: 0.7190 - val_loss: 0.2813 - val_f1: 0.0660\n",
      "Epoch 613/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2968 - f1: 0.7157 - val_loss: 0.2811 - val_f1: 0.0661\n",
      "Epoch 614/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2966 - f1: 0.7171 - val_loss: 0.2807 - val_f1: 0.0659\n",
      "Epoch 615/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2956 - f1: 0.7186 - val_loss: 0.2821 - val_f1: 0.0662\n",
      "Epoch 616/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2959 - f1: 0.7188 - val_loss: 0.2833 - val_f1: 0.0663\n",
      "Epoch 617/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2965 - f1: 0.7186 - val_loss: 0.2866 - val_f1: 0.0673\n",
      "Epoch 618/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2955 - f1: 0.7204 - val_loss: 0.2833 - val_f1: 0.0663\n",
      "Epoch 619/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2953 - f1: 0.7185 - val_loss: 0.2827 - val_f1: 0.0664\n",
      "Epoch 620/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2955 - f1: 0.7158 - val_loss: 0.2825 - val_f1: 0.0665\n",
      "Epoch 621/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2966 - f1: 0.7157 - val_loss: 0.2823 - val_f1: 0.0660\n",
      "Epoch 622/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2944 - f1: 0.7174 - val_loss: 0.2834 - val_f1: 0.0663\n",
      "Epoch 623/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2953 - f1: 0.7180 - val_loss: 0.2830 - val_f1: 0.0663\n",
      "Epoch 624/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2963 - f1: 0.7160 - val_loss: 0.2842 - val_f1: 0.0666\n",
      "Epoch 625/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2947 - f1: 0.7188 - val_loss: 0.2840 - val_f1: 0.0668\n",
      "Epoch 626/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2966 - f1: 0.7177 - val_loss: 0.2819 - val_f1: 0.0664\n",
      "Epoch 627/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2952 - f1: 0.7198 - val_loss: 0.2847 - val_f1: 0.0669\n",
      "Epoch 628/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2954 - f1: 0.7178 - val_loss: 0.2847 - val_f1: 0.0667\n",
      "Epoch 629/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2969 - f1: 0.7158 - val_loss: 0.2825 - val_f1: 0.0668\n",
      "Epoch 630/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2956 - f1: 0.7192 - val_loss: 0.2832 - val_f1: 0.0664\n",
      "Epoch 631/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2966 - f1: 0.7180 - val_loss: 0.2821 - val_f1: 0.0664\n",
      "Epoch 632/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2963 - f1: 0.7175 - val_loss: 0.2810 - val_f1: 0.0656\n",
      "Epoch 633/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2951 - f1: 0.7184 - val_loss: 0.2853 - val_f1: 0.0664\n",
      "Epoch 634/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2957 - f1: 0.7182 - val_loss: 0.2819 - val_f1: 0.0662\n",
      "Epoch 635/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2950 - f1: 0.7192 - val_loss: 0.2825 - val_f1: 0.0663\n",
      "Epoch 636/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2953 - f1: 0.7174 - val_loss: 0.2830 - val_f1: 0.0664\n",
      "Epoch 637/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2967 - f1: 0.7172 - val_loss: 0.2812 - val_f1: 0.0659\n",
      "Epoch 638/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2961 - f1: 0.7183 - val_loss: 0.2834 - val_f1: 0.0663\n",
      "Epoch 639/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2956 - f1: 0.7140 - val_loss: 0.2830 - val_f1: 0.0661\n",
      "Epoch 640/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2950 - f1: 0.7199 - val_loss: 0.2809 - val_f1: 0.0660\n",
      "Epoch 641/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2953 - f1: 0.7186 - val_loss: 0.2851 - val_f1: 0.0665\n",
      "Epoch 642/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2954 - f1: 0.7201 - val_loss: 0.2845 - val_f1: 0.0667\n",
      "Epoch 643/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2944 - f1: 0.7190 - val_loss: 0.2828 - val_f1: 0.0661\n",
      "Epoch 644/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2949 - f1: 0.7190 - val_loss: 0.2823 - val_f1: 0.0662\n",
      "Epoch 645/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2951 - f1: 0.7206 - val_loss: 0.2830 - val_f1: 0.0662\n",
      "Epoch 646/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2940 - f1: 0.7194 - val_loss: 0.2856 - val_f1: 0.0670\n",
      "Epoch 647/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2946 - f1: 0.7203 - val_loss: 0.2800 - val_f1: 0.0652\n",
      "Epoch 648/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2944 - f1: 0.7218 - val_loss: 0.2842 - val_f1: 0.0665\n",
      "Epoch 649/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2960 - f1: 0.7163 - val_loss: 0.2805 - val_f1: 0.0658\n",
      "Epoch 650/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2953 - f1: 0.7200 - val_loss: 0.2821 - val_f1: 0.0658\n",
      "Epoch 651/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2940 - f1: 0.7185 - val_loss: 0.2819 - val_f1: 0.0659\n",
      "Epoch 652/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2961 - f1: 0.7174 - val_loss: 0.2837 - val_f1: 0.0665\n",
      "Epoch 653/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2950 - f1: 0.7192 - val_loss: 0.2805 - val_f1: 0.0659\n",
      "Epoch 654/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2955 - f1: 0.7166 - val_loss: 0.2851 - val_f1: 0.0664\n",
      "Epoch 655/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2959 - f1: 0.7187 - val_loss: 0.2811 - val_f1: 0.0658\n",
      "Epoch 656/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2947 - f1: 0.7202 - val_loss: 0.2822 - val_f1: 0.0660\n",
      "Epoch 657/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2946 - f1: 0.7167 - val_loss: 0.2823 - val_f1: 0.0661\n",
      "Epoch 658/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2963 - f1: 0.7163 - val_loss: 0.2851 - val_f1: 0.0665\n",
      "Epoch 659/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2950 - f1: 0.7187 - val_loss: 0.2840 - val_f1: 0.0666\n",
      "Epoch 660/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2946 - f1: 0.7182 - val_loss: 0.2863 - val_f1: 0.0671\n",
      "Epoch 661/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2941 - f1: 0.7192 - val_loss: 0.2797 - val_f1: 0.0653\n",
      "Epoch 662/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2964 - f1: 0.7170 - val_loss: 0.2835 - val_f1: 0.0663\n",
      "Epoch 663/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2939 - f1: 0.7214 - val_loss: 0.2803 - val_f1: 0.0654\n",
      "Epoch 664/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2942 - f1: 0.7175 - val_loss: 0.2861 - val_f1: 0.0670\n",
      "Epoch 665/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2941 - f1: 0.7220 - val_loss: 0.2854 - val_f1: 0.0666\n",
      "Epoch 666/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2939 - f1: 0.7206 - val_loss: 0.2848 - val_f1: 0.0670\n",
      "Epoch 667/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2944 - f1: 0.7194 - val_loss: 0.2798 - val_f1: 0.0655\n",
      "Epoch 668/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2956 - f1: 0.7171 - val_loss: 0.2852 - val_f1: 0.0665\n",
      "Epoch 669/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2948 - f1: 0.7195 - val_loss: 0.2833 - val_f1: 0.0661\n",
      "Epoch 670/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2948 - f1: 0.7206 - val_loss: 0.2784 - val_f1: 0.0653\n",
      "Epoch 671/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2937 - f1: 0.7196 - val_loss: 0.2788 - val_f1: 0.0654\n",
      "Epoch 672/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2936 - f1: 0.7193 - val_loss: 0.2866 - val_f1: 0.0667\n",
      "Epoch 673/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2947 - f1: 0.7206 - val_loss: 0.2851 - val_f1: 0.0670\n",
      "Epoch 674/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2941 - f1: 0.7207 - val_loss: 0.2821 - val_f1: 0.0655\n",
      "Epoch 675/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2939 - f1: 0.7209 - val_loss: 0.2832 - val_f1: 0.0661\n",
      "Epoch 676/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2938 - f1: 0.7197 - val_loss: 0.2834 - val_f1: 0.0665\n",
      "Epoch 677/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2939 - f1: 0.7196 - val_loss: 0.2847 - val_f1: 0.0666\n",
      "Epoch 678/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2961 - f1: 0.7169 - val_loss: 0.2815 - val_f1: 0.0654\n",
      "Epoch 679/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2945 - f1: 0.7193 - val_loss: 0.2840 - val_f1: 0.0661\n",
      "Epoch 680/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2949 - f1: 0.7178 - val_loss: 0.2818 - val_f1: 0.0658\n",
      "Epoch 681/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2941 - f1: 0.7212 - val_loss: 0.2801 - val_f1: 0.0655\n",
      "Epoch 682/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2938 - f1: 0.7216 - val_loss: 0.2806 - val_f1: 0.0655\n",
      "Epoch 683/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2933 - f1: 0.7214 - val_loss: 0.2807 - val_f1: 0.0655\n",
      "Epoch 684/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2943 - f1: 0.7196 - val_loss: 0.2812 - val_f1: 0.0657\n",
      "Epoch 685/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2943 - f1: 0.7174 - val_loss: 0.2835 - val_f1: 0.0660\n",
      "Epoch 686/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2923 - f1: 0.7229 - val_loss: 0.2860 - val_f1: 0.0664\n",
      "Epoch 687/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2941 - f1: 0.7195 - val_loss: 0.2831 - val_f1: 0.0664\n",
      "Epoch 688/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2943 - f1: 0.7204 - val_loss: 0.2850 - val_f1: 0.0665\n",
      "Epoch 689/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2940 - f1: 0.7219 - val_loss: 0.2804 - val_f1: 0.0654\n",
      "Epoch 690/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2955 - f1: 0.7199 - val_loss: 0.2824 - val_f1: 0.0661\n",
      "Epoch 691/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2957 - f1: 0.7176 - val_loss: 0.2828 - val_f1: 0.0660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2936 - f1: 0.7208 - val_loss: 0.2831 - val_f1: 0.0659\n",
      "Epoch 693/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2935 - f1: 0.7211 - val_loss: 0.2846 - val_f1: 0.0666\n",
      "Epoch 694/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2936 - f1: 0.7205 - val_loss: 0.2817 - val_f1: 0.0662\n",
      "Epoch 695/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2943 - f1: 0.7204 - val_loss: 0.2805 - val_f1: 0.0658\n",
      "Epoch 696/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2929 - f1: 0.7226 - val_loss: 0.2865 - val_f1: 0.0667\n",
      "Epoch 697/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2934 - f1: 0.7207 - val_loss: 0.2825 - val_f1: 0.0656\n",
      "Epoch 698/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2929 - f1: 0.7211 - val_loss: 0.2824 - val_f1: 0.0661\n",
      "Epoch 699/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2940 - f1: 0.7223 - val_loss: 0.2835 - val_f1: 0.0661\n",
      "Epoch 700/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2941 - f1: 0.7214 - val_loss: 0.2844 - val_f1: 0.0664\n",
      "Epoch 701/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2924 - f1: 0.7238 - val_loss: 0.2828 - val_f1: 0.0661\n",
      "Epoch 702/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2951 - f1: 0.7181 - val_loss: 0.2828 - val_f1: 0.0664\n",
      "Epoch 703/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2934 - f1: 0.7194 - val_loss: 0.2847 - val_f1: 0.0664\n",
      "Epoch 704/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2933 - f1: 0.7220 - val_loss: 0.2817 - val_f1: 0.0660\n",
      "Epoch 705/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2942 - f1: 0.7206 - val_loss: 0.2789 - val_f1: 0.0653\n",
      "Epoch 706/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2946 - f1: 0.7201 - val_loss: 0.2838 - val_f1: 0.0661\n",
      "Epoch 707/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2939 - f1: 0.7202 - val_loss: 0.2853 - val_f1: 0.0664\n",
      "Epoch 708/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2926 - f1: 0.7226 - val_loss: 0.2831 - val_f1: 0.0658\n",
      "Epoch 709/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2935 - f1: 0.7215 - val_loss: 0.2841 - val_f1: 0.0662\n",
      "Epoch 710/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2913 - f1: 0.7246 - val_loss: 0.2862 - val_f1: 0.0668\n",
      "Epoch 711/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2923 - f1: 0.7248 - val_loss: 0.2841 - val_f1: 0.0659\n",
      "Epoch 712/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2929 - f1: 0.7229 - val_loss: 0.2814 - val_f1: 0.0657\n",
      "Epoch 713/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2934 - f1: 0.7206 - val_loss: 0.2888 - val_f1: 0.0671\n",
      "Epoch 714/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2932 - f1: 0.7210 - val_loss: 0.2818 - val_f1: 0.0655\n",
      "Epoch 715/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2936 - f1: 0.7202 - val_loss: 0.2873 - val_f1: 0.0671\n",
      "Epoch 716/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2930 - f1: 0.7212 - val_loss: 0.2846 - val_f1: 0.0661\n",
      "Epoch 717/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2937 - f1: 0.7199 - val_loss: 0.2875 - val_f1: 0.0663\n",
      "Epoch 718/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2936 - f1: 0.7194 - val_loss: 0.2860 - val_f1: 0.0668\n",
      "Epoch 719/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2935 - f1: 0.7240 - val_loss: 0.2855 - val_f1: 0.0662\n",
      "Epoch 720/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2926 - f1: 0.7217 - val_loss: 0.2821 - val_f1: 0.0657\n",
      "Epoch 721/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2934 - f1: 0.7230 - val_loss: 0.2825 - val_f1: 0.0661\n",
      "Epoch 722/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2922 - f1: 0.7243 - val_loss: 0.2811 - val_f1: 0.0656\n",
      "Epoch 723/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2930 - f1: 0.7225 - val_loss: 0.2851 - val_f1: 0.0664\n",
      "Epoch 724/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2924 - f1: 0.7209 - val_loss: 0.2841 - val_f1: 0.0661\n",
      "Epoch 725/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2935 - f1: 0.7207 - val_loss: 0.2850 - val_f1: 0.0663\n",
      "Epoch 726/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2931 - f1: 0.7208 - val_loss: 0.2852 - val_f1: 0.0664\n",
      "Epoch 727/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2937 - f1: 0.7207 - val_loss: 0.2790 - val_f1: 0.0654\n",
      "Epoch 728/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2936 - f1: 0.7204 - val_loss: 0.2798 - val_f1: 0.0653\n",
      "Epoch 729/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2915 - f1: 0.7247 - val_loss: 0.2838 - val_f1: 0.0663\n",
      "Epoch 730/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2920 - f1: 0.7227 - val_loss: 0.2832 - val_f1: 0.0661\n",
      "Epoch 731/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2924 - f1: 0.7235 - val_loss: 0.2836 - val_f1: 0.0661\n",
      "Epoch 732/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2924 - f1: 0.7227 - val_loss: 0.2850 - val_f1: 0.0663\n",
      "Epoch 733/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2922 - f1: 0.7232 - val_loss: 0.2830 - val_f1: 0.0662\n",
      "Epoch 734/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2930 - f1: 0.7204 - val_loss: 0.2844 - val_f1: 0.0661\n",
      "Epoch 735/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2921 - f1: 0.7218 - val_loss: 0.2837 - val_f1: 0.0660\n",
      "Epoch 736/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2922 - f1: 0.7213 - val_loss: 0.2879 - val_f1: 0.0669\n",
      "Epoch 737/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2919 - f1: 0.7228 - val_loss: 0.2859 - val_f1: 0.0664\n",
      "Epoch 738/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2930 - f1: 0.7195 - val_loss: 0.2843 - val_f1: 0.0664\n",
      "Epoch 739/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2938 - f1: 0.7207 - val_loss: 0.2815 - val_f1: 0.0659\n",
      "Epoch 740/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2926 - f1: 0.7225 - val_loss: 0.2838 - val_f1: 0.0663\n",
      "Epoch 741/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2934 - f1: 0.7215 - val_loss: 0.2815 - val_f1: 0.0660\n",
      "Epoch 742/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2917 - f1: 0.7235 - val_loss: 0.2864 - val_f1: 0.0666\n",
      "Epoch 743/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2934 - f1: 0.7218 - val_loss: 0.2849 - val_f1: 0.0665\n",
      "Epoch 744/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2932 - f1: 0.7212 - val_loss: 0.2827 - val_f1: 0.0659\n",
      "Epoch 745/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2913 - f1: 0.7227 - val_loss: 0.2834 - val_f1: 0.0667\n",
      "Epoch 746/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2932 - f1: 0.7223 - val_loss: 0.2835 - val_f1: 0.0663\n",
      "Epoch 747/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2925 - f1: 0.7238 - val_loss: 0.2819 - val_f1: 0.0658\n",
      "Epoch 748/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2917 - f1: 0.7227 - val_loss: 0.2873 - val_f1: 0.0667\n",
      "Epoch 749/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2924 - f1: 0.7230 - val_loss: 0.2821 - val_f1: 0.0660\n",
      "Epoch 750/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2919 - f1: 0.7225 - val_loss: 0.2845 - val_f1: 0.0663\n",
      "Epoch 751/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2920 - f1: 0.7229 - val_loss: 0.2858 - val_f1: 0.0670\n",
      "Epoch 752/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2927 - f1: 0.7229 - val_loss: 0.2843 - val_f1: 0.0663\n",
      "Epoch 753/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2925 - f1: 0.7218 - val_loss: 0.2844 - val_f1: 0.0658\n",
      "Epoch 754/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2910 - f1: 0.7264 - val_loss: 0.2848 - val_f1: 0.0661\n",
      "Epoch 755/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2942 - f1: 0.7209 - val_loss: 0.2821 - val_f1: 0.0657\n",
      "Epoch 756/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2922 - f1: 0.7234 - val_loss: 0.2890 - val_f1: 0.0674\n",
      "Epoch 757/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2926 - f1: 0.7227 - val_loss: 0.2839 - val_f1: 0.0664\n",
      "Epoch 758/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2925 - f1: 0.7204 - val_loss: 0.2841 - val_f1: 0.0664\n",
      "Epoch 759/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2918 - f1: 0.7230 - val_loss: 0.2877 - val_f1: 0.0669\n",
      "Epoch 760/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2919 - f1: 0.7247 - val_loss: 0.2811 - val_f1: 0.0658\n",
      "Epoch 761/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2906 - f1: 0.7239 - val_loss: 0.2848 - val_f1: 0.0662\n",
      "Epoch 762/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2920 - f1: 0.7238 - val_loss: 0.2767 - val_f1: 0.0647\n",
      "Epoch 763/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2912 - f1: 0.7232 - val_loss: 0.2830 - val_f1: 0.0658\n",
      "Epoch 764/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2934 - f1: 0.7221 - val_loss: 0.2811 - val_f1: 0.0657\n",
      "Epoch 765/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2906 - f1: 0.7279 - val_loss: 0.2828 - val_f1: 0.0661\n",
      "Epoch 766/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2917 - f1: 0.7228 - val_loss: 0.2829 - val_f1: 0.0662\n",
      "Epoch 767/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2920 - f1: 0.7225 - val_loss: 0.2825 - val_f1: 0.0659\n",
      "Epoch 768/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2918 - f1: 0.7230 - val_loss: 0.2846 - val_f1: 0.0664\n",
      "Epoch 769/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2928 - f1: 0.7216 - val_loss: 0.2809 - val_f1: 0.0656\n",
      "Epoch 770/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2915 - f1: 0.7241 - val_loss: 0.2840 - val_f1: 0.0664\n",
      "Epoch 771/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2921 - f1: 0.7221 - val_loss: 0.2870 - val_f1: 0.0665\n",
      "Epoch 772/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2908 - f1: 0.7246 - val_loss: 0.2881 - val_f1: 0.0668\n",
      "Epoch 773/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2912 - f1: 0.7222 - val_loss: 0.2864 - val_f1: 0.0665\n",
      "Epoch 774/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2918 - f1: 0.7220 - val_loss: 0.2837 - val_f1: 0.0663\n",
      "Epoch 775/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2923 - f1: 0.7221 - val_loss: 0.2830 - val_f1: 0.0660\n",
      "Epoch 776/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2927 - f1: 0.7222 - val_loss: 0.2817 - val_f1: 0.0661\n",
      "Epoch 777/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2925 - f1: 0.7218 - val_loss: 0.2869 - val_f1: 0.0667\n",
      "Epoch 778/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2933 - f1: 0.7197 - val_loss: 0.2829 - val_f1: 0.0661\n",
      "Epoch 779/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2912 - f1: 0.7230 - val_loss: 0.2861 - val_f1: 0.0667\n",
      "Epoch 780/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2913 - f1: 0.7250 - val_loss: 0.2843 - val_f1: 0.0664\n",
      "Epoch 781/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2905 - f1: 0.7247 - val_loss: 0.2823 - val_f1: 0.0659\n",
      "Epoch 782/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2917 - f1: 0.7228 - val_loss: 0.2859 - val_f1: 0.0665\n",
      "Epoch 783/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2919 - f1: 0.7243 - val_loss: 0.2824 - val_f1: 0.0658\n",
      "Epoch 784/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2931 - f1: 0.7215 - val_loss: 0.2829 - val_f1: 0.0661\n",
      "Epoch 785/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2918 - f1: 0.7234 - val_loss: 0.2868 - val_f1: 0.0663\n",
      "Epoch 786/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2913 - f1: 0.7255 - val_loss: 0.2815 - val_f1: 0.0660\n",
      "Epoch 787/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2918 - f1: 0.7233 - val_loss: 0.2871 - val_f1: 0.0667\n",
      "Epoch 788/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2909 - f1: 0.7237 - val_loss: 0.2845 - val_f1: 0.0663\n",
      "Epoch 789/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2914 - f1: 0.7236 - val_loss: 0.2833 - val_f1: 0.0666\n",
      "Epoch 790/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2911 - f1: 0.7243 - val_loss: 0.2830 - val_f1: 0.0662\n",
      "Epoch 791/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2922 - f1: 0.7242 - val_loss: 0.2864 - val_f1: 0.0668\n",
      "Epoch 792/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2920 - f1: 0.7212 - val_loss: 0.2851 - val_f1: 0.0663\n",
      "Epoch 793/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2918 - f1: 0.7224 - val_loss: 0.2862 - val_f1: 0.0663\n",
      "Epoch 794/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2918 - f1: 0.7238 - val_loss: 0.2826 - val_f1: 0.0660\n",
      "Epoch 795/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2921 - f1: 0.7218 - val_loss: 0.2837 - val_f1: 0.0663\n",
      "Epoch 796/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2903 - f1: 0.7259 - val_loss: 0.2819 - val_f1: 0.0659\n",
      "Epoch 797/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2898 - f1: 0.7243 - val_loss: 0.2856 - val_f1: 0.0661\n",
      "Epoch 798/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2917 - f1: 0.7230 - val_loss: 0.2859 - val_f1: 0.0665\n",
      "Epoch 799/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2906 - f1: 0.7260 - val_loss: 0.2834 - val_f1: 0.0663\n",
      "Epoch 800/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2909 - f1: 0.7243 - val_loss: 0.2850 - val_f1: 0.0664\n",
      "Epoch 801/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2926 - f1: 0.7219 - val_loss: 0.2791 - val_f1: 0.0654\n",
      "Epoch 802/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2913 - f1: 0.7241 - val_loss: 0.2822 - val_f1: 0.0659\n",
      "Epoch 803/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2917 - f1: 0.7228 - val_loss: 0.2820 - val_f1: 0.0654\n",
      "Epoch 804/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2925 - f1: 0.7221 - val_loss: 0.2821 - val_f1: 0.0658\n",
      "Epoch 805/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2917 - f1: 0.7226 - val_loss: 0.2800 - val_f1: 0.0651\n",
      "Epoch 806/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2904 - f1: 0.7264 - val_loss: 0.2830 - val_f1: 0.0660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 807/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2916 - f1: 0.7238 - val_loss: 0.2843 - val_f1: 0.0664\n",
      "Epoch 808/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2910 - f1: 0.7258 - val_loss: 0.2864 - val_f1: 0.0663\n",
      "Epoch 809/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2905 - f1: 0.7251 - val_loss: 0.2852 - val_f1: 0.0665\n",
      "Epoch 810/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2906 - f1: 0.7234 - val_loss: 0.2841 - val_f1: 0.0666\n",
      "Epoch 811/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2912 - f1: 0.7223 - val_loss: 0.2839 - val_f1: 0.0662\n",
      "Epoch 812/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2904 - f1: 0.7242 - val_loss: 0.2861 - val_f1: 0.0667\n",
      "Epoch 813/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2919 - f1: 0.7238 - val_loss: 0.2878 - val_f1: 0.0669\n",
      "Epoch 814/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2931 - f1: 0.7228 - val_loss: 0.2838 - val_f1: 0.0663\n",
      "Epoch 815/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2897 - f1: 0.7253 - val_loss: 0.2858 - val_f1: 0.0666\n",
      "Epoch 816/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2919 - f1: 0.7253 - val_loss: 0.2837 - val_f1: 0.0664\n",
      "Epoch 817/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2917 - f1: 0.7244 - val_loss: 0.2830 - val_f1: 0.0660\n",
      "Epoch 818/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2919 - f1: 0.7238 - val_loss: 0.2848 - val_f1: 0.0665\n",
      "Epoch 819/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2913 - f1: 0.7243 - val_loss: 0.2855 - val_f1: 0.0667\n",
      "Epoch 820/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2909 - f1: 0.7240 - val_loss: 0.2835 - val_f1: 0.0660\n",
      "Epoch 821/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2901 - f1: 0.7255 - val_loss: 0.2864 - val_f1: 0.0667\n",
      "Epoch 822/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2917 - f1: 0.7251 - val_loss: 0.2852 - val_f1: 0.0663\n",
      "Epoch 823/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2913 - f1: 0.7250 - val_loss: 0.2854 - val_f1: 0.0663\n",
      "Epoch 824/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2910 - f1: 0.7236 - val_loss: 0.2852 - val_f1: 0.0662\n",
      "Epoch 825/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2898 - f1: 0.7248 - val_loss: 0.2857 - val_f1: 0.0664\n",
      "Epoch 826/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2920 - f1: 0.7222 - val_loss: 0.2819 - val_f1: 0.0659\n",
      "Epoch 827/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2914 - f1: 0.7253 - val_loss: 0.2823 - val_f1: 0.0656\n",
      "Epoch 828/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2904 - f1: 0.7247 - val_loss: 0.2848 - val_f1: 0.0665\n",
      "Epoch 829/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2904 - f1: 0.7271 - val_loss: 0.2845 - val_f1: 0.0663\n",
      "Epoch 830/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2886 - f1: 0.7290 - val_loss: 0.2848 - val_f1: 0.0661\n",
      "Epoch 831/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2891 - f1: 0.7270 - val_loss: 0.2797 - val_f1: 0.0654\n",
      "Epoch 832/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2911 - f1: 0.7251 - val_loss: 0.2857 - val_f1: 0.0665\n",
      "Epoch 833/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2897 - f1: 0.7274 - val_loss: 0.2857 - val_f1: 0.0667\n",
      "Epoch 834/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2897 - f1: 0.7268 - val_loss: 0.2857 - val_f1: 0.0664\n",
      "Epoch 835/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2890 - f1: 0.7272 - val_loss: 0.2833 - val_f1: 0.0662\n",
      "Epoch 836/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2912 - f1: 0.7243 - val_loss: 0.2832 - val_f1: 0.0663\n",
      "Epoch 837/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2897 - f1: 0.7267 - val_loss: 0.2852 - val_f1: 0.0665\n",
      "Epoch 838/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2913 - f1: 0.7263 - val_loss: 0.2841 - val_f1: 0.0663\n",
      "Epoch 839/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2898 - f1: 0.7254 - val_loss: 0.2858 - val_f1: 0.0666\n",
      "Epoch 840/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2904 - f1: 0.7265 - val_loss: 0.2857 - val_f1: 0.0663\n",
      "Epoch 841/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2905 - f1: 0.7262 - val_loss: 0.2822 - val_f1: 0.0660\n",
      "Epoch 842/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2905 - f1: 0.7263 - val_loss: 0.2866 - val_f1: 0.0664\n",
      "Epoch 843/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2903 - f1: 0.7259 - val_loss: 0.2821 - val_f1: 0.0662\n",
      "Epoch 844/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2900 - f1: 0.7249 - val_loss: 0.2826 - val_f1: 0.0660\n",
      "Epoch 845/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2905 - f1: 0.7255 - val_loss: 0.2815 - val_f1: 0.0657\n",
      "Epoch 846/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2899 - f1: 0.7247 - val_loss: 0.2845 - val_f1: 0.0663\n",
      "Epoch 847/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2903 - f1: 0.7257 - val_loss: 0.2872 - val_f1: 0.0669\n",
      "Epoch 848/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2900 - f1: 0.7264 - val_loss: 0.2822 - val_f1: 0.0659\n",
      "Epoch 849/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2906 - f1: 0.7250 - val_loss: 0.2847 - val_f1: 0.0661\n",
      "Epoch 850/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2900 - f1: 0.7277 - val_loss: 0.2847 - val_f1: 0.0662\n",
      "Epoch 851/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2893 - f1: 0.7252 - val_loss: 0.2866 - val_f1: 0.0667\n",
      "Epoch 852/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2902 - f1: 0.7232 - val_loss: 0.2878 - val_f1: 0.0669\n",
      "Epoch 853/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2906 - f1: 0.7247 - val_loss: 0.2812 - val_f1: 0.0659\n",
      "Epoch 854/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2898 - f1: 0.7256 - val_loss: 0.2851 - val_f1: 0.0665\n",
      "Epoch 855/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2899 - f1: 0.7259 - val_loss: 0.2858 - val_f1: 0.0663\n",
      "Epoch 856/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2898 - f1: 0.7246 - val_loss: 0.2874 - val_f1: 0.0666\n",
      "Epoch 857/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2894 - f1: 0.7249 - val_loss: 0.2872 - val_f1: 0.0666\n",
      "Epoch 858/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2903 - f1: 0.7228 - val_loss: 0.2847 - val_f1: 0.0666\n",
      "Epoch 859/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2892 - f1: 0.7276 - val_loss: 0.2840 - val_f1: 0.0660\n",
      "Epoch 860/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2909 - f1: 0.7254 - val_loss: 0.2877 - val_f1: 0.0668\n",
      "Epoch 861/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2890 - f1: 0.7289 - val_loss: 0.2857 - val_f1: 0.0666\n",
      "Epoch 862/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2899 - f1: 0.7274 - val_loss: 0.2852 - val_f1: 0.0661\n",
      "Epoch 863/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2892 - f1: 0.7295 - val_loss: 0.2824 - val_f1: 0.0662\n",
      "Epoch 864/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2916 - f1: 0.7234 - val_loss: 0.2822 - val_f1: 0.0660\n",
      "Epoch 865/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2895 - f1: 0.7261 - val_loss: 0.2819 - val_f1: 0.0656\n",
      "Epoch 866/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2895 - f1: 0.7273 - val_loss: 0.2859 - val_f1: 0.0660\n",
      "Epoch 867/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2904 - f1: 0.7247 - val_loss: 0.2831 - val_f1: 0.0658\n",
      "Epoch 868/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2902 - f1: 0.7247 - val_loss: 0.2832 - val_f1: 0.0664\n",
      "Epoch 869/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2895 - f1: 0.7252 - val_loss: 0.2858 - val_f1: 0.0667\n",
      "Epoch 870/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2892 - f1: 0.7255 - val_loss: 0.2847 - val_f1: 0.0664\n",
      "Epoch 871/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2887 - f1: 0.7271 - val_loss: 0.2828 - val_f1: 0.0660\n",
      "Epoch 872/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2897 - f1: 0.7253 - val_loss: 0.2832 - val_f1: 0.0661\n",
      "Epoch 873/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2899 - f1: 0.7264 - val_loss: 0.2827 - val_f1: 0.0658\n",
      "Epoch 874/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2901 - f1: 0.7255 - val_loss: 0.2843 - val_f1: 0.0666\n",
      "Epoch 875/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2894 - f1: 0.7255 - val_loss: 0.2855 - val_f1: 0.0666\n",
      "Epoch 876/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2892 - f1: 0.7245 - val_loss: 0.2863 - val_f1: 0.0662\n",
      "Epoch 877/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2890 - f1: 0.7256 - val_loss: 0.2828 - val_f1: 0.0662\n",
      "Epoch 878/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2882 - f1: 0.7286 - val_loss: 0.2878 - val_f1: 0.0666\n",
      "Epoch 879/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2902 - f1: 0.7259 - val_loss: 0.2838 - val_f1: 0.0661\n",
      "Epoch 880/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2894 - f1: 0.7281 - val_loss: 0.2869 - val_f1: 0.0667\n",
      "Epoch 881/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2894 - f1: 0.7270 - val_loss: 0.2850 - val_f1: 0.0665\n",
      "Epoch 882/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2900 - f1: 0.7262 - val_loss: 0.2853 - val_f1: 0.0666\n",
      "Epoch 883/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2890 - f1: 0.7283 - val_loss: 0.2867 - val_f1: 0.0664\n",
      "Epoch 884/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2883 - f1: 0.7275 - val_loss: 0.2835 - val_f1: 0.0666\n",
      "Epoch 885/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2889 - f1: 0.7266 - val_loss: 0.2838 - val_f1: 0.0665\n",
      "Epoch 886/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2891 - f1: 0.7282 - val_loss: 0.2846 - val_f1: 0.0664\n",
      "Epoch 887/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2901 - f1: 0.7248 - val_loss: 0.2827 - val_f1: 0.0656\n",
      "Epoch 888/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2897 - f1: 0.7270 - val_loss: 0.2866 - val_f1: 0.0665\n",
      "Epoch 889/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2890 - f1: 0.7292 - val_loss: 0.2856 - val_f1: 0.0662\n",
      "Epoch 890/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2899 - f1: 0.7241 - val_loss: 0.2793 - val_f1: 0.0659\n",
      "Epoch 891/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2888 - f1: 0.7268 - val_loss: 0.2849 - val_f1: 0.0664\n",
      "Epoch 892/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2883 - f1: 0.7287 - val_loss: 0.2856 - val_f1: 0.0666\n",
      "Epoch 893/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2888 - f1: 0.7265 - val_loss: 0.2871 - val_f1: 0.0671\n",
      "Epoch 894/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2895 - f1: 0.7265 - val_loss: 0.2877 - val_f1: 0.0666\n",
      "Epoch 895/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2897 - f1: 0.7266 - val_loss: 0.2834 - val_f1: 0.0663\n",
      "Epoch 896/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2892 - f1: 0.7269 - val_loss: 0.2839 - val_f1: 0.0664\n",
      "Epoch 897/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2883 - f1: 0.7295 - val_loss: 0.2836 - val_f1: 0.0666\n",
      "Epoch 898/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2894 - f1: 0.7254 - val_loss: 0.2862 - val_f1: 0.0667\n",
      "Epoch 899/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2890 - f1: 0.7253 - val_loss: 0.2844 - val_f1: 0.0663\n",
      "Epoch 900/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2895 - f1: 0.7252 - val_loss: 0.2862 - val_f1: 0.0667\n",
      "Epoch 901/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2901 - f1: 0.7244 - val_loss: 0.2864 - val_f1: 0.0668\n",
      "Epoch 902/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2886 - f1: 0.7273 - val_loss: 0.2835 - val_f1: 0.0660\n",
      "Epoch 903/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2897 - f1: 0.7274 - val_loss: 0.2845 - val_f1: 0.0662\n",
      "Epoch 904/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2898 - f1: 0.7259 - val_loss: 0.2860 - val_f1: 0.0667\n",
      "Epoch 905/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2880 - f1: 0.7298 - val_loss: 0.2832 - val_f1: 0.0661\n",
      "Epoch 906/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2898 - f1: 0.7259 - val_loss: 0.2841 - val_f1: 0.0664\n",
      "Epoch 907/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2880 - f1: 0.7263 - val_loss: 0.2818 - val_f1: 0.0661\n",
      "Epoch 908/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2880 - f1: 0.7292 - val_loss: 0.2830 - val_f1: 0.0664\n",
      "Epoch 909/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2896 - f1: 0.7275 - val_loss: 0.2843 - val_f1: 0.0663\n",
      "Epoch 910/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2893 - f1: 0.7268 - val_loss: 0.2865 - val_f1: 0.0665\n",
      "Epoch 911/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2881 - f1: 0.7261 - val_loss: 0.2826 - val_f1: 0.0664\n",
      "Epoch 912/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2883 - f1: 0.7272 - val_loss: 0.2869 - val_f1: 0.0666\n",
      "Epoch 913/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2887 - f1: 0.7276 - val_loss: 0.2865 - val_f1: 0.0665\n",
      "Epoch 914/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2890 - f1: 0.7258 - val_loss: 0.2842 - val_f1: 0.0663\n",
      "Epoch 915/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2895 - f1: 0.7254 - val_loss: 0.2819 - val_f1: 0.0663\n",
      "Epoch 916/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2892 - f1: 0.7271 - val_loss: 0.2828 - val_f1: 0.0666\n",
      "Epoch 917/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2892 - f1: 0.7258 - val_loss: 0.2848 - val_f1: 0.0662\n",
      "Epoch 918/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2884 - f1: 0.7295 - val_loss: 0.2821 - val_f1: 0.0659\n",
      "Epoch 919/2000\n",
      "168135/168135 [==============================] - 15s 89us/step - loss: 0.2885 - f1: 0.7286 - val_loss: 0.2897 - val_f1: 0.0670\n",
      "Epoch 920/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2885 - f1: 0.7278 - val_loss: 0.2857 - val_f1: 0.0664\n",
      "Epoch 921/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2888 - f1: 0.7273 - val_loss: 0.2844 - val_f1: 0.0663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2896 - f1: 0.7260 - val_loss: 0.2869 - val_f1: 0.0665\n",
      "Epoch 923/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2889 - f1: 0.7274 - val_loss: 0.2864 - val_f1: 0.0668\n",
      "Epoch 924/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2889 - f1: 0.7278 - val_loss: 0.2840 - val_f1: 0.0664\n",
      "Epoch 925/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2889 - f1: 0.7264 - val_loss: 0.2867 - val_f1: 0.0663\n",
      "Epoch 926/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2884 - f1: 0.7280 - val_loss: 0.2865 - val_f1: 0.0669\n",
      "Epoch 927/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2887 - f1: 0.7262 - val_loss: 0.2823 - val_f1: 0.0661\n",
      "Epoch 928/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2873 - f1: 0.7284 - val_loss: 0.2867 - val_f1: 0.0670\n",
      "Epoch 929/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2894 - f1: 0.7262 - val_loss: 0.2828 - val_f1: 0.0662\n",
      "Epoch 930/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2889 - f1: 0.7287 - val_loss: 0.2855 - val_f1: 0.0663\n",
      "Epoch 931/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2887 - f1: 0.7291 - val_loss: 0.2817 - val_f1: 0.0663\n",
      "Epoch 932/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2886 - f1: 0.7269 - val_loss: 0.2864 - val_f1: 0.0668\n",
      "Epoch 933/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2892 - f1: 0.7287 - val_loss: 0.2840 - val_f1: 0.0658\n",
      "Epoch 934/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2882 - f1: 0.7263 - val_loss: 0.2851 - val_f1: 0.0665\n",
      "Epoch 935/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2886 - f1: 0.7263 - val_loss: 0.2846 - val_f1: 0.0664\n",
      "Epoch 936/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2884 - f1: 0.7288 - val_loss: 0.2809 - val_f1: 0.0657\n",
      "Epoch 937/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2879 - f1: 0.7273 - val_loss: 0.2837 - val_f1: 0.0661\n",
      "Epoch 938/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2893 - f1: 0.7266 - val_loss: 0.2823 - val_f1: 0.0660\n",
      "Epoch 939/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2882 - f1: 0.7258 - val_loss: 0.2822 - val_f1: 0.0659\n",
      "Epoch 940/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2885 - f1: 0.7288 - val_loss: 0.2836 - val_f1: 0.0666\n",
      "Epoch 941/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2881 - f1: 0.7281 - val_loss: 0.2828 - val_f1: 0.0661\n",
      "Epoch 942/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2896 - f1: 0.7272 - val_loss: 0.2829 - val_f1: 0.0660\n",
      "Epoch 943/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2886 - f1: 0.7274 - val_loss: 0.2896 - val_f1: 0.0670\n",
      "Epoch 944/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2889 - f1: 0.7265 - val_loss: 0.2820 - val_f1: 0.0658\n",
      "Epoch 945/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2883 - f1: 0.7285 - val_loss: 0.2860 - val_f1: 0.0665\n",
      "Epoch 946/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2879 - f1: 0.7275 - val_loss: 0.2868 - val_f1: 0.0666\n",
      "Epoch 947/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2876 - f1: 0.7297 - val_loss: 0.2839 - val_f1: 0.0660\n",
      "Epoch 948/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2886 - f1: 0.7265 - val_loss: 0.2838 - val_f1: 0.0663\n",
      "Epoch 949/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2882 - f1: 0.7280 - val_loss: 0.2867 - val_f1: 0.0668\n",
      "Epoch 950/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2878 - f1: 0.7277 - val_loss: 0.2881 - val_f1: 0.0665\n",
      "Epoch 951/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2893 - f1: 0.7273 - val_loss: 0.2862 - val_f1: 0.0665\n",
      "Epoch 952/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2871 - f1: 0.7296 - val_loss: 0.2829 - val_f1: 0.0657\n",
      "Epoch 953/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2891 - f1: 0.7253 - val_loss: 0.2838 - val_f1: 0.0663\n",
      "Epoch 954/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2875 - f1: 0.7270 - val_loss: 0.2872 - val_f1: 0.0669\n",
      "Epoch 955/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2872 - f1: 0.7287 - val_loss: 0.2861 - val_f1: 0.0665\n",
      "Epoch 956/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2871 - f1: 0.7296 - val_loss: 0.2862 - val_f1: 0.0665\n",
      "Epoch 957/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2885 - f1: 0.7261 - val_loss: 0.2825 - val_f1: 0.0660\n",
      "Epoch 958/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2869 - f1: 0.7310 - val_loss: 0.2819 - val_f1: 0.0654\n",
      "Epoch 959/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2878 - f1: 0.7282 - val_loss: 0.2863 - val_f1: 0.0666\n",
      "Epoch 960/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2876 - f1: 0.7291 - val_loss: 0.2888 - val_f1: 0.0672\n",
      "Epoch 961/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2876 - f1: 0.7268 - val_loss: 0.2879 - val_f1: 0.0668\n",
      "Epoch 962/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2869 - f1: 0.7285 - val_loss: 0.2877 - val_f1: 0.0670\n",
      "Epoch 963/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2866 - f1: 0.7298 - val_loss: 0.2843 - val_f1: 0.0662\n",
      "Epoch 964/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2886 - f1: 0.7264 - val_loss: 0.2861 - val_f1: 0.0664\n",
      "Epoch 965/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2889 - f1: 0.7272 - val_loss: 0.2861 - val_f1: 0.0666\n",
      "Epoch 966/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2887 - f1: 0.7259 - val_loss: 0.2886 - val_f1: 0.0668\n",
      "Epoch 967/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2867 - f1: 0.7300 - val_loss: 0.2866 - val_f1: 0.0662\n",
      "Epoch 968/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2866 - f1: 0.7301 - val_loss: 0.2868 - val_f1: 0.0664\n",
      "Epoch 969/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2889 - f1: 0.7283 - val_loss: 0.2885 - val_f1: 0.0670\n",
      "Epoch 970/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2884 - f1: 0.7282 - val_loss: 0.2864 - val_f1: 0.0666\n",
      "Epoch 971/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2890 - f1: 0.7264 - val_loss: 0.2859 - val_f1: 0.0665\n",
      "Epoch 972/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2879 - f1: 0.7293 - val_loss: 0.2850 - val_f1: 0.0666\n",
      "Epoch 973/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2879 - f1: 0.7289 - val_loss: 0.2877 - val_f1: 0.0668\n",
      "Epoch 974/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2871 - f1: 0.7289 - val_loss: 0.2830 - val_f1: 0.0663\n",
      "Epoch 975/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2886 - f1: 0.7275 - val_loss: 0.2848 - val_f1: 0.0662\n",
      "Epoch 976/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2880 - f1: 0.7289 - val_loss: 0.2855 - val_f1: 0.0665\n",
      "Epoch 977/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2881 - f1: 0.7279 - val_loss: 0.2834 - val_f1: 0.0661\n",
      "Epoch 978/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2885 - f1: 0.7281 - val_loss: 0.2845 - val_f1: 0.0665\n",
      "Epoch 979/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2875 - f1: 0.7300 - val_loss: 0.2864 - val_f1: 0.0668\n",
      "Epoch 980/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2874 - f1: 0.7288 - val_loss: 0.2831 - val_f1: 0.0660\n",
      "Epoch 981/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2873 - f1: 0.7283 - val_loss: 0.2845 - val_f1: 0.0665\n",
      "Epoch 982/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2876 - f1: 0.7306 - val_loss: 0.2849 - val_f1: 0.0664\n",
      "Epoch 983/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2866 - f1: 0.7308 - val_loss: 0.2862 - val_f1: 0.0666\n",
      "Epoch 984/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2870 - f1: 0.7287 - val_loss: 0.2835 - val_f1: 0.0660\n",
      "Epoch 985/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2867 - f1: 0.7306 - val_loss: 0.2863 - val_f1: 0.0665\n",
      "Epoch 986/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2861 - f1: 0.7300 - val_loss: 0.2830 - val_f1: 0.0663\n",
      "Epoch 987/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2880 - f1: 0.7283 - val_loss: 0.2812 - val_f1: 0.0660\n",
      "Epoch 988/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2870 - f1: 0.7301 - val_loss: 0.2862 - val_f1: 0.0662\n",
      "Epoch 989/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2879 - f1: 0.7270 - val_loss: 0.2833 - val_f1: 0.0659\n",
      "Epoch 990/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2862 - f1: 0.7302 - val_loss: 0.2851 - val_f1: 0.0665\n",
      "Epoch 991/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2864 - f1: 0.7305 - val_loss: 0.2835 - val_f1: 0.0661\n",
      "Epoch 992/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2872 - f1: 0.7304 - val_loss: 0.2863 - val_f1: 0.0666\n",
      "Epoch 993/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2868 - f1: 0.7306 - val_loss: 0.2843 - val_f1: 0.0662\n",
      "Epoch 994/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2867 - f1: 0.7307 - val_loss: 0.2828 - val_f1: 0.0660\n",
      "Epoch 995/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2874 - f1: 0.7288 - val_loss: 0.2888 - val_f1: 0.0672\n",
      "Epoch 996/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2883 - f1: 0.7282 - val_loss: 0.2917 - val_f1: 0.0675\n",
      "Epoch 997/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2879 - f1: 0.7269 - val_loss: 0.2868 - val_f1: 0.0667\n",
      "Epoch 998/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2881 - f1: 0.7283 - val_loss: 0.2829 - val_f1: 0.0662\n",
      "Epoch 999/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2881 - f1: 0.7286 - val_loss: 0.2844 - val_f1: 0.0667\n",
      "Epoch 1000/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2877 - f1: 0.7286 - val_loss: 0.2842 - val_f1: 0.0662\n",
      "Epoch 1001/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2870 - f1: 0.7312 - val_loss: 0.2871 - val_f1: 0.0668\n",
      "Epoch 1002/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2872 - f1: 0.7273 - val_loss: 0.2879 - val_f1: 0.0668\n",
      "Epoch 1003/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2870 - f1: 0.7280 - val_loss: 0.2827 - val_f1: 0.0661\n",
      "Epoch 1004/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2857 - f1: 0.7329 - val_loss: 0.2835 - val_f1: 0.0663\n",
      "Epoch 1005/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2874 - f1: 0.7301 - val_loss: 0.2858 - val_f1: 0.0668\n",
      "Epoch 1006/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2875 - f1: 0.7282 - val_loss: 0.2825 - val_f1: 0.0657\n",
      "Epoch 1007/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2874 - f1: 0.7302 - val_loss: 0.2832 - val_f1: 0.0667\n",
      "Epoch 1008/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2865 - f1: 0.7293 - val_loss: 0.2830 - val_f1: 0.0660\n",
      "Epoch 1009/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2876 - f1: 0.7285 - val_loss: 0.2855 - val_f1: 0.0669\n",
      "Epoch 1010/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2876 - f1: 0.7274 - val_loss: 0.2867 - val_f1: 0.0664\n",
      "Epoch 1011/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2866 - f1: 0.7288 - val_loss: 0.2852 - val_f1: 0.0665\n",
      "Epoch 1012/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2870 - f1: 0.7291 - val_loss: 0.2848 - val_f1: 0.0660\n",
      "Epoch 1013/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2870 - f1: 0.7294 - val_loss: 0.2841 - val_f1: 0.0664\n",
      "Epoch 1014/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2876 - f1: 0.7299 - val_loss: 0.2841 - val_f1: 0.0666\n",
      "Epoch 1015/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2859 - f1: 0.7298 - val_loss: 0.2885 - val_f1: 0.0669\n",
      "Epoch 1016/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2877 - f1: 0.7288 - val_loss: 0.2908 - val_f1: 0.0674\n",
      "Epoch 1017/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2874 - f1: 0.7301 - val_loss: 0.2840 - val_f1: 0.0661\n",
      "Epoch 1018/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2861 - f1: 0.7297 - val_loss: 0.2880 - val_f1: 0.0667\n",
      "Epoch 1019/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2862 - f1: 0.7314 - val_loss: 0.2860 - val_f1: 0.0665\n",
      "Epoch 1020/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2861 - f1: 0.7292 - val_loss: 0.2855 - val_f1: 0.0661\n",
      "Epoch 1021/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2860 - f1: 0.7302 - val_loss: 0.2832 - val_f1: 0.0658\n",
      "Epoch 1022/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2873 - f1: 0.7292 - val_loss: 0.2861 - val_f1: 0.0666\n",
      "Epoch 1023/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2875 - f1: 0.7274 - val_loss: 0.2837 - val_f1: 0.0661\n",
      "Epoch 1024/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2876 - f1: 0.7305 - val_loss: 0.2832 - val_f1: 0.0659\n",
      "Epoch 1025/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2866 - f1: 0.7276 - val_loss: 0.2855 - val_f1: 0.0667\n",
      "Epoch 1026/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2865 - f1: 0.7305 - val_loss: 0.2862 - val_f1: 0.0665\n",
      "Epoch 1027/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2881 - f1: 0.7292 - val_loss: 0.2845 - val_f1: 0.0663\n",
      "Epoch 1028/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2865 - f1: 0.7296 - val_loss: 0.2834 - val_f1: 0.0662\n",
      "Epoch 1029/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2864 - f1: 0.7309 - val_loss: 0.2877 - val_f1: 0.0668\n",
      "Epoch 1030/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2868 - f1: 0.7303 - val_loss: 0.2844 - val_f1: 0.0662\n",
      "Epoch 1031/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2870 - f1: 0.7299 - val_loss: 0.2827 - val_f1: 0.0662\n",
      "Epoch 1032/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2857 - f1: 0.7300 - val_loss: 0.2850 - val_f1: 0.0661\n",
      "Epoch 1033/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2866 - f1: 0.7333 - val_loss: 0.2843 - val_f1: 0.0662\n",
      "Epoch 1034/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2882 - f1: 0.7285 - val_loss: 0.2856 - val_f1: 0.0663\n",
      "Epoch 1035/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2883 - f1: 0.7285 - val_loss: 0.2811 - val_f1: 0.0655\n",
      "Epoch 1036/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2849 - f1: 0.7311 - val_loss: 0.2858 - val_f1: 0.0665\n",
      "Epoch 1037/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2861 - f1: 0.7335 - val_loss: 0.2919 - val_f1: 0.0671\n",
      "Epoch 1038/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2863 - f1: 0.7294 - val_loss: 0.2836 - val_f1: 0.0657\n",
      "Epoch 1039/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2873 - f1: 0.7285 - val_loss: 0.2809 - val_f1: 0.0656\n",
      "Epoch 1040/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2866 - f1: 0.7298 - val_loss: 0.2844 - val_f1: 0.0664\n",
      "Epoch 1041/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2871 - f1: 0.7294 - val_loss: 0.2816 - val_f1: 0.0660\n",
      "Epoch 1042/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2872 - f1: 0.7275 - val_loss: 0.2886 - val_f1: 0.0671\n",
      "Epoch 1043/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2859 - f1: 0.7318 - val_loss: 0.2807 - val_f1: 0.0659\n",
      "Epoch 1044/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2868 - f1: 0.7289 - val_loss: 0.2860 - val_f1: 0.0669\n",
      "Epoch 1045/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2873 - f1: 0.7315 - val_loss: 0.2826 - val_f1: 0.0660\n",
      "Epoch 1046/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2870 - f1: 0.7278 - val_loss: 0.2851 - val_f1: 0.0665\n",
      "Epoch 1047/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2862 - f1: 0.7312 - val_loss: 0.2877 - val_f1: 0.0666\n",
      "Epoch 1048/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2863 - f1: 0.7287 - val_loss: 0.2874 - val_f1: 0.0665\n",
      "Epoch 1049/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2864 - f1: 0.7330 - val_loss: 0.2887 - val_f1: 0.0668\n",
      "Epoch 1050/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2868 - f1: 0.7290 - val_loss: 0.2853 - val_f1: 0.0661\n",
      "Epoch 1051/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2855 - f1: 0.7333 - val_loss: 0.2859 - val_f1: 0.0665\n",
      "Epoch 1052/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2858 - f1: 0.7311 - val_loss: 0.2828 - val_f1: 0.0657\n",
      "Epoch 1053/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2863 - f1: 0.7290 - val_loss: 0.2856 - val_f1: 0.0665\n",
      "Epoch 1054/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2868 - f1: 0.7298 - val_loss: 0.2849 - val_f1: 0.0662\n",
      "Epoch 1055/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2858 - f1: 0.7301 - val_loss: 0.2839 - val_f1: 0.0661\n",
      "Epoch 1056/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2872 - f1: 0.7302 - val_loss: 0.2893 - val_f1: 0.0665\n",
      "Epoch 1057/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2865 - f1: 0.7304 - val_loss: 0.2846 - val_f1: 0.0661\n",
      "Epoch 1058/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2859 - f1: 0.7318 - val_loss: 0.2874 - val_f1: 0.0664\n",
      "Epoch 1059/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2858 - f1: 0.7304 - val_loss: 0.2831 - val_f1: 0.0661\n",
      "Epoch 1060/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2863 - f1: 0.7313 - val_loss: 0.2849 - val_f1: 0.0664\n",
      "Epoch 1061/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2854 - f1: 0.7314 - val_loss: 0.2831 - val_f1: 0.0661\n",
      "Epoch 1062/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2858 - f1: 0.7317 - val_loss: 0.2864 - val_f1: 0.0666\n",
      "Epoch 1063/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2857 - f1: 0.7307 - val_loss: 0.2863 - val_f1: 0.0666\n",
      "Epoch 1064/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2857 - f1: 0.7299 - val_loss: 0.2868 - val_f1: 0.0669\n",
      "Epoch 1065/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2842 - f1: 0.7328 - val_loss: 0.2871 - val_f1: 0.0664\n",
      "Epoch 1066/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2867 - f1: 0.7290 - val_loss: 0.2891 - val_f1: 0.0669\n",
      "Epoch 1067/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2863 - f1: 0.7289 - val_loss: 0.2890 - val_f1: 0.0671\n",
      "Epoch 1068/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2870 - f1: 0.7292 - val_loss: 0.2854 - val_f1: 0.0663\n",
      "Epoch 1069/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2873 - f1: 0.7294 - val_loss: 0.2846 - val_f1: 0.0664\n",
      "Epoch 1070/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2867 - f1: 0.7318 - val_loss: 0.2838 - val_f1: 0.0664\n",
      "Epoch 1071/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2847 - f1: 0.7313 - val_loss: 0.2867 - val_f1: 0.0667\n",
      "Epoch 1072/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2871 - f1: 0.7284 - val_loss: 0.2872 - val_f1: 0.0667\n",
      "Epoch 1073/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2860 - f1: 0.7316 - val_loss: 0.2879 - val_f1: 0.0667\n",
      "Epoch 1074/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2869 - f1: 0.7315 - val_loss: 0.2863 - val_f1: 0.0665\n",
      "Epoch 1075/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2859 - f1: 0.7303 - val_loss: 0.2855 - val_f1: 0.0665\n",
      "Epoch 1076/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2862 - f1: 0.7294 - val_loss: 0.2879 - val_f1: 0.0666\n",
      "Epoch 1077/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2875 - f1: 0.7286 - val_loss: 0.2839 - val_f1: 0.0663\n",
      "Epoch 1078/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2853 - f1: 0.7323 - val_loss: 0.2846 - val_f1: 0.0663\n",
      "Epoch 1079/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2858 - f1: 0.7305 - val_loss: 0.2851 - val_f1: 0.0662\n",
      "Epoch 1080/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2859 - f1: 0.7292 - val_loss: 0.2864 - val_f1: 0.0664\n",
      "Epoch 1081/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2859 - f1: 0.7318 - val_loss: 0.2899 - val_f1: 0.0672\n",
      "Epoch 1082/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2864 - f1: 0.7300 - val_loss: 0.2866 - val_f1: 0.0664\n",
      "Epoch 1083/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2863 - f1: 0.7306 - val_loss: 0.2832 - val_f1: 0.0659\n",
      "Epoch 1084/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2860 - f1: 0.7292 - val_loss: 0.2862 - val_f1: 0.0664\n",
      "Epoch 1085/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2848 - f1: 0.7303 - val_loss: 0.2863 - val_f1: 0.0664\n",
      "Epoch 1086/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2848 - f1: 0.7312 - val_loss: 0.2835 - val_f1: 0.0661\n",
      "Epoch 1087/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2852 - f1: 0.7327 - val_loss: 0.2868 - val_f1: 0.0665\n",
      "Epoch 1088/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2867 - f1: 0.7290 - val_loss: 0.2869 - val_f1: 0.0665\n",
      "Epoch 1089/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2854 - f1: 0.7310 - val_loss: 0.2885 - val_f1: 0.0670\n",
      "Epoch 1090/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2866 - f1: 0.7297 - val_loss: 0.2841 - val_f1: 0.0660\n",
      "Epoch 1091/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2845 - f1: 0.7338 - val_loss: 0.2886 - val_f1: 0.0669\n",
      "Epoch 1092/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2861 - f1: 0.7305 - val_loss: 0.2859 - val_f1: 0.0665\n",
      "Epoch 1093/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2857 - f1: 0.7307 - val_loss: 0.2866 - val_f1: 0.0666\n",
      "Epoch 1094/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2862 - f1: 0.7317 - val_loss: 0.2854 - val_f1: 0.0665\n",
      "Epoch 1095/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2858 - f1: 0.7328 - val_loss: 0.2891 - val_f1: 0.0668\n",
      "Epoch 1096/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2848 - f1: 0.7325 - val_loss: 0.2859 - val_f1: 0.0667\n",
      "Epoch 1097/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2853 - f1: 0.7284 - val_loss: 0.2875 - val_f1: 0.0669\n",
      "Epoch 1098/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2856 - f1: 0.7325 - val_loss: 0.2831 - val_f1: 0.0662\n",
      "Epoch 1099/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2857 - f1: 0.7328 - val_loss: 0.2887 - val_f1: 0.0669\n",
      "Epoch 1100/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2852 - f1: 0.7299 - val_loss: 0.2867 - val_f1: 0.0664\n",
      "Epoch 1101/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2835 - f1: 0.7316 - val_loss: 0.2851 - val_f1: 0.0663\n",
      "Epoch 1102/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2860 - f1: 0.7312 - val_loss: 0.2890 - val_f1: 0.0666\n",
      "Epoch 1103/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2868 - f1: 0.7296 - val_loss: 0.2819 - val_f1: 0.0658\n",
      "Epoch 1104/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2863 - f1: 0.7327 - val_loss: 0.2867 - val_f1: 0.0665\n",
      "Epoch 1105/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2861 - f1: 0.7288 - val_loss: 0.2855 - val_f1: 0.0662\n",
      "Epoch 1106/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2860 - f1: 0.7312 - val_loss: 0.2904 - val_f1: 0.0667\n",
      "Epoch 1107/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2851 - f1: 0.7312 - val_loss: 0.2890 - val_f1: 0.0665\n",
      "Epoch 1108/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2845 - f1: 0.7344 - val_loss: 0.2899 - val_f1: 0.0670\n",
      "Epoch 1109/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2850 - f1: 0.7340 - val_loss: 0.2887 - val_f1: 0.0665\n",
      "Epoch 1110/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2854 - f1: 0.7307 - val_loss: 0.2836 - val_f1: 0.0659\n",
      "Epoch 1111/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2845 - f1: 0.7326 - val_loss: 0.2863 - val_f1: 0.0666\n",
      "Epoch 1112/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2846 - f1: 0.7314 - val_loss: 0.2841 - val_f1: 0.0663\n",
      "Epoch 1113/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2852 - f1: 0.7321 - val_loss: 0.2898 - val_f1: 0.0665\n",
      "Epoch 1114/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2858 - f1: 0.7341 - val_loss: 0.2852 - val_f1: 0.0662\n",
      "Epoch 1115/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2847 - f1: 0.7321 - val_loss: 0.2855 - val_f1: 0.0664\n",
      "Epoch 1116/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2848 - f1: 0.7325 - val_loss: 0.2856 - val_f1: 0.0662\n",
      "Epoch 1117/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2863 - f1: 0.7314 - val_loss: 0.2838 - val_f1: 0.0657\n",
      "Epoch 1118/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2853 - f1: 0.7317 - val_loss: 0.2874 - val_f1: 0.0666\n",
      "Epoch 1119/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2844 - f1: 0.7337 - val_loss: 0.2873 - val_f1: 0.0664\n",
      "Epoch 1120/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2853 - f1: 0.7317 - val_loss: 0.2815 - val_f1: 0.0657\n",
      "Epoch 1121/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2845 - f1: 0.7335 - val_loss: 0.2857 - val_f1: 0.0665\n",
      "Epoch 1122/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2848 - f1: 0.7321 - val_loss: 0.2902 - val_f1: 0.0670\n",
      "Epoch 1123/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2860 - f1: 0.7293 - val_loss: 0.2850 - val_f1: 0.0663\n",
      "Epoch 1124/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2857 - f1: 0.7315 - val_loss: 0.2877 - val_f1: 0.0669\n",
      "Epoch 1125/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2867 - f1: 0.7294 - val_loss: 0.2816 - val_f1: 0.0658\n",
      "Epoch 1126/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2854 - f1: 0.7303 - val_loss: 0.2855 - val_f1: 0.0665\n",
      "Epoch 1127/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2862 - f1: 0.7318 - val_loss: 0.2842 - val_f1: 0.0662\n",
      "Epoch 1128/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2840 - f1: 0.7339 - val_loss: 0.2874 - val_f1: 0.0665\n",
      "Epoch 1129/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2865 - f1: 0.7306 - val_loss: 0.2862 - val_f1: 0.0666\n",
      "Epoch 1130/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2853 - f1: 0.7305 - val_loss: 0.2883 - val_f1: 0.0671\n",
      "Epoch 1131/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2861 - f1: 0.7320 - val_loss: 0.2858 - val_f1: 0.0669\n",
      "Epoch 1132/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2856 - f1: 0.7323 - val_loss: 0.2848 - val_f1: 0.0662\n",
      "Epoch 1133/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2860 - f1: 0.7292 - val_loss: 0.2863 - val_f1: 0.0669\n",
      "Epoch 1134/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2850 - f1: 0.7335 - val_loss: 0.2873 - val_f1: 0.0668\n",
      "Epoch 1135/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2851 - f1: 0.7324 - val_loss: 0.2858 - val_f1: 0.0662\n",
      "Epoch 1136/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2850 - f1: 0.7322 - val_loss: 0.2892 - val_f1: 0.0669\n",
      "Epoch 1137/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2854 - f1: 0.7302 - val_loss: 0.2825 - val_f1: 0.0661\n",
      "Epoch 1138/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2847 - f1: 0.7331 - val_loss: 0.2868 - val_f1: 0.0663\n",
      "Epoch 1139/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2862 - f1: 0.7326 - val_loss: 0.2840 - val_f1: 0.0664\n",
      "Epoch 1140/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2855 - f1: 0.7325 - val_loss: 0.2826 - val_f1: 0.0659\n",
      "Epoch 1141/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2851 - f1: 0.7320 - val_loss: 0.2837 - val_f1: 0.0659\n",
      "Epoch 1142/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2850 - f1: 0.7310 - val_loss: 0.2853 - val_f1: 0.0665\n",
      "Epoch 1143/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2850 - f1: 0.7331 - val_loss: 0.2870 - val_f1: 0.0667\n",
      "Epoch 1144/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2840 - f1: 0.7319 - val_loss: 0.2847 - val_f1: 0.0663\n",
      "Epoch 1145/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2848 - f1: 0.7325 - val_loss: 0.2866 - val_f1: 0.0665\n",
      "Epoch 1146/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2855 - f1: 0.7330 - val_loss: 0.2857 - val_f1: 0.0663\n",
      "Epoch 1147/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2838 - f1: 0.7331 - val_loss: 0.2854 - val_f1: 0.0666\n",
      "Epoch 1148/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2859 - f1: 0.7303 - val_loss: 0.2832 - val_f1: 0.0661\n",
      "Epoch 1149/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2858 - f1: 0.7309 - val_loss: 0.2865 - val_f1: 0.0659\n",
      "Epoch 1150/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2854 - f1: 0.7302 - val_loss: 0.2853 - val_f1: 0.0664\n",
      "Epoch 1151/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2843 - f1: 0.7315 - val_loss: 0.2863 - val_f1: 0.0666\n",
      "Epoch 1152/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2846 - f1: 0.7315 - val_loss: 0.2857 - val_f1: 0.0662\n",
      "Epoch 1153/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2861 - f1: 0.7311 - val_loss: 0.2847 - val_f1: 0.0661\n",
      "Epoch 1154/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2864 - f1: 0.7284 - val_loss: 0.2849 - val_f1: 0.0666\n",
      "Epoch 1155/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2840 - f1: 0.7332 - val_loss: 0.2853 - val_f1: 0.0661\n",
      "Epoch 1156/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2859 - f1: 0.7313 - val_loss: 0.2860 - val_f1: 0.0664\n",
      "Epoch 1157/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2863 - f1: 0.7301 - val_loss: 0.2857 - val_f1: 0.0663\n",
      "Epoch 1158/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2838 - f1: 0.7343 - val_loss: 0.2847 - val_f1: 0.0662\n",
      "Epoch 1159/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2854 - f1: 0.7310 - val_loss: 0.2888 - val_f1: 0.0668\n",
      "Epoch 1160/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2847 - f1: 0.7306 - val_loss: 0.2850 - val_f1: 0.0663\n",
      "Epoch 1161/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2843 - f1: 0.7305 - val_loss: 0.2869 - val_f1: 0.0660\n",
      "Epoch 1162/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2855 - f1: 0.7318 - val_loss: 0.2858 - val_f1: 0.0663\n",
      "Epoch 1163/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2852 - f1: 0.7299 - val_loss: 0.2853 - val_f1: 0.0664\n",
      "Epoch 1164/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2848 - f1: 0.7316 - val_loss: 0.2877 - val_f1: 0.0669\n",
      "Epoch 1165/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2865 - f1: 0.7307 - val_loss: 0.2849 - val_f1: 0.0662\n",
      "Epoch 1166/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2841 - f1: 0.7307 - val_loss: 0.2881 - val_f1: 0.0666\n",
      "Epoch 1167/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2862 - f1: 0.7300 - val_loss: 0.2844 - val_f1: 0.0661\n",
      "Epoch 1168/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2843 - f1: 0.7341 - val_loss: 0.2835 - val_f1: 0.0661\n",
      "Epoch 1169/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2848 - f1: 0.7329 - val_loss: 0.2869 - val_f1: 0.0664\n",
      "Epoch 1170/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2841 - f1: 0.7346 - val_loss: 0.2879 - val_f1: 0.0669\n",
      "Epoch 1171/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2844 - f1: 0.7323 - val_loss: 0.2881 - val_f1: 0.0667\n",
      "Epoch 1172/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2837 - f1: 0.7336 - val_loss: 0.2859 - val_f1: 0.0667\n",
      "Epoch 1173/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2852 - f1: 0.7338 - val_loss: 0.2844 - val_f1: 0.0663\n",
      "Epoch 1174/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2855 - f1: 0.7319 - val_loss: 0.2878 - val_f1: 0.0670\n",
      "Epoch 1175/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2842 - f1: 0.7344 - val_loss: 0.2846 - val_f1: 0.0659\n",
      "Epoch 1176/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2848 - f1: 0.7316 - val_loss: 0.2904 - val_f1: 0.0670\n",
      "Epoch 1177/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2849 - f1: 0.7332 - val_loss: 0.2920 - val_f1: 0.0669\n",
      "Epoch 1178/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2842 - f1: 0.7340 - val_loss: 0.2841 - val_f1: 0.0660\n",
      "Epoch 1179/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2857 - f1: 0.7316 - val_loss: 0.2831 - val_f1: 0.0659\n",
      "Epoch 1180/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2843 - f1: 0.7328 - val_loss: 0.2872 - val_f1: 0.0665\n",
      "Epoch 1181/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2846 - f1: 0.7329 - val_loss: 0.2847 - val_f1: 0.0666\n",
      "Epoch 1182/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2853 - f1: 0.7315 - val_loss: 0.2863 - val_f1: 0.0666\n",
      "Epoch 1183/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2856 - f1: 0.7312 - val_loss: 0.2836 - val_f1: 0.0665\n",
      "Epoch 1184/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2844 - f1: 0.7331 - val_loss: 0.2834 - val_f1: 0.0663\n",
      "Epoch 1185/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2858 - f1: 0.7322 - val_loss: 0.2850 - val_f1: 0.0665\n",
      "Epoch 1186/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2850 - f1: 0.7320 - val_loss: 0.2827 - val_f1: 0.0657\n",
      "Epoch 1187/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2849 - f1: 0.7312 - val_loss: 0.2828 - val_f1: 0.0664\n",
      "Epoch 1188/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2845 - f1: 0.7343 - val_loss: 0.2843 - val_f1: 0.0666\n",
      "Epoch 1189/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2830 - f1: 0.7337 - val_loss: 0.2914 - val_f1: 0.0673\n",
      "Epoch 1190/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2848 - f1: 0.7335 - val_loss: 0.2865 - val_f1: 0.0669\n",
      "Epoch 1191/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2850 - f1: 0.7333 - val_loss: 0.2843 - val_f1: 0.0664\n",
      "Epoch 1192/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2839 - f1: 0.7330 - val_loss: 0.2860 - val_f1: 0.0665\n",
      "Epoch 1193/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2843 - f1: 0.7330 - val_loss: 0.2911 - val_f1: 0.0672\n",
      "Epoch 1194/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2851 - f1: 0.7318 - val_loss: 0.2864 - val_f1: 0.0663\n",
      "Epoch 1195/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2840 - f1: 0.7325 - val_loss: 0.2881 - val_f1: 0.0672\n",
      "Epoch 1196/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2846 - f1: 0.7309 - val_loss: 0.2874 - val_f1: 0.0667\n",
      "Epoch 1197/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2857 - f1: 0.7303 - val_loss: 0.2832 - val_f1: 0.0662\n",
      "Epoch 1198/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2852 - f1: 0.7317 - val_loss: 0.2861 - val_f1: 0.0667\n",
      "Epoch 1199/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2848 - f1: 0.7302 - val_loss: 0.2810 - val_f1: 0.0657\n",
      "Epoch 1200/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2836 - f1: 0.7337 - val_loss: 0.2820 - val_f1: 0.0658\n",
      "Epoch 1201/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2847 - f1: 0.7338 - val_loss: 0.2841 - val_f1: 0.0663\n",
      "Epoch 1202/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2840 - f1: 0.7324 - val_loss: 0.2863 - val_f1: 0.0665\n",
      "Epoch 1203/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2835 - f1: 0.7350 - val_loss: 0.2880 - val_f1: 0.0668\n",
      "Epoch 1204/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2833 - f1: 0.7357 - val_loss: 0.2869 - val_f1: 0.0664\n",
      "Epoch 1205/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2855 - f1: 0.7328 - val_loss: 0.2873 - val_f1: 0.0662\n",
      "Epoch 1206/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2851 - f1: 0.7312 - val_loss: 0.2879 - val_f1: 0.0668\n",
      "Epoch 1207/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2839 - f1: 0.7309 - val_loss: 0.2886 - val_f1: 0.0664\n",
      "Epoch 1208/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2846 - f1: 0.7338 - val_loss: 0.2850 - val_f1: 0.0663\n",
      "Epoch 1209/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2844 - f1: 0.7335 - val_loss: 0.2871 - val_f1: 0.0666\n",
      "Epoch 1210/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2838 - f1: 0.7336 - val_loss: 0.2898 - val_f1: 0.0672\n",
      "Epoch 1211/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2846 - f1: 0.7316 - val_loss: 0.2882 - val_f1: 0.0667\n",
      "Epoch 1212/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2848 - f1: 0.7338 - val_loss: 0.2851 - val_f1: 0.0664\n",
      "Epoch 1213/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2845 - f1: 0.7327 - val_loss: 0.2895 - val_f1: 0.0668\n",
      "Epoch 1214/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2840 - f1: 0.7329 - val_loss: 0.2891 - val_f1: 0.0666\n",
      "Epoch 1215/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2853 - f1: 0.7305 - val_loss: 0.2854 - val_f1: 0.0666\n",
      "Epoch 1216/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2833 - f1: 0.7349 - val_loss: 0.2872 - val_f1: 0.0666\n",
      "Epoch 1217/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2842 - f1: 0.7316 - val_loss: 0.2855 - val_f1: 0.0664\n",
      "Epoch 1218/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2826 - f1: 0.7350 - val_loss: 0.2880 - val_f1: 0.0669\n",
      "Epoch 1219/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2829 - f1: 0.7356 - val_loss: 0.2842 - val_f1: 0.0663\n",
      "Epoch 1220/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2836 - f1: 0.7331 - val_loss: 0.2865 - val_f1: 0.0667\n",
      "Epoch 1221/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2839 - f1: 0.7334 - val_loss: 0.2847 - val_f1: 0.0657\n",
      "Epoch 1222/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2836 - f1: 0.7325 - val_loss: 0.2844 - val_f1: 0.0661\n",
      "Epoch 1223/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2840 - f1: 0.7327 - val_loss: 0.2878 - val_f1: 0.0670\n",
      "Epoch 1224/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2847 - f1: 0.7323 - val_loss: 0.2871 - val_f1: 0.0665\n",
      "Epoch 1225/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2818 - f1: 0.7353 - val_loss: 0.2868 - val_f1: 0.0664\n",
      "Epoch 1226/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2840 - f1: 0.7325 - val_loss: 0.2875 - val_f1: 0.0663\n",
      "Epoch 1227/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2837 - f1: 0.7328 - val_loss: 0.2906 - val_f1: 0.0674\n",
      "Epoch 1228/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2857 - f1: 0.7325 - val_loss: 0.2832 - val_f1: 0.0660\n",
      "Epoch 1229/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2842 - f1: 0.7327 - val_loss: 0.2847 - val_f1: 0.0661\n",
      "Epoch 1230/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2846 - f1: 0.7330 - val_loss: 0.2850 - val_f1: 0.0663\n",
      "Epoch 1231/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2840 - f1: 0.7365 - val_loss: 0.2834 - val_f1: 0.0662\n",
      "Epoch 1232/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2829 - f1: 0.7347 - val_loss: 0.2875 - val_f1: 0.0664\n",
      "Epoch 1233/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2847 - f1: 0.7349 - val_loss: 0.2832 - val_f1: 0.0660\n",
      "Epoch 1234/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2836 - f1: 0.7330 - val_loss: 0.2865 - val_f1: 0.0664\n",
      "Epoch 1235/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2836 - f1: 0.7350 - val_loss: 0.2890 - val_f1: 0.0667\n",
      "Epoch 1236/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2852 - f1: 0.7303 - val_loss: 0.2856 - val_f1: 0.0667\n",
      "Epoch 1237/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2836 - f1: 0.7349 - val_loss: 0.2820 - val_f1: 0.0660\n",
      "Epoch 1238/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2837 - f1: 0.7328 - val_loss: 0.2841 - val_f1: 0.0664\n",
      "Epoch 1239/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2844 - f1: 0.7331 - val_loss: 0.2822 - val_f1: 0.0657\n",
      "Epoch 1240/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2829 - f1: 0.7349 - val_loss: 0.2901 - val_f1: 0.0672\n",
      "Epoch 1241/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2845 - f1: 0.7328 - val_loss: 0.2857 - val_f1: 0.0664\n",
      "Epoch 1242/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2840 - f1: 0.7333 - val_loss: 0.2899 - val_f1: 0.0672\n",
      "Epoch 1243/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2833 - f1: 0.7354 - val_loss: 0.2869 - val_f1: 0.0668\n",
      "Epoch 1244/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2833 - f1: 0.7364 - val_loss: 0.2829 - val_f1: 0.0658\n",
      "Epoch 1245/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2834 - f1: 0.7316 - val_loss: 0.2873 - val_f1: 0.0665\n",
      "Epoch 1246/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2825 - f1: 0.7372 - val_loss: 0.2888 - val_f1: 0.0666\n",
      "Epoch 1247/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2835 - f1: 0.7340 - val_loss: 0.2864 - val_f1: 0.0663\n",
      "Epoch 1248/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2841 - f1: 0.7328 - val_loss: 0.2885 - val_f1: 0.0670\n",
      "Epoch 1249/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2838 - f1: 0.7340 - val_loss: 0.2859 - val_f1: 0.0663\n",
      "Epoch 1250/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2835 - f1: 0.7337 - val_loss: 0.2887 - val_f1: 0.0669\n",
      "Epoch 1251/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2842 - f1: 0.7329 - val_loss: 0.2814 - val_f1: 0.0654\n",
      "Epoch 1252/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2846 - f1: 0.7313 - val_loss: 0.2845 - val_f1: 0.0659\n",
      "Epoch 1253/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2839 - f1: 0.7338 - val_loss: 0.2846 - val_f1: 0.0660\n",
      "Epoch 1254/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2847 - f1: 0.7330 - val_loss: 0.2888 - val_f1: 0.0670\n",
      "Epoch 1255/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2838 - f1: 0.7345 - val_loss: 0.2886 - val_f1: 0.0669\n",
      "Epoch 1256/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2830 - f1: 0.7357 - val_loss: 0.2841 - val_f1: 0.0655\n",
      "Epoch 1257/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2840 - f1: 0.7334 - val_loss: 0.2875 - val_f1: 0.0668\n",
      "Epoch 1258/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2849 - f1: 0.7321 - val_loss: 0.2811 - val_f1: 0.0659\n",
      "Epoch 1259/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2827 - f1: 0.7360 - val_loss: 0.2865 - val_f1: 0.0662\n",
      "Epoch 1260/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2843 - f1: 0.7329 - val_loss: 0.2867 - val_f1: 0.0666\n",
      "Epoch 1261/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2832 - f1: 0.7354 - val_loss: 0.2877 - val_f1: 0.0669\n",
      "Epoch 1262/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2840 - f1: 0.7328 - val_loss: 0.2885 - val_f1: 0.0665\n",
      "Epoch 1263/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2841 - f1: 0.7327 - val_loss: 0.2852 - val_f1: 0.0663\n",
      "Epoch 1264/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2833 - f1: 0.7365 - val_loss: 0.2846 - val_f1: 0.0660\n",
      "Epoch 1265/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2840 - f1: 0.7339 - val_loss: 0.2876 - val_f1: 0.0668\n",
      "Epoch 1266/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2841 - f1: 0.7326 - val_loss: 0.2854 - val_f1: 0.0664\n",
      "Epoch 1267/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2847 - f1: 0.7331 - val_loss: 0.2855 - val_f1: 0.0660\n",
      "Epoch 1268/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2834 - f1: 0.7340 - val_loss: 0.2896 - val_f1: 0.0669\n",
      "Epoch 1269/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2817 - f1: 0.7367 - val_loss: 0.2845 - val_f1: 0.0661\n",
      "Epoch 1270/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2836 - f1: 0.7327 - val_loss: 0.2842 - val_f1: 0.0661\n",
      "Epoch 1271/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2836 - f1: 0.7347 - val_loss: 0.2861 - val_f1: 0.0665\n",
      "Epoch 1272/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2826 - f1: 0.7334 - val_loss: 0.2842 - val_f1: 0.0665\n",
      "Epoch 1273/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2822 - f1: 0.7369 - val_loss: 0.2866 - val_f1: 0.0663\n",
      "Epoch 1274/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2838 - f1: 0.7342 - val_loss: 0.2866 - val_f1: 0.0660\n",
      "Epoch 1275/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2832 - f1: 0.7349 - val_loss: 0.2860 - val_f1: 0.0662\n",
      "Epoch 1276/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2836 - f1: 0.7322 - val_loss: 0.2850 - val_f1: 0.0659\n",
      "Epoch 1277/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2824 - f1: 0.7370 - val_loss: 0.2897 - val_f1: 0.0669\n",
      "Epoch 1278/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2846 - f1: 0.7335 - val_loss: 0.2849 - val_f1: 0.0664\n",
      "Epoch 1279/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2834 - f1: 0.7356 - val_loss: 0.2873 - val_f1: 0.0668\n",
      "Epoch 1280/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2827 - f1: 0.7347 - val_loss: 0.2848 - val_f1: 0.0661\n",
      "Epoch 1281/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2828 - f1: 0.7358 - val_loss: 0.2869 - val_f1: 0.0662\n",
      "Epoch 1282/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2830 - f1: 0.7337 - val_loss: 0.2836 - val_f1: 0.0659\n",
      "Epoch 1283/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2827 - f1: 0.7351 - val_loss: 0.2850 - val_f1: 0.0660\n",
      "Epoch 1284/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2835 - f1: 0.7322 - val_loss: 0.2869 - val_f1: 0.0663\n",
      "Epoch 1285/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2843 - f1: 0.7323 - val_loss: 0.2845 - val_f1: 0.0660\n",
      "Epoch 1286/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2827 - f1: 0.7357 - val_loss: 0.2843 - val_f1: 0.0661\n",
      "Epoch 1287/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2837 - f1: 0.7336 - val_loss: 0.2899 - val_f1: 0.0671\n",
      "Epoch 1288/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2822 - f1: 0.7346 - val_loss: 0.2898 - val_f1: 0.0669\n",
      "Epoch 1289/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2827 - f1: 0.7349 - val_loss: 0.2882 - val_f1: 0.0662\n",
      "Epoch 1290/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2830 - f1: 0.7340 - val_loss: 0.2853 - val_f1: 0.0661\n",
      "Epoch 1291/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2832 - f1: 0.7334 - val_loss: 0.2832 - val_f1: 0.0656\n",
      "Epoch 1292/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2830 - f1: 0.7331 - val_loss: 0.2889 - val_f1: 0.0668\n",
      "Epoch 1293/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2822 - f1: 0.7359 - val_loss: 0.2877 - val_f1: 0.0669\n",
      "Epoch 1294/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2830 - f1: 0.7368 - val_loss: 0.2827 - val_f1: 0.0659\n",
      "Epoch 1295/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2824 - f1: 0.7374 - val_loss: 0.2906 - val_f1: 0.0672\n",
      "Epoch 1296/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2826 - f1: 0.7352 - val_loss: 0.2873 - val_f1: 0.0662\n",
      "Epoch 1297/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2830 - f1: 0.7343 - val_loss: 0.2857 - val_f1: 0.0661\n",
      "Epoch 1298/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2825 - f1: 0.7358 - val_loss: 0.2856 - val_f1: 0.0657\n",
      "Epoch 1299/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2832 - f1: 0.7350 - val_loss: 0.2885 - val_f1: 0.0665\n",
      "Epoch 1300/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2832 - f1: 0.7332 - val_loss: 0.2892 - val_f1: 0.0667\n",
      "Epoch 1301/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2816 - f1: 0.7345 - val_loss: 0.2878 - val_f1: 0.0670\n",
      "Epoch 1302/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2830 - f1: 0.7322 - val_loss: 0.2843 - val_f1: 0.0664\n",
      "Epoch 1303/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2826 - f1: 0.7362 - val_loss: 0.2853 - val_f1: 0.0662\n",
      "Epoch 1304/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2834 - f1: 0.7346 - val_loss: 0.2855 - val_f1: 0.0662\n",
      "Epoch 1305/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2832 - f1: 0.7347 - val_loss: 0.2888 - val_f1: 0.0668\n",
      "Epoch 1306/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2833 - f1: 0.7354 - val_loss: 0.2869 - val_f1: 0.0665\n",
      "Epoch 1307/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2837 - f1: 0.7344 - val_loss: 0.2875 - val_f1: 0.0662\n",
      "Epoch 1308/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2815 - f1: 0.7367 - val_loss: 0.2857 - val_f1: 0.0660\n",
      "Epoch 1309/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2838 - f1: 0.7325 - val_loss: 0.2873 - val_f1: 0.0666\n",
      "Epoch 1310/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2831 - f1: 0.7364 - val_loss: 0.2890 - val_f1: 0.0666\n",
      "Epoch 1311/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2836 - f1: 0.7351 - val_loss: 0.2844 - val_f1: 0.0664\n",
      "Epoch 1312/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2819 - f1: 0.7362 - val_loss: 0.2860 - val_f1: 0.0666\n",
      "Epoch 1313/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2835 - f1: 0.7330 - val_loss: 0.2863 - val_f1: 0.0664\n",
      "Epoch 1314/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2846 - f1: 0.7350 - val_loss: 0.2885 - val_f1: 0.0669\n",
      "Epoch 1315/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2831 - f1: 0.7338 - val_loss: 0.2886 - val_f1: 0.0671\n",
      "Epoch 1316/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2833 - f1: 0.7352 - val_loss: 0.2851 - val_f1: 0.0661\n",
      "Epoch 1317/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2837 - f1: 0.7328 - val_loss: 0.2875 - val_f1: 0.0668\n",
      "Epoch 1318/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2816 - f1: 0.7360 - val_loss: 0.2875 - val_f1: 0.0666\n",
      "Epoch 1319/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2833 - f1: 0.7345 - val_loss: 0.2850 - val_f1: 0.0663\n",
      "Epoch 1320/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2826 - f1: 0.7352 - val_loss: 0.2879 - val_f1: 0.0664\n",
      "Epoch 1321/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2839 - f1: 0.7307 - val_loss: 0.2871 - val_f1: 0.0664\n",
      "Epoch 1322/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2832 - f1: 0.7347 - val_loss: 0.2901 - val_f1: 0.0670\n",
      "Epoch 1323/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2831 - f1: 0.7335 - val_loss: 0.2881 - val_f1: 0.0669\n",
      "Epoch 1324/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2824 - f1: 0.7363 - val_loss: 0.2851 - val_f1: 0.0665\n",
      "Epoch 1325/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2835 - f1: 0.7330 - val_loss: 0.2840 - val_f1: 0.0662\n",
      "Epoch 1326/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2827 - f1: 0.7354 - val_loss: 0.2869 - val_f1: 0.0665\n",
      "Epoch 1327/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2818 - f1: 0.7365 - val_loss: 0.2862 - val_f1: 0.0665\n",
      "Epoch 1328/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2821 - f1: 0.7368 - val_loss: 0.2889 - val_f1: 0.0669\n",
      "Epoch 1329/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2833 - f1: 0.7350 - val_loss: 0.2852 - val_f1: 0.0659\n",
      "Epoch 1330/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2813 - f1: 0.7400 - val_loss: 0.2853 - val_f1: 0.0660\n",
      "Epoch 1331/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2820 - f1: 0.7346 - val_loss: 0.2859 - val_f1: 0.0664\n",
      "Epoch 1332/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2830 - f1: 0.7339 - val_loss: 0.2830 - val_f1: 0.0663\n",
      "Epoch 1333/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2832 - f1: 0.7335 - val_loss: 0.2876 - val_f1: 0.0665\n",
      "Epoch 1334/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2821 - f1: 0.7346 - val_loss: 0.2913 - val_f1: 0.0673\n",
      "Epoch 1335/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2821 - f1: 0.7359 - val_loss: 0.2854 - val_f1: 0.0665\n",
      "Epoch 1336/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2813 - f1: 0.7383 - val_loss: 0.2911 - val_f1: 0.0662\n",
      "Epoch 1337/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2832 - f1: 0.7332 - val_loss: 0.2849 - val_f1: 0.0660\n",
      "Epoch 1338/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2834 - f1: 0.7345 - val_loss: 0.2863 - val_f1: 0.0663\n",
      "Epoch 1339/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2829 - f1: 0.7333 - val_loss: 0.2860 - val_f1: 0.0664\n",
      "Epoch 1340/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2833 - f1: 0.7342 - val_loss: 0.2807 - val_f1: 0.0659\n",
      "Epoch 1341/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2828 - f1: 0.7359 - val_loss: 0.2871 - val_f1: 0.0666\n",
      "Epoch 1342/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2824 - f1: 0.7357 - val_loss: 0.2819 - val_f1: 0.0662\n",
      "Epoch 1343/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2826 - f1: 0.7346 - val_loss: 0.2863 - val_f1: 0.0666\n",
      "Epoch 1344/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2831 - f1: 0.7342 - val_loss: 0.2873 - val_f1: 0.0666\n",
      "Epoch 1345/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2820 - f1: 0.7365 - val_loss: 0.2869 - val_f1: 0.0665\n",
      "Epoch 1346/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2816 - f1: 0.7378 - val_loss: 0.2873 - val_f1: 0.0669\n",
      "Epoch 1347/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2815 - f1: 0.7371 - val_loss: 0.2854 - val_f1: 0.0663\n",
      "Epoch 1348/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2837 - f1: 0.7348 - val_loss: 0.2874 - val_f1: 0.0661\n",
      "Epoch 1349/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2834 - f1: 0.7331 - val_loss: 0.2883 - val_f1: 0.0665\n",
      "Epoch 1350/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2833 - f1: 0.7337 - val_loss: 0.2843 - val_f1: 0.0658\n",
      "Epoch 1351/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2816 - f1: 0.7359 - val_loss: 0.2838 - val_f1: 0.0657\n",
      "Epoch 1352/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2833 - f1: 0.7353 - val_loss: 0.2861 - val_f1: 0.0668\n",
      "Epoch 1353/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2835 - f1: 0.7354 - val_loss: 0.2841 - val_f1: 0.0658\n",
      "Epoch 1354/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2813 - f1: 0.7368 - val_loss: 0.2829 - val_f1: 0.0661\n",
      "Epoch 1355/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2824 - f1: 0.7358 - val_loss: 0.2832 - val_f1: 0.0657\n",
      "Epoch 1356/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2834 - f1: 0.7325 - val_loss: 0.2828 - val_f1: 0.0653\n",
      "Epoch 1357/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2828 - f1: 0.7368 - val_loss: 0.2896 - val_f1: 0.0670\n",
      "Epoch 1358/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2817 - f1: 0.7358 - val_loss: 0.2905 - val_f1: 0.0671\n",
      "Epoch 1359/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2820 - f1: 0.7362 - val_loss: 0.2862 - val_f1: 0.0667\n",
      "Epoch 1360/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2830 - f1: 0.7355 - val_loss: 0.2864 - val_f1: 0.0664\n",
      "Epoch 1361/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2820 - f1: 0.7368 - val_loss: 0.2899 - val_f1: 0.0669\n",
      "Epoch 1362/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2823 - f1: 0.7338 - val_loss: 0.2861 - val_f1: 0.0665\n",
      "Epoch 1363/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2822 - f1: 0.7369 - val_loss: 0.2871 - val_f1: 0.0662\n",
      "Epoch 1364/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2805 - f1: 0.7384 - val_loss: 0.2847 - val_f1: 0.0657\n",
      "Epoch 1365/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2822 - f1: 0.7339 - val_loss: 0.2866 - val_f1: 0.0663\n",
      "Epoch 1366/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2826 - f1: 0.7347 - val_loss: 0.2862 - val_f1: 0.0663\n",
      "Epoch 1367/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2821 - f1: 0.7336 - val_loss: 0.2849 - val_f1: 0.0661\n",
      "Epoch 1368/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2827 - f1: 0.7359 - val_loss: 0.2853 - val_f1: 0.0660\n",
      "Epoch 1369/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2821 - f1: 0.7377 - val_loss: 0.2875 - val_f1: 0.0663\n",
      "Epoch 1370/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2824 - f1: 0.7352 - val_loss: 0.2881 - val_f1: 0.0665\n",
      "Epoch 1371/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2811 - f1: 0.7374 - val_loss: 0.2827 - val_f1: 0.0655\n",
      "Epoch 1372/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2831 - f1: 0.7368 - val_loss: 0.2905 - val_f1: 0.0669\n",
      "Epoch 1373/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2811 - f1: 0.7377 - val_loss: 0.2878 - val_f1: 0.0670\n",
      "Epoch 1374/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2838 - f1: 0.7335 - val_loss: 0.2885 - val_f1: 0.0670\n",
      "Epoch 1375/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2811 - f1: 0.7379 - val_loss: 0.2881 - val_f1: 0.0664\n",
      "Epoch 1376/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2830 - f1: 0.7349 - val_loss: 0.2856 - val_f1: 0.0665\n",
      "Epoch 1377/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2835 - f1: 0.7349 - val_loss: 0.2841 - val_f1: 0.0659\n",
      "Epoch 1378/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2811 - f1: 0.7385 - val_loss: 0.2933 - val_f1: 0.0671\n",
      "Epoch 1379/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2825 - f1: 0.7339 - val_loss: 0.2854 - val_f1: 0.0663\n",
      "Epoch 1380/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2817 - f1: 0.7339 - val_loss: 0.2861 - val_f1: 0.0662\n",
      "Epoch 1381/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2829 - f1: 0.7337 - val_loss: 0.2851 - val_f1: 0.0662\n",
      "Epoch 1382/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2829 - f1: 0.7323 - val_loss: 0.2869 - val_f1: 0.0665\n",
      "Epoch 1383/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2821 - f1: 0.7355 - val_loss: 0.2847 - val_f1: 0.0664\n",
      "Epoch 1384/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2822 - f1: 0.7369 - val_loss: 0.2866 - val_f1: 0.0664\n",
      "Epoch 1385/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2812 - f1: 0.7363 - val_loss: 0.2923 - val_f1: 0.0669\n",
      "Epoch 1386/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2828 - f1: 0.7355 - val_loss: 0.2880 - val_f1: 0.0666\n",
      "Epoch 1387/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2817 - f1: 0.7374 - val_loss: 0.2865 - val_f1: 0.0659\n",
      "Epoch 1388/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2822 - f1: 0.7349 - val_loss: 0.2851 - val_f1: 0.0661\n",
      "Epoch 1389/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2826 - f1: 0.7357 - val_loss: 0.2836 - val_f1: 0.0659\n",
      "Epoch 1390/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2822 - f1: 0.7359 - val_loss: 0.2845 - val_f1: 0.0662\n",
      "Epoch 1391/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2816 - f1: 0.7362 - val_loss: 0.2880 - val_f1: 0.0667\n",
      "Epoch 1392/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2824 - f1: 0.7337 - val_loss: 0.2878 - val_f1: 0.0666\n",
      "Epoch 1393/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2820 - f1: 0.7343 - val_loss: 0.2857 - val_f1: 0.0663\n",
      "Epoch 1394/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2830 - f1: 0.7347 - val_loss: 0.2913 - val_f1: 0.0670\n",
      "Epoch 1395/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2825 - f1: 0.7353 - val_loss: 0.2870 - val_f1: 0.0667\n",
      "Epoch 1396/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2832 - f1: 0.7346 - val_loss: 0.2876 - val_f1: 0.0665\n",
      "Epoch 1397/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2814 - f1: 0.7363 - val_loss: 0.2921 - val_f1: 0.0671\n",
      "Epoch 1398/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2819 - f1: 0.7355 - val_loss: 0.2881 - val_f1: 0.0663\n",
      "Epoch 1399/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2829 - f1: 0.7365 - val_loss: 0.2910 - val_f1: 0.0672\n",
      "Epoch 1400/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2815 - f1: 0.7337 - val_loss: 0.2860 - val_f1: 0.0663\n",
      "Epoch 1401/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2820 - f1: 0.7362 - val_loss: 0.2852 - val_f1: 0.0657\n",
      "Epoch 1402/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2821 - f1: 0.7377 - val_loss: 0.2859 - val_f1: 0.0664\n",
      "Epoch 1403/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2843 - f1: 0.7340 - val_loss: 0.2865 - val_f1: 0.0664\n",
      "Epoch 1404/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2838 - f1: 0.7336 - val_loss: 0.2882 - val_f1: 0.0667\n",
      "Epoch 1405/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2829 - f1: 0.7334 - val_loss: 0.2861 - val_f1: 0.0663\n",
      "Epoch 1406/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2820 - f1: 0.7373 - val_loss: 0.2878 - val_f1: 0.0666\n",
      "Epoch 1407/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2820 - f1: 0.7362 - val_loss: 0.2894 - val_f1: 0.0668\n",
      "Epoch 1408/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2809 - f1: 0.7392 - val_loss: 0.2820 - val_f1: 0.0656\n",
      "Epoch 1409/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2808 - f1: 0.7380 - val_loss: 0.2906 - val_f1: 0.0670\n",
      "Epoch 1410/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2803 - f1: 0.7375 - val_loss: 0.2841 - val_f1: 0.0658\n",
      "Epoch 1411/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2814 - f1: 0.7364 - val_loss: 0.2903 - val_f1: 0.0674\n",
      "Epoch 1412/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2825 - f1: 0.7323 - val_loss: 0.2871 - val_f1: 0.0667\n",
      "Epoch 1413/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2814 - f1: 0.7360 - val_loss: 0.2884 - val_f1: 0.0668\n",
      "Epoch 1414/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2812 - f1: 0.7363 - val_loss: 0.2845 - val_f1: 0.0657\n",
      "Epoch 1415/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2817 - f1: 0.7354 - val_loss: 0.2880 - val_f1: 0.0664\n",
      "Epoch 1416/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2819 - f1: 0.7350 - val_loss: 0.2845 - val_f1: 0.0659\n",
      "Epoch 1417/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2817 - f1: 0.7380 - val_loss: 0.2871 - val_f1: 0.0667\n",
      "Epoch 1418/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2810 - f1: 0.7371 - val_loss: 0.2859 - val_f1: 0.0662\n",
      "Epoch 1419/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2818 - f1: 0.7357 - val_loss: 0.2864 - val_f1: 0.0662\n",
      "Epoch 1420/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2809 - f1: 0.7372 - val_loss: 0.2884 - val_f1: 0.0667\n",
      "Epoch 1421/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2813 - f1: 0.7377 - val_loss: 0.2877 - val_f1: 0.0668\n",
      "Epoch 1422/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2822 - f1: 0.7357 - val_loss: 0.2900 - val_f1: 0.0669\n",
      "Epoch 1423/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2822 - f1: 0.7354 - val_loss: 0.2886 - val_f1: 0.0665\n",
      "Epoch 1424/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2821 - f1: 0.7345 - val_loss: 0.2867 - val_f1: 0.0665\n",
      "Epoch 1425/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2829 - f1: 0.7357 - val_loss: 0.2879 - val_f1: 0.0667\n",
      "Epoch 1426/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2834 - f1: 0.7360 - val_loss: 0.2864 - val_f1: 0.0662\n",
      "Epoch 1427/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2818 - f1: 0.7368 - val_loss: 0.2844 - val_f1: 0.0662\n",
      "Epoch 1428/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2816 - f1: 0.7377 - val_loss: 0.2878 - val_f1: 0.0667\n",
      "Epoch 1429/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2824 - f1: 0.7346 - val_loss: 0.2885 - val_f1: 0.0666\n",
      "Epoch 1430/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2805 - f1: 0.7368 - val_loss: 0.2896 - val_f1: 0.0666\n",
      "Epoch 1431/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2811 - f1: 0.7366 - val_loss: 0.2862 - val_f1: 0.0665\n",
      "Epoch 1432/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2817 - f1: 0.7376 - val_loss: 0.2865 - val_f1: 0.0665\n",
      "Epoch 1433/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2821 - f1: 0.7364 - val_loss: 0.2874 - val_f1: 0.0667\n",
      "Epoch 1434/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2827 - f1: 0.7334 - val_loss: 0.2871 - val_f1: 0.0663\n",
      "Epoch 1435/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2808 - f1: 0.7350 - val_loss: 0.2880 - val_f1: 0.0669\n",
      "Epoch 1436/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2824 - f1: 0.7351 - val_loss: 0.2880 - val_f1: 0.0666\n",
      "Epoch 1437/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2823 - f1: 0.7352 - val_loss: 0.2849 - val_f1: 0.0660\n",
      "Epoch 1438/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2825 - f1: 0.7358 - val_loss: 0.2833 - val_f1: 0.0660\n",
      "Epoch 1439/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2822 - f1: 0.7353 - val_loss: 0.2898 - val_f1: 0.0670\n",
      "Epoch 1440/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2802 - f1: 0.7384 - val_loss: 0.2862 - val_f1: 0.0658\n",
      "Epoch 1441/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2815 - f1: 0.7361 - val_loss: 0.2850 - val_f1: 0.0660\n",
      "Epoch 1442/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2821 - f1: 0.7349 - val_loss: 0.2864 - val_f1: 0.0663\n",
      "Epoch 1443/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2802 - f1: 0.7361 - val_loss: 0.2911 - val_f1: 0.0669\n",
      "Epoch 1444/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2815 - f1: 0.7365 - val_loss: 0.2892 - val_f1: 0.0663\n",
      "Epoch 1445/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2822 - f1: 0.7357 - val_loss: 0.2865 - val_f1: 0.0659\n",
      "Epoch 1446/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2816 - f1: 0.7370 - val_loss: 0.2899 - val_f1: 0.0670\n",
      "Epoch 1447/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2818 - f1: 0.7348 - val_loss: 0.2868 - val_f1: 0.0665\n",
      "Epoch 1448/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2822 - f1: 0.7365 - val_loss: 0.2881 - val_f1: 0.0662\n",
      "Epoch 1449/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2807 - f1: 0.7362 - val_loss: 0.2837 - val_f1: 0.0659\n",
      "Epoch 1450/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2808 - f1: 0.7378 - val_loss: 0.2845 - val_f1: 0.0659\n",
      "Epoch 1451/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2810 - f1: 0.7370 - val_loss: 0.2854 - val_f1: 0.0658\n",
      "Epoch 1452/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2807 - f1: 0.7378 - val_loss: 0.2848 - val_f1: 0.0663\n",
      "Epoch 1453/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2819 - f1: 0.7354 - val_loss: 0.2880 - val_f1: 0.0661\n",
      "Epoch 1454/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2810 - f1: 0.7376 - val_loss: 0.2891 - val_f1: 0.0668\n",
      "Epoch 1455/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2806 - f1: 0.7376 - val_loss: 0.2927 - val_f1: 0.0668\n",
      "Epoch 1456/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2818 - f1: 0.7364 - val_loss: 0.2902 - val_f1: 0.0668\n",
      "Epoch 1457/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2796 - f1: 0.7400 - val_loss: 0.2883 - val_f1: 0.0667\n",
      "Epoch 1458/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2822 - f1: 0.7349 - val_loss: 0.2891 - val_f1: 0.0668\n",
      "Epoch 1459/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2810 - f1: 0.7360 - val_loss: 0.2896 - val_f1: 0.0664\n",
      "Epoch 1460/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2811 - f1: 0.7360 - val_loss: 0.2849 - val_f1: 0.0656\n",
      "Epoch 1461/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2816 - f1: 0.7363 - val_loss: 0.2862 - val_f1: 0.0665\n",
      "Epoch 1462/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2822 - f1: 0.7359 - val_loss: 0.2873 - val_f1: 0.0665\n",
      "Epoch 1463/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2821 - f1: 0.7349 - val_loss: 0.2918 - val_f1: 0.0671\n",
      "Epoch 1464/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2809 - f1: 0.7366 - val_loss: 0.2852 - val_f1: 0.0663\n",
      "Epoch 1465/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2811 - f1: 0.7375 - val_loss: 0.2899 - val_f1: 0.0667\n",
      "Epoch 1466/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2795 - f1: 0.7386 - val_loss: 0.2895 - val_f1: 0.0668\n",
      "Epoch 1467/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2818 - f1: 0.7345 - val_loss: 0.2840 - val_f1: 0.0662\n",
      "Epoch 1468/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2827 - f1: 0.7346 - val_loss: 0.2918 - val_f1: 0.0670\n",
      "Epoch 1469/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2826 - f1: 0.7344 - val_loss: 0.2883 - val_f1: 0.0667\n",
      "Epoch 1470/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2808 - f1: 0.7391 - val_loss: 0.2891 - val_f1: 0.0665\n",
      "Epoch 1471/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2823 - f1: 0.7362 - val_loss: 0.2880 - val_f1: 0.0664\n",
      "Epoch 1472/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2822 - f1: 0.7343 - val_loss: 0.2907 - val_f1: 0.0670\n",
      "Epoch 1473/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2809 - f1: 0.7366 - val_loss: 0.2910 - val_f1: 0.0674\n",
      "Epoch 1474/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2814 - f1: 0.7368 - val_loss: 0.2881 - val_f1: 0.0668\n",
      "Epoch 1475/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2820 - f1: 0.7369 - val_loss: 0.2868 - val_f1: 0.0665\n",
      "Epoch 1476/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2819 - f1: 0.7357 - val_loss: 0.2910 - val_f1: 0.0668\n",
      "Epoch 1477/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2824 - f1: 0.7340 - val_loss: 0.2859 - val_f1: 0.0661\n",
      "Epoch 1478/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2825 - f1: 0.7342 - val_loss: 0.2892 - val_f1: 0.0666\n",
      "Epoch 1479/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2810 - f1: 0.7351 - val_loss: 0.2937 - val_f1: 0.0671\n",
      "Epoch 1480/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2805 - f1: 0.7381 - val_loss: 0.2863 - val_f1: 0.0662\n",
      "Epoch 1481/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2805 - f1: 0.7384 - val_loss: 0.2892 - val_f1: 0.0663\n",
      "Epoch 1482/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2818 - f1: 0.7352 - val_loss: 0.2855 - val_f1: 0.0660\n",
      "Epoch 1483/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2802 - f1: 0.7377 - val_loss: 0.2864 - val_f1: 0.0660\n",
      "Epoch 1484/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2808 - f1: 0.7388 - val_loss: 0.2932 - val_f1: 0.0671\n",
      "Epoch 1485/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2812 - f1: 0.7383 - val_loss: 0.2856 - val_f1: 0.0659\n",
      "Epoch 1486/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2826 - f1: 0.7328 - val_loss: 0.2889 - val_f1: 0.0670\n",
      "Epoch 1487/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2799 - f1: 0.7385 - val_loss: 0.2902 - val_f1: 0.0668\n",
      "Epoch 1488/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2815 - f1: 0.7374 - val_loss: 0.2888 - val_f1: 0.0666\n",
      "Epoch 1489/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2812 - f1: 0.7364 - val_loss: 0.2847 - val_f1: 0.0660\n",
      "Epoch 1490/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2804 - f1: 0.7382 - val_loss: 0.2837 - val_f1: 0.0657\n",
      "Epoch 1491/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2810 - f1: 0.7356 - val_loss: 0.2870 - val_f1: 0.0660\n",
      "Epoch 1492/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2811 - f1: 0.7381 - val_loss: 0.2867 - val_f1: 0.0662\n",
      "Epoch 1493/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2809 - f1: 0.7369 - val_loss: 0.2880 - val_f1: 0.0664\n",
      "Epoch 1494/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2816 - f1: 0.7366 - val_loss: 0.2914 - val_f1: 0.0669\n",
      "Epoch 1495/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2808 - f1: 0.7360 - val_loss: 0.2875 - val_f1: 0.0661\n",
      "Epoch 1496/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2808 - f1: 0.7370 - val_loss: 0.2872 - val_f1: 0.0663\n",
      "Epoch 1497/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2812 - f1: 0.7380 - val_loss: 0.2851 - val_f1: 0.0662\n",
      "Epoch 1498/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2807 - f1: 0.7359 - val_loss: 0.2847 - val_f1: 0.0660\n",
      "Epoch 1499/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2813 - f1: 0.7354 - val_loss: 0.2894 - val_f1: 0.0668\n",
      "Epoch 1500/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2795 - f1: 0.7401 - val_loss: 0.2900 - val_f1: 0.0666\n",
      "Epoch 1501/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2812 - f1: 0.7357 - val_loss: 0.2890 - val_f1: 0.0668\n",
      "Epoch 1502/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2812 - f1: 0.7376 - val_loss: 0.2893 - val_f1: 0.0669\n",
      "Epoch 1503/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2810 - f1: 0.7370 - val_loss: 0.2831 - val_f1: 0.0655\n",
      "Epoch 1504/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2819 - f1: 0.7372 - val_loss: 0.2884 - val_f1: 0.0669\n",
      "Epoch 1505/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2810 - f1: 0.7365 - val_loss: 0.2878 - val_f1: 0.0664\n",
      "Epoch 1506/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2806 - f1: 0.7389 - val_loss: 0.2851 - val_f1: 0.0659\n",
      "Epoch 1507/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2816 - f1: 0.7366 - val_loss: 0.2904 - val_f1: 0.0667\n",
      "Epoch 1508/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2823 - f1: 0.7365 - val_loss: 0.2845 - val_f1: 0.0658\n",
      "Epoch 1509/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2814 - f1: 0.7364 - val_loss: 0.2894 - val_f1: 0.0671\n",
      "Epoch 1510/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2816 - f1: 0.7369 - val_loss: 0.2881 - val_f1: 0.0663\n",
      "Epoch 1511/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2805 - f1: 0.7379 - val_loss: 0.2870 - val_f1: 0.0662\n",
      "Epoch 1512/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2810 - f1: 0.7380 - val_loss: 0.2876 - val_f1: 0.0666\n",
      "Epoch 1513/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2810 - f1: 0.7372 - val_loss: 0.2901 - val_f1: 0.0667\n",
      "Epoch 1514/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2814 - f1: 0.7369 - val_loss: 0.2879 - val_f1: 0.0667\n",
      "Epoch 1515/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2790 - f1: 0.7379 - val_loss: 0.2875 - val_f1: 0.0660\n",
      "Epoch 1516/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2797 - f1: 0.7399 - val_loss: 0.2917 - val_f1: 0.0671\n",
      "Epoch 1517/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2806 - f1: 0.7366 - val_loss: 0.2912 - val_f1: 0.0670\n",
      "Epoch 1518/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2818 - f1: 0.7354 - val_loss: 0.2869 - val_f1: 0.0660\n",
      "Epoch 1519/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2804 - f1: 0.7385 - val_loss: 0.2883 - val_f1: 0.0666\n",
      "Epoch 1520/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2802 - f1: 0.7362 - val_loss: 0.2857 - val_f1: 0.0658\n",
      "Epoch 1521/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2810 - f1: 0.7358 - val_loss: 0.2896 - val_f1: 0.0666\n",
      "Epoch 1522/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2799 - f1: 0.7407 - val_loss: 0.2883 - val_f1: 0.0661\n",
      "Epoch 1523/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2805 - f1: 0.7373 - val_loss: 0.2888 - val_f1: 0.0663\n",
      "Epoch 1524/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2803 - f1: 0.7383 - val_loss: 0.2907 - val_f1: 0.0665\n",
      "Epoch 1525/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2814 - f1: 0.7379 - val_loss: 0.2856 - val_f1: 0.0659\n",
      "Epoch 1526/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2800 - f1: 0.7369 - val_loss: 0.2913 - val_f1: 0.0671\n",
      "Epoch 1527/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2804 - f1: 0.7357 - val_loss: 0.2840 - val_f1: 0.0656\n",
      "Epoch 1528/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2826 - f1: 0.7343 - val_loss: 0.2859 - val_f1: 0.0662\n",
      "Epoch 1529/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2788 - f1: 0.7396 - val_loss: 0.2870 - val_f1: 0.0660\n",
      "Epoch 1530/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2798 - f1: 0.7368 - val_loss: 0.2910 - val_f1: 0.0667\n",
      "Epoch 1531/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2812 - f1: 0.7361 - val_loss: 0.2867 - val_f1: 0.0662\n",
      "Epoch 1532/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2805 - f1: 0.7381 - val_loss: 0.2835 - val_f1: 0.0658\n",
      "Epoch 1533/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2828 - f1: 0.7348 - val_loss: 0.2870 - val_f1: 0.0662\n",
      "Epoch 1534/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2812 - f1: 0.7373 - val_loss: 0.2882 - val_f1: 0.0665\n",
      "Epoch 1535/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2813 - f1: 0.7363 - val_loss: 0.2873 - val_f1: 0.0664\n",
      "Epoch 1536/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2807 - f1: 0.7377 - val_loss: 0.2876 - val_f1: 0.0666\n",
      "Epoch 1537/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2818 - f1: 0.7363 - val_loss: 0.2850 - val_f1: 0.0663\n",
      "Epoch 1538/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2817 - f1: 0.7366 - val_loss: 0.2870 - val_f1: 0.0665\n",
      "Epoch 1539/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2811 - f1: 0.7380 - val_loss: 0.2911 - val_f1: 0.0672\n",
      "Epoch 1540/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2809 - f1: 0.7363 - val_loss: 0.2867 - val_f1: 0.0666\n",
      "Epoch 1541/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2811 - f1: 0.7372 - val_loss: 0.2858 - val_f1: 0.0661\n",
      "Epoch 1542/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2801 - f1: 0.7383 - val_loss: 0.2860 - val_f1: 0.0662\n",
      "Epoch 1543/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2821 - f1: 0.7374 - val_loss: 0.2903 - val_f1: 0.0671\n",
      "Epoch 1544/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2812 - f1: 0.7360 - val_loss: 0.2878 - val_f1: 0.0667\n",
      "Epoch 1545/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2804 - f1: 0.7388 - val_loss: 0.2923 - val_f1: 0.0669\n",
      "Epoch 1546/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2808 - f1: 0.7374 - val_loss: 0.2851 - val_f1: 0.0663\n",
      "Epoch 1547/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2797 - f1: 0.7402 - val_loss: 0.2844 - val_f1: 0.0659\n",
      "Epoch 1548/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2807 - f1: 0.7388 - val_loss: 0.2835 - val_f1: 0.0658\n",
      "Epoch 1549/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2812 - f1: 0.7386 - val_loss: 0.2882 - val_f1: 0.0665\n",
      "Epoch 1550/2000\n",
      "168135/168135 [==============================] - 13s 74us/step - loss: 0.2805 - f1: 0.7408 - val_loss: 0.2868 - val_f1: 0.0663\n",
      "Epoch 1551/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2817 - f1: 0.7370 - val_loss: 0.2879 - val_f1: 0.0664\n",
      "Epoch 1552/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2809 - f1: 0.7363 - val_loss: 0.2878 - val_f1: 0.0663\n",
      "Epoch 1553/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2795 - f1: 0.7369 - val_loss: 0.2912 - val_f1: 0.0669\n",
      "Epoch 1554/2000\n",
      "168135/168135 [==============================] - 12s 73us/step - loss: 0.2809 - f1: 0.7373 - val_loss: 0.2865 - val_f1: 0.0662\n",
      "Epoch 1555/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2799 - f1: 0.7391 - val_loss: 0.2862 - val_f1: 0.0661\n",
      "Epoch 1556/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2817 - f1: 0.7366 - val_loss: 0.2872 - val_f1: 0.0663\n",
      "Epoch 1557/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2798 - f1: 0.7397 - val_loss: 0.2859 - val_f1: 0.0660\n",
      "Epoch 1558/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2795 - f1: 0.7367 - val_loss: 0.2935 - val_f1: 0.0671\n",
      "Epoch 1559/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2803 - f1: 0.7371 - val_loss: 0.2862 - val_f1: 0.0660\n",
      "Epoch 1560/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2798 - f1: 0.7386 - val_loss: 0.2871 - val_f1: 0.0666\n",
      "Epoch 1561/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2797 - f1: 0.7398 - val_loss: 0.2883 - val_f1: 0.0667\n",
      "Epoch 1562/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2801 - f1: 0.7391 - val_loss: 0.2923 - val_f1: 0.0671\n",
      "Epoch 1563/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2804 - f1: 0.7391 - val_loss: 0.2832 - val_f1: 0.0655\n",
      "Epoch 1564/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2808 - f1: 0.7338 - val_loss: 0.2852 - val_f1: 0.0658\n",
      "Epoch 1565/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2803 - f1: 0.7367 - val_loss: 0.2881 - val_f1: 0.0667\n",
      "Epoch 1566/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2806 - f1: 0.7380 - val_loss: 0.2879 - val_f1: 0.0663\n",
      "Epoch 1567/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2795 - f1: 0.7390 - val_loss: 0.2896 - val_f1: 0.0670\n",
      "Epoch 1568/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2796 - f1: 0.7397 - val_loss: 0.2889 - val_f1: 0.0667\n",
      "Epoch 1569/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2804 - f1: 0.7398 - val_loss: 0.2834 - val_f1: 0.0656\n",
      "Epoch 1570/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2796 - f1: 0.7399 - val_loss: 0.2841 - val_f1: 0.0660\n",
      "Epoch 1571/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2786 - f1: 0.7390 - val_loss: 0.2883 - val_f1: 0.0663\n",
      "Epoch 1572/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2811 - f1: 0.7379 - val_loss: 0.2896 - val_f1: 0.0668\n",
      "Epoch 1573/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2794 - f1: 0.7377 - val_loss: 0.2852 - val_f1: 0.0664\n",
      "Epoch 1574/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2798 - f1: 0.7370 - val_loss: 0.2885 - val_f1: 0.0664\n",
      "Epoch 1575/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2801 - f1: 0.7392 - val_loss: 0.2876 - val_f1: 0.0663\n",
      "Epoch 1576/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2806 - f1: 0.7371 - val_loss: 0.2845 - val_f1: 0.0659\n",
      "Epoch 1577/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2794 - f1: 0.7383 - val_loss: 0.2863 - val_f1: 0.0660\n",
      "Epoch 1578/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2803 - f1: 0.7379 - val_loss: 0.2887 - val_f1: 0.0665\n",
      "Epoch 1579/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2814 - f1: 0.7352 - val_loss: 0.2847 - val_f1: 0.0658\n",
      "Epoch 1580/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2796 - f1: 0.7373 - val_loss: 0.2923 - val_f1: 0.0670\n",
      "Epoch 1581/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2792 - f1: 0.7387 - val_loss: 0.2866 - val_f1: 0.0662\n",
      "Epoch 1582/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2805 - f1: 0.7386 - val_loss: 0.2878 - val_f1: 0.0659\n",
      "Epoch 1583/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2806 - f1: 0.7385 - val_loss: 0.2893 - val_f1: 0.0662\n",
      "Epoch 1584/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2801 - f1: 0.7373 - val_loss: 0.2869 - val_f1: 0.0662\n",
      "Epoch 1585/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2794 - f1: 0.7383 - val_loss: 0.2926 - val_f1: 0.0666\n",
      "Epoch 1586/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2789 - f1: 0.7412 - val_loss: 0.2880 - val_f1: 0.0661\n",
      "Epoch 1587/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2803 - f1: 0.7390 - val_loss: 0.2890 - val_f1: 0.0665\n",
      "Epoch 1588/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2801 - f1: 0.7375 - val_loss: 0.2876 - val_f1: 0.0661\n",
      "Epoch 1589/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2796 - f1: 0.7400 - val_loss: 0.2864 - val_f1: 0.0664\n",
      "Epoch 1590/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2796 - f1: 0.7401 - val_loss: 0.2917 - val_f1: 0.0668\n",
      "Epoch 1591/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2803 - f1: 0.7373 - val_loss: 0.2898 - val_f1: 0.0668\n",
      "Epoch 1592/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2797 - f1: 0.7383 - val_loss: 0.2855 - val_f1: 0.0660\n",
      "Epoch 1593/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2789 - f1: 0.7393 - val_loss: 0.2840 - val_f1: 0.0658\n",
      "Epoch 1594/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2799 - f1: 0.7402 - val_loss: 0.2855 - val_f1: 0.0660\n",
      "Epoch 1595/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2817 - f1: 0.7351 - val_loss: 0.2903 - val_f1: 0.0668\n",
      "Epoch 1596/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2805 - f1: 0.7361 - val_loss: 0.2860 - val_f1: 0.0662\n",
      "Epoch 1597/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2803 - f1: 0.7372 - val_loss: 0.2880 - val_f1: 0.0668\n",
      "Epoch 1598/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2799 - f1: 0.7374 - val_loss: 0.2910 - val_f1: 0.0670\n",
      "Epoch 1599/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2802 - f1: 0.7387 - val_loss: 0.2856 - val_f1: 0.0660\n",
      "Epoch 1600/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2793 - f1: 0.7378 - val_loss: 0.2867 - val_f1: 0.0666\n",
      "Epoch 1601/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2789 - f1: 0.7391 - val_loss: 0.2891 - val_f1: 0.0663\n",
      "Epoch 1602/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2808 - f1: 0.7374 - val_loss: 0.2869 - val_f1: 0.0661\n",
      "Epoch 1603/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2811 - f1: 0.7398 - val_loss: 0.2869 - val_f1: 0.0661\n",
      "Epoch 1604/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2802 - f1: 0.7375 - val_loss: 0.2855 - val_f1: 0.0656\n",
      "Epoch 1605/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2798 - f1: 0.7386 - val_loss: 0.2921 - val_f1: 0.0668\n",
      "Epoch 1606/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2797 - f1: 0.7389 - val_loss: 0.2898 - val_f1: 0.0667\n",
      "Epoch 1607/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2804 - f1: 0.7391 - val_loss: 0.2874 - val_f1: 0.0661\n",
      "Epoch 1608/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2800 - f1: 0.7401 - val_loss: 0.2915 - val_f1: 0.0668\n",
      "Epoch 1609/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2801 - f1: 0.7395 - val_loss: 0.2916 - val_f1: 0.0671\n",
      "Epoch 1610/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2791 - f1: 0.7400 - val_loss: 0.2891 - val_f1: 0.0669\n",
      "Epoch 1611/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2803 - f1: 0.7405 - val_loss: 0.2921 - val_f1: 0.0672\n",
      "Epoch 1612/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2802 - f1: 0.7389 - val_loss: 0.2912 - val_f1: 0.0670\n",
      "Epoch 1613/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2806 - f1: 0.7378 - val_loss: 0.2846 - val_f1: 0.0661\n",
      "Epoch 1614/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2794 - f1: 0.7391 - val_loss: 0.2859 - val_f1: 0.0659\n",
      "Epoch 1615/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2788 - f1: 0.7394 - val_loss: 0.2907 - val_f1: 0.0669\n",
      "Epoch 1616/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2789 - f1: 0.7399 - val_loss: 0.2895 - val_f1: 0.0663\n",
      "Epoch 1617/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2816 - f1: 0.7360 - val_loss: 0.2880 - val_f1: 0.0660\n",
      "Epoch 1618/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2804 - f1: 0.7381 - val_loss: 0.2835 - val_f1: 0.0655\n",
      "Epoch 1619/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2780 - f1: 0.7413 - val_loss: 0.2872 - val_f1: 0.0662\n",
      "Epoch 1620/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2787 - f1: 0.7402 - val_loss: 0.2909 - val_f1: 0.0670\n",
      "Epoch 1621/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2800 - f1: 0.7387 - val_loss: 0.2864 - val_f1: 0.0665\n",
      "Epoch 1622/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2788 - f1: 0.7403 - val_loss: 0.2908 - val_f1: 0.0668\n",
      "Epoch 1623/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2792 - f1: 0.7420 - val_loss: 0.2878 - val_f1: 0.0662\n",
      "Epoch 1624/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2800 - f1: 0.7385 - val_loss: 0.2886 - val_f1: 0.0666\n",
      "Epoch 1625/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2795 - f1: 0.7391 - val_loss: 0.2874 - val_f1: 0.0663\n",
      "Epoch 1626/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2800 - f1: 0.7407 - val_loss: 0.2860 - val_f1: 0.0659\n",
      "Epoch 1627/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2806 - f1: 0.7371 - val_loss: 0.2860 - val_f1: 0.0660\n",
      "Epoch 1628/2000\n",
      "168135/168135 [==============================] - 12s 72us/step - loss: 0.2783 - f1: 0.7399 - val_loss: 0.2888 - val_f1: 0.0662\n",
      "Epoch 1629/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2802 - f1: 0.7392 - val_loss: 0.2881 - val_f1: 0.0668\n",
      "Epoch 1630/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2794 - f1: 0.7377 - val_loss: 0.2865 - val_f1: 0.0662\n",
      "Epoch 1631/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2802 - f1: 0.7366 - val_loss: 0.2850 - val_f1: 0.0659\n",
      "Epoch 1632/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2790 - f1: 0.7397 - val_loss: 0.2890 - val_f1: 0.0667\n",
      "Epoch 1633/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2794 - f1: 0.7379 - val_loss: 0.2877 - val_f1: 0.0661\n",
      "Epoch 1634/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2802 - f1: 0.7381 - val_loss: 0.2885 - val_f1: 0.0665\n",
      "Epoch 1635/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2793 - f1: 0.7393 - val_loss: 0.2911 - val_f1: 0.0669\n",
      "Epoch 1636/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2796 - f1: 0.7391 - val_loss: 0.2894 - val_f1: 0.0669\n",
      "Epoch 1637/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2789 - f1: 0.7398 - val_loss: 0.2857 - val_f1: 0.0660\n",
      "Epoch 1638/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2793 - f1: 0.7398 - val_loss: 0.2870 - val_f1: 0.0663\n",
      "Epoch 1639/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2793 - f1: 0.7393 - val_loss: 0.2883 - val_f1: 0.0663\n",
      "Epoch 1640/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2801 - f1: 0.7379 - val_loss: 0.2892 - val_f1: 0.0665\n",
      "Epoch 1641/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2781 - f1: 0.7410 - val_loss: 0.2894 - val_f1: 0.0664\n",
      "Epoch 1642/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2804 - f1: 0.7359 - val_loss: 0.2863 - val_f1: 0.0663\n",
      "Epoch 1643/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2775 - f1: 0.7420 - val_loss: 0.2898 - val_f1: 0.0667\n",
      "Epoch 1644/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2802 - f1: 0.7375 - val_loss: 0.2886 - val_f1: 0.0665\n",
      "Epoch 1645/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2799 - f1: 0.7402 - val_loss: 0.2857 - val_f1: 0.0654\n",
      "Epoch 1646/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2789 - f1: 0.7404 - val_loss: 0.2901 - val_f1: 0.0665\n",
      "Epoch 1647/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2793 - f1: 0.7382 - val_loss: 0.2891 - val_f1: 0.0663\n",
      "Epoch 1648/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2801 - f1: 0.7364 - val_loss: 0.2893 - val_f1: 0.0666\n",
      "Epoch 1649/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2802 - f1: 0.7392 - val_loss: 0.2858 - val_f1: 0.0660\n",
      "Epoch 1650/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2805 - f1: 0.7364 - val_loss: 0.2869 - val_f1: 0.0662\n",
      "Epoch 1651/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2797 - f1: 0.7390 - val_loss: 0.2900 - val_f1: 0.0668\n",
      "Epoch 1652/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2792 - f1: 0.7381 - val_loss: 0.2894 - val_f1: 0.0665\n",
      "Epoch 1653/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2804 - f1: 0.7382 - val_loss: 0.2858 - val_f1: 0.0661\n",
      "Epoch 1654/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2796 - f1: 0.7400 - val_loss: 0.2929 - val_f1: 0.0667\n",
      "Epoch 1655/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2795 - f1: 0.7382 - val_loss: 0.2939 - val_f1: 0.0676\n",
      "Epoch 1656/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2802 - f1: 0.7345 - val_loss: 0.2885 - val_f1: 0.0664\n",
      "Epoch 1657/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2798 - f1: 0.7382 - val_loss: 0.2869 - val_f1: 0.0661\n",
      "Epoch 1658/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2804 - f1: 0.7385 - val_loss: 0.2861 - val_f1: 0.0661\n",
      "Epoch 1659/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2787 - f1: 0.7383 - val_loss: 0.2925 - val_f1: 0.0671\n",
      "Epoch 1660/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2782 - f1: 0.7427 - val_loss: 0.2896 - val_f1: 0.0667\n",
      "Epoch 1661/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2793 - f1: 0.7386 - val_loss: 0.2908 - val_f1: 0.0670\n",
      "Epoch 1662/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2796 - f1: 0.7386 - val_loss: 0.2876 - val_f1: 0.0664\n",
      "Epoch 1663/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2788 - f1: 0.7403 - val_loss: 0.2863 - val_f1: 0.0663\n",
      "Epoch 1664/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2795 - f1: 0.7392 - val_loss: 0.2845 - val_f1: 0.0659\n",
      "Epoch 1665/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2787 - f1: 0.7392 - val_loss: 0.2891 - val_f1: 0.0668\n",
      "Epoch 1666/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2791 - f1: 0.7413 - val_loss: 0.2905 - val_f1: 0.0664\n",
      "Epoch 1667/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2792 - f1: 0.7385 - val_loss: 0.2896 - val_f1: 0.0668\n",
      "Epoch 1668/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2800 - f1: 0.7385 - val_loss: 0.2870 - val_f1: 0.0662\n",
      "Epoch 1669/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2796 - f1: 0.7376 - val_loss: 0.2883 - val_f1: 0.0664\n",
      "Epoch 1670/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2797 - f1: 0.7386 - val_loss: 0.2865 - val_f1: 0.0662\n",
      "Epoch 1671/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2805 - f1: 0.7380 - val_loss: 0.2888 - val_f1: 0.0666\n",
      "Epoch 1672/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2796 - f1: 0.7388 - val_loss: 0.2874 - val_f1: 0.0660\n",
      "Epoch 1673/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2792 - f1: 0.7382 - val_loss: 0.2872 - val_f1: 0.0662\n",
      "Epoch 1674/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2799 - f1: 0.7381 - val_loss: 0.2887 - val_f1: 0.0663\n",
      "Epoch 1675/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2796 - f1: 0.7368 - val_loss: 0.2885 - val_f1: 0.0668\n",
      "Epoch 1676/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2792 - f1: 0.7391 - val_loss: 0.2872 - val_f1: 0.0663\n",
      "Epoch 1677/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2793 - f1: 0.7405 - val_loss: 0.2898 - val_f1: 0.0670\n",
      "Epoch 1678/2000\n",
      "168135/168135 [==============================] - 12s 74us/step - loss: 0.2793 - f1: 0.7364 - val_loss: 0.2906 - val_f1: 0.0667\n",
      "Epoch 1679/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2785 - f1: 0.7404 - val_loss: 0.2922 - val_f1: 0.0671\n",
      "Epoch 1680/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2784 - f1: 0.7411 - val_loss: 0.2909 - val_f1: 0.0671\n",
      "Epoch 1681/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2803 - f1: 0.7376 - val_loss: 0.2877 - val_f1: 0.0664\n",
      "Epoch 1682/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2802 - f1: 0.7396 - val_loss: 0.2913 - val_f1: 0.0671\n",
      "Epoch 1683/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2781 - f1: 0.7402 - val_loss: 0.2905 - val_f1: 0.0667\n",
      "Epoch 1684/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2796 - f1: 0.7391 - val_loss: 0.2888 - val_f1: 0.0667\n",
      "Epoch 1685/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2804 - f1: 0.7356 - val_loss: 0.2880 - val_f1: 0.0663\n",
      "Epoch 1686/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2788 - f1: 0.7393 - val_loss: 0.2912 - val_f1: 0.0668\n",
      "Epoch 1687/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2802 - f1: 0.7394 - val_loss: 0.2844 - val_f1: 0.0657\n",
      "Epoch 1688/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2793 - f1: 0.7396 - val_loss: 0.2885 - val_f1: 0.0662\n",
      "Epoch 1689/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2791 - f1: 0.7376 - val_loss: 0.2869 - val_f1: 0.0663\n",
      "Epoch 1690/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2794 - f1: 0.7399 - val_loss: 0.2896 - val_f1: 0.0668\n",
      "Epoch 1691/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2803 - f1: 0.7380 - val_loss: 0.2874 - val_f1: 0.0665\n",
      "Epoch 1692/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2782 - f1: 0.7416 - val_loss: 0.2904 - val_f1: 0.0666\n",
      "Epoch 1693/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2784 - f1: 0.7422 - val_loss: 0.2874 - val_f1: 0.0660\n",
      "Epoch 1694/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2789 - f1: 0.7386 - val_loss: 0.2928 - val_f1: 0.0673\n",
      "Epoch 1695/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2775 - f1: 0.7411 - val_loss: 0.2909 - val_f1: 0.0665\n",
      "Epoch 1696/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2787 - f1: 0.7395 - val_loss: 0.2865 - val_f1: 0.0663\n",
      "Epoch 1697/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2788 - f1: 0.7427 - val_loss: 0.2824 - val_f1: 0.0653\n",
      "Epoch 1698/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2783 - f1: 0.7407 - val_loss: 0.2889 - val_f1: 0.0666\n",
      "Epoch 1699/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2794 - f1: 0.7378 - val_loss: 0.2888 - val_f1: 0.0667\n",
      "Epoch 1700/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2795 - f1: 0.7384 - val_loss: 0.2920 - val_f1: 0.0671\n",
      "Epoch 1701/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2788 - f1: 0.7404 - val_loss: 0.2862 - val_f1: 0.0657\n",
      "Epoch 1702/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2785 - f1: 0.7415 - val_loss: 0.2879 - val_f1: 0.0667\n",
      "Epoch 1703/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2794 - f1: 0.7394 - val_loss: 0.2859 - val_f1: 0.0661\n",
      "Epoch 1704/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2781 - f1: 0.7398 - val_loss: 0.2928 - val_f1: 0.0668\n",
      "Epoch 1705/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2799 - f1: 0.7399 - val_loss: 0.2858 - val_f1: 0.0662\n",
      "Epoch 1706/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2793 - f1: 0.7378 - val_loss: 0.2870 - val_f1: 0.0664\n",
      "Epoch 1707/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2792 - f1: 0.7375 - val_loss: 0.2845 - val_f1: 0.0657\n",
      "Epoch 1708/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2790 - f1: 0.7383 - val_loss: 0.2895 - val_f1: 0.0668\n",
      "Epoch 1709/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2776 - f1: 0.7403 - val_loss: 0.2917 - val_f1: 0.0669\n",
      "Epoch 1710/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2796 - f1: 0.7381 - val_loss: 0.2858 - val_f1: 0.0660\n",
      "Epoch 1711/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2798 - f1: 0.7383 - val_loss: 0.2875 - val_f1: 0.0667\n",
      "Epoch 1712/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2798 - f1: 0.7398 - val_loss: 0.2866 - val_f1: 0.0661\n",
      "Epoch 1713/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2790 - f1: 0.7398 - val_loss: 0.2876 - val_f1: 0.0665\n",
      "Epoch 1714/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2797 - f1: 0.7384 - val_loss: 0.2869 - val_f1: 0.0664\n",
      "Epoch 1715/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2799 - f1: 0.7376 - val_loss: 0.2886 - val_f1: 0.0667\n",
      "Epoch 1716/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2793 - f1: 0.7399 - val_loss: 0.2896 - val_f1: 0.0666\n",
      "Epoch 1717/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2783 - f1: 0.7404 - val_loss: 0.2895 - val_f1: 0.0659\n",
      "Epoch 1718/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2794 - f1: 0.7385 - val_loss: 0.2893 - val_f1: 0.0667\n",
      "Epoch 1719/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2792 - f1: 0.7395 - val_loss: 0.2894 - val_f1: 0.0666\n",
      "Epoch 1720/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2794 - f1: 0.7389 - val_loss: 0.2879 - val_f1: 0.0660\n",
      "Epoch 1721/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2795 - f1: 0.7383 - val_loss: 0.2906 - val_f1: 0.0667\n",
      "Epoch 1722/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2794 - f1: 0.7398 - val_loss: 0.2906 - val_f1: 0.0665\n",
      "Epoch 1723/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2796 - f1: 0.7385 - val_loss: 0.2862 - val_f1: 0.0661\n",
      "Epoch 1724/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2779 - f1: 0.7416 - val_loss: 0.2909 - val_f1: 0.0668\n",
      "Epoch 1725/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2789 - f1: 0.7393 - val_loss: 0.2846 - val_f1: 0.0656\n",
      "Epoch 1726/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2778 - f1: 0.7414 - val_loss: 0.2885 - val_f1: 0.0666\n",
      "Epoch 1727/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2793 - f1: 0.7414 - val_loss: 0.2903 - val_f1: 0.0670\n",
      "Epoch 1728/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2788 - f1: 0.7408 - val_loss: 0.2906 - val_f1: 0.0669\n",
      "Epoch 1729/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2791 - f1: 0.7395 - val_loss: 0.2921 - val_f1: 0.0670\n",
      "Epoch 1730/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2785 - f1: 0.7400 - val_loss: 0.2892 - val_f1: 0.0669\n",
      "Epoch 1731/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2787 - f1: 0.7398 - val_loss: 0.2845 - val_f1: 0.0659\n",
      "Epoch 1732/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2791 - f1: 0.7396 - val_loss: 0.2877 - val_f1: 0.0668\n",
      "Epoch 1733/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2801 - f1: 0.7384 - val_loss: 0.2887 - val_f1: 0.0667\n",
      "Epoch 1734/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2789 - f1: 0.7399 - val_loss: 0.2882 - val_f1: 0.0666\n",
      "Epoch 1735/2000\n",
      "168135/168135 [==============================] - 12s 74us/step - loss: 0.2805 - f1: 0.7385 - val_loss: 0.2862 - val_f1: 0.0663\n",
      "Epoch 1736/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2789 - f1: 0.7390 - val_loss: 0.2888 - val_f1: 0.0670\n",
      "Epoch 1737/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2785 - f1: 0.7405 - val_loss: 0.2908 - val_f1: 0.0667\n",
      "Epoch 1738/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2779 - f1: 0.7429 - val_loss: 0.2905 - val_f1: 0.0668\n",
      "Epoch 1739/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2794 - f1: 0.7377 - val_loss: 0.2848 - val_f1: 0.0663\n",
      "Epoch 1740/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2788 - f1: 0.7381 - val_loss: 0.2919 - val_f1: 0.0673\n",
      "Epoch 1741/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2776 - f1: 0.7425 - val_loss: 0.2915 - val_f1: 0.0673\n",
      "Epoch 1742/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2774 - f1: 0.7410 - val_loss: 0.2884 - val_f1: 0.0665\n",
      "Epoch 1743/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2787 - f1: 0.7417 - val_loss: 0.2899 - val_f1: 0.0668\n",
      "Epoch 1744/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2786 - f1: 0.7407 - val_loss: 0.2874 - val_f1: 0.0662\n",
      "Epoch 1745/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2791 - f1: 0.7404 - val_loss: 0.2902 - val_f1: 0.0670\n",
      "Epoch 1746/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2776 - f1: 0.7411 - val_loss: 0.2879 - val_f1: 0.0664\n",
      "Epoch 1747/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2783 - f1: 0.7416 - val_loss: 0.2915 - val_f1: 0.0665\n",
      "Epoch 1748/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2793 - f1: 0.7387 - val_loss: 0.2896 - val_f1: 0.0663\n",
      "Epoch 1749/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2779 - f1: 0.7397 - val_loss: 0.2901 - val_f1: 0.0670\n",
      "Epoch 1750/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2797 - f1: 0.7374 - val_loss: 0.2847 - val_f1: 0.0659\n",
      "Epoch 1751/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2798 - f1: 0.7366 - val_loss: 0.2882 - val_f1: 0.0663\n",
      "Epoch 1752/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2772 - f1: 0.7418 - val_loss: 0.2892 - val_f1: 0.0665\n",
      "Epoch 1753/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2772 - f1: 0.7437 - val_loss: 0.2903 - val_f1: 0.0665\n",
      "Epoch 1754/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2779 - f1: 0.7390 - val_loss: 0.2860 - val_f1: 0.0658\n",
      "Epoch 1755/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2783 - f1: 0.7417 - val_loss: 0.2908 - val_f1: 0.0664\n",
      "Epoch 1756/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2794 - f1: 0.7395 - val_loss: 0.2865 - val_f1: 0.0665\n",
      "Epoch 1757/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2797 - f1: 0.7388 - val_loss: 0.2920 - val_f1: 0.0665\n",
      "Epoch 1758/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2787 - f1: 0.7392 - val_loss: 0.2861 - val_f1: 0.0661\n",
      "Epoch 1759/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2782 - f1: 0.7392 - val_loss: 0.2894 - val_f1: 0.0665\n",
      "Epoch 1760/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2785 - f1: 0.7403 - val_loss: 0.2882 - val_f1: 0.0665\n",
      "Epoch 1761/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2783 - f1: 0.7400 - val_loss: 0.2879 - val_f1: 0.0663\n",
      "Epoch 1762/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2784 - f1: 0.7410 - val_loss: 0.2856 - val_f1: 0.0657\n",
      "Epoch 1763/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2780 - f1: 0.7403 - val_loss: 0.2903 - val_f1: 0.0669\n",
      "Epoch 1764/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2770 - f1: 0.7413 - val_loss: 0.2900 - val_f1: 0.0668\n",
      "Epoch 1765/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2782 - f1: 0.7388 - val_loss: 0.2883 - val_f1: 0.0667\n",
      "Epoch 1766/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2794 - f1: 0.7384 - val_loss: 0.2879 - val_f1: 0.0667\n",
      "Epoch 1767/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2791 - f1: 0.7401 - val_loss: 0.2874 - val_f1: 0.0663\n",
      "Epoch 1768/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2784 - f1: 0.7394 - val_loss: 0.2883 - val_f1: 0.0667\n",
      "Epoch 1769/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2800 - f1: 0.7390 - val_loss: 0.2888 - val_f1: 0.0664\n",
      "Epoch 1770/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2789 - f1: 0.7394 - val_loss: 0.2899 - val_f1: 0.0668\n",
      "Epoch 1771/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2783 - f1: 0.7412 - val_loss: 0.2895 - val_f1: 0.0661\n",
      "Epoch 1772/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2796 - f1: 0.7411 - val_loss: 0.2842 - val_f1: 0.0654\n",
      "Epoch 1773/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2795 - f1: 0.7379 - val_loss: 0.2861 - val_f1: 0.0664\n",
      "Epoch 1774/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2793 - f1: 0.7369 - val_loss: 0.2897 - val_f1: 0.0667\n",
      "Epoch 1775/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2788 - f1: 0.7420 - val_loss: 0.2897 - val_f1: 0.0662\n",
      "Epoch 1776/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2780 - f1: 0.7390 - val_loss: 0.2919 - val_f1: 0.0668\n",
      "Epoch 1777/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2779 - f1: 0.7393 - val_loss: 0.2904 - val_f1: 0.0671\n",
      "Epoch 1778/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2786 - f1: 0.7401 - val_loss: 0.2896 - val_f1: 0.0665\n",
      "Epoch 1779/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2775 - f1: 0.7418 - val_loss: 0.2877 - val_f1: 0.0665\n",
      "Epoch 1780/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2791 - f1: 0.7385 - val_loss: 0.2856 - val_f1: 0.0664\n",
      "Epoch 1781/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2775 - f1: 0.7411 - val_loss: 0.2931 - val_f1: 0.0673\n",
      "Epoch 1782/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2786 - f1: 0.7419 - val_loss: 0.2891 - val_f1: 0.0664\n",
      "Epoch 1783/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2782 - f1: 0.7398 - val_loss: 0.2922 - val_f1: 0.0670\n",
      "Epoch 1784/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2779 - f1: 0.7415 - val_loss: 0.2902 - val_f1: 0.0669\n",
      "Epoch 1785/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2775 - f1: 0.7408 - val_loss: 0.2897 - val_f1: 0.0665\n",
      "Epoch 1786/2000\n",
      "168135/168135 [==============================] - 12s 74us/step - loss: 0.2783 - f1: 0.7382 - val_loss: 0.2856 - val_f1: 0.0656\n",
      "Epoch 1787/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2781 - f1: 0.7418 - val_loss: 0.2872 - val_f1: 0.0664\n",
      "Epoch 1788/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2786 - f1: 0.7401 - val_loss: 0.2903 - val_f1: 0.0661\n",
      "Epoch 1789/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2785 - f1: 0.7397 - val_loss: 0.2881 - val_f1: 0.0664\n",
      "Epoch 1790/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2792 - f1: 0.7386 - val_loss: 0.2902 - val_f1: 0.0670\n",
      "Epoch 1791/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2781 - f1: 0.7443 - val_loss: 0.2923 - val_f1: 0.0669\n",
      "Epoch 1792/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2797 - f1: 0.7386 - val_loss: 0.2871 - val_f1: 0.0661\n",
      "Epoch 1793/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2790 - f1: 0.7380 - val_loss: 0.2853 - val_f1: 0.0662\n",
      "Epoch 1794/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2789 - f1: 0.7403 - val_loss: 0.2882 - val_f1: 0.0666\n",
      "Epoch 1795/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2778 - f1: 0.7415 - val_loss: 0.2885 - val_f1: 0.0666\n",
      "Epoch 1796/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2787 - f1: 0.7422 - val_loss: 0.2899 - val_f1: 0.0670\n",
      "Epoch 1797/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2785 - f1: 0.7415 - val_loss: 0.2889 - val_f1: 0.0664\n",
      "Epoch 1798/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2772 - f1: 0.7416 - val_loss: 0.2887 - val_f1: 0.0669\n",
      "Epoch 1799/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2784 - f1: 0.7408 - val_loss: 0.2879 - val_f1: 0.0665\n",
      "Epoch 1800/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2791 - f1: 0.7395 - val_loss: 0.2861 - val_f1: 0.0663\n",
      "Epoch 1801/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2784 - f1: 0.7412 - val_loss: 0.2938 - val_f1: 0.0673\n",
      "Epoch 1802/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2786 - f1: 0.7395 - val_loss: 0.2894 - val_f1: 0.0667\n",
      "Epoch 1803/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2778 - f1: 0.7393 - val_loss: 0.2887 - val_f1: 0.0663\n",
      "Epoch 1804/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2778 - f1: 0.7417 - val_loss: 0.2887 - val_f1: 0.0664\n",
      "Epoch 1805/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2782 - f1: 0.7401 - val_loss: 0.2896 - val_f1: 0.0661\n",
      "Epoch 1806/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2793 - f1: 0.7392 - val_loss: 0.2850 - val_f1: 0.0659\n",
      "Epoch 1807/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2781 - f1: 0.7419 - val_loss: 0.2876 - val_f1: 0.0665\n",
      "Epoch 1808/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2786 - f1: 0.7394 - val_loss: 0.2879 - val_f1: 0.0662\n",
      "Epoch 1809/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2775 - f1: 0.7412 - val_loss: 0.2890 - val_f1: 0.0667\n",
      "Epoch 1810/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2786 - f1: 0.7425 - val_loss: 0.2845 - val_f1: 0.0660\n",
      "Epoch 1811/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2776 - f1: 0.7400 - val_loss: 0.2878 - val_f1: 0.0661\n",
      "Epoch 1812/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2795 - f1: 0.7392 - val_loss: 0.2900 - val_f1: 0.0667\n",
      "Epoch 1813/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2777 - f1: 0.7393 - val_loss: 0.2847 - val_f1: 0.0659\n",
      "Epoch 1814/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2781 - f1: 0.7401 - val_loss: 0.2914 - val_f1: 0.0669\n",
      "Epoch 1815/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2787 - f1: 0.7397 - val_loss: 0.2911 - val_f1: 0.0667\n",
      "Epoch 1816/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2775 - f1: 0.7429 - val_loss: 0.2894 - val_f1: 0.0662\n",
      "Epoch 1817/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2781 - f1: 0.7415 - val_loss: 0.2896 - val_f1: 0.0662\n",
      "Epoch 1818/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2789 - f1: 0.7407 - val_loss: 0.2901 - val_f1: 0.0667\n",
      "Epoch 1819/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2794 - f1: 0.7380 - val_loss: 0.2903 - val_f1: 0.0663\n",
      "Epoch 1820/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2786 - f1: 0.7399 - val_loss: 0.2881 - val_f1: 0.0666\n",
      "Epoch 1821/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2781 - f1: 0.7395 - val_loss: 0.2846 - val_f1: 0.0658\n",
      "Epoch 1822/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2767 - f1: 0.7434 - val_loss: 0.2926 - val_f1: 0.0670\n",
      "Epoch 1823/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2774 - f1: 0.7409 - val_loss: 0.2866 - val_f1: 0.0661\n",
      "Epoch 1824/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2789 - f1: 0.7402 - val_loss: 0.2917 - val_f1: 0.0666\n",
      "Epoch 1825/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2773 - f1: 0.7423 - val_loss: 0.2892 - val_f1: 0.0665\n",
      "Epoch 1826/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2784 - f1: 0.7392 - val_loss: 0.2868 - val_f1: 0.0658\n",
      "Epoch 1827/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2773 - f1: 0.7423 - val_loss: 0.2880 - val_f1: 0.0662\n",
      "Epoch 1828/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2782 - f1: 0.7413 - val_loss: 0.2863 - val_f1: 0.0662\n",
      "Epoch 1829/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2779 - f1: 0.7389 - val_loss: 0.2906 - val_f1: 0.0671\n",
      "Epoch 1830/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2779 - f1: 0.7395 - val_loss: 0.2900 - val_f1: 0.0665\n",
      "Epoch 1831/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2768 - f1: 0.7423 - val_loss: 0.2867 - val_f1: 0.0659\n",
      "Epoch 1832/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2776 - f1: 0.7401 - val_loss: 0.2870 - val_f1: 0.0660\n",
      "Epoch 1833/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2785 - f1: 0.7418 - val_loss: 0.2886 - val_f1: 0.0661\n",
      "Epoch 1834/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2778 - f1: 0.7417 - val_loss: 0.2898 - val_f1: 0.0666\n",
      "Epoch 1835/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2766 - f1: 0.7424 - val_loss: 0.2906 - val_f1: 0.0665\n",
      "Epoch 1836/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2784 - f1: 0.7386 - val_loss: 0.2884 - val_f1: 0.0661\n",
      "Epoch 1837/2000\n",
      "168135/168135 [==============================] - 12s 73us/step - loss: 0.2773 - f1: 0.7413 - val_loss: 0.2892 - val_f1: 0.0663\n",
      "Epoch 1838/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2782 - f1: 0.7408 - val_loss: 0.2894 - val_f1: 0.0663\n",
      "Epoch 1839/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2773 - f1: 0.7413 - val_loss: 0.2896 - val_f1: 0.0663\n",
      "Epoch 1840/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2781 - f1: 0.7404 - val_loss: 0.2907 - val_f1: 0.0666\n",
      "Epoch 1841/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2773 - f1: 0.7435 - val_loss: 0.2896 - val_f1: 0.0667\n",
      "Epoch 1842/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2795 - f1: 0.7394 - val_loss: 0.2900 - val_f1: 0.0664\n",
      "Epoch 1843/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2768 - f1: 0.7409 - val_loss: 0.2912 - val_f1: 0.0668\n",
      "Epoch 1844/2000\n",
      "168135/168135 [==============================] - 12s 74us/step - loss: 0.2776 - f1: 0.7423 - val_loss: 0.2894 - val_f1: 0.0665\n",
      "Epoch 1845/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2789 - f1: 0.7377 - val_loss: 0.2851 - val_f1: 0.0653\n",
      "Epoch 1846/2000\n",
      "168135/168135 [==============================] - 12s 73us/step - loss: 0.2769 - f1: 0.7424 - val_loss: 0.2885 - val_f1: 0.0662\n",
      "Epoch 1847/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2771 - f1: 0.7424 - val_loss: 0.2884 - val_f1: 0.0661\n",
      "Epoch 1848/2000\n",
      "168135/168135 [==============================] - 12s 73us/step - loss: 0.2777 - f1: 0.7392 - val_loss: 0.2856 - val_f1: 0.0657\n",
      "Epoch 1849/2000\n",
      "168135/168135 [==============================] - 12s 70us/step - loss: 0.2775 - f1: 0.7424 - val_loss: 0.2932 - val_f1: 0.0670\n",
      "Epoch 1850/2000\n",
      "168135/168135 [==============================] - 12s 71us/step - loss: 0.2769 - f1: 0.7424 - val_loss: 0.2889 - val_f1: 0.0664\n",
      "Epoch 1851/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2782 - f1: 0.7409 - val_loss: 0.2885 - val_f1: 0.0666\n",
      "Epoch 1852/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2775 - f1: 0.7412 - val_loss: 0.2915 - val_f1: 0.0665\n",
      "Epoch 1853/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2784 - f1: 0.7426 - val_loss: 0.2906 - val_f1: 0.0666\n",
      "Epoch 1854/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2786 - f1: 0.7386 - val_loss: 0.2899 - val_f1: 0.0666\n",
      "Epoch 1855/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2778 - f1: 0.7407 - val_loss: 0.2901 - val_f1: 0.0663\n",
      "Epoch 1856/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2779 - f1: 0.7414 - val_loss: 0.2877 - val_f1: 0.0661\n",
      "Epoch 1857/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2783 - f1: 0.7412 - val_loss: 0.2879 - val_f1: 0.0662\n",
      "Epoch 1858/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2779 - f1: 0.7416 - val_loss: 0.2837 - val_f1: 0.0651\n",
      "Epoch 1859/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2776 - f1: 0.7392 - val_loss: 0.2864 - val_f1: 0.0660\n",
      "Epoch 1860/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2791 - f1: 0.7392 - val_loss: 0.2896 - val_f1: 0.0663\n",
      "Epoch 1861/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2790 - f1: 0.7404 - val_loss: 0.2925 - val_f1: 0.0669\n",
      "Epoch 1862/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2769 - f1: 0.7413 - val_loss: 0.2898 - val_f1: 0.0665\n",
      "Epoch 1863/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2785 - f1: 0.7395 - val_loss: 0.2879 - val_f1: 0.0662\n",
      "Epoch 1864/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2790 - f1: 0.7402 - val_loss: 0.2899 - val_f1: 0.0663\n",
      "Epoch 1865/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2778 - f1: 0.7402 - val_loss: 0.2925 - val_f1: 0.0672\n",
      "Epoch 1866/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2774 - f1: 0.7412 - val_loss: 0.2945 - val_f1: 0.0668\n",
      "Epoch 1867/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2791 - f1: 0.7396 - val_loss: 0.2874 - val_f1: 0.0663\n",
      "Epoch 1868/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2777 - f1: 0.7394 - val_loss: 0.2865 - val_f1: 0.0659\n",
      "Epoch 1869/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2772 - f1: 0.7418 - val_loss: 0.2904 - val_f1: 0.0662\n",
      "Epoch 1870/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2777 - f1: 0.7402 - val_loss: 0.2896 - val_f1: 0.0661\n",
      "Epoch 1871/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2776 - f1: 0.7400 - val_loss: 0.2876 - val_f1: 0.0662\n",
      "Epoch 1872/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2770 - f1: 0.7412 - val_loss: 0.2848 - val_f1: 0.0659\n",
      "Epoch 1873/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2774 - f1: 0.7406 - val_loss: 0.2868 - val_f1: 0.0658\n",
      "Epoch 1874/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2782 - f1: 0.7403 - val_loss: 0.2865 - val_f1: 0.0662\n",
      "Epoch 1875/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2787 - f1: 0.7401 - val_loss: 0.2918 - val_f1: 0.0665\n",
      "Epoch 1876/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2788 - f1: 0.7380 - val_loss: 0.2888 - val_f1: 0.0665\n",
      "Epoch 1877/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2786 - f1: 0.7404 - val_loss: 0.2886 - val_f1: 0.0664\n",
      "Epoch 1878/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2776 - f1: 0.7411 - val_loss: 0.2855 - val_f1: 0.0657\n",
      "Epoch 1879/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2785 - f1: 0.7398 - val_loss: 0.2886 - val_f1: 0.0662\n",
      "Epoch 1880/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2771 - f1: 0.7420 - val_loss: 0.2897 - val_f1: 0.0663\n",
      "Epoch 1881/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2780 - f1: 0.7409 - val_loss: 0.2869 - val_f1: 0.0660\n",
      "Epoch 1882/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2775 - f1: 0.7418 - val_loss: 0.2892 - val_f1: 0.0659\n",
      "Epoch 1883/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2778 - f1: 0.7404 - val_loss: 0.2905 - val_f1: 0.0666\n",
      "Epoch 1884/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2770 - f1: 0.7398 - val_loss: 0.2916 - val_f1: 0.0669\n",
      "Epoch 1885/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2781 - f1: 0.7412 - val_loss: 0.2898 - val_f1: 0.0666\n",
      "Epoch 1886/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2777 - f1: 0.7412 - val_loss: 0.2904 - val_f1: 0.0668\n",
      "Epoch 1887/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2777 - f1: 0.7397 - val_loss: 0.2930 - val_f1: 0.0672\n",
      "Epoch 1888/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2799 - f1: 0.7393 - val_loss: 0.2877 - val_f1: 0.0664\n",
      "Epoch 1889/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2769 - f1: 0.7419 - val_loss: 0.2866 - val_f1: 0.0660\n",
      "Epoch 1890/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2772 - f1: 0.7407 - val_loss: 0.2921 - val_f1: 0.0668\n",
      "Epoch 1891/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2788 - f1: 0.7381 - val_loss: 0.2893 - val_f1: 0.0662\n",
      "Epoch 1892/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2785 - f1: 0.7409 - val_loss: 0.2874 - val_f1: 0.0663\n",
      "Epoch 1893/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2764 - f1: 0.7443 - val_loss: 0.2892 - val_f1: 0.0667\n",
      "Epoch 1894/2000\n",
      "168135/168135 [==============================] - 12s 74us/step - loss: 0.2768 - f1: 0.7419 - val_loss: 0.2917 - val_f1: 0.0668\n",
      "Epoch 1895/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2771 - f1: 0.7430 - val_loss: 0.2875 - val_f1: 0.0660\n",
      "Epoch 1896/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2774 - f1: 0.7424 - val_loss: 0.2904 - val_f1: 0.0666\n",
      "Epoch 1897/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2768 - f1: 0.7411 - val_loss: 0.2866 - val_f1: 0.0659\n",
      "Epoch 1898/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2778 - f1: 0.7414 - val_loss: 0.2871 - val_f1: 0.0663\n",
      "Epoch 1899/2000\n",
      "168135/168135 [==============================] - 12s 71us/step - loss: 0.2776 - f1: 0.7412 - val_loss: 0.2878 - val_f1: 0.0665\n",
      "Epoch 1900/2000\n",
      "168135/168135 [==============================] - 12s 70us/step - loss: 0.2778 - f1: 0.7417 - val_loss: 0.2871 - val_f1: 0.0665\n",
      "Epoch 1901/2000\n",
      "168135/168135 [==============================] - 12s 69us/step - loss: 0.2771 - f1: 0.7423 - val_loss: 0.2893 - val_f1: 0.0666\n",
      "Epoch 1902/2000\n",
      "168135/168135 [==============================] - 12s 70us/step - loss: 0.2780 - f1: 0.7417 - val_loss: 0.2924 - val_f1: 0.0667\n",
      "Epoch 1903/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2775 - f1: 0.7415 - val_loss: 0.2874 - val_f1: 0.0662\n",
      "Epoch 1904/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2789 - f1: 0.7401 - val_loss: 0.2849 - val_f1: 0.0658\n",
      "Epoch 1905/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2775 - f1: 0.7408 - val_loss: 0.2883 - val_f1: 0.0667\n",
      "Epoch 1906/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2773 - f1: 0.7412 - val_loss: 0.2870 - val_f1: 0.0665\n",
      "Epoch 1907/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2777 - f1: 0.7413 - val_loss: 0.2880 - val_f1: 0.0660\n",
      "Epoch 1908/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2762 - f1: 0.7445 - val_loss: 0.2881 - val_f1: 0.0662\n",
      "Epoch 1909/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2762 - f1: 0.7454 - val_loss: 0.2892 - val_f1: 0.0663\n",
      "Epoch 1910/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2791 - f1: 0.7423 - val_loss: 0.2899 - val_f1: 0.0664\n",
      "Epoch 1911/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2762 - f1: 0.7418 - val_loss: 0.2901 - val_f1: 0.0664\n",
      "Epoch 1912/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2784 - f1: 0.7408 - val_loss: 0.2862 - val_f1: 0.0660\n",
      "Epoch 1913/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2772 - f1: 0.7417 - val_loss: 0.2895 - val_f1: 0.0667\n",
      "Epoch 1914/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2768 - f1: 0.7433 - val_loss: 0.2897 - val_f1: 0.0665\n",
      "Epoch 1915/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2784 - f1: 0.7404 - val_loss: 0.2899 - val_f1: 0.0665\n",
      "Epoch 1916/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2781 - f1: 0.7403 - val_loss: 0.2908 - val_f1: 0.0669\n",
      "Epoch 1917/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2776 - f1: 0.7420 - val_loss: 0.2891 - val_f1: 0.0667\n",
      "Epoch 1918/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2784 - f1: 0.7388 - val_loss: 0.2868 - val_f1: 0.0661\n",
      "Epoch 1919/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2767 - f1: 0.7411 - val_loss: 0.2924 - val_f1: 0.0668\n",
      "Epoch 1920/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2775 - f1: 0.7412 - val_loss: 0.2856 - val_f1: 0.0658\n",
      "Epoch 1921/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2776 - f1: 0.7421 - val_loss: 0.2916 - val_f1: 0.0667\n",
      "Epoch 1922/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2774 - f1: 0.7402 - val_loss: 0.2925 - val_f1: 0.0665\n",
      "Epoch 1923/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2781 - f1: 0.7405 - val_loss: 0.2902 - val_f1: 0.0665\n",
      "Epoch 1924/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2761 - f1: 0.7423 - val_loss: 0.2931 - val_f1: 0.0670\n",
      "Epoch 1925/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2785 - f1: 0.7405 - val_loss: 0.2883 - val_f1: 0.0667\n",
      "Epoch 1926/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2782 - f1: 0.7402 - val_loss: 0.2866 - val_f1: 0.0662\n",
      "Epoch 1927/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2767 - f1: 0.7425 - val_loss: 0.2901 - val_f1: 0.0669\n",
      "Epoch 1928/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2764 - f1: 0.7427 - val_loss: 0.2891 - val_f1: 0.0661\n",
      "Epoch 1929/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2777 - f1: 0.7408 - val_loss: 0.2929 - val_f1: 0.0671\n",
      "Epoch 1930/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2772 - f1: 0.7421 - val_loss: 0.2842 - val_f1: 0.0657\n",
      "Epoch 1931/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2790 - f1: 0.7396 - val_loss: 0.2862 - val_f1: 0.0664\n",
      "Epoch 1932/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2777 - f1: 0.7420 - val_loss: 0.2869 - val_f1: 0.0658\n",
      "Epoch 1933/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2787 - f1: 0.7380 - val_loss: 0.2893 - val_f1: 0.0662\n",
      "Epoch 1934/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2775 - f1: 0.7408 - val_loss: 0.2884 - val_f1: 0.0662\n",
      "Epoch 1935/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2768 - f1: 0.7414 - val_loss: 0.2872 - val_f1: 0.0656\n",
      "Epoch 1936/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2773 - f1: 0.7394 - val_loss: 0.2864 - val_f1: 0.0659\n",
      "Epoch 1937/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2774 - f1: 0.7428 - val_loss: 0.2885 - val_f1: 0.0659\n",
      "Epoch 1938/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2770 - f1: 0.7416 - val_loss: 0.2862 - val_f1: 0.0659\n",
      "Epoch 1939/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2751 - f1: 0.7427 - val_loss: 0.2881 - val_f1: 0.0657\n",
      "Epoch 1940/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2761 - f1: 0.7445 - val_loss: 0.2876 - val_f1: 0.0657\n",
      "Epoch 1941/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2769 - f1: 0.7438 - val_loss: 0.2876 - val_f1: 0.0661\n",
      "Epoch 1942/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2768 - f1: 0.7425 - val_loss: 0.2902 - val_f1: 0.0666\n",
      "Epoch 1943/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2777 - f1: 0.7425 - val_loss: 0.2932 - val_f1: 0.0668\n",
      "Epoch 1944/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2761 - f1: 0.7434 - val_loss: 0.2911 - val_f1: 0.0665\n",
      "Epoch 1945/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2768 - f1: 0.7419 - val_loss: 0.2842 - val_f1: 0.0658\n",
      "Epoch 1946/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2765 - f1: 0.7437 - val_loss: 0.2864 - val_f1: 0.0657\n",
      "Epoch 1947/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2761 - f1: 0.7434 - val_loss: 0.2881 - val_f1: 0.0658\n",
      "Epoch 1948/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 12s 74us/step - loss: 0.2782 - f1: 0.7415 - val_loss: 0.2941 - val_f1: 0.0670\n",
      "Epoch 1949/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2769 - f1: 0.7427 - val_loss: 0.2859 - val_f1: 0.0663\n",
      "Epoch 1950/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2786 - f1: 0.7395 - val_loss: 0.2875 - val_f1: 0.0661\n",
      "Epoch 1951/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2770 - f1: 0.7423 - val_loss: 0.2915 - val_f1: 0.0665\n",
      "Epoch 1952/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2782 - f1: 0.7425 - val_loss: 0.2861 - val_f1: 0.0660\n",
      "Epoch 1953/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2777 - f1: 0.7427 - val_loss: 0.2918 - val_f1: 0.0669\n",
      "Epoch 1954/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2774 - f1: 0.7420 - val_loss: 0.2908 - val_f1: 0.0661\n",
      "Epoch 1955/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2775 - f1: 0.7426 - val_loss: 0.2890 - val_f1: 0.0662\n",
      "Epoch 1956/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2771 - f1: 0.7423 - val_loss: 0.2905 - val_f1: 0.0664\n",
      "Epoch 1957/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2780 - f1: 0.7393 - val_loss: 0.2925 - val_f1: 0.0673\n",
      "Epoch 1958/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2778 - f1: 0.7409 - val_loss: 0.2862 - val_f1: 0.0658\n",
      "Epoch 1959/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2777 - f1: 0.7413 - val_loss: 0.2870 - val_f1: 0.0657\n",
      "Epoch 1960/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2792 - f1: 0.7418 - val_loss: 0.2866 - val_f1: 0.0659\n",
      "Epoch 1961/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.2769 - f1: 0.7422 - val_loss: 0.2900 - val_f1: 0.0668\n",
      "Epoch 1962/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2790 - f1: 0.7381 - val_loss: 0.2856 - val_f1: 0.0660\n",
      "Epoch 1963/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2780 - f1: 0.7408 - val_loss: 0.2892 - val_f1: 0.0660\n",
      "Epoch 1964/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2773 - f1: 0.7417 - val_loss: 0.2890 - val_f1: 0.0663\n",
      "Epoch 1965/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2762 - f1: 0.7438 - val_loss: 0.2902 - val_f1: 0.0665\n",
      "Epoch 1966/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2766 - f1: 0.7407 - val_loss: 0.2903 - val_f1: 0.0666\n",
      "Epoch 1967/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2772 - f1: 0.7409 - val_loss: 0.2887 - val_f1: 0.0662\n",
      "Epoch 1968/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2771 - f1: 0.7439 - val_loss: 0.2897 - val_f1: 0.0665\n",
      "Epoch 1969/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2777 - f1: 0.7408 - val_loss: 0.2895 - val_f1: 0.0663\n",
      "Epoch 1970/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2759 - f1: 0.7425 - val_loss: 0.2908 - val_f1: 0.0665\n",
      "Epoch 1971/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2779 - f1: 0.7409 - val_loss: 0.2859 - val_f1: 0.0653\n",
      "Epoch 1972/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2764 - f1: 0.7410 - val_loss: 0.2886 - val_f1: 0.0667\n",
      "Epoch 1973/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2759 - f1: 0.7433 - val_loss: 0.2913 - val_f1: 0.0665\n",
      "Epoch 1974/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2767 - f1: 0.7421 - val_loss: 0.2922 - val_f1: 0.0667\n",
      "Epoch 1975/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2769 - f1: 0.7416 - val_loss: 0.2875 - val_f1: 0.0658\n",
      "Epoch 1976/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2768 - f1: 0.7427 - val_loss: 0.2887 - val_f1: 0.0664\n",
      "Epoch 1977/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2776 - f1: 0.7421 - val_loss: 0.2918 - val_f1: 0.0667\n",
      "Epoch 1978/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2779 - f1: 0.7413 - val_loss: 0.2946 - val_f1: 0.0674\n",
      "Epoch 1979/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2763 - f1: 0.7438 - val_loss: 0.2899 - val_f1: 0.0662\n",
      "Epoch 1980/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2781 - f1: 0.7388 - val_loss: 0.2866 - val_f1: 0.0658\n",
      "Epoch 1981/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2768 - f1: 0.7439 - val_loss: 0.2928 - val_f1: 0.0667\n",
      "Epoch 1982/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2775 - f1: 0.7406 - val_loss: 0.2931 - val_f1: 0.0671\n",
      "Epoch 1983/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2771 - f1: 0.7428 - val_loss: 0.2888 - val_f1: 0.0660\n",
      "Epoch 1984/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2767 - f1: 0.7407 - val_loss: 0.2884 - val_f1: 0.0662\n",
      "Epoch 1985/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2759 - f1: 0.7445 - val_loss: 0.2902 - val_f1: 0.0666\n",
      "Epoch 1986/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2768 - f1: 0.7415 - val_loss: 0.2905 - val_f1: 0.0660\n",
      "Epoch 1987/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2767 - f1: 0.7402 - val_loss: 0.2927 - val_f1: 0.0669\n",
      "Epoch 1988/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2763 - f1: 0.7434 - val_loss: 0.2878 - val_f1: 0.0663\n",
      "Epoch 1989/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2770 - f1: 0.7420 - val_loss: 0.2878 - val_f1: 0.0657\n",
      "Epoch 1990/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2771 - f1: 0.7406 - val_loss: 0.2842 - val_f1: 0.0655\n",
      "Epoch 1991/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2781 - f1: 0.7405 - val_loss: 0.2902 - val_f1: 0.0664\n",
      "Epoch 1992/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2766 - f1: 0.7426 - val_loss: 0.2853 - val_f1: 0.0657\n",
      "Epoch 1993/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2765 - f1: 0.7414 - val_loss: 0.2917 - val_f1: 0.0668\n",
      "Epoch 1994/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2791 - f1: 0.7393 - val_loss: 0.2903 - val_f1: 0.0664\n",
      "Epoch 1995/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2774 - f1: 0.7425 - val_loss: 0.2870 - val_f1: 0.0662\n",
      "Epoch 1996/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2761 - f1: 0.7437 - val_loss: 0.2916 - val_f1: 0.0669\n",
      "Epoch 1997/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2771 - f1: 0.7399 - val_loss: 0.2899 - val_f1: 0.0663\n",
      "Epoch 1998/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2762 - f1: 0.7438 - val_loss: 0.2899 - val_f1: 0.0663\n",
      "Epoch 1999/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2764 - f1: 0.7437 - val_loss: 0.2872 - val_f1: 0.0662\n",
      "Epoch 2000/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2770 - f1: 0.7422 - val_loss: 0.2882 - val_f1: 0.0661\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEYCAYAAACz2+rVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XeYFeX5//H3zdKLSFmN0kEUqQILggYbqNgoGqNEY5fYTYxRE6MSk/hN/KUYjVHRKGpUrCAmGCwBKwqLAipFQUCWuvRedrl/fzyzZw/L2d2zy54t7Od1Xec6M3Om3FPO3PM808zdERERAahR0QGIiEjloaQgIiIxSgoiIhKjpCAiIjFKCiIiEqOkICIiMUoKlYCZtTUzN7OaKRr/ZWb2YSrGXcQ065nZx2Z2ZimGfdPMLk1FXOXBzH5lZk9UdBwHIjMbZWb/ippbm9kWM0srrt/9nOYgM1trZheZ2d/MrPv+jrMyU1IoA2Y2yczuTdB9qJmtTNXOvpJ7DPiTu0/M65Dsn9Tdz3D3p1MaXSHMbIyZ/W5/xuHu97n7VWUVU3kws5PMLKui4ygJd//O3Ru6e26KJ3USMBgYBLQDvkzx9CpUddxZpcIY4D4zu8f3vhvwx8Bz7p6TqgmbWc1Ujr+03P2Skg5jZgaYu+9JQUhlorIub0kdd/911Hh5hQZSTlRSKBvjgabAgLwOZtYEOBt4Jmo/y8w+N7NNZrbUzEYVNjIzO9zMJpjZOjNbYGZXx/02ysxeMbN/mdkm4LIEwzeLht9kZtOADgV+/1sUwyYzm2FmAwqOI67fMWb2j6hKZ4uZfWRm3zOzB8xsvZnNM7OeBWJ/1cyyzWyRmd0UdR8M/Aq4IBrPrKj7FDP7vZl9BGwD2kfdroob59VmNtfMNpvZHDPrFXW/w8wWxnUfXth8JMPMRgIXAbdFMb4RdV9sZreb2Wxgq5nVLGw+o/7jqzjyqgYvNbPvzGyNmd0Z129fM5tqZhvMbIWZ/d3Masf97mZ2nZl9E83nb82sQzTMJjN7qUD/Z5vZzGh8H8dXdUTzcauZzTazjWb2opnVNbMGwJvA4dF8b4nmr060npdHnwfMrE4Ry++KaD2tt1B6blNIf/81sxsKdJtlZudGzUltn1ag2tXM2pnZe9FyehtoXqD/ly2U3Dea2ftm1iXut3pm9mczWxL9/qGZ1UtiuMZm9ky0HSwxs1+bWdXer7q7PmXwAR4Hnohr/wkwM679JKAbIRF3B1YBw6Lf2gIO1Iza3wP+AdQFjgGygYHRb6OA3cCwaFz1EsQyFngJaAB0BZYBH8b9fjHQjFBS/DmwEqhbyHyNAdYAvaN4/gcsAi4B0oDfAZOjfmsAM4C7gdpAe+Bb4PS42P9VYPxTgO+ALlE8taJuV0W/nx/F3wcw4AigTdxvh0fTvQDYChy2n+txDPC7At0WAzOBVkC9ksxn3Lp9PBq2B7ATODr6vTfQL5r3tsBc4Kdx03ZgAnBQtIx2Au9G02wMzAEujfrtBawGjo3WzaVR7HXi5mNatMyaRtO6Jm77zCow3/cCnwCHAOnAx8BvC1luw4AFwNHRvPwa+LiQfi8BPopr7wxsiIuz0O2zkGWb97+ZCvwFqAOcAGwmbnsDrgAaRb8/wN7/z4cJ212LaNkdFxdPUcM9A7we/d4W+Bq4sqL3R/v1H6joAA6UD/B9YCPRThr4CPhZEf0/APw1ao5t3IQdTy7QKK7f/wPGRM2jgPeLGG8aIWl0iut2H3FJIcEw64Eehfw2Bng8rv1GYG5cezdgQ9R8LPBdgeF/CTwVF3uipHBvgm55SWEScHOS62AmMHQ/1+MYEieFK+Lak57PuHXbMq7facCFhUz/p8C4uHYHjo9rnwHcHtf+Z+CBqPkRCuy0gfnAiXHzcXHcb/cDj0bNJ7FvUlgInBnXfjqwuJC43yRuZ0hInNuIEniBfhsREnibqP33wJPJbJ+FLNuaQGsgB2gQN9zzBbe3uN8OjoZtHMW6nUL+A0UMl0ZI0p3jfv8JMGV/tsGK/lTtYk4l4u4fEo7oh5pZe8KR7fN5v5vZsWY2OSpmbgSuoUDxNnI4sM7dN8d1W0I4gsmztIhQ0gl/kvh+lsT3YGY/j4r5G81sA2EDTxRLnlVxzdsTtDeMmtsQqiA25H0IVUaHFjFuKHp+WhF2Tvsws0viqko2EEpF+8xHVA2ypcDn/WJiKirG0sznyrjmbUTLzMyONLN/R9UTmwgJvOA8lGT5/7xAXK0I21SRcRTicPbedpYUGFe8NsDf4qa7jlCya1Gwx2jb/g9wYdTpQuC5vN9LsX3mxbre3bcWiDdvnGlm9gcL1Y2bCAmSaLzNCaXgfbazJIarzb7LaJ95rkqUFMrWM4Si8Y+Bt9w9/s/7PKEaoJW7NwYeJfxpCloONDWzRnHdWhOqUPIU9WjbbMIRU6sCwwMQ1c/eDvwQaOLuBxNKOIliKamlwCJ3Pzju08jd8y5LLSzuouZnKQXOiQBE9dWPAzcAzaL5+JIE8+HuOz1cpRL/OaGEscR3L24+S+IRYB7Q0d0PIiSX0q6LpcDvC8RV391fSGLYRPO9nLCzz9M66lbYtH9SYNr13P3jQvp/ARhhZv0J1WqTYb+2zxVAk+j8SHy8eX4EDCVcQdSYUMogGu8aYAcJtrMkhtvNvsso/r9a5SgplK1nCBvP1UDBSyobEUoAO8ysL2Fj24e7LyXU3f5fdBKwO3AlcUdSRfFwed5rwCgzq29mnQl1y/Fx5BCSR00zu5tQX10WpgGbLJyUrRcdZXU1sz7R76uAtiU8EfcEcKuZ9bbgiCghNCDsyLIBzOxyQklhf60i1NcXpbj5LIlGwCZgi5l1Aq4txTjyPA5cE5VKzcwaWLjAoVGxQ4b5bmZmjeO6vQD82szSzaw54RxKYZcUPwr8Mu8kbHQC9vwipjeRsDO9F3jR8684K9X26e5LgEzgN2ZW28y+D5wT10sjQlXPWqA+oUSWN+we4EngLxZOsKeZWX8LJ9WLGi6XcO7u92bWKNoub6HwZVQlKCmUIXdfTNihNyCUCuJdB9xrZpsJf66XihjVCMIRyXJgHHCPu79dglBuIFQLrCTUkT8V99skQv3v14Si7g6Krr5JWvQnOYdwcnwR4UjqCcIRFsDL0fdaM/ssyXG+TKhzfp5w4nA80NTd5xDq06cSdmjdCOdx9tc/gc5RNcj4QmIqbj5L4lbCAcJmwk79xdIEHcWVSTgg+TuhHn4BCa5OK2TYeYQk8G0074cTLiLIBGYDXwCfRd0SDT8O+CMwNqpm+RI4o4jp7SQcvAwirpqV/ds+f0Q437MOuIfoyr/IM9H4lhFOzn9SYNhbCfM4k5CU/kjYPxY33I2E8yPfAh9G8/JkkvFWShadHBERqfbMzIC3gMGe+pviKiWVFERECPcqEK4oSiPcuVwtKSmIiARHE05qN6KMqlSrIlUfiYhIjEoKIiISU+UeiNe8eXNv27ZtRYchIlKlzJgxY427pxfXX5VLCm3btiUzM7OiwxARqVLMbEnxfan6SERE4igpiIhIjJKCiIjEKCmIiEiMkoKIiMQoKYiISIySgoiIxCgpiIgkY/Nm2LWrdMO6Q3Z2aH7lFVhY4CVvy5aFfgrKzc3vd8+efX9PASUFEal4O3dCTs7e7Zs27dvfV1/tvXPcvRtefRUefjh0nz8fHn007GD/9jf4y19g40bIyoJ16+BPfwIzeOONMLw7PPQQfP45dOsWfjvooPD9n//AlClwzjlw6KGhe506cN550LAhtGgR+kv0eeIJ+MUv4IUXoF07qFEDDjkk/Hb++XDEEXv337Jl6KfgeGrWzO83LS3EmWJV7oF4GRkZrjuaRZK0a1fYmaSl7fube9hhHnxwfrdNm6B9exg2DH7zm7DTbdsW3nkHFi2CadPg2muhTRto1gymToW//hWuuSb026QJNGgAs2eHnWy3bjB0aNgh//SnMGkSjB4NgwfDf/8LGRmwZg0sXhymf/TRYdz//W95LJ2q59FH4Sc/KdWgZjbD3TOK7U9JQaQC5ebC9u3hyHPx4rBTbtMm7MRr1YLatcNRonvY0TZpAq+9Bv37Q4cO+cPfcw9ceWXY8R5+eDjKlcrnpZdCiejuu2HBgvzut90GXbvC88/nJ8QxY+Cyy0KS3boVrrgC/vnPUk9aSUEkFbKywvehh4ad9hdfQP36obrjxhuhZ0+4806YOBHmzIH77ks8nkMOgdWryy/uyqxly/zlmqdxYzjySJg+PbTfckuoCvr5z+H11/Orhxo1CjvSH/4wVNV8//thR5pnyxZ47z249dZQkrn99lAdtHNnSKa1aoXqHTNYuTKsyzfegAEDoHXrcB5g1iwYNChMc9euUIUEYXy5uVC3bmjftCns8Js2zZ/+5s1hnBCGr5ngcXPbtuX3A2GcZqE6qQwpKciBb+JEOOWU/D9lIuvWhTrgO++EgQPh3XdDFcidd4aqjHHjQpG8oMMOC3XUq1alLv6KdvjhcNxx4cRnvAcfDHXi550XjlAXLAill3btwg5sypRQMtm9G2bMCMuoVi341a9gxw7497/hwgvDTq1GjbAz/O670LxpE7z4Yhi+YJVWdnZIBrVr53fbtAm++QZ69y7ZvO3ZE3b6DRqUatEciJQUpOpavToc4U2aFE7m5R2dDR4cjiiHDw9Hb3keeSTUcx95JHz9dcXFnYzhw0MiKszXX4dqoh/8AI45Bm66Key8Bw8OO96zzgp1+G3awIYN4Qjz3ntDnX6NGmFHeMQR4XvmzFDNlJMTdsBmRce2a1c4Wm7dumznWSoFJQWpWDt3hp36aaeFI8nWrcNOKTs77MCvvjrs/G++OdSvrlwJf/xjRUedWK1acOyx4dLAFSvC0WyTJmHnPGQIfPllODLduDGcWG3YMOywIVQTbdgQklq9ehU7H1KtKSlI2frkE1i7NpzcXL8+HLHXrx+qFAYODDvEOnXyd4aVwTXXhDivvDIcadetG66Wef/9UAI599z8utx168KOPjc3cb2vSBWXbFLQ1i/5NmzIv5ywVSu4/3545pmw4582rfjht28vmzjOPx/mzYMHHgjnAC65JNRfv/02XH992GkvXBiqSSBUx5x5ZtHnFvL07x8+BeWdHFRCkGpOJYUD3caN4Yaevn3zu7nnX9lw/PHw0UdlP92TT4bJk0Pz0KHhWvRu3cJJ3ZdfDte8N20Kp54K6emwfHk4ek9mxy4iJVYpSgpmNhj4G5AGPOHufyjw+1+Bk6PW+sAh7n4wUnruoa5++vSQEC6+uOj+S5oQBgyADz4IzXffHdoHDgzXUN9yS9jx59m5M5zgjD/6fuihxEfjHTqULA4RSYmUJQUzSwMeBk4FsoDpZjbB3efk9ePuP4vr/0agZ6riOaB89124IqVmzXCJYJcu+XeElkaNGuFE6UEHhRtmatcO13s3bhx+3707nGwtylNP7dst73rueKqeEanUUvkP7QsscPdvAcxsLDAUmFNI/yOAe1IYT9X3zTfhaPzf/96/8QwfHqps/vrXvW+aKUxxCUFEDhipTAotgKVx7VnAsYl6NLM2QDvgf4X8PhIYCdC6OlxDnZsbqmOuvhoeewz+9a+SDd+vX7haCOB//4NevfKP+kVEipDKpJDoTpnCzmpfCLzi7rmJfnT30cBoCCeayya8SmTr1lANlJ4ebtm/6KLQ/ZlnCh+mefOwo+/UCZ5+OjycbO3a8A2huUaNcJmliEiSUpkUsoBWce0tgeWF9HshcH0KY6mc8h4BfPDBez82OJGGDcMjHX7841BXf/bZ+96hmpcQCjaLiCQplUlhOtDRzNoBywg7/h8V7MnMjgKaAFNTGEvl4R6elHj33cU/kqF2bVi6NJQK8p6vLiKSQilLCu6eY2Y3AJMIl6Q+6e5fmdm9QKa7T4h6HQGM9ap2w0RJuENmZrgu//zzC39RxkcfhSqkdu10lY6IVIiU7nncfSIwsUC3uwu0j0plDBVq+/bwFMkBAwrvZ/r0kDT69Cm/uERECqHD0VRZsyYc9SeyaFG4vPTUU8s3JhGRYugdzWVp5sxwxZBZ4oTQp084udy2rRKCiFRKKimUpZ4JbsiePz/cfdywYfnHIyJSQioplIWsrH2vDHrmmfB4iCOPVEIQkSpDSWF//P73IRm0irsdo0uXcPL4xz/WFUQiUuVor1UamzaF+wz+9re9u0+bpquIRKRKU1IojYLPEfr738PLX0REqjglhZJw3/fxEbm5+S+sERGp4rQ3S9asWWHnv359aG/YMDzETglBRA4g2qMl48sv4Zhj8ttvuw02b4Z69SouJhGRFFD1UXFycvZ+xeSWLeHl9iIiByCVFIozaVJ+87JlSggickBTSaEwM2ZARkZ+++jR4c5kEZEDmEoKhYlPCD/6UXg1pojIAU4lhUSWx70g7uOPoX//iotFRKQcqaSQyHHHhe8TTlBCEJFqRUkh3s6d8JOfwJIlof211yo2HhGRcqbqozy5uVC3bmg+6qjwykzdhyAi1YxKCnneey+/ecoUJQQRqZaUFCDcizBwYGieNw++972KjUdEpIKkNCmY2WAzm29mC8zsjkL6+aGZzTGzr8zs+VTGk9CcOTB4cGhOTw8vxRERqaZSlhTMLA14GDgD6AyMMLPOBfrpCPwSON7duwA/TVU8+3CHK68ML8XJs2jRvm9QExGpRlJZUugLLHD3b919FzAWGFqgn6uBh919PYC7r05hPEFOTnj3QY0a8OSToVt6euiuR1iISDWXyqTQAlga154VdYt3JHCkmX1kZp+Y2eBEIzKzkWaWaWaZ2dnZpY/ommugVi34xz/yu40fD6tXQ1pa6ccrInKASGVSSFQP4wXaawIdgZOAEcATZnbwPgO5j3b3DHfPSE9PL31Ejz2W33zMMeHO5aEFCy8iItVXKpNCFhD3RntaAssT9PO6u+9290XAfEKSKHs7doTv44+H7dvDfQiHHZaSSYmIVFWpTArTgY5m1s7MagMXAhMK9DMeOBnAzJoTqpO+TUk0CxeG7+uuy79JTURE9pKypODuOcANwCRgLvCSu39lZvea2ZCot0nAWjObA0wGfuHua1MS0KJF4bt9+5SMXkTkQJDSx1y4+0RgYoFud8c1O3BL9EmtvOqjhg1TPikRkaqq+tzRvGtX+K5Vq2LjEBGpxKpPUti9O3zXrl2xcYiIVGLVJymopCAiUqzqkxRUUhARKVb1SQoqKYiIFKv6JAWVFEREilV93rx23nlw9NG6cU1EpAjVJym0b68b10REilF9qo9ERKRYSgoiIhKjpCAiIjFKCiIiEqOkICIiMUoKIiISo6QgIiIxSgoiIhKjpCAiIjFKCiIiEqOkICIiMUoKIiISk9KkYGaDzWy+mS0wszsS/H6ZmWWb2czoc1Uq4xERkaKl7CmpZpYGPAycCmQB081sgrvPKdDri+5+Q6riEBGR5BVbUrDgYjO7O2pvbWZ9kxh3X2CBu3/r7ruAscDQ/QtXRERSKZnqo38A/YERUftmQgmgOC2ApXHtWVG3gs4zs9lm9oqZtUpivCIikiLJJIVj3f16YAeAu68HknmnpSXo5gXa3wDaunt34B3g6YQjMhtpZplmlpmdnZ3EpEVEpDSSSQq7o/MDDmBm6cCeJIbLAuKP/FsCy+N7cPe17r4zan0c6J1oRO4+2t0z3D0jPT09iUmLiEhpJJMUHgTGAYeY2e+BD4H7khhuOtDRzNqZWW3gQmBCfA9mdlhc6xBgblJRi4hIShR79ZG7P2dmM4CBhCqhYe5e7M7b3XPM7AZgEpAGPOnuX5nZvUCmu08AbjKzIUAOsA64rPSzIiIi+8vcC1bzRz+YNS1qQHdfl5KIipGRkeGZmZkVMWkRkSrLzGa4e0Zx/RVVUphBOI9gQGtgfdR8MPAd0K4M4hQRkUqk0HMK7t7O3dsTqn/Ocffm7t4MOBt4rbwCFBGR8pPMieY+7j4xr8Xd3wROTF1IIiJSUZJ5zMUaM/s18C9CddLFwNqURiUiIhUimZLCCCCdcFnqeOAQ8u9uFhGRA0gyl6SuA24uh1hERKSCFZsUojuYbwO6AHXzurv7KSmMS6Ra2r17N1lZWezYsaOiQ5Eqqm7durRs2ZJatWqVavhkzik8B7xIuOroGuBSQA8gEkmBrKwsGjVqRNu2bTFL9PgwkcK5O2vXriUrK4t27Up310Ay5xSaufs/gd3u/p67XwH0K9XURKRIO3bsoFmzZkoIUipmRrNmzfarpJlMSWF39L3CzM4iPNSuZamnKCJFUkKQ/bG/208yJYXfmVlj4OfArcATwM/2a6oickCaOXMmEydOLPT3zMxMbrrpppTGcN99yTyvc19XXXUVc+YUfDFkxSpueaZCsUnB3f/t7hvd/Ut3P9nde0cPsxMR2UtRO7GcnBwyMjJ48MEHUxpDYUnB3dmzp/Cn/j/xxBN07tw5VWGVSqVKCmb2kJk9WNinPIMUkfKxePFiOnXqxFVXXUXXrl256KKLeOeddzj++OPp2LEj06ZNA2Dr1q1cccUV9OnTh549e/L666+za9cu7r77bl588UWOOeYYXnzxRUaNGsXIkSM57bTTuOSSS5gyZQpnn302AFu2bOHyyy+nW7dudO/enVdffRWAa6+9loyMDLp06cI999xTovjvuOMOtm/fzjHHHMNFF13E4sWLOfroo7nuuuvo1asXS5cu5a233qJ///706tWL888/ny1btgBw0kknkfewzYYNG3LnnXfSo0cP+vXrx6pVqwB44403OPbYY+nZsyeDBg2KdR81ahSXXnopp512Gm3btuW1117jtttuo1u3bgwePJjdu0Mt/IwZMzjxxBPp3bs3p59+OitWrIhN+/bbb6dv374ceeSRfPDBBwmX57p16xg2bBjdu3enX79+zJ49e39Wd2LunvBDuMroUmA04R0KN0af94G/FjZcqj+9e/d2kQPVnDlz8ltuvtn9xBPL9nPzzUVOf9GiRZ6WluazZ8/23Nxc79Wrl19++eW+Z88eHz9+vA8dOtTd3X/5y1/6s88+6+7u69ev944dO/qWLVv8qaee8uuvvz42vnvuucd79erl27Ztc3f3yZMn+1lnneXu7rfddpvfHBfPunXr3N197dq17u6ek5PjJ554os+aNasES9C9QYMGe82PmfnUqVPd3T07O9sHDBjgW7ZscXf3P/zhD/6b3/zG3d1PPPFEnz59uru7Az5hwgR3d//FL37hv/3tb2Mx7tmzx93dH3/8cb/lllti83n88cf7rl27fObMmV6vXj2fOHGiu7sPGzbMx40b57t27fL+/fv76tWr3d197Nixfvnll8emnTeu//znPz5w4EB3932W5w033OCjRo1yd/d3333Xe/TokXAZ7LUdRQivLCh2H1voiWZ3fxrAzC4DTnb33VH7o8BbZZ+eRKQyaNeuHd26dQOgS5cuDBw4EDOjW7duLF68GIC33nqLCRMm8Kc//QkIV0199913Ccc3ZMgQ6tWrt0/3d955h7Fjx8bamzRpAsBLL73E6NGjycnJYcWKFcyZM4fu3buXen7atGlDv37hgslPPvmEOXPmcPzxxwOwa9cu+vfvv88wtWvXjpVoevfuzdtvvw2ES4YvuOACVqxYwa5du/a67POMM86gVq1adOvWjdzcXAYPHgwQW27z58/nyy+/5NRTTwUgNzeXww7Lf8/YueeeG5te3nIu6MMPP4yVqE455RTWrl3Lxo0bady4camXT0HJXH10ONCI8BIcgIZRNxFJpQceqJDJ1qlTJ9Zco0aNWHuNGjXIyckBQg3Dq6++ylFHHbXXsJ9++uk+42vQoEHC6bj7PlfKLFq0iD/96U9Mnz6dJk2acNlll+1zeeXSpUs555xzALjmmmu45ppripyf+Om7O6eeeiovvPBCkcPUqlUrFltaWlpsvm+88UZuueUWhgwZwpQpUxg1alRsmPjlFD983nJzd7p06cLUqVMTTjNv+PjpFeQJ3n9T1lerJXP10R+Az81sjJmNAT4juddxisgB6vTTT+ehhx6K7aQ+//xzABo1asTmzZuTGsdpp53G3//+91j7+vXr2bRpEw0aNKBx48asWrWKN998c5/hWrVqxcyZM5k5c2bChFCrVq1YHX5B/fr146OPPmLBggUAbNu2ja+//jqpeAE2btxIixYtAHj66aeTHg7gqKOOIjs7O5YUdu/ezVdffVXkMAWX5wknnMBzzz0HwJQpU2jevDkHHXRQieIoTjJXHz0FHEt4IN44oH9e1ZKIVE933XUXu3fvpnv37nTt2pW77roLgJNPPpk5c+bETowW5de//jXr16+na9eu9OjRg8mTJ9OjRw969uxJly5duOKKK2LVPCUxcuRIunfvzkUXXbTPb+np6YwZM4YRI0bETtbOmzcv6XGPGjWK888/nwEDBtC8efMSxVW7dm1eeeUVbr/9dnr06MExxxzDxx9/XOQwBZfnqFGjyMzMpHv37txxxx0lTkzJKOp1nJ3cfZ6Z9Ur0u7t/VubRJEGv45QD2dy5czn66KMrOgyp4hJtR2XxOs5bgJHAnxP85oAeiCcicoAp6uqjkdH3yaUduZkNBv4GpAFPuPsfCunvB8DLhLe8qRggIlJBij2nYGazzOyXZtahJCM2szTgYeAMoDMwwsz2uV3QzBoBNwH7XrYgIiLlKpmrj4YAucBLZjbdzG41s9ZJDNcXWODu37r7LmAsMDRBf78F7gf0AHkRkQqWzNVHS9z9fnfvDfwI6A4sSmLcLYClce1ZUbcYM+sJtHL3fycfsoiIpEoyN69hZm2BHwIXEEoNtyUzWIJusUudzKwG8FfgsiSmP5Jw0pvWrZMppIiISGkkc07hU+A1wsni8929r7snuiKpoCygVVx7S8K7GPI0AroCU8xsMeHFPRPMbJ9Lptx9tLtnuHtGenp6EpMWkYpQGR6dXVJt27ZlzZo1ABx33HEJ+7nssst45ZVXyjOsCpNMSeFSd0/+7o5804GOZtYOWAZcSKh+AsDdNwKxuz/MbApwq64+Eqm6Zs6cSWZmJmeeeeY+v+U9Ojsjo9hL5StMcTeTVQdFPTr74qjxTDO7peCnuBG7ew5wAzAJmAu85O5fmdlTbIMnAAAXKUlEQVS9ZjakTKIXkTJV1R+d/cgjj3Dbbfm122PGjOHGG28EYNiwYfTu3ZsuXbowevTohMM3bNgQCM8YuuGGG+jcuTNnnXUWq1evjvVz77330qdPH7p27crIkSNjj/pYsGABgwYNokePHvTq1YuFCxeyZcsWBg4cSK9evejWrRuvv/56bDx/+ctf6Nq1K127duWBCnrOVUKFPT4V+En0fU+Cz93JPII1FR89OlsOZPGPPK6AJ2dX+Udnr1692jt06BBrHzx4sH/wwQd7jXfbtm3epUsXX7Nmjbu7t2nTxrOzs909/7Hbr776qg8aNMhzcnJ82bJl3rhxY3/55Zf3Go+7+8UXXxx7xHbfvn39tddec3f37du3+9atW3337t2+ceNGdw+P7e7QoYPv2bPHMzMzvWvXrr5lyxbfvHmzd+7c2T/77LOk57M4qXp09mNR4zvu/lH8b2ZW8geSiEiVUJUfnZ2enk779u355JNP6NixI/Pnz489P+nBBx9k3LhxQHjS6jfffEOzZs0Sjuf9999nxIgRpKWlcfjhh3PKKfkPcJg8eTL3338/27ZtY926dXTp0oWTTjqJZcuWMXz4cADq1q0LhIfe/epXv+L999+nRo0aLFu2jFWrVvHhhx8yfPjw2BNczz33XD744AN69uyZ1HymUjLnFB4CCj7/KFE3ESlDFVWjUNUfnX3BBRfw0ksv0alTJ4YPH46ZMWXKFN555x2mTp1K/fr1Oemkk/YZb0GJHkm9Y8cOrrvuOjIzM2nVqhWjRo1ix44dCR9pDfDcc8+RnZ3NjBkzqFWrFm3bti2y/8qgqHMK/c3s50B6gfMJowhXIolINVWZH5197rnnMn78eF544QUuuOACIDzyukmTJtSvX5958+bxySefFBnbCSecwNixY8nNzWXFihVMnjwZIJZImjdvzpYtW2JXJB100EG0bNmS8ePHA7Bz5062bdvGxo0bOeSQQ6hVqxaTJ09myZIlsfGPHz+ebdu2sXXrVsaNG8eAAQOSWm6pVtQlqbUJL9SpSbh8NO+zCfhB6kMTkcqqMj86u0mTJnTu3JklS5bQt29fAAYPHkxOTg7du3fnrrvuir2JrTDDhw+nY8eOdOvWjWuvvZYTTzwRgIMPPpirr76abt26MWzYMPr06RMb5tlnn+XBBx+ke/fuHHfccaxcuZKLLrqIzMxMMjIyeO655+jUqRMAvXr14rLLLqNv374ce+yxXHXVVZWi6giKeHQ2xJ5f9KK7V5okoEdny4FMj86WsrA/j84u8uY1d88Fmu5feCIiUlUkc6L5czObQHi09da8ju7+WsqiEhGRCpFMUmgKrGXvl+o44dEXIiJyACk2Kbj75eURiIgEiS7VFEnW/l7umswD8Y40s3fN7MuovbuZ/Xq/pioiCdWtW5e1a9dW6uvYpfJyd9auXRu7ea40kqk+ehz4BfBYNNHZZvY88LtST1VEEmrZsiVZWVlkZ2dXdChSRdWtW5eWLVuWevhkkkJ9d59WoDibU+opikihatWqRbt27So6DKnGknkd55ro/cwOYGY/AFakNCoREakQyZQUrgdGA53MbBnhVZwXFz2IiIhURclcffQtMMjMGgA13D25B5uIiEiVk8zVR/eZ2cHuvtXdN5tZEzPTSWYRkQNQMucUznD3DXkt7r4e2PddeyIiUuUlkxTSzCz2gHUzqwfUKaJ/ERGpopI50fwv4F0zeypqvxx4OnUhiYhIRUnmRPP9ZjYbGAQY8F+gTaoDExGR8pdM9RHASmAPcB4wEJibzEBmNtjM5pvZAjO7I8Hv15jZF2Y208w+NLPOSUcuIiJlrtCSgpkdCVwIjCA8JfVFwkt5Tk5mxNELeh4GTgWygOlmNsHd58T19ry7Pxr1PwT4CzC4NDMiIiL7r6iSwjxCqeAcd/++uz8E5JZg3H2BBe7+rbvvAsYCQ+N7cPdNca0NiO6aFhGRilFUUjiPUG002cweN7OBhHMKyWoBLI1rz4q67cXMrjezhcD9wE0lGL+IiJSxQpOCu49z9wuATsAU4GfAoWb2iJmdlsS4EyWQfUoC7v6wu3cAbgcSPpLbzEaaWaaZZerpkSIiqVPsieboTubn3P1soCUwE9jnpHECWUCruPaWwPIi+h8LDCskhtHunuHuGenp6UlMWkRESiPZq48AcPd17v6Yu59SfN9MBzqaWTszq004aT0hvgcz6xjXehbwTUniERGRspXMzWul4u45ZnYDMAlIA55096/M7F4g090nADeY2SBgN7AeuDRV8YiISPFSlhQA3H0iMLFAt7vjmm9O5fRFRKRkSlR9JCIiBzYlBRERiVFSEBGRGCUFERGJUVIQEZEYJQUREYlRUhARkRglBRERiVFSEBGRGCUFERGJUVIQEZEYJQUREYlRUhARkRglBRERiVFSEBGRGCUFERGJUVIQEZEYJQUREYlRUhARkRglBRERiUlpUjCzwWY238wWmNkdCX6/xczmmNlsM3vXzNqkMh4RESlaypKCmaUBDwNnAJ2BEWbWuUBvnwMZ7t4deAW4P1XxiIhI8VJZUugLLHD3b919FzAWGBrfg7tPdvdtUesnQMsUxiMiIsVIZVJoASyNa8+KuhXmSuDNFMYjIiLFqJnCcVuCbp6wR7OLgQzgxEJ+HwmMBGjdunVZxSciIgWksqSQBbSKa28JLC/Yk5kNAu4Ehrj7zkQjcvfR7p7h7hnp6ekpCVZERFKbFKYDHc2snZnVBi4EJsT3YGY9gccICWF1CmMREZEkpCwpuHsOcAMwCZgLvOTuX5nZvWY2JOrt/wENgZfNbKaZTShkdCIiUg5SeU4Bd58ITCzQ7e645kGpnL6IiJSM7mgWEZEYJQUREYlRUhARkRglBRERiVFSEBGRGCUFERGJUVIQEZEYJQUREYlRUhARkRglBRERiVFSEBGRGCUFERGJUVIQEZEYJQUREYlRUhARkRglBRERiVFSEBGRGCUFERGJUVIQEZEYJQUREYlRUhARkZiUJgUzG2xm881sgZndkeD3E8zsMzPLMbMfpDIWEREpXsqSgpmlAQ8DZwCdgRFm1rlAb98BlwHPpyoOERFJXs0UjrsvsMDdvwUws7HAUGBOXg/uvjj6bU8K4xARkSSlsvqoBbA0rj0r6lZiZjbSzDLNLDM7O7tMghMRkX2lMilYgm5emhG5+2h3z3D3jPT09P0MS0RECpPKpJAFtIprbwksT+H0RERkP6UyKUwHOppZOzOrDVwITEjh9EREZD+lLCm4ew5wAzAJmAu85O5fmdm9ZjYEwMz6mFkWcD7wmJl9lap4RESkeKm8+gh3nwhMLNDt7rjm6YRqJRERqQR0R7OIiMSktKRQmaxZA1ddBa+/DqeeCp99BjfdBJs2Qfv20KlT+BxyCJjB9u1Qpw7UqlXRkYuIlJ9qkxTGjAkJAeDtt8P3PfckN2xaGhx0EKxfD716wfz5ULs2dOsGs2bBiBHw6KOhW8eO4dO5M+zYAbt2wf/+B6edBps3w0svwZ49cO+9sHRp+HToEJLQ4sXQrh1Mmwbdu8OyZbBkCTRrBjVrhnHUrw+vvRYS2Pe+B7Nnh9imTIGhQ2HnTnjkEbjySliwIEx/5kxo0QKOPBImToR+/eDYY+Hpp8N4Fi+GjAx47z3o3RvOOANWrgwxvfkmHH00DBoEixZB3bph+q1ahaR5/PFheezcCZ98Al26QMuWkJ0NrVuHhDt/fliGGRkhCX/0UYhnzZrwW+fO0LcvHHUU/PvfITE3bQo33xyW5dVXh3lcuBDmzAnLrF69sNyzs2HevLCeataECy4Iy/mrr8KyOe64MGyDBmH9ZWaGZXLccaH/+fPD8l29OsQ6axb07AkbNsCqVWFddOoUYm3cOMzbhg3hwKFdO/juOzjiCPjXv8Ly2rkz9L9tGwwYEOL885/D+mzdGg47DLZuDct50SLIygrDrVkDjRqF+Z07N6y7+vXDMuvaNcxnvXohng0boGHDsOwffzwsq3POCcPn5MCkSWE8Y8fCli1h2ZpBmzYhjpUroUkTmDo1zPeQIZCeDi+8ACedBLt3h2llZYX1lZ0d1s3BB4flc+qpYX0++2yY9kcfhXV25ZVhm5g1Kwybt06nTg3bTI8e8O23oVv//mHZv/NOWH5r1oRYr7gC1q0LB2NNm8LkyWH5nHdeWCY7d4Z5nzYNDj00rMumTcOy2rMnrJ+aNeHrr8N28b3vhW3144/Dem7cOCyLTz8NzXnro0mTMP3p0+GUU8K6W7w49PPZZyHWCy6ADz8M42nWLKyHL7+EwYOhT5+wXa5eHbafr78Owx59dIj7vfegRg045pgw7OzZ8P77YRv7xS/CsnrjjfztrWvXEMvixWFZpKfDpZeG/2Gqr8o391LdOlBhMjIyPDMzs8TDLVgQNsCTTgp/zu3bw8b74YdhY8jJCX+qTz8NG9i4cWUfe+PGsHFj2Y9XRKqHhx+G664r3bBmNsPdM4rrr9qUFI44Inzy1K8fjghOOaX049yzJxxJNW4MubnhKGb58nB0Uq9eOFrMzQ3NdeqEYZYvD/2ZheHr1w9Htjt2hKOGI48E9zDcli3hyNwsDNewYThqWLo0HAk2bRqav/46HN01aRKG37Il/LZnTxhu164wjfT0EGuDBuE7KysctUyYACecEKY5blwYR3Z2+K1Nm1ACatAgHOls3hyOcFeuDEdZeYlu48bQT9Om4eipZs3Q3KRJGKZZM/jii3B09+yzYZyNGsHnn4fptW4d+lm6NHyvWwcrVsDhh4dYBgwIR6dLloT5mD49lBquvjosu7yj2c2bYfz4UIqoVSss908/hTPPDEddaWkh7oYNQ8nBPcQ0Y0Y4Av7ii7D+Nm8O85CdHeJYvjyU6GrXDjEdckiYblZWONJMSwvLe+HCMJ65c8O8r14N774bumVnQ9u2oWSUnh6ONOfODXGvWxfmrU6d0Fy/fljH27aFcS9dGqa7Y0eIa/v2sPzatoUPPghHyN26hXEuXBji/OyzMMzSpWHaAweG7WTDhrC8ly8P661LlzCuvPU3f37YFrKzw3rOzg5H9ps2hfjatAnbVFpa6Pb++2G8V10Vtu3Nm8MBV7NmoTS1fHmIo1GjMO7Vq8M4srJCKWLo0FDK3Lkz9N+nD6xdG9bN/PlhfH37hubmzcP/aPv28L/o1SschXfoEGJt3z60d+4cui1dGv5DHTqEODZvDut6/fqwfJs1C3Ece2woCa1Zk/8f3rUrrPsGDUK88+eH6e3aFf4z7duH7eXkk0P/8+aFEkD37iHGQw4J08vJCetn/vwwno0bw3ysWBHmc/nysHyXLAnrvkmTsH0sWhRKOUuXhhiHDg0lzFSrNiUFEZHqLNmSgq4+EhGRGCUFERGJUVIQEZEYJQUREYlRUhARkRglBRERiVFSEBGRGCUFERGJqXI3r5lZNrCklIM3B9aUYThlRXGVjOIqmcoaF1Te2A7EuNq4e7FPTqpySWF/mFlmMnf0lTfFVTKKq2Qqa1xQeWOrznGp+khERGKUFEREJKa6JYXRFR1AIRRXySiukqmscUHlja3axlWtzimIiEjRqltJQUREiqCkICIiMdUmKZjZYDObb2YLzOyOcpxuKzObbGZzzewrM7s56j7KzJaZ2czoc2bcML+M4pxvZqenOL7FZvZFFENm1K2pmb1tZt9E302i7mZmD0axzTazXimK6ai45TLTzDaZ2U8rYpmZ2ZNmttrMvozrVuLlY2aXRv1/Y2aXpiiu/2dm86JpjzOzg6Pubc1se9xyezRumN7R+l8QxW4piKvE662s/6+FxPViXEyLzWxm1L08l1dh+4eK28bc/YD/AGnAQqA9UBuYBXQup2kfBvSKmhsBXwOdgVHArQn67xzFVwdoF8WdlsL4FgPNC3S7H7gjar4D+GPUfCbwJmBAP+DTclp3K4E2FbHMgBOAXsCXpV0+QFPg2+i7SdTcJAVxnQbUjJr/GBdX2/j+CoxnGtA/ivlN4IwUxFWi9ZaK/2uiuAr8/mfg7gpYXoXtHypsG6suJYW+wAJ3/9bddwFjgaHlMWF3X+Hun0XNm4G5QIsiBhkKjHX3ne6+CFhAiL88DQWejpqfBobFdX/Gg0+Ag83ssBTHMhBY6O5F3cWesmXm7u8D6xJMryTL53TgbXdf5+7rgbeBwWUdl7u/5e45UesnQMuixhHFdpC7T/WwZ3kmbl7KLK4iFLbeyvz/WlRc0dH+D4EXihpHipZXYfuHCtvGqktSaAEsjWvPougdc0qYWVugJ/Bp1OmGqAj4ZF7xkPKP1YG3zGyGmY2Muh3q7isgbLTAIRUUG8CF7P1nrQzLrKTLpyKW2xWEI8o87czsczN7z8wGRN1aRLGUR1wlWW/lvbwGAKvc/Zu4buW+vArsHypsG6suSSFRvV+5XotrZg2BV4Gfuvsm4BGgA3AMsIJQfIXyj/V4d+8FnAFcb2YnFNFvucZmZrWBIcDLUafKsswKU1gc5b3c7gRygOeiTiuA1u7eE7gFeN7MDirHuEq63sp7fY5g7wOPcl9eCfYPhfZaSAxlFlt1SQpZQKu49pbA8vKauJnVIqzw59z9NQB3X+Xuue6+B3ic/OqOco3V3ZdH36uBcVEcq/KqhaLv1RURGyFRfebuq6IYK8Uyo+TLp9zii04wng1cFFVxEFXPrI2aZxDq64+M4oqvYkpJXKVYb+W5vGoC5wIvxsVbrssr0f6BCtzGqktSmA50NLN20dHnhcCE8phwVF/5T2Cuu/8lrnt8XfxwIO+qiAnAhWZWx8zaAR0JJ7dSEVsDM2uU10w4UfllFEPe1QuXAq/HxXZJdAVEP2BjXhE3RfY6gqsMyyxueiVZPpOA08ysSVR1clrUrUyZ2WDgdmCIu2+L655uZmlRc3vC8vk2im2zmfWLttNL4ualLOMq6Xorz//rIGCeu8eqhcpzeRW2f6Ait7H9OXNelT6Es/ZfE7L+neU43e8TinGzgZnR50zgWeCLqPsE4LC4Ye6M4pzPfl7dUExs7QlXdswCvspbLkAz4F3gm+i7adTdgIej2L4AMlIYW31gLdA4rlu5LzNCUloB7CYcjV1ZmuVDqONfEH0uT1FcCwj1ynnb2aNRv+dF63cW8BlwTtx4Mgg76YXA34meclDGcZV4vZX1/zVRXFH3McA1Bfotz+VV2P6hwrYxPeZCRERiqkv1kYiIJEFJQUREYpQUREQkRklBRERilBRERCRGSUEkjpnVMLNJZta6omMRqQi6JFUkjpl1AFq6+3sVHYtIRVBSEImYWS7hhqA8Y939DxUVj0hFUFIQiZjZFndvWNFxiFQknVMQKYaFt3L90cymRZ8jou5tzOzd6JHQ7+adhzCzQy28+WxW9Dku6j4+ekT5V3mPKTezNDMbY2ZfWnij188qbk5FoGZFByBSidSz6JWMkf9z97ynZ25y975mdgnwAOFJpH8nvPDkaTO7AniQ8DKUB4H33H149GC1vNLHFe6+zszqAdPN7FXCW75auHtXAIteoSlSUVR9JBIprPrIzBYDp7j7t9Fjjle6ezMzW0N4uNvuqPsKd29uZtmEk9U7C4xnFOEpoRCSwemEB8FlAhOB/wBveXjEtEiFUPWRSHK8kObC+tmLmZ1EeExzf3fvAXwO1PXw6sQewBTgeuCJsghWpLSUFESSc0Hc99So+WPCs/4BLgI+jJrfBa6F2DmDg4DGwHp332ZmnQgvXcfMmgM13P1V4C7Cy+VFKoyqj0QiCS5J/a+73xFVHz1FeM59DWCEuy+I3qn7JNAcyCY8w/47MzsUGE14X0UuIUF8BownvDd3PpAOjALWR+POO0D7pbvHv1tZpFwpKYgUI0oKGe6+pqJjEUk1VR+JiEiMSgoiIhKjkoKIiMQoKYiISIySgoiIxCgpiIhIjJKCiIjE/H+g2sHVZAZGywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna2.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[24968  2017]\n",
      " [ 1530  1485]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEYCAYAAADh1BXbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XecVNX5x/HPd1kQFBCQooKAYEFRQUAwGpWowV6jiS1iRFFjicZG1ERsUWOLSNToz4YNW1SsSDTEhhQRFSMgKEgXBAUEFPD5/XHOwGXcMsvOzuzOPu993dfOPbede2fmmVNukZnhnHOucorynQHnnCsEHkydcy4LPJg651wWeDB1zrks8GDqnHNZ4MHUOeeywIOpc85lgQdT55zLgmoXTCVNl7RC0rLEsGWcdo+kyZJ+lHRKhutrIul+SfMkLZU0RdKlVboTVUhSV0nvS1oe/3fNYJltJa2U9EgirXc8jsnj3DcxfWRcJjVtcmLaZWnLrYjrah6n/03STElLJM2QdHlafkp9HyXtJGm4pIWSSryiRNJxkj6V9J2kaZL2KmGeKyWZpP3T0veXND4uO1PSr0tYtm9c9rS09G6S3oz7PF/SHxLT/iNpQdznDyUdkbbsCfFYfCfpOUnNEtN2kPSGpG8lTZV0VNqyG0u6Mx6TbyW9WdJxKWE/Pkm8R2vS3s/LMllHKesdKumKMqbXj8fvu7ithZJGSDq6Ats4UNLUDc1jXphZtRqA6cD+pUw7G9gPGAeckuH6HgCeBJoSfjw6AcdkOc/FOTo29YAZwAXARsB5cbxeOcu9BrwFPJJI6w3MKmOZkcBpGeZrIPBGYnx7YJP4ujXwCXB0Ju9jXLYfcET4eP5kW7+M+7x7fD9bA63T5ukIfAzMSX6WgB2Br4CDgGJgM6Bj2rJNgUnAxOT+A83jsifGY98I2CExfZfU5wDoBSwFtojjneP43kBD4DFgaOqzA0wB/gjUAfYFvgO2S6z7EWAo0CLO030DPjsZv58ZrGsocEUZ0+sDBrSJ4y2AU4FFwKUZbuNAYGouvlfZGvKegRIO4nRKCaaJed5O/xKWMe9E4MgypncGRsQ3ej5wWUzfCPh7/ELOia83itN6A7OAS4F5wMMx/VBgAvAN8C6wS5aPTR9gNqBE2pfAgWUscxzhx2QgVRBMAQHTgL6lTG9NCGyXVOR9BLah5GD6LtCvnDy9Ahyc/lmKQeyacpa9G/h9+v4Df029zxkck57ASqBnYtnHEtM7Aj8QAvJOwLK09/S1VD4JPy5LgMaV/OyU+H4CZwCT4+f/JeIPEyFoDwYWAN8CH8a8nAesAr6P+X6qhHWuF0wT6ScBy1P7Erc9ifBDMxU4NaZvBqwAfozbWBbT9gRGx/zMAW4jRwWZTIZqV82vAu8B10n6naRtkxMkNQL+DbwKbEn4Ar8eJ19OKP10BboQviDJqs3mQDOgHdBfUjfgfsIHZDPgn8AwSRuVlClJH0n6ppThzlL2pTPwkcVPXPRRTC9pG42Bq4ELS1lfy1hd/ULSbZI2SZt+fayivSOpdynr2AtoBTyTtu0BkpYRfnQ2IQSySpFUB+gBtIjV4VmSBktqkJjnWOAHM3u5hFXsHuf5WNJcSY+kVbd7xvXfXcqyiyS9K+krSS9IapuWvxclrSR84UcSSt4Q3p8PU/OZ2TRCMN2O8GP0k10lBFkIpdwZwFXxvfhY0q8S2zxB0kclrKNcko4DzgcOI7yHHxBKwRAKBt0Jgb8pcAKw2MwGEd7ra8ysoZkdW4FNPgs0iOsFmEuoJTQGzgT+IamzmX0NHAV8HrfRMKatAs4hfO/2ivk+jeoi39G8hF+16YRfom/i8FwJ81SkZNoAuAx4n/BmTAUOitOOBz4oZblpwMGJ8QOA6fF1b8KXoX5i+l2klXoIv/j7ZPHY/JlYPUykPQoMLGX+24nVKn5aMt2cUO0tArYG3gT+mZjei1By2gjoSyg9dCxhG/cBD5ayfQG7AlcBjSryPlJCyZTwg2eEILUFoer9DnBdnN4Q+AzYOvFZSpZMf4hp28V5nwEejdPqxPX+LI6PZP2S6ZT4edyNUPIaBLxTQr7rEgLEBYm014Ez0+abHT9HdYHPgUvi6z4xn8PjfJfFfR5IaObZh/D92KGk41bGZ2e9/Ylp/wFOTMv7KkJgPZjQPNOTRKk5zlehan7atG+AX5Wy3KvAGfF1udV8YADweLa+X5UdqmvJ9EgzaxKHIyuzIjNbYWZ/NbPuhBLjk8BTsUSyFSFolmRLQokgZUZMS1lgZisT4+2AC5MlzLj+5DKVtYzwK57UmBDo1qPQMbU/oSr0E2Y2z8z+Z2Y/mtkXhC/zMYnpo81sqZl9b2YPEYLWwWnbaAAcCzxUyjbMzD4gVNmuynAfy7Ii/r/DzOaa2ULg1kS+riJUxb8oY/kHzGyKmS0jVL9Ty/6eUOofVcayz5rZ2Pi+XwXsIWnT5ExmtsrMXgEOkHR4TC71fTOzVcCRwCGEJqMLCZ/RWYntrgKuNbMfzOy/hCDYp5R8VkQ74O7E53UBsBpoQ2gquY9Qw5ofO8AaVmZjseazKaFJAUmHSxojaVHc/r6EH8jSlt9R0iuxNrUE+EtZ8+dadQ2mVcLMlhC+QJsQSmMzCdWYkswhfNhS2sa0tatLm38moYTUJDFsbGaPl7TytJ7W9KGkaiaEksIukpJVw11ierreQHvgS0nzgIuAX0kaX8q6jZKrnGVNP5rwxRhZxnIQOllKO84ZM7PFhCBT2n0j9wPOUzhzYx7hx+xJrTt746Nylj0qsewewC2SBpeybOp1accsuc+fEJqKwgJSB0KJf0rcr4/MbB8z28zMDgA6AGMS260qMwk1g+RntoGZvR9/CG81s10Jn7EuQOrshQ29b+dRhB+H92NgfQq4BmhpZk2AN1h3PEvaxr3AeEINKdWEVdZnNrfyXTROHyi7N78eoQrxDnB6fF1Uzvr+TKiapZa9HFhMqOY1IrTbnM+6HtpecblrCZ0dLQi/fm8TSgdQQucNoa1tJqF6LELAPoQSqreVODap3vw/xPyeQym9+cDGhKp8argZeBpokdiHtjGvWxFKOw/EaU0IzRr1CUHhREIP8/Zp23gNuDotrYjQbtw0rrtnPMbnZfI+xmXqE5ogLL7eKLHs1cBYoGXcxlus66zZLG2fZxJKzg3j9FOBLwjBamNCCfDhxD4nl32X0MO+aZy+b/zcdCVUh28D3orTOhGq9g3itJMIVfVucXpnQifSXvFz8QiJ5hpCsKof83RRzGOqs7MuoWnqz/G92JNQE+lUwc/OSH5azT+e0E66fRxvSqyCE9qIe8RtNoqfjwFx2t+B+8vYVnpv/maEpqKFrOvgbU7oYOoVPzOHEzrtrojTu8Zj1jCx3o+IHZnxmE4D/p3vmLU2f/nOQAlvxHRKD6Yj45uUHHqXs74rCD36S1hXitojMX0nQpvWYkI1K/WBSbWLzY3DIGIbKaX0hBPaecYS2oXmEn55sxZM4zZ2JbT/riD8Su+amHYZ8Eopyw1k/TbTPxLa7ZYTgs4dqbwSfkDGxi/tN4ROvF+mra81oUq4TVp6EaHtaxGhejsl5ivZW13q+0goTadPm55Yti5wZ8zXvOT7kslniVA9XxCHh4GmZXzW0oPPWfGYLQZeALaK6TsQOp1Sx2sscFTasicQzrz4DngeaJaYdlNc5zJC9Tr9mHYGRsVl/5dcN+GH7pMMPjc/2Z+Y3o9Qcl5C+GG+O/FZnhjztAB4ENg4TtuRcIbGN6S14Se+Oxbzuwz4mvAd+3XafH8knG62mNB5+y/WBVMRfnS+jttpRqg9TInrHEmoZVabYKqYceecc5VQq9pMnXOuqhREMI09fCV15GzwJXPOOVcRXs13zrksKM53BmoiFTcw1WuU72zUOl13aFv+TC7rPhj//kIza5GNddVp3M5s9Ypy57MVC4ab2YHZ2GaueDDdAKrXiI22/8nNhlwVe/PdQfnOQq3UqH6dGeXPlRlbvSKj787KCf+oNifjZ8qDqXMudyQoqpPvXFQJD6bOudxSQfR7/4QHU+dcbqn6XAGaTR5MnXM55NV855yrPOHVfOecqzx5Nd8557LCq/nOOVdZ8mq+c85VmvCSqXPOVZ6XTJ1zLjuKvAPKOecqx6v5zjmXDV7Nd8657PDzTJ1zrpL8rlHOOZclXs13zrks8Gq+c85VllfznXOu8vyuUc45lw1eMnXOuezwkqlzzmWBd0A551wl+XmmzjmXHfKSqXPOVY7wYOqcc5UnIb8Fn3POVZ6XTJ1zLgs8mDrnXGUJr+Y751xlCXnJ1DnnsqGoyK+Acs65SvOSqXPOVZbiUIA8mDrnckbIq/nOOZcNhVrNL8yfCOdc9aUMhvJWIW0l6T+SPpX0iaQ/xPRmkkZI+iz+bxrTJWmQpKmSPpLULbGuvnH+zyT1TaR3l/RxXGaQyvkV8GDqnMsdhd788oYMrAYuNLMdgN2BsyXtCAwAXjezbYHX4zjAQcC2cegP3AUh+AJXAr2AnsCVqQAc5+mfWO7AsjLkwdQ5l1OSyh3KY2ZzzWx8fL0U+BRoDRwBPBRnewg4Mr4+AhhiwXtAE0lbAAcAI8xskZktBkYAB8Zpjc1slJkZMCSxrhJ5m6lzLmcqcNJ+c0njEuP3mNk9Ja5Tag/sCowGWpnZXAgBV1LLOFtrYGZisVkxraz0WSWkl8qDqXMudzK/nHShmfUod3VSQ+AZ4HwzW1JGoC5pgm1Aeqm8mu+cy6lsVPPjeuoSAumjZvavmDw/VtGJ/7+K6bOArRKLtwHmlJPepoT0UnkwrYHatGrCq/ecxwfPXMH7T1/O2cf3Xm/6+b/djxUfDGazJpsA0KRRA5645XTGPPEn3nr4InbsuMXaeTdt2IDHburHhH9dwQfPXEGvXbYGYJftWvPfhy7kvaEDePvRS+jRuV3O9q8mmDVzJgf32Y/uXTqz2647c+fgQQAsWrSIww/uQ9fO23P4wX1YvHgxAJMnT2LfffZks8YNuP22W9auZ8qUyezRs9vaYcsWTfjHHbfnZZ9yRUUqdyh3HSHi3gd8ama3JiYNA1I98n2B5xPpJ8de/d2Bb2NzwHCgj6SmseOpDzA8Tlsqafe4rZMT6yqRV/NroNVrfmTArf9iwqRZNNx4I9597FJeHz2JSZ/Po02rJuy7eye+nLto7fyX9DuADyfP4jcX3st27Vvx9wG/5uAz7wDg5kuO4bV3/8cJF99H3eI6bFy/HgDXnX8k193zCq+98z8O+PmOXHf+kRxwemF/ySuiuLiYv954E1137cbSpUvZ62e7se9++/PIww+xzy/248KLL+WWm27k1ptv5JrrbqBZ02bcdMvfeXHY+t/H7bbbnnfHjAdgzZo1bNdhKw47vMx+jhovS+eZ7gn8FvhY0oSYdhlwA/CkpH7Al8CxcdrLwMHAVGA58DsAM1sk6RpgbJzvajNLfXnOAh4EGgCvxKFUVVYyldRe0orUjkqankifmDbvQEkXVVVe0rZ1Wdp4Kl8dJU2QtCwX+aiMeQuXMGFSaBtftvx7Jn0xjy1bNAHgbxf9istvf47QARl06rA5I8dMBmDK9Pm027IZLZs1otEm9fl5t448+OwoAFatXsO3y1YAYAaNN6kPhNLr3AXf5mz/aoLNt9iCrruGUxUbNWrE9p06MWf2bF56YRgnnnQyACeedPLa4NmiZUu699iNunXrlrrOkW+8ztZbd6Rtu8KtBWRSxc+wN/9tM5OZ7WJmXePwspl9bWb7mdm28f+iOL+Z2dlm1tHMdjazcYl13W9m28ThgUT6ODPbKS5zjiW/VCWo6pLpNDPrWsXbqKjLgL+mJ5rZNKBrTQimSW23aEbX7dswduJ0DtlnZ+Z89Q0fT5m93jwfT5nNEft15d0Jn9OjczvabtGM1q2asGbNjyxcvIx7rjqJnbdrzQefzuSivz3N8pU/cPHNT/PCP87m+guOoqhI/OKUW0rJgZsxfTofTZhAj569WPDVfDbfIjSjbL7FFixc8FU5S6/z9FNPcOxvjquqbFYbhXo5aS73akEmM0nqKum9eJXCs4krGEZKulHSGElTJO0V0+tIuknS2LjMGTF9C0lvxtLmREl7SboBaBDTHq1gvvpLGidpnK1eUfG9rwKbNKjH4zefxsU3P8PqNWu4tN8BXH3XSz+Z7+YHRtCk0ca8N3QAZx23Dx9OnsXqNT9SXFyHrp224t6n3uJnx9/I8hXfc9GpvwSg/7F7cckt/2Lbg/7MJTc/w11Xnpjr3asRli1bxknHH8sNN99K48aNN3g9P/zwAy+/9AJHHX1MFnNXTWXhCqjqKGfB1Mx2S4ymqtQTYjPAmYlpQ4BLzWwX4GPC1QkpxWbWEzg/kd6P0Ji8G7AbcLqkrYETCA3JXYEuwAQzGwCsiFWCE0vIV1n5v8fMephZDxU3qOjuZ11xcRGP33w6T7wyjuff+JAObVrQrvVmjHniT0x66Spat2zCqMcupdVmjVj63UrOGPgIux93A/3+PITmTRsyffbXzJ6/mNlffcPYiTMAePbfE+jaKXRsnnhoL557PTRFPTPiA++AKsGqVas46bhj+PVxJ3DEkUcD0KJlK+bNnQvAvLlzad6iZVmrWOu14a/QteuutGzVqsryW11kqze/uslXeXtaop2jK3A3gKRNgSZm9t8430PA3onlUqc/vA+0j6/7EHrpJhBO2t2McOnXWOB3kgYCO8erJArG3VeeyOQv5jHokTcA+GTqHNrt9yc6HXIlnQ65ktlffcPPTriR+V8vZdOGDahbXAeA3x21B2+Pn8rS71Yy/+ulzJq3mG3bhS98757bM+nzeQDMXfAte3XfNqZvx9QvMyrA1xpmxtlnnMb2nXbg3D9csDb94EMP49FHhgDw6CNDOOSwwzNa39NPDuWYXxd+FV+CoiKVO9RENa03//v4fw3r8i7gXDMbnj6zpL2BQ4CHJd1kZkNyk82qtUfXDpx4aC8+njKb94aGS4+vHDyM4W//r8T5O3XYnP+75resWfMjkz6fx5lXPbp22h9vfIoH/noK9YrrMH32Qvpf+QgAZ1/zGDddfAzFxUV8//1qzrn28arfsRpk1Lvv8Phjj9B5p53Zo2foiLry6mv540WX0vfE43j4wftps1Vbhjz2BADz581j7z17snTJEoqKirhz8O2M/WAijRs3Zvny5bzx+r+5ffDd+dylHKm5Jc/yqJwOqg1fcbjE60Uz26m89Fh6XGZmN0v6EDjHzN6K6Zua2QWSRgIXmdk4Sc2BcWbWXlJ/wikPx5rZKknbAbOB5sBsM1st6XygvZmdL2kx0NLMVpWS72Vm1rCsfSvauKVttP2vK3xMXOUseG9QvrNQKzWqX+f9TK5GykT9zbeztieX/z5+dtNBWdtmrlTHkmlf4G5JGwOfE88HK8P/Ear84+PJtQsINyToDVwsaRWwjHDSLcA9wEeSxqfaTZ1zORKr+YUo58HUzKYDO6WlDUy8nkC4pVb6cr0TrxcS20zN7EfC6U6XpS3yEOvuHpNcz6XApRuWe+dcZYjCDaZV2QG1Btg0cXVCtZY6aR+Yn++8OFfIvAOqgsxsJuvfQKBaS520n+98OFfQFHr0C1F1bDN1zhUoUbjPgPJg6pzLoZpbjS+PB1PnXE55ydQ55yrL20ydc67yCvnUKA+mzrmc8mq+c85lQYHGUg+mzrnckV9O6pxz2VC4d43yYOqcyykvmTrnXGX5qVHOOVd5fjmpc85liVfznXMuC7xk6pxzlVUb20wllfkQcDNbkv3sOOcKmWrpXaM+AYzQZpySGjegbRXmyzlXoIoKtGhaajA1sxpzl3znXM1RoLE0s2dASTpO0mXxdRtJ3as2W865QiRBnSKVO9RE5QZTSYOBXwC/jUnLgburMlPOucIlqdyhJsqkN38PM+sm6QMAM1skqV4V58s5V4BE4baZZlLNXyWpiNDphKTNgB+rNFfOuYJVpPKH8ki6X9JXkiYm0gZKmi1pQhwOTkz7k6SpkiZLOiCRfmBMmyppQCJ9a0mjJX0m6YlMCpCZBNN/AM8ALSRdBbwN3JjBcs45t74MqvgZVvMfBA4sIf02M+sah5fDJrUjcBzQOS5zp6Q6kuoQ4ttBwI7A8XFeCDHuNjPbFlgM9CsvQ+VW881siKT3gf1j0rFmNrGsZZxzriSCrHQwmdmbktpnOPsRwFAz+x74QtJUoGecNtXMPgeQNBQ4QtKnwL7ACXGeh4CBwF1lbSSj3nygDrAK+KECyzjn3E9I5Q9Ac0njEkP/DFd/jqSPYjNA05jWGpiZmGdWTCstfTPgGzNbnZZepkx68y8HHge2BNoAj0n6U3nLOedcSTKs5i80sx6J4Z4MVn0X0BHoCswFbkltsoR50y9IyiS9TJn05p8EdDez5QCSrgPeB67PYFnnnFsrdZ5pVTCz+eu2o3uBF+PoLCB5EVIbYE58XVL6QqCJpOJYOk3OX6pMquwzWD/oFgOfZ7Ccc879hDIYNmi90haJ0aOAVN/OMOA4SRtJ2hrYFhgDjAW2jT339QidVMPMzID/AMfE5fsCz5e3/bJudHIboWi7HPhE0vA43ofQo++ccxWWjZPyJT0O9Ca0rc4CrgR6S+pKiFPTgTMAzOwTSU8C/wNWA2eb2Zq4nnOA4YR+ofvN7JO4iUuBoZKuBT4A7isvT2VV81NR/RPgpUT6e+XuqXPOlUDKzuWiZnZ8CcmlBjwzuw64roT0l4GXS0j/nHU9/hkp60Yn5UZi55yrqAK9AKr8DihJHQkRfUegfirdzLarwnw55wpQts4zrY4y6YB6EHiAcBwOAp4EhlZhnpxzBaxQb3SSSTDd2MyGA5jZNDO7gnAXKeecq7Cq6s3Pt0zOM/1e4adimqQzgdlAy6rNlnOuEFXleab5lkkwvQBoCJxHaDvdFDi1KjPlnCtcNbUaX55MbnQyOr5cyrobRDvn3AYp0Fha5kn7z1LG9ahmdnSV5Mg5V7CydZ5pdVRWyXRwznJRw+y6Q1veGe2Hx7kNUeuq+Wb2ei4z4pyrHQr1Hp6ZdEA551xWFPJJ+x5MnXM5VaCxNPNgKmmjeNt/55zbIIV8nmkmd9rvKelj4LM43kXSHVWeM+dcQcrwsSU1TiZtwYOAQ4GvAczsQ/xyUufcBhBQJJU71ESZVPOLzGxG2ukMa6ooP865AlenZsbKcmUSTGdK6glYfM70ucCUqs2Wc64QqQaXPMuTSTA9i1DVbwvMB/4d05xzrsIKNJZmdG3+V4QHTTnnXKUIKC7Q3vxM7rR/LyVco29m/askR865glZrS6aEan1KfcIjVGdWTXaccwVNtfikfTN7Ijku6WFgRJXlyDlXsATUKdCi6YZcTro10C7bGXHO1Q61tmQqaTHr2kyLgEXAgKrMlHOucNW6W/ABxGc/dSE89wngRzMr9YbRzjlXlnBtfr5zUTXK3K0YOJ81szVx8EDqnKuUQr2cNJPfiDGSulV5TpxzBS/cz7T8oSYq6xlQxWa2Gvg5cLqkacB3hONhZuYB1jlXQaKImlnyLE9ZbaZjgG7AkTnKi3OuwInaedK+AMxsWo7y4pwrdKqdl5O2kPTH0iaa2a1VkB/nXAEr5JJpWU29dYCGQKNSBuecq7Bs9OZLul/SV5ImJtKaSRoh6bP4v2lMl6RBkqZK+ijZoS6pb5z/M0l9E+ndJX0clxmkDE6OLatkOtfMri53r5xzLkPhctKsrOpBYDAwJJE2AHjdzG6QNCCOXwocBGwbh17AXUAvSc2AK4EehAuT3pc0zMwWx3n6A+8BLwMHAq+UlaGySqYFWhh3zuWNwhVQ5Q3lMbM3CVdjJh0BPBRfP8S6zvMjgCEWvAc0kbQFcAAwwswWxQA6AjgwTmtsZqPiufVDyKAjvqyS6X7l7pFzzlVQhqW05pLGJcbvMbN7ylmmlZnNBTCzuZJaxvTWrH+nu1kxraz0WSWkl6nUYGpm6VHfOecqpQJ3jVpoZj2yuNl0tgHpZaqh1xo452qqKnzU8/xYRSf+/yqmzwK2SszXBphTTnqbEtLL5MHUOZczQtRR+cMGGgakeuT7As8n0k+Ovfq7A9/G5oDhQB9JTWPPfx9geJy2VNLusRf/5MS6SrUh9zN1zrkNlo1b8El6HOhNaFudReiVvwF4UlI/4Evg2Dj7y8DBwFRgOfA7CE2Zkq4Bxsb5rk40b55FOGOgAaEXv8yefPBg6pzLsWycJmRmx5cy6Scd57FH/uxS1nM/cH8J6eOAnSqSJw+mzrmckfyxJc45lxW18k77zjmXbYUZSj2YOudyyJ9O6pxzWVKgsdSDqXMul4QKtKLvwdQ5lzNezXfOuWyo3OWi1ZoHU+dcTtXURzmXx4Opcy5nBBToI6A8mDrncqtQO6D8rlE13BmnnUrbLVvSveu6y4ivvXogHdq1plf3rvTq3pVXX3kZgLFjxqxN69mtC88/9+zaZV4b/iq7dN6ezp224aa/3ZDz/ahpSjruKbfdejMN6oqFCxcC8O233/KrIw+jZ7cudOvSmSEPPrB23k02qrP2PTnmqMNzlv98ysYzoKojL5nWcL/tewpn/v4cTjv15PXSz/3DBVzwx4vWS+u80068M3ocxcXFzJ07l17du3DIoYchifPPO5uXXhlB6zZt+Pnuu3HooYezw4475nJXapTSjvvMmTN5498j2Kpt27Vp/7zrH3TaYUeeee4FFixYQJfO23PcCSdSr149GjRowOj3J+Q6+3lTyNX8nJdMJbWXtELShDg+PT09MdSrgu33lvRifH2KpIHx9QWSvpQ0ONvbrEo/32tvmjVrltG8G2+8McXF4ffz+5Ur114jPXbMGDp23IatO3SgXr16HPub43jxhXJv31irlXbcL7noAq67/m/rXX8uiWVLl2JmfLdsGU2bNVv7PtQ+yuivJspXNX+amXUtLT0x/JCcKKnKPoFmdhvwl6paf67dfedgdtt1F8447VQWL168Nn3M6NF069KZHrvuzKB/3E1xcTFz5symTZt1Nxxv3boNs2fPzke2a7QXXxjGllu2ZpcuXdZLP/P35zBp0qd0aLslPXbdmZtvvZ2iovDVW7lyJXv26sHee+7OsOefy0e2c0uhZFqN3r+sAAAR90lEQVTeUBNVhzbTBWVNlDRQ0j2SXgOGxBLsW5LGx2GPON/aEmccHyzplPj6QEmTJL0NHJ1Y/QpgWSaZlNRf0jhJ4xYsLDPLeXf6GWfxv8nTGP3+BDbfYgsGXHzh2mk9e/Vi/Ief8Paosdx04/WsXLmScLvH9RXqnX2qyvLly7nx+uv4y8CfPh19xGvD2aVLVz7/cg6jx03ggj+cw5IlSwCY8vmXvDN6HA89/BgXX3g+n0+bluus51So5hdmm2neg6mZ7ZYY7Zio4v8jkd4dOMLMTiA81+WXZtYN+A0wqKz1S6oP3AscBuwFbJ7Y9hNmdnOG+bzHzHqYWY8WzVtktG/50qpVK+rUqUNRURGn9judcePG/GSeTjvswCabbMInEyfSunUbZs1a95DG2bNnseWWW+YyyzXe59OmMWP6F/Ts3oXtt2nP7Fmz+FnPbsybN4+HH3qAI446Gkl03GYb2rffmsmTJgGsPc5bd+jA3nv3ZsKED/K5GzmhDIaaKO/BNE2ymp+8M/YwM1sRX9cF7pX0MfAUUF4vSSfgCzP7LN5x+5HsZ7t6mTt37trXzz/3LDt2Dj3O07/4gtWrVwMwY8YMpkyZTLv27emx225MnfoZ07/4gh9++IGnnhjKIYfWjp7lbNlp5535cs5XTJ46nclTp9O6TRtGjRnP5ptvzlZbtWXkG68DMH/+fKZMmczWHTqwePFivv/+ewAWLlzIqFHvsMMOhd/pJ6ncoSaqKa3g3yVeXwDMB7oQfgxWxvTVrP/jUD/xutzHtNZUJ590PG/9dyQLFy6kY/s2/PkvV/Hmf0fy0YcTkES79u25485/AvDuO29z8003ULe4LkVFRdx+x500b94cgNtuH8xhhxzAmjVr6HvKqezYuXM+d6vaK+m4n3JqvxLnHXD5n+nf7xR6dN0Zw7jurzfSvHlzRr37Luf+/gyKior48ccfuejiAbXiDIoaGivLpZLay6p0g1J74EUz2ynD9IHAslR1XNJtwCwzu0XS74D7zUyStgLeArYnBNIJwFXAUGAK8AszmxYfxNXIzA4tIW+nAD3M7Jyy9qF79x72zuhxFdxz52qmBnX1fraeYb/DzrvakGEjy52vZ4cmWdtmrlS3an4m7gT6SnoP2I5YajWzmcCTwEfAo8AHMX0l0B94KXZAzchHpp1zqTbRwjw1qtpU881sOiU8DdDMBqaNfwbskkj6U2LaJcAlJazjVULbqXMunwr4rlH5KJmuATZNnbRfXUi6gBCYl+Q7L84VMqn8oSbKeck0Vse3KnfGHIsn7d+W73w4V9hqbjW+PNWmmu+cqx1qasmzPB5MnXM5IzyYOudcVng13znnssBLps45V1k1uLe+PB5MnXM55dV855yrJL/TvnPOZUuW7sEnabqkj+MtO8fFtGaSRkj6LP5vGtMlaZCkqZI+ktQtsZ6+cf7PJPXd0N3yYOqcy6ksX5v/i3jLztRNUQYAr5vZtsDrcRzgIGDbOPQH7oIQfIErgV5AT+DKVACuKA+mzrmcquLHlhwBPBRfPwQcmUgfYsF7QBNJWwAHACPMbJGZLQZGAAdu0H5VKtvOOVdRmVXzm6ceExSH/iWsyYDXJL2fmN7KzOYCxP8tY3prYGZi2VkxrbT0CvMOKOdczqRuwZeBhRncz3RPM5sjqSUwQtKkcjadzspIrzAvmTrncieLTyc1sznx/1fAs4Q2z/mx+k78/1WcfRbr32CpDTCnjPQK82DqnMutLPTmS9pEUqPUa6APMBEYBqR65PsCz8fXw4CTY6/+7sC3sRlgONBHUtPY8dQnplWYV/OdczmUtVvwtQKejQ/fKwYeM7NXJY0FnpTUD/gSODbO/zJwMDAVWA78DsDMFkm6Bhgb57vazBZtSIY8mDrnciZbJ+2b2eeEh2qmp38N7FdCugFnp6fHafcD91c2Tx5MnXO5VaBXQHkwdc7lVFGB3unEg6lzLqcKM5R6MHXO5ZLfgs855yovPLakMKOpB1PnXE4VZij1YOqcy7ECLZh6MHXO5ZZX851zLgsKM5R6MHXO5ZC8N98557LDq/nOOZcFhRlKPZg653JKfjmpc85VVjhpP9+5qBp+c2jnnMsCL5k653LKq/nOOVdZfmqUc85VXoaPeKqRPJg653LKzzN1zrksKNBY6sHUOZdbBRpLPZg653KrUKv5Ck9AdRUhaQEwI9/52EDNgYX5zkQtVJOPezsza5GNFUl6lXAsyrPQzA7MxjZzxYNpLSNpnJn1yHc+ahs/7oXPr4Byzrks8GDqnHNZ4MG09rkn3xmopfy4FzhvM3XOuSzwkqlzzmWBB1PnnMsCD6bOOZcFHkxrGUn+njtXBfyLVYtIamhmP3pAzS1J50nqk+98uKrlX6paQtLzwHRJrT2g5o6ky4DfA8dIOijf+XFVx79QtYCktsAE4C5glAfUnHoO+CUwCjjaA2rh8rtGFThJPzOzUcCVcbwuMFpSLzObLanIzH7Mby4Lj6TfAE3M7J9x/D9AA+AoSZjZK3nNoMs6L5kUMEntgOGSTkqlmdkA4CFCQPUSatVZBXSU1A/AzKYDwwg1hKO8hFp4vGRaoGKJc4akXwBPSJoITDSz1WZ2ebyn5GhJPc1sjpdQs0PSuUBdM7tV0vfAmtQ0M5slaVgcPVqSzOzlvGTUZZ0H0wIkaRcz+yiOLgF6mNk3cVqRmf0YA2odYEwqoOYtwwVC0kbAJOD3kr4xs/sT02TBLEkvAcuAX0laamZv5SvPLnu8eleYjpc0TNLTwLHpgTRVrY9V/meAVyX5D2slSKpjZt8DbwNjgNNSVfzULKkXZjYjzrMnsCCnGXVVxm90UkCSVXVJc4CVZtYhjtczsx/iaxHe+x8lDQaeM7N/5y3jBSL+SL0GjAe2BJoCr5nZ7anpiffn58AyM5uQr/y67PJgWiBiyWhN7K3fDtgZOBtYYGZHx3lkaW94PJF/We5zXHgk7Qv0N7PjJG0KdAEGAE8nq/yuMHk1vwDEEs+aRMloFzMbamZ7AS0lPRdnvUPSeo/O8EC64ZR4Mpyk+sAPQHdJjc3sW+BDQpv1+ZL2z1M2XY54MC0Asbouwgnib5rZ45KKJdU1s58DDSSNAhqZ2bj85rZwpEr5ki4EjjGztwlt0HdIahQD6iLgL96MUvi806EGS6u2bwx8Bbwn6VjgCKCJpCfM7ABJO5vZxyUs5yqohNPIioGfS1oJPAKcDIyV9CWhmeW5uJwf9wLmbaY1VKqNNL5uDHwHXAgcDowm9Co3Bjqa2V8Sy/kXOgtiTWB/MxsRx88htFWPNLN/SdoFqJeqCfhxL3xeMq2B0tpIHwaWA58ALwL3mdnXcb4hhGrmWv6Fzpq9gasltTCzx8xssKQrgb9IakDodPoeSizJugLkbaY1UKKN9FFCKXQIcA3Q2My+ltRa0oOEmsf5sH5niau4eIHDWmb2X+BW4ARJJ8bkawg/bKQCaXztgbQW8JJpzdUa+BJ4CbgNGGhm70lqSri65tFEFdRLRpWQOO2sCLgeWAy8ZWZPxd+oc+OduXYE3jCzR/OYXZcnXjKtIdJLRoQrZzYhVO1HmtktcZ6HgA6JQCoPpJWTCKQvEH6olgOvSNrPzJ4C/gRsC8wwsyvAawK1kZdMa4C0NtJTCe2gzwHvAJ2ACfEOUTcSeo8/SC3rbaQbLq1EfxgwFriFcOyfAl6WdISZvSpptJmtLmE5V0t4b341l6hiilAKNcKJ4I0JX/DfEa7xbkYoGa1tI/VAuuES9zGoA1wL3AvMBe4AZpnZQEmPACcQLpKYGJfz415Lecm0mksE0vOBD83sMoDYwfQCcKSZ3S+pqZktjtO8ZFRJieN3I7DYzD4HkDQXmBanTQXOSwXSuJwH0lrK20yrKa1/w+bOhOp9J0nNAczsFMJJ+h/GOz6l7gzlbaSVIOlvkraKr88E9gDejePFhFrBPpLGA1ua2eA4zb9LtZxX86uhtBPyG5rZMkkdgP8DHgeGmtnSOL2fmd2Xx+wWDEm3Azua2S/j+J7AmYTOvjvNbGq8kcz2QBszezXO51V758G0utH69xx9HKgDrCa02X1OCKhPE059WpJYzr/QlSBpKOEO+b+K4/sTOvi6A0cCC4FnzOyztOW8ScUBXs2vVlJV9BhIHwNmAxcDQwnnkrYDziM8Orh7clkPpBsudjI1SYyfBlwObBRvXvIi0AI4RVKL5LIeSF2Kd0BVE5KOB+pLGhI7nb4BBll4ENsXCo/E+K2Z9ZN0jJlNzmuGC4Skk81siKTDgfskTQG+Bg6y+IQCMxsZb7HXzMz8zviuRF4yrQZiO1xbws2Efx2T6wGDE7N9CjSSVD8VSP3E8Kw4X9IgC08h6E+4PHeZrXvUS10AM3vVzB6LaX7c3U94MK0GzGwVcDvhuUCHS/oloeNjhaRXJO0MXAHMM7OVieW8ar+BJL0s6WjgZ0BPSYeY2QpCE8ocSc/GZpdVJVyX78fd/YQH0zySdG7qixqDZEvC3YiOAQ4hnBA+FegLzDGz8+JyXjKqBEmdgV8S2kS/B/Y0s5cA4lkS5xBOgRoZ09aUsirn1vI20zyJQfQg4BeEZ6ifAvwK2BfoGf+vMrNz05bz3uNKMrNPJB0BXCup2MwehlClN7NVZrZU0rnAcfnNqatJPJjmQaLT40hCp8dkwvX2h5jZIoUnizYCjpW00Mzei8v5CflZYmYvxwL+DZJ+MLMnYpU+9Xz7JcA94Keducz4eaZ5EK+eedvMzlO4kfA9wOapk8XjPBsDPzOz1/OVz9pA0sHADcB1ZvZETPPSv6swbzPNoUw7PQDMbHkqkHobadUxs5cJj2O+XPEmz7bu2fZ+3F3GvGSaI7HTYwJwsoWnh669ZDROb0Q4Faq9me2Tr3zWVrGEei1wN7CZmV2f5yy5GsbbTHPEOz2qt9iGKsLlun3znR9X83jJNMdKaaP7SQeHd3rkh6RNLTzv3rkK8ZJpjqX1IhN7kS2908MDaX54IHUbyoNpHqQF1GIzezTZ6eGB1Lmax4NpniQC6rWSNiF2enggda5m8mCaR97p4Vzh8A6oasA7PZyr+TyYOudcFvgVUM45lwUeTJ1zLgs8mLpSSVojaYKkiZKeijdf2dB19Zb0Ynx9uKQBZczbRNLvN2AbAyVdlGl62jwPSjqmAttqL2liRfPoCpcHU1eWFWbW1cx2An4g3P1/LQUV/gyZ2TAzu6GMWZoQbv7iXI3hwdRl6i1gm1gi+1TSncB4YCtJfSSNkjQ+lmAbAkg6UNIkSW8DR6dWJOkUSYPj61bxblkfxmEPwuW2HWOp+KY438WSxkr6SNJViXVdLmmypH8TnmdfJkmnx/V8KOmZtNL2/pLekjRF0qFx/jqSbkps+4zKHkhXmDyYunJJKiY8FeDjmLQ9MMTMdgW+Izyfan8z6waMA/6o8DTPe4HDgL2AzUtZ/SDgv2bWBegGfEK4Jd60WCq+WFIfYFvCEwi6At0l7S2pO+HGMLsSgvVuGezOv8xst7i9T4F+iWntgX0Ij4y5O+5DP+BbM9strv90SVtnsB1Xy/hJ+64sDSRNiK/fAu4DtgRmpO7+D+wO7Ai8E6/oqgeMAjoBX5jZZwCSHiE8/TPdvsDJsPZZS99Kapo2T584fBDHGxKCayPgWTNbHrcxLIN92knStYSmhIbA8MS0J+NlvZ9J+jzuQx9gl0R76qZx21My2JarRTyYurKsMLOuyYQYML9LJgEjzOz4tPm6Atk6iVnA9Wb2z7RtnL8B23gQONLMPlR47lbvxLT0dVnc9rlmlgy6SGpfwe26AufVfFdZ7wF7StoGwuNWJG0HTAK2ltQxznd8Kcu/DpwVl60jqTGwlFDqTBkOnJpoi20tqSXwJnCUpAbx5tqHZZDfRsBcSXWBE9OmHSupKOa5AzA5bvusOD+Stov3UnBuPV4ydZViZgtiCe9xSRvF5CvMbIqk/sBLkhYCbwM7lbCKPwD3SOoHrAHOMrNRkt6Jpx69EttNdwBGxZLxMuAkMxsv6QnCEwxmEJoiyvNnYHSc/2PWD9qTgf8CrYAzzWylpP8jtKWOj/dRWAAcmdnRcbWJX07qnHNZ4NV855zLAg+mzjmXBR5MnXMuCzyYOudcFngwdc65LPBg6pxzWeDB1DnnsuD/AXK/sPtkngEMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[25019  1967]\n",
      " [ 1529  1486]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[120080   5851]\n",
      " [  7908  34296]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna2.predict(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list3 = [100,100,1]\n",
    "activation_list3 = ['tanh', 'tanh', 'sigmoid']\n",
    "dropout_list3 = [0.3,0.3,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 30,301\n",
      "Trainable params: 30,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna3 = new_rna()\n",
    "rna3.build_model(data_shape,n_list3,activation_list3,dropout_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168135 samples, validate on 30001 samples\n",
      "Epoch 1/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.4089 - f1: 0.5621 - val_loss: 0.2819 - val_f1: 0.0697\n",
      "Epoch 2/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3914 - f1: 0.5844 - val_loss: 0.2802 - val_f1: 0.0703\n",
      "Epoch 3/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3884 - f1: 0.5926 - val_loss: 0.2801 - val_f1: 0.0702\n",
      "Epoch 4/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3868 - f1: 0.5930 - val_loss: 0.2796 - val_f1: 0.0699\n",
      "Epoch 5/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3859 - f1: 0.5946 - val_loss: 0.2805 - val_f1: 0.0705\n",
      "Epoch 6/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3853 - f1: 0.5966 - val_loss: 0.2827 - val_f1: 0.0710\n",
      "Epoch 7/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3845 - f1: 0.5982 - val_loss: 0.2812 - val_f1: 0.0701\n",
      "Epoch 8/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3843 - f1: 0.5952 - val_loss: 0.2805 - val_f1: 0.0701\n",
      "Epoch 9/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3837 - f1: 0.5966 - val_loss: 0.2806 - val_f1: 0.0705\n",
      "Epoch 10/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3833 - f1: 0.5981 - val_loss: 0.2820 - val_f1: 0.0710\n",
      "Epoch 11/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3831 - f1: 0.5975 - val_loss: 0.2831 - val_f1: 0.0713\n",
      "Epoch 12/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3827 - f1: 0.5987 - val_loss: 0.2816 - val_f1: 0.0706\n",
      "Epoch 13/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3826 - f1: 0.5990 - val_loss: 0.2811 - val_f1: 0.0705\n",
      "Epoch 14/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3821 - f1: 0.5976 - val_loss: 0.2801 - val_f1: 0.0708\n",
      "Epoch 15/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3811 - f1: 0.6003 - val_loss: 0.2789 - val_f1: 0.0699\n",
      "Epoch 16/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3816 - f1: 0.5971 - val_loss: 0.2787 - val_f1: 0.0698\n",
      "Epoch 17/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3808 - f1: 0.5967 - val_loss: 0.2817 - val_f1: 0.0711\n",
      "Epoch 18/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3802 - f1: 0.6012 - val_loss: 0.2793 - val_f1: 0.0700\n",
      "Epoch 19/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3799 - f1: 0.5988 - val_loss: 0.2820 - val_f1: 0.0707\n",
      "Epoch 20/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3797 - f1: 0.6002 - val_loss: 0.2781 - val_f1: 0.0700\n",
      "Epoch 21/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3788 - f1: 0.6008 - val_loss: 0.2790 - val_f1: 0.0698\n",
      "Epoch 22/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3783 - f1: 0.5994 - val_loss: 0.2788 - val_f1: 0.0694\n",
      "Epoch 23/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3783 - f1: 0.5980 - val_loss: 0.2753 - val_f1: 0.0691\n",
      "Epoch 24/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3780 - f1: 0.6004 - val_loss: 0.2747 - val_f1: 0.0693\n",
      "Epoch 25/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3768 - f1: 0.6000 - val_loss: 0.2784 - val_f1: 0.0701\n",
      "Epoch 26/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3763 - f1: 0.5996 - val_loss: 0.2765 - val_f1: 0.0698\n",
      "Epoch 27/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3757 - f1: 0.6029 - val_loss: 0.2753 - val_f1: 0.0690\n",
      "Epoch 28/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3753 - f1: 0.6023 - val_loss: 0.2728 - val_f1: 0.0683\n",
      "Epoch 29/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3745 - f1: 0.6022 - val_loss: 0.2786 - val_f1: 0.0698\n",
      "Epoch 30/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3742 - f1: 0.6041 - val_loss: 0.2744 - val_f1: 0.0686\n",
      "Epoch 31/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3733 - f1: 0.6007 - val_loss: 0.2738 - val_f1: 0.0688\n",
      "Epoch 32/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3728 - f1: 0.6047 - val_loss: 0.2753 - val_f1: 0.0688\n",
      "Epoch 33/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3725 - f1: 0.6045 - val_loss: 0.2745 - val_f1: 0.0693\n",
      "Epoch 34/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3718 - f1: 0.6043 - val_loss: 0.2769 - val_f1: 0.0686\n",
      "Epoch 35/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3711 - f1: 0.6060 - val_loss: 0.2752 - val_f1: 0.0699\n",
      "Epoch 36/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3705 - f1: 0.6063 - val_loss: 0.2734 - val_f1: 0.0688\n",
      "Epoch 37/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3706 - f1: 0.6058 - val_loss: 0.2736 - val_f1: 0.0687\n",
      "Epoch 38/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3691 - f1: 0.6072 - val_loss: 0.2754 - val_f1: 0.0689\n",
      "Epoch 39/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3695 - f1: 0.6078 - val_loss: 0.2766 - val_f1: 0.0688\n",
      "Epoch 40/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3678 - f1: 0.6093 - val_loss: 0.2719 - val_f1: 0.0686\n",
      "Epoch 41/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3673 - f1: 0.6094 - val_loss: 0.2731 - val_f1: 0.0684\n",
      "Epoch 42/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3668 - f1: 0.6077 - val_loss: 0.2730 - val_f1: 0.0689\n",
      "Epoch 43/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3661 - f1: 0.6115 - val_loss: 0.2750 - val_f1: 0.0691\n",
      "Epoch 44/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3641 - f1: 0.6142 - val_loss: 0.2720 - val_f1: 0.0688\n",
      "Epoch 45/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3643 - f1: 0.6147 - val_loss: 0.2702 - val_f1: 0.0682\n",
      "Epoch 46/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3631 - f1: 0.6135 - val_loss: 0.2750 - val_f1: 0.0694\n",
      "Epoch 47/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3627 - f1: 0.6137 - val_loss: 0.2718 - val_f1: 0.0686\n",
      "Epoch 48/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.3620 - f1: 0.6154 - val_loss: 0.2712 - val_f1: 0.0680\n",
      "Epoch 49/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3604 - f1: 0.6194 - val_loss: 0.2696 - val_f1: 0.0680\n",
      "Epoch 50/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3606 - f1: 0.6169 - val_loss: 0.2691 - val_f1: 0.0677\n",
      "Epoch 51/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.3601 - f1: 0.6188 - val_loss: 0.2725 - val_f1: 0.0684\n",
      "Epoch 52/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3591 - f1: 0.6200 - val_loss: 0.2694 - val_f1: 0.0678\n",
      "Epoch 53/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3583 - f1: 0.6215 - val_loss: 0.2688 - val_f1: 0.0676\n",
      "Epoch 54/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3575 - f1: 0.6214 - val_loss: 0.2690 - val_f1: 0.0676\n",
      "Epoch 55/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3562 - f1: 0.6254 - val_loss: 0.2695 - val_f1: 0.0679\n",
      "Epoch 56/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3560 - f1: 0.6244 - val_loss: 0.2695 - val_f1: 0.0676\n",
      "Epoch 57/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3557 - f1: 0.6240 - val_loss: 0.2690 - val_f1: 0.0680\n",
      "Epoch 58/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3535 - f1: 0.6279 - val_loss: 0.2672 - val_f1: 0.0674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3524 - f1: 0.6282 - val_loss: 0.2685 - val_f1: 0.0679\n",
      "Epoch 60/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3515 - f1: 0.6333 - val_loss: 0.2677 - val_f1: 0.0676\n",
      "Epoch 61/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3513 - f1: 0.6350 - val_loss: 0.2660 - val_f1: 0.0672\n",
      "Epoch 62/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3500 - f1: 0.6337 - val_loss: 0.2656 - val_f1: 0.0669\n",
      "Epoch 63/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3486 - f1: 0.6370 - val_loss: 0.2687 - val_f1: 0.0678\n",
      "Epoch 64/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3484 - f1: 0.6372 - val_loss: 0.2657 - val_f1: 0.0672\n",
      "Epoch 65/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3480 - f1: 0.6375 - val_loss: 0.2660 - val_f1: 0.0670\n",
      "Epoch 66/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3467 - f1: 0.6376 - val_loss: 0.2647 - val_f1: 0.0670\n",
      "Epoch 67/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3460 - f1: 0.6410 - val_loss: 0.2627 - val_f1: 0.0663\n",
      "Epoch 68/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3445 - f1: 0.6409 - val_loss: 0.2638 - val_f1: 0.0670\n",
      "Epoch 69/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3451 - f1: 0.6386 - val_loss: 0.2661 - val_f1: 0.0671\n",
      "Epoch 70/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3431 - f1: 0.6432 - val_loss: 0.2649 - val_f1: 0.0671\n",
      "Epoch 71/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3422 - f1: 0.6442 - val_loss: 0.2668 - val_f1: 0.0672\n",
      "Epoch 72/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3412 - f1: 0.6471 - val_loss: 0.2622 - val_f1: 0.0664\n",
      "Epoch 73/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3403 - f1: 0.6441 - val_loss: 0.2626 - val_f1: 0.0663\n",
      "Epoch 74/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3394 - f1: 0.6480 - val_loss: 0.2672 - val_f1: 0.0670\n",
      "Epoch 75/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3384 - f1: 0.6537 - val_loss: 0.2668 - val_f1: 0.0673\n",
      "Epoch 76/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3397 - f1: 0.6489 - val_loss: 0.2640 - val_f1: 0.0669\n",
      "Epoch 77/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3378 - f1: 0.6510 - val_loss: 0.2644 - val_f1: 0.0664\n",
      "Epoch 78/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3358 - f1: 0.6564 - val_loss: 0.2665 - val_f1: 0.0666\n",
      "Epoch 79/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3354 - f1: 0.6538 - val_loss: 0.2650 - val_f1: 0.0667\n",
      "Epoch 80/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3339 - f1: 0.6577 - val_loss: 0.2631 - val_f1: 0.0662\n",
      "Epoch 81/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3324 - f1: 0.6577 - val_loss: 0.2617 - val_f1: 0.0656\n",
      "Epoch 82/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3340 - f1: 0.6587 - val_loss: 0.2617 - val_f1: 0.0655\n",
      "Epoch 83/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3331 - f1: 0.6590 - val_loss: 0.2634 - val_f1: 0.0661\n",
      "Epoch 84/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3318 - f1: 0.6592 - val_loss: 0.2638 - val_f1: 0.0663\n",
      "Epoch 85/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3302 - f1: 0.6654 - val_loss: 0.2626 - val_f1: 0.0657\n",
      "Epoch 86/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3295 - f1: 0.6597 - val_loss: 0.2626 - val_f1: 0.0656\n",
      "Epoch 87/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3292 - f1: 0.6634 - val_loss: 0.2634 - val_f1: 0.0664\n",
      "Epoch 88/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3291 - f1: 0.6646 - val_loss: 0.2625 - val_f1: 0.0659\n",
      "Epoch 89/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3274 - f1: 0.6669 - val_loss: 0.2636 - val_f1: 0.0659\n",
      "Epoch 90/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3262 - f1: 0.6689 - val_loss: 0.2641 - val_f1: 0.0661\n",
      "Epoch 91/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3262 - f1: 0.6688 - val_loss: 0.2655 - val_f1: 0.0662\n",
      "Epoch 92/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3247 - f1: 0.6747 - val_loss: 0.2623 - val_f1: 0.0658\n",
      "Epoch 93/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3252 - f1: 0.6715 - val_loss: 0.2643 - val_f1: 0.0660\n",
      "Epoch 94/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3236 - f1: 0.6739 - val_loss: 0.2623 - val_f1: 0.0653\n",
      "Epoch 95/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3243 - f1: 0.6687 - val_loss: 0.2611 - val_f1: 0.0649\n",
      "Epoch 96/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3226 - f1: 0.6731 - val_loss: 0.2620 - val_f1: 0.0652\n",
      "Epoch 97/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3216 - f1: 0.6744 - val_loss: 0.2670 - val_f1: 0.0664\n",
      "Epoch 98/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3221 - f1: 0.6741 - val_loss: 0.2664 - val_f1: 0.0663\n",
      "Epoch 99/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3198 - f1: 0.6777 - val_loss: 0.2622 - val_f1: 0.0652\n",
      "Epoch 100/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3187 - f1: 0.6770 - val_loss: 0.2634 - val_f1: 0.0650\n",
      "Epoch 101/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3184 - f1: 0.6776 - val_loss: 0.2615 - val_f1: 0.0646\n",
      "Epoch 102/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3167 - f1: 0.6826 - val_loss: 0.2630 - val_f1: 0.0651\n",
      "Epoch 103/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3166 - f1: 0.6806 - val_loss: 0.2619 - val_f1: 0.0652\n",
      "Epoch 104/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3172 - f1: 0.6807 - val_loss: 0.2602 - val_f1: 0.0640\n",
      "Epoch 105/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3159 - f1: 0.6830 - val_loss: 0.2609 - val_f1: 0.0644\n",
      "Epoch 106/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3155 - f1: 0.6822 - val_loss: 0.2620 - val_f1: 0.0644\n",
      "Epoch 107/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3138 - f1: 0.6888 - val_loss: 0.2600 - val_f1: 0.0638\n",
      "Epoch 108/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3135 - f1: 0.6855 - val_loss: 0.2637 - val_f1: 0.0648\n",
      "Epoch 109/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3142 - f1: 0.6860 - val_loss: 0.2614 - val_f1: 0.0643\n",
      "Epoch 110/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3128 - f1: 0.6878 - val_loss: 0.2610 - val_f1: 0.0640\n",
      "Epoch 111/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.3111 - f1: 0.6870 - val_loss: 0.2621 - val_f1: 0.0638\n",
      "Epoch 112/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3117 - f1: 0.6878 - val_loss: 0.2647 - val_f1: 0.0652\n",
      "Epoch 113/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3106 - f1: 0.6903 - val_loss: 0.2624 - val_f1: 0.0643\n",
      "Epoch 114/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3098 - f1: 0.6901 - val_loss: 0.2631 - val_f1: 0.0647\n",
      "Epoch 115/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.3098 - f1: 0.6911 - val_loss: 0.2624 - val_f1: 0.0643\n",
      "Epoch 116/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.3084 - f1: 0.6919 - val_loss: 0.2615 - val_f1: 0.0636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3076 - f1: 0.6919 - val_loss: 0.2616 - val_f1: 0.0636\n",
      "Epoch 118/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.3075 - f1: 0.6944 - val_loss: 0.2617 - val_f1: 0.0635\n",
      "Epoch 119/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3065 - f1: 0.6972 - val_loss: 0.2637 - val_f1: 0.0641\n",
      "Epoch 120/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3065 - f1: 0.6934 - val_loss: 0.2623 - val_f1: 0.0639\n",
      "Epoch 121/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3048 - f1: 0.6947 - val_loss: 0.2630 - val_f1: 0.0641\n",
      "Epoch 122/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3042 - f1: 0.6965 - val_loss: 0.2638 - val_f1: 0.0643\n",
      "Epoch 123/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3034 - f1: 0.6978 - val_loss: 0.2633 - val_f1: 0.0641\n",
      "Epoch 124/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3031 - f1: 0.7002 - val_loss: 0.2616 - val_f1: 0.0632\n",
      "Epoch 125/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3031 - f1: 0.6999 - val_loss: 0.2619 - val_f1: 0.0633\n",
      "Epoch 126/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3041 - f1: 0.6985 - val_loss: 0.2617 - val_f1: 0.0634\n",
      "Epoch 127/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.3013 - f1: 0.7009 - val_loss: 0.2629 - val_f1: 0.0635\n",
      "Epoch 128/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3026 - f1: 0.7029 - val_loss: 0.2632 - val_f1: 0.0639\n",
      "Epoch 129/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.3006 - f1: 0.7024 - val_loss: 0.2600 - val_f1: 0.0626\n",
      "Epoch 130/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3008 - f1: 0.7050 - val_loss: 0.2629 - val_f1: 0.0636\n",
      "Epoch 131/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.3004 - f1: 0.7009 - val_loss: 0.2645 - val_f1: 0.0637\n",
      "Epoch 132/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2990 - f1: 0.7044 - val_loss: 0.2601 - val_f1: 0.0622\n",
      "Epoch 133/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2989 - f1: 0.7061 - val_loss: 0.2638 - val_f1: 0.0636\n",
      "Epoch 134/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2973 - f1: 0.7088 - val_loss: 0.2627 - val_f1: 0.0630\n",
      "Epoch 135/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2977 - f1: 0.7061 - val_loss: 0.2628 - val_f1: 0.0631\n",
      "Epoch 136/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2980 - f1: 0.7061 - val_loss: 0.2634 - val_f1: 0.0633\n",
      "Epoch 137/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2966 - f1: 0.7081 - val_loss: 0.2633 - val_f1: 0.0634\n",
      "Epoch 138/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2974 - f1: 0.7075 - val_loss: 0.2626 - val_f1: 0.0632\n",
      "Epoch 139/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2950 - f1: 0.7114 - val_loss: 0.2632 - val_f1: 0.0631\n",
      "Epoch 140/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2955 - f1: 0.7101 - val_loss: 0.2621 - val_f1: 0.0626\n",
      "Epoch 141/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2943 - f1: 0.7112 - val_loss: 0.2644 - val_f1: 0.0638\n",
      "Epoch 142/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2941 - f1: 0.7110 - val_loss: 0.2606 - val_f1: 0.0616\n",
      "Epoch 143/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2938 - f1: 0.7099 - val_loss: 0.2636 - val_f1: 0.0631\n",
      "Epoch 144/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2954 - f1: 0.7112 - val_loss: 0.2624 - val_f1: 0.0626\n",
      "Epoch 145/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2933 - f1: 0.7127 - val_loss: 0.2614 - val_f1: 0.0621\n",
      "Epoch 146/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2918 - f1: 0.7127 - val_loss: 0.2624 - val_f1: 0.0629\n",
      "Epoch 147/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2908 - f1: 0.7153 - val_loss: 0.2639 - val_f1: 0.0628\n",
      "Epoch 148/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2899 - f1: 0.7159 - val_loss: 0.2633 - val_f1: 0.0622\n",
      "Epoch 149/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2917 - f1: 0.7127 - val_loss: 0.2634 - val_f1: 0.0623\n",
      "Epoch 150/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2897 - f1: 0.7165 - val_loss: 0.2622 - val_f1: 0.0621\n",
      "Epoch 151/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2896 - f1: 0.7158 - val_loss: 0.2623 - val_f1: 0.0622\n",
      "Epoch 152/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2894 - f1: 0.7180 - val_loss: 0.2657 - val_f1: 0.0641\n",
      "Epoch 153/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2887 - f1: 0.7174 - val_loss: 0.2652 - val_f1: 0.0635\n",
      "Epoch 154/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2897 - f1: 0.7162 - val_loss: 0.2637 - val_f1: 0.0621\n",
      "Epoch 155/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2883 - f1: 0.7176 - val_loss: 0.2636 - val_f1: 0.0622\n",
      "Epoch 156/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2883 - f1: 0.7198 - val_loss: 0.2648 - val_f1: 0.0628\n",
      "Epoch 157/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2870 - f1: 0.7184 - val_loss: 0.2626 - val_f1: 0.0621\n",
      "Epoch 158/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2876 - f1: 0.7165 - val_loss: 0.2651 - val_f1: 0.0630\n",
      "Epoch 159/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2851 - f1: 0.7205 - val_loss: 0.2654 - val_f1: 0.0626\n",
      "Epoch 160/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2853 - f1: 0.7212 - val_loss: 0.2647 - val_f1: 0.0621\n",
      "Epoch 161/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2856 - f1: 0.7212 - val_loss: 0.2631 - val_f1: 0.0620\n",
      "Epoch 162/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2850 - f1: 0.7223 - val_loss: 0.2655 - val_f1: 0.0621\n",
      "Epoch 163/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2853 - f1: 0.7204 - val_loss: 0.2638 - val_f1: 0.0619\n",
      "Epoch 164/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2829 - f1: 0.7237 - val_loss: 0.2644 - val_f1: 0.0621\n",
      "Epoch 165/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2834 - f1: 0.7236 - val_loss: 0.2650 - val_f1: 0.0630\n",
      "Epoch 166/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2835 - f1: 0.7226 - val_loss: 0.2651 - val_f1: 0.0624\n",
      "Epoch 167/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2835 - f1: 0.7235 - val_loss: 0.2644 - val_f1: 0.0619\n",
      "Epoch 168/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2825 - f1: 0.7263 - val_loss: 0.2642 - val_f1: 0.0620\n",
      "Epoch 169/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2820 - f1: 0.7267 - val_loss: 0.2635 - val_f1: 0.0616\n",
      "Epoch 170/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2811 - f1: 0.7252 - val_loss: 0.2655 - val_f1: 0.0622\n",
      "Epoch 171/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2823 - f1: 0.7255 - val_loss: 0.2651 - val_f1: 0.0621\n",
      "Epoch 172/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2814 - f1: 0.7259 - val_loss: 0.2641 - val_f1: 0.0620\n",
      "Epoch 173/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2817 - f1: 0.7264 - val_loss: 0.2652 - val_f1: 0.0622\n",
      "Epoch 174/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2802 - f1: 0.7264 - val_loss: 0.2651 - val_f1: 0.0617\n",
      "Epoch 175/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2815 - f1: 0.7296 - val_loss: 0.2656 - val_f1: 0.0621\n",
      "Epoch 176/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2794 - f1: 0.7296 - val_loss: 0.2648 - val_f1: 0.0619\n",
      "Epoch 177/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2792 - f1: 0.7281 - val_loss: 0.2658 - val_f1: 0.0625\n",
      "Epoch 178/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2780 - f1: 0.7323 - val_loss: 0.2649 - val_f1: 0.0616\n",
      "Epoch 179/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2791 - f1: 0.7291 - val_loss: 0.2684 - val_f1: 0.0626\n",
      "Epoch 180/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2800 - f1: 0.7296 - val_loss: 0.2670 - val_f1: 0.0625\n",
      "Epoch 181/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2800 - f1: 0.7274 - val_loss: 0.2655 - val_f1: 0.0614\n",
      "Epoch 182/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2773 - f1: 0.7306 - val_loss: 0.2664 - val_f1: 0.0625\n",
      "Epoch 183/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2777 - f1: 0.7320 - val_loss: 0.2665 - val_f1: 0.0620\n",
      "Epoch 184/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2776 - f1: 0.7310 - val_loss: 0.2645 - val_f1: 0.0615\n",
      "Epoch 185/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2763 - f1: 0.7321 - val_loss: 0.2659 - val_f1: 0.0613\n",
      "Epoch 186/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2742 - f1: 0.7340 - val_loss: 0.2669 - val_f1: 0.0621\n",
      "Epoch 187/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2770 - f1: 0.7330 - val_loss: 0.2648 - val_f1: 0.0613\n",
      "Epoch 188/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2753 - f1: 0.7334 - val_loss: 0.2659 - val_f1: 0.0620\n",
      "Epoch 189/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2761 - f1: 0.7317 - val_loss: 0.2660 - val_f1: 0.0609\n",
      "Epoch 190/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2747 - f1: 0.7350 - val_loss: 0.2670 - val_f1: 0.0616\n",
      "Epoch 191/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2751 - f1: 0.7358 - val_loss: 0.2669 - val_f1: 0.0617\n",
      "Epoch 192/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2743 - f1: 0.7364 - val_loss: 0.2671 - val_f1: 0.0616\n",
      "Epoch 193/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2733 - f1: 0.7365 - val_loss: 0.2660 - val_f1: 0.0613\n",
      "Epoch 194/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2761 - f1: 0.7329 - val_loss: 0.2664 - val_f1: 0.0615\n",
      "Epoch 195/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2717 - f1: 0.7382 - val_loss: 0.2652 - val_f1: 0.0613\n",
      "Epoch 196/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2729 - f1: 0.7372 - val_loss: 0.2668 - val_f1: 0.0607\n",
      "Epoch 197/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2726 - f1: 0.7376 - val_loss: 0.2668 - val_f1: 0.0616\n",
      "Epoch 198/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2727 - f1: 0.7376 - val_loss: 0.2676 - val_f1: 0.0617\n",
      "Epoch 199/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2730 - f1: 0.7378 - val_loss: 0.2670 - val_f1: 0.0615\n",
      "Epoch 200/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2712 - f1: 0.7371 - val_loss: 0.2663 - val_f1: 0.0608\n",
      "Epoch 201/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2721 - f1: 0.7375 - val_loss: 0.2662 - val_f1: 0.0610\n",
      "Epoch 202/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2725 - f1: 0.7386 - val_loss: 0.2669 - val_f1: 0.0615\n",
      "Epoch 203/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2725 - f1: 0.7387 - val_loss: 0.2673 - val_f1: 0.0611\n",
      "Epoch 204/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2680 - f1: 0.7419 - val_loss: 0.2694 - val_f1: 0.0615\n",
      "Epoch 205/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2716 - f1: 0.7367 - val_loss: 0.2675 - val_f1: 0.0618\n",
      "Epoch 206/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2703 - f1: 0.7400 - val_loss: 0.2708 - val_f1: 0.0622\n",
      "Epoch 207/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2693 - f1: 0.7417 - val_loss: 0.2686 - val_f1: 0.0623\n",
      "Epoch 208/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2678 - f1: 0.7413 - val_loss: 0.2673 - val_f1: 0.0614\n",
      "Epoch 209/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2687 - f1: 0.7409 - val_loss: 0.2682 - val_f1: 0.0618\n",
      "Epoch 210/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2685 - f1: 0.7436 - val_loss: 0.2682 - val_f1: 0.0614\n",
      "Epoch 211/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2692 - f1: 0.7412 - val_loss: 0.2672 - val_f1: 0.0609\n",
      "Epoch 212/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2692 - f1: 0.7402 - val_loss: 0.2692 - val_f1: 0.0616\n",
      "Epoch 213/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2677 - f1: 0.7425 - val_loss: 0.2686 - val_f1: 0.0609\n",
      "Epoch 214/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2698 - f1: 0.7385 - val_loss: 0.2679 - val_f1: 0.0615\n",
      "Epoch 215/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2659 - f1: 0.7435 - val_loss: 0.2698 - val_f1: 0.0611\n",
      "Epoch 216/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2680 - f1: 0.7447 - val_loss: 0.2670 - val_f1: 0.0606\n",
      "Epoch 217/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2681 - f1: 0.7418 - val_loss: 0.2689 - val_f1: 0.0607\n",
      "Epoch 218/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2668 - f1: 0.7441 - val_loss: 0.2674 - val_f1: 0.0606\n",
      "Epoch 219/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2660 - f1: 0.7457 - val_loss: 0.2698 - val_f1: 0.0608\n",
      "Epoch 220/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2662 - f1: 0.7439 - val_loss: 0.2691 - val_f1: 0.0620\n",
      "Epoch 221/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2646 - f1: 0.7479 - val_loss: 0.2690 - val_f1: 0.0611\n",
      "Epoch 222/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2656 - f1: 0.7445 - val_loss: 0.2668 - val_f1: 0.0604\n",
      "Epoch 223/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2666 - f1: 0.7425 - val_loss: 0.2691 - val_f1: 0.0621\n",
      "Epoch 224/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2658 - f1: 0.7449 - val_loss: 0.2691 - val_f1: 0.0608\n",
      "Epoch 225/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2643 - f1: 0.7469 - val_loss: 0.2692 - val_f1: 0.0611\n",
      "Epoch 226/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2658 - f1: 0.7431 - val_loss: 0.2698 - val_f1: 0.0614\n",
      "Epoch 227/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2633 - f1: 0.7469 - val_loss: 0.2688 - val_f1: 0.0615\n",
      "Epoch 228/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2644 - f1: 0.7469 - val_loss: 0.2701 - val_f1: 0.0613\n",
      "Epoch 229/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2635 - f1: 0.7494 - val_loss: 0.2707 - val_f1: 0.0615\n",
      "Epoch 230/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2647 - f1: 0.7463 - val_loss: 0.2702 - val_f1: 0.0619\n",
      "Epoch 231/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2644 - f1: 0.7469 - val_loss: 0.2690 - val_f1: 0.0614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2633 - f1: 0.7477 - val_loss: 0.2704 - val_f1: 0.0618\n",
      "Epoch 233/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2634 - f1: 0.7467 - val_loss: 0.2696 - val_f1: 0.0611\n",
      "Epoch 234/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2630 - f1: 0.7478 - val_loss: 0.2707 - val_f1: 0.0616\n",
      "Epoch 235/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2602 - f1: 0.7512 - val_loss: 0.2697 - val_f1: 0.0603\n",
      "Epoch 236/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2617 - f1: 0.7487 - val_loss: 0.2694 - val_f1: 0.0614\n",
      "Epoch 237/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2621 - f1: 0.7487 - val_loss: 0.2699 - val_f1: 0.0607\n",
      "Epoch 238/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2621 - f1: 0.7494 - val_loss: 0.2704 - val_f1: 0.0610\n",
      "Epoch 239/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2605 - f1: 0.7513 - val_loss: 0.2712 - val_f1: 0.0610\n",
      "Epoch 240/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2626 - f1: 0.7476 - val_loss: 0.2709 - val_f1: 0.0611\n",
      "Epoch 241/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2604 - f1: 0.7508 - val_loss: 0.2719 - val_f1: 0.0606\n",
      "Epoch 242/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2607 - f1: 0.7502 - val_loss: 0.2699 - val_f1: 0.0602\n",
      "Epoch 243/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2608 - f1: 0.7506 - val_loss: 0.2716 - val_f1: 0.0615\n",
      "Epoch 244/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2610 - f1: 0.7502 - val_loss: 0.2709 - val_f1: 0.0611\n",
      "Epoch 245/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2598 - f1: 0.7501 - val_loss: 0.2704 - val_f1: 0.0606\n",
      "Epoch 246/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2619 - f1: 0.7498 - val_loss: 0.2698 - val_f1: 0.0605\n",
      "Epoch 247/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2605 - f1: 0.7493 - val_loss: 0.2727 - val_f1: 0.0615\n",
      "Epoch 248/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2600 - f1: 0.7522 - val_loss: 0.2716 - val_f1: 0.0610\n",
      "Epoch 249/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2583 - f1: 0.7553 - val_loss: 0.2730 - val_f1: 0.0617\n",
      "Epoch 250/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2600 - f1: 0.7508 - val_loss: 0.2710 - val_f1: 0.0613\n",
      "Epoch 251/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2586 - f1: 0.7552 - val_loss: 0.2707 - val_f1: 0.0618\n",
      "Epoch 252/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2579 - f1: 0.7543 - val_loss: 0.2722 - val_f1: 0.0610\n",
      "Epoch 253/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2596 - f1: 0.7530 - val_loss: 0.2703 - val_f1: 0.0605\n",
      "Epoch 254/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2592 - f1: 0.7553 - val_loss: 0.2705 - val_f1: 0.0609\n",
      "Epoch 255/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2581 - f1: 0.7533 - val_loss: 0.2741 - val_f1: 0.0618\n",
      "Epoch 256/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2575 - f1: 0.7536 - val_loss: 0.2722 - val_f1: 0.0612\n",
      "Epoch 257/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2574 - f1: 0.7554 - val_loss: 0.2713 - val_f1: 0.0615\n",
      "Epoch 258/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2581 - f1: 0.7545 - val_loss: 0.2716 - val_f1: 0.0609\n",
      "Epoch 259/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2567 - f1: 0.7552 - val_loss: 0.2709 - val_f1: 0.0604\n",
      "Epoch 260/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2578 - f1: 0.7541 - val_loss: 0.2732 - val_f1: 0.0611\n",
      "Epoch 261/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2568 - f1: 0.7557 - val_loss: 0.2715 - val_f1: 0.0617\n",
      "Epoch 262/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2561 - f1: 0.7558 - val_loss: 0.2726 - val_f1: 0.0606\n",
      "Epoch 263/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2588 - f1: 0.7546 - val_loss: 0.2715 - val_f1: 0.0613\n",
      "Epoch 264/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2570 - f1: 0.7562 - val_loss: 0.2723 - val_f1: 0.0609\n",
      "Epoch 265/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2581 - f1: 0.7544 - val_loss: 0.2710 - val_f1: 0.0606\n",
      "Epoch 266/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2551 - f1: 0.7564 - val_loss: 0.2739 - val_f1: 0.0615\n",
      "Epoch 267/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2565 - f1: 0.7563 - val_loss: 0.2714 - val_f1: 0.0604\n",
      "Epoch 268/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2535 - f1: 0.7570 - val_loss: 0.2743 - val_f1: 0.0608\n",
      "Epoch 269/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2561 - f1: 0.7570 - val_loss: 0.2735 - val_f1: 0.0613\n",
      "Epoch 270/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2554 - f1: 0.7571 - val_loss: 0.2751 - val_f1: 0.0615\n",
      "Epoch 271/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2533 - f1: 0.7606 - val_loss: 0.2727 - val_f1: 0.0607\n",
      "Epoch 272/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2547 - f1: 0.7573 - val_loss: 0.2739 - val_f1: 0.0616\n",
      "Epoch 273/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2555 - f1: 0.7583 - val_loss: 0.2721 - val_f1: 0.0612\n",
      "Epoch 274/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2533 - f1: 0.7603 - val_loss: 0.2721 - val_f1: 0.0605\n",
      "Epoch 275/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2555 - f1: 0.7559 - val_loss: 0.2731 - val_f1: 0.0609\n",
      "Epoch 276/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2542 - f1: 0.7590 - val_loss: 0.2737 - val_f1: 0.0613\n",
      "Epoch 277/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2546 - f1: 0.7563 - val_loss: 0.2733 - val_f1: 0.0611\n",
      "Epoch 278/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2530 - f1: 0.7596 - val_loss: 0.2747 - val_f1: 0.0610\n",
      "Epoch 279/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2540 - f1: 0.7578 - val_loss: 0.2726 - val_f1: 0.0608\n",
      "Epoch 280/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2525 - f1: 0.7595 - val_loss: 0.2721 - val_f1: 0.0609\n",
      "Epoch 281/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2534 - f1: 0.7591 - val_loss: 0.2733 - val_f1: 0.0614\n",
      "Epoch 282/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2544 - f1: 0.7611 - val_loss: 0.2730 - val_f1: 0.0600\n",
      "Epoch 283/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2520 - f1: 0.7608 - val_loss: 0.2736 - val_f1: 0.0601\n",
      "Epoch 284/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2536 - f1: 0.7590 - val_loss: 0.2724 - val_f1: 0.0603\n",
      "Epoch 285/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2518 - f1: 0.7602 - val_loss: 0.2744 - val_f1: 0.0606\n",
      "Epoch 286/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2541 - f1: 0.7576 - val_loss: 0.2742 - val_f1: 0.0606\n",
      "Epoch 287/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2516 - f1: 0.7616 - val_loss: 0.2738 - val_f1: 0.0601\n",
      "Epoch 288/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2541 - f1: 0.7613 - val_loss: 0.2737 - val_f1: 0.0601\n",
      "Epoch 289/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2524 - f1: 0.7616 - val_loss: 0.2735 - val_f1: 0.0608\n",
      "Epoch 290/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2520 - f1: 0.7608 - val_loss: 0.2726 - val_f1: 0.0607\n",
      "Epoch 291/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2537 - f1: 0.7594 - val_loss: 0.2718 - val_f1: 0.0599\n",
      "Epoch 292/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2501 - f1: 0.7622 - val_loss: 0.2738 - val_f1: 0.0598\n",
      "Epoch 293/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2513 - f1: 0.7636 - val_loss: 0.2739 - val_f1: 0.0605\n",
      "Epoch 294/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2513 - f1: 0.7629 - val_loss: 0.2762 - val_f1: 0.0604\n",
      "Epoch 295/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2500 - f1: 0.7635 - val_loss: 0.2746 - val_f1: 0.0602\n",
      "Epoch 296/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2508 - f1: 0.7618 - val_loss: 0.2725 - val_f1: 0.0604\n",
      "Epoch 297/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2488 - f1: 0.7646 - val_loss: 0.2752 - val_f1: 0.0609\n",
      "Epoch 298/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2496 - f1: 0.7636 - val_loss: 0.2748 - val_f1: 0.0611\n",
      "Epoch 299/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2513 - f1: 0.7635 - val_loss: 0.2743 - val_f1: 0.0609\n",
      "Epoch 300/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2521 - f1: 0.7610 - val_loss: 0.2758 - val_f1: 0.0609\n",
      "Epoch 301/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2495 - f1: 0.7647 - val_loss: 0.2748 - val_f1: 0.0607\n",
      "Epoch 302/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2491 - f1: 0.7662 - val_loss: 0.2755 - val_f1: 0.0599\n",
      "Epoch 303/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2495 - f1: 0.7654 - val_loss: 0.2768 - val_f1: 0.0607\n",
      "Epoch 304/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2494 - f1: 0.7634 - val_loss: 0.2750 - val_f1: 0.0606\n",
      "Epoch 305/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2503 - f1: 0.7640 - val_loss: 0.2741 - val_f1: 0.0607\n",
      "Epoch 306/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2482 - f1: 0.7663 - val_loss: 0.2744 - val_f1: 0.0600\n",
      "Epoch 307/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2493 - f1: 0.7638 - val_loss: 0.2746 - val_f1: 0.0605\n",
      "Epoch 308/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2490 - f1: 0.7648 - val_loss: 0.2739 - val_f1: 0.0607\n",
      "Epoch 309/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2479 - f1: 0.7657 - val_loss: 0.2758 - val_f1: 0.0601\n",
      "Epoch 310/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2488 - f1: 0.7641 - val_loss: 0.2753 - val_f1: 0.0604\n",
      "Epoch 311/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2478 - f1: 0.7676 - val_loss: 0.2730 - val_f1: 0.0599\n",
      "Epoch 312/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2473 - f1: 0.7633 - val_loss: 0.2765 - val_f1: 0.0598\n",
      "Epoch 313/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2484 - f1: 0.7656 - val_loss: 0.2737 - val_f1: 0.0598\n",
      "Epoch 314/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2487 - f1: 0.7639 - val_loss: 0.2748 - val_f1: 0.0604\n",
      "Epoch 315/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2488 - f1: 0.7660 - val_loss: 0.2746 - val_f1: 0.0604\n",
      "Epoch 316/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2482 - f1: 0.7651 - val_loss: 0.2755 - val_f1: 0.0597\n",
      "Epoch 317/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2477 - f1: 0.7660 - val_loss: 0.2758 - val_f1: 0.0602\n",
      "Epoch 318/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2478 - f1: 0.7651 - val_loss: 0.2762 - val_f1: 0.0610\n",
      "Epoch 319/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2480 - f1: 0.7638 - val_loss: 0.2776 - val_f1: 0.0605\n",
      "Epoch 320/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2474 - f1: 0.7653 - val_loss: 0.2750 - val_f1: 0.0593\n",
      "Epoch 321/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2469 - f1: 0.7672 - val_loss: 0.2761 - val_f1: 0.0608\n",
      "Epoch 322/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2485 - f1: 0.7642 - val_loss: 0.2756 - val_f1: 0.0593\n",
      "Epoch 323/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2465 - f1: 0.7674 - val_loss: 0.2755 - val_f1: 0.0606\n",
      "Epoch 324/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2458 - f1: 0.7674 - val_loss: 0.2767 - val_f1: 0.0602\n",
      "Epoch 325/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2475 - f1: 0.7654 - val_loss: 0.2753 - val_f1: 0.0602\n",
      "Epoch 326/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2459 - f1: 0.7677 - val_loss: 0.2754 - val_f1: 0.0605\n",
      "Epoch 327/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2476 - f1: 0.7668 - val_loss: 0.2760 - val_f1: 0.0600\n",
      "Epoch 328/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2468 - f1: 0.7650 - val_loss: 0.2743 - val_f1: 0.0604\n",
      "Epoch 329/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2466 - f1: 0.7683 - val_loss: 0.2739 - val_f1: 0.0609\n",
      "Epoch 330/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2475 - f1: 0.7690 - val_loss: 0.2732 - val_f1: 0.0600\n",
      "Epoch 331/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2459 - f1: 0.7662 - val_loss: 0.2762 - val_f1: 0.0596\n",
      "Epoch 332/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2455 - f1: 0.7684 - val_loss: 0.2763 - val_f1: 0.0601\n",
      "Epoch 333/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2454 - f1: 0.7680 - val_loss: 0.2756 - val_f1: 0.0608\n",
      "Epoch 334/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2438 - f1: 0.7683 - val_loss: 0.2764 - val_f1: 0.0601\n",
      "Epoch 335/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2452 - f1: 0.7678 - val_loss: 0.2772 - val_f1: 0.0598\n",
      "Epoch 336/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2452 - f1: 0.7673 - val_loss: 0.2741 - val_f1: 0.0590\n",
      "Epoch 337/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2447 - f1: 0.7679 - val_loss: 0.2768 - val_f1: 0.0610\n",
      "Epoch 338/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2430 - f1: 0.7733 - val_loss: 0.2802 - val_f1: 0.0602\n",
      "Epoch 339/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2463 - f1: 0.7666 - val_loss: 0.2736 - val_f1: 0.0595\n",
      "Epoch 340/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2445 - f1: 0.7697 - val_loss: 0.2759 - val_f1: 0.0592\n",
      "Epoch 341/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2425 - f1: 0.7695 - val_loss: 0.2770 - val_f1: 0.0602\n",
      "Epoch 342/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2452 - f1: 0.7688 - val_loss: 0.2785 - val_f1: 0.0605\n",
      "Epoch 343/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2445 - f1: 0.7688 - val_loss: 0.2771 - val_f1: 0.0598\n",
      "Epoch 344/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2433 - f1: 0.7719 - val_loss: 0.2777 - val_f1: 0.0602\n",
      "Epoch 345/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2429 - f1: 0.7707 - val_loss: 0.2774 - val_f1: 0.0603\n",
      "Epoch 346/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2448 - f1: 0.7690 - val_loss: 0.2753 - val_f1: 0.0593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2441 - f1: 0.7710 - val_loss: 0.2759 - val_f1: 0.0604\n",
      "Epoch 348/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2438 - f1: 0.7686 - val_loss: 0.2765 - val_f1: 0.0607\n",
      "Epoch 349/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2435 - f1: 0.7733 - val_loss: 0.2745 - val_f1: 0.0592\n",
      "Epoch 350/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2429 - f1: 0.7710 - val_loss: 0.2782 - val_f1: 0.0601\n",
      "Epoch 351/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2417 - f1: 0.7735 - val_loss: 0.2785 - val_f1: 0.0602\n",
      "Epoch 352/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2428 - f1: 0.7720 - val_loss: 0.2773 - val_f1: 0.0603\n",
      "Epoch 353/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2418 - f1: 0.7726 - val_loss: 0.2785 - val_f1: 0.0604\n",
      "Epoch 354/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2442 - f1: 0.7708 - val_loss: 0.2768 - val_f1: 0.0610\n",
      "Epoch 355/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2421 - f1: 0.7709 - val_loss: 0.2773 - val_f1: 0.0603\n",
      "Epoch 356/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2416 - f1: 0.7735 - val_loss: 0.2778 - val_f1: 0.0603\n",
      "Epoch 357/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2418 - f1: 0.7717 - val_loss: 0.2765 - val_f1: 0.0601\n",
      "Epoch 358/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2414 - f1: 0.7727 - val_loss: 0.2771 - val_f1: 0.0600\n",
      "Epoch 359/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2426 - f1: 0.7715 - val_loss: 0.2770 - val_f1: 0.0611\n",
      "Epoch 360/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2419 - f1: 0.7731 - val_loss: 0.2777 - val_f1: 0.0611\n",
      "Epoch 361/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2440 - f1: 0.7710 - val_loss: 0.2762 - val_f1: 0.0599\n",
      "Epoch 362/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2429 - f1: 0.7723 - val_loss: 0.2786 - val_f1: 0.0607\n",
      "Epoch 363/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2408 - f1: 0.7730 - val_loss: 0.2777 - val_f1: 0.0597\n",
      "Epoch 364/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2398 - f1: 0.7742 - val_loss: 0.2777 - val_f1: 0.0591\n",
      "Epoch 365/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2414 - f1: 0.7734 - val_loss: 0.2791 - val_f1: 0.0607\n",
      "Epoch 366/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2419 - f1: 0.7730 - val_loss: 0.2775 - val_f1: 0.0596\n",
      "Epoch 367/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2412 - f1: 0.7722 - val_loss: 0.2777 - val_f1: 0.0599\n",
      "Epoch 368/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2422 - f1: 0.7729 - val_loss: 0.2796 - val_f1: 0.0604\n",
      "Epoch 369/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2408 - f1: 0.7736 - val_loss: 0.2776 - val_f1: 0.0596\n",
      "Epoch 370/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2419 - f1: 0.7720 - val_loss: 0.2784 - val_f1: 0.0602\n",
      "Epoch 371/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2417 - f1: 0.7718 - val_loss: 0.2755 - val_f1: 0.0590\n",
      "Epoch 372/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2405 - f1: 0.7731 - val_loss: 0.2774 - val_f1: 0.0603\n",
      "Epoch 373/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2407 - f1: 0.7735 - val_loss: 0.2764 - val_f1: 0.0597\n",
      "Epoch 374/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2401 - f1: 0.7728 - val_loss: 0.2772 - val_f1: 0.0596\n",
      "Epoch 375/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2404 - f1: 0.7750 - val_loss: 0.2785 - val_f1: 0.0591\n",
      "Epoch 376/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2389 - f1: 0.7756 - val_loss: 0.2803 - val_f1: 0.0593\n",
      "Epoch 377/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2397 - f1: 0.7735 - val_loss: 0.2798 - val_f1: 0.0602\n",
      "Epoch 378/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2392 - f1: 0.7745 - val_loss: 0.2792 - val_f1: 0.0598\n",
      "Epoch 379/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2396 - f1: 0.7759 - val_loss: 0.2789 - val_f1: 0.0602\n",
      "Epoch 380/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2401 - f1: 0.7748 - val_loss: 0.2797 - val_f1: 0.0590\n",
      "Epoch 381/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2397 - f1: 0.7777 - val_loss: 0.2801 - val_f1: 0.0612\n",
      "Epoch 382/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2394 - f1: 0.7751 - val_loss: 0.2775 - val_f1: 0.0597\n",
      "Epoch 383/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2391 - f1: 0.7754 - val_loss: 0.2770 - val_f1: 0.0596\n",
      "Epoch 384/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2398 - f1: 0.7745 - val_loss: 0.2789 - val_f1: 0.0607\n",
      "Epoch 385/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2402 - f1: 0.7733 - val_loss: 0.2800 - val_f1: 0.0597\n",
      "Epoch 386/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2399 - f1: 0.7754 - val_loss: 0.2814 - val_f1: 0.0596\n",
      "Epoch 387/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2402 - f1: 0.7741 - val_loss: 0.2785 - val_f1: 0.0603\n",
      "Epoch 388/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2381 - f1: 0.7781 - val_loss: 0.2804 - val_f1: 0.0593\n",
      "Epoch 389/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2400 - f1: 0.7742 - val_loss: 0.2799 - val_f1: 0.0590\n",
      "Epoch 390/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2374 - f1: 0.7792 - val_loss: 0.2787 - val_f1: 0.0608\n",
      "Epoch 391/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2396 - f1: 0.7766 - val_loss: 0.2805 - val_f1: 0.0589\n",
      "Epoch 392/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2396 - f1: 0.7754 - val_loss: 0.2791 - val_f1: 0.0591\n",
      "Epoch 393/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2401 - f1: 0.7755 - val_loss: 0.2779 - val_f1: 0.0589\n",
      "Epoch 394/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2368 - f1: 0.7771 - val_loss: 0.2807 - val_f1: 0.0604\n",
      "Epoch 395/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2394 - f1: 0.7763 - val_loss: 0.2800 - val_f1: 0.0599\n",
      "Epoch 396/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2387 - f1: 0.7773 - val_loss: 0.2814 - val_f1: 0.0601\n",
      "Epoch 397/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2380 - f1: 0.7766 - val_loss: 0.2773 - val_f1: 0.0579\n",
      "Epoch 398/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2395 - f1: 0.7745 - val_loss: 0.2783 - val_f1: 0.0596\n",
      "Epoch 399/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2377 - f1: 0.7773 - val_loss: 0.2800 - val_f1: 0.0592\n",
      "Epoch 400/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2377 - f1: 0.7771 - val_loss: 0.2786 - val_f1: 0.0598\n",
      "Epoch 401/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2376 - f1: 0.7781 - val_loss: 0.2794 - val_f1: 0.0595\n",
      "Epoch 402/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2389 - f1: 0.7760 - val_loss: 0.2780 - val_f1: 0.0599\n",
      "Epoch 403/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2375 - f1: 0.7767 - val_loss: 0.2786 - val_f1: 0.0597\n",
      "Epoch 404/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2374 - f1: 0.7741 - val_loss: 0.2804 - val_f1: 0.0605\n",
      "Epoch 405/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2378 - f1: 0.7768 - val_loss: 0.2809 - val_f1: 0.0597\n",
      "Epoch 406/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2386 - f1: 0.7756 - val_loss: 0.2802 - val_f1: 0.0602\n",
      "Epoch 407/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2351 - f1: 0.7801 - val_loss: 0.2805 - val_f1: 0.0603\n",
      "Epoch 408/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2372 - f1: 0.7785 - val_loss: 0.2811 - val_f1: 0.0592\n",
      "Epoch 409/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2368 - f1: 0.7784 - val_loss: 0.2781 - val_f1: 0.0594\n",
      "Epoch 410/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2367 - f1: 0.7770 - val_loss: 0.2808 - val_f1: 0.0597\n",
      "Epoch 411/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2364 - f1: 0.7785 - val_loss: 0.2814 - val_f1: 0.0588\n",
      "Epoch 412/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2362 - f1: 0.7771 - val_loss: 0.2809 - val_f1: 0.0597\n",
      "Epoch 413/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2362 - f1: 0.7786 - val_loss: 0.2800 - val_f1: 0.0597\n",
      "Epoch 414/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2354 - f1: 0.7801 - val_loss: 0.2797 - val_f1: 0.0598\n",
      "Epoch 415/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2377 - f1: 0.7780 - val_loss: 0.2788 - val_f1: 0.0594\n",
      "Epoch 416/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2349 - f1: 0.7807 - val_loss: 0.2793 - val_f1: 0.0582\n",
      "Epoch 417/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2359 - f1: 0.7797 - val_loss: 0.2803 - val_f1: 0.0576\n",
      "Epoch 418/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2355 - f1: 0.7786 - val_loss: 0.2801 - val_f1: 0.0595\n",
      "Epoch 419/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2358 - f1: 0.7809 - val_loss: 0.2816 - val_f1: 0.0594\n",
      "Epoch 420/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2371 - f1: 0.7780 - val_loss: 0.2805 - val_f1: 0.0601\n",
      "Epoch 421/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2355 - f1: 0.7793 - val_loss: 0.2805 - val_f1: 0.0589\n",
      "Epoch 422/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2364 - f1: 0.7806 - val_loss: 0.2813 - val_f1: 0.0589\n",
      "Epoch 423/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2359 - f1: 0.7785 - val_loss: 0.2797 - val_f1: 0.0590\n",
      "Epoch 424/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2348 - f1: 0.7790 - val_loss: 0.2811 - val_f1: 0.0597\n",
      "Epoch 425/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2364 - f1: 0.7786 - val_loss: 0.2807 - val_f1: 0.0597\n",
      "Epoch 426/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2344 - f1: 0.7813 - val_loss: 0.2805 - val_f1: 0.0596\n",
      "Epoch 427/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2359 - f1: 0.7786 - val_loss: 0.2823 - val_f1: 0.0591\n",
      "Epoch 428/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2354 - f1: 0.7791 - val_loss: 0.2807 - val_f1: 0.0582\n",
      "Epoch 429/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2360 - f1: 0.7790 - val_loss: 0.2812 - val_f1: 0.0593\n",
      "Epoch 430/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2348 - f1: 0.7810 - val_loss: 0.2803 - val_f1: 0.0597\n",
      "Epoch 431/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2345 - f1: 0.7811 - val_loss: 0.2817 - val_f1: 0.0586\n",
      "Epoch 432/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2346 - f1: 0.7809 - val_loss: 0.2795 - val_f1: 0.0594\n",
      "Epoch 433/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2339 - f1: 0.7832 - val_loss: 0.2809 - val_f1: 0.0592\n",
      "Epoch 434/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2347 - f1: 0.7817 - val_loss: 0.2818 - val_f1: 0.0582\n",
      "Epoch 435/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2356 - f1: 0.7823 - val_loss: 0.2791 - val_f1: 0.0585\n",
      "Epoch 436/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2343 - f1: 0.7809 - val_loss: 0.2803 - val_f1: 0.0590\n",
      "Epoch 437/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2333 - f1: 0.7819 - val_loss: 0.2803 - val_f1: 0.0596\n",
      "Epoch 438/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2324 - f1: 0.7833 - val_loss: 0.2838 - val_f1: 0.0583\n",
      "Epoch 439/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2346 - f1: 0.7811 - val_loss: 0.2810 - val_f1: 0.0594\n",
      "Epoch 440/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2350 - f1: 0.7823 - val_loss: 0.2813 - val_f1: 0.0590\n",
      "Epoch 441/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2332 - f1: 0.7801 - val_loss: 0.2832 - val_f1: 0.0590\n",
      "Epoch 442/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2345 - f1: 0.7811 - val_loss: 0.2819 - val_f1: 0.0588\n",
      "Epoch 443/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2357 - f1: 0.7821 - val_loss: 0.2798 - val_f1: 0.0592\n",
      "Epoch 444/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2320 - f1: 0.7839 - val_loss: 0.2818 - val_f1: 0.0588\n",
      "Epoch 445/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2343 - f1: 0.7812 - val_loss: 0.2804 - val_f1: 0.0587\n",
      "Epoch 446/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2350 - f1: 0.7812 - val_loss: 0.2827 - val_f1: 0.0592\n",
      "Epoch 447/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2335 - f1: 0.7809 - val_loss: 0.2824 - val_f1: 0.0597\n",
      "Epoch 448/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2334 - f1: 0.7823 - val_loss: 0.2820 - val_f1: 0.0596\n",
      "Epoch 449/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2348 - f1: 0.7828 - val_loss: 0.2820 - val_f1: 0.0592\n",
      "Epoch 450/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2334 - f1: 0.7805 - val_loss: 0.2805 - val_f1: 0.0592\n",
      "Epoch 451/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2333 - f1: 0.7819 - val_loss: 0.2825 - val_f1: 0.0592\n",
      "Epoch 452/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2342 - f1: 0.7821 - val_loss: 0.2805 - val_f1: 0.0593\n",
      "Epoch 453/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2317 - f1: 0.7834 - val_loss: 0.2857 - val_f1: 0.0585\n",
      "Epoch 454/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2330 - f1: 0.7805 - val_loss: 0.2829 - val_f1: 0.0588\n",
      "Epoch 455/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2301 - f1: 0.7864 - val_loss: 0.2840 - val_f1: 0.0594\n",
      "Epoch 456/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2330 - f1: 0.7838 - val_loss: 0.2811 - val_f1: 0.0584\n",
      "Epoch 457/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2319 - f1: 0.7827 - val_loss: 0.2819 - val_f1: 0.0586\n",
      "Epoch 458/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2320 - f1: 0.7827 - val_loss: 0.2822 - val_f1: 0.0592\n",
      "Epoch 459/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2322 - f1: 0.7845 - val_loss: 0.2836 - val_f1: 0.0579\n",
      "Epoch 460/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2337 - f1: 0.7842 - val_loss: 0.2818 - val_f1: 0.0594\n",
      "Epoch 461/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2323 - f1: 0.7846 - val_loss: 0.2824 - val_f1: 0.0584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2322 - f1: 0.7841 - val_loss: 0.2836 - val_f1: 0.0589\n",
      "Epoch 463/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2322 - f1: 0.7867 - val_loss: 0.2825 - val_f1: 0.0596\n",
      "Epoch 464/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2315 - f1: 0.7853 - val_loss: 0.2823 - val_f1: 0.0595\n",
      "Epoch 465/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2315 - f1: 0.7836 - val_loss: 0.2823 - val_f1: 0.0580\n",
      "Epoch 466/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2316 - f1: 0.7838 - val_loss: 0.2820 - val_f1: 0.0592\n",
      "Epoch 467/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2322 - f1: 0.7833 - val_loss: 0.2829 - val_f1: 0.0585\n",
      "Epoch 468/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2320 - f1: 0.7841 - val_loss: 0.2840 - val_f1: 0.0584\n",
      "Epoch 469/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2302 - f1: 0.7845 - val_loss: 0.2840 - val_f1: 0.0585\n",
      "Epoch 470/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2305 - f1: 0.7856 - val_loss: 0.2816 - val_f1: 0.0604\n",
      "Epoch 471/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2305 - f1: 0.7835 - val_loss: 0.2838 - val_f1: 0.0583\n",
      "Epoch 472/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2324 - f1: 0.7835 - val_loss: 0.2818 - val_f1: 0.0590\n",
      "Epoch 473/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2322 - f1: 0.7826 - val_loss: 0.2817 - val_f1: 0.0591\n",
      "Epoch 474/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2319 - f1: 0.7836 - val_loss: 0.2821 - val_f1: 0.0593\n",
      "Epoch 475/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2310 - f1: 0.7836 - val_loss: 0.2835 - val_f1: 0.0590\n",
      "Epoch 476/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2313 - f1: 0.7852 - val_loss: 0.2831 - val_f1: 0.0585\n",
      "Epoch 477/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2304 - f1: 0.7862 - val_loss: 0.2850 - val_f1: 0.0589\n",
      "Epoch 478/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2305 - f1: 0.7840 - val_loss: 0.2841 - val_f1: 0.0583\n",
      "Epoch 479/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2308 - f1: 0.7857 - val_loss: 0.2838 - val_f1: 0.0595\n",
      "Epoch 480/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2310 - f1: 0.7847 - val_loss: 0.2821 - val_f1: 0.0595\n",
      "Epoch 481/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2320 - f1: 0.7828 - val_loss: 0.2839 - val_f1: 0.0593\n",
      "Epoch 482/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2318 - f1: 0.7836 - val_loss: 0.2836 - val_f1: 0.0589\n",
      "Epoch 483/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2299 - f1: 0.7852 - val_loss: 0.2841 - val_f1: 0.0590\n",
      "Epoch 484/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2291 - f1: 0.7855 - val_loss: 0.2863 - val_f1: 0.0583\n",
      "Epoch 485/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2300 - f1: 0.7857 - val_loss: 0.2826 - val_f1: 0.0589\n",
      "Epoch 486/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2297 - f1: 0.7867 - val_loss: 0.2829 - val_f1: 0.0593\n",
      "Epoch 487/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2299 - f1: 0.7859 - val_loss: 0.2847 - val_f1: 0.0581\n",
      "Epoch 488/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2293 - f1: 0.7876 - val_loss: 0.2825 - val_f1: 0.0583\n",
      "Epoch 489/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2303 - f1: 0.7846 - val_loss: 0.2837 - val_f1: 0.0583\n",
      "Epoch 490/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2311 - f1: 0.7853 - val_loss: 0.2820 - val_f1: 0.0588\n",
      "Epoch 491/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2305 - f1: 0.7849 - val_loss: 0.2850 - val_f1: 0.0594\n",
      "Epoch 492/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2296 - f1: 0.7893 - val_loss: 0.2852 - val_f1: 0.0595\n",
      "Epoch 493/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2300 - f1: 0.7844 - val_loss: 0.2838 - val_f1: 0.0593\n",
      "Epoch 494/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2295 - f1: 0.7874 - val_loss: 0.2849 - val_f1: 0.0592\n",
      "Epoch 495/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2287 - f1: 0.7890 - val_loss: 0.2851 - val_f1: 0.0598\n",
      "Epoch 496/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2288 - f1: 0.7874 - val_loss: 0.2833 - val_f1: 0.0581\n",
      "Epoch 497/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2303 - f1: 0.7863 - val_loss: 0.2830 - val_f1: 0.0590\n",
      "Epoch 498/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2301 - f1: 0.7872 - val_loss: 0.2819 - val_f1: 0.0592\n",
      "Epoch 499/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2289 - f1: 0.7873 - val_loss: 0.2843 - val_f1: 0.0587\n",
      "Epoch 500/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2301 - f1: 0.7850 - val_loss: 0.2839 - val_f1: 0.0585\n",
      "Epoch 501/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2286 - f1: 0.7858 - val_loss: 0.2861 - val_f1: 0.0587\n",
      "Epoch 502/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2291 - f1: 0.7859 - val_loss: 0.2838 - val_f1: 0.0591\n",
      "Epoch 503/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2290 - f1: 0.7878 - val_loss: 0.2841 - val_f1: 0.0601\n",
      "Epoch 504/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2287 - f1: 0.7887 - val_loss: 0.2835 - val_f1: 0.0595\n",
      "Epoch 505/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2299 - f1: 0.7876 - val_loss: 0.2843 - val_f1: 0.0587\n",
      "Epoch 506/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2305 - f1: 0.7846 - val_loss: 0.2848 - val_f1: 0.0595\n",
      "Epoch 507/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2300 - f1: 0.7870 - val_loss: 0.2841 - val_f1: 0.0586\n",
      "Epoch 508/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2289 - f1: 0.7856 - val_loss: 0.2843 - val_f1: 0.0588\n",
      "Epoch 509/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2278 - f1: 0.7900 - val_loss: 0.2866 - val_f1: 0.0594\n",
      "Epoch 510/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2287 - f1: 0.7891 - val_loss: 0.2841 - val_f1: 0.0579\n",
      "Epoch 511/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2288 - f1: 0.7844 - val_loss: 0.2850 - val_f1: 0.0582\n",
      "Epoch 512/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2286 - f1: 0.7874 - val_loss: 0.2849 - val_f1: 0.0582\n",
      "Epoch 513/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2280 - f1: 0.7882 - val_loss: 0.2840 - val_f1: 0.0594\n",
      "Epoch 514/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2271 - f1: 0.7867 - val_loss: 0.2828 - val_f1: 0.0591\n",
      "Epoch 515/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2266 - f1: 0.7895 - val_loss: 0.2850 - val_f1: 0.0598\n",
      "Epoch 516/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2273 - f1: 0.7879 - val_loss: 0.2861 - val_f1: 0.0592\n",
      "Epoch 517/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2287 - f1: 0.7864 - val_loss: 0.2851 - val_f1: 0.0589\n",
      "Epoch 518/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2286 - f1: 0.7869 - val_loss: 0.2833 - val_f1: 0.0599\n",
      "Epoch 519/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2270 - f1: 0.7876 - val_loss: 0.2859 - val_f1: 0.0593\n",
      "Epoch 520/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2270 - f1: 0.7900 - val_loss: 0.2846 - val_f1: 0.0592\n",
      "Epoch 521/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2264 - f1: 0.7898 - val_loss: 0.2838 - val_f1: 0.0587\n",
      "Epoch 522/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2290 - f1: 0.7861 - val_loss: 0.2828 - val_f1: 0.0592\n",
      "Epoch 523/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2268 - f1: 0.7896 - val_loss: 0.2864 - val_f1: 0.0588\n",
      "Epoch 524/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2264 - f1: 0.7883 - val_loss: 0.2847 - val_f1: 0.0590\n",
      "Epoch 525/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2280 - f1: 0.7881 - val_loss: 0.2860 - val_f1: 0.0596\n",
      "Epoch 526/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2269 - f1: 0.7904 - val_loss: 0.2841 - val_f1: 0.0591\n",
      "Epoch 527/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2293 - f1: 0.7882 - val_loss: 0.2849 - val_f1: 0.0593\n",
      "Epoch 528/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2276 - f1: 0.7897 - val_loss: 0.2840 - val_f1: 0.0591\n",
      "Epoch 529/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2255 - f1: 0.7906 - val_loss: 0.2856 - val_f1: 0.0588\n",
      "Epoch 530/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2279 - f1: 0.7897 - val_loss: 0.2864 - val_f1: 0.0594\n",
      "Epoch 531/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2264 - f1: 0.7917 - val_loss: 0.2868 - val_f1: 0.0590\n",
      "Epoch 532/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2269 - f1: 0.7900 - val_loss: 0.2873 - val_f1: 0.0583\n",
      "Epoch 533/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2261 - f1: 0.7894 - val_loss: 0.2849 - val_f1: 0.0595\n",
      "Epoch 534/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2262 - f1: 0.7908 - val_loss: 0.2862 - val_f1: 0.0586\n",
      "Epoch 535/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2276 - f1: 0.7910 - val_loss: 0.2849 - val_f1: 0.0593\n",
      "Epoch 536/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2272 - f1: 0.7879 - val_loss: 0.2832 - val_f1: 0.0589\n",
      "Epoch 537/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2250 - f1: 0.7921 - val_loss: 0.2883 - val_f1: 0.0588\n",
      "Epoch 538/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2252 - f1: 0.7896 - val_loss: 0.2873 - val_f1: 0.0592\n",
      "Epoch 539/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2253 - f1: 0.7910 - val_loss: 0.2869 - val_f1: 0.0590\n",
      "Epoch 540/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2257 - f1: 0.7893 - val_loss: 0.2863 - val_f1: 0.0586\n",
      "Epoch 541/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2261 - f1: 0.7904 - val_loss: 0.2859 - val_f1: 0.0587\n",
      "Epoch 542/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2270 - f1: 0.7877 - val_loss: 0.2850 - val_f1: 0.0592\n",
      "Epoch 543/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2239 - f1: 0.7938 - val_loss: 0.2858 - val_f1: 0.0594\n",
      "Epoch 544/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2248 - f1: 0.7915 - val_loss: 0.2877 - val_f1: 0.0599\n",
      "Epoch 545/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2263 - f1: 0.7910 - val_loss: 0.2897 - val_f1: 0.0583\n",
      "Epoch 546/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2270 - f1: 0.7889 - val_loss: 0.2881 - val_f1: 0.0593\n",
      "Epoch 547/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2259 - f1: 0.7895 - val_loss: 0.2866 - val_f1: 0.0581\n",
      "Epoch 548/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2238 - f1: 0.7925 - val_loss: 0.2858 - val_f1: 0.0593\n",
      "Epoch 549/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2269 - f1: 0.7893 - val_loss: 0.2867 - val_f1: 0.0585\n",
      "Epoch 550/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2259 - f1: 0.7897 - val_loss: 0.2847 - val_f1: 0.0588\n",
      "Epoch 551/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2259 - f1: 0.7901 - val_loss: 0.2841 - val_f1: 0.0581\n",
      "Epoch 552/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2263 - f1: 0.7901 - val_loss: 0.2839 - val_f1: 0.0584\n",
      "Epoch 553/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2253 - f1: 0.7905 - val_loss: 0.2836 - val_f1: 0.0595\n",
      "Epoch 554/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.2247 - f1: 0.7910 - val_loss: 0.2867 - val_f1: 0.0587\n",
      "Epoch 555/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.2263 - f1: 0.7909 - val_loss: 0.2854 - val_f1: 0.0587\n",
      "Epoch 556/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2251 - f1: 0.7907 - val_loss: 0.2849 - val_f1: 0.0583\n",
      "Epoch 557/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2243 - f1: 0.7923 - val_loss: 0.2860 - val_f1: 0.0594\n",
      "Epoch 558/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2252 - f1: 0.7895 - val_loss: 0.2853 - val_f1: 0.0592\n",
      "Epoch 559/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2258 - f1: 0.7884 - val_loss: 0.2852 - val_f1: 0.0585\n",
      "Epoch 560/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2248 - f1: 0.7936 - val_loss: 0.2871 - val_f1: 0.0589\n",
      "Epoch 561/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2252 - f1: 0.7906 - val_loss: 0.2857 - val_f1: 0.0582\n",
      "Epoch 562/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2239 - f1: 0.7915 - val_loss: 0.2863 - val_f1: 0.0593\n",
      "Epoch 563/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2254 - f1: 0.7912 - val_loss: 0.2848 - val_f1: 0.0602\n",
      "Epoch 564/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2259 - f1: 0.7904 - val_loss: 0.2852 - val_f1: 0.0581\n",
      "Epoch 565/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2228 - f1: 0.7942 - val_loss: 0.2876 - val_f1: 0.0581\n",
      "Epoch 566/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2249 - f1: 0.7932 - val_loss: 0.2850 - val_f1: 0.0585\n",
      "Epoch 567/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2256 - f1: 0.7915 - val_loss: 0.2858 - val_f1: 0.0585\n",
      "Epoch 568/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2234 - f1: 0.7933 - val_loss: 0.2854 - val_f1: 0.0582\n",
      "Epoch 569/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2246 - f1: 0.7913 - val_loss: 0.2854 - val_f1: 0.0589\n",
      "Epoch 570/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2252 - f1: 0.7932 - val_loss: 0.2873 - val_f1: 0.0585\n",
      "Epoch 571/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2255 - f1: 0.7905 - val_loss: 0.2852 - val_f1: 0.0585\n",
      "Epoch 572/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2244 - f1: 0.7907 - val_loss: 0.2899 - val_f1: 0.0586\n",
      "Epoch 573/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2248 - f1: 0.7902 - val_loss: 0.2865 - val_f1: 0.0584\n",
      "Epoch 574/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2237 - f1: 0.7922 - val_loss: 0.2881 - val_f1: 0.0590\n",
      "Epoch 575/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2275 - f1: 0.7877 - val_loss: 0.2861 - val_f1: 0.0612\n",
      "Epoch 576/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2235 - f1: 0.7956 - val_loss: 0.2880 - val_f1: 0.0587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 577/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2237 - f1: 0.7912 - val_loss: 0.2894 - val_f1: 0.0591\n",
      "Epoch 578/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2237 - f1: 0.7928 - val_loss: 0.2899 - val_f1: 0.0593\n",
      "Epoch 579/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2246 - f1: 0.7939 - val_loss: 0.2872 - val_f1: 0.0583\n",
      "Epoch 580/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2233 - f1: 0.7921 - val_loss: 0.2858 - val_f1: 0.0585\n",
      "Epoch 581/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2246 - f1: 0.7925 - val_loss: 0.2890 - val_f1: 0.0585\n",
      "Epoch 582/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2235 - f1: 0.7920 - val_loss: 0.2866 - val_f1: 0.0588\n",
      "Epoch 583/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2239 - f1: 0.7908 - val_loss: 0.2863 - val_f1: 0.0592\n",
      "Epoch 584/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2238 - f1: 0.7931 - val_loss: 0.2878 - val_f1: 0.0590\n",
      "Epoch 585/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2246 - f1: 0.7937 - val_loss: 0.2884 - val_f1: 0.0590\n",
      "Epoch 586/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2240 - f1: 0.7922 - val_loss: 0.2873 - val_f1: 0.0592\n",
      "Epoch 587/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2239 - f1: 0.7938 - val_loss: 0.2888 - val_f1: 0.0595\n",
      "Epoch 588/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2231 - f1: 0.7923 - val_loss: 0.2852 - val_f1: 0.0594\n",
      "Epoch 589/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2237 - f1: 0.7936 - val_loss: 0.2857 - val_f1: 0.0590\n",
      "Epoch 590/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2229 - f1: 0.7919 - val_loss: 0.2876 - val_f1: 0.0589\n",
      "Epoch 591/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2246 - f1: 0.7905 - val_loss: 0.2866 - val_f1: 0.0591\n",
      "Epoch 592/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2233 - f1: 0.7924 - val_loss: 0.2863 - val_f1: 0.0587\n",
      "Epoch 593/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2231 - f1: 0.7949 - val_loss: 0.2853 - val_f1: 0.0590\n",
      "Epoch 594/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2235 - f1: 0.7933 - val_loss: 0.2860 - val_f1: 0.0589\n",
      "Epoch 595/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2222 - f1: 0.7957 - val_loss: 0.2878 - val_f1: 0.0602\n",
      "Epoch 596/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2229 - f1: 0.7942 - val_loss: 0.2872 - val_f1: 0.0594\n",
      "Epoch 597/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2232 - f1: 0.7925 - val_loss: 0.2864 - val_f1: 0.0582\n",
      "Epoch 598/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2228 - f1: 0.7944 - val_loss: 0.2880 - val_f1: 0.0582\n",
      "Epoch 599/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2230 - f1: 0.7928 - val_loss: 0.2885 - val_f1: 0.0588\n",
      "Epoch 600/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2224 - f1: 0.7950 - val_loss: 0.2919 - val_f1: 0.0584\n",
      "Epoch 601/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2229 - f1: 0.7913 - val_loss: 0.2880 - val_f1: 0.0584\n",
      "Epoch 602/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2223 - f1: 0.7948 - val_loss: 0.2881 - val_f1: 0.0593\n",
      "Epoch 603/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2226 - f1: 0.7940 - val_loss: 0.2893 - val_f1: 0.0582\n",
      "Epoch 604/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2227 - f1: 0.7932 - val_loss: 0.2856 - val_f1: 0.0593\n",
      "Epoch 605/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2221 - f1: 0.7933 - val_loss: 0.2875 - val_f1: 0.0590\n",
      "Epoch 606/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2205 - f1: 0.7948 - val_loss: 0.2877 - val_f1: 0.0592\n",
      "Epoch 607/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2199 - f1: 0.7967 - val_loss: 0.2888 - val_f1: 0.0592\n",
      "Epoch 608/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2238 - f1: 0.7908 - val_loss: 0.2904 - val_f1: 0.0587\n",
      "Epoch 609/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2234 - f1: 0.7938 - val_loss: 0.2875 - val_f1: 0.0595\n",
      "Epoch 610/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2229 - f1: 0.7940 - val_loss: 0.2888 - val_f1: 0.0598\n",
      "Epoch 611/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2214 - f1: 0.7965 - val_loss: 0.2881 - val_f1: 0.0575\n",
      "Epoch 612/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2223 - f1: 0.7933 - val_loss: 0.2869 - val_f1: 0.0579\n",
      "Epoch 613/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2219 - f1: 0.7936 - val_loss: 0.2897 - val_f1: 0.0593\n",
      "Epoch 614/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2216 - f1: 0.7949 - val_loss: 0.2901 - val_f1: 0.0578\n",
      "Epoch 615/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2224 - f1: 0.7944 - val_loss: 0.2880 - val_f1: 0.0591\n",
      "Epoch 616/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2211 - f1: 0.7967 - val_loss: 0.2877 - val_f1: 0.0580\n",
      "Epoch 617/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2226 - f1: 0.7958 - val_loss: 0.2885 - val_f1: 0.0572\n",
      "Epoch 618/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2225 - f1: 0.7928 - val_loss: 0.2884 - val_f1: 0.0587\n",
      "Epoch 619/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2215 - f1: 0.7954 - val_loss: 0.2880 - val_f1: 0.0592\n",
      "Epoch 620/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2214 - f1: 0.7965 - val_loss: 0.2875 - val_f1: 0.0585\n",
      "Epoch 621/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2191 - f1: 0.7982 - val_loss: 0.2892 - val_f1: 0.0591\n",
      "Epoch 622/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2207 - f1: 0.7961 - val_loss: 0.2893 - val_f1: 0.0590\n",
      "Epoch 623/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2221 - f1: 0.7939 - val_loss: 0.2886 - val_f1: 0.0581\n",
      "Epoch 624/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2216 - f1: 0.7968 - val_loss: 0.2885 - val_f1: 0.0577\n",
      "Epoch 625/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2213 - f1: 0.7962 - val_loss: 0.2899 - val_f1: 0.0592\n",
      "Epoch 626/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2207 - f1: 0.7964 - val_loss: 0.2894 - val_f1: 0.0573\n",
      "Epoch 627/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2212 - f1: 0.7948 - val_loss: 0.2891 - val_f1: 0.0583\n",
      "Epoch 628/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2211 - f1: 0.7974 - val_loss: 0.2913 - val_f1: 0.0589\n",
      "Epoch 629/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2210 - f1: 0.7946 - val_loss: 0.2905 - val_f1: 0.0576\n",
      "Epoch 630/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2213 - f1: 0.7967 - val_loss: 0.2901 - val_f1: 0.0583\n",
      "Epoch 631/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2216 - f1: 0.7956 - val_loss: 0.2874 - val_f1: 0.0582\n",
      "Epoch 632/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2197 - f1: 0.7966 - val_loss: 0.2900 - val_f1: 0.0585\n",
      "Epoch 633/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2214 - f1: 0.7965 - val_loss: 0.2918 - val_f1: 0.0583\n",
      "Epoch 634/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2220 - f1: 0.7950 - val_loss: 0.2890 - val_f1: 0.0592\n",
      "Epoch 635/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2203 - f1: 0.7959 - val_loss: 0.2885 - val_f1: 0.0594\n",
      "Epoch 636/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2213 - f1: 0.7954 - val_loss: 0.2904 - val_f1: 0.0591\n",
      "Epoch 637/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2216 - f1: 0.7954 - val_loss: 0.2884 - val_f1: 0.0585\n",
      "Epoch 638/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2203 - f1: 0.7956 - val_loss: 0.2885 - val_f1: 0.0582\n",
      "Epoch 639/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2205 - f1: 0.7982 - val_loss: 0.2908 - val_f1: 0.0589\n",
      "Epoch 640/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2213 - f1: 0.7962 - val_loss: 0.2894 - val_f1: 0.0581\n",
      "Epoch 641/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2196 - f1: 0.7950 - val_loss: 0.2883 - val_f1: 0.0572\n",
      "Epoch 642/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2214 - f1: 0.7959 - val_loss: 0.2904 - val_f1: 0.0587\n",
      "Epoch 643/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2199 - f1: 0.7947 - val_loss: 0.2889 - val_f1: 0.0597\n",
      "Epoch 644/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2209 - f1: 0.7962 - val_loss: 0.2877 - val_f1: 0.0590\n",
      "Epoch 645/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2194 - f1: 0.7977 - val_loss: 0.2896 - val_f1: 0.0589\n",
      "Epoch 646/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2208 - f1: 0.7960 - val_loss: 0.2867 - val_f1: 0.0594\n",
      "Epoch 647/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2229 - f1: 0.7948 - val_loss: 0.2890 - val_f1: 0.0590\n",
      "Epoch 648/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2200 - f1: 0.7965 - val_loss: 0.2871 - val_f1: 0.0586\n",
      "Epoch 649/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2187 - f1: 0.7991 - val_loss: 0.2917 - val_f1: 0.0577\n",
      "Epoch 650/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2210 - f1: 0.7960 - val_loss: 0.2873 - val_f1: 0.0587\n",
      "Epoch 651/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2204 - f1: 0.7964 - val_loss: 0.2901 - val_f1: 0.0585\n",
      "Epoch 652/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2190 - f1: 0.7994 - val_loss: 0.2900 - val_f1: 0.0577\n",
      "Epoch 653/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2188 - f1: 0.7960 - val_loss: 0.2901 - val_f1: 0.0593\n",
      "Epoch 654/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2190 - f1: 0.7962 - val_loss: 0.2915 - val_f1: 0.0592\n",
      "Epoch 655/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2211 - f1: 0.7943 - val_loss: 0.2884 - val_f1: 0.0587\n",
      "Epoch 656/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2203 - f1: 0.7952 - val_loss: 0.2925 - val_f1: 0.0587\n",
      "Epoch 657/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2214 - f1: 0.7956 - val_loss: 0.2880 - val_f1: 0.0584\n",
      "Epoch 658/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2201 - f1: 0.7976 - val_loss: 0.2913 - val_f1: 0.0594\n",
      "Epoch 659/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2188 - f1: 0.7969 - val_loss: 0.2899 - val_f1: 0.0582\n",
      "Epoch 660/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2206 - f1: 0.7965 - val_loss: 0.2892 - val_f1: 0.0586\n",
      "Epoch 661/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2190 - f1: 0.7974 - val_loss: 0.2888 - val_f1: 0.0581\n",
      "Epoch 662/2000\n",
      "168135/168135 [==============================] - 14s 80us/step - loss: 0.2187 - f1: 0.7965 - val_loss: 0.2890 - val_f1: 0.0586\n",
      "Epoch 663/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2207 - f1: 0.7961 - val_loss: 0.2887 - val_f1: 0.0585\n",
      "Epoch 664/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2200 - f1: 0.7960 - val_loss: 0.2910 - val_f1: 0.0588\n",
      "Epoch 665/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2188 - f1: 0.7973 - val_loss: 0.2901 - val_f1: 0.0594\n",
      "Epoch 666/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2193 - f1: 0.7977 - val_loss: 0.2896 - val_f1: 0.0586\n",
      "Epoch 667/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2198 - f1: 0.7969 - val_loss: 0.2886 - val_f1: 0.0587\n",
      "Epoch 668/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2196 - f1: 0.7969 - val_loss: 0.2900 - val_f1: 0.0582\n",
      "Epoch 669/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2185 - f1: 0.7968 - val_loss: 0.2887 - val_f1: 0.0593\n",
      "Epoch 670/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2192 - f1: 0.7996 - val_loss: 0.2912 - val_f1: 0.0582\n",
      "Epoch 671/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2179 - f1: 0.7992 - val_loss: 0.2911 - val_f1: 0.0587\n",
      "Epoch 672/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2190 - f1: 0.7982 - val_loss: 0.2932 - val_f1: 0.0581\n",
      "Epoch 673/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2202 - f1: 0.7966 - val_loss: 0.2895 - val_f1: 0.0581\n",
      "Epoch 674/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2176 - f1: 0.7985 - val_loss: 0.2884 - val_f1: 0.0588\n",
      "Epoch 675/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2190 - f1: 0.7992 - val_loss: 0.2880 - val_f1: 0.0581\n",
      "Epoch 676/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2184 - f1: 0.7987 - val_loss: 0.2884 - val_f1: 0.0583\n",
      "Epoch 677/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2199 - f1: 0.7975 - val_loss: 0.2863 - val_f1: 0.0589\n",
      "Epoch 678/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2188 - f1: 0.7980 - val_loss: 0.2899 - val_f1: 0.0577\n",
      "Epoch 679/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2214 - f1: 0.7962 - val_loss: 0.2863 - val_f1: 0.0584\n",
      "Epoch 680/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2184 - f1: 0.7975 - val_loss: 0.2892 - val_f1: 0.0588\n",
      "Epoch 681/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.2188 - f1: 0.7974 - val_loss: 0.2891 - val_f1: 0.0589\n",
      "Epoch 682/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2202 - f1: 0.7971 - val_loss: 0.2896 - val_f1: 0.0583\n",
      "Epoch 683/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2181 - f1: 0.7983 - val_loss: 0.2920 - val_f1: 0.0578\n",
      "Epoch 684/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2182 - f1: 0.7995 - val_loss: 0.2899 - val_f1: 0.0581\n",
      "Epoch 685/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2187 - f1: 0.7987 - val_loss: 0.2914 - val_f1: 0.0588\n",
      "Epoch 686/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2177 - f1: 0.7977 - val_loss: 0.2918 - val_f1: 0.0575\n",
      "Epoch 687/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2177 - f1: 0.7990 - val_loss: 0.2891 - val_f1: 0.0590\n",
      "Epoch 688/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2172 - f1: 0.7995 - val_loss: 0.2910 - val_f1: 0.0580\n",
      "Epoch 689/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2170 - f1: 0.7994 - val_loss: 0.2895 - val_f1: 0.0575\n",
      "Epoch 690/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2194 - f1: 0.7988 - val_loss: 0.2885 - val_f1: 0.0589\n",
      "Epoch 691/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2191 - f1: 0.7954 - val_loss: 0.2892 - val_f1: 0.0595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2176 - f1: 0.7996 - val_loss: 0.2906 - val_f1: 0.0587\n",
      "Epoch 693/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2184 - f1: 0.7995 - val_loss: 0.2902 - val_f1: 0.0580\n",
      "Epoch 694/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2193 - f1: 0.7980 - val_loss: 0.2901 - val_f1: 0.0586\n",
      "Epoch 695/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2176 - f1: 0.7962 - val_loss: 0.2912 - val_f1: 0.0587\n",
      "Epoch 696/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2176 - f1: 0.7989 - val_loss: 0.2894 - val_f1: 0.0590\n",
      "Epoch 697/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2186 - f1: 0.7980 - val_loss: 0.2880 - val_f1: 0.0580\n",
      "Epoch 698/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2165 - f1: 0.7998 - val_loss: 0.2904 - val_f1: 0.0587\n",
      "Epoch 699/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2179 - f1: 0.7989 - val_loss: 0.2928 - val_f1: 0.0592\n",
      "Epoch 700/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2183 - f1: 0.8004 - val_loss: 0.2906 - val_f1: 0.0578\n",
      "Epoch 701/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2184 - f1: 0.7975 - val_loss: 0.2898 - val_f1: 0.0589\n",
      "Epoch 702/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2163 - f1: 0.8015 - val_loss: 0.2902 - val_f1: 0.0586\n",
      "Epoch 703/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2173 - f1: 0.7998 - val_loss: 0.2918 - val_f1: 0.0582\n",
      "Epoch 704/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2179 - f1: 0.8007 - val_loss: 0.2913 - val_f1: 0.0576\n",
      "Epoch 705/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2178 - f1: 0.7983 - val_loss: 0.2908 - val_f1: 0.0590\n",
      "Epoch 706/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2183 - f1: 0.7997 - val_loss: 0.2872 - val_f1: 0.0586\n",
      "Epoch 707/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2188 - f1: 0.7972 - val_loss: 0.2909 - val_f1: 0.0595\n",
      "Epoch 708/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2183 - f1: 0.8000 - val_loss: 0.2913 - val_f1: 0.0585\n",
      "Epoch 709/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2154 - f1: 0.8028 - val_loss: 0.2927 - val_f1: 0.0582\n",
      "Epoch 710/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2185 - f1: 0.7980 - val_loss: 0.2915 - val_f1: 0.0573\n",
      "Epoch 711/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2173 - f1: 0.7994 - val_loss: 0.2915 - val_f1: 0.0595\n",
      "Epoch 712/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2166 - f1: 0.7990 - val_loss: 0.2895 - val_f1: 0.0586\n",
      "Epoch 713/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2171 - f1: 0.7998 - val_loss: 0.2887 - val_f1: 0.0587\n",
      "Epoch 714/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2166 - f1: 0.8006 - val_loss: 0.2917 - val_f1: 0.0581\n",
      "Epoch 715/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2162 - f1: 0.8009 - val_loss: 0.2908 - val_f1: 0.0593\n",
      "Epoch 716/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2172 - f1: 0.8009 - val_loss: 0.2885 - val_f1: 0.0586\n",
      "Epoch 717/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2173 - f1: 0.8000 - val_loss: 0.2903 - val_f1: 0.0574\n",
      "Epoch 718/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2180 - f1: 0.7969 - val_loss: 0.2914 - val_f1: 0.0583\n",
      "Epoch 719/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2159 - f1: 0.8019 - val_loss: 0.2898 - val_f1: 0.0585\n",
      "Epoch 720/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2156 - f1: 0.8017 - val_loss: 0.2941 - val_f1: 0.0578\n",
      "Epoch 721/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2155 - f1: 0.7998 - val_loss: 0.2924 - val_f1: 0.0592\n",
      "Epoch 722/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2173 - f1: 0.7972 - val_loss: 0.2895 - val_f1: 0.0591\n",
      "Epoch 723/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2175 - f1: 0.7998 - val_loss: 0.2908 - val_f1: 0.0585\n",
      "Epoch 724/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2164 - f1: 0.8029 - val_loss: 0.2930 - val_f1: 0.0577\n",
      "Epoch 725/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2151 - f1: 0.8013 - val_loss: 0.2914 - val_f1: 0.0589\n",
      "Epoch 726/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2155 - f1: 0.8004 - val_loss: 0.2916 - val_f1: 0.0585\n",
      "Epoch 727/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2174 - f1: 0.8000 - val_loss: 0.2936 - val_f1: 0.0592\n",
      "Epoch 728/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2163 - f1: 0.8024 - val_loss: 0.2908 - val_f1: 0.0586\n",
      "Epoch 729/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2160 - f1: 0.8006 - val_loss: 0.2918 - val_f1: 0.0581\n",
      "Epoch 730/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2171 - f1: 0.8013 - val_loss: 0.2909 - val_f1: 0.0576\n",
      "Epoch 731/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2170 - f1: 0.8011 - val_loss: 0.2913 - val_f1: 0.0583\n",
      "Epoch 732/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2151 - f1: 0.8017 - val_loss: 0.2939 - val_f1: 0.0590\n",
      "Epoch 733/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2153 - f1: 0.8018 - val_loss: 0.2914 - val_f1: 0.0587\n",
      "Epoch 734/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2165 - f1: 0.8009 - val_loss: 0.2909 - val_f1: 0.0586\n",
      "Epoch 735/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2158 - f1: 0.8022 - val_loss: 0.2931 - val_f1: 0.0597\n",
      "Epoch 736/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2165 - f1: 0.8014 - val_loss: 0.2917 - val_f1: 0.0589\n",
      "Epoch 737/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2173 - f1: 0.8019 - val_loss: 0.2903 - val_f1: 0.0591\n",
      "Epoch 738/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2172 - f1: 0.8012 - val_loss: 0.2934 - val_f1: 0.0581\n",
      "Epoch 739/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2162 - f1: 0.8006 - val_loss: 0.2897 - val_f1: 0.0581\n",
      "Epoch 740/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2156 - f1: 0.7994 - val_loss: 0.2933 - val_f1: 0.0592\n",
      "Epoch 741/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2155 - f1: 0.8019 - val_loss: 0.2911 - val_f1: 0.0587\n",
      "Epoch 742/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2165 - f1: 0.8007 - val_loss: 0.2928 - val_f1: 0.0591\n",
      "Epoch 743/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2157 - f1: 0.8024 - val_loss: 0.2925 - val_f1: 0.0589\n",
      "Epoch 744/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2171 - f1: 0.7997 - val_loss: 0.2927 - val_f1: 0.0586\n",
      "Epoch 745/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2166 - f1: 0.8007 - val_loss: 0.2921 - val_f1: 0.0581\n",
      "Epoch 746/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2142 - f1: 0.8021 - val_loss: 0.2946 - val_f1: 0.0586\n",
      "Epoch 747/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2160 - f1: 0.8022 - val_loss: 0.2908 - val_f1: 0.0583\n",
      "Epoch 748/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2157 - f1: 0.8039 - val_loss: 0.2908 - val_f1: 0.0584\n",
      "Epoch 749/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2155 - f1: 0.8022 - val_loss: 0.2918 - val_f1: 0.0583\n",
      "Epoch 750/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2162 - f1: 0.8008 - val_loss: 0.2900 - val_f1: 0.0587\n",
      "Epoch 751/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2156 - f1: 0.8029 - val_loss: 0.2933 - val_f1: 0.0584\n",
      "Epoch 752/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2150 - f1: 0.8039 - val_loss: 0.2911 - val_f1: 0.0581\n",
      "Epoch 753/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2154 - f1: 0.7998 - val_loss: 0.2946 - val_f1: 0.0577\n",
      "Epoch 754/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2164 - f1: 0.8007 - val_loss: 0.2926 - val_f1: 0.0574\n",
      "Epoch 755/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2151 - f1: 0.8020 - val_loss: 0.2944 - val_f1: 0.0581\n",
      "Epoch 756/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2158 - f1: 0.8004 - val_loss: 0.2899 - val_f1: 0.0581\n",
      "Epoch 757/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2145 - f1: 0.8007 - val_loss: 0.2921 - val_f1: 0.0576\n",
      "Epoch 758/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2157 - f1: 0.8012 - val_loss: 0.2929 - val_f1: 0.0584\n",
      "Epoch 759/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2135 - f1: 0.8046 - val_loss: 0.2937 - val_f1: 0.0582\n",
      "Epoch 760/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2143 - f1: 0.8031 - val_loss: 0.2932 - val_f1: 0.0577\n",
      "Epoch 761/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2143 - f1: 0.8031 - val_loss: 0.2909 - val_f1: 0.0586\n",
      "Epoch 762/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2163 - f1: 0.8020 - val_loss: 0.2910 - val_f1: 0.0591\n",
      "Epoch 763/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2148 - f1: 0.8020 - val_loss: 0.2919 - val_f1: 0.0586\n",
      "Epoch 764/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2143 - f1: 0.8030 - val_loss: 0.2934 - val_f1: 0.0585\n",
      "Epoch 765/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2139 - f1: 0.8051 - val_loss: 0.2924 - val_f1: 0.0591\n",
      "Epoch 766/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2151 - f1: 0.8026 - val_loss: 0.2926 - val_f1: 0.0581\n",
      "Epoch 767/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2155 - f1: 0.8024 - val_loss: 0.2928 - val_f1: 0.0585\n",
      "Epoch 768/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2149 - f1: 0.8035 - val_loss: 0.2905 - val_f1: 0.0577\n",
      "Epoch 769/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2162 - f1: 0.8023 - val_loss: 0.2942 - val_f1: 0.0581\n",
      "Epoch 770/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2144 - f1: 0.8040 - val_loss: 0.2932 - val_f1: 0.0586\n",
      "Epoch 771/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2139 - f1: 0.8020 - val_loss: 0.2927 - val_f1: 0.0584\n",
      "Epoch 772/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2159 - f1: 0.8024 - val_loss: 0.2923 - val_f1: 0.0582\n",
      "Epoch 773/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2149 - f1: 0.8016 - val_loss: 0.2921 - val_f1: 0.0588\n",
      "Epoch 774/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2146 - f1: 0.8015 - val_loss: 0.2928 - val_f1: 0.0584\n",
      "Epoch 775/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2141 - f1: 0.8045 - val_loss: 0.2933 - val_f1: 0.0587\n",
      "Epoch 776/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2146 - f1: 0.8017 - val_loss: 0.2912 - val_f1: 0.0583\n",
      "Epoch 777/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2154 - f1: 0.8022 - val_loss: 0.2935 - val_f1: 0.0594\n",
      "Epoch 778/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2149 - f1: 0.8015 - val_loss: 0.2934 - val_f1: 0.0584\n",
      "Epoch 779/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2144 - f1: 0.8023 - val_loss: 0.2935 - val_f1: 0.0597\n",
      "Epoch 780/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2127 - f1: 0.8060 - val_loss: 0.2928 - val_f1: 0.0591\n",
      "Epoch 781/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2154 - f1: 0.8010 - val_loss: 0.2940 - val_f1: 0.0589\n",
      "Epoch 782/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2158 - f1: 0.8009 - val_loss: 0.2894 - val_f1: 0.0584\n",
      "Epoch 783/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2145 - f1: 0.8034 - val_loss: 0.2951 - val_f1: 0.0586\n",
      "Epoch 784/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2142 - f1: 0.8023 - val_loss: 0.2926 - val_f1: 0.0587\n",
      "Epoch 785/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2138 - f1: 0.8030 - val_loss: 0.2911 - val_f1: 0.0592\n",
      "Epoch 786/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2150 - f1: 0.8020 - val_loss: 0.2927 - val_f1: 0.0585\n",
      "Epoch 787/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2143 - f1: 0.8025 - val_loss: 0.2917 - val_f1: 0.0597\n",
      "Epoch 788/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2147 - f1: 0.8026 - val_loss: 0.2924 - val_f1: 0.0587\n",
      "Epoch 789/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2144 - f1: 0.8029 - val_loss: 0.2931 - val_f1: 0.0593\n",
      "Epoch 790/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2152 - f1: 0.8018 - val_loss: 0.2923 - val_f1: 0.0587\n",
      "Epoch 791/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2127 - f1: 0.8042 - val_loss: 0.2929 - val_f1: 0.0598\n",
      "Epoch 792/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2123 - f1: 0.8062 - val_loss: 0.2958 - val_f1: 0.0585\n",
      "Epoch 793/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2135 - f1: 0.8043 - val_loss: 0.2924 - val_f1: 0.0584\n",
      "Epoch 794/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2141 - f1: 0.8016 - val_loss: 0.2945 - val_f1: 0.0592\n",
      "Epoch 795/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2152 - f1: 0.8018 - val_loss: 0.2911 - val_f1: 0.0579\n",
      "Epoch 796/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2141 - f1: 0.8030 - val_loss: 0.2941 - val_f1: 0.0588\n",
      "Epoch 797/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2123 - f1: 0.8065 - val_loss: 0.2925 - val_f1: 0.0574\n",
      "Epoch 798/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2143 - f1: 0.8039 - val_loss: 0.2944 - val_f1: 0.0588\n",
      "Epoch 799/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2125 - f1: 0.8057 - val_loss: 0.2948 - val_f1: 0.0579\n",
      "Epoch 800/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2146 - f1: 0.8030 - val_loss: 0.2928 - val_f1: 0.0579\n",
      "Epoch 801/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2128 - f1: 0.8025 - val_loss: 0.2923 - val_f1: 0.0586\n",
      "Epoch 802/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2141 - f1: 0.8033 - val_loss: 0.2925 - val_f1: 0.0592\n",
      "Epoch 803/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.2143 - f1: 0.8019 - val_loss: 0.2911 - val_f1: 0.0589\n",
      "Epoch 804/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2115 - f1: 0.8081 - val_loss: 0.2939 - val_f1: 0.0580\n",
      "Epoch 805/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2131 - f1: 0.8027 - val_loss: 0.2968 - val_f1: 0.0586\n",
      "Epoch 806/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2129 - f1: 0.8036 - val_loss: 0.2930 - val_f1: 0.0577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 807/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2128 - f1: 0.8055 - val_loss: 0.2948 - val_f1: 0.0582\n",
      "Epoch 808/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2130 - f1: 0.8060 - val_loss: 0.2922 - val_f1: 0.0591\n",
      "Epoch 809/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2133 - f1: 0.8054 - val_loss: 0.2934 - val_f1: 0.0567\n",
      "Epoch 810/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2132 - f1: 0.8047 - val_loss: 0.2898 - val_f1: 0.0581\n",
      "Epoch 811/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2131 - f1: 0.8047 - val_loss: 0.2939 - val_f1: 0.0575\n",
      "Epoch 812/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2145 - f1: 0.8041 - val_loss: 0.2946 - val_f1: 0.0584\n",
      "Epoch 813/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2156 - f1: 0.8008 - val_loss: 0.2904 - val_f1: 0.0584\n",
      "Epoch 814/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2125 - f1: 0.8063 - val_loss: 0.2927 - val_f1: 0.0581\n",
      "Epoch 815/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2131 - f1: 0.8045 - val_loss: 0.2945 - val_f1: 0.0576\n",
      "Epoch 816/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2127 - f1: 0.8077 - val_loss: 0.2931 - val_f1: 0.0582\n",
      "Epoch 817/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2135 - f1: 0.8048 - val_loss: 0.2926 - val_f1: 0.0578\n",
      "Epoch 818/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2110 - f1: 0.8077 - val_loss: 0.2918 - val_f1: 0.0581\n",
      "Epoch 819/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2127 - f1: 0.8053 - val_loss: 0.2924 - val_f1: 0.0577\n",
      "Epoch 820/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2124 - f1: 0.8042 - val_loss: 0.2953 - val_f1: 0.0582\n",
      "Epoch 821/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2128 - f1: 0.8039 - val_loss: 0.2928 - val_f1: 0.0579\n",
      "Epoch 822/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2120 - f1: 0.8054 - val_loss: 0.2930 - val_f1: 0.0585\n",
      "Epoch 823/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2125 - f1: 0.8029 - val_loss: 0.2923 - val_f1: 0.0592\n",
      "Epoch 824/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2116 - f1: 0.8066 - val_loss: 0.2927 - val_f1: 0.0590\n",
      "Epoch 825/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2122 - f1: 0.8048 - val_loss: 0.2905 - val_f1: 0.0576\n",
      "Epoch 826/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2121 - f1: 0.8040 - val_loss: 0.2938 - val_f1: 0.0590\n",
      "Epoch 827/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2118 - f1: 0.8049 - val_loss: 0.2924 - val_f1: 0.0583\n",
      "Epoch 828/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2127 - f1: 0.8054 - val_loss: 0.2937 - val_f1: 0.0589\n",
      "Epoch 829/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2126 - f1: 0.8042 - val_loss: 0.2935 - val_f1: 0.0586\n",
      "Epoch 830/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2133 - f1: 0.8021 - val_loss: 0.2943 - val_f1: 0.0585\n",
      "Epoch 831/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2130 - f1: 0.8060 - val_loss: 0.2938 - val_f1: 0.0581\n",
      "Epoch 832/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2119 - f1: 0.8056 - val_loss: 0.2929 - val_f1: 0.0579\n",
      "Epoch 833/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2107 - f1: 0.8062 - val_loss: 0.2945 - val_f1: 0.0582\n",
      "Epoch 834/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2141 - f1: 0.8026 - val_loss: 0.2925 - val_f1: 0.0587\n",
      "Epoch 835/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2128 - f1: 0.8032 - val_loss: 0.2944 - val_f1: 0.0579\n",
      "Epoch 836/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2109 - f1: 0.8078 - val_loss: 0.2944 - val_f1: 0.0586\n",
      "Epoch 837/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2137 - f1: 0.8030 - val_loss: 0.2929 - val_f1: 0.0574\n",
      "Epoch 838/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2117 - f1: 0.8063 - val_loss: 0.2910 - val_f1: 0.0585\n",
      "Epoch 839/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2140 - f1: 0.8035 - val_loss: 0.2919 - val_f1: 0.0588\n",
      "Epoch 840/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2121 - f1: 0.8040 - val_loss: 0.2915 - val_f1: 0.0586\n",
      "Epoch 841/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2127 - f1: 0.8036 - val_loss: 0.2950 - val_f1: 0.0579\n",
      "Epoch 842/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2133 - f1: 0.8054 - val_loss: 0.2941 - val_f1: 0.0582\n",
      "Epoch 843/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2120 - f1: 0.8054 - val_loss: 0.2922 - val_f1: 0.0594\n",
      "Epoch 844/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2132 - f1: 0.8055 - val_loss: 0.2919 - val_f1: 0.0586\n",
      "Epoch 845/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2126 - f1: 0.8050 - val_loss: 0.2919 - val_f1: 0.0582\n",
      "Epoch 846/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2113 - f1: 0.8074 - val_loss: 0.2958 - val_f1: 0.0596\n",
      "Epoch 847/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2114 - f1: 0.8068 - val_loss: 0.2919 - val_f1: 0.0583\n",
      "Epoch 848/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2112 - f1: 0.8049 - val_loss: 0.2918 - val_f1: 0.0576\n",
      "Epoch 849/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2119 - f1: 0.8061 - val_loss: 0.2953 - val_f1: 0.0585\n",
      "Epoch 850/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2126 - f1: 0.8056 - val_loss: 0.2947 - val_f1: 0.0594\n",
      "Epoch 851/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2129 - f1: 0.8045 - val_loss: 0.2924 - val_f1: 0.0586\n",
      "Epoch 852/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2130 - f1: 0.8063 - val_loss: 0.2937 - val_f1: 0.0583\n",
      "Epoch 853/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2131 - f1: 0.8045 - val_loss: 0.2888 - val_f1: 0.0580\n",
      "Epoch 854/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2135 - f1: 0.8028 - val_loss: 0.2934 - val_f1: 0.0576\n",
      "Epoch 855/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2123 - f1: 0.8040 - val_loss: 0.2940 - val_f1: 0.0582\n",
      "Epoch 856/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2114 - f1: 0.8067 - val_loss: 0.2945 - val_f1: 0.0581\n",
      "Epoch 857/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2129 - f1: 0.8045 - val_loss: 0.2929 - val_f1: 0.0587\n",
      "Epoch 858/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2119 - f1: 0.8052 - val_loss: 0.2953 - val_f1: 0.0586\n",
      "Epoch 859/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2113 - f1: 0.8070 - val_loss: 0.2940 - val_f1: 0.0592\n",
      "Epoch 860/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2124 - f1: 0.8039 - val_loss: 0.2946 - val_f1: 0.0586\n",
      "Epoch 861/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2104 - f1: 0.8072 - val_loss: 0.2973 - val_f1: 0.0585\n",
      "Epoch 862/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2125 - f1: 0.8034 - val_loss: 0.2920 - val_f1: 0.0588\n",
      "Epoch 863/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2105 - f1: 0.8080 - val_loss: 0.2933 - val_f1: 0.0589\n",
      "Epoch 864/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2130 - f1: 0.8040 - val_loss: 0.2902 - val_f1: 0.0576\n",
      "Epoch 865/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2108 - f1: 0.8085 - val_loss: 0.2948 - val_f1: 0.0575\n",
      "Epoch 866/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2101 - f1: 0.8079 - val_loss: 0.2960 - val_f1: 0.0585\n",
      "Epoch 867/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2111 - f1: 0.8065 - val_loss: 0.2937 - val_f1: 0.0586\n",
      "Epoch 868/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2119 - f1: 0.8072 - val_loss: 0.2933 - val_f1: 0.0580\n",
      "Epoch 869/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2106 - f1: 0.8069 - val_loss: 0.2951 - val_f1: 0.0591\n",
      "Epoch 870/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2119 - f1: 0.8061 - val_loss: 0.2942 - val_f1: 0.0583\n",
      "Epoch 871/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2103 - f1: 0.8075 - val_loss: 0.2953 - val_f1: 0.0589\n",
      "Epoch 872/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2107 - f1: 0.8046 - val_loss: 0.2937 - val_f1: 0.0579\n",
      "Epoch 873/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2117 - f1: 0.8056 - val_loss: 0.2957 - val_f1: 0.0585\n",
      "Epoch 874/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2122 - f1: 0.8056 - val_loss: 0.2928 - val_f1: 0.0583\n",
      "Epoch 875/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2109 - f1: 0.8056 - val_loss: 0.2956 - val_f1: 0.0592\n",
      "Epoch 876/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2118 - f1: 0.8078 - val_loss: 0.2952 - val_f1: 0.0586\n",
      "Epoch 877/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2110 - f1: 0.8068 - val_loss: 0.2925 - val_f1: 0.0585\n",
      "Epoch 878/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2108 - f1: 0.8053 - val_loss: 0.2930 - val_f1: 0.0582\n",
      "Epoch 879/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2107 - f1: 0.8065 - val_loss: 0.2952 - val_f1: 0.0574\n",
      "Epoch 880/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2105 - f1: 0.8073 - val_loss: 0.2955 - val_f1: 0.0578\n",
      "Epoch 881/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2112 - f1: 0.8065 - val_loss: 0.2929 - val_f1: 0.0594\n",
      "Epoch 882/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2089 - f1: 0.8101 - val_loss: 0.2973 - val_f1: 0.0594\n",
      "Epoch 883/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2124 - f1: 0.8050 - val_loss: 0.2908 - val_f1: 0.0578\n",
      "Epoch 884/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2088 - f1: 0.8069 - val_loss: 0.2978 - val_f1: 0.0580\n",
      "Epoch 885/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2104 - f1: 0.8086 - val_loss: 0.2948 - val_f1: 0.0572\n",
      "Epoch 886/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2104 - f1: 0.8065 - val_loss: 0.2955 - val_f1: 0.0594\n",
      "Epoch 887/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2106 - f1: 0.8065 - val_loss: 0.2935 - val_f1: 0.0581\n",
      "Epoch 888/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2106 - f1: 0.8065 - val_loss: 0.2971 - val_f1: 0.0581\n",
      "Epoch 889/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2119 - f1: 0.8071 - val_loss: 0.2938 - val_f1: 0.0583\n",
      "Epoch 890/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2086 - f1: 0.8094 - val_loss: 0.2940 - val_f1: 0.0583\n",
      "Epoch 891/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2118 - f1: 0.8049 - val_loss: 0.2917 - val_f1: 0.0582\n",
      "Epoch 892/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2091 - f1: 0.8110 - val_loss: 0.2933 - val_f1: 0.0575\n",
      "Epoch 893/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2111 - f1: 0.8051 - val_loss: 0.2932 - val_f1: 0.0579\n",
      "Epoch 894/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2118 - f1: 0.8056 - val_loss: 0.2963 - val_f1: 0.0571\n",
      "Epoch 895/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2110 - f1: 0.8061 - val_loss: 0.2947 - val_f1: 0.0586\n",
      "Epoch 896/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2100 - f1: 0.8080 - val_loss: 0.2932 - val_f1: 0.0574\n",
      "Epoch 897/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2097 - f1: 0.8090 - val_loss: 0.2945 - val_f1: 0.0576\n",
      "Epoch 898/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2100 - f1: 0.8084 - val_loss: 0.2935 - val_f1: 0.0573\n",
      "Epoch 899/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2102 - f1: 0.8084 - val_loss: 0.2941 - val_f1: 0.0573\n",
      "Epoch 900/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2103 - f1: 0.8072 - val_loss: 0.2956 - val_f1: 0.0579\n",
      "Epoch 901/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2113 - f1: 0.8052 - val_loss: 0.2957 - val_f1: 0.0583\n",
      "Epoch 902/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2113 - f1: 0.8056 - val_loss: 0.2941 - val_f1: 0.0594\n",
      "Epoch 903/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2102 - f1: 0.8088 - val_loss: 0.2957 - val_f1: 0.0578\n",
      "Epoch 904/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2093 - f1: 0.8104 - val_loss: 0.2960 - val_f1: 0.0586\n",
      "Epoch 905/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2109 - f1: 0.8057 - val_loss: 0.2962 - val_f1: 0.0592\n",
      "Epoch 906/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2103 - f1: 0.8069 - val_loss: 0.2961 - val_f1: 0.0588\n",
      "Epoch 907/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2112 - f1: 0.8063 - val_loss: 0.2933 - val_f1: 0.0580\n",
      "Epoch 908/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2104 - f1: 0.8063 - val_loss: 0.2972 - val_f1: 0.0577\n",
      "Epoch 909/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2088 - f1: 0.8113 - val_loss: 0.2936 - val_f1: 0.0583\n",
      "Epoch 910/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2098 - f1: 0.8081 - val_loss: 0.2944 - val_f1: 0.0584\n",
      "Epoch 911/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2102 - f1: 0.8082 - val_loss: 0.2952 - val_f1: 0.0580\n",
      "Epoch 912/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2113 - f1: 0.8067 - val_loss: 0.2958 - val_f1: 0.0582\n",
      "Epoch 913/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2104 - f1: 0.8091 - val_loss: 0.2919 - val_f1: 0.0583\n",
      "Epoch 914/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2085 - f1: 0.8115 - val_loss: 0.2935 - val_f1: 0.0585\n",
      "Epoch 915/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2097 - f1: 0.8094 - val_loss: 0.2965 - val_f1: 0.0589\n",
      "Epoch 916/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2089 - f1: 0.8085 - val_loss: 0.2972 - val_f1: 0.0576\n",
      "Epoch 917/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2093 - f1: 0.8079 - val_loss: 0.2932 - val_f1: 0.0582\n",
      "Epoch 918/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2085 - f1: 0.8086 - val_loss: 0.2963 - val_f1: 0.0589\n",
      "Epoch 919/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2091 - f1: 0.8079 - val_loss: 0.2944 - val_f1: 0.0583\n",
      "Epoch 920/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2098 - f1: 0.8085 - val_loss: 0.2962 - val_f1: 0.0572\n",
      "Epoch 921/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2099 - f1: 0.8062 - val_loss: 0.2946 - val_f1: 0.0579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2089 - f1: 0.8084 - val_loss: 0.2973 - val_f1: 0.0570\n",
      "Epoch 923/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2096 - f1: 0.8089 - val_loss: 0.2945 - val_f1: 0.0585\n",
      "Epoch 924/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2080 - f1: 0.8104 - val_loss: 0.2940 - val_f1: 0.0582\n",
      "Epoch 925/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2092 - f1: 0.8087 - val_loss: 0.2953 - val_f1: 0.0582\n",
      "Epoch 926/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2094 - f1: 0.8093 - val_loss: 0.2979 - val_f1: 0.0580\n",
      "Epoch 927/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2108 - f1: 0.8086 - val_loss: 0.2945 - val_f1: 0.0588\n",
      "Epoch 928/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2105 - f1: 0.8067 - val_loss: 0.2946 - val_f1: 0.0589\n",
      "Epoch 929/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2100 - f1: 0.8067 - val_loss: 0.2924 - val_f1: 0.0585\n",
      "Epoch 930/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2067 - f1: 0.8126 - val_loss: 0.2964 - val_f1: 0.0576\n",
      "Epoch 931/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2091 - f1: 0.8077 - val_loss: 0.2949 - val_f1: 0.0581\n",
      "Epoch 932/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2096 - f1: 0.8078 - val_loss: 0.2947 - val_f1: 0.0576\n",
      "Epoch 933/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2095 - f1: 0.8095 - val_loss: 0.2944 - val_f1: 0.0581\n",
      "Epoch 934/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2101 - f1: 0.8082 - val_loss: 0.2963 - val_f1: 0.0586\n",
      "Epoch 935/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2100 - f1: 0.8069 - val_loss: 0.2949 - val_f1: 0.0574\n",
      "Epoch 936/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2094 - f1: 0.8071 - val_loss: 0.3004 - val_f1: 0.0576\n",
      "Epoch 937/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2086 - f1: 0.8091 - val_loss: 0.2966 - val_f1: 0.0587\n",
      "Epoch 938/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2098 - f1: 0.8079 - val_loss: 0.2952 - val_f1: 0.0580\n",
      "Epoch 939/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2077 - f1: 0.8106 - val_loss: 0.2978 - val_f1: 0.0583\n",
      "Epoch 940/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2101 - f1: 0.8088 - val_loss: 0.2958 - val_f1: 0.0582\n",
      "Epoch 941/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2089 - f1: 0.8092 - val_loss: 0.2924 - val_f1: 0.0577\n",
      "Epoch 942/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2104 - f1: 0.8049 - val_loss: 0.2984 - val_f1: 0.0578\n",
      "Epoch 943/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2100 - f1: 0.8088 - val_loss: 0.2946 - val_f1: 0.0584\n",
      "Epoch 944/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2094 - f1: 0.8078 - val_loss: 0.2973 - val_f1: 0.0580\n",
      "Epoch 945/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2095 - f1: 0.8085 - val_loss: 0.2939 - val_f1: 0.0584\n",
      "Epoch 946/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2087 - f1: 0.8076 - val_loss: 0.2948 - val_f1: 0.0586\n",
      "Epoch 947/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2060 - f1: 0.8113 - val_loss: 0.2986 - val_f1: 0.0590\n",
      "Epoch 948/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2100 - f1: 0.8072 - val_loss: 0.2953 - val_f1: 0.0588\n",
      "Epoch 949/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2097 - f1: 0.8080 - val_loss: 0.2948 - val_f1: 0.0581\n",
      "Epoch 950/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2087 - f1: 0.8076 - val_loss: 0.2931 - val_f1: 0.0584\n",
      "Epoch 951/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2080 - f1: 0.8084 - val_loss: 0.2956 - val_f1: 0.0589\n",
      "Epoch 952/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2092 - f1: 0.8089 - val_loss: 0.2985 - val_f1: 0.0579\n",
      "Epoch 953/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2080 - f1: 0.8109 - val_loss: 0.2993 - val_f1: 0.0584\n",
      "Epoch 954/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2098 - f1: 0.8079 - val_loss: 0.2956 - val_f1: 0.0593\n",
      "Epoch 955/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2097 - f1: 0.8070 - val_loss: 0.2958 - val_f1: 0.0587\n",
      "Epoch 956/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2087 - f1: 0.8095 - val_loss: 0.2938 - val_f1: 0.0578\n",
      "Epoch 957/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2079 - f1: 0.8117 - val_loss: 0.2994 - val_f1: 0.0572\n",
      "Epoch 958/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2094 - f1: 0.8090 - val_loss: 0.2959 - val_f1: 0.0575\n",
      "Epoch 959/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2080 - f1: 0.8107 - val_loss: 0.2956 - val_f1: 0.0590\n",
      "Epoch 960/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2097 - f1: 0.8078 - val_loss: 0.2921 - val_f1: 0.0576\n",
      "Epoch 961/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2090 - f1: 0.8087 - val_loss: 0.2964 - val_f1: 0.0582\n",
      "Epoch 962/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2089 - f1: 0.8099 - val_loss: 0.2980 - val_f1: 0.0590\n",
      "Epoch 963/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2089 - f1: 0.8080 - val_loss: 0.2978 - val_f1: 0.0591\n",
      "Epoch 964/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2096 - f1: 0.8076 - val_loss: 0.2957 - val_f1: 0.0587\n",
      "Epoch 965/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2078 - f1: 0.8087 - val_loss: 0.2985 - val_f1: 0.0590\n",
      "Epoch 966/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2078 - f1: 0.8101 - val_loss: 0.2953 - val_f1: 0.0579\n",
      "Epoch 967/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2086 - f1: 0.8098 - val_loss: 0.2942 - val_f1: 0.0588\n",
      "Epoch 968/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2079 - f1: 0.8112 - val_loss: 0.2984 - val_f1: 0.0580\n",
      "Epoch 969/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2065 - f1: 0.8093 - val_loss: 0.2964 - val_f1: 0.0579\n",
      "Epoch 970/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2093 - f1: 0.8085 - val_loss: 0.2961 - val_f1: 0.0577\n",
      "Epoch 971/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2080 - f1: 0.8095 - val_loss: 0.2977 - val_f1: 0.0579\n",
      "Epoch 972/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2077 - f1: 0.8079 - val_loss: 0.2965 - val_f1: 0.0586\n",
      "Epoch 973/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2104 - f1: 0.8071 - val_loss: 0.2953 - val_f1: 0.0580\n",
      "Epoch 974/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2092 - f1: 0.8091 - val_loss: 0.2967 - val_f1: 0.0595\n",
      "Epoch 975/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2090 - f1: 0.8089 - val_loss: 0.2958 - val_f1: 0.0570\n",
      "Epoch 976/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2077 - f1: 0.8105 - val_loss: 0.2949 - val_f1: 0.0585\n",
      "Epoch 977/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2089 - f1: 0.8099 - val_loss: 0.2967 - val_f1: 0.0576\n",
      "Epoch 978/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2090 - f1: 0.8098 - val_loss: 0.2953 - val_f1: 0.0585\n",
      "Epoch 979/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2065 - f1: 0.8112 - val_loss: 0.2982 - val_f1: 0.0585\n",
      "Epoch 980/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2082 - f1: 0.8115 - val_loss: 0.2976 - val_f1: 0.0582\n",
      "Epoch 981/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2067 - f1: 0.8115 - val_loss: 0.2974 - val_f1: 0.0588\n",
      "Epoch 982/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2070 - f1: 0.8127 - val_loss: 0.2974 - val_f1: 0.0586\n",
      "Epoch 983/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2093 - f1: 0.8066 - val_loss: 0.2966 - val_f1: 0.0578\n",
      "Epoch 984/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2078 - f1: 0.8111 - val_loss: 0.2941 - val_f1: 0.0580\n",
      "Epoch 985/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2068 - f1: 0.8091 - val_loss: 0.2961 - val_f1: 0.0586\n",
      "Epoch 986/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2070 - f1: 0.8112 - val_loss: 0.2944 - val_f1: 0.0582\n",
      "Epoch 987/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2070 - f1: 0.8102 - val_loss: 0.2980 - val_f1: 0.0585\n",
      "Epoch 988/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2083 - f1: 0.8097 - val_loss: 0.2958 - val_f1: 0.0585\n",
      "Epoch 989/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2080 - f1: 0.8094 - val_loss: 0.2957 - val_f1: 0.0591\n",
      "Epoch 990/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2088 - f1: 0.8095 - val_loss: 0.2957 - val_f1: 0.0579\n",
      "Epoch 991/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2070 - f1: 0.8131 - val_loss: 0.2948 - val_f1: 0.0592\n",
      "Epoch 992/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2068 - f1: 0.8112 - val_loss: 0.2960 - val_f1: 0.0578\n",
      "Epoch 993/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2067 - f1: 0.8103 - val_loss: 0.2949 - val_f1: 0.0587\n",
      "Epoch 994/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2086 - f1: 0.8096 - val_loss: 0.2958 - val_f1: 0.0584\n",
      "Epoch 995/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2079 - f1: 0.8083 - val_loss: 0.2956 - val_f1: 0.0579\n",
      "Epoch 996/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2088 - f1: 0.8106 - val_loss: 0.2970 - val_f1: 0.0584\n",
      "Epoch 997/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2055 - f1: 0.8119 - val_loss: 0.2969 - val_f1: 0.0585\n",
      "Epoch 998/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2069 - f1: 0.8107 - val_loss: 0.2943 - val_f1: 0.0583\n",
      "Epoch 999/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2079 - f1: 0.8089 - val_loss: 0.2957 - val_f1: 0.0585\n",
      "Epoch 1000/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2076 - f1: 0.8124 - val_loss: 0.2951 - val_f1: 0.0581\n",
      "Epoch 1001/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2083 - f1: 0.8097 - val_loss: 0.2943 - val_f1: 0.0580\n",
      "Epoch 1002/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2073 - f1: 0.8100 - val_loss: 0.2970 - val_f1: 0.0591\n",
      "Epoch 1003/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2087 - f1: 0.8098 - val_loss: 0.2957 - val_f1: 0.0583\n",
      "Epoch 1004/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2069 - f1: 0.8124 - val_loss: 0.2961 - val_f1: 0.0584\n",
      "Epoch 1005/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2069 - f1: 0.8091 - val_loss: 0.2982 - val_f1: 0.0579\n",
      "Epoch 1006/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2077 - f1: 0.8115 - val_loss: 0.2971 - val_f1: 0.0583\n",
      "Epoch 1007/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2084 - f1: 0.8088 - val_loss: 0.2951 - val_f1: 0.0585\n",
      "Epoch 1008/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2074 - f1: 0.8119 - val_loss: 0.2936 - val_f1: 0.0578\n",
      "Epoch 1009/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2067 - f1: 0.8114 - val_loss: 0.3000 - val_f1: 0.0584\n",
      "Epoch 1010/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2061 - f1: 0.8135 - val_loss: 0.2946 - val_f1: 0.0578\n",
      "Epoch 1011/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2072 - f1: 0.8114 - val_loss: 0.2981 - val_f1: 0.0584\n",
      "Epoch 1012/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2092 - f1: 0.8101 - val_loss: 0.2965 - val_f1: 0.0585\n",
      "Epoch 1013/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2068 - f1: 0.8106 - val_loss: 0.2973 - val_f1: 0.0585\n",
      "Epoch 1014/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2064 - f1: 0.8112 - val_loss: 0.2979 - val_f1: 0.0577\n",
      "Epoch 1015/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2078 - f1: 0.8111 - val_loss: 0.2981 - val_f1: 0.0585\n",
      "Epoch 1016/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2066 - f1: 0.8120 - val_loss: 0.2975 - val_f1: 0.0582\n",
      "Epoch 1017/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2070 - f1: 0.8110 - val_loss: 0.2957 - val_f1: 0.0583\n",
      "Epoch 1018/2000\n",
      "168135/168135 [==============================] - 15s 91us/step - loss: 0.2073 - f1: 0.8101 - val_loss: 0.2946 - val_f1: 0.0578\n",
      "Epoch 1019/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2064 - f1: 0.8095 - val_loss: 0.2973 - val_f1: 0.0577\n",
      "Epoch 1020/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2076 - f1: 0.8114 - val_loss: 0.2960 - val_f1: 0.0586\n",
      "Epoch 1021/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2061 - f1: 0.8115 - val_loss: 0.2959 - val_f1: 0.0573\n",
      "Epoch 1022/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2069 - f1: 0.8119 - val_loss: 0.3000 - val_f1: 0.0582\n",
      "Epoch 1023/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2069 - f1: 0.8108 - val_loss: 0.2980 - val_f1: 0.0579\n",
      "Epoch 1024/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2065 - f1: 0.8113 - val_loss: 0.2983 - val_f1: 0.0572\n",
      "Epoch 1025/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2049 - f1: 0.8115 - val_loss: 0.2964 - val_f1: 0.0583\n",
      "Epoch 1026/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2062 - f1: 0.8116 - val_loss: 0.2970 - val_f1: 0.0586\n",
      "Epoch 1027/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2067 - f1: 0.8101 - val_loss: 0.2994 - val_f1: 0.0580\n",
      "Epoch 1028/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2059 - f1: 0.8126 - val_loss: 0.2977 - val_f1: 0.0573\n",
      "Epoch 1029/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2061 - f1: 0.8116 - val_loss: 0.2964 - val_f1: 0.0574\n",
      "Epoch 1030/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2070 - f1: 0.8115 - val_loss: 0.2978 - val_f1: 0.0585\n",
      "Epoch 1031/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2061 - f1: 0.8123 - val_loss: 0.2970 - val_f1: 0.0581\n",
      "Epoch 1032/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2072 - f1: 0.8110 - val_loss: 0.2928 - val_f1: 0.0580\n",
      "Epoch 1033/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2062 - f1: 0.8102 - val_loss: 0.2967 - val_f1: 0.0589\n",
      "Epoch 1034/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2077 - f1: 0.8114 - val_loss: 0.2957 - val_f1: 0.0582\n",
      "Epoch 1035/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2056 - f1: 0.8119 - val_loss: 0.2966 - val_f1: 0.0578\n",
      "Epoch 1036/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2050 - f1: 0.8135 - val_loss: 0.2972 - val_f1: 0.0577\n",
      "Epoch 1037/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2082 - f1: 0.8101 - val_loss: 0.2960 - val_f1: 0.0585\n",
      "Epoch 1038/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2063 - f1: 0.8117 - val_loss: 0.2971 - val_f1: 0.0579\n",
      "Epoch 1039/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2069 - f1: 0.8108 - val_loss: 0.2949 - val_f1: 0.0573\n",
      "Epoch 1040/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2064 - f1: 0.8129 - val_loss: 0.2971 - val_f1: 0.0582\n",
      "Epoch 1041/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2064 - f1: 0.8116 - val_loss: 0.2969 - val_f1: 0.0591\n",
      "Epoch 1042/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2070 - f1: 0.8104 - val_loss: 0.2965 - val_f1: 0.0581\n",
      "Epoch 1043/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2077 - f1: 0.8110 - val_loss: 0.2987 - val_f1: 0.0594\n",
      "Epoch 1044/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2068 - f1: 0.8105 - val_loss: 0.2983 - val_f1: 0.0586\n",
      "Epoch 1045/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2052 - f1: 0.8152 - val_loss: 0.2984 - val_f1: 0.0586\n",
      "Epoch 1046/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2066 - f1: 0.8115 - val_loss: 0.2988 - val_f1: 0.0582\n",
      "Epoch 1047/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2048 - f1: 0.8144 - val_loss: 0.2968 - val_f1: 0.0585\n",
      "Epoch 1048/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2075 - f1: 0.8111 - val_loss: 0.2967 - val_f1: 0.0586\n",
      "Epoch 1049/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2061 - f1: 0.8125 - val_loss: 0.2956 - val_f1: 0.0575\n",
      "Epoch 1050/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2055 - f1: 0.8108 - val_loss: 0.2965 - val_f1: 0.0577\n",
      "Epoch 1051/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2046 - f1: 0.8157 - val_loss: 0.2990 - val_f1: 0.0594\n",
      "Epoch 1052/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2067 - f1: 0.8120 - val_loss: 0.2989 - val_f1: 0.0583\n",
      "Epoch 1053/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2075 - f1: 0.8092 - val_loss: 0.2955 - val_f1: 0.0586\n",
      "Epoch 1054/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2052 - f1: 0.8128 - val_loss: 0.2986 - val_f1: 0.0576\n",
      "Epoch 1055/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2079 - f1: 0.8106 - val_loss: 0.2943 - val_f1: 0.0586\n",
      "Epoch 1056/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2067 - f1: 0.8103 - val_loss: 0.3008 - val_f1: 0.0579\n",
      "Epoch 1057/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2061 - f1: 0.8118 - val_loss: 0.2973 - val_f1: 0.0583\n",
      "Epoch 1058/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2057 - f1: 0.8132 - val_loss: 0.2996 - val_f1: 0.0584\n",
      "Epoch 1059/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2058 - f1: 0.8138 - val_loss: 0.2974 - val_f1: 0.0588\n",
      "Epoch 1060/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2050 - f1: 0.8132 - val_loss: 0.3003 - val_f1: 0.0579\n",
      "Epoch 1061/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2059 - f1: 0.8129 - val_loss: 0.2989 - val_f1: 0.0584\n",
      "Epoch 1062/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2073 - f1: 0.8102 - val_loss: 0.2986 - val_f1: 0.0584\n",
      "Epoch 1063/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2066 - f1: 0.8101 - val_loss: 0.2982 - val_f1: 0.0582\n",
      "Epoch 1064/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2047 - f1: 0.8142 - val_loss: 0.2995 - val_f1: 0.0586\n",
      "Epoch 1065/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2056 - f1: 0.8134 - val_loss: 0.2984 - val_f1: 0.0583\n",
      "Epoch 1066/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2064 - f1: 0.8121 - val_loss: 0.2961 - val_f1: 0.0586\n",
      "Epoch 1067/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2041 - f1: 0.8143 - val_loss: 0.2984 - val_f1: 0.0588\n",
      "Epoch 1068/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2063 - f1: 0.8119 - val_loss: 0.2985 - val_f1: 0.0584\n",
      "Epoch 1069/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2045 - f1: 0.8123 - val_loss: 0.3015 - val_f1: 0.0577\n",
      "Epoch 1070/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2052 - f1: 0.8122 - val_loss: 0.2990 - val_f1: 0.0582\n",
      "Epoch 1071/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2038 - f1: 0.8137 - val_loss: 0.2978 - val_f1: 0.0591\n",
      "Epoch 1072/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2056 - f1: 0.8138 - val_loss: 0.2951 - val_f1: 0.0584\n",
      "Epoch 1073/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2053 - f1: 0.8126 - val_loss: 0.2947 - val_f1: 0.0581\n",
      "Epoch 1074/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2040 - f1: 0.8139 - val_loss: 0.2997 - val_f1: 0.0581\n",
      "Epoch 1075/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2063 - f1: 0.8116 - val_loss: 0.2984 - val_f1: 0.0579\n",
      "Epoch 1076/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2050 - f1: 0.8111 - val_loss: 0.2999 - val_f1: 0.0588\n",
      "Epoch 1077/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2054 - f1: 0.8123 - val_loss: 0.3002 - val_f1: 0.0581\n",
      "Epoch 1078/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2068 - f1: 0.8120 - val_loss: 0.2968 - val_f1: 0.0578\n",
      "Epoch 1079/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2046 - f1: 0.8143 - val_loss: 0.2989 - val_f1: 0.0585\n",
      "Epoch 1080/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2044 - f1: 0.8134 - val_loss: 0.3008 - val_f1: 0.0588\n",
      "Epoch 1081/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2042 - f1: 0.8141 - val_loss: 0.2961 - val_f1: 0.0578\n",
      "Epoch 1082/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2052 - f1: 0.8126 - val_loss: 0.3003 - val_f1: 0.0579\n",
      "Epoch 1083/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2045 - f1: 0.8143 - val_loss: 0.2988 - val_f1: 0.0580\n",
      "Epoch 1084/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2060 - f1: 0.8110 - val_loss: 0.2960 - val_f1: 0.0589\n",
      "Epoch 1085/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2048 - f1: 0.8136 - val_loss: 0.2981 - val_f1: 0.0588\n",
      "Epoch 1086/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2058 - f1: 0.8130 - val_loss: 0.2939 - val_f1: 0.0581\n",
      "Epoch 1087/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2040 - f1: 0.8156 - val_loss: 0.2984 - val_f1: 0.0588\n",
      "Epoch 1088/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2050 - f1: 0.8134 - val_loss: 0.2984 - val_f1: 0.0579\n",
      "Epoch 1089/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2048 - f1: 0.8117 - val_loss: 0.2984 - val_f1: 0.0577\n",
      "Epoch 1090/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2053 - f1: 0.8123 - val_loss: 0.2985 - val_f1: 0.0577\n",
      "Epoch 1091/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2032 - f1: 0.8142 - val_loss: 0.2990 - val_f1: 0.0575\n",
      "Epoch 1092/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2037 - f1: 0.8137 - val_loss: 0.2970 - val_f1: 0.0581\n",
      "Epoch 1093/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2040 - f1: 0.8167 - val_loss: 0.2977 - val_f1: 0.0583\n",
      "Epoch 1094/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2048 - f1: 0.8128 - val_loss: 0.2995 - val_f1: 0.0585\n",
      "Epoch 1095/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2052 - f1: 0.8151 - val_loss: 0.2991 - val_f1: 0.0579\n",
      "Epoch 1096/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2069 - f1: 0.8111 - val_loss: 0.2956 - val_f1: 0.0576\n",
      "Epoch 1097/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.2037 - f1: 0.8141 - val_loss: 0.2984 - val_f1: 0.0583\n",
      "Epoch 1098/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2048 - f1: 0.8132 - val_loss: 0.2984 - val_f1: 0.0583\n",
      "Epoch 1099/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2033 - f1: 0.8157 - val_loss: 0.2983 - val_f1: 0.0589\n",
      "Epoch 1100/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2054 - f1: 0.8143 - val_loss: 0.2979 - val_f1: 0.0580\n",
      "Epoch 1101/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2068 - f1: 0.8116 - val_loss: 0.2996 - val_f1: 0.0586\n",
      "Epoch 1102/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2053 - f1: 0.8127 - val_loss: 0.2974 - val_f1: 0.0577\n",
      "Epoch 1103/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2045 - f1: 0.8133 - val_loss: 0.2961 - val_f1: 0.0572\n",
      "Epoch 1104/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2053 - f1: 0.8135 - val_loss: 0.2962 - val_f1: 0.0575\n",
      "Epoch 1105/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2050 - f1: 0.8133 - val_loss: 0.2953 - val_f1: 0.0584\n",
      "Epoch 1106/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2043 - f1: 0.8142 - val_loss: 0.2993 - val_f1: 0.0582\n",
      "Epoch 1107/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2046 - f1: 0.8152 - val_loss: 0.2988 - val_f1: 0.0584\n",
      "Epoch 1108/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2031 - f1: 0.8143 - val_loss: 0.3011 - val_f1: 0.0583\n",
      "Epoch 1109/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2046 - f1: 0.8147 - val_loss: 0.2957 - val_f1: 0.0582\n",
      "Epoch 1110/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2061 - f1: 0.8115 - val_loss: 0.2968 - val_f1: 0.0592\n",
      "Epoch 1111/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2066 - f1: 0.8110 - val_loss: 0.2976 - val_f1: 0.0580\n",
      "Epoch 1112/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2042 - f1: 0.8122 - val_loss: 0.2983 - val_f1: 0.0586\n",
      "Epoch 1113/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2042 - f1: 0.8127 - val_loss: 0.2981 - val_f1: 0.0581\n",
      "Epoch 1114/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2032 - f1: 0.8149 - val_loss: 0.2999 - val_f1: 0.0586\n",
      "Epoch 1115/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2046 - f1: 0.8133 - val_loss: 0.2945 - val_f1: 0.0587\n",
      "Epoch 1116/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2057 - f1: 0.8130 - val_loss: 0.2952 - val_f1: 0.0582\n",
      "Epoch 1117/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2032 - f1: 0.8152 - val_loss: 0.2996 - val_f1: 0.0584\n",
      "Epoch 1118/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2050 - f1: 0.8117 - val_loss: 0.2972 - val_f1: 0.0590\n",
      "Epoch 1119/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2014 - f1: 0.8185 - val_loss: 0.3002 - val_f1: 0.0586\n",
      "Epoch 1120/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2046 - f1: 0.8146 - val_loss: 0.2988 - val_f1: 0.0587\n",
      "Epoch 1121/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2038 - f1: 0.8136 - val_loss: 0.2989 - val_f1: 0.0584\n",
      "Epoch 1122/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2038 - f1: 0.8136 - val_loss: 0.3005 - val_f1: 0.0578\n",
      "Epoch 1123/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2041 - f1: 0.8154 - val_loss: 0.2975 - val_f1: 0.0578\n",
      "Epoch 1124/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2031 - f1: 0.8138 - val_loss: 0.3007 - val_f1: 0.0586\n",
      "Epoch 1125/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2015 - f1: 0.8161 - val_loss: 0.3020 - val_f1: 0.0586\n",
      "Epoch 1126/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2029 - f1: 0.8166 - val_loss: 0.2988 - val_f1: 0.0591\n",
      "Epoch 1127/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2036 - f1: 0.8162 - val_loss: 0.2978 - val_f1: 0.0586\n",
      "Epoch 1128/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2062 - f1: 0.8126 - val_loss: 0.2988 - val_f1: 0.0586\n",
      "Epoch 1129/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2026 - f1: 0.8141 - val_loss: 0.3001 - val_f1: 0.0577\n",
      "Epoch 1130/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2037 - f1: 0.8136 - val_loss: 0.3005 - val_f1: 0.0575\n",
      "Epoch 1131/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2037 - f1: 0.8149 - val_loss: 0.2995 - val_f1: 0.0586\n",
      "Epoch 1132/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2039 - f1: 0.8151 - val_loss: 0.2956 - val_f1: 0.0586\n",
      "Epoch 1133/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2025 - f1: 0.8162 - val_loss: 0.2983 - val_f1: 0.0585\n",
      "Epoch 1134/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2064 - f1: 0.8110 - val_loss: 0.3008 - val_f1: 0.0593\n",
      "Epoch 1135/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2037 - f1: 0.8140 - val_loss: 0.3001 - val_f1: 0.0581\n",
      "Epoch 1136/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2043 - f1: 0.8117 - val_loss: 0.2977 - val_f1: 0.0588\n",
      "Epoch 1137/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2006 - f1: 0.8168 - val_loss: 0.3018 - val_f1: 0.0588\n",
      "Epoch 1138/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2032 - f1: 0.8155 - val_loss: 0.2998 - val_f1: 0.0582\n",
      "Epoch 1139/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2032 - f1: 0.8147 - val_loss: 0.2998 - val_f1: 0.0581\n",
      "Epoch 1140/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2007 - f1: 0.8188 - val_loss: 0.3002 - val_f1: 0.0588\n",
      "Epoch 1141/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2035 - f1: 0.8150 - val_loss: 0.2992 - val_f1: 0.0590\n",
      "Epoch 1142/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2046 - f1: 0.8130 - val_loss: 0.2999 - val_f1: 0.0592\n",
      "Epoch 1143/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2034 - f1: 0.8145 - val_loss: 0.2988 - val_f1: 0.0587\n",
      "Epoch 1144/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2039 - f1: 0.8139 - val_loss: 0.3000 - val_f1: 0.0578\n",
      "Epoch 1145/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2025 - f1: 0.8147 - val_loss: 0.3011 - val_f1: 0.0582\n",
      "Epoch 1146/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2036 - f1: 0.8149 - val_loss: 0.2998 - val_f1: 0.0594\n",
      "Epoch 1147/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2019 - f1: 0.8160 - val_loss: 0.2990 - val_f1: 0.0578\n",
      "Epoch 1148/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2045 - f1: 0.8134 - val_loss: 0.3025 - val_f1: 0.0583\n",
      "Epoch 1149/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2026 - f1: 0.8168 - val_loss: 0.2981 - val_f1: 0.0579\n",
      "Epoch 1150/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2040 - f1: 0.8139 - val_loss: 0.2974 - val_f1: 0.0593\n",
      "Epoch 1151/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2037 - f1: 0.8158 - val_loss: 0.2993 - val_f1: 0.0592\n",
      "Epoch 1152/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2022 - f1: 0.8160 - val_loss: 0.2976 - val_f1: 0.0574\n",
      "Epoch 1153/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2029 - f1: 0.8152 - val_loss: 0.2990 - val_f1: 0.0591\n",
      "Epoch 1154/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2024 - f1: 0.8169 - val_loss: 0.2990 - val_f1: 0.0579\n",
      "Epoch 1155/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2025 - f1: 0.8160 - val_loss: 0.2993 - val_f1: 0.0580\n",
      "Epoch 1156/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2013 - f1: 0.8184 - val_loss: 0.3004 - val_f1: 0.0575\n",
      "Epoch 1157/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2028 - f1: 0.8159 - val_loss: 0.3014 - val_f1: 0.0583\n",
      "Epoch 1158/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2025 - f1: 0.8156 - val_loss: 0.3026 - val_f1: 0.0579\n",
      "Epoch 1159/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2020 - f1: 0.8158 - val_loss: 0.2992 - val_f1: 0.0585\n",
      "Epoch 1160/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2050 - f1: 0.8121 - val_loss: 0.2970 - val_f1: 0.0581\n",
      "Epoch 1161/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2045 - f1: 0.8153 - val_loss: 0.2986 - val_f1: 0.0583\n",
      "Epoch 1162/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2030 - f1: 0.8136 - val_loss: 0.2968 - val_f1: 0.0584\n",
      "Epoch 1163/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2029 - f1: 0.8159 - val_loss: 0.3002 - val_f1: 0.0585\n",
      "Epoch 1164/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2017 - f1: 0.8170 - val_loss: 0.2982 - val_f1: 0.0587\n",
      "Epoch 1165/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2041 - f1: 0.8137 - val_loss: 0.2959 - val_f1: 0.0590\n",
      "Epoch 1166/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2035 - f1: 0.8144 - val_loss: 0.3016 - val_f1: 0.0589\n",
      "Epoch 1167/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2037 - f1: 0.8149 - val_loss: 0.2990 - val_f1: 0.0587\n",
      "Epoch 1168/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2032 - f1: 0.8164 - val_loss: 0.2982 - val_f1: 0.0579\n",
      "Epoch 1169/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2033 - f1: 0.8131 - val_loss: 0.3004 - val_f1: 0.0580\n",
      "Epoch 1170/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2041 - f1: 0.8136 - val_loss: 0.2997 - val_f1: 0.0579\n",
      "Epoch 1171/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2045 - f1: 0.8142 - val_loss: 0.2989 - val_f1: 0.0578\n",
      "Epoch 1172/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2047 - f1: 0.8128 - val_loss: 0.2960 - val_f1: 0.0578\n",
      "Epoch 1173/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2022 - f1: 0.8149 - val_loss: 0.3004 - val_f1: 0.0588\n",
      "Epoch 1174/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2030 - f1: 0.8132 - val_loss: 0.2991 - val_f1: 0.0578\n",
      "Epoch 1175/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2023 - f1: 0.8172 - val_loss: 0.3007 - val_f1: 0.0588\n",
      "Epoch 1176/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2031 - f1: 0.8159 - val_loss: 0.3013 - val_f1: 0.0582\n",
      "Epoch 1177/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2022 - f1: 0.8156 - val_loss: 0.2990 - val_f1: 0.0586\n",
      "Epoch 1178/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2034 - f1: 0.8158 - val_loss: 0.2996 - val_f1: 0.0584\n",
      "Epoch 1179/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2034 - f1: 0.8150 - val_loss: 0.3006 - val_f1: 0.0581\n",
      "Epoch 1180/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2034 - f1: 0.8135 - val_loss: 0.2964 - val_f1: 0.0583\n",
      "Epoch 1181/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2050 - f1: 0.8134 - val_loss: 0.2986 - val_f1: 0.0592\n",
      "Epoch 1182/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2021 - f1: 0.8154 - val_loss: 0.2978 - val_f1: 0.0593\n",
      "Epoch 1183/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2028 - f1: 0.8139 - val_loss: 0.3031 - val_f1: 0.0580\n",
      "Epoch 1184/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2018 - f1: 0.8175 - val_loss: 0.3030 - val_f1: 0.0582\n",
      "Epoch 1185/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2026 - f1: 0.8159 - val_loss: 0.2978 - val_f1: 0.0583\n",
      "Epoch 1186/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2036 - f1: 0.8151 - val_loss: 0.2986 - val_f1: 0.0582\n",
      "Epoch 1187/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2012 - f1: 0.8184 - val_loss: 0.2986 - val_f1: 0.0589\n",
      "Epoch 1188/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2016 - f1: 0.8189 - val_loss: 0.2997 - val_f1: 0.0584\n",
      "Epoch 1189/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2025 - f1: 0.8153 - val_loss: 0.3023 - val_f1: 0.0586\n",
      "Epoch 1190/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2031 - f1: 0.8125 - val_loss: 0.3021 - val_f1: 0.0581\n",
      "Epoch 1191/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2033 - f1: 0.8159 - val_loss: 0.2997 - val_f1: 0.0582\n",
      "Epoch 1192/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2027 - f1: 0.8148 - val_loss: 0.2973 - val_f1: 0.0577\n",
      "Epoch 1193/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2017 - f1: 0.8174 - val_loss: 0.3004 - val_f1: 0.0584\n",
      "Epoch 1194/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2022 - f1: 0.8157 - val_loss: 0.3009 - val_f1: 0.0581\n",
      "Epoch 1195/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2023 - f1: 0.8157 - val_loss: 0.3005 - val_f1: 0.0582\n",
      "Epoch 1196/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2028 - f1: 0.8170 - val_loss: 0.3011 - val_f1: 0.0575\n",
      "Epoch 1197/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2025 - f1: 0.8158 - val_loss: 0.2997 - val_f1: 0.0581\n",
      "Epoch 1198/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2025 - f1: 0.8172 - val_loss: 0.3015 - val_f1: 0.0577\n",
      "Epoch 1199/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2020 - f1: 0.8171 - val_loss: 0.3000 - val_f1: 0.0590\n",
      "Epoch 1200/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2042 - f1: 0.8127 - val_loss: 0.3006 - val_f1: 0.0586\n",
      "Epoch 1201/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2026 - f1: 0.8125 - val_loss: 0.2986 - val_f1: 0.0587\n",
      "Epoch 1202/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2025 - f1: 0.8142 - val_loss: 0.2993 - val_f1: 0.0577\n",
      "Epoch 1203/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2016 - f1: 0.8166 - val_loss: 0.3000 - val_f1: 0.0575\n",
      "Epoch 1204/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2029 - f1: 0.8183 - val_loss: 0.2994 - val_f1: 0.0592\n",
      "Epoch 1205/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2034 - f1: 0.8134 - val_loss: 0.3011 - val_f1: 0.0579\n",
      "Epoch 1206/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2039 - f1: 0.8144 - val_loss: 0.3003 - val_f1: 0.0567\n",
      "Epoch 1207/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2028 - f1: 0.8154 - val_loss: 0.2988 - val_f1: 0.0573\n",
      "Epoch 1208/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2024 - f1: 0.8160 - val_loss: 0.2993 - val_f1: 0.0582\n",
      "Epoch 1209/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2017 - f1: 0.8159 - val_loss: 0.3007 - val_f1: 0.0585\n",
      "Epoch 1210/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2008 - f1: 0.8176 - val_loss: 0.3002 - val_f1: 0.0584\n",
      "Epoch 1211/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2007 - f1: 0.8168 - val_loss: 0.2988 - val_f1: 0.0579\n",
      "Epoch 1212/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2016 - f1: 0.8178 - val_loss: 0.3036 - val_f1: 0.0583\n",
      "Epoch 1213/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2035 - f1: 0.8168 - val_loss: 0.3002 - val_f1: 0.0592\n",
      "Epoch 1214/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2040 - f1: 0.8161 - val_loss: 0.3003 - val_f1: 0.0578\n",
      "Epoch 1215/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2031 - f1: 0.8156 - val_loss: 0.2987 - val_f1: 0.0578\n",
      "Epoch 1216/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2031 - f1: 0.8158 - val_loss: 0.2998 - val_f1: 0.0588\n",
      "Epoch 1217/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2017 - f1: 0.8184 - val_loss: 0.2972 - val_f1: 0.0578\n",
      "Epoch 1218/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2016 - f1: 0.8162 - val_loss: 0.3013 - val_f1: 0.0580\n",
      "Epoch 1219/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2015 - f1: 0.8176 - val_loss: 0.3004 - val_f1: 0.0575\n",
      "Epoch 1220/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2026 - f1: 0.8150 - val_loss: 0.2993 - val_f1: 0.0574\n",
      "Epoch 1221/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2013 - f1: 0.8154 - val_loss: 0.2996 - val_f1: 0.0590\n",
      "Epoch 1222/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2024 - f1: 0.8162 - val_loss: 0.3004 - val_f1: 0.0587\n",
      "Epoch 1223/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2012 - f1: 0.8179 - val_loss: 0.3002 - val_f1: 0.0580\n",
      "Epoch 1224/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2006 - f1: 0.8182 - val_loss: 0.3038 - val_f1: 0.0581\n",
      "Epoch 1225/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2021 - f1: 0.8166 - val_loss: 0.2985 - val_f1: 0.0582\n",
      "Epoch 1226/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2025 - f1: 0.8154 - val_loss: 0.2985 - val_f1: 0.0584\n",
      "Epoch 1227/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2020 - f1: 0.8148 - val_loss: 0.2977 - val_f1: 0.0586\n",
      "Epoch 1228/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1987 - f1: 0.8197 - val_loss: 0.3048 - val_f1: 0.0579\n",
      "Epoch 1229/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2025 - f1: 0.8150 - val_loss: 0.3030 - val_f1: 0.0577\n",
      "Epoch 1230/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2016 - f1: 0.8155 - val_loss: 0.3011 - val_f1: 0.0579\n",
      "Epoch 1231/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2019 - f1: 0.8175 - val_loss: 0.3019 - val_f1: 0.0581\n",
      "Epoch 1232/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2030 - f1: 0.8166 - val_loss: 0.2985 - val_f1: 0.0586\n",
      "Epoch 1233/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2008 - f1: 0.8179 - val_loss: 0.3013 - val_f1: 0.0576\n",
      "Epoch 1234/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2014 - f1: 0.8171 - val_loss: 0.2999 - val_f1: 0.0590\n",
      "Epoch 1235/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2026 - f1: 0.8151 - val_loss: 0.2990 - val_f1: 0.0589\n",
      "Epoch 1236/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2013 - f1: 0.8174 - val_loss: 0.3004 - val_f1: 0.0577\n",
      "Epoch 1237/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2026 - f1: 0.8167 - val_loss: 0.3044 - val_f1: 0.0576\n",
      "Epoch 1238/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2013 - f1: 0.8180 - val_loss: 0.2997 - val_f1: 0.0585\n",
      "Epoch 1239/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2038 - f1: 0.8150 - val_loss: 0.3007 - val_f1: 0.0573\n",
      "Epoch 1240/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2015 - f1: 0.8173 - val_loss: 0.3004 - val_f1: 0.0586\n",
      "Epoch 1241/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2019 - f1: 0.8151 - val_loss: 0.3013 - val_f1: 0.0588\n",
      "Epoch 1242/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2027 - f1: 0.8135 - val_loss: 0.3023 - val_f1: 0.0580\n",
      "Epoch 1243/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2009 - f1: 0.8170 - val_loss: 0.3007 - val_f1: 0.0584\n",
      "Epoch 1244/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2014 - f1: 0.8161 - val_loss: 0.3008 - val_f1: 0.0585\n",
      "Epoch 1245/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2024 - f1: 0.8169 - val_loss: 0.3010 - val_f1: 0.0589\n",
      "Epoch 1246/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2011 - f1: 0.8169 - val_loss: 0.2981 - val_f1: 0.0581\n",
      "Epoch 1247/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2005 - f1: 0.8190 - val_loss: 0.3014 - val_f1: 0.0583\n",
      "Epoch 1248/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2021 - f1: 0.8164 - val_loss: 0.2996 - val_f1: 0.0588\n",
      "Epoch 1249/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2021 - f1: 0.8161 - val_loss: 0.2958 - val_f1: 0.0569\n",
      "Epoch 1250/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2011 - f1: 0.8165 - val_loss: 0.2995 - val_f1: 0.0578\n",
      "Epoch 1251/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2019 - f1: 0.8153 - val_loss: 0.2985 - val_f1: 0.0582\n",
      "Epoch 1252/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2014 - f1: 0.8175 - val_loss: 0.3019 - val_f1: 0.0576\n",
      "Epoch 1253/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2017 - f1: 0.8152 - val_loss: 0.2988 - val_f1: 0.0586\n",
      "Epoch 1254/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2003 - f1: 0.8185 - val_loss: 0.3011 - val_f1: 0.0581\n",
      "Epoch 1255/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2004 - f1: 0.8177 - val_loss: 0.3015 - val_f1: 0.0588\n",
      "Epoch 1256/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2005 - f1: 0.8208 - val_loss: 0.2996 - val_f1: 0.0583\n",
      "Epoch 1257/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2027 - f1: 0.8148 - val_loss: 0.3012 - val_f1: 0.0579\n",
      "Epoch 1258/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2012 - f1: 0.8184 - val_loss: 0.3009 - val_f1: 0.0588\n",
      "Epoch 1259/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2020 - f1: 0.8166 - val_loss: 0.3008 - val_f1: 0.0582\n",
      "Epoch 1260/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.2016 - f1: 0.8159 - val_loss: 0.3014 - val_f1: 0.0589\n",
      "Epoch 1261/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2025 - f1: 0.8158 - val_loss: 0.2973 - val_f1: 0.0578\n",
      "Epoch 1262/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2006 - f1: 0.8177 - val_loss: 0.2992 - val_f1: 0.0571\n",
      "Epoch 1263/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2016 - f1: 0.8175 - val_loss: 0.3018 - val_f1: 0.0578\n",
      "Epoch 1264/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2026 - f1: 0.8153 - val_loss: 0.2998 - val_f1: 0.0576\n",
      "Epoch 1265/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2014 - f1: 0.8164 - val_loss: 0.3007 - val_f1: 0.0584\n",
      "Epoch 1266/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2008 - f1: 0.8174 - val_loss: 0.3026 - val_f1: 0.0577\n",
      "Epoch 1267/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2014 - f1: 0.8163 - val_loss: 0.3029 - val_f1: 0.0582\n",
      "Epoch 1268/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2008 - f1: 0.8177 - val_loss: 0.3035 - val_f1: 0.0583\n",
      "Epoch 1269/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2006 - f1: 0.8184 - val_loss: 0.2992 - val_f1: 0.0575\n",
      "Epoch 1270/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2013 - f1: 0.8174 - val_loss: 0.3023 - val_f1: 0.0577\n",
      "Epoch 1271/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2005 - f1: 0.8175 - val_loss: 0.3048 - val_f1: 0.0573\n",
      "Epoch 1272/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2020 - f1: 0.8154 - val_loss: 0.2989 - val_f1: 0.0582\n",
      "Epoch 1273/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2007 - f1: 0.8167 - val_loss: 0.3035 - val_f1: 0.0582\n",
      "Epoch 1274/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2011 - f1: 0.8174 - val_loss: 0.3005 - val_f1: 0.0580\n",
      "Epoch 1275/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2023 - f1: 0.8157 - val_loss: 0.3046 - val_f1: 0.0586\n",
      "Epoch 1276/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1992 - f1: 0.8186 - val_loss: 0.3013 - val_f1: 0.0579\n",
      "Epoch 1277/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2004 - f1: 0.8184 - val_loss: 0.2993 - val_f1: 0.0584\n",
      "Epoch 1278/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2009 - f1: 0.8173 - val_loss: 0.3020 - val_f1: 0.0580\n",
      "Epoch 1279/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2011 - f1: 0.8166 - val_loss: 0.3015 - val_f1: 0.0577\n",
      "Epoch 1280/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2012 - f1: 0.8169 - val_loss: 0.2997 - val_f1: 0.0581\n",
      "Epoch 1281/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2013 - f1: 0.8170 - val_loss: 0.3009 - val_f1: 0.0579\n",
      "Epoch 1282/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2001 - f1: 0.8186 - val_loss: 0.3013 - val_f1: 0.0589\n",
      "Epoch 1283/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1993 - f1: 0.8194 - val_loss: 0.3038 - val_f1: 0.0584\n",
      "Epoch 1284/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1991 - f1: 0.8183 - val_loss: 0.3037 - val_f1: 0.0581\n",
      "Epoch 1285/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2006 - f1: 0.8200 - val_loss: 0.2982 - val_f1: 0.0580\n",
      "Epoch 1286/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2003 - f1: 0.8174 - val_loss: 0.3050 - val_f1: 0.0580\n",
      "Epoch 1287/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1989 - f1: 0.8198 - val_loss: 0.3013 - val_f1: 0.0577\n",
      "Epoch 1288/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1992 - f1: 0.8194 - val_loss: 0.3028 - val_f1: 0.0580\n",
      "Epoch 1289/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1993 - f1: 0.8182 - val_loss: 0.3034 - val_f1: 0.0582\n",
      "Epoch 1290/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1996 - f1: 0.8184 - val_loss: 0.3011 - val_f1: 0.0590\n",
      "Epoch 1291/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2020 - f1: 0.8176 - val_loss: 0.3020 - val_f1: 0.0578\n",
      "Epoch 1292/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2023 - f1: 0.8162 - val_loss: 0.2998 - val_f1: 0.0575\n",
      "Epoch 1293/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2012 - f1: 0.8185 - val_loss: 0.2975 - val_f1: 0.0577\n",
      "Epoch 1294/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2013 - f1: 0.8168 - val_loss: 0.2992 - val_f1: 0.0582\n",
      "Epoch 1295/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2013 - f1: 0.8181 - val_loss: 0.3002 - val_f1: 0.0590\n",
      "Epoch 1296/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2007 - f1: 0.8189 - val_loss: 0.3015 - val_f1: 0.0574\n",
      "Epoch 1297/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1990 - f1: 0.8206 - val_loss: 0.3054 - val_f1: 0.0587\n",
      "Epoch 1298/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2012 - f1: 0.8161 - val_loss: 0.2991 - val_f1: 0.0583\n",
      "Epoch 1299/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2012 - f1: 0.8167 - val_loss: 0.3024 - val_f1: 0.0584\n",
      "Epoch 1300/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1990 - f1: 0.8175 - val_loss: 0.3024 - val_f1: 0.0578\n",
      "Epoch 1301/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2000 - f1: 0.8176 - val_loss: 0.3010 - val_f1: 0.0587\n",
      "Epoch 1302/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2015 - f1: 0.8157 - val_loss: 0.3027 - val_f1: 0.0581\n",
      "Epoch 1303/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2009 - f1: 0.8172 - val_loss: 0.3047 - val_f1: 0.0588\n",
      "Epoch 1304/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1990 - f1: 0.8189 - val_loss: 0.3039 - val_f1: 0.0587\n",
      "Epoch 1305/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1997 - f1: 0.8189 - val_loss: 0.3005 - val_f1: 0.0580\n",
      "Epoch 1306/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1991 - f1: 0.8175 - val_loss: 0.3031 - val_f1: 0.0583\n",
      "Epoch 1307/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2006 - f1: 0.8187 - val_loss: 0.3017 - val_f1: 0.0583\n",
      "Epoch 1308/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2003 - f1: 0.8186 - val_loss: 0.3007 - val_f1: 0.0581\n",
      "Epoch 1309/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1993 - f1: 0.8202 - val_loss: 0.3022 - val_f1: 0.0578\n",
      "Epoch 1310/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2004 - f1: 0.8167 - val_loss: 0.2989 - val_f1: 0.0586\n",
      "Epoch 1311/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1998 - f1: 0.8186 - val_loss: 0.3056 - val_f1: 0.0585\n",
      "Epoch 1312/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1980 - f1: 0.8207 - val_loss: 0.3041 - val_f1: 0.0577\n",
      "Epoch 1313/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2000 - f1: 0.8185 - val_loss: 0.3016 - val_f1: 0.0576\n",
      "Epoch 1314/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1993 - f1: 0.8189 - val_loss: 0.3024 - val_f1: 0.0582\n",
      "Epoch 1315/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2006 - f1: 0.8170 - val_loss: 0.3025 - val_f1: 0.0582\n",
      "Epoch 1316/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.1990 - f1: 0.8176 - val_loss: 0.3026 - val_f1: 0.0581\n",
      "Epoch 1317/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1992 - f1: 0.8196 - val_loss: 0.3023 - val_f1: 0.0580\n",
      "Epoch 1318/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1990 - f1: 0.8195 - val_loss: 0.3004 - val_f1: 0.0586\n",
      "Epoch 1319/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1992 - f1: 0.8183 - val_loss: 0.3029 - val_f1: 0.0575\n",
      "Epoch 1320/2000\n",
      "168135/168135 [==============================] - 15s 90us/step - loss: 0.2001 - f1: 0.8192 - val_loss: 0.3020 - val_f1: 0.0579\n",
      "Epoch 1321/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1984 - f1: 0.8206 - val_loss: 0.3026 - val_f1: 0.0580\n",
      "Epoch 1322/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2006 - f1: 0.8173 - val_loss: 0.3006 - val_f1: 0.0586\n",
      "Epoch 1323/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1991 - f1: 0.8193 - val_loss: 0.3021 - val_f1: 0.0576\n",
      "Epoch 1324/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2003 - f1: 0.8176 - val_loss: 0.2990 - val_f1: 0.0566\n",
      "Epoch 1325/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2018 - f1: 0.8170 - val_loss: 0.3004 - val_f1: 0.0581\n",
      "Epoch 1326/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2011 - f1: 0.8176 - val_loss: 0.3012 - val_f1: 0.0575\n",
      "Epoch 1327/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1977 - f1: 0.8222 - val_loss: 0.3054 - val_f1: 0.0580\n",
      "Epoch 1328/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2009 - f1: 0.8197 - val_loss: 0.2993 - val_f1: 0.0575\n",
      "Epoch 1329/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1993 - f1: 0.8198 - val_loss: 0.3044 - val_f1: 0.0577\n",
      "Epoch 1330/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2017 - f1: 0.8184 - val_loss: 0.3025 - val_f1: 0.0596\n",
      "Epoch 1331/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1994 - f1: 0.8193 - val_loss: 0.3013 - val_f1: 0.0584\n",
      "Epoch 1332/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1999 - f1: 0.8184 - val_loss: 0.3008 - val_f1: 0.0578\n",
      "Epoch 1333/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2014 - f1: 0.8173 - val_loss: 0.2999 - val_f1: 0.0585\n",
      "Epoch 1334/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1983 - f1: 0.8222 - val_loss: 0.3028 - val_f1: 0.0581\n",
      "Epoch 1335/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2010 - f1: 0.8181 - val_loss: 0.3018 - val_f1: 0.0579\n",
      "Epoch 1336/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1979 - f1: 0.8205 - val_loss: 0.2979 - val_f1: 0.0582\n",
      "Epoch 1337/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2003 - f1: 0.8174 - val_loss: 0.2991 - val_f1: 0.0584\n",
      "Epoch 1338/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2009 - f1: 0.8168 - val_loss: 0.3040 - val_f1: 0.0577\n",
      "Epoch 1339/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2018 - f1: 0.8165 - val_loss: 0.2998 - val_f1: 0.0585\n",
      "Epoch 1340/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2005 - f1: 0.8178 - val_loss: 0.2995 - val_f1: 0.0582\n",
      "Epoch 1341/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1996 - f1: 0.8183 - val_loss: 0.3033 - val_f1: 0.0587\n",
      "Epoch 1342/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1987 - f1: 0.8197 - val_loss: 0.2998 - val_f1: 0.0579\n",
      "Epoch 1343/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2001 - f1: 0.8186 - val_loss: 0.3011 - val_f1: 0.0582\n",
      "Epoch 1344/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1979 - f1: 0.8190 - val_loss: 0.3024 - val_f1: 0.0586\n",
      "Epoch 1345/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1993 - f1: 0.8202 - val_loss: 0.3020 - val_f1: 0.0584\n",
      "Epoch 1346/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2003 - f1: 0.8187 - val_loss: 0.3016 - val_f1: 0.0580\n",
      "Epoch 1347/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2002 - f1: 0.8186 - val_loss: 0.3005 - val_f1: 0.0585\n",
      "Epoch 1348/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1989 - f1: 0.8199 - val_loss: 0.3039 - val_f1: 0.0578\n",
      "Epoch 1349/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.2005 - f1: 0.8184 - val_loss: 0.3037 - val_f1: 0.0583\n",
      "Epoch 1350/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2005 - f1: 0.8181 - val_loss: 0.3003 - val_f1: 0.0586\n",
      "Epoch 1351/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1996 - f1: 0.8193 - val_loss: 0.3022 - val_f1: 0.0589\n",
      "Epoch 1352/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1999 - f1: 0.8189 - val_loss: 0.3035 - val_f1: 0.0580\n",
      "Epoch 1353/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1981 - f1: 0.8187 - val_loss: 0.3031 - val_f1: 0.0579\n",
      "Epoch 1354/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2008 - f1: 0.8185 - val_loss: 0.3007 - val_f1: 0.0584\n",
      "Epoch 1355/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2015 - f1: 0.8190 - val_loss: 0.3019 - val_f1: 0.0582\n",
      "Epoch 1356/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1987 - f1: 0.8204 - val_loss: 0.3026 - val_f1: 0.0576\n",
      "Epoch 1357/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1998 - f1: 0.8169 - val_loss: 0.3020 - val_f1: 0.0581\n",
      "Epoch 1358/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1982 - f1: 0.8206 - val_loss: 0.3024 - val_f1: 0.0575\n",
      "Epoch 1359/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2004 - f1: 0.8184 - val_loss: 0.2983 - val_f1: 0.0588\n",
      "Epoch 1360/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2009 - f1: 0.8180 - val_loss: 0.2994 - val_f1: 0.0588\n",
      "Epoch 1361/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1986 - f1: 0.8197 - val_loss: 0.3043 - val_f1: 0.0578\n",
      "Epoch 1362/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.1987 - f1: 0.8212 - val_loss: 0.3023 - val_f1: 0.0574\n",
      "Epoch 1363/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2012 - f1: 0.8174 - val_loss: 0.2993 - val_f1: 0.0581\n",
      "Epoch 1364/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1980 - f1: 0.8216 - val_loss: 0.3045 - val_f1: 0.0581\n",
      "Epoch 1365/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.2004 - f1: 0.8177 - val_loss: 0.3014 - val_f1: 0.0584\n",
      "Epoch 1366/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1982 - f1: 0.8191 - val_loss: 0.3051 - val_f1: 0.0590\n",
      "Epoch 1367/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2006 - f1: 0.8193 - val_loss: 0.3041 - val_f1: 0.0590\n",
      "Epoch 1368/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.2001 - f1: 0.8173 - val_loss: 0.3039 - val_f1: 0.0581\n",
      "Epoch 1369/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1985 - f1: 0.8200 - val_loss: 0.3046 - val_f1: 0.0576\n",
      "Epoch 1370/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1968 - f1: 0.8221 - val_loss: 0.3076 - val_f1: 0.0574\n",
      "Epoch 1371/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1989 - f1: 0.8197 - val_loss: 0.3046 - val_f1: 0.0583\n",
      "Epoch 1372/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.1991 - f1: 0.8195 - val_loss: 0.3039 - val_f1: 0.0580\n",
      "Epoch 1373/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.1996 - f1: 0.8199 - val_loss: 0.3037 - val_f1: 0.0582\n",
      "Epoch 1374/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1991 - f1: 0.8200 - val_loss: 0.3020 - val_f1: 0.0578\n",
      "Epoch 1375/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1985 - f1: 0.8215 - val_loss: 0.3062 - val_f1: 0.0582\n",
      "Epoch 1376/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1987 - f1: 0.8203 - val_loss: 0.3046 - val_f1: 0.0583\n",
      "Epoch 1377/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1995 - f1: 0.8192 - val_loss: 0.3021 - val_f1: 0.0579\n",
      "Epoch 1378/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1968 - f1: 0.8224 - val_loss: 0.3015 - val_f1: 0.0581\n",
      "Epoch 1379/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.2002 - f1: 0.8186 - val_loss: 0.3004 - val_f1: 0.0577\n",
      "Epoch 1380/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1983 - f1: 0.8218 - val_loss: 0.3035 - val_f1: 0.0583\n",
      "Epoch 1381/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1982 - f1: 0.8200 - val_loss: 0.3042 - val_f1: 0.0584\n",
      "Epoch 1382/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1979 - f1: 0.8195 - val_loss: 0.3017 - val_f1: 0.0588\n",
      "Epoch 1383/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1980 - f1: 0.8216 - val_loss: 0.3022 - val_f1: 0.0583\n",
      "Epoch 1384/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1992 - f1: 0.8210 - val_loss: 0.3021 - val_f1: 0.0581\n",
      "Epoch 1385/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2011 - f1: 0.8164 - val_loss: 0.3031 - val_f1: 0.0577\n",
      "Epoch 1386/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1989 - f1: 0.8198 - val_loss: 0.3004 - val_f1: 0.0587\n",
      "Epoch 1387/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.1991 - f1: 0.8189 - val_loss: 0.3035 - val_f1: 0.0578\n",
      "Epoch 1388/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1966 - f1: 0.8217 - val_loss: 0.3052 - val_f1: 0.0583\n",
      "Epoch 1389/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1974 - f1: 0.8206 - val_loss: 0.3018 - val_f1: 0.0582\n",
      "Epoch 1390/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1983 - f1: 0.8211 - val_loss: 0.3066 - val_f1: 0.0585\n",
      "Epoch 1391/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1985 - f1: 0.8196 - val_loss: 0.3049 - val_f1: 0.0581\n",
      "Epoch 1392/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1972 - f1: 0.8208 - val_loss: 0.3008 - val_f1: 0.0582\n",
      "Epoch 1393/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1988 - f1: 0.8207 - val_loss: 0.3041 - val_f1: 0.0587\n",
      "Epoch 1394/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1977 - f1: 0.8201 - val_loss: 0.3023 - val_f1: 0.0584\n",
      "Epoch 1395/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1972 - f1: 0.8215 - val_loss: 0.3019 - val_f1: 0.0583\n",
      "Epoch 1396/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1996 - f1: 0.8200 - val_loss: 0.3034 - val_f1: 0.0583\n",
      "Epoch 1397/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1986 - f1: 0.8216 - val_loss: 0.2994 - val_f1: 0.0570\n",
      "Epoch 1398/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1970 - f1: 0.8226 - val_loss: 0.3023 - val_f1: 0.0583\n",
      "Epoch 1399/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1982 - f1: 0.8223 - val_loss: 0.3004 - val_f1: 0.0577\n",
      "Epoch 1400/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1982 - f1: 0.8208 - val_loss: 0.3027 - val_f1: 0.0582\n",
      "Epoch 1401/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1987 - f1: 0.8200 - val_loss: 0.3019 - val_f1: 0.0585\n",
      "Epoch 1402/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1976 - f1: 0.8203 - val_loss: 0.3027 - val_f1: 0.0586\n",
      "Epoch 1403/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1984 - f1: 0.8194 - val_loss: 0.3055 - val_f1: 0.0584\n",
      "Epoch 1404/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1975 - f1: 0.8205 - val_loss: 0.3010 - val_f1: 0.0586\n",
      "Epoch 1405/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1986 - f1: 0.8220 - val_loss: 0.3009 - val_f1: 0.0585\n",
      "Epoch 1406/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1968 - f1: 0.8215 - val_loss: 0.3044 - val_f1: 0.0586\n",
      "Epoch 1407/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1978 - f1: 0.8205 - val_loss: 0.3015 - val_f1: 0.0587\n",
      "Epoch 1408/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1983 - f1: 0.8215 - val_loss: 0.3026 - val_f1: 0.0574\n",
      "Epoch 1409/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1991 - f1: 0.8205 - val_loss: 0.3005 - val_f1: 0.0583\n",
      "Epoch 1410/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1971 - f1: 0.8221 - val_loss: 0.3044 - val_f1: 0.0586\n",
      "Epoch 1411/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1990 - f1: 0.8194 - val_loss: 0.3015 - val_f1: 0.0581\n",
      "Epoch 1412/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1979 - f1: 0.8201 - val_loss: 0.3031 - val_f1: 0.0585\n",
      "Epoch 1413/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1974 - f1: 0.8218 - val_loss: 0.3049 - val_f1: 0.0581\n",
      "Epoch 1414/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1992 - f1: 0.8197 - val_loss: 0.3007 - val_f1: 0.0578\n",
      "Epoch 1415/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1984 - f1: 0.8216 - val_loss: 0.3036 - val_f1: 0.0582\n",
      "Epoch 1416/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1983 - f1: 0.8202 - val_loss: 0.3013 - val_f1: 0.0585\n",
      "Epoch 1417/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1973 - f1: 0.8203 - val_loss: 0.3037 - val_f1: 0.0580\n",
      "Epoch 1418/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1990 - f1: 0.8219 - val_loss: 0.2972 - val_f1: 0.0582\n",
      "Epoch 1419/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1988 - f1: 0.8215 - val_loss: 0.3044 - val_f1: 0.0581\n",
      "Epoch 1420/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1978 - f1: 0.8214 - val_loss: 0.3004 - val_f1: 0.0578\n",
      "Epoch 1421/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1988 - f1: 0.8206 - val_loss: 0.3038 - val_f1: 0.0585\n",
      "Epoch 1422/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.1996 - f1: 0.8192 - val_loss: 0.3014 - val_f1: 0.0577\n",
      "Epoch 1423/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.1980 - f1: 0.8210 - val_loss: 0.3033 - val_f1: 0.0571\n",
      "Epoch 1424/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1978 - f1: 0.8220 - val_loss: 0.3031 - val_f1: 0.0581\n",
      "Epoch 1425/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.1977 - f1: 0.8222 - val_loss: 0.3056 - val_f1: 0.0576\n",
      "Epoch 1426/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1975 - f1: 0.8204 - val_loss: 0.3021 - val_f1: 0.0584\n",
      "Epoch 1427/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1998 - f1: 0.8185 - val_loss: 0.3007 - val_f1: 0.0577\n",
      "Epoch 1428/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1988 - f1: 0.8205 - val_loss: 0.3022 - val_f1: 0.0580\n",
      "Epoch 1429/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1979 - f1: 0.8207 - val_loss: 0.3026 - val_f1: 0.0580\n",
      "Epoch 1430/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1981 - f1: 0.8212 - val_loss: 0.3040 - val_f1: 0.0587\n",
      "Epoch 1431/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1970 - f1: 0.8230 - val_loss: 0.3033 - val_f1: 0.0581\n",
      "Epoch 1432/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1983 - f1: 0.8194 - val_loss: 0.3049 - val_f1: 0.0587\n",
      "Epoch 1433/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1993 - f1: 0.8191 - val_loss: 0.3047 - val_f1: 0.0579\n",
      "Epoch 1434/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1969 - f1: 0.8212 - val_loss: 0.3022 - val_f1: 0.0578\n",
      "Epoch 1435/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.1980 - f1: 0.8229 - val_loss: 0.3021 - val_f1: 0.0576\n",
      "Epoch 1436/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1968 - f1: 0.8224 - val_loss: 0.3023 - val_f1: 0.0585\n",
      "Epoch 1437/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1983 - f1: 0.8194 - val_loss: 0.3014 - val_f1: 0.0578\n",
      "Epoch 1438/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1966 - f1: 0.8240 - val_loss: 0.3013 - val_f1: 0.0591\n",
      "Epoch 1439/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1971 - f1: 0.8232 - val_loss: 0.3044 - val_f1: 0.0588\n",
      "Epoch 1440/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1979 - f1: 0.8204 - val_loss: 0.3074 - val_f1: 0.0578\n",
      "Epoch 1441/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1976 - f1: 0.8209 - val_loss: 0.3024 - val_f1: 0.0579\n",
      "Epoch 1442/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1985 - f1: 0.8200 - val_loss: 0.3036 - val_f1: 0.0583\n",
      "Epoch 1443/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1980 - f1: 0.8197 - val_loss: 0.3031 - val_f1: 0.0580\n",
      "Epoch 1444/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1977 - f1: 0.8202 - val_loss: 0.3017 - val_f1: 0.0579\n",
      "Epoch 1445/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1973 - f1: 0.8219 - val_loss: 0.3020 - val_f1: 0.0579\n",
      "Epoch 1446/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1982 - f1: 0.8201 - val_loss: 0.3022 - val_f1: 0.0589\n",
      "Epoch 1447/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.2005 - f1: 0.8174 - val_loss: 0.3041 - val_f1: 0.0584\n",
      "Epoch 1448/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1995 - f1: 0.8194 - val_loss: 0.3026 - val_f1: 0.0584\n",
      "Epoch 1449/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1978 - f1: 0.8201 - val_loss: 0.3050 - val_f1: 0.0585\n",
      "Epoch 1450/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1971 - f1: 0.8222 - val_loss: 0.3023 - val_f1: 0.0581\n",
      "Epoch 1451/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1980 - f1: 0.8203 - val_loss: 0.3033 - val_f1: 0.0580\n",
      "Epoch 1452/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1980 - f1: 0.8196 - val_loss: 0.3013 - val_f1: 0.0583\n",
      "Epoch 1453/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1993 - f1: 0.8183 - val_loss: 0.2970 - val_f1: 0.0584\n",
      "Epoch 1454/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1958 - f1: 0.8218 - val_loss: 0.3026 - val_f1: 0.0578\n",
      "Epoch 1455/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1984 - f1: 0.8201 - val_loss: 0.3009 - val_f1: 0.0572\n",
      "Epoch 1456/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1974 - f1: 0.8211 - val_loss: 0.2991 - val_f1: 0.0581\n",
      "Epoch 1457/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1955 - f1: 0.8221 - val_loss: 0.3019 - val_f1: 0.0586\n",
      "Epoch 1458/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1983 - f1: 0.8202 - val_loss: 0.3020 - val_f1: 0.0578\n",
      "Epoch 1459/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1961 - f1: 0.8237 - val_loss: 0.3029 - val_f1: 0.0583\n",
      "Epoch 1460/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1981 - f1: 0.8197 - val_loss: 0.3044 - val_f1: 0.0571\n",
      "Epoch 1461/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1991 - f1: 0.8187 - val_loss: 0.3032 - val_f1: 0.0574\n",
      "Epoch 1462/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1978 - f1: 0.8202 - val_loss: 0.3036 - val_f1: 0.0587\n",
      "Epoch 1463/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1971 - f1: 0.8206 - val_loss: 0.3021 - val_f1: 0.0582\n",
      "Epoch 1464/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1973 - f1: 0.8219 - val_loss: 0.3021 - val_f1: 0.0583\n",
      "Epoch 1465/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1968 - f1: 0.8224 - val_loss: 0.3063 - val_f1: 0.0580\n",
      "Epoch 1466/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1969 - f1: 0.8230 - val_loss: 0.3011 - val_f1: 0.0583\n",
      "Epoch 1467/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1981 - f1: 0.8203 - val_loss: 0.3016 - val_f1: 0.0578\n",
      "Epoch 1468/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1978 - f1: 0.8213 - val_loss: 0.3054 - val_f1: 0.0580\n",
      "Epoch 1469/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1969 - f1: 0.8215 - val_loss: 0.3010 - val_f1: 0.0579\n",
      "Epoch 1470/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.2003 - f1: 0.8176 - val_loss: 0.3035 - val_f1: 0.0571\n",
      "Epoch 1471/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1958 - f1: 0.8220 - val_loss: 0.2993 - val_f1: 0.0591\n",
      "Epoch 1472/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1973 - f1: 0.8226 - val_loss: 0.3027 - val_f1: 0.0579\n",
      "Epoch 1473/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1984 - f1: 0.8203 - val_loss: 0.3040 - val_f1: 0.0575\n",
      "Epoch 1474/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1987 - f1: 0.8198 - val_loss: 0.3004 - val_f1: 0.0580\n",
      "Epoch 1475/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1976 - f1: 0.8203 - val_loss: 0.3066 - val_f1: 0.0574\n",
      "Epoch 1476/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1965 - f1: 0.8210 - val_loss: 0.3009 - val_f1: 0.0587\n",
      "Epoch 1477/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1979 - f1: 0.8217 - val_loss: 0.3013 - val_f1: 0.0581\n",
      "Epoch 1478/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1974 - f1: 0.8215 - val_loss: 0.3006 - val_f1: 0.0580\n",
      "Epoch 1479/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1970 - f1: 0.8214 - val_loss: 0.3046 - val_f1: 0.0582\n",
      "Epoch 1480/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1973 - f1: 0.8202 - val_loss: 0.3025 - val_f1: 0.0586\n",
      "Epoch 1481/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1986 - f1: 0.8206 - val_loss: 0.2982 - val_f1: 0.0575\n",
      "Epoch 1482/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1958 - f1: 0.8218 - val_loss: 0.3039 - val_f1: 0.0581\n",
      "Epoch 1483/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1970 - f1: 0.8212 - val_loss: 0.3074 - val_f1: 0.0576\n",
      "Epoch 1484/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1978 - f1: 0.8224 - val_loss: 0.3037 - val_f1: 0.0583\n",
      "Epoch 1485/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1980 - f1: 0.8200 - val_loss: 0.3008 - val_f1: 0.0584\n",
      "Epoch 1486/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1966 - f1: 0.8221 - val_loss: 0.3058 - val_f1: 0.0578\n",
      "Epoch 1487/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1972 - f1: 0.8200 - val_loss: 0.3051 - val_f1: 0.0584\n",
      "Epoch 1488/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1989 - f1: 0.8195 - val_loss: 0.3001 - val_f1: 0.0583\n",
      "Epoch 1489/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.1950 - f1: 0.8241 - val_loss: 0.3055 - val_f1: 0.0581\n",
      "Epoch 1490/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1979 - f1: 0.8208 - val_loss: 0.3015 - val_f1: 0.0583\n",
      "Epoch 1491/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1963 - f1: 0.8238 - val_loss: 0.3046 - val_f1: 0.0584\n",
      "Epoch 1492/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1967 - f1: 0.8231 - val_loss: 0.3037 - val_f1: 0.0586\n",
      "Epoch 1493/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1979 - f1: 0.8205 - val_loss: 0.3014 - val_f1: 0.0579\n",
      "Epoch 1494/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1976 - f1: 0.8208 - val_loss: 0.3017 - val_f1: 0.0575\n",
      "Epoch 1495/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1961 - f1: 0.8219 - val_loss: 0.3058 - val_f1: 0.0579\n",
      "Epoch 1496/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1979 - f1: 0.8207 - val_loss: 0.3005 - val_f1: 0.0584\n",
      "Epoch 1497/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1976 - f1: 0.8203 - val_loss: 0.3012 - val_f1: 0.0585\n",
      "Epoch 1498/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1981 - f1: 0.8203 - val_loss: 0.3011 - val_f1: 0.0579\n",
      "Epoch 1499/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1979 - f1: 0.8216 - val_loss: 0.3028 - val_f1: 0.0586\n",
      "Epoch 1500/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1967 - f1: 0.8240 - val_loss: 0.3034 - val_f1: 0.0589\n",
      "Epoch 1501/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1967 - f1: 0.8236 - val_loss: 0.3065 - val_f1: 0.0583\n",
      "Epoch 1502/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1972 - f1: 0.8222 - val_loss: 0.3028 - val_f1: 0.0578\n",
      "Epoch 1503/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1976 - f1: 0.8230 - val_loss: 0.3035 - val_f1: 0.0574\n",
      "Epoch 1504/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1986 - f1: 0.8203 - val_loss: 0.3034 - val_f1: 0.0586\n",
      "Epoch 1505/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1944 - f1: 0.8246 - val_loss: 0.3051 - val_f1: 0.0580\n",
      "Epoch 1506/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1977 - f1: 0.8214 - val_loss: 0.3010 - val_f1: 0.0586\n",
      "Epoch 1507/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1961 - f1: 0.8231 - val_loss: 0.3061 - val_f1: 0.0580\n",
      "Epoch 1508/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1950 - f1: 0.8227 - val_loss: 0.3058 - val_f1: 0.0578\n",
      "Epoch 1509/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1964 - f1: 0.8218 - val_loss: 0.3057 - val_f1: 0.0582\n",
      "Epoch 1510/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1991 - f1: 0.8200 - val_loss: 0.3016 - val_f1: 0.0583\n",
      "Epoch 1511/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1959 - f1: 0.8213 - val_loss: 0.3067 - val_f1: 0.0579\n",
      "Epoch 1512/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1965 - f1: 0.8225 - val_loss: 0.2999 - val_f1: 0.0582\n",
      "Epoch 1513/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1978 - f1: 0.8214 - val_loss: 0.3084 - val_f1: 0.0581\n",
      "Epoch 1514/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1961 - f1: 0.8231 - val_loss: 0.3021 - val_f1: 0.0582\n",
      "Epoch 1515/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1966 - f1: 0.8220 - val_loss: 0.3017 - val_f1: 0.0576\n",
      "Epoch 1516/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1967 - f1: 0.8216 - val_loss: 0.3046 - val_f1: 0.0577\n",
      "Epoch 1517/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.1962 - f1: 0.8234 - val_loss: 0.3065 - val_f1: 0.0573\n",
      "Epoch 1518/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1970 - f1: 0.8224 - val_loss: 0.3018 - val_f1: 0.0583\n",
      "Epoch 1519/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1964 - f1: 0.8221 - val_loss: 0.3039 - val_f1: 0.0579\n",
      "Epoch 1520/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1968 - f1: 0.8204 - val_loss: 0.3016 - val_f1: 0.0587\n",
      "Epoch 1521/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1982 - f1: 0.8208 - val_loss: 0.3023 - val_f1: 0.0575\n",
      "Epoch 1522/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.1973 - f1: 0.8220 - val_loss: 0.3022 - val_f1: 0.0585\n",
      "Epoch 1523/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1959 - f1: 0.8230 - val_loss: 0.3036 - val_f1: 0.0586\n",
      "Epoch 1524/2000\n",
      "168135/168135 [==============================] - 14s 82us/step - loss: 0.1964 - f1: 0.8222 - val_loss: 0.3037 - val_f1: 0.0582\n",
      "Epoch 1525/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1969 - f1: 0.8211 - val_loss: 0.3049 - val_f1: 0.0577\n",
      "Epoch 1526/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1967 - f1: 0.8240 - val_loss: 0.3037 - val_f1: 0.0576\n",
      "Epoch 1527/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1959 - f1: 0.8223 - val_loss: 0.3010 - val_f1: 0.0577\n",
      "Epoch 1528/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1952 - f1: 0.8242 - val_loss: 0.3057 - val_f1: 0.0582\n",
      "Epoch 1529/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1985 - f1: 0.8190 - val_loss: 0.3053 - val_f1: 0.0578\n",
      "Epoch 1530/2000\n",
      "168135/168135 [==============================] - 15s 89us/step - loss: 0.1960 - f1: 0.8235 - val_loss: 0.3044 - val_f1: 0.0572\n",
      "Epoch 1531/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1942 - f1: 0.8226 - val_loss: 0.3034 - val_f1: 0.0575\n",
      "Epoch 1532/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1959 - f1: 0.8208 - val_loss: 0.3007 - val_f1: 0.0589\n",
      "Epoch 1533/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1972 - f1: 0.8226 - val_loss: 0.3019 - val_f1: 0.0572\n",
      "Epoch 1534/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1941 - f1: 0.8261 - val_loss: 0.3068 - val_f1: 0.0581\n",
      "Epoch 1535/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1975 - f1: 0.8206 - val_loss: 0.3017 - val_f1: 0.0582\n",
      "Epoch 1536/2000\n",
      "168135/168135 [==============================] - 15s 91us/step - loss: 0.1959 - f1: 0.8229 - val_loss: 0.3019 - val_f1: 0.0588\n",
      "Epoch 1537/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1957 - f1: 0.8234 - val_loss: 0.3028 - val_f1: 0.0585\n",
      "Epoch 1538/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.1975 - f1: 0.8205 - val_loss: 0.3017 - val_f1: 0.0577\n",
      "Epoch 1539/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.1969 - f1: 0.8222 - val_loss: 0.3025 - val_f1: 0.0582\n",
      "Epoch 1540/2000\n",
      "168135/168135 [==============================] - 15s 89us/step - loss: 0.1955 - f1: 0.8224 - val_loss: 0.3042 - val_f1: 0.0577\n",
      "Epoch 1541/2000\n",
      "168135/168135 [==============================] - 15s 91us/step - loss: 0.1961 - f1: 0.8239 - val_loss: 0.3036 - val_f1: 0.0573\n",
      "Epoch 1542/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.1966 - f1: 0.8213 - val_loss: 0.3042 - val_f1: 0.0582\n",
      "Epoch 1543/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1963 - f1: 0.8214 - val_loss: 0.3044 - val_f1: 0.0579\n",
      "Epoch 1544/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1977 - f1: 0.8201 - val_loss: 0.3042 - val_f1: 0.0588\n",
      "Epoch 1545/2000\n",
      "168135/168135 [==============================] - 17s 101us/step - loss: 0.1962 - f1: 0.8230 - val_loss: 0.3036 - val_f1: 0.0577\n",
      "Epoch 1546/2000\n",
      "168135/168135 [==============================] - 15s 88us/step - loss: 0.1970 - f1: 0.8223 - val_loss: 0.3037 - val_f1: 0.0585\n",
      "Epoch 1547/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1966 - f1: 0.8221 - val_loss: 0.3039 - val_f1: 0.0584\n",
      "Epoch 1548/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1973 - f1: 0.8208 - val_loss: 0.3034 - val_f1: 0.0582\n",
      "Epoch 1549/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1959 - f1: 0.8233 - val_loss: 0.3072 - val_f1: 0.0587\n",
      "Epoch 1550/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1959 - f1: 0.8232 - val_loss: 0.3039 - val_f1: 0.0585\n",
      "Epoch 1551/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1973 - f1: 0.8215 - val_loss: 0.3046 - val_f1: 0.0583\n",
      "Epoch 1552/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1942 - f1: 0.8232 - val_loss: 0.3053 - val_f1: 0.0578\n",
      "Epoch 1553/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1953 - f1: 0.8218 - val_loss: 0.3082 - val_f1: 0.0588\n",
      "Epoch 1554/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1960 - f1: 0.8239 - val_loss: 0.3026 - val_f1: 0.0580\n",
      "Epoch 1555/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1937 - f1: 0.8230 - val_loss: 0.3045 - val_f1: 0.0590\n",
      "Epoch 1556/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1964 - f1: 0.8236 - val_loss: 0.3038 - val_f1: 0.0585\n",
      "Epoch 1557/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1958 - f1: 0.8246 - val_loss: 0.3046 - val_f1: 0.0573\n",
      "Epoch 1558/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1947 - f1: 0.8213 - val_loss: 0.3038 - val_f1: 0.0587\n",
      "Epoch 1559/2000\n",
      "168135/168135 [==============================] - 14s 83us/step - loss: 0.1947 - f1: 0.8243 - val_loss: 0.3036 - val_f1: 0.0582\n",
      "Epoch 1560/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1961 - f1: 0.8229 - val_loss: 0.3038 - val_f1: 0.0587\n",
      "Epoch 1561/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1954 - f1: 0.8229 - val_loss: 0.3029 - val_f1: 0.0581\n",
      "Epoch 1562/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1973 - f1: 0.8212 - val_loss: 0.3056 - val_f1: 0.0585\n",
      "Epoch 1563/2000\n",
      "168135/168135 [==============================] - 15s 86us/step - loss: 0.1953 - f1: 0.8254 - val_loss: 0.3047 - val_f1: 0.0578\n",
      "Epoch 1564/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1965 - f1: 0.8226 - val_loss: 0.3034 - val_f1: 0.0582\n",
      "Epoch 1565/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1961 - f1: 0.8214 - val_loss: 0.3065 - val_f1: 0.0578\n",
      "Epoch 1566/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1967 - f1: 0.8229 - val_loss: 0.3030 - val_f1: 0.0585\n",
      "Epoch 1567/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1962 - f1: 0.8236 - val_loss: 0.3089 - val_f1: 0.0581\n",
      "Epoch 1568/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1948 - f1: 0.8242 - val_loss: 0.3060 - val_f1: 0.0581\n",
      "Epoch 1569/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1969 - f1: 0.8215 - val_loss: 0.3010 - val_f1: 0.0579\n",
      "Epoch 1570/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1971 - f1: 0.8221 - val_loss: 0.3035 - val_f1: 0.0585\n",
      "Epoch 1571/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1938 - f1: 0.8242 - val_loss: 0.3036 - val_f1: 0.0580\n",
      "Epoch 1572/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1954 - f1: 0.8233 - val_loss: 0.3039 - val_f1: 0.0585\n",
      "Epoch 1573/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1957 - f1: 0.8219 - val_loss: 0.3047 - val_f1: 0.0583\n",
      "Epoch 1574/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1955 - f1: 0.8247 - val_loss: 0.3033 - val_f1: 0.0576\n",
      "Epoch 1575/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1953 - f1: 0.8236 - val_loss: 0.3032 - val_f1: 0.0583\n",
      "Epoch 1576/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1949 - f1: 0.8241 - val_loss: 0.3064 - val_f1: 0.0577\n",
      "Epoch 1577/2000\n",
      "168135/168135 [==============================] - 14s 84us/step - loss: 0.1962 - f1: 0.8225 - val_loss: 0.3035 - val_f1: 0.0573\n",
      "Epoch 1578/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1951 - f1: 0.8225 - val_loss: 0.3025 - val_f1: 0.0578\n",
      "Epoch 1579/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1960 - f1: 0.8233 - val_loss: 0.3035 - val_f1: 0.0586\n",
      "Epoch 1580/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.1952 - f1: 0.8226 - val_loss: 0.3009 - val_f1: 0.0580\n",
      "Epoch 1581/2000\n",
      "168135/168135 [==============================] - 14s 86us/step - loss: 0.1985 - f1: 0.8201 - val_loss: 0.3053 - val_f1: 0.0583\n",
      "Epoch 1582/2000\n",
      "168135/168135 [==============================] - 14s 85us/step - loss: 0.1940 - f1: 0.8249 - val_loss: 0.3064 - val_f1: 0.0578\n",
      "Epoch 1583/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1964 - f1: 0.8221 - val_loss: 0.3050 - val_f1: 0.0579\n",
      "Epoch 1592/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1949 - f1: 0.8240 - val_loss: 0.3037 - val_f1: 0.0582\n",
      "Epoch 1593/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1944 - f1: 0.8239 - val_loss: 0.3064 - val_f1: 0.0576\n",
      "Epoch 1594/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1976 - f1: 0.8212 - val_loss: 0.3049 - val_f1: 0.0582\n",
      "Epoch 1595/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1944 - f1: 0.8234 - val_loss: 0.3036 - val_f1: 0.0586\n",
      "Epoch 1596/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1956 - f1: 0.8233 - val_loss: 0.3025 - val_f1: 0.0589\n",
      "Epoch 1597/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1946 - f1: 0.8245 - val_loss: 0.3022 - val_f1: 0.0574\n",
      "Epoch 1598/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1963 - f1: 0.8234 - val_loss: 0.3055 - val_f1: 0.0582\n",
      "Epoch 1599/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1956 - f1: 0.8228 - val_loss: 0.3059 - val_f1: 0.0576\n",
      "Epoch 1600/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.1961 - f1: 0.8218 - val_loss: 0.3055 - val_f1: 0.0589\n",
      "Epoch 1601/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1953 - f1: 0.8230 - val_loss: 0.3087 - val_f1: 0.0577\n",
      "Epoch 1602/2000\n",
      "139104/168135 [=======================>......] - ETA: 2s - loss: 0.1957 - f1: 0.8223"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1959 - f1: 0.8234 - val_loss: 0.3053 - val_f1: 0.0580\n",
      "Epoch 1610/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1955 - f1: 0.8235 - val_loss: 0.3025 - val_f1: 0.0574\n",
      "Epoch 1611/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1957 - f1: 0.8232 - val_loss: 0.3090 - val_f1: 0.0579\n",
      "Epoch 1612/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1949 - f1: 0.8243 - val_loss: 0.3053 - val_f1: 0.0584\n",
      "Epoch 1613/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1943 - f1: 0.8255 - val_loss: 0.3029 - val_f1: 0.0587\n",
      "Epoch 1614/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1942 - f1: 0.8237 - val_loss: 0.3029 - val_f1: 0.0583\n",
      "Epoch 1615/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1951 - f1: 0.8255 - val_loss: 0.3057 - val_f1: 0.0584\n",
      "Epoch 1616/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1963 - f1: 0.8227 - val_loss: 0.3045 - val_f1: 0.0577\n",
      "Epoch 1617/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1949 - f1: 0.8245 - val_loss: 0.3046 - val_f1: 0.0575\n",
      "Epoch 1618/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1964 - f1: 0.8224 - val_loss: 0.3065 - val_f1: 0.0586\n",
      "Epoch 1619/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1950 - f1: 0.8243 - val_loss: 0.3039 - val_f1: 0.0580\n",
      "Epoch 1620/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1944 - f1: 0.8235 - val_loss: 0.3054 - val_f1: 0.0576\n",
      "Epoch 1621/2000\n",
      " 76480/168135 [============>.................] - ETA: 6s - loss: 0.1937 - f1: 0.8225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1945 - f1: 0.8261 - val_loss: 0.3043 - val_f1: 0.0577\n",
      "Epoch 1631/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1950 - f1: 0.8234 - val_loss: 0.3055 - val_f1: 0.0582\n",
      "Epoch 1632/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1941 - f1: 0.8251 - val_loss: 0.3075 - val_f1: 0.0578\n",
      "Epoch 1633/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1937 - f1: 0.8259 - val_loss: 0.3076 - val_f1: 0.0584\n",
      "Epoch 1634/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1947 - f1: 0.8264 - val_loss: 0.3016 - val_f1: 0.0582\n",
      "Epoch 1635/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1934 - f1: 0.8265 - val_loss: 0.3059 - val_f1: 0.0577\n",
      "Epoch 1636/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1937 - f1: 0.8243 - val_loss: 0.3044 - val_f1: 0.0579\n",
      "Epoch 1637/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1944 - f1: 0.8235 - val_loss: 0.3069 - val_f1: 0.0590\n",
      "Epoch 1638/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1936 - f1: 0.8260 - val_loss: 0.3060 - val_f1: 0.0586\n",
      "Epoch 1639/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1928 - f1: 0.8261 - val_loss: 0.3085 - val_f1: 0.0579\n",
      "Epoch 1640/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1954 - f1: 0.8243 - val_loss: 0.3022 - val_f1: 0.0587\n",
      "Epoch 1641/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1949 - f1: 0.8251 - val_loss: 0.3047 - val_f1: 0.0590\n",
      "Epoch 1642/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1940 - f1: 0.8254 - val_loss: 0.3075 - val_f1: 0.0581\n",
      "Epoch 1643/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1935 - f1: 0.8252 - val_loss: 0.3101 - val_f1: 0.0585\n",
      "Epoch 1644/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1938 - f1: 0.8244 - val_loss: 0.3088 - val_f1: 0.0582\n",
      "Epoch 1645/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1939 - f1: 0.8250 - val_loss: 0.3046 - val_f1: 0.0584\n",
      "Epoch 1646/2000\n",
      "168135/168135 [==============================] - 13s 80us/step - loss: 0.1961 - f1: 0.8234 - val_loss: 0.3044 - val_f1: 0.0585\n",
      "Epoch 1647/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1945 - f1: 0.8242 - val_loss: 0.3040 - val_f1: 0.0581\n",
      "Epoch 1648/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1954 - f1: 0.8240 - val_loss: 0.3062 - val_f1: 0.0580\n",
      "Epoch 1649/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1935 - f1: 0.8263 - val_loss: 0.3060 - val_f1: 0.0575\n",
      "Epoch 1650/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1943 - f1: 0.8253 - val_loss: 0.3050 - val_f1: 0.0585\n",
      "Epoch 1651/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1960 - f1: 0.8236 - val_loss: 0.3060 - val_f1: 0.0585\n",
      "Epoch 1652/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1950 - f1: 0.8246 - val_loss: 0.3061 - val_f1: 0.0580\n",
      "Epoch 1653/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1944 - f1: 0.8239 - val_loss: 0.3051 - val_f1: 0.0582\n",
      "Epoch 1654/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1966 - f1: 0.8219 - val_loss: 0.3069 - val_f1: 0.0580\n",
      "Epoch 1655/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1946 - f1: 0.8241 - val_loss: 0.3050 - val_f1: 0.0579\n",
      "Epoch 1656/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1946 - f1: 0.8224 - val_loss: 0.3049 - val_f1: 0.0583\n",
      "Epoch 1657/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1962 - f1: 0.8251 - val_loss: 0.3041 - val_f1: 0.0579\n",
      "Epoch 1658/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1947 - f1: 0.8243 - val_loss: 0.3047 - val_f1: 0.0589\n",
      "Epoch 1659/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1936 - f1: 0.8237 - val_loss: 0.3065 - val_f1: 0.0580\n",
      "Epoch 1660/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1952 - f1: 0.8244 - val_loss: 0.3010 - val_f1: 0.0579\n",
      "Epoch 1661/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1944 - f1: 0.8249 - val_loss: 0.3075 - val_f1: 0.0576\n",
      "Epoch 1662/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1953 - f1: 0.8234 - val_loss: 0.3057 - val_f1: 0.0580\n",
      "Epoch 1663/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1944 - f1: 0.8239 - val_loss: 0.3030 - val_f1: 0.0581\n",
      "Epoch 1664/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1947 - f1: 0.8245 - val_loss: 0.3047 - val_f1: 0.0580\n",
      "Epoch 1665/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1955 - f1: 0.8237 - val_loss: 0.3035 - val_f1: 0.0585\n",
      "Epoch 1666/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1941 - f1: 0.8258 - val_loss: 0.3060 - val_f1: 0.0586\n",
      "Epoch 1667/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1927 - f1: 0.8253 - val_loss: 0.3068 - val_f1: 0.0573\n",
      "Epoch 1668/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1945 - f1: 0.8249 - val_loss: 0.3076 - val_f1: 0.0573\n",
      "Epoch 1669/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1927 - f1: 0.8263 - val_loss: 0.3057 - val_f1: 0.0576\n",
      "Epoch 1670/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1948 - f1: 0.8243 - val_loss: 0.3060 - val_f1: 0.0584\n",
      "Epoch 1671/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1949 - f1: 0.8236 - val_loss: 0.3070 - val_f1: 0.0575\n",
      "Epoch 1672/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1947 - f1: 0.8255 - val_loss: 0.3028 - val_f1: 0.0584\n",
      "Epoch 1673/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1933 - f1: 0.8252 - val_loss: 0.3072 - val_f1: 0.0580\n",
      "Epoch 1674/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1951 - f1: 0.8247 - val_loss: 0.3025 - val_f1: 0.0578\n",
      "Epoch 1675/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1948 - f1: 0.8238 - val_loss: 0.3026 - val_f1: 0.0583\n",
      "Epoch 1676/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1947 - f1: 0.8240 - val_loss: 0.3028 - val_f1: 0.0578\n",
      "Epoch 1677/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1959 - f1: 0.8241 - val_loss: 0.3050 - val_f1: 0.0577\n",
      "Epoch 1678/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1939 - f1: 0.8251 - val_loss: 0.3075 - val_f1: 0.0587\n",
      "Epoch 1679/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1928 - f1: 0.8255 - val_loss: 0.3059 - val_f1: 0.0590\n",
      "Epoch 1680/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1955 - f1: 0.8238 - val_loss: 0.3050 - val_f1: 0.0582\n",
      "Epoch 1681/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1935 - f1: 0.8251 - val_loss: 0.3096 - val_f1: 0.0571\n",
      "Epoch 1682/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1944 - f1: 0.8259 - val_loss: 0.3057 - val_f1: 0.0587\n",
      "Epoch 1683/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1947 - f1: 0.8247 - val_loss: 0.3051 - val_f1: 0.0586\n",
      "Epoch 1684/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1942 - f1: 0.8243 - val_loss: 0.3090 - val_f1: 0.0578\n",
      "Epoch 1685/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1935 - f1: 0.8254 - val_loss: 0.3083 - val_f1: 0.0574\n",
      "Epoch 1686/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1938 - f1: 0.8246 - val_loss: 0.3084 - val_f1: 0.0586\n",
      "Epoch 1687/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165024/168135 [============================>.] - ETA: 0s - loss: 0.1940 - f1: 0.8262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1938 - f1: 0.8259 - val_loss: 0.3020 - val_f1: 0.0579\n",
      "Epoch 1691/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1934 - f1: 0.8260 - val_loss: 0.3033 - val_f1: 0.0578\n",
      "Epoch 1692/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1955 - f1: 0.8233 - val_loss: 0.3036 - val_f1: 0.0580\n",
      "Epoch 1693/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1940 - f1: 0.8243 - val_loss: 0.3075 - val_f1: 0.0586\n",
      "Epoch 1694/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1945 - f1: 0.8257 - val_loss: 0.3076 - val_f1: 0.0586\n",
      "Epoch 1695/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1959 - f1: 0.8249 - val_loss: 0.3014 - val_f1: 0.0577\n",
      "Epoch 1696/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1944 - f1: 0.8229 - val_loss: 0.3063 - val_f1: 0.0578\n",
      "Epoch 1697/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1936 - f1: 0.8242 - val_loss: 0.3061 - val_f1: 0.0588\n",
      "Epoch 1698/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1951 - f1: 0.8243 - val_loss: 0.3056 - val_f1: 0.0580\n",
      "Epoch 1699/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1939 - f1: 0.8236 - val_loss: 0.3063 - val_f1: 0.0580\n",
      "Epoch 1700/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1930 - f1: 0.8264 - val_loss: 0.3065 - val_f1: 0.0586\n",
      "Epoch 1701/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1926 - f1: 0.8267 - val_loss: 0.3071 - val_f1: 0.0575\n",
      "Epoch 1702/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1932 - f1: 0.8257 - val_loss: 0.3066 - val_f1: 0.0587\n",
      "Epoch 1703/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1939 - f1: 0.8239 - val_loss: 0.3110 - val_f1: 0.0586\n",
      "Epoch 1704/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1946 - f1: 0.8249 - val_loss: 0.3061 - val_f1: 0.0586\n",
      "Epoch 1705/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1949 - f1: 0.8230 - val_loss: 0.3069 - val_f1: 0.0586\n",
      "Epoch 1706/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1943 - f1: 0.8248 - val_loss: 0.3074 - val_f1: 0.0575\n",
      "Epoch 1707/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1941 - f1: 0.8249 - val_loss: 0.3107 - val_f1: 0.0585\n",
      "Epoch 1708/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1944 - f1: 0.8229 - val_loss: 0.3051 - val_f1: 0.0579\n",
      "Epoch 1709/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1936 - f1: 0.8242 - val_loss: 0.3067 - val_f1: 0.0589\n",
      "Epoch 1710/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1938 - f1: 0.8261 - val_loss: 0.3022 - val_f1: 0.0590\n",
      "Epoch 1711/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1948 - f1: 0.8234 - val_loss: 0.3030 - val_f1: 0.0584\n",
      "Epoch 1712/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1924 - f1: 0.8268 - val_loss: 0.3039 - val_f1: 0.0580\n",
      "Epoch 1713/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1947 - f1: 0.8221 - val_loss: 0.3061 - val_f1: 0.0593\n",
      "Epoch 1714/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1934 - f1: 0.8263 - val_loss: 0.3082 - val_f1: 0.0586\n",
      "Epoch 1715/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1930 - f1: 0.8253 - val_loss: 0.3047 - val_f1: 0.0586\n",
      "Epoch 1716/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1931 - f1: 0.8255 - val_loss: 0.3072 - val_f1: 0.0585\n",
      "Epoch 1717/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1935 - f1: 0.8268 - val_loss: 0.3072 - val_f1: 0.0586\n",
      "Epoch 1718/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1928 - f1: 0.8245 - val_loss: 0.3075 - val_f1: 0.0583\n",
      "Epoch 1719/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1939 - f1: 0.8244 - val_loss: 0.3041 - val_f1: 0.0586\n",
      "Epoch 1720/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1937 - f1: 0.8262 - val_loss: 0.3059 - val_f1: 0.0579\n",
      "Epoch 1721/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1936 - f1: 0.8266 - val_loss: 0.3044 - val_f1: 0.0583\n",
      "Epoch 1722/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1950 - f1: 0.8242 - val_loss: 0.3093 - val_f1: 0.0584\n",
      "Epoch 1723/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1934 - f1: 0.8283 - val_loss: 0.3058 - val_f1: 0.0581\n",
      "Epoch 1724/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1939 - f1: 0.8262 - val_loss: 0.3072 - val_f1: 0.0582\n",
      "Epoch 1725/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1952 - f1: 0.8239 - val_loss: 0.3070 - val_f1: 0.0582\n",
      "Epoch 1726/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1925 - f1: 0.8274 - val_loss: 0.3089 - val_f1: 0.0586\n",
      "Epoch 1727/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1925 - f1: 0.8279 - val_loss: 0.3057 - val_f1: 0.0588\n",
      "Epoch 1728/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1926 - f1: 0.8270 - val_loss: 0.3064 - val_f1: 0.0581\n",
      "Epoch 1729/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1939 - f1: 0.8246 - val_loss: 0.3069 - val_f1: 0.0587\n",
      "Epoch 1730/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1942 - f1: 0.8253 - val_loss: 0.3058 - val_f1: 0.0582\n",
      "Epoch 1731/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1955 - f1: 0.8232 - val_loss: 0.3027 - val_f1: 0.0588\n",
      "Epoch 1732/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1943 - f1: 0.8245 - val_loss: 0.3066 - val_f1: 0.0586\n",
      "Epoch 1733/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1942 - f1: 0.8260 - val_loss: 0.3066 - val_f1: 0.0578\n",
      "Epoch 1734/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1929 - f1: 0.8247 - val_loss: 0.3123 - val_f1: 0.0580\n",
      "Epoch 1735/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1936 - f1: 0.8252 - val_loss: 0.3050 - val_f1: 0.0588\n",
      "Epoch 1736/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1940 - f1: 0.8241 - val_loss: 0.3063 - val_f1: 0.0583\n",
      "Epoch 1737/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1942 - f1: 0.8250 - val_loss: 0.3058 - val_f1: 0.0586\n",
      "Epoch 1738/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1941 - f1: 0.8241 - val_loss: 0.3063 - val_f1: 0.0583\n",
      "Epoch 1739/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.1918 - f1: 0.8279 - val_loss: 0.3052 - val_f1: 0.0574\n",
      "Epoch 1740/2000\n",
      " 99776/168135 [================>.............] - ETA: 4s - loss: 0.1924 - f1: 0.8245"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1926 - f1: 0.8277 - val_loss: 0.3031 - val_f1: 0.0584\n",
      "Epoch 1745/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1940 - f1: 0.8251 - val_loss: 0.3027 - val_f1: 0.0578\n",
      "Epoch 1746/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1941 - f1: 0.8256 - val_loss: 0.3065 - val_f1: 0.0568\n",
      "Epoch 1747/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1937 - f1: 0.8262 - val_loss: 0.3062 - val_f1: 0.0582\n",
      "Epoch 1748/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1926 - f1: 0.8267 - val_loss: 0.3039 - val_f1: 0.0584\n",
      "Epoch 1749/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1943 - f1: 0.8256 - val_loss: 0.3044 - val_f1: 0.0589\n",
      "Epoch 1750/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1921 - f1: 0.8274 - val_loss: 0.3058 - val_f1: 0.0582\n",
      "Epoch 1751/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1918 - f1: 0.8279 - val_loss: 0.3119 - val_f1: 0.0583\n",
      "Epoch 1752/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1937 - f1: 0.8258 - val_loss: 0.3035 - val_f1: 0.0577\n",
      "Epoch 1753/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1933 - f1: 0.8261 - val_loss: 0.3059 - val_f1: 0.0587\n",
      "Epoch 1754/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1930 - f1: 0.8263 - val_loss: 0.3085 - val_f1: 0.0577\n",
      "Epoch 1755/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1940 - f1: 0.8261 - val_loss: 0.3060 - val_f1: 0.0576\n",
      "Epoch 1756/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1934 - f1: 0.8246 - val_loss: 0.3080 - val_f1: 0.0580\n",
      "Epoch 1757/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1922 - f1: 0.8278 - val_loss: 0.3063 - val_f1: 0.0574\n",
      "Epoch 1758/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1932 - f1: 0.8282 - val_loss: 0.3096 - val_f1: 0.0575\n",
      "Epoch 1759/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1940 - f1: 0.8250 - val_loss: 0.3070 - val_f1: 0.0579\n",
      "Epoch 1760/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1932 - f1: 0.8257 - val_loss: 0.3074 - val_f1: 0.0586\n",
      "Epoch 1761/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1924 - f1: 0.8255 - val_loss: 0.3088 - val_f1: 0.0578\n",
      "Epoch 1762/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1930 - f1: 0.8251 - val_loss: 0.3088 - val_f1: 0.0576\n",
      "Epoch 1763/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1953 - f1: 0.8234 - val_loss: 0.3014 - val_f1: 0.0581\n",
      "Epoch 1764/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1929 - f1: 0.8250 - val_loss: 0.3031 - val_f1: 0.0581\n",
      "Epoch 1765/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1932 - f1: 0.8260 - val_loss: 0.3061 - val_f1: 0.0580\n",
      "Epoch 1766/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1922 - f1: 0.8264 - val_loss: 0.3102 - val_f1: 0.0588\n",
      "Epoch 1767/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1934 - f1: 0.8261 - val_loss: 0.3082 - val_f1: 0.0579\n",
      "Epoch 1768/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1931 - f1: 0.8245 - val_loss: 0.3055 - val_f1: 0.0582\n",
      "Epoch 1769/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1941 - f1: 0.8269 - val_loss: 0.3049 - val_f1: 0.0576\n",
      "Epoch 1770/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1929 - f1: 0.8272 - val_loss: 0.3060 - val_f1: 0.0579\n",
      "Epoch 1771/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1924 - f1: 0.8254 - val_loss: 0.3059 - val_f1: 0.0583\n",
      "Epoch 1772/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1929 - f1: 0.8271 - val_loss: 0.3039 - val_f1: 0.0578\n",
      "Epoch 1773/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1911 - f1: 0.8291 - val_loss: 0.3066 - val_f1: 0.0577\n",
      "Epoch 1774/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1933 - f1: 0.8262 - val_loss: 0.3039 - val_f1: 0.0583\n",
      "Epoch 1775/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1927 - f1: 0.8263 - val_loss: 0.3069 - val_f1: 0.0585\n",
      "Epoch 1776/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1931 - f1: 0.8263 - val_loss: 0.3086 - val_f1: 0.0579\n",
      "Epoch 1777/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1920 - f1: 0.8271 - val_loss: 0.3049 - val_f1: 0.0579\n",
      "Epoch 1778/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1931 - f1: 0.8258 - val_loss: 0.3084 - val_f1: 0.0582\n",
      "Epoch 1779/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1932 - f1: 0.8272 - val_loss: 0.3067 - val_f1: 0.0579\n",
      "Epoch 1780/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1916 - f1: 0.8275 - val_loss: 0.3097 - val_f1: 0.0575\n",
      "Epoch 1781/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1923 - f1: 0.8286 - val_loss: 0.3050 - val_f1: 0.0585\n",
      "Epoch 1782/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1908 - f1: 0.8282 - val_loss: 0.3084 - val_f1: 0.0576\n",
      "Epoch 1783/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1945 - f1: 0.8266 - val_loss: 0.3057 - val_f1: 0.0581\n",
      "Epoch 1784/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1934 - f1: 0.8256 - val_loss: 0.3080 - val_f1: 0.0583\n",
      "Epoch 1785/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1912 - f1: 0.8287 - val_loss: 0.3052 - val_f1: 0.0579\n",
      "Epoch 1786/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1949 - f1: 0.8241 - val_loss: 0.3050 - val_f1: 0.0577\n",
      "Epoch 1787/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1927 - f1: 0.8282 - val_loss: 0.3067 - val_f1: 0.0581\n",
      "Epoch 1788/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1928 - f1: 0.8267 - val_loss: 0.3066 - val_f1: 0.0584\n",
      "Epoch 1789/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1910 - f1: 0.8291 - val_loss: 0.3069 - val_f1: 0.0580\n",
      "Epoch 1790/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1929 - f1: 0.8271 - val_loss: 0.3084 - val_f1: 0.0581\n",
      "Epoch 1791/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1913 - f1: 0.8277 - val_loss: 0.3050 - val_f1: 0.0592\n",
      "Epoch 1792/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1919 - f1: 0.8271 - val_loss: 0.3085 - val_f1: 0.0586\n",
      "Epoch 1793/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1917 - f1: 0.8284 - val_loss: 0.3094 - val_f1: 0.0582\n",
      "Epoch 1794/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1924 - f1: 0.8270 - val_loss: 0.3069 - val_f1: 0.0572\n",
      "Epoch 1795/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1926 - f1: 0.8264 - val_loss: 0.3056 - val_f1: 0.0575\n",
      "Epoch 1796/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1922 - f1: 0.8257 - val_loss: 0.3064 - val_f1: 0.0578\n",
      "Epoch 1797/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1912 - f1: 0.8281 - val_loss: 0.3077 - val_f1: 0.0588\n",
      "Epoch 1798/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1943 - f1: 0.8243 - val_loss: 0.3041 - val_f1: 0.0579\n",
      "Epoch 1799/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1917 - f1: 0.8278 - val_loss: 0.3069 - val_f1: 0.0576\n",
      "Epoch 1800/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1928 - f1: 0.8252 - val_loss: 0.3030 - val_f1: 0.0581\n",
      "Epoch 1801/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1931 - f1: 0.8259 - val_loss: 0.3015 - val_f1: 0.0582\n",
      "Epoch 1802/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1932 - f1: 0.8262 - val_loss: 0.3068 - val_f1: 0.0586\n",
      "Epoch 1803/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1917 - f1: 0.8269 - val_loss: 0.3082 - val_f1: 0.0586\n",
      "Epoch 1804/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1927 - f1: 0.8266 - val_loss: 0.3050 - val_f1: 0.0579\n",
      "Epoch 1805/2000\n",
      "116896/168135 [===================>..........] - ETA: 3s - loss: 0.1912 - f1: 0.8285"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1915 - f1: 0.8285 - val_loss: 0.3051 - val_f1: 0.0580\n",
      "Epoch 1813/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1930 - f1: 0.8277 - val_loss: 0.3050 - val_f1: 0.0594\n",
      "Epoch 1814/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1920 - f1: 0.8293 - val_loss: 0.3055 - val_f1: 0.0576\n",
      "Epoch 1815/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1939 - f1: 0.8249 - val_loss: 0.3061 - val_f1: 0.0585\n",
      "Epoch 1816/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1946 - f1: 0.8237 - val_loss: 0.3035 - val_f1: 0.0580\n",
      "Epoch 1817/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1927 - f1: 0.8270 - val_loss: 0.3033 - val_f1: 0.0587\n",
      "Epoch 1818/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1921 - f1: 0.8286 - val_loss: 0.3109 - val_f1: 0.0573\n",
      "Epoch 1819/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1920 - f1: 0.8257 - val_loss: 0.3111 - val_f1: 0.0576\n",
      "Epoch 1820/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1926 - f1: 0.8261 - val_loss: 0.3087 - val_f1: 0.0584\n",
      "Epoch 1821/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1915 - f1: 0.8265 - val_loss: 0.3082 - val_f1: 0.0579\n",
      "Epoch 1822/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1924 - f1: 0.8282 - val_loss: 0.3067 - val_f1: 0.0584\n",
      "Epoch 1823/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1921 - f1: 0.8273 - val_loss: 0.3063 - val_f1: 0.0579\n",
      "Epoch 1824/2000\n",
      " 78880/168135 [=============>................] - ETA: 6s - loss: 0.1915 - f1: 0.8274"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1931 - f1: 0.8267 - val_loss: 0.3059 - val_f1: 0.0576\n",
      "Epoch 1835/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1938 - f1: 0.8261 - val_loss: 0.3060 - val_f1: 0.0575\n",
      "Epoch 1836/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1927 - f1: 0.8267 - val_loss: 0.3049 - val_f1: 0.0572\n",
      "Epoch 1837/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1938 - f1: 0.8247 - val_loss: 0.3053 - val_f1: 0.0575\n",
      "Epoch 1838/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1924 - f1: 0.8266 - val_loss: 0.3048 - val_f1: 0.0580\n",
      "Epoch 1839/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1932 - f1: 0.8239 - val_loss: 0.3068 - val_f1: 0.0577\n",
      "Epoch 1840/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1916 - f1: 0.8270 - val_loss: 0.3040 - val_f1: 0.0579\n",
      "Epoch 1841/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1919 - f1: 0.8279 - val_loss: 0.3109 - val_f1: 0.0579\n",
      "Epoch 1842/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1928 - f1: 0.8278 - val_loss: 0.3078 - val_f1: 0.0585\n",
      "Epoch 1843/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1932 - f1: 0.8246 - val_loss: 0.3051 - val_f1: 0.0576\n",
      "Epoch 1844/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1923 - f1: 0.8268 - val_loss: 0.3090 - val_f1: 0.0581\n",
      "Epoch 1845/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1910 - f1: 0.8297 - val_loss: 0.3067 - val_f1: 0.0579\n",
      "Epoch 1846/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1929 - f1: 0.8257 - val_loss: 0.3057 - val_f1: 0.0584\n",
      "Epoch 1847/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1920 - f1: 0.8272 - val_loss: 0.3079 - val_f1: 0.0579\n",
      "Epoch 1848/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1925 - f1: 0.8272 - val_loss: 0.3077 - val_f1: 0.0576\n",
      "Epoch 1849/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1906 - f1: 0.8275 - val_loss: 0.3059 - val_f1: 0.0581\n",
      "Epoch 1850/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1924 - f1: 0.8257 - val_loss: 0.3072 - val_f1: 0.0581\n",
      "Epoch 1851/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1923 - f1: 0.8283 - val_loss: 0.3068 - val_f1: 0.0577\n",
      "Epoch 1852/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1922 - f1: 0.8261 - val_loss: 0.3086 - val_f1: 0.0579\n",
      "Epoch 1853/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1921 - f1: 0.8263 - val_loss: 0.3094 - val_f1: 0.0582\n",
      "Epoch 1854/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1914 - f1: 0.8288 - val_loss: 0.3076 - val_f1: 0.0576\n",
      "Epoch 1855/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1916 - f1: 0.8273 - val_loss: 0.3061 - val_f1: 0.0582\n",
      "Epoch 1856/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1923 - f1: 0.8258 - val_loss: 0.3078 - val_f1: 0.0585\n",
      "Epoch 1857/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1908 - f1: 0.8277 - val_loss: 0.3048 - val_f1: 0.0590\n",
      "Epoch 1858/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1911 - f1: 0.8296 - val_loss: 0.3066 - val_f1: 0.0587\n",
      "Epoch 1859/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1918 - f1: 0.8278 - val_loss: 0.3100 - val_f1: 0.0573\n",
      "Epoch 1860/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1922 - f1: 0.8284 - val_loss: 0.3075 - val_f1: 0.0575\n",
      "Epoch 1861/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1901 - f1: 0.8297 - val_loss: 0.3090 - val_f1: 0.0582\n",
      "Epoch 1862/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1921 - f1: 0.8271 - val_loss: 0.3038 - val_f1: 0.0581\n",
      "Epoch 1863/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1928 - f1: 0.8249 - val_loss: 0.3020 - val_f1: 0.0580\n",
      "Epoch 1864/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1908 - f1: 0.8279 - val_loss: 0.3075 - val_f1: 0.0575\n",
      "Epoch 1865/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1920 - f1: 0.8276 - val_loss: 0.3065 - val_f1: 0.0581\n",
      "Epoch 1866/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1915 - f1: 0.8279 - val_loss: 0.3084 - val_f1: 0.0587\n",
      "Epoch 1867/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1909 - f1: 0.8302 - val_loss: 0.3099 - val_f1: 0.0583\n",
      "Epoch 1868/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1923 - f1: 0.8262 - val_loss: 0.3089 - val_f1: 0.0585\n",
      "Epoch 1869/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1906 - f1: 0.8292 - val_loss: 0.3059 - val_f1: 0.0585\n",
      "Epoch 1870/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1924 - f1: 0.8261 - val_loss: 0.3031 - val_f1: 0.0579\n",
      "Epoch 1871/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1903 - f1: 0.8300 - val_loss: 0.3070 - val_f1: 0.0581\n",
      "Epoch 1872/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1925 - f1: 0.8271 - val_loss: 0.3074 - val_f1: 0.0574\n",
      "Epoch 1873/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1922 - f1: 0.8254 - val_loss: 0.3091 - val_f1: 0.0583\n",
      "Epoch 1874/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1914 - f1: 0.8280 - val_loss: 0.3105 - val_f1: 0.0586\n",
      "Epoch 1875/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1922 - f1: 0.8277 - val_loss: 0.3065 - val_f1: 0.0585\n",
      "Epoch 1876/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1924 - f1: 0.8268 - val_loss: 0.3106 - val_f1: 0.0583\n",
      "Epoch 1877/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1917 - f1: 0.8285 - val_loss: 0.3051 - val_f1: 0.0584\n",
      "Epoch 1878/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1911 - f1: 0.8287 - val_loss: 0.3085 - val_f1: 0.0584\n",
      "Epoch 1879/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1914 - f1: 0.8275 - val_loss: 0.3075 - val_f1: 0.0586\n",
      "Epoch 1880/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1894 - f1: 0.8292 - val_loss: 0.3066 - val_f1: 0.0584\n",
      "Epoch 1881/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1921 - f1: 0.8267 - val_loss: 0.3090 - val_f1: 0.0580\n",
      "Epoch 1882/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1921 - f1: 0.8279 - val_loss: 0.3067 - val_f1: 0.0587\n",
      "Epoch 1883/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1915 - f1: 0.8282 - val_loss: 0.3083 - val_f1: 0.0583\n",
      "Epoch 1884/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1907 - f1: 0.8285 - val_loss: 0.3085 - val_f1: 0.0589\n",
      "Epoch 1885/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1920 - f1: 0.8268 - val_loss: 0.3054 - val_f1: 0.0586\n",
      "Epoch 1886/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1919 - f1: 0.8288 - val_loss: 0.3081 - val_f1: 0.0581\n",
      "Epoch 1887/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1921 - f1: 0.8269 - val_loss: 0.3101 - val_f1: 0.0576\n",
      "Epoch 1888/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1905 - f1: 0.8275 - val_loss: 0.3072 - val_f1: 0.0580\n",
      "Epoch 1889/2000\n",
      " 33088/168135 [====>.........................] - ETA: 9s - loss: 0.1881 - f1: 0.8302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1916 - f1: 0.8267 - val_loss: 0.3074 - val_f1: 0.0581\n",
      "Epoch 1895/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1910 - f1: 0.8274 - val_loss: 0.3057 - val_f1: 0.0578\n",
      "Epoch 1896/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1908 - f1: 0.8284 - val_loss: 0.3085 - val_f1: 0.0574\n",
      "Epoch 1897/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1930 - f1: 0.8252 - val_loss: 0.3028 - val_f1: 0.0583\n",
      "Epoch 1898/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1923 - f1: 0.8271 - val_loss: 0.3025 - val_f1: 0.0584\n",
      "Epoch 1899/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1922 - f1: 0.8257 - val_loss: 0.3056 - val_f1: 0.0584\n",
      "Epoch 1900/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1921 - f1: 0.8260 - val_loss: 0.3046 - val_f1: 0.0586\n",
      "Epoch 1901/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1915 - f1: 0.8297 - val_loss: 0.3073 - val_f1: 0.0582\n",
      "Epoch 1902/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1906 - f1: 0.8291 - val_loss: 0.3099 - val_f1: 0.0577\n",
      "Epoch 1903/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1910 - f1: 0.8306 - val_loss: 0.3080 - val_f1: 0.0579\n",
      "Epoch 1904/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1909 - f1: 0.8306 - val_loss: 0.3061 - val_f1: 0.0568\n",
      "Epoch 1905/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1900 - f1: 0.8285 - val_loss: 0.3082 - val_f1: 0.0578\n",
      "Epoch 1906/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1912 - f1: 0.8274 - val_loss: 0.3063 - val_f1: 0.0579\n",
      "Epoch 1907/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1905 - f1: 0.8297 - val_loss: 0.3089 - val_f1: 0.0585\n",
      "Epoch 1908/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1916 - f1: 0.8278 - val_loss: 0.3087 - val_f1: 0.0576\n",
      "Epoch 1909/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1912 - f1: 0.8270 - val_loss: 0.3063 - val_f1: 0.0579\n",
      "Epoch 1910/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1908 - f1: 0.8280 - val_loss: 0.3088 - val_f1: 0.0582\n",
      "Epoch 1911/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1910 - f1: 0.8297 - val_loss: 0.3056 - val_f1: 0.0586\n",
      "Epoch 1912/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1922 - f1: 0.8270 - val_loss: 0.3067 - val_f1: 0.0573\n",
      "Epoch 1913/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1910 - f1: 0.8278 - val_loss: 0.3061 - val_f1: 0.0582\n",
      "Epoch 1914/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1905 - f1: 0.8298 - val_loss: 0.3071 - val_f1: 0.0577\n",
      "Epoch 1915/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1924 - f1: 0.8253 - val_loss: 0.3057 - val_f1: 0.0580\n",
      "Epoch 1916/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1916 - f1: 0.8281 - val_loss: 0.3053 - val_f1: 0.0576\n",
      "Epoch 1917/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1910 - f1: 0.8281 - val_loss: 0.3083 - val_f1: 0.0584\n",
      "Epoch 1918/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1903 - f1: 0.8294 - val_loss: 0.3073 - val_f1: 0.0579\n",
      "Epoch 1919/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1905 - f1: 0.8283 - val_loss: 0.3053 - val_f1: 0.0587\n",
      "Epoch 1920/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1906 - f1: 0.8273 - val_loss: 0.3076 - val_f1: 0.0584\n",
      "Epoch 1921/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1919 - f1: 0.8274 - val_loss: 0.3059 - val_f1: 0.0583\n",
      "Epoch 1922/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1921 - f1: 0.8284 - val_loss: 0.3061 - val_f1: 0.0585\n",
      "Epoch 1923/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1928 - f1: 0.8271 - val_loss: 0.3058 - val_f1: 0.0587\n",
      "Epoch 1924/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1904 - f1: 0.8306 - val_loss: 0.3091 - val_f1: 0.0583\n",
      "Epoch 1925/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1915 - f1: 0.8260 - val_loss: 0.3049 - val_f1: 0.0584\n",
      "Epoch 1926/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1918 - f1: 0.8275 - val_loss: 0.3097 - val_f1: 0.0573\n",
      "Epoch 1927/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1915 - f1: 0.8278 - val_loss: 0.3060 - val_f1: 0.0580\n",
      "Epoch 1928/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1894 - f1: 0.8296 - val_loss: 0.3073 - val_f1: 0.0577\n",
      "Epoch 1929/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1887 - f1: 0.8306 - val_loss: 0.3101 - val_f1: 0.0585\n",
      "Epoch 1930/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1919 - f1: 0.8276 - val_loss: 0.3053 - val_f1: 0.0578\n",
      "Epoch 1931/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1898 - f1: 0.8297 - val_loss: 0.3111 - val_f1: 0.0582\n",
      "Epoch 1932/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1909 - f1: 0.8300 - val_loss: 0.3074 - val_f1: 0.0572\n",
      "Epoch 1933/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1901 - f1: 0.8284 - val_loss: 0.3119 - val_f1: 0.0576\n",
      "Epoch 1934/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1900 - f1: 0.8284 - val_loss: 0.3051 - val_f1: 0.0581\n",
      "Epoch 1935/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1920 - f1: 0.8282 - val_loss: 0.3074 - val_f1: 0.0584\n",
      "Epoch 1936/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1896 - f1: 0.8293 - val_loss: 0.3056 - val_f1: 0.0574\n",
      "Epoch 1937/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1903 - f1: 0.8270 - val_loss: 0.3096 - val_f1: 0.0574\n",
      "Epoch 1938/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1889 - f1: 0.8304 - val_loss: 0.3054 - val_f1: 0.0588\n",
      "Epoch 1939/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1900 - f1: 0.8276 - val_loss: 0.3077 - val_f1: 0.0581\n",
      "Epoch 1940/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1909 - f1: 0.8293 - val_loss: 0.3121 - val_f1: 0.0575\n",
      "Epoch 1941/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1890 - f1: 0.8300 - val_loss: 0.3103 - val_f1: 0.0577\n",
      "Epoch 1942/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1915 - f1: 0.8277 - val_loss: 0.3048 - val_f1: 0.0568\n",
      "Epoch 1943/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1918 - f1: 0.8248 - val_loss: 0.3063 - val_f1: 0.0576\n",
      "Epoch 1944/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1909 - f1: 0.8275 - val_loss: 0.3071 - val_f1: 0.0585\n",
      "Epoch 1945/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1907 - f1: 0.8292 - val_loss: 0.3072 - val_f1: 0.0585\n",
      "Epoch 1946/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1897 - f1: 0.8324 - val_loss: 0.3078 - val_f1: 0.0576\n",
      "Epoch 1947/2000\n",
      "168135/168135 [==============================] - 14s 81us/step - loss: 0.1913 - f1: 0.8277 - val_loss: 0.3065 - val_f1: 0.0579\n",
      "Epoch 1948/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1904 - f1: 0.8292 - val_loss: 0.3121 - val_f1: 0.0576\n",
      "Epoch 1949/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1907 - f1: 0.8290 - val_loss: 0.3120 - val_f1: 0.0576\n",
      "Epoch 1950/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1914 - f1: 0.8308 - val_loss: 0.3015 - val_f1: 0.0575\n",
      "Epoch 1951/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1921 - f1: 0.8266 - val_loss: 0.3044 - val_f1: 0.0575\n",
      "Epoch 1952/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1908 - f1: 0.8279 - val_loss: 0.3070 - val_f1: 0.0585\n",
      "Epoch 1953/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1916 - f1: 0.8282 - val_loss: 0.3060 - val_f1: 0.0580\n",
      "Epoch 1954/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1887 - f1: 0.8305 - val_loss: 0.3088 - val_f1: 0.0576\n",
      "Epoch 1955/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1907 - f1: 0.8277 - val_loss: 0.3090 - val_f1: 0.0582\n",
      "Epoch 1956/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1924 - f1: 0.8270 - val_loss: 0.3073 - val_f1: 0.0578\n",
      "Epoch 1957/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1905 - f1: 0.8281 - val_loss: 0.3113 - val_f1: 0.0590\n",
      "Epoch 1958/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1892 - f1: 0.8320 - val_loss: 0.3076 - val_f1: 0.0593\n",
      "Epoch 1959/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1909 - f1: 0.8289 - val_loss: 0.3062 - val_f1: 0.0578\n",
      "Epoch 1960/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1898 - f1: 0.8295 - val_loss: 0.3075 - val_f1: 0.0577\n",
      "Epoch 1961/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1907 - f1: 0.8292 - val_loss: 0.3099 - val_f1: 0.0583\n",
      "Epoch 1962/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1912 - f1: 0.8294 - val_loss: 0.3076 - val_f1: 0.0575\n",
      "Epoch 1963/2000\n",
      "168135/168135 [==============================] - 13s 79us/step - loss: 0.1903 - f1: 0.8303 - val_loss: 0.3072 - val_f1: 0.0579\n",
      "Epoch 1964/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1922 - f1: 0.8268 - val_loss: 0.3044 - val_f1: 0.0575\n",
      "Epoch 1965/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1910 - f1: 0.8273 - val_loss: 0.3064 - val_f1: 0.0588\n",
      "Epoch 1966/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1897 - f1: 0.8308 - val_loss: 0.3072 - val_f1: 0.0582\n",
      "Epoch 1967/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1912 - f1: 0.8279 - val_loss: 0.3106 - val_f1: 0.0578\n",
      "Epoch 1968/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1911 - f1: 0.8292 - val_loss: 0.3087 - val_f1: 0.0574\n",
      "Epoch 1969/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1905 - f1: 0.8273 - val_loss: 0.3108 - val_f1: 0.0585\n",
      "Epoch 1970/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1912 - f1: 0.8290 - val_loss: 0.3067 - val_f1: 0.0584\n",
      "Epoch 1971/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1909 - f1: 0.8280 - val_loss: 0.3078 - val_f1: 0.0582\n",
      "Epoch 1972/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1884 - f1: 0.8296 - val_loss: 0.3133 - val_f1: 0.0575\n",
      "Epoch 1973/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1905 - f1: 0.8287 - val_loss: 0.3106 - val_f1: 0.0585\n",
      "Epoch 1974/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1900 - f1: 0.8308 - val_loss: 0.3092 - val_f1: 0.0572\n",
      "Epoch 1975/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1929 - f1: 0.8266 - val_loss: 0.3031 - val_f1: 0.0581\n",
      "Epoch 1976/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1921 - f1: 0.8278 - val_loss: 0.3048 - val_f1: 0.0586\n",
      "Epoch 1977/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1919 - f1: 0.8275 - val_loss: 0.3054 - val_f1: 0.0578\n",
      "Epoch 1978/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1898 - f1: 0.8283 - val_loss: 0.3080 - val_f1: 0.0578\n",
      "Epoch 1979/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1902 - f1: 0.8273 - val_loss: 0.3054 - val_f1: 0.0585\n",
      "Epoch 1980/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1909 - f1: 0.8313 - val_loss: 0.3100 - val_f1: 0.0573\n",
      "Epoch 1981/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1896 - f1: 0.8305 - val_loss: 0.3084 - val_f1: 0.0581\n",
      "Epoch 1982/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1891 - f1: 0.8301 - val_loss: 0.3084 - val_f1: 0.0584\n",
      "Epoch 1983/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1907 - f1: 0.8276 - val_loss: 0.3068 - val_f1: 0.0576\n",
      "Epoch 1984/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1894 - f1: 0.8285 - val_loss: 0.3084 - val_f1: 0.0576\n",
      "Epoch 1985/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1906 - f1: 0.8267 - val_loss: 0.3113 - val_f1: 0.0576\n",
      "Epoch 1986/2000\n",
      "125600/168135 [=====================>........] - ETA: 3s - loss: 0.1923 - f1: 0.8259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1910 - f1: 0.8276 - val_loss: 0.3062 - val_f1: 0.0575\n",
      "Epoch 1993/2000\n",
      "168135/168135 [==============================] - 13s 75us/step - loss: 0.1929 - f1: 0.8255 - val_loss: 0.3071 - val_f1: 0.0578\n",
      "Epoch 1994/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1905 - f1: 0.8281 - val_loss: 0.3081 - val_f1: 0.0572\n",
      "Epoch 1995/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1909 - f1: 0.8285 - val_loss: 0.3115 - val_f1: 0.0583\n",
      "Epoch 1996/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1916 - f1: 0.8283 - val_loss: 0.3069 - val_f1: 0.0582\n",
      "Epoch 1997/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1890 - f1: 0.8307 - val_loss: 0.3087 - val_f1: 0.0577\n",
      "Epoch 1998/2000\n",
      "168135/168135 [==============================] - 13s 76us/step - loss: 0.1912 - f1: 0.8274 - val_loss: 0.3057 - val_f1: 0.0576\n",
      "Epoch 1999/2000\n",
      "168135/168135 [==============================] - 13s 78us/step - loss: 0.1906 - f1: 0.8302 - val_loss: 0.3089 - val_f1: 0.0579\n",
      "Epoch 2000/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.1897 - f1: 0.8295 - val_loss: 0.3079 - val_f1: 0.0581\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna3.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[25684  1301]\n",
      " [ 1786  1229]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[25667  1319]\n",
      " [ 1779  1236]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[124295   1636]\n",
      " [  2205  39999]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna3.predict(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list4 = [50,50,50,1]\n",
    "activation_list4 = ['tanh','tanh','tanh','sigmoid']\n",
    "dropout_list4 = [0.3,0.3,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 15,201\n",
      "Trainable params: 15,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna4 = new_rna()\n",
    "rna4.build_model(data_shape,n_list4,activation_list4,dropout_list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168135 samples, validate on 30001 samples\n",
      "Epoch 1/2000\n",
      "168135/168135 [==============================] - 16s 98us/step - loss: 0.4177 - f1: 0.5502 - val_loss: 0.2867 - val_f1: 0.0726\n",
      "Epoch 2/2000\n",
      "168135/168135 [==============================] - 16s 92us/step - loss: 0.3968 - f1: 0.5894 - val_loss: 0.2832 - val_f1: 0.0716\n",
      "Epoch 3/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3942 - f1: 0.5961 - val_loss: 0.2815 - val_f1: 0.0719\n",
      "Epoch 4/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3919 - f1: 0.5960 - val_loss: 0.2820 - val_f1: 0.0724\n",
      "Epoch 5/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3912 - f1: 0.5963 - val_loss: 0.2848 - val_f1: 0.0723\n",
      "Epoch 6/2000\n",
      "168135/168135 [==============================] - 16s 93us/step - loss: 0.3907 - f1: 0.5986 - val_loss: 0.2813 - val_f1: 0.0719\n",
      "Epoch 7/2000\n",
      "168135/168135 [==============================] - 16s 93us/step - loss: 0.3891 - f1: 0.5975 - val_loss: 0.2852 - val_f1: 0.0720\n",
      "Epoch 8/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3891 - f1: 0.5989 - val_loss: 0.2806 - val_f1: 0.0709\n",
      "Epoch 9/2000\n",
      "168135/168135 [==============================] - 16s 92us/step - loss: 0.3881 - f1: 0.5987 - val_loss: 0.2827 - val_f1: 0.0721\n",
      "Epoch 10/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3875 - f1: 0.6006 - val_loss: 0.2819 - val_f1: 0.0713\n",
      "Epoch 11/2000\n",
      " 18592/168135 [==>...........................] - ETA: 12s - loss: 0.3834 - f1: 0.6044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 16s 93us/step - loss: 0.3839 - f1: 0.5990 - val_loss: 0.2821 - val_f1: 0.0718\n",
      "Epoch 19/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3826 - f1: 0.6025 - val_loss: 0.2806 - val_f1: 0.0712\n",
      "Epoch 20/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3826 - f1: 0.5993 - val_loss: 0.2807 - val_f1: 0.0714\n",
      "Epoch 21/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3815 - f1: 0.6010 - val_loss: 0.2802 - val_f1: 0.0707\n",
      "Epoch 22/2000\n",
      "168135/168135 [==============================] - 16s 92us/step - loss: 0.3819 - f1: 0.6020 - val_loss: 0.2774 - val_f1: 0.0703\n",
      "Epoch 23/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3810 - f1: 0.6033 - val_loss: 0.2797 - val_f1: 0.0706\n",
      "Epoch 24/2000\n",
      "168135/168135 [==============================] - 16s 92us/step - loss: 0.3815 - f1: 0.5984 - val_loss: 0.2805 - val_f1: 0.0706\n",
      "Epoch 25/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3802 - f1: 0.6013 - val_loss: 0.2798 - val_f1: 0.0708\n",
      "Epoch 26/2000\n",
      "168135/168135 [==============================] - 16s 94us/step - loss: 0.3802 - f1: 0.6026 - val_loss: 0.2790 - val_f1: 0.0705\n",
      "Epoch 27/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3804 - f1: 0.6008 - val_loss: 0.2791 - val_f1: 0.0706\n",
      "Epoch 28/2000\n",
      " 30560/168135 [====>.........................] - ETA: 11s - loss: 0.3794 - f1: 0.6092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 16s 94us/step - loss: 0.3776 - f1: 0.6030 - val_loss: 0.2803 - val_f1: 0.0707\n",
      "Epoch 34/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3766 - f1: 0.6058 - val_loss: 0.2810 - val_f1: 0.0707\n",
      "Epoch 35/2000\n",
      "168135/168135 [==============================] - 15s 92us/step - loss: 0.3765 - f1: 0.6048 - val_loss: 0.2766 - val_f1: 0.0700\n",
      "Epoch 36/2000\n",
      "168135/168135 [==============================] - 16s 92us/step - loss: 0.3753 - f1: 0.6054 - val_loss: 0.2773 - val_f1: 0.0701\n",
      "Epoch 37/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.3755 - f1: 0.6048 - val_loss: 0.2802 - val_f1: 0.0707\n",
      "Epoch 38/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3752 - f1: 0.6053 - val_loss: 0.2786 - val_f1: 0.0702\n",
      "Epoch 39/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3739 - f1: 0.6077 - val_loss: 0.2803 - val_f1: 0.0705\n",
      "Epoch 40/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3744 - f1: 0.6075 - val_loss: 0.2788 - val_f1: 0.0703\n",
      "Epoch 41/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3740 - f1: 0.6072 - val_loss: 0.2791 - val_f1: 0.0701\n",
      "Epoch 42/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3734 - f1: 0.6064 - val_loss: 0.2790 - val_f1: 0.0703\n",
      "Epoch 43/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3737 - f1: 0.6094 - val_loss: 0.2793 - val_f1: 0.0702\n",
      "Epoch 44/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3724 - f1: 0.6093 - val_loss: 0.2804 - val_f1: 0.0708\n",
      "Epoch 45/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3728 - f1: 0.6083 - val_loss: 0.2772 - val_f1: 0.0697\n",
      "Epoch 46/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3717 - f1: 0.6111 - val_loss: 0.2801 - val_f1: 0.0706\n",
      "Epoch 47/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3716 - f1: 0.6125 - val_loss: 0.2782 - val_f1: 0.0701\n",
      "Epoch 48/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3715 - f1: 0.6119 - val_loss: 0.2777 - val_f1: 0.0698\n",
      "Epoch 49/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3703 - f1: 0.6115 - val_loss: 0.2781 - val_f1: 0.0701\n",
      "Epoch 50/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3704 - f1: 0.6109 - val_loss: 0.2805 - val_f1: 0.0704\n",
      "Epoch 51/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3691 - f1: 0.6136 - val_loss: 0.2793 - val_f1: 0.0702\n",
      "Epoch 52/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3696 - f1: 0.6130 - val_loss: 0.2781 - val_f1: 0.0696\n",
      "Epoch 53/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3691 - f1: 0.6144 - val_loss: 0.2788 - val_f1: 0.0700\n",
      "Epoch 54/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3694 - f1: 0.6124 - val_loss: 0.2777 - val_f1: 0.0700\n",
      "Epoch 55/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3681 - f1: 0.6129 - val_loss: 0.2776 - val_f1: 0.0695\n",
      "Epoch 56/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3671 - f1: 0.6165 - val_loss: 0.2793 - val_f1: 0.0706\n",
      "Epoch 57/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3678 - f1: 0.6160 - val_loss: 0.2763 - val_f1: 0.0693\n",
      "Epoch 58/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3665 - f1: 0.6181 - val_loss: 0.2776 - val_f1: 0.0696\n",
      "Epoch 59/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3666 - f1: 0.6161 - val_loss: 0.2822 - val_f1: 0.0711\n",
      "Epoch 60/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3658 - f1: 0.6182 - val_loss: 0.2798 - val_f1: 0.0704\n",
      "Epoch 61/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3658 - f1: 0.6173 - val_loss: 0.2773 - val_f1: 0.0698\n",
      "Epoch 62/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3654 - f1: 0.6189 - val_loss: 0.2777 - val_f1: 0.0696\n",
      "Epoch 63/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3651 - f1: 0.6181 - val_loss: 0.2798 - val_f1: 0.0698\n",
      "Epoch 64/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3639 - f1: 0.6203 - val_loss: 0.2790 - val_f1: 0.0699\n",
      "Epoch 65/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3647 - f1: 0.6201 - val_loss: 0.2769 - val_f1: 0.0694\n",
      "Epoch 66/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3632 - f1: 0.6209 - val_loss: 0.2763 - val_f1: 0.0694\n",
      "Epoch 67/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3635 - f1: 0.6211 - val_loss: 0.2780 - val_f1: 0.0699\n",
      "Epoch 68/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3624 - f1: 0.6242 - val_loss: 0.2781 - val_f1: 0.0702\n",
      "Epoch 69/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3628 - f1: 0.6193 - val_loss: 0.2787 - val_f1: 0.0703\n",
      "Epoch 70/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3617 - f1: 0.6244 - val_loss: 0.2749 - val_f1: 0.0692\n",
      "Epoch 71/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3618 - f1: 0.6263 - val_loss: 0.2768 - val_f1: 0.0697\n",
      "Epoch 72/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3613 - f1: 0.6263 - val_loss: 0.2777 - val_f1: 0.0698\n",
      "Epoch 73/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3610 - f1: 0.6279 - val_loss: 0.2780 - val_f1: 0.0703\n",
      "Epoch 74/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3610 - f1: 0.6238 - val_loss: 0.2768 - val_f1: 0.0698\n",
      "Epoch 75/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3596 - f1: 0.6303 - val_loss: 0.2776 - val_f1: 0.0696\n",
      "Epoch 76/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3593 - f1: 0.6315 - val_loss: 0.2796 - val_f1: 0.0704\n",
      "Epoch 77/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.3583 - f1: 0.6292 - val_loss: 0.2784 - val_f1: 0.0698\n",
      "Epoch 78/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3587 - f1: 0.6308 - val_loss: 0.2780 - val_f1: 0.0700\n",
      "Epoch 79/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3583 - f1: 0.6300 - val_loss: 0.2747 - val_f1: 0.0693\n",
      "Epoch 80/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3587 - f1: 0.6287 - val_loss: 0.2777 - val_f1: 0.0697\n",
      "Epoch 81/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3578 - f1: 0.6307 - val_loss: 0.2777 - val_f1: 0.0700\n",
      "Epoch 82/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3576 - f1: 0.6313 - val_loss: 0.2774 - val_f1: 0.0695\n",
      "Epoch 83/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3567 - f1: 0.6325 - val_loss: 0.2769 - val_f1: 0.0693\n",
      "Epoch 84/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3562 - f1: 0.6328 - val_loss: 0.2776 - val_f1: 0.0697\n",
      "Epoch 85/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3550 - f1: 0.6345 - val_loss: 0.2774 - val_f1: 0.0696\n",
      "Epoch 86/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3559 - f1: 0.6353 - val_loss: 0.2799 - val_f1: 0.0703\n",
      "Epoch 87/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3560 - f1: 0.6337 - val_loss: 0.2798 - val_f1: 0.0704\n",
      "Epoch 88/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3550 - f1: 0.6335 - val_loss: 0.2781 - val_f1: 0.0700\n",
      "Epoch 89/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3542 - f1: 0.6369 - val_loss: 0.2760 - val_f1: 0.0693\n",
      "Epoch 90/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3539 - f1: 0.6366 - val_loss: 0.2794 - val_f1: 0.0700\n",
      "Epoch 91/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3537 - f1: 0.6362 - val_loss: 0.2810 - val_f1: 0.0703\n",
      "Epoch 92/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3537 - f1: 0.6367 - val_loss: 0.2739 - val_f1: 0.0685\n",
      "Epoch 93/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3532 - f1: 0.6379 - val_loss: 0.2760 - val_f1: 0.0690\n",
      "Epoch 94/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3520 - f1: 0.6401 - val_loss: 0.2773 - val_f1: 0.0696\n",
      "Epoch 95/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3519 - f1: 0.6394 - val_loss: 0.2759 - val_f1: 0.0691\n",
      "Epoch 96/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3519 - f1: 0.6402 - val_loss: 0.2756 - val_f1: 0.0689\n",
      "Epoch 97/2000\n",
      " 60704/168135 [=========>....................] - ETA: 4s - loss: 0.3512 - f1: 0.6393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3492 - f1: 0.6447 - val_loss: 0.2764 - val_f1: 0.0687\n",
      "Epoch 107/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3478 - f1: 0.6483 - val_loss: 0.2770 - val_f1: 0.0690\n",
      "Epoch 108/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3487 - f1: 0.6454 - val_loss: 0.2753 - val_f1: 0.0689\n",
      "Epoch 109/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3469 - f1: 0.6481 - val_loss: 0.2757 - val_f1: 0.0692\n",
      "Epoch 110/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3476 - f1: 0.6472 - val_loss: 0.2749 - val_f1: 0.0682\n",
      "Epoch 111/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3461 - f1: 0.6483 - val_loss: 0.2761 - val_f1: 0.0689\n",
      "Epoch 112/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3466 - f1: 0.6476 - val_loss: 0.2806 - val_f1: 0.0701\n",
      "Epoch 113/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3471 - f1: 0.6471 - val_loss: 0.2766 - val_f1: 0.0691\n",
      "Epoch 114/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.3458 - f1: 0.6486 - val_loss: 0.2764 - val_f1: 0.0689\n",
      "Epoch 115/2000\n",
      " 30784/168135 [====>.........................] - ETA: 7s - loss: 0.3476 - f1: 0.6436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3422 - f1: 0.6546 - val_loss: 0.2784 - val_f1: 0.0696\n",
      "Epoch 126/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3428 - f1: 0.6541 - val_loss: 0.2777 - val_f1: 0.0694\n",
      "Epoch 127/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3416 - f1: 0.6585 - val_loss: 0.2767 - val_f1: 0.0694\n",
      "Epoch 128/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3416 - f1: 0.6564 - val_loss: 0.2775 - val_f1: 0.0692\n",
      "Epoch 129/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3425 - f1: 0.6553 - val_loss: 0.2763 - val_f1: 0.0693\n",
      "Epoch 130/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3416 - f1: 0.6565 - val_loss: 0.2760 - val_f1: 0.0690\n",
      "Epoch 131/2000\n",
      "114400/168135 [===================>..........] - ETA: 2s - loss: 0.3426 - f1: 0.6545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3367 - f1: 0.6664 - val_loss: 0.2769 - val_f1: 0.0691\n",
      "Epoch 149/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3374 - f1: 0.6626 - val_loss: 0.2776 - val_f1: 0.0692\n",
      "Epoch 150/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3367 - f1: 0.6644 - val_loss: 0.2787 - val_f1: 0.0698\n",
      "Epoch 151/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3358 - f1: 0.6665 - val_loss: 0.2784 - val_f1: 0.0695\n",
      "Epoch 152/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3371 - f1: 0.6620 - val_loss: 0.2757 - val_f1: 0.0692\n",
      "Epoch 153/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3360 - f1: 0.6637 - val_loss: 0.2766 - val_f1: 0.0694\n",
      "Epoch 154/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3356 - f1: 0.6650 - val_loss: 0.2783 - val_f1: 0.0697\n",
      "Epoch 155/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3349 - f1: 0.6663 - val_loss: 0.2779 - val_f1: 0.0695\n",
      "Epoch 156/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3349 - f1: 0.6663 - val_loss: 0.2757 - val_f1: 0.0689\n",
      "Epoch 157/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3357 - f1: 0.6671 - val_loss: 0.2806 - val_f1: 0.0701\n",
      "Epoch 158/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3348 - f1: 0.6664 - val_loss: 0.2797 - val_f1: 0.0698\n",
      "Epoch 159/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3347 - f1: 0.6664 - val_loss: 0.2775 - val_f1: 0.0695\n",
      "Epoch 160/2000\n",
      " 92064/168135 [===============>..............] - ETA: 3s - loss: 0.3322 - f1: 0.6708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3332 - f1: 0.6702 - val_loss: 0.2784 - val_f1: 0.0695\n",
      "Epoch 167/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3325 - f1: 0.6714 - val_loss: 0.2800 - val_f1: 0.0699\n",
      "Epoch 168/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3331 - f1: 0.6698 - val_loss: 0.2757 - val_f1: 0.0689\n",
      "Epoch 169/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3344 - f1: 0.6698 - val_loss: 0.2747 - val_f1: 0.0690\n",
      "Epoch 170/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3310 - f1: 0.6712 - val_loss: 0.2768 - val_f1: 0.0693\n",
      "Epoch 171/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3323 - f1: 0.6698 - val_loss: 0.2774 - val_f1: 0.0693\n",
      "Epoch 172/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3316 - f1: 0.6713 - val_loss: 0.2791 - val_f1: 0.0698\n",
      "Epoch 173/2000\n",
      " 28928/168135 [====>.........................] - ETA: 6s - loss: 0.3348 - f1: 0.6735"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3315 - f1: 0.6724 - val_loss: 0.2754 - val_f1: 0.0687\n",
      "Epoch 182/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3293 - f1: 0.6760 - val_loss: 0.2790 - val_f1: 0.0695\n",
      "Epoch 183/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3314 - f1: 0.6724 - val_loss: 0.2763 - val_f1: 0.0689\n",
      "Epoch 184/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3302 - f1: 0.6729 - val_loss: 0.2766 - val_f1: 0.0688\n",
      "Epoch 185/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3305 - f1: 0.6720 - val_loss: 0.2811 - val_f1: 0.0696\n",
      "Epoch 186/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3295 - f1: 0.6743 - val_loss: 0.2792 - val_f1: 0.0694\n",
      "Epoch 187/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3296 - f1: 0.6753 - val_loss: 0.2775 - val_f1: 0.0691\n",
      "Epoch 188/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3300 - f1: 0.6749 - val_loss: 0.2804 - val_f1: 0.0697\n",
      "Epoch 189/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3293 - f1: 0.6767 - val_loss: 0.2801 - val_f1: 0.0696\n",
      "Epoch 190/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3283 - f1: 0.6777 - val_loss: 0.2764 - val_f1: 0.0689\n",
      "Epoch 191/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3287 - f1: 0.6756 - val_loss: 0.2797 - val_f1: 0.0691\n",
      "Epoch 192/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3279 - f1: 0.6768 - val_loss: 0.2761 - val_f1: 0.0685\n",
      "Epoch 193/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3283 - f1: 0.6779 - val_loss: 0.2779 - val_f1: 0.0690\n",
      "Epoch 194/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3286 - f1: 0.6765 - val_loss: 0.2794 - val_f1: 0.0693\n",
      "Epoch 195/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3287 - f1: 0.6740 - val_loss: 0.2758 - val_f1: 0.0684\n",
      "Epoch 196/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3280 - f1: 0.6746 - val_loss: 0.2784 - val_f1: 0.0693\n",
      "Epoch 197/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3277 - f1: 0.6791 - val_loss: 0.2816 - val_f1: 0.0696\n",
      "Epoch 198/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3279 - f1: 0.6778 - val_loss: 0.2827 - val_f1: 0.0700\n",
      "Epoch 199/2000\n",
      " 59168/168135 [=========>....................] - ETA: 5s - loss: 0.3272 - f1: 0.6769"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3247 - f1: 0.6829 - val_loss: 0.2784 - val_f1: 0.0690\n",
      "Epoch 211/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3241 - f1: 0.6818 - val_loss: 0.2791 - val_f1: 0.0691\n",
      "Epoch 212/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3256 - f1: 0.6802 - val_loss: 0.2832 - val_f1: 0.0698\n",
      "Epoch 213/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3254 - f1: 0.6837 - val_loss: 0.2793 - val_f1: 0.0693\n",
      "Epoch 214/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3257 - f1: 0.6796 - val_loss: 0.2777 - val_f1: 0.0692\n",
      "Epoch 215/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3252 - f1: 0.6823 - val_loss: 0.2806 - val_f1: 0.0695\n",
      "Epoch 216/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3253 - f1: 0.6818 - val_loss: 0.2764 - val_f1: 0.0685\n",
      "Epoch 217/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3256 - f1: 0.6836 - val_loss: 0.2775 - val_f1: 0.0688\n",
      "Epoch 218/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3256 - f1: 0.6801 - val_loss: 0.2762 - val_f1: 0.0687\n",
      "Epoch 219/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3251 - f1: 0.6824 - val_loss: 0.2761 - val_f1: 0.0686\n",
      "Epoch 220/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3241 - f1: 0.6827 - val_loss: 0.2783 - val_f1: 0.0691\n",
      "Epoch 221/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3249 - f1: 0.6827 - val_loss: 0.2780 - val_f1: 0.0688\n",
      "Epoch 222/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3234 - f1: 0.6840 - val_loss: 0.2824 - val_f1: 0.0699\n",
      "Epoch 223/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3247 - f1: 0.6836 - val_loss: 0.2768 - val_f1: 0.0690\n",
      "Epoch 224/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3236 - f1: 0.6846 - val_loss: 0.2796 - val_f1: 0.0692\n",
      "Epoch 225/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3236 - f1: 0.6831 - val_loss: 0.2793 - val_f1: 0.0691\n",
      "Epoch 226/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3236 - f1: 0.6832 - val_loss: 0.2800 - val_f1: 0.0694\n",
      "Epoch 227/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3235 - f1: 0.6825 - val_loss: 0.2804 - val_f1: 0.0694\n",
      "Epoch 228/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3237 - f1: 0.6829 - val_loss: 0.2816 - val_f1: 0.0700\n",
      "Epoch 229/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3236 - f1: 0.6843 - val_loss: 0.2776 - val_f1: 0.0691\n",
      "Epoch 230/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3232 - f1: 0.6832 - val_loss: 0.2769 - val_f1: 0.0689\n",
      "Epoch 231/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3233 - f1: 0.6847 - val_loss: 0.2772 - val_f1: 0.0691\n",
      "Epoch 232/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3237 - f1: 0.6860 - val_loss: 0.2763 - val_f1: 0.0688\n",
      "Epoch 233/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3216 - f1: 0.6865 - val_loss: 0.2794 - val_f1: 0.0695\n",
      "Epoch 234/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3234 - f1: 0.6835 - val_loss: 0.2761 - val_f1: 0.0686\n",
      "Epoch 235/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3234 - f1: 0.6872 - val_loss: 0.2786 - val_f1: 0.0692\n",
      "Epoch 236/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3235 - f1: 0.6815 - val_loss: 0.2795 - val_f1: 0.0696\n",
      "Epoch 237/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3222 - f1: 0.6867 - val_loss: 0.2807 - val_f1: 0.0695\n",
      "Epoch 238/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3223 - f1: 0.6872 - val_loss: 0.2798 - val_f1: 0.0694\n",
      "Epoch 239/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3214 - f1: 0.6861 - val_loss: 0.2736 - val_f1: 0.0683\n",
      "Epoch 240/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3231 - f1: 0.6858 - val_loss: 0.2822 - val_f1: 0.0700\n",
      "Epoch 241/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3209 - f1: 0.6882 - val_loss: 0.2806 - val_f1: 0.0695\n",
      "Epoch 242/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3230 - f1: 0.6840 - val_loss: 0.2775 - val_f1: 0.0692\n",
      "Epoch 243/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3204 - f1: 0.6869 - val_loss: 0.2809 - val_f1: 0.0700\n",
      "Epoch 244/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3203 - f1: 0.6889 - val_loss: 0.2796 - val_f1: 0.0696\n",
      "Epoch 245/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3215 - f1: 0.6877 - val_loss: 0.2768 - val_f1: 0.0692\n",
      "Epoch 246/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3224 - f1: 0.6867 - val_loss: 0.2797 - val_f1: 0.0693\n",
      "Epoch 247/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3214 - f1: 0.6864 - val_loss: 0.2790 - val_f1: 0.0695\n",
      "Epoch 248/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3198 - f1: 0.6897 - val_loss: 0.2820 - val_f1: 0.0701\n",
      "Epoch 249/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3218 - f1: 0.6869 - val_loss: 0.2812 - val_f1: 0.0697\n",
      "Epoch 250/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3207 - f1: 0.6870 - val_loss: 0.2797 - val_f1: 0.0693\n",
      "Epoch 251/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3202 - f1: 0.6885 - val_loss: 0.2786 - val_f1: 0.0688\n",
      "Epoch 252/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3205 - f1: 0.6877 - val_loss: 0.2760 - val_f1: 0.0687\n",
      "Epoch 253/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3201 - f1: 0.6856 - val_loss: 0.2796 - val_f1: 0.0693\n",
      "Epoch 254/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3192 - f1: 0.6912 - val_loss: 0.2775 - val_f1: 0.0689\n",
      "Epoch 255/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3201 - f1: 0.6900 - val_loss: 0.2767 - val_f1: 0.0686\n",
      "Epoch 256/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3203 - f1: 0.6873 - val_loss: 0.2797 - val_f1: 0.0694\n",
      "Epoch 257/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3195 - f1: 0.6915 - val_loss: 0.2785 - val_f1: 0.0691\n",
      "Epoch 258/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3200 - f1: 0.6909 - val_loss: 0.2741 - val_f1: 0.0680\n",
      "Epoch 259/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3186 - f1: 0.6915 - val_loss: 0.2797 - val_f1: 0.0692\n",
      "Epoch 260/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3187 - f1: 0.6926 - val_loss: 0.2757 - val_f1: 0.0682\n",
      "Epoch 261/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3190 - f1: 0.6925 - val_loss: 0.2790 - val_f1: 0.0691\n",
      "Epoch 262/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3191 - f1: 0.6905 - val_loss: 0.2818 - val_f1: 0.0695\n",
      "Epoch 263/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3194 - f1: 0.6879 - val_loss: 0.2825 - val_f1: 0.0696\n",
      "Epoch 264/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3175 - f1: 0.6912 - val_loss: 0.2829 - val_f1: 0.0699\n",
      "Epoch 265/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3194 - f1: 0.6916 - val_loss: 0.2832 - val_f1: 0.0699\n",
      "Epoch 266/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3185 - f1: 0.6910 - val_loss: 0.2783 - val_f1: 0.0689\n",
      "Epoch 267/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3180 - f1: 0.6899 - val_loss: 0.2782 - val_f1: 0.0690\n",
      "Epoch 268/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3189 - f1: 0.6913 - val_loss: 0.2785 - val_f1: 0.0688\n",
      "Epoch 269/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3188 - f1: 0.6928 - val_loss: 0.2808 - val_f1: 0.0694\n",
      "Epoch 270/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3195 - f1: 0.6886 - val_loss: 0.2792 - val_f1: 0.0689\n",
      "Epoch 271/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3193 - f1: 0.6915 - val_loss: 0.2807 - val_f1: 0.0694\n",
      "Epoch 272/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3178 - f1: 0.6914 - val_loss: 0.2766 - val_f1: 0.0684\n",
      "Epoch 273/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3180 - f1: 0.6894 - val_loss: 0.2801 - val_f1: 0.0690\n",
      "Epoch 274/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3177 - f1: 0.6927 - val_loss: 0.2792 - val_f1: 0.0689\n",
      "Epoch 275/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3192 - f1: 0.6923 - val_loss: 0.2793 - val_f1: 0.0691\n",
      "Epoch 276/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3170 - f1: 0.6915 - val_loss: 0.2792 - val_f1: 0.0689\n",
      "Epoch 277/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3178 - f1: 0.6930 - val_loss: 0.2765 - val_f1: 0.0684\n",
      "Epoch 278/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3174 - f1: 0.6928 - val_loss: 0.2779 - val_f1: 0.0687\n",
      "Epoch 279/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3178 - f1: 0.6922 - val_loss: 0.2812 - val_f1: 0.0693\n",
      "Epoch 280/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3178 - f1: 0.6909 - val_loss: 0.2812 - val_f1: 0.0693\n",
      "Epoch 281/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3182 - f1: 0.6928 - val_loss: 0.2772 - val_f1: 0.0689\n",
      "Epoch 282/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3168 - f1: 0.6937 - val_loss: 0.2795 - val_f1: 0.0691\n",
      "Epoch 283/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3170 - f1: 0.6949 - val_loss: 0.2803 - val_f1: 0.0694\n",
      "Epoch 284/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3170 - f1: 0.6918 - val_loss: 0.2878 - val_f1: 0.0707\n",
      "Epoch 285/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3164 - f1: 0.6949 - val_loss: 0.2737 - val_f1: 0.0681\n",
      "Epoch 286/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3178 - f1: 0.6912 - val_loss: 0.2861 - val_f1: 0.0705\n",
      "Epoch 287/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3167 - f1: 0.6922 - val_loss: 0.2812 - val_f1: 0.0692\n",
      "Epoch 288/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3178 - f1: 0.6890 - val_loss: 0.2793 - val_f1: 0.0691\n",
      "Epoch 289/2000\n",
      " 30176/168135 [====>.........................] - ETA: 6s - loss: 0.3155 - f1: 0.6879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3162 - f1: 0.6953 - val_loss: 0.2818 - val_f1: 0.0691\n",
      "Epoch 298/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3153 - f1: 0.6952 - val_loss: 0.2784 - val_f1: 0.0688\n",
      "Epoch 299/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3164 - f1: 0.6943 - val_loss: 0.2818 - val_f1: 0.0699\n",
      "Epoch 300/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3147 - f1: 0.6958 - val_loss: 0.2796 - val_f1: 0.0688\n",
      "Epoch 301/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3157 - f1: 0.6945 - val_loss: 0.2796 - val_f1: 0.0690\n",
      "Epoch 302/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3157 - f1: 0.6935 - val_loss: 0.2827 - val_f1: 0.0692\n",
      "Epoch 303/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3142 - f1: 0.6937 - val_loss: 0.2805 - val_f1: 0.0691\n",
      "Epoch 304/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3139 - f1: 0.6954 - val_loss: 0.2837 - val_f1: 0.0696\n",
      "Epoch 305/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3146 - f1: 0.6974 - val_loss: 0.2752 - val_f1: 0.0679\n",
      "Epoch 306/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3150 - f1: 0.6948 - val_loss: 0.2826 - val_f1: 0.0696\n",
      "Epoch 307/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3158 - f1: 0.6967 - val_loss: 0.2782 - val_f1: 0.0687\n",
      "Epoch 308/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3149 - f1: 0.6962 - val_loss: 0.2784 - val_f1: 0.0684\n",
      "Epoch 309/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3142 - f1: 0.6972 - val_loss: 0.2816 - val_f1: 0.0693\n",
      "Epoch 310/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3147 - f1: 0.6968 - val_loss: 0.2841 - val_f1: 0.0698\n",
      "Epoch 311/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3160 - f1: 0.6954 - val_loss: 0.2764 - val_f1: 0.0683\n",
      "Epoch 312/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3138 - f1: 0.6991 - val_loss: 0.2816 - val_f1: 0.0693\n",
      "Epoch 313/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3140 - f1: 0.6968 - val_loss: 0.2748 - val_f1: 0.0677\n",
      "Epoch 314/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3145 - f1: 0.6969 - val_loss: 0.2791 - val_f1: 0.0689\n",
      "Epoch 315/2000\n",
      " 46496/168135 [=======>......................] - ETA: 5s - loss: 0.3120 - f1: 0.6998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3150 - f1: 0.6964 - val_loss: 0.2791 - val_f1: 0.0686\n",
      "Epoch 327/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3141 - f1: 0.6974 - val_loss: 0.2834 - val_f1: 0.0696\n",
      "Epoch 328/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3139 - f1: 0.6952 - val_loss: 0.2783 - val_f1: 0.0685\n",
      "Epoch 329/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3139 - f1: 0.6977 - val_loss: 0.2806 - val_f1: 0.0691\n",
      "Epoch 330/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3128 - f1: 0.6984 - val_loss: 0.2791 - val_f1: 0.0689\n",
      "Epoch 331/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3131 - f1: 0.7002 - val_loss: 0.2846 - val_f1: 0.0696\n",
      "Epoch 332/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3122 - f1: 0.6998 - val_loss: 0.2811 - val_f1: 0.0690\n",
      "Epoch 333/2000\n",
      " 16960/168135 [==>...........................] - ETA: 9s - loss: 0.3123 - f1: 0.7013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3128 - f1: 0.6991 - val_loss: 0.2767 - val_f1: 0.0683\n",
      "Epoch 344/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3120 - f1: 0.6988 - val_loss: 0.2771 - val_f1: 0.0681\n",
      "Epoch 345/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3131 - f1: 0.6969 - val_loss: 0.2805 - val_f1: 0.0689\n",
      "Epoch 346/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3121 - f1: 0.6995 - val_loss: 0.2838 - val_f1: 0.0694\n",
      "Epoch 347/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3130 - f1: 0.7002 - val_loss: 0.2839 - val_f1: 0.0692\n",
      "Epoch 348/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3130 - f1: 0.6978 - val_loss: 0.2804 - val_f1: 0.0689\n",
      "Epoch 349/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3122 - f1: 0.6994 - val_loss: 0.2782 - val_f1: 0.0682\n",
      "Epoch 350/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3116 - f1: 0.7016 - val_loss: 0.2806 - val_f1: 0.0687\n",
      "Epoch 351/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3126 - f1: 0.6994 - val_loss: 0.2770 - val_f1: 0.0681\n",
      "Epoch 352/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3104 - f1: 0.7021 - val_loss: 0.2805 - val_f1: 0.0686\n",
      "Epoch 353/2000\n",
      " 41472/168135 [======>.......................] - ETA: 5s - loss: 0.3124 - f1: 0.6948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3117 - f1: 0.6997 - val_loss: 0.2796 - val_f1: 0.0688\n",
      "Epoch 371/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3116 - f1: 0.7011 - val_loss: 0.2796 - val_f1: 0.0686\n",
      "Epoch 372/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3090 - f1: 0.7029 - val_loss: 0.2817 - val_f1: 0.0693\n",
      "Epoch 373/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3100 - f1: 0.7011 - val_loss: 0.2804 - val_f1: 0.0687\n",
      "Epoch 374/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3112 - f1: 0.7015 - val_loss: 0.2832 - val_f1: 0.0691\n",
      "Epoch 375/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3097 - f1: 0.7017 - val_loss: 0.2778 - val_f1: 0.0684\n",
      "Epoch 376/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3096 - f1: 0.7049 - val_loss: 0.2783 - val_f1: 0.0681\n",
      "Epoch 377/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3097 - f1: 0.7035 - val_loss: 0.2829 - val_f1: 0.0693\n",
      "Epoch 378/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3101 - f1: 0.7041 - val_loss: 0.2796 - val_f1: 0.0687\n",
      "Epoch 379/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3105 - f1: 0.7023 - val_loss: 0.2788 - val_f1: 0.0686\n",
      "Epoch 380/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3079 - f1: 0.7064 - val_loss: 0.2823 - val_f1: 0.0692\n",
      "Epoch 381/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3096 - f1: 0.7044 - val_loss: 0.2830 - val_f1: 0.0693\n",
      "Epoch 382/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3092 - f1: 0.7032 - val_loss: 0.2822 - val_f1: 0.0690\n",
      "Epoch 383/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3106 - f1: 0.7009 - val_loss: 0.2755 - val_f1: 0.0679\n",
      "Epoch 384/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3112 - f1: 0.7013 - val_loss: 0.2794 - val_f1: 0.0686\n",
      "Epoch 385/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3080 - f1: 0.7052 - val_loss: 0.2822 - val_f1: 0.0692\n",
      "Epoch 386/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3096 - f1: 0.7029 - val_loss: 0.2842 - val_f1: 0.0692\n",
      "Epoch 387/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3087 - f1: 0.7054 - val_loss: 0.2816 - val_f1: 0.0691\n",
      "Epoch 388/2000\n",
      " 44672/168135 [======>.......................] - ETA: 6s - loss: 0.3116 - f1: 0.7033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3078 - f1: 0.7052 - val_loss: 0.2763 - val_f1: 0.0678\n",
      "Epoch 409/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3077 - f1: 0.7058 - val_loss: 0.2830 - val_f1: 0.0695\n",
      "Epoch 410/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3086 - f1: 0.7054 - val_loss: 0.2820 - val_f1: 0.0688\n",
      "Epoch 411/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3069 - f1: 0.7066 - val_loss: 0.2809 - val_f1: 0.0686\n",
      "Epoch 412/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3078 - f1: 0.7025 - val_loss: 0.2839 - val_f1: 0.0695\n",
      "Epoch 413/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3084 - f1: 0.7045 - val_loss: 0.2818 - val_f1: 0.0689\n",
      "Epoch 414/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3076 - f1: 0.7054 - val_loss: 0.2853 - val_f1: 0.0694\n",
      "Epoch 415/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3085 - f1: 0.7051 - val_loss: 0.2786 - val_f1: 0.0684\n",
      "Epoch 416/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3074 - f1: 0.7072 - val_loss: 0.2780 - val_f1: 0.0683\n",
      "Epoch 417/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3079 - f1: 0.7059 - val_loss: 0.2762 - val_f1: 0.0678\n",
      "Epoch 418/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3071 - f1: 0.7058 - val_loss: 0.2839 - val_f1: 0.0690\n",
      "Epoch 419/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3077 - f1: 0.7055 - val_loss: 0.2807 - val_f1: 0.0685\n",
      "Epoch 420/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3074 - f1: 0.7087 - val_loss: 0.2818 - val_f1: 0.0689\n",
      "Epoch 421/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3072 - f1: 0.7063 - val_loss: 0.2849 - val_f1: 0.0693\n",
      "Epoch 422/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3065 - f1: 0.7084 - val_loss: 0.2801 - val_f1: 0.0687\n",
      "Epoch 423/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3059 - f1: 0.7094 - val_loss: 0.2847 - val_f1: 0.0697\n",
      "Epoch 424/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3051 - f1: 0.7098 - val_loss: 0.2861 - val_f1: 0.0697\n",
      "Epoch 425/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3071 - f1: 0.7071 - val_loss: 0.2810 - val_f1: 0.0686\n",
      "Epoch 426/2000\n",
      "104992/168135 [=================>............] - ETA: 2s - loss: 0.3088 - f1: 0.7075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3062 - f1: 0.7074 - val_loss: 0.2759 - val_f1: 0.0676\n",
      "Epoch 452/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3060 - f1: 0.7093 - val_loss: 0.2773 - val_f1: 0.0679\n",
      "Epoch 453/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3057 - f1: 0.7096 - val_loss: 0.2798 - val_f1: 0.0681\n",
      "Epoch 454/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3049 - f1: 0.7109 - val_loss: 0.2793 - val_f1: 0.0683\n",
      "Epoch 455/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3043 - f1: 0.7112 - val_loss: 0.2790 - val_f1: 0.0686\n",
      "Epoch 456/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3053 - f1: 0.7105 - val_loss: 0.2836 - val_f1: 0.0692\n",
      "Epoch 457/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3054 - f1: 0.7100 - val_loss: 0.2797 - val_f1: 0.0682\n",
      "Epoch 458/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3051 - f1: 0.7075 - val_loss: 0.2826 - val_f1: 0.0686\n",
      "Epoch 459/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3061 - f1: 0.7079 - val_loss: 0.2831 - val_f1: 0.0696\n",
      "Epoch 460/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3057 - f1: 0.7078 - val_loss: 0.2796 - val_f1: 0.0685\n",
      "Epoch 461/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3053 - f1: 0.7099 - val_loss: 0.2781 - val_f1: 0.0680\n",
      "Epoch 462/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3058 - f1: 0.7088 - val_loss: 0.2802 - val_f1: 0.0687\n",
      "Epoch 463/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3056 - f1: 0.7083 - val_loss: 0.2841 - val_f1: 0.0696\n",
      "Epoch 464/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3057 - f1: 0.7103 - val_loss: 0.2818 - val_f1: 0.0685\n",
      "Epoch 465/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3055 - f1: 0.7104 - val_loss: 0.2822 - val_f1: 0.0687\n",
      "Epoch 466/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3054 - f1: 0.7088 - val_loss: 0.2777 - val_f1: 0.0680\n",
      "Epoch 467/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3053 - f1: 0.7090 - val_loss: 0.2801 - val_f1: 0.0683\n",
      "Epoch 468/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3045 - f1: 0.7113 - val_loss: 0.2804 - val_f1: 0.0685\n",
      "Epoch 469/2000\n",
      "126400/168135 [=====================>........] - ETA: 1s - loss: 0.3023 - f1: 0.7131"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3044 - f1: 0.7086 - val_loss: 0.2818 - val_f1: 0.0687\n",
      "Epoch 495/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3046 - f1: 0.7119 - val_loss: 0.2838 - val_f1: 0.0687\n",
      "Epoch 496/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3035 - f1: 0.7129 - val_loss: 0.2817 - val_f1: 0.0684\n",
      "Epoch 497/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3028 - f1: 0.7127 - val_loss: 0.2818 - val_f1: 0.0684\n",
      "Epoch 498/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3031 - f1: 0.7122 - val_loss: 0.2828 - val_f1: 0.0689\n",
      "Epoch 499/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3032 - f1: 0.7118 - val_loss: 0.2810 - val_f1: 0.0682\n",
      "Epoch 500/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3023 - f1: 0.7113 - val_loss: 0.2837 - val_f1: 0.0688\n",
      "Epoch 501/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3042 - f1: 0.7121 - val_loss: 0.2777 - val_f1: 0.0676\n",
      "Epoch 502/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3041 - f1: 0.7119 - val_loss: 0.2841 - val_f1: 0.0691\n",
      "Epoch 503/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3042 - f1: 0.7117 - val_loss: 0.2830 - val_f1: 0.0686\n",
      "Epoch 504/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3035 - f1: 0.7121 - val_loss: 0.2799 - val_f1: 0.0680\n",
      "Epoch 505/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3042 - f1: 0.7105 - val_loss: 0.2785 - val_f1: 0.0680\n",
      "Epoch 506/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3030 - f1: 0.7119 - val_loss: 0.2784 - val_f1: 0.0679\n",
      "Epoch 507/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3025 - f1: 0.7124 - val_loss: 0.2858 - val_f1: 0.0694\n",
      "Epoch 508/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3032 - f1: 0.7115 - val_loss: 0.2875 - val_f1: 0.0696\n",
      "Epoch 509/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3033 - f1: 0.7135 - val_loss: 0.2857 - val_f1: 0.0694\n",
      "Epoch 510/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3044 - f1: 0.7112 - val_loss: 0.2821 - val_f1: 0.0689\n",
      "Epoch 511/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3026 - f1: 0.7117 - val_loss: 0.2785 - val_f1: 0.0677\n",
      "Epoch 512/2000\n",
      " 23392/168135 [===>..........................] - ETA: 7s - loss: 0.2995 - f1: 0.7198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3033 - f1: 0.7123 - val_loss: 0.2805 - val_f1: 0.0683\n",
      "Epoch 534/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3024 - f1: 0.7125 - val_loss: 0.2832 - val_f1: 0.0684\n",
      "Epoch 535/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3026 - f1: 0.7121 - val_loss: 0.2799 - val_f1: 0.0676\n",
      "Epoch 536/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3017 - f1: 0.7129 - val_loss: 0.2766 - val_f1: 0.0672\n",
      "Epoch 537/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3024 - f1: 0.7116 - val_loss: 0.2822 - val_f1: 0.0685\n",
      "Epoch 538/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3034 - f1: 0.7111 - val_loss: 0.2801 - val_f1: 0.0681\n",
      "Epoch 539/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3019 - f1: 0.7142 - val_loss: 0.2811 - val_f1: 0.0680\n",
      "Epoch 540/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3020 - f1: 0.7106 - val_loss: 0.2783 - val_f1: 0.0674\n",
      "Epoch 541/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3025 - f1: 0.7126 - val_loss: 0.2841 - val_f1: 0.0692\n",
      "Epoch 542/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3007 - f1: 0.7160 - val_loss: 0.2811 - val_f1: 0.0680\n",
      "Epoch 543/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3016 - f1: 0.7152 - val_loss: 0.2800 - val_f1: 0.0679\n",
      "Epoch 544/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3020 - f1: 0.7143 - val_loss: 0.2839 - val_f1: 0.0689\n",
      "Epoch 545/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3033 - f1: 0.7125 - val_loss: 0.2818 - val_f1: 0.0685\n",
      "Epoch 546/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3020 - f1: 0.7134 - val_loss: 0.2852 - val_f1: 0.0690\n",
      "Epoch 547/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3015 - f1: 0.7149 - val_loss: 0.2842 - val_f1: 0.0687\n",
      "Epoch 548/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3020 - f1: 0.7149 - val_loss: 0.2818 - val_f1: 0.0685\n",
      "Epoch 549/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3027 - f1: 0.7112 - val_loss: 0.2795 - val_f1: 0.0678\n",
      "Epoch 550/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3025 - f1: 0.7123 - val_loss: 0.2818 - val_f1: 0.0685\n",
      "Epoch 551/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3013 - f1: 0.7135 - val_loss: 0.2799 - val_f1: 0.0683\n",
      "Epoch 552/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3010 - f1: 0.7144 - val_loss: 0.2852 - val_f1: 0.0689\n",
      "Epoch 553/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3025 - f1: 0.7117 - val_loss: 0.2825 - val_f1: 0.0688\n",
      "Epoch 554/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3021 - f1: 0.7148 - val_loss: 0.2798 - val_f1: 0.0679\n",
      "Epoch 555/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3015 - f1: 0.7137 - val_loss: 0.2807 - val_f1: 0.0679\n",
      "Epoch 556/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3026 - f1: 0.7129 - val_loss: 0.2827 - val_f1: 0.0689\n",
      "Epoch 557/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3006 - f1: 0.7127 - val_loss: 0.2822 - val_f1: 0.0680\n",
      "Epoch 558/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3019 - f1: 0.7155 - val_loss: 0.2843 - val_f1: 0.0687\n",
      "Epoch 559/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2996 - f1: 0.7171 - val_loss: 0.2807 - val_f1: 0.0683\n",
      "Epoch 560/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3017 - f1: 0.7136 - val_loss: 0.2828 - val_f1: 0.0687\n",
      "Epoch 561/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3013 - f1: 0.7141 - val_loss: 0.2811 - val_f1: 0.0683\n",
      "Epoch 562/2000\n",
      "153344/168135 [==========================>...] - ETA: 0s - loss: 0.3011 - f1: 0.7160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3014 - f1: 0.7144 - val_loss: 0.2802 - val_f1: 0.0683\n",
      "Epoch 572/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3000 - f1: 0.7134 - val_loss: 0.2817 - val_f1: 0.0680\n",
      "Epoch 573/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3003 - f1: 0.7153 - val_loss: 0.2804 - val_f1: 0.0682\n",
      "Epoch 574/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3011 - f1: 0.7146 - val_loss: 0.2800 - val_f1: 0.0678\n",
      "Epoch 575/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3013 - f1: 0.7164 - val_loss: 0.2834 - val_f1: 0.0685\n",
      "Epoch 576/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3002 - f1: 0.7176 - val_loss: 0.2863 - val_f1: 0.0691\n",
      "Epoch 577/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3008 - f1: 0.7136 - val_loss: 0.2803 - val_f1: 0.0679\n",
      "Epoch 578/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3037 - f1: 0.7111 - val_loss: 0.2791 - val_f1: 0.0678\n",
      "Epoch 579/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3019 - f1: 0.7121 - val_loss: 0.2784 - val_f1: 0.0675\n",
      "Epoch 580/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3004 - f1: 0.7172 - val_loss: 0.2796 - val_f1: 0.0674\n",
      "Epoch 581/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2996 - f1: 0.7171 - val_loss: 0.2798 - val_f1: 0.0677\n",
      "Epoch 582/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2999 - f1: 0.7169 - val_loss: 0.2846 - val_f1: 0.0690\n",
      "Epoch 583/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3002 - f1: 0.7165 - val_loss: 0.2842 - val_f1: 0.0689\n",
      "Epoch 584/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3003 - f1: 0.7167 - val_loss: 0.2783 - val_f1: 0.0678\n",
      "Epoch 585/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.3002 - f1: 0.7173 - val_loss: 0.2804 - val_f1: 0.0681\n",
      "Epoch 586/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3007 - f1: 0.7157 - val_loss: 0.2809 - val_f1: 0.0681\n",
      "Epoch 587/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2989 - f1: 0.7183 - val_loss: 0.2849 - val_f1: 0.0687\n",
      "Epoch 588/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3000 - f1: 0.7151 - val_loss: 0.2846 - val_f1: 0.0689\n",
      "Epoch 589/2000\n",
      "122144/168135 [====================>.........] - ETA: 2s - loss: 0.3012 - f1: 0.7164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3006 - f1: 0.7155 - val_loss: 0.2808 - val_f1: 0.0681\n",
      "Epoch 599/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3003 - f1: 0.7153 - val_loss: 0.2833 - val_f1: 0.0686\n",
      "Epoch 600/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2992 - f1: 0.7157 - val_loss: 0.2828 - val_f1: 0.0680\n",
      "Epoch 601/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3002 - f1: 0.7160 - val_loss: 0.2824 - val_f1: 0.0685\n",
      "Epoch 602/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2993 - f1: 0.7154 - val_loss: 0.2832 - val_f1: 0.0686\n",
      "Epoch 603/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2990 - f1: 0.7176 - val_loss: 0.2823 - val_f1: 0.0683\n",
      "Epoch 604/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3010 - f1: 0.7165 - val_loss: 0.2820 - val_f1: 0.0684\n",
      "Epoch 605/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2996 - f1: 0.7162 - val_loss: 0.2870 - val_f1: 0.0691\n",
      "Epoch 606/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3000 - f1: 0.7158 - val_loss: 0.2847 - val_f1: 0.0686\n",
      "Epoch 607/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3015 - f1: 0.7141 - val_loss: 0.2803 - val_f1: 0.0678\n",
      "Epoch 608/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.3003 - f1: 0.7148 - val_loss: 0.2842 - val_f1: 0.0688\n",
      "Epoch 609/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2988 - f1: 0.7169 - val_loss: 0.2802 - val_f1: 0.0676\n",
      "Epoch 610/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2994 - f1: 0.7186 - val_loss: 0.2809 - val_f1: 0.0681\n",
      "Epoch 611/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2983 - f1: 0.7196 - val_loss: 0.2825 - val_f1: 0.0686\n",
      "Epoch 612/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2997 - f1: 0.7157 - val_loss: 0.2796 - val_f1: 0.0679\n",
      "Epoch 613/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.3001 - f1: 0.7189 - val_loss: 0.2789 - val_f1: 0.0676\n",
      "Epoch 614/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2985 - f1: 0.7184 - val_loss: 0.2824 - val_f1: 0.0683\n",
      "Epoch 615/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2997 - f1: 0.7169 - val_loss: 0.2800 - val_f1: 0.0676\n",
      "Epoch 616/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2991 - f1: 0.7177 - val_loss: 0.2811 - val_f1: 0.0681\n",
      "Epoch 617/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2995 - f1: 0.7158 - val_loss: 0.2809 - val_f1: 0.0681\n",
      "Epoch 618/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2990 - f1: 0.7203 - val_loss: 0.2834 - val_f1: 0.0686\n",
      "Epoch 619/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2985 - f1: 0.7175 - val_loss: 0.2853 - val_f1: 0.0687\n",
      "Epoch 620/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.3001 - f1: 0.7155 - val_loss: 0.2817 - val_f1: 0.0682\n",
      "Epoch 621/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2990 - f1: 0.7168 - val_loss: 0.2829 - val_f1: 0.0684\n",
      "Epoch 622/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2987 - f1: 0.7189 - val_loss: 0.2792 - val_f1: 0.0678\n",
      "Epoch 623/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2994 - f1: 0.7163 - val_loss: 0.2807 - val_f1: 0.0678\n",
      "Epoch 624/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2998 - f1: 0.7159 - val_loss: 0.2806 - val_f1: 0.0677\n",
      "Epoch 625/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2992 - f1: 0.7159 - val_loss: 0.2798 - val_f1: 0.0677\n",
      "Epoch 626/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2995 - f1: 0.7163 - val_loss: 0.2825 - val_f1: 0.0683\n",
      "Epoch 627/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2994 - f1: 0.7150 - val_loss: 0.2762 - val_f1: 0.0672\n",
      "Epoch 628/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2986 - f1: 0.7157 - val_loss: 0.2795 - val_f1: 0.0673\n",
      "Epoch 629/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2990 - f1: 0.7170 - val_loss: 0.2786 - val_f1: 0.0674\n",
      "Epoch 630/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2987 - f1: 0.7163 - val_loss: 0.2807 - val_f1: 0.0683\n",
      "Epoch 631/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2990 - f1: 0.7172 - val_loss: 0.2792 - val_f1: 0.0672\n",
      "Epoch 632/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2981 - f1: 0.7194 - val_loss: 0.2795 - val_f1: 0.0677\n",
      "Epoch 633/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2985 - f1: 0.7166 - val_loss: 0.2796 - val_f1: 0.0675\n",
      "Epoch 634/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2991 - f1: 0.7169 - val_loss: 0.2864 - val_f1: 0.0688\n",
      "Epoch 635/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2984 - f1: 0.7203 - val_loss: 0.2809 - val_f1: 0.0677\n",
      "Epoch 636/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2982 - f1: 0.7179 - val_loss: 0.2813 - val_f1: 0.0677\n",
      "Epoch 637/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2986 - f1: 0.7176 - val_loss: 0.2825 - val_f1: 0.0682\n",
      "Epoch 638/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2987 - f1: 0.7188 - val_loss: 0.2864 - val_f1: 0.0686\n",
      "Epoch 639/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2989 - f1: 0.7178 - val_loss: 0.2818 - val_f1: 0.0683\n",
      "Epoch 640/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2977 - f1: 0.7194 - val_loss: 0.2849 - val_f1: 0.0685\n",
      "Epoch 641/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2985 - f1: 0.7174 - val_loss: 0.2837 - val_f1: 0.0682\n",
      "Epoch 642/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2995 - f1: 0.7153 - val_loss: 0.2829 - val_f1: 0.0687\n",
      "Epoch 643/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2979 - f1: 0.7201 - val_loss: 0.2797 - val_f1: 0.0672\n",
      "Epoch 644/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2970 - f1: 0.7177 - val_loss: 0.2837 - val_f1: 0.0681\n",
      "Epoch 645/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2995 - f1: 0.7165 - val_loss: 0.2830 - val_f1: 0.0680\n",
      "Epoch 646/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2984 - f1: 0.7185 - val_loss: 0.2812 - val_f1: 0.0679\n",
      "Epoch 647/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2979 - f1: 0.7206 - val_loss: 0.2793 - val_f1: 0.0676\n",
      "Epoch 648/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2980 - f1: 0.7198 - val_loss: 0.2825 - val_f1: 0.0684\n",
      "Epoch 649/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2984 - f1: 0.7177 - val_loss: 0.2833 - val_f1: 0.0680\n",
      "Epoch 650/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2969 - f1: 0.7201 - val_loss: 0.2845 - val_f1: 0.0683\n",
      "Epoch 651/2000\n",
      " 76288/168135 [============>.................] - ETA: 4s - loss: 0.2984 - f1: 0.7177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2983 - f1: 0.7189 - val_loss: 0.2846 - val_f1: 0.0691\n",
      "Epoch 660/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2986 - f1: 0.7191 - val_loss: 0.2806 - val_f1: 0.0675\n",
      "Epoch 661/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2981 - f1: 0.7183 - val_loss: 0.2799 - val_f1: 0.0675\n",
      "Epoch 662/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2978 - f1: 0.7167 - val_loss: 0.2802 - val_f1: 0.0679\n",
      "Epoch 663/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2982 - f1: 0.7200 - val_loss: 0.2859 - val_f1: 0.0688\n",
      "Epoch 664/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2975 - f1: 0.7183 - val_loss: 0.2843 - val_f1: 0.0687\n",
      "Epoch 665/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2982 - f1: 0.7155 - val_loss: 0.2856 - val_f1: 0.0689\n",
      "Epoch 666/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2981 - f1: 0.7204 - val_loss: 0.2822 - val_f1: 0.0679\n",
      "Epoch 667/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2982 - f1: 0.7179 - val_loss: 0.2819 - val_f1: 0.0681\n",
      "Epoch 668/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2985 - f1: 0.7152 - val_loss: 0.2811 - val_f1: 0.0682\n",
      "Epoch 669/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2972 - f1: 0.7194 - val_loss: 0.2864 - val_f1: 0.0692\n",
      "Epoch 670/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2976 - f1: 0.7194 - val_loss: 0.2904 - val_f1: 0.0695\n",
      "Epoch 671/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2971 - f1: 0.7211 - val_loss: 0.2801 - val_f1: 0.0677\n",
      "Epoch 672/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2972 - f1: 0.7190 - val_loss: 0.2814 - val_f1: 0.0678\n",
      "Epoch 673/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2974 - f1: 0.7204 - val_loss: 0.2821 - val_f1: 0.0676\n",
      "Epoch 674/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2961 - f1: 0.7210 - val_loss: 0.2799 - val_f1: 0.0679\n",
      "Epoch 675/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2976 - f1: 0.7180 - val_loss: 0.2850 - val_f1: 0.0687\n",
      "Epoch 676/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2976 - f1: 0.7182 - val_loss: 0.2806 - val_f1: 0.0675\n",
      "Epoch 677/2000\n",
      "  4608/168135 [..............................] - ETA: 7s - loss: 0.2946 - f1: 0.7205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2971 - f1: 0.7161 - val_loss: 0.2828 - val_f1: 0.0682\n",
      "Epoch 688/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2973 - f1: 0.7179 - val_loss: 0.2765 - val_f1: 0.0665\n",
      "Epoch 689/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2968 - f1: 0.7201 - val_loss: 0.2822 - val_f1: 0.0676\n",
      "Epoch 690/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2975 - f1: 0.7211 - val_loss: 0.2833 - val_f1: 0.0682\n",
      "Epoch 691/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2965 - f1: 0.7197 - val_loss: 0.2813 - val_f1: 0.0676\n",
      "Epoch 692/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2979 - f1: 0.7161 - val_loss: 0.2827 - val_f1: 0.0685\n",
      "Epoch 693/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2974 - f1: 0.7197 - val_loss: 0.2771 - val_f1: 0.0670\n",
      "Epoch 694/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2974 - f1: 0.7198 - val_loss: 0.2788 - val_f1: 0.0675\n",
      "Epoch 695/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2961 - f1: 0.7200 - val_loss: 0.2845 - val_f1: 0.0684\n",
      "Epoch 696/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2961 - f1: 0.7219 - val_loss: 0.2881 - val_f1: 0.0689\n",
      "Epoch 697/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2963 - f1: 0.7192 - val_loss: 0.2840 - val_f1: 0.0685\n",
      "Epoch 698/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2961 - f1: 0.7190 - val_loss: 0.2846 - val_f1: 0.0683\n",
      "Epoch 699/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2972 - f1: 0.7232 - val_loss: 0.2801 - val_f1: 0.0677\n",
      "Epoch 700/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2978 - f1: 0.7195 - val_loss: 0.2834 - val_f1: 0.0684\n",
      "Epoch 701/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2971 - f1: 0.7210 - val_loss: 0.2846 - val_f1: 0.0685\n",
      "Epoch 702/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2971 - f1: 0.7184 - val_loss: 0.2846 - val_f1: 0.0681\n",
      "Epoch 703/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2975 - f1: 0.7198 - val_loss: 0.2819 - val_f1: 0.0677\n",
      "Epoch 704/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2984 - f1: 0.7171 - val_loss: 0.2794 - val_f1: 0.0677\n",
      "Epoch 705/2000\n",
      "153632/168135 [==========================>...] - ETA: 0s - loss: 0.2955 - f1: 0.7217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2952 - f1: 0.7226 - val_loss: 0.2846 - val_f1: 0.0686\n",
      "Epoch 718/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2970 - f1: 0.7204 - val_loss: 0.2792 - val_f1: 0.0673\n",
      "Epoch 719/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2958 - f1: 0.7207 - val_loss: 0.2799 - val_f1: 0.0676\n",
      "Epoch 720/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2966 - f1: 0.7209 - val_loss: 0.2858 - val_f1: 0.0684\n",
      "Epoch 721/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2968 - f1: 0.7205 - val_loss: 0.2792 - val_f1: 0.0674\n",
      "Epoch 722/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2957 - f1: 0.7216 - val_loss: 0.2833 - val_f1: 0.0681\n",
      "Epoch 723/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2952 - f1: 0.7200 - val_loss: 0.2849 - val_f1: 0.0683\n",
      "Epoch 724/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2952 - f1: 0.7217 - val_loss: 0.2844 - val_f1: 0.0681\n",
      "Epoch 725/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2972 - f1: 0.7197 - val_loss: 0.2816 - val_f1: 0.0675\n",
      "Epoch 726/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2973 - f1: 0.7172 - val_loss: 0.2807 - val_f1: 0.0678\n",
      "Epoch 727/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2960 - f1: 0.7211 - val_loss: 0.2771 - val_f1: 0.0674\n",
      "Epoch 728/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2969 - f1: 0.7203 - val_loss: 0.2853 - val_f1: 0.0685\n",
      "Epoch 729/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2958 - f1: 0.7204 - val_loss: 0.2843 - val_f1: 0.0685\n",
      "Epoch 730/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2968 - f1: 0.7197 - val_loss: 0.2817 - val_f1: 0.0682\n",
      "Epoch 731/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2943 - f1: 0.7236 - val_loss: 0.2826 - val_f1: 0.0679\n",
      "Epoch 732/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2955 - f1: 0.7238 - val_loss: 0.2880 - val_f1: 0.0686\n",
      "Epoch 733/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2961 - f1: 0.7210 - val_loss: 0.2801 - val_f1: 0.0676\n",
      "Epoch 734/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2958 - f1: 0.7217 - val_loss: 0.2815 - val_f1: 0.0679\n",
      "Epoch 735/2000\n",
      " 97792/168135 [================>.............] - ETA: 3s - loss: 0.2969 - f1: 0.7172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2972 - f1: 0.7207 - val_loss: 0.2834 - val_f1: 0.0683\n",
      "Epoch 749/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2955 - f1: 0.7230 - val_loss: 0.2872 - val_f1: 0.0683\n",
      "Epoch 750/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2949 - f1: 0.7201 - val_loss: 0.2835 - val_f1: 0.0680\n",
      "Epoch 751/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2970 - f1: 0.7194 - val_loss: 0.2800 - val_f1: 0.0678\n",
      "Epoch 752/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2959 - f1: 0.7225 - val_loss: 0.2812 - val_f1: 0.0677\n",
      "Epoch 753/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2959 - f1: 0.7217 - val_loss: 0.2793 - val_f1: 0.0676\n",
      "Epoch 754/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2962 - f1: 0.7213 - val_loss: 0.2809 - val_f1: 0.0677\n",
      "Epoch 755/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2950 - f1: 0.7226 - val_loss: 0.2852 - val_f1: 0.0687\n",
      "Epoch 756/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2969 - f1: 0.7211 - val_loss: 0.2828 - val_f1: 0.0683\n",
      "Epoch 757/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2941 - f1: 0.7233 - val_loss: 0.2844 - val_f1: 0.0685\n",
      "Epoch 758/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2953 - f1: 0.7224 - val_loss: 0.2884 - val_f1: 0.0689\n",
      "Epoch 759/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2950 - f1: 0.7204 - val_loss: 0.2855 - val_f1: 0.0682\n",
      "Epoch 760/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2954 - f1: 0.7227 - val_loss: 0.2842 - val_f1: 0.0682\n",
      "Epoch 761/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2958 - f1: 0.7203 - val_loss: 0.2795 - val_f1: 0.0674\n",
      "Epoch 762/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2948 - f1: 0.7231 - val_loss: 0.2841 - val_f1: 0.0681\n",
      "Epoch 763/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2960 - f1: 0.7215 - val_loss: 0.2814 - val_f1: 0.0678\n",
      "Epoch 764/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2953 - f1: 0.7216 - val_loss: 0.2857 - val_f1: 0.0686\n",
      "Epoch 765/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2957 - f1: 0.7229 - val_loss: 0.2812 - val_f1: 0.0679\n",
      "Epoch 766/2000\n",
      "104736/168135 [=================>............] - ETA: 2s - loss: 0.2963 - f1: 0.7180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2946 - f1: 0.7207 - val_loss: 0.2843 - val_f1: 0.0683\n",
      "Epoch 779/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2974 - f1: 0.7196 - val_loss: 0.2828 - val_f1: 0.0679\n",
      "Epoch 780/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2953 - f1: 0.7224 - val_loss: 0.2848 - val_f1: 0.0682\n",
      "Epoch 781/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2953 - f1: 0.7200 - val_loss: 0.2833 - val_f1: 0.0680\n",
      "Epoch 782/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2952 - f1: 0.7213 - val_loss: 0.2855 - val_f1: 0.0681\n",
      "Epoch 783/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2967 - f1: 0.7192 - val_loss: 0.2858 - val_f1: 0.0687\n",
      "Epoch 784/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2947 - f1: 0.7218 - val_loss: 0.2870 - val_f1: 0.0687\n",
      "Epoch 785/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2945 - f1: 0.7222 - val_loss: 0.2834 - val_f1: 0.0680\n",
      "Epoch 786/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2952 - f1: 0.7213 - val_loss: 0.2819 - val_f1: 0.0675\n",
      "Epoch 787/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2950 - f1: 0.7235 - val_loss: 0.2815 - val_f1: 0.0677\n",
      "Epoch 788/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2949 - f1: 0.7236 - val_loss: 0.2835 - val_f1: 0.0683\n",
      "Epoch 789/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2946 - f1: 0.7208 - val_loss: 0.2842 - val_f1: 0.0683\n",
      "Epoch 790/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2948 - f1: 0.7214 - val_loss: 0.2828 - val_f1: 0.0680\n",
      "Epoch 791/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2946 - f1: 0.7219 - val_loss: 0.2827 - val_f1: 0.0681\n",
      "Epoch 792/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2943 - f1: 0.7217 - val_loss: 0.2876 - val_f1: 0.0688\n",
      "Epoch 793/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2946 - f1: 0.7222 - val_loss: 0.2776 - val_f1: 0.0672\n",
      "Epoch 794/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2946 - f1: 0.7225 - val_loss: 0.2793 - val_f1: 0.0671\n",
      "Epoch 795/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2962 - f1: 0.7181 - val_loss: 0.2877 - val_f1: 0.0692\n",
      "Epoch 796/2000\n",
      "134464/168135 [======================>.......] - ETA: 1s - loss: 0.2947 - f1: 0.7199"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2943 - f1: 0.7229 - val_loss: 0.2864 - val_f1: 0.0685\n",
      "Epoch 810/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2927 - f1: 0.7236 - val_loss: 0.2823 - val_f1: 0.0679\n",
      "Epoch 811/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2928 - f1: 0.7271 - val_loss: 0.2846 - val_f1: 0.0680\n",
      "Epoch 812/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2933 - f1: 0.7245 - val_loss: 0.2802 - val_f1: 0.0675\n",
      "Epoch 813/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2935 - f1: 0.7233 - val_loss: 0.2868 - val_f1: 0.0684\n",
      "Epoch 814/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2939 - f1: 0.7242 - val_loss: 0.2854 - val_f1: 0.0685\n",
      "Epoch 815/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2949 - f1: 0.7226 - val_loss: 0.2844 - val_f1: 0.0682\n",
      "Epoch 816/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2936 - f1: 0.7247 - val_loss: 0.2846 - val_f1: 0.0684\n",
      "Epoch 817/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2952 - f1: 0.7226 - val_loss: 0.2808 - val_f1: 0.0677\n",
      "Epoch 818/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2946 - f1: 0.7211 - val_loss: 0.2861 - val_f1: 0.0686\n",
      "Epoch 819/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2937 - f1: 0.7218 - val_loss: 0.2820 - val_f1: 0.0679\n",
      "Epoch 820/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2936 - f1: 0.7229 - val_loss: 0.2823 - val_f1: 0.0681\n",
      "Epoch 821/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2942 - f1: 0.7228 - val_loss: 0.2837 - val_f1: 0.0681\n",
      "Epoch 822/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2948 - f1: 0.7201 - val_loss: 0.2797 - val_f1: 0.0674\n",
      "Epoch 823/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2943 - f1: 0.7216 - val_loss: 0.2883 - val_f1: 0.0687\n",
      "Epoch 824/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2942 - f1: 0.7226 - val_loss: 0.2830 - val_f1: 0.0680\n",
      "Epoch 825/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2939 - f1: 0.7242 - val_loss: 0.2838 - val_f1: 0.0676\n",
      "Epoch 826/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2933 - f1: 0.7236 - val_loss: 0.2829 - val_f1: 0.0679\n",
      "Epoch 827/2000\n",
      " 19712/168135 [==>...........................] - ETA: 6s - loss: 0.2939 - f1: 0.72"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2933 - f1: 0.7218 - val_loss: 0.2865 - val_f1: 0.0685\n",
      "Epoch 840/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2946 - f1: 0.7244 - val_loss: 0.2821 - val_f1: 0.0679\n",
      "Epoch 841/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2932 - f1: 0.7238 - val_loss: 0.2837 - val_f1: 0.0679\n",
      "Epoch 842/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2928 - f1: 0.7242 - val_loss: 0.2853 - val_f1: 0.0678\n",
      "Epoch 843/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2934 - f1: 0.7233 - val_loss: 0.2828 - val_f1: 0.0682\n",
      "Epoch 844/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2938 - f1: 0.7219 - val_loss: 0.2807 - val_f1: 0.0678\n",
      "Epoch 845/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2939 - f1: 0.7244 - val_loss: 0.2842 - val_f1: 0.0681\n",
      "Epoch 846/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2934 - f1: 0.7237 - val_loss: 0.2892 - val_f1: 0.0688\n",
      "Epoch 847/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2938 - f1: 0.7218 - val_loss: 0.2856 - val_f1: 0.0681\n",
      "Epoch 848/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2919 - f1: 0.7245 - val_loss: 0.2807 - val_f1: 0.0677\n",
      "Epoch 849/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2942 - f1: 0.7232 - val_loss: 0.2840 - val_f1: 0.0681\n",
      "Epoch 850/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2929 - f1: 0.7240 - val_loss: 0.2845 - val_f1: 0.0682\n",
      "Epoch 851/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2925 - f1: 0.7252 - val_loss: 0.2876 - val_f1: 0.0687\n",
      "Epoch 852/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2926 - f1: 0.7265 - val_loss: 0.2838 - val_f1: 0.0683\n",
      "Epoch 853/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2940 - f1: 0.7225 - val_loss: 0.2858 - val_f1: 0.0677\n",
      "Epoch 854/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2943 - f1: 0.7236 - val_loss: 0.2809 - val_f1: 0.0676\n",
      "Epoch 855/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2941 - f1: 0.7249 - val_loss: 0.2835 - val_f1: 0.0680\n",
      "Epoch 856/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2927 - f1: 0.7230 - val_loss: 0.2855 - val_f1: 0.0684\n",
      "Epoch 857/2000\n",
      "101024/168135 [=================>............] - ETA: 3s - loss: 0.2906 - f1: 0.72"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2927 - f1: 0.7254 - val_loss: 0.2876 - val_f1: 0.0684\n",
      "Epoch 870/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2924 - f1: 0.7268 - val_loss: 0.2813 - val_f1: 0.0677\n",
      "Epoch 871/2000\n",
      "168135/168135 [==============================] - 8s 51us/step - loss: 0.2930 - f1: 0.7258 - val_loss: 0.2863 - val_f1: 0.0686\n",
      "Epoch 872/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2926 - f1: 0.7251 - val_loss: 0.2850 - val_f1: 0.0684\n",
      "Epoch 873/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2926 - f1: 0.7242 - val_loss: 0.2825 - val_f1: 0.0679\n",
      "Epoch 874/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2938 - f1: 0.7224 - val_loss: 0.2841 - val_f1: 0.0683\n",
      "Epoch 875/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2917 - f1: 0.7280 - val_loss: 0.2841 - val_f1: 0.0681\n",
      "Epoch 876/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2928 - f1: 0.7241 - val_loss: 0.2826 - val_f1: 0.0678\n",
      "Epoch 877/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2941 - f1: 0.7252 - val_loss: 0.2837 - val_f1: 0.0679\n",
      "Epoch 878/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2922 - f1: 0.7249 - val_loss: 0.2848 - val_f1: 0.0685\n",
      "Epoch 879/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2927 - f1: 0.7248 - val_loss: 0.2830 - val_f1: 0.0679\n",
      "Epoch 880/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2926 - f1: 0.7253 - val_loss: 0.2814 - val_f1: 0.0675\n",
      "Epoch 881/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2921 - f1: 0.7267 - val_loss: 0.2822 - val_f1: 0.0674\n",
      "Epoch 882/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2917 - f1: 0.7266 - val_loss: 0.2808 - val_f1: 0.0676\n",
      "Epoch 883/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2939 - f1: 0.7232 - val_loss: 0.2794 - val_f1: 0.0668\n",
      "Epoch 884/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2941 - f1: 0.7244 - val_loss: 0.2876 - val_f1: 0.0687\n",
      "Epoch 885/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2939 - f1: 0.7237 - val_loss: 0.2871 - val_f1: 0.0684\n",
      "Epoch 886/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2930 - f1: 0.7254 - val_loss: 0.2847 - val_f1: 0.0682\n",
      "Epoch 887/2000\n",
      "  9504/168135 [>.............................] - ETA: 7s - loss: 0.2995 - f1: 0.7254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2922 - f1: 0.7271 - val_loss: 0.2870 - val_f1: 0.0678\n",
      "Epoch 898/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2934 - f1: 0.7241 - val_loss: 0.2771 - val_f1: 0.0664\n",
      "Epoch 899/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2929 - f1: 0.7248 - val_loss: 0.2827 - val_f1: 0.0679\n",
      "Epoch 900/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2919 - f1: 0.7243 - val_loss: 0.2820 - val_f1: 0.0675\n",
      "Epoch 901/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2924 - f1: 0.7250 - val_loss: 0.2877 - val_f1: 0.0687\n",
      "Epoch 902/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2922 - f1: 0.7259 - val_loss: 0.2871 - val_f1: 0.0682\n",
      "Epoch 903/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2928 - f1: 0.7253 - val_loss: 0.2829 - val_f1: 0.0678\n",
      "Epoch 904/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2930 - f1: 0.7241 - val_loss: 0.2820 - val_f1: 0.0676\n",
      "Epoch 905/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2926 - f1: 0.7260 - val_loss: 0.2834 - val_f1: 0.0680\n",
      "Epoch 906/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2920 - f1: 0.7256 - val_loss: 0.2869 - val_f1: 0.0687\n",
      "Epoch 907/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2925 - f1: 0.7256 - val_loss: 0.2864 - val_f1: 0.0682\n",
      "Epoch 908/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2929 - f1: 0.7249 - val_loss: 0.2801 - val_f1: 0.0674\n",
      "Epoch 909/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2910 - f1: 0.7263 - val_loss: 0.2797 - val_f1: 0.0670\n",
      "Epoch 910/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2917 - f1: 0.7281 - val_loss: 0.2808 - val_f1: 0.0675\n",
      "Epoch 911/2000\n",
      "168135/168135 [==============================] - 9s 51us/step - loss: 0.2932 - f1: 0.7253 - val_loss: 0.2848 - val_f1: 0.0682\n",
      "Epoch 912/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2921 - f1: 0.7245 - val_loss: 0.2825 - val_f1: 0.0678\n",
      "Epoch 913/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2917 - f1: 0.7277 - val_loss: 0.2815 - val_f1: 0.0676\n",
      "Epoch 914/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2919 - f1: 0.7264 - val_loss: 0.2836 - val_f1: 0.0683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2908 - f1: 0.7269 - val_loss: 0.2800 - val_f1: 0.0672\n",
      "Epoch 925/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2914 - f1: 0.7267 - val_loss: 0.2836 - val_f1: 0.0682\n",
      "Epoch 926/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2911 - f1: 0.7262 - val_loss: 0.2793 - val_f1: 0.0669\n",
      "Epoch 927/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2923 - f1: 0.7245 - val_loss: 0.2894 - val_f1: 0.0683\n",
      "Epoch 928/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2919 - f1: 0.7259 - val_loss: 0.2873 - val_f1: 0.0683\n",
      "Epoch 929/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2921 - f1: 0.7271 - val_loss: 0.2805 - val_f1: 0.0673\n",
      "Epoch 930/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2920 - f1: 0.7259 - val_loss: 0.2833 - val_f1: 0.0676\n",
      "Epoch 931/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2908 - f1: 0.7280 - val_loss: 0.2881 - val_f1: 0.0679\n",
      "Epoch 932/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2928 - f1: 0.7250 - val_loss: 0.2841 - val_f1: 0.0678\n",
      "Epoch 933/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2915 - f1: 0.7275 - val_loss: 0.2898 - val_f1: 0.0687\n",
      "Epoch 934/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2916 - f1: 0.7265 - val_loss: 0.2818 - val_f1: 0.0673\n",
      "Epoch 935/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2918 - f1: 0.7259 - val_loss: 0.2803 - val_f1: 0.0671\n",
      "Epoch 936/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2910 - f1: 0.7276 - val_loss: 0.2860 - val_f1: 0.0680\n",
      "Epoch 937/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2913 - f1: 0.7265 - val_loss: 0.2840 - val_f1: 0.0677\n",
      "Epoch 938/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2914 - f1: 0.7270 - val_loss: 0.2827 - val_f1: 0.0678\n",
      "Epoch 939/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2916 - f1: 0.7265 - val_loss: 0.2815 - val_f1: 0.0677\n",
      "Epoch 940/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2910 - f1: 0.7290 - val_loss: 0.2810 - val_f1: 0.0674\n",
      "Epoch 941/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2917 - f1: 0.7266 - val_loss: 0.2854 - val_f1: 0.0685\n",
      "Epoch 942/2000\n",
      "156768/168135 [==========================>...] - ETA: 0s - loss: 0.2916 - f1: 0.7254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2926 - f1: 0.7251 - val_loss: 0.2839 - val_f1: 0.0679\n",
      "Epoch 952/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2911 - f1: 0.7255 - val_loss: 0.2843 - val_f1: 0.0680\n",
      "Epoch 953/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2912 - f1: 0.7278 - val_loss: 0.2837 - val_f1: 0.0676\n",
      "Epoch 954/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2921 - f1: 0.7256 - val_loss: 0.2881 - val_f1: 0.0683\n",
      "Epoch 955/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2911 - f1: 0.7267 - val_loss: 0.2838 - val_f1: 0.0679\n",
      "Epoch 956/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2907 - f1: 0.7287 - val_loss: 0.2836 - val_f1: 0.0675\n",
      "Epoch 957/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2911 - f1: 0.7275 - val_loss: 0.2871 - val_f1: 0.0682\n",
      "Epoch 958/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2914 - f1: 0.7252 - val_loss: 0.2842 - val_f1: 0.0679\n",
      "Epoch 959/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2908 - f1: 0.7272 - val_loss: 0.2822 - val_f1: 0.0677\n",
      "Epoch 960/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2917 - f1: 0.7278 - val_loss: 0.2816 - val_f1: 0.0678\n",
      "Epoch 961/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2892 - f1: 0.7295 - val_loss: 0.2857 - val_f1: 0.0682\n",
      "Epoch 962/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2918 - f1: 0.7271 - val_loss: 0.2863 - val_f1: 0.0680\n",
      "Epoch 963/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2900 - f1: 0.7281 - val_loss: 0.2880 - val_f1: 0.0682\n",
      "Epoch 964/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2908 - f1: 0.7292 - val_loss: 0.2795 - val_f1: 0.0671\n",
      "Epoch 965/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2918 - f1: 0.7260 - val_loss: 0.2857 - val_f1: 0.0680\n",
      "Epoch 966/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2905 - f1: 0.7290 - val_loss: 0.2838 - val_f1: 0.0672\n",
      "Epoch 967/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2913 - f1: 0.7272 - val_loss: 0.2883 - val_f1: 0.0682\n",
      "Epoch 968/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2898 - f1: 0.7285 - val_loss: 0.2814 - val_f1: 0.0671\n",
      "Epoch 969/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2902 - f1: 0.7273 - val_loss: 0.2860 - val_f1: 0.0676\n",
      "Epoch 970/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2905 - f1: 0.7270 - val_loss: 0.2831 - val_f1: 0.0677\n",
      "Epoch 971/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2905 - f1: 0.7274 - val_loss: 0.2822 - val_f1: 0.0675\n",
      "Epoch 972/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2911 - f1: 0.7247 - val_loss: 0.2864 - val_f1: 0.0677\n",
      "Epoch 973/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2903 - f1: 0.7301 - val_loss: 0.2818 - val_f1: 0.0677\n",
      "Epoch 974/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2916 - f1: 0.7254 - val_loss: 0.2813 - val_f1: 0.0674\n",
      "Epoch 975/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2918 - f1: 0.7252 - val_loss: 0.2882 - val_f1: 0.0687\n",
      "Epoch 976/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2910 - f1: 0.7282 - val_loss: 0.2847 - val_f1: 0.0679\n",
      "Epoch 977/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2925 - f1: 0.7267 - val_loss: 0.2787 - val_f1: 0.0672\n",
      "Epoch 978/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2915 - f1: 0.7273 - val_loss: 0.2824 - val_f1: 0.0677\n",
      "Epoch 979/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2910 - f1: 0.7268 - val_loss: 0.2815 - val_f1: 0.0675\n",
      "Epoch 980/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2906 - f1: 0.7289 - val_loss: 0.2838 - val_f1: 0.0679\n",
      "Epoch 981/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2914 - f1: 0.7238 - val_loss: 0.2855 - val_f1: 0.0682\n",
      "Epoch 982/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2896 - f1: 0.7305 - val_loss: 0.2842 - val_f1: 0.0675\n",
      "Epoch 983/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2909 - f1: 0.7300 - val_loss: 0.2851 - val_f1: 0.0680\n",
      "Epoch 984/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2900 - f1: 0.7288 - val_loss: 0.2830 - val_f1: 0.0677\n",
      "Epoch 985/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2909 - f1: 0.7283 - val_loss: 0.2863 - val_f1: 0.0682\n",
      "Epoch 986/2000\n",
      " 83712/168135 [=============>................] - ETA: 3s - loss: 0.2897 - f1: 0.7266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2903 - f1: 0.7284 - val_loss: 0.2857 - val_f1: 0.0679\n",
      "Epoch 996/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2906 - f1: 0.7284 - val_loss: 0.2806 - val_f1: 0.0671\n",
      "Epoch 997/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2907 - f1: 0.7283 - val_loss: 0.2816 - val_f1: 0.0673\n",
      "Epoch 998/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2903 - f1: 0.7295 - val_loss: 0.2855 - val_f1: 0.0681\n",
      "Epoch 999/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2917 - f1: 0.7281 - val_loss: 0.2850 - val_f1: 0.0678\n",
      "Epoch 1000/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2896 - f1: 0.7257 - val_loss: 0.2846 - val_f1: 0.0679\n",
      "Epoch 1001/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2902 - f1: 0.7273 - val_loss: 0.2862 - val_f1: 0.0683\n",
      "Epoch 1002/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2906 - f1: 0.7280 - val_loss: 0.2841 - val_f1: 0.0679\n",
      "Epoch 1003/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2899 - f1: 0.7296 - val_loss: 0.2831 - val_f1: 0.0675\n",
      "Epoch 1004/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2908 - f1: 0.7258 - val_loss: 0.2858 - val_f1: 0.0681\n",
      "Epoch 1005/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2906 - f1: 0.7274 - val_loss: 0.2828 - val_f1: 0.0676\n",
      "Epoch 1006/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2896 - f1: 0.7296 - val_loss: 0.2830 - val_f1: 0.0677\n",
      "Epoch 1007/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2908 - f1: 0.7267 - val_loss: 0.2860 - val_f1: 0.0678\n",
      "Epoch 1008/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2896 - f1: 0.7278 - val_loss: 0.2846 - val_f1: 0.0675\n",
      "Epoch 1009/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2908 - f1: 0.7271 - val_loss: 0.2855 - val_f1: 0.0680\n",
      "Epoch 1010/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2900 - f1: 0.7273 - val_loss: 0.2837 - val_f1: 0.0676\n",
      "Epoch 1011/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2905 - f1: 0.7277 - val_loss: 0.2846 - val_f1: 0.0674\n",
      "Epoch 1012/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2917 - f1: 0.7258 - val_loss: 0.2837 - val_f1: 0.0673\n",
      "Epoch 1013/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2894 - f1: 0.7292 - val_loss: 0.2853 - val_f1: 0.0678\n",
      "Epoch 1014/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2903 - f1: 0.7295 - val_loss: 0.2854 - val_f1: 0.0677\n",
      "Epoch 1015/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2896 - f1: 0.7281 - val_loss: 0.2846 - val_f1: 0.0675\n",
      "Epoch 1016/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2895 - f1: 0.7297 - val_loss: 0.2910 - val_f1: 0.0686\n",
      "Epoch 1017/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2897 - f1: 0.7274 - val_loss: 0.2843 - val_f1: 0.0674\n",
      "Epoch 1018/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2905 - f1: 0.7284 - val_loss: 0.2835 - val_f1: 0.0673\n",
      "Epoch 1019/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2899 - f1: 0.7285 - val_loss: 0.2899 - val_f1: 0.0681\n",
      "Epoch 1020/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2906 - f1: 0.7289 - val_loss: 0.2812 - val_f1: 0.0673\n",
      "Epoch 1021/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2899 - f1: 0.7284 - val_loss: 0.2875 - val_f1: 0.0681\n",
      "Epoch 1022/2000\n",
      " 11456/168135 [=>............................] - ETA: 7s - loss: 0.2833 - f1: 0.7340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2891 - f1: 0.7301 - val_loss: 0.2820 - val_f1: 0.0671\n",
      "Epoch 1033/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2899 - f1: 0.7281 - val_loss: 0.2858 - val_f1: 0.0679\n",
      "Epoch 1034/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2887 - f1: 0.7322 - val_loss: 0.2826 - val_f1: 0.0673\n",
      "Epoch 1035/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2900 - f1: 0.7295 - val_loss: 0.2827 - val_f1: 0.0676\n",
      "Epoch 1036/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2893 - f1: 0.7306 - val_loss: 0.2856 - val_f1: 0.0676\n",
      "Epoch 1037/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2903 - f1: 0.7265 - val_loss: 0.2867 - val_f1: 0.0679\n",
      "Epoch 1038/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2903 - f1: 0.7286 - val_loss: 0.2835 - val_f1: 0.0679\n",
      "Epoch 1039/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2897 - f1: 0.7270 - val_loss: 0.2887 - val_f1: 0.0689\n",
      "Epoch 1040/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2893 - f1: 0.7298 - val_loss: 0.2851 - val_f1: 0.0681\n",
      "Epoch 1041/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2906 - f1: 0.7279 - val_loss: 0.2873 - val_f1: 0.0682\n",
      "Epoch 1042/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2891 - f1: 0.7316 - val_loss: 0.2812 - val_f1: 0.0676\n",
      "Epoch 1043/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2889 - f1: 0.7313 - val_loss: 0.2833 - val_f1: 0.0675\n",
      "Epoch 1044/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2891 - f1: 0.7305 - val_loss: 0.2834 - val_f1: 0.0671\n",
      "Epoch 1045/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2899 - f1: 0.7278 - val_loss: 0.2897 - val_f1: 0.0685\n",
      "Epoch 1046/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2909 - f1: 0.7287 - val_loss: 0.2788 - val_f1: 0.0668\n",
      "Epoch 1047/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2895 - f1: 0.7276 - val_loss: 0.2835 - val_f1: 0.0677\n",
      "Epoch 1048/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2879 - f1: 0.7287 - val_loss: 0.2870 - val_f1: 0.0678\n",
      "Epoch 1049/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2893 - f1: 0.7297 - val_loss: 0.2870 - val_f1: 0.0680\n",
      "Epoch 1050/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2900 - f1: 0.7286 - val_loss: 0.2842 - val_f1: 0.0672\n",
      "Epoch 1051/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2905 - f1: 0.7258 - val_loss: 0.2849 - val_f1: 0.0675\n",
      "Epoch 1052/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2892 - f1: 0.7283 - val_loss: 0.2825 - val_f1: 0.0670\n",
      "Epoch 1053/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2889 - f1: 0.7285 - val_loss: 0.2807 - val_f1: 0.0673\n",
      "Epoch 1054/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2888 - f1: 0.7292 - val_loss: 0.2827 - val_f1: 0.0674\n",
      "Epoch 1055/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2898 - f1: 0.7270 - val_loss: 0.2868 - val_f1: 0.0676\n",
      "Epoch 1056/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2882 - f1: 0.7311 - val_loss: 0.2924 - val_f1: 0.0687\n",
      "Epoch 1057/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2891 - f1: 0.7283 - val_loss: 0.2783 - val_f1: 0.0666\n",
      "Epoch 1058/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2888 - f1: 0.7301 - val_loss: 0.2858 - val_f1: 0.0678\n",
      "Epoch 1059/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2890 - f1: 0.7306 - val_loss: 0.2892 - val_f1: 0.0685\n",
      "Epoch 1060/2000\n",
      " 83872/168135 [=============>................] - ETA: 3s - loss: 0.2906 - f1: 0.7260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2895 - f1: 0.7313 - val_loss: 0.2835 - val_f1: 0.0677\n",
      "Epoch 1070/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2888 - f1: 0.7304 - val_loss: 0.2795 - val_f1: 0.0667\n",
      "Epoch 1071/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2887 - f1: 0.7298 - val_loss: 0.2814 - val_f1: 0.0670\n",
      "Epoch 1072/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2892 - f1: 0.7285 - val_loss: 0.2872 - val_f1: 0.0680\n",
      "Epoch 1073/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2890 - f1: 0.7303 - val_loss: 0.2815 - val_f1: 0.0673\n",
      "Epoch 1074/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2881 - f1: 0.7323 - val_loss: 0.2841 - val_f1: 0.0674\n",
      "Epoch 1075/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2892 - f1: 0.7312 - val_loss: 0.2823 - val_f1: 0.0673\n",
      "Epoch 1076/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2887 - f1: 0.7300 - val_loss: 0.2885 - val_f1: 0.0680\n",
      "Epoch 1077/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2896 - f1: 0.7303 - val_loss: 0.2854 - val_f1: 0.0678\n",
      "Epoch 1078/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2893 - f1: 0.7302 - val_loss: 0.2853 - val_f1: 0.0678\n",
      "Epoch 1079/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2906 - f1: 0.7291 - val_loss: 0.2809 - val_f1: 0.0666\n",
      "Epoch 1080/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2896 - f1: 0.7297 - val_loss: 0.2844 - val_f1: 0.0676\n",
      "Epoch 1081/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2898 - f1: 0.7306 - val_loss: 0.2791 - val_f1: 0.0667\n",
      "Epoch 1082/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2898 - f1: 0.7299 - val_loss: 0.2829 - val_f1: 0.0675\n",
      "Epoch 1083/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2905 - f1: 0.7279 - val_loss: 0.2844 - val_f1: 0.0680\n",
      "Epoch 1084/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2885 - f1: 0.7294 - val_loss: 0.2865 - val_f1: 0.0678\n",
      "Epoch 1085/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2897 - f1: 0.7284 - val_loss: 0.2850 - val_f1: 0.0677\n",
      "Epoch 1086/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2902 - f1: 0.7285 - val_loss: 0.2820 - val_f1: 0.0669\n",
      "Epoch 1087/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2891 - f1: 0.7296 - val_loss: 0.2840 - val_f1: 0.0673\n",
      "Epoch 1088/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2890 - f1: 0.7294 - val_loss: 0.2842 - val_f1: 0.0677\n",
      "Epoch 1089/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2890 - f1: 0.7280 - val_loss: 0.2928 - val_f1: 0.0688\n",
      "Epoch 1090/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2892 - f1: 0.7300 - val_loss: 0.2823 - val_f1: 0.0672\n",
      "Epoch 1091/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2895 - f1: 0.7293 - val_loss: 0.2862 - val_f1: 0.0679\n",
      "Epoch 1092/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2899 - f1: 0.7289 - val_loss: 0.2839 - val_f1: 0.0674\n",
      "Epoch 1093/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2881 - f1: 0.7290 - val_loss: 0.2842 - val_f1: 0.0676\n",
      "Epoch 1094/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2877 - f1: 0.7316 - val_loss: 0.2846 - val_f1: 0.0677\n",
      "Epoch 1095/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2879 - f1: 0.7325 - val_loss: 0.2816 - val_f1: 0.0673\n",
      "Epoch 1096/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2889 - f1: 0.7291 - val_loss: 0.2866 - val_f1: 0.0680\n",
      "Epoch 1097/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2882 - f1: 0.7279 - val_loss: 0.2846 - val_f1: 0.0677\n",
      "Epoch 1098/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2887 - f1: 0.7302 - val_loss: 0.2846 - val_f1: 0.0675\n",
      "Epoch 1099/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2876 - f1: 0.7308 - val_loss: 0.2831 - val_f1: 0.0675\n",
      "Epoch 1100/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2870 - f1: 0.7310 - val_loss: 0.2826 - val_f1: 0.0675\n",
      "Epoch 1101/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2878 - f1: 0.7294 - val_loss: 0.2857 - val_f1: 0.0678\n",
      "Epoch 1102/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2877 - f1: 0.7324 - val_loss: 0.2853 - val_f1: 0.0673\n",
      "Epoch 1103/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2880 - f1: 0.7316 - val_loss: 0.2872 - val_f1: 0.0680\n",
      "Epoch 1104/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2885 - f1: 0.7292 - val_loss: 0.2809 - val_f1: 0.0672\n",
      "Epoch 1105/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2900 - f1: 0.7272 - val_loss: 0.2842 - val_f1: 0.0677\n",
      "Epoch 1106/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2902 - f1: 0.7263 - val_loss: 0.2837 - val_f1: 0.0673\n",
      "Epoch 1107/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2900 - f1: 0.7288 - val_loss: 0.2846 - val_f1: 0.0678\n",
      "Epoch 1108/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2882 - f1: 0.7304 - val_loss: 0.2843 - val_f1: 0.0677\n",
      "Epoch 1109/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2887 - f1: 0.7290 - val_loss: 0.2832 - val_f1: 0.0672\n",
      "Epoch 1110/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2904 - f1: 0.7274 - val_loss: 0.2905 - val_f1: 0.0685\n",
      "Epoch 1111/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2889 - f1: 0.7305 - val_loss: 0.2851 - val_f1: 0.0675\n",
      "Epoch 1112/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2894 - f1: 0.7278 - val_loss: 0.2851 - val_f1: 0.0676\n",
      "Epoch 1113/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2876 - f1: 0.7303 - val_loss: 0.2893 - val_f1: 0.0684\n",
      "Epoch 1114/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2874 - f1: 0.7319 - val_loss: 0.2821 - val_f1: 0.0671\n",
      "Epoch 1115/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2887 - f1: 0.7294 - val_loss: 0.2815 - val_f1: 0.0673\n",
      "Epoch 1116/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2888 - f1: 0.7314 - val_loss: 0.2881 - val_f1: 0.0681\n",
      "Epoch 1117/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2872 - f1: 0.7317 - val_loss: 0.2812 - val_f1: 0.0671\n",
      "Epoch 1118/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2886 - f1: 0.7281 - val_loss: 0.2842 - val_f1: 0.0679\n",
      "Epoch 1119/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2883 - f1: 0.7306 - val_loss: 0.2822 - val_f1: 0.0672\n",
      "Epoch 1120/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2872 - f1: 0.7329 - val_loss: 0.2848 - val_f1: 0.0677\n",
      "Epoch 1121/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2880 - f1: 0.7317 - val_loss: 0.2855 - val_f1: 0.0673\n",
      "Epoch 1122/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2884 - f1: 0.7308 - val_loss: 0.2860 - val_f1: 0.0674\n",
      "Epoch 1123/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2884 - f1: 0.7297 - val_loss: 0.2853 - val_f1: 0.0674\n",
      "Epoch 1124/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2887 - f1: 0.7301 - val_loss: 0.2874 - val_f1: 0.0681\n",
      "Epoch 1125/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2885 - f1: 0.7298 - val_loss: 0.2846 - val_f1: 0.0677\n",
      "Epoch 1126/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2886 - f1: 0.7317 - val_loss: 0.2874 - val_f1: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1127/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2890 - f1: 0.7300 - val_loss: 0.2829 - val_f1: 0.0674\n",
      "Epoch 1128/2000\n",
      " 64224/168135 [==========>...................] - ETA: 4s - loss: 0.2878 - f1: 0.7298"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2891 - f1: 0.7302 - val_loss: 0.2813 - val_f1: 0.0667\n",
      "Epoch 1137/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2894 - f1: 0.7282 - val_loss: 0.2858 - val_f1: 0.0674\n",
      "Epoch 1138/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2882 - f1: 0.7296 - val_loss: 0.2871 - val_f1: 0.0681\n",
      "Epoch 1139/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2892 - f1: 0.7287 - val_loss: 0.2852 - val_f1: 0.0675\n",
      "Epoch 1140/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2880 - f1: 0.7316 - val_loss: 0.2854 - val_f1: 0.0677\n",
      "Epoch 1141/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2884 - f1: 0.7294 - val_loss: 0.2871 - val_f1: 0.0675\n",
      "Epoch 1142/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2882 - f1: 0.7297 - val_loss: 0.2878 - val_f1: 0.0683\n",
      "Epoch 1143/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2883 - f1: 0.7309 - val_loss: 0.2843 - val_f1: 0.0672\n",
      "Epoch 1144/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2887 - f1: 0.7305 - val_loss: 0.2855 - val_f1: 0.0677\n",
      "Epoch 1145/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2878 - f1: 0.7319 - val_loss: 0.2870 - val_f1: 0.0680\n",
      "Epoch 1146/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2885 - f1: 0.7300 - val_loss: 0.2895 - val_f1: 0.0679\n",
      "Epoch 1147/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2879 - f1: 0.7317 - val_loss: 0.2818 - val_f1: 0.0670\n",
      "Epoch 1148/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2880 - f1: 0.7294 - val_loss: 0.2855 - val_f1: 0.0675\n",
      "Epoch 1149/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2881 - f1: 0.7330 - val_loss: 0.2875 - val_f1: 0.0677\n",
      "Epoch 1150/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2884 - f1: 0.7325 - val_loss: 0.2850 - val_f1: 0.0680\n",
      "Epoch 1151/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2885 - f1: 0.7325 - val_loss: 0.2810 - val_f1: 0.0666\n",
      "Epoch 1152/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2870 - f1: 0.7336 - val_loss: 0.2887 - val_f1: 0.0680\n",
      "Epoch 1153/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2884 - f1: 0.7303 - val_loss: 0.2864 - val_f1: 0.0678\n",
      "Epoch 1154/2000\n",
      "148768/168135 [=========================>....] - ETA: 0s - loss: 0.2879 - f1: 0.7302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2891 - f1: 0.7292 - val_loss: 0.2823 - val_f1: 0.0670\n",
      "Epoch 1163/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2872 - f1: 0.7344 - val_loss: 0.2862 - val_f1: 0.0675\n",
      "Epoch 1164/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2885 - f1: 0.7301 - val_loss: 0.2898 - val_f1: 0.0680\n",
      "Epoch 1165/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2886 - f1: 0.7279 - val_loss: 0.2832 - val_f1: 0.0676\n",
      "Epoch 1166/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2887 - f1: 0.7304 - val_loss: 0.2846 - val_f1: 0.0673\n",
      "Epoch 1167/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2863 - f1: 0.7305 - val_loss: 0.2817 - val_f1: 0.0674\n",
      "Epoch 1168/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2871 - f1: 0.7328 - val_loss: 0.2833 - val_f1: 0.0673\n",
      "Epoch 1169/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2876 - f1: 0.7311 - val_loss: 0.2849 - val_f1: 0.0675\n",
      "Epoch 1170/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2890 - f1: 0.7281 - val_loss: 0.2905 - val_f1: 0.0681\n",
      "Epoch 1171/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2888 - f1: 0.7307 - val_loss: 0.2857 - val_f1: 0.0677\n",
      "Epoch 1172/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2874 - f1: 0.7313 - val_loss: 0.2826 - val_f1: 0.0669\n",
      "Epoch 1173/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2889 - f1: 0.7298 - val_loss: 0.2842 - val_f1: 0.0673\n",
      "Epoch 1174/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2872 - f1: 0.7304 - val_loss: 0.2858 - val_f1: 0.0674\n",
      "Epoch 1175/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2884 - f1: 0.7312 - val_loss: 0.2804 - val_f1: 0.0667\n",
      "Epoch 1176/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2866 - f1: 0.7331 - val_loss: 0.2865 - val_f1: 0.0678\n",
      "Epoch 1177/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2869 - f1: 0.7338 - val_loss: 0.2857 - val_f1: 0.0674\n",
      "Epoch 1178/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2874 - f1: 0.7302 - val_loss: 0.2831 - val_f1: 0.0672\n",
      "Epoch 1179/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2868 - f1: 0.7311 - val_loss: 0.2812 - val_f1: 0.0669\n",
      "Epoch 1180/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2875 - f1: 0.7298 - val_loss: 0.2851 - val_f1: 0.0674\n",
      "Epoch 1181/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2870 - f1: 0.7344 - val_loss: 0.2898 - val_f1: 0.0680\n",
      "Epoch 1182/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2869 - f1: 0.7324 - val_loss: 0.2789 - val_f1: 0.0665\n",
      "Epoch 1183/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2871 - f1: 0.7324 - val_loss: 0.2844 - val_f1: 0.0673\n",
      "Epoch 1184/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2875 - f1: 0.7313 - val_loss: 0.2871 - val_f1: 0.0678\n",
      "Epoch 1185/2000\n",
      "116640/168135 [===================>..........] - ETA: 2s - loss: 0.2877 - f1: 0.7331"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2886 - f1: 0.7296 - val_loss: 0.2858 - val_f1: 0.0675\n",
      "Epoch 1195/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2867 - f1: 0.7310 - val_loss: 0.2899 - val_f1: 0.0684\n",
      "Epoch 1196/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2878 - f1: 0.7300 - val_loss: 0.2884 - val_f1: 0.0681\n",
      "Epoch 1197/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2883 - f1: 0.7273 - val_loss: 0.2849 - val_f1: 0.0675\n",
      "Epoch 1198/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2892 - f1: 0.7276 - val_loss: 0.2859 - val_f1: 0.0676\n",
      "Epoch 1199/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2880 - f1: 0.7321 - val_loss: 0.2867 - val_f1: 0.0680\n",
      "Epoch 1200/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2867 - f1: 0.7332 - val_loss: 0.2806 - val_f1: 0.0670\n",
      "Epoch 1201/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2880 - f1: 0.7318 - val_loss: 0.2837 - val_f1: 0.0674\n",
      "Epoch 1202/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2876 - f1: 0.7308 - val_loss: 0.2862 - val_f1: 0.0678\n",
      "Epoch 1203/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2882 - f1: 0.7311 - val_loss: 0.2882 - val_f1: 0.0682\n",
      "Epoch 1204/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2859 - f1: 0.7332 - val_loss: 0.2866 - val_f1: 0.0675\n",
      "Epoch 1205/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2867 - f1: 0.7316 - val_loss: 0.2876 - val_f1: 0.0678\n",
      "Epoch 1206/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2882 - f1: 0.7307 - val_loss: 0.2821 - val_f1: 0.0671\n",
      "Epoch 1207/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2877 - f1: 0.7317 - val_loss: 0.2840 - val_f1: 0.0676\n",
      "Epoch 1208/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2875 - f1: 0.7315 - val_loss: 0.2902 - val_f1: 0.0678\n",
      "Epoch 1209/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2870 - f1: 0.7317 - val_loss: 0.2850 - val_f1: 0.0675\n",
      "Epoch 1210/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2881 - f1: 0.7305 - val_loss: 0.2818 - val_f1: 0.0670\n",
      "Epoch 1211/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2892 - f1: 0.7307 - val_loss: 0.2839 - val_f1: 0.0674\n",
      "Epoch 1212/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2867 - f1: 0.7340 - val_loss: 0.2834 - val_f1: 0.0668\n",
      "Epoch 1213/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2879 - f1: 0.7301 - val_loss: 0.2883 - val_f1: 0.0683\n",
      "Epoch 1214/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2873 - f1: 0.7309 - val_loss: 0.2862 - val_f1: 0.0676\n",
      "Epoch 1215/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2873 - f1: 0.7320 - val_loss: 0.2862 - val_f1: 0.0676\n",
      "Epoch 1216/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2866 - f1: 0.7337 - val_loss: 0.2870 - val_f1: 0.0677\n",
      "Epoch 1217/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2884 - f1: 0.7302 - val_loss: 0.2869 - val_f1: 0.0674\n",
      "Epoch 1218/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2871 - f1: 0.7322 - val_loss: 0.2843 - val_f1: 0.0673\n",
      "Epoch 1219/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2877 - f1: 0.7303 - val_loss: 0.2871 - val_f1: 0.0681\n",
      "Epoch 1220/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2861 - f1: 0.7306 - val_loss: 0.2828 - val_f1: 0.0671\n",
      "Epoch 1221/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2864 - f1: 0.7325 - val_loss: 0.2856 - val_f1: 0.0676\n",
      "Epoch 1222/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2873 - f1: 0.7327 - val_loss: 0.2874 - val_f1: 0.0674\n",
      "Epoch 1223/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2869 - f1: 0.7328 - val_loss: 0.2868 - val_f1: 0.0680\n",
      "Epoch 1224/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2879 - f1: 0.7317 - val_loss: 0.2857 - val_f1: 0.0671\n",
      "Epoch 1225/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2873 - f1: 0.7329 - val_loss: 0.2839 - val_f1: 0.0674\n",
      "Epoch 1226/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2872 - f1: 0.7320 - val_loss: 0.2865 - val_f1: 0.0674\n",
      "Epoch 1227/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2884 - f1: 0.7304 - val_loss: 0.2867 - val_f1: 0.0676\n",
      "Epoch 1228/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2860 - f1: 0.7330 - val_loss: 0.2861 - val_f1: 0.0674\n",
      "Epoch 1229/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2875 - f1: 0.7309 - val_loss: 0.2804 - val_f1: 0.0670\n",
      "Epoch 1230/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2870 - f1: 0.7308 - val_loss: 0.2852 - val_f1: 0.0677\n",
      "Epoch 1231/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2862 - f1: 0.7322 - val_loss: 0.2869 - val_f1: 0.0678\n",
      "Epoch 1232/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2866 - f1: 0.7338 - val_loss: 0.2832 - val_f1: 0.0669\n",
      "Epoch 1233/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2872 - f1: 0.7319 - val_loss: 0.2833 - val_f1: 0.0670\n",
      "Epoch 1234/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2860 - f1: 0.7320 - val_loss: 0.2814 - val_f1: 0.0666\n",
      "Epoch 1235/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2869 - f1: 0.7328 - val_loss: 0.2824 - val_f1: 0.0668\n",
      "Epoch 1236/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2875 - f1: 0.7331 - val_loss: 0.2859 - val_f1: 0.0676\n",
      "Epoch 1237/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2876 - f1: 0.7305 - val_loss: 0.2901 - val_f1: 0.0681\n",
      "Epoch 1238/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2880 - f1: 0.7318 - val_loss: 0.2835 - val_f1: 0.0668\n",
      "Epoch 1239/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2880 - f1: 0.7328 - val_loss: 0.2826 - val_f1: 0.0667\n",
      "Epoch 1240/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2872 - f1: 0.7336 - val_loss: 0.2845 - val_f1: 0.0675\n",
      "Epoch 1241/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2872 - f1: 0.7319 - val_loss: 0.2819 - val_f1: 0.0669\n",
      "Epoch 1242/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2872 - f1: 0.7309 - val_loss: 0.2818 - val_f1: 0.0666\n",
      "Epoch 1243/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2870 - f1: 0.7315 - val_loss: 0.2803 - val_f1: 0.0668\n",
      "Epoch 1244/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2876 - f1: 0.7308 - val_loss: 0.2870 - val_f1: 0.0678\n",
      "Epoch 1245/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2871 - f1: 0.7310 - val_loss: 0.2809 - val_f1: 0.0670\n",
      "Epoch 1246/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2868 - f1: 0.7312 - val_loss: 0.2842 - val_f1: 0.0673\n",
      "Epoch 1247/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2848 - f1: 0.7356 - val_loss: 0.2865 - val_f1: 0.0676\n",
      "Epoch 1248/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2861 - f1: 0.7330 - val_loss: 0.2846 - val_f1: 0.0673\n",
      "Epoch 1249/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2861 - f1: 0.7337 - val_loss: 0.2861 - val_f1: 0.0676\n",
      "Epoch 1250/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2867 - f1: 0.7324 - val_loss: 0.2855 - val_f1: 0.0675\n",
      "Epoch 1251/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2850 - f1: 0.7333 - val_loss: 0.2883 - val_f1: 0.0678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1252/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2878 - f1: 0.7314 - val_loss: 0.2846 - val_f1: 0.0675\n",
      "Epoch 1253/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2867 - f1: 0.7310 - val_loss: 0.2839 - val_f1: 0.0673\n",
      "Epoch 1254/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2870 - f1: 0.7313 - val_loss: 0.2876 - val_f1: 0.0679\n",
      "Epoch 1255/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2866 - f1: 0.7311 - val_loss: 0.2847 - val_f1: 0.0677\n",
      "Epoch 1256/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2866 - f1: 0.7339 - val_loss: 0.2918 - val_f1: 0.0684\n",
      "Epoch 1257/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2871 - f1: 0.7327 - val_loss: 0.2906 - val_f1: 0.0685\n",
      "Epoch 1258/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2873 - f1: 0.7325 - val_loss: 0.2870 - val_f1: 0.0675\n",
      "Epoch 1259/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2867 - f1: 0.7331 - val_loss: 0.2851 - val_f1: 0.0676\n",
      "Epoch 1260/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2856 - f1: 0.7334 - val_loss: 0.2882 - val_f1: 0.0680\n",
      "Epoch 1261/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2856 - f1: 0.7342 - val_loss: 0.2890 - val_f1: 0.0678\n",
      "Epoch 1262/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2859 - f1: 0.7336 - val_loss: 0.2895 - val_f1: 0.0679\n",
      "Epoch 1263/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2865 - f1: 0.7343 - val_loss: 0.2835 - val_f1: 0.0670\n",
      "Epoch 1264/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2873 - f1: 0.7319 - val_loss: 0.2809 - val_f1: 0.0665\n",
      "Epoch 1265/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2866 - f1: 0.7314 - val_loss: 0.2839 - val_f1: 0.0674\n",
      "Epoch 1266/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2868 - f1: 0.7341 - val_loss: 0.2847 - val_f1: 0.0675\n",
      "Epoch 1267/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2853 - f1: 0.7333 - val_loss: 0.2900 - val_f1: 0.0683\n",
      "Epoch 1268/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2872 - f1: 0.7322 - val_loss: 0.2869 - val_f1: 0.0676\n",
      "Epoch 1269/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2866 - f1: 0.7320 - val_loss: 0.2919 - val_f1: 0.0680\n",
      "Epoch 1270/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2868 - f1: 0.7339 - val_loss: 0.2839 - val_f1: 0.0673\n",
      "Epoch 1271/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2862 - f1: 0.7331 - val_loss: 0.2833 - val_f1: 0.0672\n",
      "Epoch 1272/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2875 - f1: 0.7320 - val_loss: 0.2864 - val_f1: 0.0678\n",
      "Epoch 1273/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2858 - f1: 0.7330 - val_loss: 0.2858 - val_f1: 0.0679\n",
      "Epoch 1274/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2877 - f1: 0.7345 - val_loss: 0.2850 - val_f1: 0.0672\n",
      "Epoch 1275/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2851 - f1: 0.7339 - val_loss: 0.2880 - val_f1: 0.0678\n",
      "Epoch 1276/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2869 - f1: 0.7323 - val_loss: 0.2829 - val_f1: 0.0672\n",
      "Epoch 1277/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2871 - f1: 0.7325 - val_loss: 0.2889 - val_f1: 0.0680\n",
      "Epoch 1278/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2862 - f1: 0.7318 - val_loss: 0.2864 - val_f1: 0.0675\n",
      "Epoch 1279/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2879 - f1: 0.7310 - val_loss: 0.2850 - val_f1: 0.0679\n",
      "Epoch 1280/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2859 - f1: 0.7345 - val_loss: 0.2887 - val_f1: 0.0681\n",
      "Epoch 1281/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2876 - f1: 0.7322 - val_loss: 0.2856 - val_f1: 0.0678\n",
      "Epoch 1282/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2858 - f1: 0.7336 - val_loss: 0.2872 - val_f1: 0.0679\n",
      "Epoch 1283/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2862 - f1: 0.7315 - val_loss: 0.2888 - val_f1: 0.0684\n",
      "Epoch 1284/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2857 - f1: 0.7336 - val_loss: 0.2891 - val_f1: 0.0681\n",
      "Epoch 1285/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2852 - f1: 0.7343 - val_loss: 0.2886 - val_f1: 0.0681\n",
      "Epoch 1286/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2878 - f1: 0.7332 - val_loss: 0.2808 - val_f1: 0.0669\n",
      "Epoch 1287/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2871 - f1: 0.7321 - val_loss: 0.2822 - val_f1: 0.0674\n",
      "Epoch 1288/2000\n",
      " 66656/168135 [==========>...................] - ETA: 4s - loss: 0.2848 - f1: 0.7363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2861 - f1: 0.7335 - val_loss: 0.2837 - val_f1: 0.0673\n",
      "Epoch 1298/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2870 - f1: 0.7322 - val_loss: 0.2854 - val_f1: 0.0680\n",
      "Epoch 1299/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2883 - f1: 0.7297 - val_loss: 0.2833 - val_f1: 0.0673\n",
      "Epoch 1300/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2854 - f1: 0.7333 - val_loss: 0.2877 - val_f1: 0.0678\n",
      "Epoch 1301/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2870 - f1: 0.7331 - val_loss: 0.2836 - val_f1: 0.0670\n",
      "Epoch 1302/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2857 - f1: 0.7350 - val_loss: 0.2891 - val_f1: 0.0684\n",
      "Epoch 1303/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2867 - f1: 0.7351 - val_loss: 0.2854 - val_f1: 0.0675\n",
      "Epoch 1304/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2859 - f1: 0.7328 - val_loss: 0.2779 - val_f1: 0.0659\n",
      "Epoch 1305/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2852 - f1: 0.7340 - val_loss: 0.2844 - val_f1: 0.0671\n",
      "Epoch 1306/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2856 - f1: 0.7337 - val_loss: 0.2872 - val_f1: 0.0678\n",
      "Epoch 1307/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2876 - f1: 0.7298 - val_loss: 0.2862 - val_f1: 0.0675\n",
      "Epoch 1308/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2869 - f1: 0.7313 - val_loss: 0.2803 - val_f1: 0.0670\n",
      "Epoch 1309/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2852 - f1: 0.7343 - val_loss: 0.2830 - val_f1: 0.0669\n",
      "Epoch 1310/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2866 - f1: 0.7327 - val_loss: 0.2880 - val_f1: 0.0678\n",
      "Epoch 1311/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2864 - f1: 0.7309 - val_loss: 0.2894 - val_f1: 0.0680\n",
      "Epoch 1312/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2849 - f1: 0.7334 - val_loss: 0.2831 - val_f1: 0.0675\n",
      "Epoch 1313/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2867 - f1: 0.7326 - val_loss: 0.2885 - val_f1: 0.0681\n",
      "Epoch 1314/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2860 - f1: 0.7340 - val_loss: 0.2863 - val_f1: 0.0677\n",
      "Epoch 1315/2000\n",
      "126656/168135 [=====================>........] - ETA: 1s - loss: 0.2854 - f1: 0.7350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2854 - f1: 0.7350 - val_loss: 0.2855 - val_f1: 0.0673\n",
      "Epoch 1329/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2853 - f1: 0.7331 - val_loss: 0.2866 - val_f1: 0.0677\n",
      "Epoch 1330/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2866 - f1: 0.7333 - val_loss: 0.2838 - val_f1: 0.0672\n",
      "Epoch 1331/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2868 - f1: 0.7321 - val_loss: 0.2827 - val_f1: 0.0674\n",
      "Epoch 1332/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2850 - f1: 0.7352 - val_loss: 0.2845 - val_f1: 0.0674\n",
      "Epoch 1333/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2853 - f1: 0.7337 - val_loss: 0.2827 - val_f1: 0.0674\n",
      "Epoch 1334/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2844 - f1: 0.7343 - val_loss: 0.2843 - val_f1: 0.0669\n",
      "Epoch 1335/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2859 - f1: 0.7331 - val_loss: 0.2863 - val_f1: 0.0675\n",
      "Epoch 1336/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2849 - f1: 0.7326 - val_loss: 0.2904 - val_f1: 0.0686\n",
      "Epoch 1337/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2857 - f1: 0.7341 - val_loss: 0.2934 - val_f1: 0.0685\n",
      "Epoch 1338/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2855 - f1: 0.7353 - val_loss: 0.2891 - val_f1: 0.0682\n",
      "Epoch 1339/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2856 - f1: 0.7349 - val_loss: 0.2863 - val_f1: 0.0680\n",
      "Epoch 1340/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2862 - f1: 0.7343 - val_loss: 0.2873 - val_f1: 0.0679\n",
      "Epoch 1341/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2836 - f1: 0.7364 - val_loss: 0.2861 - val_f1: 0.0672\n",
      "Epoch 1342/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2848 - f1: 0.7344 - val_loss: 0.2820 - val_f1: 0.0664\n",
      "Epoch 1343/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2870 - f1: 0.7314 - val_loss: 0.2886 - val_f1: 0.0681\n",
      "Epoch 1344/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2866 - f1: 0.7353 - val_loss: 0.2881 - val_f1: 0.0681\n",
      "Epoch 1345/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2852 - f1: 0.7354 - val_loss: 0.2876 - val_f1: 0.0681\n",
      "Epoch 1346/2000\n",
      "  9408/168135 [>.............................] - ETA: 7s - loss: 0.2885 - f1: 0.7281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2848 - f1: 0.7346 - val_loss: 0.2853 - val_f1: 0.0672\n",
      "Epoch 1357/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2858 - f1: 0.7335 - val_loss: 0.2882 - val_f1: 0.0676\n",
      "Epoch 1358/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2859 - f1: 0.7349 - val_loss: 0.2883 - val_f1: 0.0682\n",
      "Epoch 1359/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2852 - f1: 0.7323 - val_loss: 0.2817 - val_f1: 0.0669\n",
      "Epoch 1360/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2873 - f1: 0.7334 - val_loss: 0.2850 - val_f1: 0.0677\n",
      "Epoch 1361/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2853 - f1: 0.7338 - val_loss: 0.2831 - val_f1: 0.0671\n",
      "Epoch 1362/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2854 - f1: 0.7338 - val_loss: 0.2875 - val_f1: 0.0676\n",
      "Epoch 1363/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2844 - f1: 0.7351 - val_loss: 0.2902 - val_f1: 0.0684\n",
      "Epoch 1364/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2854 - f1: 0.7351 - val_loss: 0.2858 - val_f1: 0.0676\n",
      "Epoch 1365/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2850 - f1: 0.7345 - val_loss: 0.2873 - val_f1: 0.0678\n",
      "Epoch 1366/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2847 - f1: 0.7348 - val_loss: 0.2908 - val_f1: 0.0679\n",
      "Epoch 1367/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2860 - f1: 0.7329 - val_loss: 0.2817 - val_f1: 0.0663\n",
      "Epoch 1368/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2867 - f1: 0.7319 - val_loss: 0.2837 - val_f1: 0.0671\n",
      "Epoch 1369/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2851 - f1: 0.7369 - val_loss: 0.2844 - val_f1: 0.0673\n",
      "Epoch 1370/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2860 - f1: 0.7328 - val_loss: 0.2862 - val_f1: 0.0675\n",
      "Epoch 1371/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2865 - f1: 0.7329 - val_loss: 0.2860 - val_f1: 0.0675\n",
      "Epoch 1372/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2850 - f1: 0.7335 - val_loss: 0.2796 - val_f1: 0.0662\n",
      "Epoch 1373/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2866 - f1: 0.7331 - val_loss: 0.2866 - val_f1: 0.0675\n",
      "Epoch 1374/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2861 - f1: 0.7321 - val_loss: 0.2860 - val_f1: 0.0678\n",
      "Epoch 1375/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2865 - f1: 0.7346 - val_loss: 0.2879 - val_f1: 0.0680\n",
      "Epoch 1376/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2851 - f1: 0.7342 - val_loss: 0.2935 - val_f1: 0.0687\n",
      "Epoch 1377/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2847 - f1: 0.7336 - val_loss: 0.2824 - val_f1: 0.0667\n",
      "Epoch 1378/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2859 - f1: 0.7318 - val_loss: 0.2853 - val_f1: 0.0680\n",
      "Epoch 1379/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2860 - f1: 0.7333 - val_loss: 0.2822 - val_f1: 0.0669\n",
      "Epoch 1380/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2856 - f1: 0.7347 - val_loss: 0.2892 - val_f1: 0.0683\n",
      "Epoch 1381/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2849 - f1: 0.7348 - val_loss: 0.2809 - val_f1: 0.0666\n",
      "Epoch 1382/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2861 - f1: 0.7332 - val_loss: 0.2827 - val_f1: 0.0666\n",
      "Epoch 1383/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2845 - f1: 0.7358 - val_loss: 0.2839 - val_f1: 0.0670\n",
      "Epoch 1384/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2863 - f1: 0.7340 - val_loss: 0.2826 - val_f1: 0.0666\n",
      "Epoch 1385/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2852 - f1: 0.7331 - val_loss: 0.2845 - val_f1: 0.0674\n",
      "Epoch 1386/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2844 - f1: 0.7362 - val_loss: 0.2882 - val_f1: 0.0676\n",
      "Epoch 1387/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2858 - f1: 0.7336 - val_loss: 0.2856 - val_f1: 0.0677\n",
      "Epoch 1388/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2863 - f1: 0.7334 - val_loss: 0.2819 - val_f1: 0.0670\n",
      "Epoch 1389/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2859 - f1: 0.7336 - val_loss: 0.2842 - val_f1: 0.0672\n",
      "Epoch 1390/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2846 - f1: 0.7357 - val_loss: 0.2859 - val_f1: 0.0675\n",
      "Epoch 1391/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2844 - f1: 0.7369 - val_loss: 0.2830 - val_f1: 0.0675\n",
      "Epoch 1392/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2844 - f1: 0.7368 - val_loss: 0.2802 - val_f1: 0.0663\n",
      "Epoch 1393/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2847 - f1: 0.7336 - val_loss: 0.2857 - val_f1: 0.0673\n",
      "Epoch 1394/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2854 - f1: 0.7331 - val_loss: 0.2875 - val_f1: 0.0679\n",
      "Epoch 1395/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2843 - f1: 0.7354 - val_loss: 0.2858 - val_f1: 0.0678\n",
      "Epoch 1396/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2854 - f1: 0.7337 - val_loss: 0.2884 - val_f1: 0.0678\n",
      "Epoch 1397/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2853 - f1: 0.7341 - val_loss: 0.2877 - val_f1: 0.0677\n",
      "Epoch 1398/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2847 - f1: 0.7362 - val_loss: 0.2857 - val_f1: 0.0673\n",
      "Epoch 1399/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2859 - f1: 0.7357 - val_loss: 0.2823 - val_f1: 0.0671\n",
      "Epoch 1400/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2863 - f1: 0.7317 - val_loss: 0.2873 - val_f1: 0.0676\n",
      "Epoch 1401/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2862 - f1: 0.7316 - val_loss: 0.2769 - val_f1: 0.0659\n",
      "Epoch 1402/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2846 - f1: 0.7349 - val_loss: 0.2903 - val_f1: 0.0683\n",
      "Epoch 1403/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2845 - f1: 0.7339 - val_loss: 0.2841 - val_f1: 0.0672\n",
      "Epoch 1404/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2850 - f1: 0.7336 - val_loss: 0.2859 - val_f1: 0.0677\n",
      "Epoch 1405/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2854 - f1: 0.7340 - val_loss: 0.2892 - val_f1: 0.0681\n",
      "Epoch 1406/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2863 - f1: 0.7348 - val_loss: 0.2824 - val_f1: 0.0675\n",
      "Epoch 1407/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2868 - f1: 0.7330 - val_loss: 0.2862 - val_f1: 0.0676\n",
      "Epoch 1408/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2841 - f1: 0.7367 - val_loss: 0.2838 - val_f1: 0.0673\n",
      "Epoch 1409/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2852 - f1: 0.7331 - val_loss: 0.2851 - val_f1: 0.0675\n",
      "Epoch 1410/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2856 - f1: 0.7348 - val_loss: 0.2878 - val_f1: 0.0679\n",
      "Epoch 1411/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2859 - f1: 0.7334 - val_loss: 0.2885 - val_f1: 0.0682\n",
      "Epoch 1412/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2847 - f1: 0.7359 - val_loss: 0.2838 - val_f1: 0.0676\n",
      "Epoch 1413/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2849 - f1: 0.7339 - val_loss: 0.2874 - val_f1: 0.0680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1414/2000\n",
      "110048/168135 [==================>...........] - ETA: 2s - loss: 0.2853 - f1: 0.73"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2853 - f1: 0.7353 - val_loss: 0.2848 - val_f1: 0.0677\n",
      "Epoch 1425/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2832 - f1: 0.7366 - val_loss: 0.2910 - val_f1: 0.0682\n",
      "Epoch 1426/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2848 - f1: 0.7338 - val_loss: 0.2824 - val_f1: 0.0670\n",
      "Epoch 1427/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2848 - f1: 0.7358 - val_loss: 0.2882 - val_f1: 0.0676\n",
      "Epoch 1428/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2849 - f1: 0.7362 - val_loss: 0.2840 - val_f1: 0.0667\n",
      "Epoch 1429/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2855 - f1: 0.7328 - val_loss: 0.2810 - val_f1: 0.0667\n",
      "Epoch 1430/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2849 - f1: 0.7342 - val_loss: 0.2823 - val_f1: 0.0668\n",
      "Epoch 1431/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2862 - f1: 0.7326 - val_loss: 0.2870 - val_f1: 0.0677\n",
      "Epoch 1432/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2844 - f1: 0.7358 - val_loss: 0.2843 - val_f1: 0.0671\n",
      "Epoch 1433/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2858 - f1: 0.7341 - val_loss: 0.2843 - val_f1: 0.0669\n",
      "Epoch 1434/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2850 - f1: 0.7333 - val_loss: 0.2861 - val_f1: 0.0679\n",
      "Epoch 1435/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2841 - f1: 0.7369 - val_loss: 0.2865 - val_f1: 0.0682\n",
      "Epoch 1436/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2844 - f1: 0.7361 - val_loss: 0.2836 - val_f1: 0.0670\n",
      "Epoch 1437/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2857 - f1: 0.7343 - val_loss: 0.2913 - val_f1: 0.0686\n",
      "Epoch 1438/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2848 - f1: 0.7355 - val_loss: 0.2855 - val_f1: 0.0676\n",
      "Epoch 1439/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2856 - f1: 0.7339 - val_loss: 0.2875 - val_f1: 0.0678\n",
      "Epoch 1440/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2840 - f1: 0.7354 - val_loss: 0.2864 - val_f1: 0.0675\n",
      "Epoch 1441/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2848 - f1: 0.7355 - val_loss: 0.2873 - val_f1: 0.0674\n",
      "Epoch 1442/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2839 - f1: 0.7382 - val_loss: 0.2906 - val_f1: 0.0682\n",
      "Epoch 1443/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2842 - f1: 0.7367 - val_loss: 0.2859 - val_f1: 0.0677\n",
      "Epoch 1444/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2838 - f1: 0.7361 - val_loss: 0.2865 - val_f1: 0.0675\n",
      "Epoch 1445/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2862 - f1: 0.7321 - val_loss: 0.2838 - val_f1: 0.0669\n",
      "Epoch 1446/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2843 - f1: 0.7361 - val_loss: 0.2880 - val_f1: 0.0679\n",
      "Epoch 1447/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2836 - f1: 0.7350 - val_loss: 0.2886 - val_f1: 0.0682\n",
      "Epoch 1448/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2854 - f1: 0.7331 - val_loss: 0.2845 - val_f1: 0.0675\n",
      "Epoch 1449/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2859 - f1: 0.7317 - val_loss: 0.2842 - val_f1: 0.0670\n",
      "Epoch 1450/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2854 - f1: 0.7347 - val_loss: 0.2869 - val_f1: 0.0675\n",
      "Epoch 1451/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2835 - f1: 0.7347 - val_loss: 0.2878 - val_f1: 0.0682\n",
      "Epoch 1452/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2860 - f1: 0.7330 - val_loss: 0.2854 - val_f1: 0.0679\n",
      "Epoch 1453/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2848 - f1: 0.7358 - val_loss: 0.2896 - val_f1: 0.0678\n",
      "Epoch 1454/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2840 - f1: 0.7354 - val_loss: 0.2885 - val_f1: 0.0676\n",
      "Epoch 1455/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2846 - f1: 0.7362 - val_loss: 0.2854 - val_f1: 0.0678\n",
      "Epoch 1456/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2863 - f1: 0.7331 - val_loss: 0.2851 - val_f1: 0.0677\n",
      "Epoch 1457/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2843 - f1: 0.7353 - val_loss: 0.2840 - val_f1: 0.0674\n",
      "Epoch 1458/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2852 - f1: 0.7354 - val_loss: 0.2801 - val_f1: 0.0668\n",
      "Epoch 1459/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2844 - f1: 0.7345 - val_loss: 0.2832 - val_f1: 0.0667\n",
      "Epoch 1460/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2850 - f1: 0.7341 - val_loss: 0.2922 - val_f1: 0.0688\n",
      "Epoch 1461/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2841 - f1: 0.7346 - val_loss: 0.2885 - val_f1: 0.0681\n",
      "Epoch 1462/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2841 - f1: 0.7361 - val_loss: 0.2836 - val_f1: 0.0668\n",
      "Epoch 1463/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2835 - f1: 0.7390 - val_loss: 0.2878 - val_f1: 0.0676\n",
      "Epoch 1464/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2841 - f1: 0.7364 - val_loss: 0.2870 - val_f1: 0.0675\n",
      "Epoch 1465/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2840 - f1: 0.7349 - val_loss: 0.2864 - val_f1: 0.0675\n",
      "Epoch 1466/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2844 - f1: 0.7359 - val_loss: 0.2904 - val_f1: 0.0683\n",
      "Epoch 1467/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2852 - f1: 0.7336 - val_loss: 0.2866 - val_f1: 0.0679\n",
      "Epoch 1468/2000\n",
      "126016/168135 [=====================>........] - ETA: 1s - loss: 0.2846 - f1: 0.7344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2847 - f1: 0.7363 - val_loss: 0.2865 - val_f1: 0.0673\n",
      "Epoch 1479/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2846 - f1: 0.7359 - val_loss: 0.2882 - val_f1: 0.0678\n",
      "Epoch 1480/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2832 - f1: 0.7375 - val_loss: 0.2846 - val_f1: 0.0675\n",
      "Epoch 1481/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2843 - f1: 0.7355 - val_loss: 0.2813 - val_f1: 0.0665\n",
      "Epoch 1482/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2838 - f1: 0.7369 - val_loss: 0.2860 - val_f1: 0.0673\n",
      "Epoch 1483/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2843 - f1: 0.7373 - val_loss: 0.2848 - val_f1: 0.0672\n",
      "Epoch 1484/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2843 - f1: 0.7357 - val_loss: 0.2904 - val_f1: 0.0682\n",
      "Epoch 1485/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2852 - f1: 0.7368 - val_loss: 0.2888 - val_f1: 0.0678\n",
      "Epoch 1486/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2848 - f1: 0.7348 - val_loss: 0.2864 - val_f1: 0.0679\n",
      "Epoch 1487/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2843 - f1: 0.7368 - val_loss: 0.2816 - val_f1: 0.0668\n",
      "Epoch 1488/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2841 - f1: 0.7365 - val_loss: 0.2864 - val_f1: 0.0675\n",
      "Epoch 1489/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2847 - f1: 0.7353 - val_loss: 0.2833 - val_f1: 0.0670\n",
      "Epoch 1490/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2846 - f1: 0.7356 - val_loss: 0.2863 - val_f1: 0.0676\n",
      "Epoch 1491/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2837 - f1: 0.7361 - val_loss: 0.2840 - val_f1: 0.0673\n",
      "Epoch 1492/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2820 - f1: 0.7379 - val_loss: 0.2860 - val_f1: 0.0673\n",
      "Epoch 1493/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2839 - f1: 0.7341 - val_loss: 0.2870 - val_f1: 0.0675\n",
      "Epoch 1494/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2837 - f1: 0.7347 - val_loss: 0.2869 - val_f1: 0.0675\n",
      "Epoch 1495/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2850 - f1: 0.7346 - val_loss: 0.2866 - val_f1: 0.0677\n",
      "Epoch 1496/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2841 - f1: 0.7363 - val_loss: 0.2875 - val_f1: 0.0677\n",
      "Epoch 1497/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2842 - f1: 0.7354 - val_loss: 0.2841 - val_f1: 0.0671\n",
      "Epoch 1498/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2849 - f1: 0.7352 - val_loss: 0.2870 - val_f1: 0.0678\n",
      "Epoch 1499/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2843 - f1: 0.7378 - val_loss: 0.2882 - val_f1: 0.0683\n",
      "Epoch 1500/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2843 - f1: 0.7360 - val_loss: 0.2879 - val_f1: 0.0676\n",
      "Epoch 1501/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2844 - f1: 0.7344 - val_loss: 0.2851 - val_f1: 0.0672\n",
      "Epoch 1502/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2836 - f1: 0.7367 - val_loss: 0.2835 - val_f1: 0.0671\n",
      "Epoch 1503/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2830 - f1: 0.7368 - val_loss: 0.2877 - val_f1: 0.0675\n",
      "Epoch 1504/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2836 - f1: 0.7356 - val_loss: 0.2863 - val_f1: 0.0677\n",
      "Epoch 1505/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2824 - f1: 0.7386 - val_loss: 0.2866 - val_f1: 0.0678\n",
      "Epoch 1506/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2846 - f1: 0.7352 - val_loss: 0.2898 - val_f1: 0.0681\n",
      "Epoch 1507/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2843 - f1: 0.7337 - val_loss: 0.2867 - val_f1: 0.0679\n",
      "Epoch 1508/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2840 - f1: 0.7381 - val_loss: 0.2829 - val_f1: 0.0669\n",
      "Epoch 1509/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2837 - f1: 0.7352 - val_loss: 0.2905 - val_f1: 0.0678\n",
      "Epoch 1510/2000\n",
      " 87392/168135 [==============>...............] - ETA: 3s - loss: 0.2820 - f1: 0.7420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2835 - f1: 0.7359 - val_loss: 0.2904 - val_f1: 0.0682\n",
      "Epoch 1520/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2845 - f1: 0.7359 - val_loss: 0.2891 - val_f1: 0.0679\n",
      "Epoch 1521/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2838 - f1: 0.7354 - val_loss: 0.2802 - val_f1: 0.0665\n",
      "Epoch 1522/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2841 - f1: 0.7357 - val_loss: 0.2848 - val_f1: 0.0674\n",
      "Epoch 1523/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2828 - f1: 0.7386 - val_loss: 0.2890 - val_f1: 0.0677\n",
      "Epoch 1524/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2837 - f1: 0.7371 - val_loss: 0.2894 - val_f1: 0.0676\n",
      "Epoch 1525/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2839 - f1: 0.7364 - val_loss: 0.2854 - val_f1: 0.0672\n",
      "Epoch 1526/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2833 - f1: 0.7348 - val_loss: 0.2875 - val_f1: 0.0675\n",
      "Epoch 1527/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2848 - f1: 0.7358 - val_loss: 0.2941 - val_f1: 0.0689\n",
      "Epoch 1528/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2833 - f1: 0.7360 - val_loss: 0.2851 - val_f1: 0.0677\n",
      "Epoch 1529/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2841 - f1: 0.7336 - val_loss: 0.2830 - val_f1: 0.0672\n",
      "Epoch 1530/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2844 - f1: 0.7362 - val_loss: 0.2864 - val_f1: 0.0677\n",
      "Epoch 1531/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2852 - f1: 0.7357 - val_loss: 0.2848 - val_f1: 0.0676\n",
      "Epoch 1532/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2845 - f1: 0.7358 - val_loss: 0.2879 - val_f1: 0.0677\n",
      "Epoch 1533/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2833 - f1: 0.7376 - val_loss: 0.2876 - val_f1: 0.0677\n",
      "Epoch 1534/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2840 - f1: 0.7341 - val_loss: 0.2907 - val_f1: 0.0681\n",
      "Epoch 1535/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2826 - f1: 0.7386 - val_loss: 0.2904 - val_f1: 0.0682\n",
      "Epoch 1536/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2828 - f1: 0.7381 - val_loss: 0.2933 - val_f1: 0.0685\n",
      "Epoch 1537/2000\n",
      "133408/168135 [======================>.......] - ETA: 1s - loss: 0.2855 - f1: 0.7344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2836 - f1: 0.7359 - val_loss: 0.2842 - val_f1: 0.0667\n",
      "Epoch 1549/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2845 - f1: 0.7349 - val_loss: 0.2870 - val_f1: 0.0675\n",
      "Epoch 1550/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2840 - f1: 0.7391 - val_loss: 0.2865 - val_f1: 0.0675\n",
      "Epoch 1551/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2824 - f1: 0.7389 - val_loss: 0.2893 - val_f1: 0.0677\n",
      "Epoch 1552/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2851 - f1: 0.7357 - val_loss: 0.2858 - val_f1: 0.0676\n",
      "Epoch 1553/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2838 - f1: 0.7358 - val_loss: 0.2908 - val_f1: 0.0681\n",
      "Epoch 1554/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2830 - f1: 0.7377 - val_loss: 0.2866 - val_f1: 0.0674\n",
      "Epoch 1555/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2842 - f1: 0.7369 - val_loss: 0.2872 - val_f1: 0.0676\n",
      "Epoch 1556/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2841 - f1: 0.7369 - val_loss: 0.2840 - val_f1: 0.0667\n",
      "Epoch 1557/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2832 - f1: 0.7348 - val_loss: 0.2862 - val_f1: 0.0676\n",
      "Epoch 1558/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2832 - f1: 0.7360 - val_loss: 0.2825 - val_f1: 0.0667\n",
      "Epoch 1559/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2828 - f1: 0.7384 - val_loss: 0.2923 - val_f1: 0.0680\n",
      "Epoch 1560/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2839 - f1: 0.7383 - val_loss: 0.2914 - val_f1: 0.0679\n",
      "Epoch 1561/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2836 - f1: 0.7367 - val_loss: 0.2874 - val_f1: 0.0677\n",
      "Epoch 1562/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2841 - f1: 0.7345 - val_loss: 0.2839 - val_f1: 0.0670\n",
      "Epoch 1563/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2830 - f1: 0.7370 - val_loss: 0.2794 - val_f1: 0.0658\n",
      "Epoch 1564/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2844 - f1: 0.7340 - val_loss: 0.2892 - val_f1: 0.0681\n",
      "Epoch 1565/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2834 - f1: 0.7337 - val_loss: 0.2838 - val_f1: 0.0669\n",
      "Epoch 1566/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2833 - f1: 0.7356 - val_loss: 0.2885 - val_f1: 0.0676\n",
      "Epoch 1567/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2822 - f1: 0.7378 - val_loss: 0.2828 - val_f1: 0.0667\n",
      "Epoch 1568/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2833 - f1: 0.7368 - val_loss: 0.2902 - val_f1: 0.0678\n",
      "Epoch 1569/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2832 - f1: 0.7363 - val_loss: 0.2901 - val_f1: 0.0682\n",
      "Epoch 1570/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2847 - f1: 0.7361 - val_loss: 0.2873 - val_f1: 0.0677\n",
      "Epoch 1571/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2830 - f1: 0.7387 - val_loss: 0.2934 - val_f1: 0.0683\n",
      "Epoch 1572/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2833 - f1: 0.7379 - val_loss: 0.2844 - val_f1: 0.0668\n",
      "Epoch 1573/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2835 - f1: 0.7340 - val_loss: 0.2910 - val_f1: 0.0682\n",
      "Epoch 1574/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2842 - f1: 0.7349 - val_loss: 0.2845 - val_f1: 0.0669\n",
      "Epoch 1575/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2841 - f1: 0.7358 - val_loss: 0.2804 - val_f1: 0.0663\n",
      "Epoch 1576/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2825 - f1: 0.7379 - val_loss: 0.2910 - val_f1: 0.0683\n",
      "Epoch 1577/2000\n",
      "125120/168135 [=====================>........] - ETA: 1s - loss: 0.2840 - f1: 0.7359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2826 - f1: 0.7402 - val_loss: 0.2891 - val_f1: 0.0678\n",
      "Epoch 1590/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2826 - f1: 0.7379 - val_loss: 0.2886 - val_f1: 0.0680\n",
      "Epoch 1591/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2837 - f1: 0.7369 - val_loss: 0.2864 - val_f1: 0.0674\n",
      "Epoch 1592/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2849 - f1: 0.7340 - val_loss: 0.2888 - val_f1: 0.0676\n",
      "Epoch 1593/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2840 - f1: 0.7348 - val_loss: 0.2850 - val_f1: 0.0673\n",
      "Epoch 1594/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2841 - f1: 0.7372 - val_loss: 0.2877 - val_f1: 0.0676\n",
      "Epoch 1595/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2834 - f1: 0.7366 - val_loss: 0.2887 - val_f1: 0.0680\n",
      "Epoch 1596/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2846 - f1: 0.7363 - val_loss: 0.2868 - val_f1: 0.0679\n",
      "Epoch 1597/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2844 - f1: 0.7346 - val_loss: 0.2852 - val_f1: 0.0672\n",
      "Epoch 1598/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2836 - f1: 0.7363 - val_loss: 0.2852 - val_f1: 0.0674\n",
      "Epoch 1599/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2816 - f1: 0.7382 - val_loss: 0.2848 - val_f1: 0.0667\n",
      "Epoch 1600/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2843 - f1: 0.7339 - val_loss: 0.2865 - val_f1: 0.0671\n",
      "Epoch 1601/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2832 - f1: 0.7372 - val_loss: 0.2844 - val_f1: 0.0676\n",
      "Epoch 1602/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2836 - f1: 0.7363 - val_loss: 0.2862 - val_f1: 0.0672\n",
      "Epoch 1603/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2831 - f1: 0.7372 - val_loss: 0.2833 - val_f1: 0.0672\n",
      "Epoch 1604/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2834 - f1: 0.7353 - val_loss: 0.2851 - val_f1: 0.0672\n",
      "Epoch 1605/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2829 - f1: 0.7356 - val_loss: 0.2871 - val_f1: 0.0678\n",
      "Epoch 1606/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2825 - f1: 0.7390 - val_loss: 0.2842 - val_f1: 0.0675\n",
      "Epoch 1607/2000\n",
      "127360/168135 [=====================>........] - ETA: 1s - loss: 0.2839 - f1: 0.7344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2833 - f1: 0.7364 - val_loss: 0.2866 - val_f1: 0.0676\n",
      "Epoch 1619/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2834 - f1: 0.7374 - val_loss: 0.2829 - val_f1: 0.0668\n",
      "Epoch 1620/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2839 - f1: 0.7347 - val_loss: 0.2872 - val_f1: 0.0681\n",
      "Epoch 1621/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2822 - f1: 0.7389 - val_loss: 0.2861 - val_f1: 0.0674\n",
      "Epoch 1622/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2819 - f1: 0.7388 - val_loss: 0.2960 - val_f1: 0.0685\n",
      "Epoch 1623/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2835 - f1: 0.7383 - val_loss: 0.2859 - val_f1: 0.0669\n",
      "Epoch 1624/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2822 - f1: 0.7375 - val_loss: 0.2862 - val_f1: 0.0672\n",
      "Epoch 1625/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2824 - f1: 0.7390 - val_loss: 0.2896 - val_f1: 0.0678\n",
      "Epoch 1626/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2829 - f1: 0.7392 - val_loss: 0.2933 - val_f1: 0.0686\n",
      "Epoch 1627/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2832 - f1: 0.7361 - val_loss: 0.2896 - val_f1: 0.0680\n",
      "Epoch 1628/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2833 - f1: 0.7373 - val_loss: 0.2810 - val_f1: 0.0663\n",
      "Epoch 1629/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2822 - f1: 0.7378 - val_loss: 0.2897 - val_f1: 0.0681\n",
      "Epoch 1630/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2825 - f1: 0.7373 - val_loss: 0.2919 - val_f1: 0.0683\n",
      "Epoch 1631/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2831 - f1: 0.7376 - val_loss: 0.2887 - val_f1: 0.0676\n",
      "Epoch 1632/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2823 - f1: 0.7376 - val_loss: 0.2872 - val_f1: 0.0674\n",
      "Epoch 1633/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2831 - f1: 0.7383 - val_loss: 0.2864 - val_f1: 0.0671\n",
      "Epoch 1634/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2843 - f1: 0.7367 - val_loss: 0.2897 - val_f1: 0.0680\n",
      "Epoch 1635/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2823 - f1: 0.7398 - val_loss: 0.2816 - val_f1: 0.0667\n",
      "Epoch 1636/2000\n",
      "159104/168135 [===========================>..] - ETA: 0s - loss: 0.2830 - f1: 0.7374"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2825 - f1: 0.7361 - val_loss: 0.2909 - val_f1: 0.0680\n",
      "Epoch 1646/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2833 - f1: 0.7374 - val_loss: 0.2908 - val_f1: 0.0683\n",
      "Epoch 1647/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2830 - f1: 0.7385 - val_loss: 0.2880 - val_f1: 0.0674\n",
      "Epoch 1648/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2835 - f1: 0.7370 - val_loss: 0.2910 - val_f1: 0.0681\n",
      "Epoch 1649/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2827 - f1: 0.7366 - val_loss: 0.2870 - val_f1: 0.0678\n",
      "Epoch 1650/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2822 - f1: 0.7375 - val_loss: 0.2916 - val_f1: 0.0676\n",
      "Epoch 1651/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2816 - f1: 0.7392 - val_loss: 0.2847 - val_f1: 0.0673\n",
      "Epoch 1652/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2844 - f1: 0.7337 - val_loss: 0.2838 - val_f1: 0.0675\n",
      "Epoch 1653/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2838 - f1: 0.7369 - val_loss: 0.2824 - val_f1: 0.0668\n",
      "Epoch 1654/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2829 - f1: 0.7402 - val_loss: 0.2855 - val_f1: 0.0672\n",
      "Epoch 1655/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2831 - f1: 0.7368 - val_loss: 0.2856 - val_f1: 0.0676\n",
      "Epoch 1656/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2831 - f1: 0.7373 - val_loss: 0.2878 - val_f1: 0.0677\n",
      "Epoch 1657/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2820 - f1: 0.7411 - val_loss: 0.2877 - val_f1: 0.0672\n",
      "Epoch 1658/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2833 - f1: 0.7351 - val_loss: 0.2852 - val_f1: 0.0675\n",
      "Epoch 1659/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2832 - f1: 0.7363 - val_loss: 0.2877 - val_f1: 0.0676\n",
      "Epoch 1660/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2828 - f1: 0.7363 - val_loss: 0.2860 - val_f1: 0.0677\n",
      "Epoch 1661/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2817 - f1: 0.7392 - val_loss: 0.2888 - val_f1: 0.0671\n",
      "Epoch 1662/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2826 - f1: 0.7363 - val_loss: 0.2892 - val_f1: 0.0671\n",
      "Epoch 1663/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2833 - f1: 0.7373 - val_loss: 0.2889 - val_f1: 0.0676\n",
      "Epoch 1664/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2816 - f1: 0.7395 - val_loss: 0.2859 - val_f1: 0.0672\n",
      "Epoch 1665/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2832 - f1: 0.7352 - val_loss: 0.2876 - val_f1: 0.0679\n",
      "Epoch 1666/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2822 - f1: 0.7399 - val_loss: 0.2834 - val_f1: 0.0668\n",
      "Epoch 1667/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2836 - f1: 0.7352 - val_loss: 0.2857 - val_f1: 0.0676\n",
      "Epoch 1668/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2832 - f1: 0.7383 - val_loss: 0.2871 - val_f1: 0.0673\n",
      "Epoch 1669/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2823 - f1: 0.7396 - val_loss: 0.2835 - val_f1: 0.0670\n",
      "Epoch 1670/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2830 - f1: 0.7371 - val_loss: 0.2861 - val_f1: 0.0672\n",
      "Epoch 1671/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2833 - f1: 0.7356 - val_loss: 0.2875 - val_f1: 0.0673\n",
      "Epoch 1672/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2826 - f1: 0.7371 - val_loss: 0.2864 - val_f1: 0.0673\n",
      "Epoch 1673/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2831 - f1: 0.7371 - val_loss: 0.2879 - val_f1: 0.0677\n",
      "Epoch 1674/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2829 - f1: 0.7369 - val_loss: 0.2857 - val_f1: 0.0671\n",
      "Epoch 1675/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2811 - f1: 0.7406 - val_loss: 0.2866 - val_f1: 0.0671\n",
      "Epoch 1676/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2832 - f1: 0.7361 - val_loss: 0.2869 - val_f1: 0.0675\n",
      "Epoch 1677/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2823 - f1: 0.7385 - val_loss: 0.2896 - val_f1: 0.0679\n",
      "Epoch 1678/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2836 - f1: 0.7369 - val_loss: 0.2858 - val_f1: 0.0672\n",
      "Epoch 1679/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2814 - f1: 0.7418 - val_loss: 0.2862 - val_f1: 0.0674\n",
      "Epoch 1680/2000\n",
      " 88544/168135 [==============>...............] - ETA: 3s - loss: 0.2841 - f1: 0.7349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2822 - f1: 0.7406 - val_loss: 0.2857 - val_f1: 0.0673\n",
      "Epoch 1689/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2831 - f1: 0.7365 - val_loss: 0.2861 - val_f1: 0.0674\n",
      "Epoch 1690/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2816 - f1: 0.7387 - val_loss: 0.2861 - val_f1: 0.0674\n",
      "Epoch 1691/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2832 - f1: 0.7369 - val_loss: 0.2815 - val_f1: 0.0669\n",
      "Epoch 1692/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2825 - f1: 0.7386 - val_loss: 0.2854 - val_f1: 0.0671\n",
      "Epoch 1693/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2818 - f1: 0.7378 - val_loss: 0.2867 - val_f1: 0.0673\n",
      "Epoch 1694/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2825 - f1: 0.7389 - val_loss: 0.2853 - val_f1: 0.0672\n",
      "Epoch 1695/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2844 - f1: 0.7345 - val_loss: 0.2859 - val_f1: 0.0673\n",
      "Epoch 1696/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2820 - f1: 0.7374 - val_loss: 0.2898 - val_f1: 0.0678\n",
      "Epoch 1697/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2817 - f1: 0.7366 - val_loss: 0.2889 - val_f1: 0.0679\n",
      "Epoch 1698/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2840 - f1: 0.7366 - val_loss: 0.2843 - val_f1: 0.0670\n",
      "Epoch 1699/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2813 - f1: 0.7399 - val_loss: 0.2887 - val_f1: 0.0677\n",
      "Epoch 1700/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2821 - f1: 0.7390 - val_loss: 0.2825 - val_f1: 0.0665\n",
      "Epoch 1701/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2827 - f1: 0.7369 - val_loss: 0.2864 - val_f1: 0.0677\n",
      "Epoch 1702/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2827 - f1: 0.7384 - val_loss: 0.2916 - val_f1: 0.0681\n",
      "Epoch 1703/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2834 - f1: 0.7369 - val_loss: 0.2871 - val_f1: 0.0674\n",
      "Epoch 1704/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2819 - f1: 0.7388 - val_loss: 0.2879 - val_f1: 0.0677\n",
      "Epoch 1705/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2828 - f1: 0.7361 - val_loss: 0.2871 - val_f1: 0.0679\n",
      "Epoch 1706/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2833 - f1: 0.7364 - val_loss: 0.2911 - val_f1: 0.0683\n",
      "Epoch 1707/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2828 - f1: 0.7359 - val_loss: 0.2900 - val_f1: 0.0680\n",
      "Epoch 1708/2000\n",
      " 86976/168135 [==============>...............] - ETA: 3s - loss: 0.2830 - f1: 0.7405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2809 - f1: 0.7384 - val_loss: 0.2875 - val_f1: 0.0674\n",
      "Epoch 1718/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2822 - f1: 0.7382 - val_loss: 0.2822 - val_f1: 0.0666\n",
      "Epoch 1719/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2808 - f1: 0.7395 - val_loss: 0.2859 - val_f1: 0.0673\n",
      "Epoch 1720/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2808 - f1: 0.7403 - val_loss: 0.2846 - val_f1: 0.0668\n",
      "Epoch 1721/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2824 - f1: 0.7381 - val_loss: 0.2914 - val_f1: 0.0684\n",
      "Epoch 1722/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2804 - f1: 0.7415 - val_loss: 0.2890 - val_f1: 0.0679\n",
      "Epoch 1723/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2826 - f1: 0.7372 - val_loss: 0.2822 - val_f1: 0.0668\n",
      "Epoch 1724/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2836 - f1: 0.7354 - val_loss: 0.2874 - val_f1: 0.0676\n",
      "Epoch 1725/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2839 - f1: 0.7371 - val_loss: 0.2850 - val_f1: 0.0666\n",
      "Epoch 1726/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2820 - f1: 0.7390 - val_loss: 0.2860 - val_f1: 0.0667\n",
      "Epoch 1727/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2819 - f1: 0.7397 - val_loss: 0.2910 - val_f1: 0.0681\n",
      "Epoch 1728/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2823 - f1: 0.7373 - val_loss: 0.2885 - val_f1: 0.0671\n",
      "Epoch 1729/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2820 - f1: 0.7403 - val_loss: 0.2837 - val_f1: 0.0664\n",
      "Epoch 1730/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2827 - f1: 0.7366 - val_loss: 0.2861 - val_f1: 0.0674\n",
      "Epoch 1731/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2818 - f1: 0.7395 - val_loss: 0.2859 - val_f1: 0.0670\n",
      "Epoch 1732/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2816 - f1: 0.7368 - val_loss: 0.2895 - val_f1: 0.0680\n",
      "Epoch 1733/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2815 - f1: 0.7383 - val_loss: 0.2829 - val_f1: 0.0666\n",
      "Epoch 1734/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2821 - f1: 0.7363 - val_loss: 0.2857 - val_f1: 0.0672\n",
      "Epoch 1735/2000\n",
      " 99296/168135 [================>.............] - ETA: 3s - loss: 0.2807 - f1: 0.7396"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2830 - f1: 0.7384 - val_loss: 0.2877 - val_f1: 0.0676\n",
      "Epoch 1747/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2820 - f1: 0.7399 - val_loss: 0.2844 - val_f1: 0.0667\n",
      "Epoch 1748/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2822 - f1: 0.7365 - val_loss: 0.2899 - val_f1: 0.0677\n",
      "Epoch 1749/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2809 - f1: 0.7408 - val_loss: 0.2915 - val_f1: 0.0683\n",
      "Epoch 1750/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2811 - f1: 0.7372 - val_loss: 0.2893 - val_f1: 0.0678\n",
      "Epoch 1751/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2826 - f1: 0.7379 - val_loss: 0.2903 - val_f1: 0.0678\n",
      "Epoch 1752/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2825 - f1: 0.7386 - val_loss: 0.2952 - val_f1: 0.0682\n",
      "Epoch 1753/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2824 - f1: 0.7383 - val_loss: 0.2826 - val_f1: 0.0668\n",
      "Epoch 1754/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2823 - f1: 0.7367 - val_loss: 0.2885 - val_f1: 0.0676\n",
      "Epoch 1755/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2819 - f1: 0.7377 - val_loss: 0.2855 - val_f1: 0.0672\n",
      "Epoch 1756/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2822 - f1: 0.7402 - val_loss: 0.2849 - val_f1: 0.0667\n",
      "Epoch 1757/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2817 - f1: 0.7388 - val_loss: 0.2872 - val_f1: 0.0675\n",
      "Epoch 1758/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2820 - f1: 0.7392 - val_loss: 0.2862 - val_f1: 0.0672\n",
      "Epoch 1759/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2824 - f1: 0.7396 - val_loss: 0.2836 - val_f1: 0.0666\n",
      "Epoch 1760/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2810 - f1: 0.7389 - val_loss: 0.2891 - val_f1: 0.0678\n",
      "Epoch 1761/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2826 - f1: 0.7382 - val_loss: 0.2857 - val_f1: 0.0671\n",
      "Epoch 1762/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2819 - f1: 0.7381 - val_loss: 0.2848 - val_f1: 0.0674\n",
      "Epoch 1763/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2809 - f1: 0.7384 - val_loss: 0.2888 - val_f1: 0.0675\n",
      "Epoch 1764/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2820 - f1: 0.7390 - val_loss: 0.2924 - val_f1: 0.0686\n",
      "Epoch 1765/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2819 - f1: 0.7361 - val_loss: 0.2910 - val_f1: 0.0677\n",
      "Epoch 1766/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2826 - f1: 0.7391 - val_loss: 0.2885 - val_f1: 0.0674\n",
      "Epoch 1767/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2820 - f1: 0.7404 - val_loss: 0.2869 - val_f1: 0.0668\n",
      "Epoch 1768/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2828 - f1: 0.7388 - val_loss: 0.2857 - val_f1: 0.0672\n",
      "Epoch 1769/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2800 - f1: 0.7408 - val_loss: 0.2889 - val_f1: 0.0677\n",
      "Epoch 1770/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2833 - f1: 0.7375 - val_loss: 0.2826 - val_f1: 0.0664\n",
      "Epoch 1771/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2821 - f1: 0.7380 - val_loss: 0.2885 - val_f1: 0.0672\n",
      "Epoch 1772/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2814 - f1: 0.7390 - val_loss: 0.2914 - val_f1: 0.0679\n",
      "Epoch 1773/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2818 - f1: 0.7379 - val_loss: 0.2894 - val_f1: 0.0678\n",
      "Epoch 1774/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2813 - f1: 0.7386 - val_loss: 0.2910 - val_f1: 0.0677\n",
      "Epoch 1775/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2826 - f1: 0.7373 - val_loss: 0.2879 - val_f1: 0.0673\n",
      "Epoch 1776/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2831 - f1: 0.7379 - val_loss: 0.2920 - val_f1: 0.0683\n",
      "Epoch 1777/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2812 - f1: 0.7373 - val_loss: 0.2963 - val_f1: 0.0689\n",
      "Epoch 1778/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2816 - f1: 0.7389 - val_loss: 0.2906 - val_f1: 0.0677\n",
      "Epoch 1779/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2813 - f1: 0.7398 - val_loss: 0.2939 - val_f1: 0.0683\n",
      "Epoch 1780/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2808 - f1: 0.7404 - val_loss: 0.2874 - val_f1: 0.0675\n",
      "Epoch 1781/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2823 - f1: 0.7388 - val_loss: 0.2895 - val_f1: 0.0677\n",
      "Epoch 1782/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2828 - f1: 0.7386 - val_loss: 0.2842 - val_f1: 0.0672\n",
      "Epoch 1783/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2810 - f1: 0.7394 - val_loss: 0.2937 - val_f1: 0.0683\n",
      "Epoch 1784/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2808 - f1: 0.7386 - val_loss: 0.2904 - val_f1: 0.0679\n",
      "Epoch 1785/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2822 - f1: 0.7360 - val_loss: 0.2862 - val_f1: 0.0672\n",
      "Epoch 1786/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2806 - f1: 0.7407 - val_loss: 0.2865 - val_f1: 0.0669\n",
      "Epoch 1787/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2817 - f1: 0.7391 - val_loss: 0.2840 - val_f1: 0.0665\n",
      "Epoch 1788/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2819 - f1: 0.7382 - val_loss: 0.2872 - val_f1: 0.0672\n",
      "Epoch 1789/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2811 - f1: 0.7394 - val_loss: 0.2891 - val_f1: 0.0677\n",
      "Epoch 1790/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2811 - f1: 0.7396 - val_loss: 0.2846 - val_f1: 0.0671\n",
      "Epoch 1791/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2820 - f1: 0.7394 - val_loss: 0.2868 - val_f1: 0.0676\n",
      "Epoch 1792/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2812 - f1: 0.7395 - val_loss: 0.2876 - val_f1: 0.0669\n",
      "Epoch 1793/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2805 - f1: 0.7407 - val_loss: 0.2851 - val_f1: 0.0669\n",
      "Epoch 1794/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2823 - f1: 0.7380 - val_loss: 0.2871 - val_f1: 0.0673\n",
      "Epoch 1795/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2823 - f1: 0.7362 - val_loss: 0.2851 - val_f1: 0.0671\n",
      "Epoch 1796/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2816 - f1: 0.7402 - val_loss: 0.2850 - val_f1: 0.0672\n",
      "Epoch 1797/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2809 - f1: 0.7403 - val_loss: 0.2851 - val_f1: 0.0671\n",
      "Epoch 1798/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2825 - f1: 0.7376 - val_loss: 0.2889 - val_f1: 0.0675\n",
      "Epoch 1799/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2827 - f1: 0.7385 - val_loss: 0.2921 - val_f1: 0.0683\n",
      "Epoch 1800/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2819 - f1: 0.7384 - val_loss: 0.2884 - val_f1: 0.0679\n",
      "Epoch 1801/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2817 - f1: 0.7397 - val_loss: 0.2883 - val_f1: 0.0677\n",
      "Epoch 1802/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2811 - f1: 0.7381 - val_loss: 0.2863 - val_f1: 0.0671\n",
      "Epoch 1803/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2801 - f1: 0.7416 - val_loss: 0.2841 - val_f1: 0.0669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1804/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2831 - f1: 0.7383 - val_loss: 0.2862 - val_f1: 0.0672\n",
      "Epoch 1805/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2816 - f1: 0.7385 - val_loss: 0.2848 - val_f1: 0.0673\n",
      "Epoch 1806/2000\n",
      "152896/168135 [==========================>...] - ETA: 0s - loss: 0.2809 - f1: 0.7393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2825 - f1: 0.7366 - val_loss: 0.2874 - val_f1: 0.0670\n",
      "Epoch 1817/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2806 - f1: 0.7391 - val_loss: 0.2873 - val_f1: 0.0671\n",
      "Epoch 1818/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2828 - f1: 0.7367 - val_loss: 0.2890 - val_f1: 0.0682\n",
      "Epoch 1819/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2814 - f1: 0.7399 - val_loss: 0.2897 - val_f1: 0.0677\n",
      "Epoch 1820/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2820 - f1: 0.7397 - val_loss: 0.2915 - val_f1: 0.0679\n",
      "Epoch 1821/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2816 - f1: 0.7355 - val_loss: 0.2877 - val_f1: 0.0679\n",
      "Epoch 1822/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2801 - f1: 0.7416 - val_loss: 0.2857 - val_f1: 0.0672\n",
      "Epoch 1823/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2817 - f1: 0.7391 - val_loss: 0.2890 - val_f1: 0.0671\n",
      "Epoch 1824/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2809 - f1: 0.7401 - val_loss: 0.2920 - val_f1: 0.0683\n",
      "Epoch 1825/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2816 - f1: 0.7393 - val_loss: 0.2885 - val_f1: 0.0678\n",
      "Epoch 1826/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2812 - f1: 0.7389 - val_loss: 0.2888 - val_f1: 0.0676\n",
      "Epoch 1827/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2817 - f1: 0.7393 - val_loss: 0.2891 - val_f1: 0.0676\n",
      "Epoch 1828/2000\n",
      " 52864/168135 [========>.....................] - ETA: 5s - loss: 0.2837 - f1: 0.7365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2816 - f1: 0.7390 - val_loss: 0.2853 - val_f1: 0.0671\n",
      "Epoch 1837/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2815 - f1: 0.7376 - val_loss: 0.2804 - val_f1: 0.0661\n",
      "Epoch 1838/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2822 - f1: 0.7375 - val_loss: 0.2841 - val_f1: 0.0669\n",
      "Epoch 1839/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2806 - f1: 0.7397 - val_loss: 0.2855 - val_f1: 0.0671\n",
      "Epoch 1840/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2814 - f1: 0.7388 - val_loss: 0.2894 - val_f1: 0.0677\n",
      "Epoch 1841/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2815 - f1: 0.7396 - val_loss: 0.2853 - val_f1: 0.0669\n",
      "Epoch 1842/2000\n",
      " 77376/168135 [============>.................] - ETA: 4s - loss: 0.2805 - f1: 0.7376"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2822 - f1: 0.7371 - val_loss: 0.2887 - val_f1: 0.0673\n",
      "Epoch 1863/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2837 - f1: 0.7370 - val_loss: 0.2886 - val_f1: 0.0681\n",
      "Epoch 1864/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2812 - f1: 0.7391 - val_loss: 0.2833 - val_f1: 0.0669\n",
      "Epoch 1865/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2825 - f1: 0.7371 - val_loss: 0.2888 - val_f1: 0.0674\n",
      "Epoch 1866/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2806 - f1: 0.7398 - val_loss: 0.2864 - val_f1: 0.0667\n",
      "Epoch 1867/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2815 - f1: 0.7396 - val_loss: 0.2860 - val_f1: 0.0674\n",
      "Epoch 1868/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2796 - f1: 0.7414 - val_loss: 0.2885 - val_f1: 0.0674\n",
      "Epoch 1869/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2813 - f1: 0.7374 - val_loss: 0.2891 - val_f1: 0.0678\n",
      "Epoch 1870/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2827 - f1: 0.7379 - val_loss: 0.2873 - val_f1: 0.0673\n",
      "Epoch 1871/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2807 - f1: 0.7396 - val_loss: 0.2902 - val_f1: 0.0673\n",
      "Epoch 1872/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2822 - f1: 0.7356 - val_loss: 0.2887 - val_f1: 0.0676\n",
      "Epoch 1873/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2812 - f1: 0.7393 - val_loss: 0.2895 - val_f1: 0.0677\n",
      "Epoch 1874/2000\n",
      " 38240/168135 [=====>........................] - ETA: 5s - loss: 0.2802 - f1: 0.7388"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2806 - f1: 0.7399 - val_loss: 0.2867 - val_f1: 0.0671\n",
      "Epoch 1884/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2800 - f1: 0.7417 - val_loss: 0.2890 - val_f1: 0.0675\n",
      "Epoch 1885/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2816 - f1: 0.7413 - val_loss: 0.2809 - val_f1: 0.0660\n",
      "Epoch 1886/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2818 - f1: 0.7399 - val_loss: 0.2902 - val_f1: 0.0675\n",
      "Epoch 1887/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2804 - f1: 0.7394 - val_loss: 0.2927 - val_f1: 0.0680\n",
      "Epoch 1888/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2814 - f1: 0.7392 - val_loss: 0.2851 - val_f1: 0.0672\n",
      "Epoch 1889/2000\n",
      " 68768/168135 [===========>..................] - ETA: 4s - loss: 0.2772 - f1: 0.74"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2813 - f1: 0.7386 - val_loss: 0.2936 - val_f1: 0.0682\n",
      "Epoch 1901/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2807 - f1: 0.7418 - val_loss: 0.2846 - val_f1: 0.0670\n",
      "Epoch 1902/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2807 - f1: 0.7430 - val_loss: 0.2894 - val_f1: 0.0674\n",
      "Epoch 1903/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2816 - f1: 0.7387 - val_loss: 0.2859 - val_f1: 0.0668\n",
      "Epoch 1904/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2805 - f1: 0.7394 - val_loss: 0.2911 - val_f1: 0.0680\n",
      "Epoch 1905/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2814 - f1: 0.7396 - val_loss: 0.2863 - val_f1: 0.0668\n",
      "Epoch 1906/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2817 - f1: 0.7399 - val_loss: 0.2888 - val_f1: 0.0674\n",
      "Epoch 1907/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2802 - f1: 0.7406 - val_loss: 0.2849 - val_f1: 0.0669\n",
      "Epoch 1908/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2810 - f1: 0.7399 - val_loss: 0.2888 - val_f1: 0.0675\n",
      "Epoch 1909/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2800 - f1: 0.7408 - val_loss: 0.2907 - val_f1: 0.0678\n",
      "Epoch 1910/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2818 - f1: 0.7388 - val_loss: 0.2891 - val_f1: 0.0680\n",
      "Epoch 1911/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2811 - f1: 0.7388 - val_loss: 0.2819 - val_f1: 0.0667\n",
      "Epoch 1912/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2802 - f1: 0.7411 - val_loss: 0.2947 - val_f1: 0.0679\n",
      "Epoch 1913/2000\n",
      "168135/168135 [==============================] - 8s 50us/step - loss: 0.2806 - f1: 0.7404 - val_loss: 0.2826 - val_f1: 0.0667\n",
      "Epoch 1914/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2822 - f1: 0.7385 - val_loss: 0.2876 - val_f1: 0.0675\n",
      "Epoch 1915/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2814 - f1: 0.7396 - val_loss: 0.2850 - val_f1: 0.0668\n",
      "Epoch 1916/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2798 - f1: 0.7395 - val_loss: 0.2910 - val_f1: 0.0681\n",
      "Epoch 1917/2000\n",
      "161920/168135 [===========================>..] - ETA: 0s - loss: 0.2797 - f1: 0.7404"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2810 - f1: 0.7415 - val_loss: 0.2916 - val_f1: 0.0678\n",
      "Epoch 1931/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2804 - f1: 0.7424 - val_loss: 0.2848 - val_f1: 0.0669\n",
      "Epoch 1932/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2812 - f1: 0.7395 - val_loss: 0.2912 - val_f1: 0.0684\n",
      "Epoch 1933/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2813 - f1: 0.7394 - val_loss: 0.2860 - val_f1: 0.0676\n",
      "Epoch 1934/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2810 - f1: 0.7391 - val_loss: 0.2917 - val_f1: 0.0678\n",
      "Epoch 1935/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2802 - f1: 0.7403 - val_loss: 0.2832 - val_f1: 0.0663\n",
      "Epoch 1936/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2799 - f1: 0.7409 - val_loss: 0.2903 - val_f1: 0.0680\n",
      "Epoch 1937/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2824 - f1: 0.7388 - val_loss: 0.2856 - val_f1: 0.0663\n",
      "Epoch 1938/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2820 - f1: 0.7379 - val_loss: 0.2865 - val_f1: 0.0673\n",
      "Epoch 1939/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2807 - f1: 0.7423 - val_loss: 0.2864 - val_f1: 0.0671\n",
      "Epoch 1940/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2813 - f1: 0.7407 - val_loss: 0.2872 - val_f1: 0.0672\n",
      "Epoch 1941/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2813 - f1: 0.7386 - val_loss: 0.2875 - val_f1: 0.0672\n",
      "Epoch 1942/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2815 - f1: 0.7387 - val_loss: 0.2879 - val_f1: 0.0674\n",
      "Epoch 1943/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2790 - f1: 0.7428 - val_loss: 0.2924 - val_f1: 0.0683\n",
      "Epoch 1944/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2810 - f1: 0.7414 - val_loss: 0.2832 - val_f1: 0.0664\n",
      "Epoch 1945/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2813 - f1: 0.7398 - val_loss: 0.2858 - val_f1: 0.0674\n",
      "Epoch 1946/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2802 - f1: 0.7401 - val_loss: 0.2920 - val_f1: 0.0677\n",
      "Epoch 1947/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2799 - f1: 0.7403 - val_loss: 0.2831 - val_f1: 0.0658\n",
      "Epoch 1948/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2785 - f1: 0.7438 - val_loss: 0.2911 - val_f1: 0.0674\n",
      "Epoch 1949/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2801 - f1: 0.7416 - val_loss: 0.2896 - val_f1: 0.0676\n",
      "Epoch 1950/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2801 - f1: 0.7384 - val_loss: 0.2865 - val_f1: 0.0671\n",
      "Epoch 1951/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2810 - f1: 0.7385 - val_loss: 0.2908 - val_f1: 0.0676\n",
      "Epoch 1952/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2808 - f1: 0.7405 - val_loss: 0.2850 - val_f1: 0.0664\n",
      "Epoch 1953/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2800 - f1: 0.7398 - val_loss: 0.2888 - val_f1: 0.0673\n",
      "Epoch 1954/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2807 - f1: 0.7400 - val_loss: 0.2893 - val_f1: 0.0680\n",
      "Epoch 1955/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2811 - f1: 0.7401 - val_loss: 0.2837 - val_f1: 0.0668\n",
      "Epoch 1956/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2806 - f1: 0.7407 - val_loss: 0.2877 - val_f1: 0.0671\n",
      "Epoch 1957/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2797 - f1: 0.7415 - val_loss: 0.2882 - val_f1: 0.0673\n",
      "Epoch 1958/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2804 - f1: 0.7407 - val_loss: 0.2803 - val_f1: 0.0660\n",
      "Epoch 1959/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2799 - f1: 0.7403 - val_loss: 0.2885 - val_f1: 0.0675\n",
      "Epoch 1960/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2803 - f1: 0.7411 - val_loss: 0.2896 - val_f1: 0.0670\n",
      "Epoch 1961/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2806 - f1: 0.7406 - val_loss: 0.2837 - val_f1: 0.0659\n",
      "Epoch 1962/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2810 - f1: 0.7389 - val_loss: 0.2910 - val_f1: 0.0677\n",
      "Epoch 1963/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2815 - f1: 0.7389 - val_loss: 0.2904 - val_f1: 0.0681\n",
      "Epoch 1964/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2814 - f1: 0.7397 - val_loss: 0.2914 - val_f1: 0.0681\n",
      "Epoch 1965/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2798 - f1: 0.7403 - val_loss: 0.2885 - val_f1: 0.0669\n",
      "Epoch 1966/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2806 - f1: 0.7392 - val_loss: 0.2880 - val_f1: 0.0677\n",
      "Epoch 1967/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2800 - f1: 0.7419 - val_loss: 0.2852 - val_f1: 0.0668\n",
      "Epoch 1968/2000\n",
      " 79840/168135 [=============>................] - ETA: 3s - loss: 0.2818 - f1: 0.7394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2806 - f1: 0.7399 - val_loss: 0.2849 - val_f1: 0.0667\n",
      "Epoch 1979/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2813 - f1: 0.7383 - val_loss: 0.2904 - val_f1: 0.0678\n",
      "Epoch 1980/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2814 - f1: 0.7389 - val_loss: 0.2938 - val_f1: 0.0678\n",
      "Epoch 1981/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2811 - f1: 0.7387 - val_loss: 0.2846 - val_f1: 0.0670\n",
      "Epoch 1982/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2803 - f1: 0.7405 - val_loss: 0.2854 - val_f1: 0.0666\n",
      "Epoch 1983/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2801 - f1: 0.7396 - val_loss: 0.2865 - val_f1: 0.0666\n",
      "Epoch 1984/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2796 - f1: 0.7414 - val_loss: 0.2858 - val_f1: 0.0663\n",
      "Epoch 1985/2000\n",
      "168135/168135 [==============================] - 8s 49us/step - loss: 0.2790 - f1: 0.7403 - val_loss: 0.2885 - val_f1: 0.0670\n",
      "Epoch 1986/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2807 - f1: 0.7381 - val_loss: 0.2853 - val_f1: 0.0667\n",
      "Epoch 1987/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2796 - f1: 0.7405 - val_loss: 0.2876 - val_f1: 0.0673\n",
      "Epoch 1988/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2804 - f1: 0.7380 - val_loss: 0.2839 - val_f1: 0.0667\n",
      "Epoch 1989/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2817 - f1: 0.7383 - val_loss: 0.2888 - val_f1: 0.0673\n",
      "Epoch 1990/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2791 - f1: 0.7425 - val_loss: 0.2876 - val_f1: 0.0680\n",
      "Epoch 1991/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2806 - f1: 0.7413 - val_loss: 0.2845 - val_f1: 0.0666\n",
      "Epoch 1992/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2813 - f1: 0.7404 - val_loss: 0.2839 - val_f1: 0.0664\n",
      "Epoch 1993/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2804 - f1: 0.7397 - val_loss: 0.2874 - val_f1: 0.0674\n",
      "Epoch 1994/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2806 - f1: 0.7401 - val_loss: 0.2868 - val_f1: 0.0670\n",
      "Epoch 1995/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2800 - f1: 0.7405 - val_loss: 0.2894 - val_f1: 0.0674\n",
      "Epoch 1996/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2799 - f1: 0.7403 - val_loss: 0.2896 - val_f1: 0.0678\n",
      "Epoch 1997/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2808 - f1: 0.7400 - val_loss: 0.2913 - val_f1: 0.0677\n",
      "Epoch 1998/2000\n",
      "168135/168135 [==============================] - 8s 47us/step - loss: 0.2791 - f1: 0.7422 - val_loss: 0.2879 - val_f1: 0.0672\n",
      "Epoch 1999/2000\n",
      "168135/168135 [==============================] - 8s 46us/step - loss: 0.2805 - f1: 0.7380 - val_loss: 0.2936 - val_f1: 0.0679\n",
      "Epoch 2000/2000\n",
      "168135/168135 [==============================] - 8s 48us/step - loss: 0.2788 - f1: 0.7420 - val_loss: 0.2880 - val_f1: 0.0670\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna4.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna4.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[24922  2063]\n",
      " [ 1497  1518]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[24984  2002]\n",
      " [ 1499  1516]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[119768   6163]\n",
      " [  7857  34347]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAEYCAYAAAD29oUSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYFNW5x/HvjxkQkE1ZXEBEERdcQEDFBeWKIrjhHoyJqETiHs3inuiNGterEXEJUQSMOy7BiBJEUVBQEBBFRBBQcQXZBYEZ3vtHnYaadrqnZ5juGabfD089dJ1zqupUTffbp09VnZKZ4ZxzLjtqVXUFnHOuJvMg65xzWeRB1jnnssiDrHPOZZEHWeecyyIPss45l0UeZJ1zLos8yDrnyiTpv5LOqup6bImqTZCVtEDSGkmrYtOOIW+wpNmSNkg6J8P1NZE0RNK3klZK+lTSVVndiSyS1FHS+5JWh/87pinbRtIoSUvD/g+SVBjymkl6W9IPkpZJmijp0KTlrwjLLQ/HcKtYXvLf6b/lWLaNpDfCPnwi6ahYXr+wXyskLZR0R6LOIX9V0lQs6b5Y/hmSZoW/9ceSTsq0XiH/d5LmS/oxrGf3WF5zSU+E47VU0uOxvKGS1iXVrSCW/xtJc0P6q4n3dMiTpNvD3+KHsM+K5Z8g6aOw7DuS2qf6myftyyuxuqxPqt9DmawjmZn1NLPHyy5Zan0Wxt4zy8L7b0B8X8tYfjdJW+5dU2ZWLSZgAXBUiryLgR7AFOCcDNf3KPAMsA3Rl8mewGmVXOfCHB2bOsDnwBXAVsBlYb5OivKjgKFAXWB74EPgspBXF9gjHBMBJwFLEvsCHAN8B+wdjt044LYM/05lLTsRuBuoB5wKLAOah7wLgW5hX1sC7wNXp9jO1sAq4PAw3xJYB/QO+3QcsBpokWG9fgPMANqH5dsC28byx4d6NwZqA/vH8oYCN6eo5xHA92G7dYAHgTdj+b8FZgOtwj58DFwQ8toBK4DDgELgGmBued9z6eqXq/cxsBDoHl43Ce+5BcA/M1x+N8By8VnLyv5XdQViBzLlhzdWZgKZB9mPgJPS5O8NjAkB5jvg2pC+FfB34Osw/R3YKuR1D2+Yq4BvgcdC+vHA9BA03gH2q+Rj0xP4ClAs7QugV4rys4BjY/N3Av8opVwt4ATAYgHpCeBvsTI9gG8z+TulWxbYHVgLNIzlj08ElVLW9XvgpRR5/YB5ieMBHAR8n1RmEXBwBvWqBXwJ9Ehz7BcABSnyUwYx4C7g/tj8juFYtw3z7wADYvn9gUnh9SXAy0l/qzWp6pnmvfOz+gFHhX26NryPHwWaEn05LwKWAi8BLUv77BF9Kb0J3BPe8/OAnmnqsDHIxtIOBjYAe4b5E4k+QyvDe/vPsbJfh+O2KkwHEH0JvQH8ACwGHgMaV+bnrrKmatNdkAWTgFsknSupXTxDUkPgNeBVojf+bsDYkH0d0BXoCHQADgSujy2+PbAtsDMwQFInYAhRq6Qp8A9gZPLP0di2Z4SfTKVND6TYl72BGRbeccGMkF6ae4G+kupLaknUwns1uR7AT8BI4GEz+z62rQ9iRT8AtpPUNJb2uKRFivrpOiTVM9WyewPzzGxlUn6qfTgcmJkirx8wPHY8pgCzJJ0oqSB0FawlOkZl1atVmPaR9GXoMvhfSYnPRlei1uaw8JN+sqQjkupzkaQlobvj1Fi6whSfB9gnTb32jpVNXlaJZSUdJmlZiuOTiVZAA6A1cBFREP9nmN8ZWE/0PkrlEKJfSE2Jgu0j5dm4mU0kCvDdQtIq4FdEvxZOAH4n6fiQd3hYpkGYJhMdi5uBHYh+gewK/Lk8dciZqo7ysW+rBUQHelmYXiylTHlasvWIvqnfJ3rDzAV6h7wzgWkplvuMkq3AY4AF4XV3op+ldWP5DwI3Ja1jNnBEJR6bPwNPJaU9DtyYovxeYb+LiFoAQ4m1gmPl6oZj0S9p/3vF5muHdbQJ84eGY1uf6Cfst0CTspYFfk1opcXybwGGllKvc4laP81KyWsNFAO7JKX3D++fIqKuguMy2SeiYGHAy0Q/ZdsAnwLnh7KDQ37/sFzf8P5sFvI7EQWaQuBYopbYoSGvB1Era79wzP5B1Ho7M+QXE1pyYb5d2JaIurd+DO+5OuE9sAG4ppzvnaGU3pL9iRTdTaFMF2BRaZ89opbsJ7G8RqHeP/t7hfyftWRD+hTgqhTLDALuDK/L7C4ATgMmV9ZnrjKn6taSPcnMmoTppLKLp2Zma8zsb2bWmehD8AzwrKRtgZ2IPnil2ZGovzPh85CWsMjMforN7wz8Id4iDeuPL7O5VhG9keMaEX2gSwgtsNHA80R9l82I+iFvTy5rZj+Z2ZPA1bEWafK2Eq9XhmXeDsd2tZndShRwumWwbEb7EFqhtxF9IS5OrjNwNjDBzObHljkKuINNAekI4GFtOjmYrl5rwus7zGyZmS0gCobHhvQ1RF+yj5jZejN7iqh74dBwPKaa2Q9mVmRmo4i+/E4JeWOBG4DniN5HC8I2F6ap1yqLfELUYh8EfEP0d/w4tuzm+s7M1iVmJG0t6WFJX0haAbwetpnKt7HXq8P/DcpZh5ZE3XVIOljSuPALaTlRIE+5fUnbS3pG0lehvkPLqG+VqW5BNivMbAXwN6KgswvRh6RtiuJfEwXOhNYhbePqksp/CdwS+3JoYmb1Q/D6GUkz9fMz5WWd+Z0J7Jd0NnY/Sv85nfgSGWRma83sB6I+t2NLKZtQm+jnVmJb8S6ADkQfyB9SLJtoeZW17Exg19BVE8/fuA+SehH9ZD3BzD5Msb2zgWFJaR2Bt8xsipltsOjn5LtELbay6jWb6NdJ8t81YUaavNLEjwdmdr+ZtTOzFkTBtpDofEGqes2MLTvCzPYxs6ZEwXpnYHI56lJWPeOuJPpsHGhmjYAjK2k7pZLUFdiOqIUM8BTR8dnJzBoDD7PpOJZ2/G8n6hLaN9T3HEp2r1QfVd2UjjX3F5D6hEodop+2bwPnh9e1yljfn4k6yBPLXkfUod8AaEjUOric6ERXQ+CgsNzNRCckmhN9M04g/NwinPhK2k4XokB7ENEfeWuis9sNN+d4lLL/nwO/C/W9hPRXF8wDrib6QDcBXgAeD3ldic5Y1yH6CXsVUetqx5Dfi6iV0p6oBfw64Uw80RfOobFj+ieiEyVNy1o25E8iOhlUFziZklcXHEl0EuPwNMfhEKKf0A2T0o8g+lneMczvH9bVM8N6DQf+E94HrYBPgP4hb9vwvukHFBD9LF3Cpu6C08J7qhbRSbKVbDqTXpeoD1Xh2I2j5Am4C4hOUrYk+uUzk9iJQKBz2GZz4GngiQq8d4aS4sRXUtrdRCe7tiL65TeS2E90ft5dMC6WV0isS6mUOsSvLmhMdJJrHjAkVmYJcFbsPbqY0JUU/i4bgF1j5Z8HHgrHZ6fw3lpQ1vGoiqnKKxA7aAtIHWTHhT9ifOpexvquJ2oxrAh/wHHAIbH8fYhOdi0NH8CrYx+MgURB+Jvwum7I605SkA3pvYhaGMvCMs9SiUE2bGN/on7WNcBUSl5GdC3wSmy+Y9jfpeHN+iybrh44gugEy8pwXN4kKbARndn/Lhy7R9l0dcXeRC27H4mC2FigSybLhrw2oV5riFqQR8Xy3iDqT10Vm15JWvc/CFd0lHJ8LiHqd19J9AH+Qznq1YioJbWS6AvzL5S8kqMb0UmeVUT9iN1ieeOB5WG9HwB9Y3lNYsfrW+BWYlcpEAXfO8LfYUl4Hd/uhNjf6R/A1kl1WpXB+2YomQXZVsBbYR9nE11SZ0l1OSe8rkiQXRPWvZyoEXMhsYYS8AuiqwpWEgX4B4j11xP13y8i+ox1AfYl+hysAqYRfeEvKOt4VMWUuATGOedcFuRFn6xzzlWVLTrIJt0+GJ+ureq6Oecc4N0FzjmXTYVlF3HJVFjPVKdh2QVdpdp/r9ZVXYW8NHXq+4vNrHllrKug0c5mRWvSlrE1i0abWa/K2F514EG2AlSnIVvtcUZVVyPvvP3uoKquQl6qV1ufl10qM1a0pszPzk/T76+WNxVUlAdZ51zuSFCroOxyNYgHWedcbmmLPt9ebh5knXO5ldlY3TWGB1nnXA55d4FzzmWP8O4C55zLHnl3gXPOZZV3FzjnXLbIuwuccy5rhLdknXMue7wl65xz2VXLT3w551x2eHeBc85lk3cXOOdcdvl1ss45lyU+CpdzzmWZdxc451wWeXeBc85li3cXOOdc9vgoXM45l03eknXOuezylqxzzmWRn/hyzrks8etknXMuu+QtWeecyw7hQdY557JHQj7UoXPOZY+3ZJ1zLovyLcjm1wVrzrmqJVAtpZ0yWo00RNL3kj6KpW0raYykOeH/bUK6JA2UNFfSDEmdYsv0C+XnSOoXS+8s6cOwzECFb4ZU20jHg6xzLmeEkNJPGRoK9EpKuxoYa2btgLFhHqA30C5MA4AHIQqYwA3AQcCBwA2xoPlgKJtYrlcZ20jJg6xzLqdq1aqVdsqEmb0FLElK7gMMC6+HASfF0odbZBLQRNIOwDHAGDNbYmZLgTFAr5DXyMwmmpkBw5PWVdo2UvI+WedcTmXQWm0maUpsfrCZDc5g1duZ2TcAZvaNpBYhvSXwZazcwpCWLn1hKenptpGSB1nnXO4oTOktNrMulbzVZFaB9Arx7gLnXM4IVUp3QQrfhZ/6hP+/D+kLgZ1i5VoBX5eR3qqU9HTbSMmDrHMupyrpxFdpRgKJKwT6Af+OpZ8drjLoCiwPP/lHAz0lbRNOePUERoe8lZK6hqsKzk5aV2nbSMm7C5xzuVUJl8lKehLoTtR/u5DoKoHbgGck9Qe+AE4PxUcBxwJzgdXAuQBmtkTSTcDkUO6vZpY4mXYh0RUM9YBXwkSabaTkQdY5lztic7sEADCzM1Nk9SilrAEXp1jPEGBIKelTgH1KSf+htG2k40HWOZdT+XbHlwdZ51zOJG5GyCceZJ1zuRNuq80nHmSdcznlLVlXLT10w1n0PnwfFi1ZSZfT/wbAKUftz3UXHMueu2xHt1/fxdSPvwCgdmEBg64/k07tW7PBNvDHO55j/PtzaFB/K14bcsXGdbZs0YSnRk3mT3c9B8CpR0frM4MPP/2Kc64dCsAtv+tDr277UEvi9Xc/4Q93jMjtzldTy5Yt48Lf/oaPZ36EJB4aPISvvlrILTfdyCezZjH+nffo3GXTNfUfzpjBJRf9lpUrV1BLtZgwaTJ169blxON68e0331BUXMShh3bj7/fdT0FBzX1Ei7dkXbX02EuTeOjpN3n4prM3ps387Gv6/uGfDLq+5InW8045FIADzvgbzbdpwIuDLuKwX93JqtVr6dr3to3l3n78Sl58fToAbVs354/n9eTIc+5m2co1NN+mAQBdO+zCwR135YAzosD++qO/p1vndox/f05W93dL8McrfkfPnr148ukRrFu3jtWrV9OkSROeeuZ5LrnotyXKFhUVcV6/X/HI0MfYr0MHfvjhB2rXrg3Av558hkaNGmFmnPmL03huxLOc8Yu+VbFLOZFvLdms3YwgqY2kNZKmh/kFsfSPksreKOmP2apL0rauTZpP1KutpOmSVuWiHuX19tTPWLJ8dYm02fO/Y87nP7/hZM9dt+eN92YDsGjpKpavXEPn9q1LlGnbujkttm3I21M/A+C8kw/hH8+8xbKVazYuB2AGW9WpTZ3ahWxVp5DCwgK+X7Ki0vdvS7NixQomTHiLc87rD0CdOnVo0qQJe+61F7vvscfPyr825r/ss+9+7NehAwBNmzbd2Fpt1KgREAXi9evW1eggVNaNCDVx37N9x9dnZtYxy9sor2tLSzSz6ljXCvnw0684ofu+FBTUYucdm7J/+51otX3JYS/P6NWZEf+dunG+3c4taNe6Ba8/egVvDvsDRx+yFwDvzpjPW1PmMH/MLcz/79947Z1ZzJ7/XU73pzqaP28ezZo1Z0D/c+naZX8uHPAbfvzxx5Tl53z6KZI44dhjOPiATvzfXXeUyD/h2GNovWMLGjRsyCmnnpbt6lepLN5WWy3lco8WZVJIUkdJk8Lgui/EBt4dJ+l2Se9J+lRSt5BeIOlOSZPDMr8N6TtIeiu0Tj+S1E3SbUC9kPZ4Oes1QNIUSVOsaE359z6Hhv17Il99t4y3H7+SO/90KpM+mE9RcXGJMqcf05lnXt000FFBQQG7tW5Bz/Pv5exrhvLgX35J4wb12HWnZuyxy3bsdsz1tD3mOrofuDuHdmqb612qdoqKipg+bSrn//ZCJk2ZRv2tt+auO25LXb64iHfemcCjwx9n7JsTGPniC7zx+tiN+S+NGs38L79h7dq1jHvj9VzsQtVRGVMNk7Mga2YHxGYTP82nh+6EC2J5w4GrzGw/4EOi2+USCs3sQODyWHp/onuRDwAOAM6XtAvwS6L7kDsCHYDpZnY1sMbMOprZWaXUK139B5tZFzProsJ65d39nCou3sCV//c8XfvexhlXDKZJw3rM/WLTd8m+u7eksKCAabM2jfL21ffLeGncDIqKNvD51z/w6YLv2a11c/r8Twfe+3ABP65Zx49r1jH67ZkctO8uVbFb1UrLVq1o2aoVBx50EAAnn3oa06dNTV2+ZSu6dTuCZs2aUb9+fXr1PpZpSeXr1q3L8cefyEsjy7wdfovm3QW58VkIdB1DEHwIQFJjoImZvRnKDQMOjy33fPj/faBNeN2TaPCH6cC7QFOikcwnA+dKuhHY18xWZnF/qpV6dWtTv24dAI48aE+KijfwybxvN+af0atkKxbgpTc+4IgDdgegaZOtabdzC+Z/9QNffruUbp13o6CgFoWFtejWqR2fzP+WfLf99tvTqtVOfDo76vse9/pY9tyrfcryR/c8ho8+nMHq1aspKipi/Ftvstde7Vm1ahXffPMNELWOX311FHvssWdO9qEqSFCrltJONc2WdnXB2vB/MZvqLuBSMxudXFjS4cBxwGOS7jSz4bmpZuUbdus5dOvcjmZNGjD31Zu46aFRLF3+I3dfdTrNtmnA8wMvYMbsrzjx4vtpvk1DXnrgYjZsML5etIz+1w8rsa5Tj+7ESZc+WCJtzDuzOOrgvZj63HUUFxvX/v1Fliz/kedfm8YRB+zOlGeuxTDGvDOLUW+VOG+Zt+7++32ce/ZZrFu3jja77srghx/l3y++wO8vv5TFixZxSp/j2K9DR14aNZptttmGyy7/PYcdfACSOKbXsfQ+9ji+++47Tjv5RNatXUvxhmKO6H4k5//2grI3vsWqma3VdBSNnZCFFUttgP+Y2T5lpYfW5iozu0vSB8AlZjY+pDc2syskjQP+aGZTJDUDpphZG0kDiEbYOd3M1kvaHfgKaAZ8ZWZFki4H2pjZ5ZKWAi3MbH2Keq8yswbp9q1W/Ra21R5nlPuYuM2zdPKgqq5CXqpXW+9X1iDadbff3VqfPTBtmTl39q607VUH1bEl2w94SFJ9YB5hWLI0HibqOpgaxn5cRPTcne7AnyStB1YRjQkJMBiYIWlqol/WOZcjobsgn+Q8yJrZApKGEDOzG2OvpwNdS1mue+z1YkKfrJltILosK/nSrGFseuBZfD1XAVdVrPbOuc0h8i/IZvPEVzHQOHEzQnWXuBkB8ItAncsiP/FVSczsS0o+P6daM7PPgBpxM4Jz1ZaiKwzySXXsk3XO1VAi/8Yu8CDrnMuhmtklkI4HWedcTnlL1jnnssX7ZJ1zLnvy8RIuD7LOuZzy7gLnnMuiPIuxVTYKl3MuD1XWKFySrpA0M4wV/aSkupJ2kfSupDmSnpZUJ5TdKszPDfltYuu5JqTPlnRMLL1XSJsr6erN2WcPss65HNr8x89IaglcBnQJA00VAH2B24F7zKwdsJRorGnC/0vNbDfgnlAOSe3DcnsDvYAHwkMACoD7gd5Ae+DMULZCPMg653Kqkm6rLSR6ykkhUB/4BjgSSDxKeRjRQFEAfdg0jskIoEcYTKoP8JSZrTWz+cBc4MAwzTWzeWa2DngqlK3Y/lZ0QeecK7dwCVe6CWiWeNRTmAbEV2FmXwF3AV8QBdflRAP5LzOzolBsIdAyvG4JfBmWLQrlm8bTk5ZJlV4hfuLLOZczGd5WuzjdeLLhuX99gF2AZcCzRD/tkyUGyy5tg5YmvbTGZ4UH3vYg65zLqUq4TvYoYL6ZLQKQ9DxwCNBEUmForbYCvg7lFxINVrUwdC80BpbE0hPiy6RKLzfvLnDO5VQlPEjxC6CrpPqhb7UH8DHwBpB4nno/IPFEypFhnpD/ukWPhBkJ9A1XH+xC9GzA94ieD9guXK1Qh+jk2MiK7q+3ZJ1zuVMJt9Wa2buSRgBTgSJgGtETT14GnpJ0c0h7JCzyCNFz/uYStWD7hvXMlPQMUYAuAi42s2IASZcAo4muXBhiZjMrWt+UQVZSozJ2dEVFN+qcy0+qpFG4zOwG4Iak5HlEVwYkl/0JOD3Fem4BbiklfRQwarMrSvqW7Ex+3jmcmDegdWVUwDmXX2rl2S1fKYOsmW0xTzVwzm058izGZnbiS1JfSdeG160kdc5utZxzNZEEBbWUdqppygyykgYB/wP8OiStBh7KZqWcczVXJVxdsEXJ5OqCQ8ysk6RpAGa2JDHwgnPOlYfwPtnSrJdUi3DHg6SmwIas1so5V2PVwB6BtDLpk70feA5oLul/gQmEUWycc65cyugqyMvuAjMbLul9olvZAE43s4+yWy3nXE0kqJEnt9LJ9I6vAmA9qQdPcM65jNTAxmpamVxdcB3wJLAj0UAJT0i6JtsVc87VTN5d8HO/Ajqb2WoASbcQjd14azYr5pyreRLXyeaTTILs50nlConuEXbOuXLLrxCbfoCYe4j6YFcDMyWNDvM9ia4wcM65cquJXQLppGvJJq4gmEk0hFjCpOxVxzlXk0k189bZdNINEPNIqjznnKuoPGvIlt0nK6kt0XiL7YG6iXQz2z2L9XLO1UD5eJ1sJte8DgUeJTo+vYFniB6R65xz5ZZvl3BlEmTrm9loADP7zMyuJxqVyznnyk1lTDVNJpdwrQ0PK/tM0gXAV0CL7FbLOVcT+XWypbsCaABcRtQ32xg4L5uVcs7VXDWxSyCdTAaIeTe8XMmmgbudc65C8izGpr0Z4QXCGLKlMbNTslIj51yN5dfJljQoZ7XYwnTcqzXjJ95X1dXIO9MWLKvqKrhK4N0FgZmNzWVFnHP5Id/GSs23/XXOVaHEzQib+7RaSU0kjZD0iaRZkg6WtK2kMZLmhP+3CWUlaaCkuZJmSOoUW0+/UH6OpH6x9M6SPgzLDNRmNL89yDrncqqW0k8Zuhd41cz2BDoAs4CrgbFm1g4YG+YhuomqXZgGAA8CSNoWuAE4CDgQuCERmEOZAbHlelV4fzMtKGmrim7EOedg03Wym9OSldQIOBx4BMDM1pnZMqAPMCwUGwacFF73AYZbZBLQRNIOwDHAGDNbYmZLgTFAr5DXyMwmmpkBw2PrKrdMnoxwoKQPgTlhvoMkP+vjnKsQKf0ENJM0JTYNSFrFrsAi4FFJ0yQ9LGlrYDsz+wYg/J+4aaol8GVs+YUhLV36wlLSKySTmxEGAscDLwKY2QeS/LZa51y5CahVdvfmYjPrkia/EOgEXGpm70q6l01dA6k2m8wqkF4hmXQX1DKzz5PSiiu6QedcfitQ+ikDC4GFsRulRhAF3e/CT33C/9/Hyu8UW74V8HUZ6a1KSa+QTILsl5IOBExSgaTLgU8rukHnXP6SRK0yprKY2bdEcWmPkNQD+BgYCSSuEOgH/Du8HgmcHa4y6AosD90Jo4GekrYJJ7x6AqND3kpJXcNVBWfH1lVumXQXXEjUZdAa+A54LaQ551y5VdK9CJcCj0uqQ/TMwXOJGo3PSOoPfAGcHsqOAo4F5hI9TutcADNbIukmYHIo91czWxJeX0g0zGs94JUwVUgmYxd8D/St6Aaccy5BQGEl3FZrZtOB0vpte5RS1oCLU6xnCDCklPQpwD6bWU0gsycj/JNSOn3NLPmMn3POlSnP7qrNqLvgtdjrusDJlLzswTnnMlO+Gw5qhEy6C56Oz0t6jOiiXeecKxcBBXnWlM2kJZtsF2Dnyq6Icy4/eEs2iaSlbOqTrQUsIf2Fv845l5IPdRgTrhHrQPRcL4AN4Uydc86VWzR2QVXXIrfS7m4IqC+YWXGYPMA65zbL5t6MsKXJ5Dvlvfj4i845V1HReLLpp5om3TO+Cs2sCDgMOF/SZ8CPRMfJzMwDr3OunEStUsdfqbnS9cm+RzToQoXHUXTOuTjhNyPECcDMPstRXZxzNZ0q57baLUm6INtc0u9TZZrZ3Vmoj3OuBvOWbEkFQANKH8DWOecqpCZeQZBOuiD7jZn9NWc1cc7VeNFttVVdi9wqs0/WOecqjfyOr7ifjcvonHObK79CbJogGxsh3DnnKoWPwuWcc1mWZzHWg6xzLneEvCXrnHPZ5Ce+nHMui/IrxHqQdc7lkOQnvpxzLqu8u8A557Iov0JsZoN2O+dcpUhcJ5tuynhdUoGkaZL+E+Z3kfSupDmSnpZUJ6RvFebnhvw2sXVcE9JnSzomlt4rpM2VtFnPNPQg65zLKSn9VA6/A2bF5m8H7jGzdsBSoH9I7w8sNbPdgHtCOSS1B/oCewO9gAdC4C4A7gd6A+2BM0PZCvEg65zLIZX5L6O1SK2A44CHw7yAI4ERocgwNj1woE+YJ+T3COX7AE+Z2Vozmw/MBQ4M01wzm2dm64CnQtkK8T5Z51zOZHhbbTNJU2Lzg81scFKZvwNXAg3DfFNgWXhkFsBCoGV43RL4EsDMiiQtD+VbApNi64wv82VS+kFlVToVD7LOudzJrEtgsZl1SbkK6XjgezN7X1L3TWv+GSsjL1V6ab/wK/ykbg+yzrmcqoRBuw8FTpR0LFAXaETUsm0SewBsK+DrUH4hsBOwUFIh0BhYEktPiC+TKr3cvE/WOZczAmop/VQWM7vGzFqZWRuiE1evm9lZwBvAaaFYP+Df4fXIME/If93MLKT3DVcf7AK0I3qA7GSgXbhaoU7YxsiK7rO3ZJ1zOZXpya0KuAp4StLNwDTgkZD+CPCYpLlELdi+AGZv+sxoAAAVJUlEQVQ2U9IzwMdAEXCxmRUDSLoEGE30GK4hZjazopXyluwW7tPZszn4gP03Tjs0a8z9A//OjA+m8z/dDubgA/an28EHMGXyewC89eY4dmzeZGP5W2/5a9r1uE3Wrv2J/qf24OwTDuOs3gfz8L23lsi/+69X0qNDq43zLzwxhF8ddwj9TujGBX17MX/OJyXKf/v1l/To0IonHr4PgM/nzaHfCd02Tkd1bM3Tjz6Y/R3LsVpS2qk8zGycmR0fXs8zswPNbDczO93M1ob0n8L8biF/Xmz5W8ysrZntYWavxNJHmdnuIe+Wzdlfb8lu4XbfYw8mTp4GQHFxMe12acUJfU7mkgsHcM11f6Fnr96MfmUU1197Fa+OeQOAQw7txogXX8poPW6TOnW24r7h/6b+1g0oWr+eC/r2puvhR7HP/gcw68NprFyxvET5niecxsm/PA+A8WNHMfDW67lnyIiN+QNvuY6uhx+1cX7nXdsx7KXxQPQ36HNYew7veVwO9ix3Et0F+STnLVlJbSStkTQ9zC9ITo9NdbKw/e6xO0TOkXRjeH2FpC8kDarsbebKuNfHsuuubWm9885IYsXKFQAsX7GcHXbYsULrcZtIov7WDQAoKlpPUdF6JFFcXMz9t/+Fi6/83xLlt27YaOPrNatXlzir/uaYl9lxp53Zpd2epW5ryjtv0rJ1G3Zo2bryd6RKVc51sluSqmrJfmZmHcuRDkDszGGlM7N7JC0FUl46Ut2NePYpTjujLwC333UPJ53Qi+uu/hMbNmxg7Li3N5Z7792JdO3SkR122JFbbr+T9u33TrkeV1JxcTHnndSdhV/M55Sz+rN3xy48PfQhDuvRm2Yttv9Z+ef+9U+eHPIARevXcd9j0bmTNat/5F+D7+Xeoc/zxCOlf6e/9vLzHH38qVndlyqR4cmtmqQ69MkuSpcp6UZJgyX9FxgeWrzjJU0N0yGh3MYWapgfJOmc8LqXpE8kTQBOia1+DbAqk0pKGiBpiqQpixenrXKVWLduHS//5yVOPvV0AB4e/CC33Xk3sz/7gtvuvJuLfvsbADru34mP5yxg0pTpXHDRJZx52slp1+NKKigoYNhL43lx/ExmzZjKtPfe5o1XX+S0Xw8otfypvzqfEa9P46I/3cjQB+4C4OGBt9H33As3toqTrV+3jgmvv8KRvU8qNX9LFnUXVF6f7JagyoOsmR0Qm20b6yq4P5beGehjZr8EvgeONrNOwC+AgenWL6ku8E/gBKAbsLG5YWZPm9ldGdZzsJl1MbMuzZo1z2jfcum/r75Cx46d2G677QB44l/D6XNS9H1yyqmn8/6U6MRXo0aNaNAg+nAf0/tY1hetZ/HixSnX40rXsFFj9j/oMKa+O4GFn8/njKM6cUr3/fhpzWpO79HpZ+WPOv5U3hrzMgAffzCF+++4gVO678czQx9k2EN3M+KxTTc0TXzrNXZv34Ftm7XI2f7kksqYaprqduIrVXfBSDNbE17XBgZJ6ggUA7uXsc49gflmNgdA0r+A0psdW7Bnn3mK03+x6Sf+9jvsyPi33uTwI7oz7o3XabtbOwC++/ZbWmy3HZKYMvk9NmzYQNOmTVOux22y9IfFFNauTcNGjVn70xqmvDOOX53/O/4zcfbGMj06tOLZsVMB+HLBZ+zUpi0A77wxeuPrB5/ceBKbhwfeRv36W5doCY/5z4ia2VUQ+Hiy1dOPsddXAN8BHYha4j+F9CJKtszrxl5X+Ja4LcHq1at5Y+wYBt7/0Ma0QQ8O5so/XE5RURF169blvgf+AcALz4/g4cEPUVhYSL169Rj62JMb3/Slrcdt8sOib7npyovYsKGYDRs20KP3yRx6ZK+U5Uc89k+mvPMmhYWFNGzchOvveKDMbfy0ZjWT3x7HVTfdU5lVr1byLMZuMUE2rjGw0Mw2SOpHdLEwwOdAe0lbEQXYHsAE4BNgF0ltzewz4MyqqHQ21a9fny++WVwi7ZBDD2PCpCk/K3vBRZdwwUWXZLwet8lue+7DsJFvpS0z9oOFG19f8efbylznby4rOVRp3Xr1eXXyvBSla4Z8C7JV3idbAQ8A/SRNIuoq+BHAzL4EngFmAI8T3fGBmf1E1D3wcjjx9XlVVNo5l+h39Uu4qoSZLQD2KSX9xqT5OcB+saRrYnlXEg1/lryOV4n6Zp1zVan8A3Nv8aqiJVsMNE7cjFBdSLqCKGCvqOq6OFeTVeKTEbYIOW/Jhp/1O5VZMMfM7B6iR1M457KmZnYJpFNtugucc/mhJrZW0/Eg65zLGeFB1jnnssq7C5xzLou8Jeucc9lSQ68gSMeDrHMup7y7wDnnsiQfn4zgQdY5l1seZJ1zLnu8u8A557LIuwuccy6bPMg651x2JIY6zCdb4niyzrktVXhabbqpzFVIO0l6Q9IsSTMl/S6kbytpjKQ54f9tQrokDZQ0V9IMSZ1i6+oXys8JDwFIpHeW9GFYZqA245k5HmSdc7m1+U9SLAL+YGZ7AV2BiyW1B64GxppZO2BsmAfoDbQL0wDgQYiCMnADcBBwIHBDIjCHMgNiy6V+zlAZPMg653KorOcilB1lzewbM5saXq8EZgEtgT7AsFBsGJB4pnofYLhFJgFNJO0AHAOMMbMlZrYUGAP0CnmNzGyimRkwPLaucvM+WedczmR4M0IzSfEH1A02s8GlFZTUBtgfeBfYzsy+gSgQS0o8U70l8GVssYUhLV36wlLSK8SDrHMut8oOsovNrEuZq5EaAM8Bl5vZijTdpqVlWAXSK8S7C5xzOVVLSjtlQlJtogD7uJk9H5K/Cz/1Cf9/H9IXUvJpLK2Ar8tIb1VKeoV4kHXO5dTmnvcKZ/ofAWaZ2d2xrJFA4gqBfsC/Y+lnh6sMugLLQ7fCaKCnpG3CCa+ewOiQt1JS17Cts2PrKjfvLnDO5U7lDHV4KPBr4MPYA1mvBW4DnpHUH/gCOD3kjQKOBeYCq4FzAcxsiaSbgMmh3F/NbEl4fSEwFKgHvBKmCvEg65zLmejxM5sXZc1sAqkbvT1KKW/AxSnWNQQYUkr6FGCfzajmRh5knXM5lV/3e3mQdc7lmD8ZwTnnsmhzuwu2NB5knXM5lV8h1oOscy6H5A9SdM657PLuAuecy6L8CrEeZJ1zOZX5rbM1hQdZ51zORDcjVHUtcsvHLnDOuSzylqxzLqe8u8A557LFL+FyzrnsyfwxXjWHB1nnXE75dbLOOZdFeRZjPcg653Irz2KsB1nnXG7lW3eBokHDXXlIWgR8XtX1qKBmwOKqrkQe2pKP+85m1rwyViTpVaJjkc5iM+tVGdurDjzI5hlJUzJ53LKrXH7c85ff8eWcc1nkQdY557LIg2z+GVzVFchTftzzlPfJOudcFnlL1jnnssiDrHPOZZEHWeecyyIPsnlGkv/Nncsh/8DlEUkNzGyDB9rcknSZpJ5VXQ9XNfzDlick/RtYIKmlB9rckXQtcBFwmqTeVV0fl3v+QcsDkloD04EHgYkeaHPqReBoYCJwigfa/OOjcNVwkg42s4nADWG+NvCupIPM7CtJtcxsQ9XWsuaR9AugiZn9I8y/AdQDTpaEmb1SpRV0OeMtmRpM0s7AaEm/SqSZ2dXAMKJA6y3a7FkPtJXUH8DMFgAjiX5RnOwt2vzhLdkaKrRQP5f0P8DTkj4CPjKzIjO7Lozp+a6kA83sa2/RVg5JlwK1zexuSWuB4kSemS2UNDLMniJJZjaqSirqcsaDbA0kaT8zmxFmVwBdzGxZyKtlZhtCoC0A3ksE2iqrcA0haSvgE+AiScvMbEgsTxZZKOllYBVwqqSVZja+qursss9/JtZMZ0oaKWkEcHpygE10D4Sug+eAVyX5F+5mkFRgZmuBCcB7wG8SXQWJIokXZvZ5KHMosCinFXU55wPE1CDxn/ySvgZ+MrNdw3wdM1sXXovob79B0iDgRTN7rcoqXkOEL6//AlOBHYFtgP+a2b2J/Njf5zBglZlNr6r6utzwIFtDhJZUcbh6YHdgX+BiYJGZnRLKyJL+4OEGhVW5r3HNI+lIYICZ9ZXUGOgAXA2MiHcduPzi3QU1QGghFcdaUvuZ2VNm1g1oIenFUPQ+SSUegeIBtuIUeyKgpLrAOqCzpEZmthz4gKhP/HJJR1VRNV0V8yBbA4Sf/SK68P0tM3tSUqGk2mZ2GFBP0kSgoZlNqdra1hyJXwWS/gCcZmYTiPq475PUMATaJcBfvDsmf/nJji1Y0s//+sD3wCRJpwN9gCaSnjazYyTta2YflrKcK6dSLncrBA6T9BPwL+BsYLKkL4i6a14My/lxz0PeJ7uFSvTBhteNgB+BPwAnAu8SneVuBLQ1s7/ElvMPeiUIvxyOMrMxYf4Sor7wcWb2vKT9gDqJXw5+3POXt2S3QEl9sI8Bq4GZwH+AR8zsh1BuONHP1Y38g15pDgf+Kqm5mT1hZoMk3QD8RVI9opNda6HUlq/LI94nuwWK9cE+TtRqHQ7cBDQysx8ktZQ0lOiXyuVQ8iSNK79w48ZGZvYmcDfwS0lnheSbiL7wSATY8NoDbB7zluyWqyXwBfAycA9wo5lNkrQN0d1Ej8d+ynpLajPELo+rBdwKLAXGm9mz4bvr0jDSWXvgdTN7vAqr66oZb8luIZJbUkR3Cm1N1EUwzsz+L5QZBuwaC7DyALt5YgH2JaIvsNXAK5J6mNmzwDVAO+BzM7se/JeD28RbsluApD7Y84j6WV8E3gb2BKaHEbduJzqbPS2xrPfBVlzSL4ATgMnA/xEd+2eBUZL6mNmrkt41s6JSlnN5zq8uqOZiP1VF1Go1ogvcGxF98M8lugd+W6KW1MY+WA+wFRcb56EAuBn4J/ANcB+w0MxulPQv4JdEN398FJbz4+5K8JZsNRcLsJcDH5jZtQDhxNZLwElmNkTSNma2NOR5S2ozxY7f7cBSM5sHIOkb4LOQNxe4LBFgw3IeYF0J3idbTankQNp7E3UT7CmpGYCZnUN088EHYQStxEhb3ge7GSTdIWmn8PoC4BDgnTBfSPQr4ghJU4EdzWxQyPPPkiuVdxdUQ0k3GjQws1WSdgUeBp4EnjKzlSG/v5k9UoXVrTEk3Qu0N7Ojw/yhwAVEJxkfMLO5YQCePYBWZvZqKOddBC4lD7LVjEqO+fokUAAUEfUJziMKtCOILtFaEVvOP+ibQdJTRE80ODXMH0V0YrEzcBKwGHjOzOYkLeddMy4t/4lTjSR+6ocA+wTwFfAn4Cmia2F3Bi4jesR05/iyHmArLpzcahKb/w1wHbBVGPTlP0Bz4BxJzePLeoB1ZfETX9WEpDOBupKGh5Ndy4CBFj2Ab76iR5v82sz6SzrNzGZXaYVrCElnm9lwSScCj0j6FPgB6G3hiRJmNi4MZbitmfmTDFy5eEu2Ggj9fK2JBnk+IyTXAQbFis0CGkqqmwiwfsF7pbhc0kCLnhoxgOg25VW26ZE9tQHM7FUzeyKk+XF3GfMgWw2Y2XrgXqLnPp0o6WiiEy5rJL0iaV/geuBbM/sptpx3EVSQpFGSTgEOBg6UdJyZrSHqivla0guh+2Z9KeMW+HF3GfMgW4UkXZr4AIfg2YJodKfTgOOILnSfC/QDvjazy8Jy3pLaDJL2Bo4m6nNdCxxqZi8DhKs2LiG6VGtcSCtOsSrnyuR9slUkBNfewP8Ap0g6BzgVOBI4MPy/3swuTVrOz2ZvJjObKakPcLOkQjN7DKKuATNbb2YrJV0K9K3amrqawINsFYidbDmJ6GTLbKLxCI4zsyWKnjTbEDhd0mIzmxSW8xsNKomZjQo/CG6TtM7Mng5dA7LICmAw+OVxbvP4dbJVINwtNMHMLlM0wPNgYPvERfChTH3gYDMbW1X1zAeSjgVuA24xs6dDmv9acJXG+2RzKNOTLQBmtjoRYL0PNnvMbBTRY7uvUxh8OxFg/bi7yuAt2RwJJ1umA2db9DTZjbfOhvyGRJdstTGzI6qqnvkqtGhvBh4CmprZrVVcJVdDeJ9sjvjJluot9NGK6LblflVdH1dzeEs2x1L0Af7sxIqfbKkakhqb2fKqroerObwlm2NJZ7UJZ7Ut+WSLB9iq4QHWVTYPslUgKdAWmtnj8ZMtHmCdqzk8yFaRWKC9WdLWhJMtHmCdq1k8yFYhP9niXM3nJ76qAT/Z4lzN5UHWOeeyyO/4cs65LPIg65xzWeRB1qUkqVjSdEkfSXo2DFpT0XV1l/Sf8PpESVenKdtE0kUV2MaNkv6YaXpSmaGSTivHttpI+qi8dXT5x4OsS2eNmXU0s32AdURPa9hIkXK/h8xspJndlqZIE6JBc5zb4nmQdZkaD+wWWnCzJD0ATAV2ktRT0kRJU0OLtwGApF6SPpE0ATglsSJJ50gaFF5vF0Yf+yBMhxDddtw2tKLvDOX+JGmypBmS/je2ruskzZb0GrBHWTsh6fywng8kPZfUOj9K0nhJn0o6PpQvkHRnbNu/3dwD6fKLB1lXJkmFRE9x+DAk7QEMN7P9gR+Jnj92lJl1AqYAv1f0dNd/AicA3YDtU6x+IPCmmXUAOgEziYYe/Cy0ov8kqSfQjuiJER2BzpIOl9SZaECd/YmC+AEZ7M7zZnZA2N4soH8srw1wBNGjfx4K+9AfWG5mB4T1ny9plwy24xzgNyO49OpJmh5ejwceAXYEPk88rQHoCrQH3g53sNUBJgJ7AvPNbA6ApH8RPQ022ZHA2bDxWVrLJW2TVKZnmKaF+QZEQbch8IKZrQ7bGJnBPu0j6WaiLokGwOhY3jPh9uY5kuaFfegJ7Bfrr20ctv1pBttyzoOsS2uNmXWMJ4RA+mM8CRhjZmcmlesIVNZF2AJuNbN/JG3j8gpsYyhwkpl9oOi5at1jecnrsrDtS80sHoyR1Kac23V5yrsL3OaaBBwqaTeIHpsjaXfgE2AXSW1DuTNTLD8WuDAsWyCpEbCSqJWaMBo4L9bX21JSC+At4GRJ9cKg5ydkUN+GwDeSagNnJeWdLqlWqPOuwOyw7QtDeSTtHsaacC4j3pJ1m8XMFoUW4ZOStgrJ15vZp5IGAC9LWgxMAPYpZRW/AwZL6g8UAxea2URJb4dLpF4J/bJ7ARNDS3oV8CszmyrpaaInTnxO1KVRlj8D74byH1IymM8G3gS2Ay4ws58kPUzUVzs1jDOxCDgps6PjnN9W65xzWeXdBc45l0UeZJ1zLos8yDrnXBZ5kHXOuSzyIOucc1nkQdY557LIg6xzzmXR/wPLjf8jkRZqbQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna4.predict(x_data,y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list5 = [100,100,100,1]\n",
    "activation_list5 = ['tanh','tanh','tanh','sigmoid']\n",
    "dropout_list5 = [0.3,0.3,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,401\n",
      "Trainable params: 40,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rna5 = new_rna()\n",
    "rna5.build_model(data_shape,n_list5,activation_list5,dropout_list5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168135 samples, validate on 30001 samples\n",
      "Epoch 1/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.4143 - f1: 0.5505 - val_loss: 0.2856 - val_f1: 0.0721\n",
      "Epoch 2/2000\n",
      "168135/168135 [==============================] - 9s 53us/step - loss: 0.3940 - f1: 0.5864 - val_loss: 0.2769 - val_f1: 0.0707\n",
      "Epoch 3/2000\n",
      "168135/168135 [==============================] - 9s 53us/step - loss: 0.3911 - f1: 0.5936 - val_loss: 0.2812 - val_f1: 0.0716\n",
      "Epoch 4/2000\n",
      "168135/168135 [==============================] - 9s 53us/step - loss: 0.3896 - f1: 0.5940 - val_loss: 0.2805 - val_f1: 0.0709\n",
      "Epoch 5/2000\n",
      "168135/168135 [==============================] - 9s 53us/step - loss: 0.3882 - f1: 0.5985 - val_loss: 0.2790 - val_f1: 0.0712\n",
      "Epoch 6/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3879 - f1: 0.5971 - val_loss: 0.2812 - val_f1: 0.0711\n",
      "Epoch 7/2000\n",
      "168135/168135 [==============================] - 9s 52us/step - loss: 0.3870 - f1: 0.5980 - val_loss: 0.2817 - val_f1: 0.0719\n",
      "Epoch 8/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3856 - f1: 0.6019 - val_loss: 0.2845 - val_f1: 0.0718\n",
      "Epoch 9/2000\n",
      "168135/168135 [==============================] - 9s 53us/step - loss: 0.3855 - f1: 0.5995 - val_loss: 0.2793 - val_f1: 0.0716\n",
      "Epoch 10/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3852 - f1: 0.6006 - val_loss: 0.2808 - val_f1: 0.0713\n",
      "Epoch 11/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3844 - f1: 0.6008 - val_loss: 0.2805 - val_f1: 0.0716\n",
      "Epoch 12/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3838 - f1: 0.6023 - val_loss: 0.2808 - val_f1: 0.0712\n",
      "Epoch 13/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3830 - f1: 0.6004 - val_loss: 0.2773 - val_f1: 0.0711\n",
      "Epoch 14/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3831 - f1: 0.6000 - val_loss: 0.2811 - val_f1: 0.0717\n",
      "Epoch 15/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3824 - f1: 0.5988 - val_loss: 0.2793 - val_f1: 0.0709\n",
      "Epoch 16/2000\n",
      "168135/168135 [==============================] - 9s 53us/step - loss: 0.3814 - f1: 0.6008 - val_loss: 0.2777 - val_f1: 0.0706\n",
      "Epoch 17/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3813 - f1: 0.5998 - val_loss: 0.2791 - val_f1: 0.0709\n",
      "Epoch 18/2000\n",
      "168135/168135 [==============================] - 9s 53us/step - loss: 0.3804 - f1: 0.6006 - val_loss: 0.2814 - val_f1: 0.0712\n",
      "Epoch 19/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3800 - f1: 0.6020 - val_loss: 0.2791 - val_f1: 0.0710\n",
      "Epoch 20/2000\n",
      " 35456/168135 [=====>........................] - ETA: 6s - loss: 0.3832 - f1: 0.59"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3749 - f1: 0.6049 - val_loss: 0.2759 - val_f1: 0.0700\n",
      "Epoch 29/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3749 - f1: 0.6027 - val_loss: 0.2765 - val_f1: 0.0699\n",
      "Epoch 30/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3744 - f1: 0.6020 - val_loss: 0.2743 - val_f1: 0.0692\n",
      "Epoch 31/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3734 - f1: 0.6045 - val_loss: 0.2752 - val_f1: 0.0697\n",
      "Epoch 32/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3730 - f1: 0.6051 - val_loss: 0.2764 - val_f1: 0.0699\n",
      "Epoch 33/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3720 - f1: 0.6061 - val_loss: 0.2741 - val_f1: 0.0699\n",
      "Epoch 34/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3723 - f1: 0.6051 - val_loss: 0.2762 - val_f1: 0.0700\n",
      "Epoch 35/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3716 - f1: 0.6046 - val_loss: 0.2799 - val_f1: 0.0706\n",
      "Epoch 36/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3706 - f1: 0.6098 - val_loss: 0.2751 - val_f1: 0.0701\n",
      "Epoch 37/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3697 - f1: 0.6083 - val_loss: 0.2743 - val_f1: 0.0694\n",
      "Epoch 38/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3695 - f1: 0.6086 - val_loss: 0.2757 - val_f1: 0.0699\n",
      "Epoch 39/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3687 - f1: 0.6072 - val_loss: 0.2754 - val_f1: 0.0699\n",
      "Epoch 40/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3690 - f1: 0.6092 - val_loss: 0.2741 - val_f1: 0.0696\n",
      "Epoch 41/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3678 - f1: 0.6087 - val_loss: 0.2750 - val_f1: 0.0698\n",
      "Epoch 42/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.3673 - f1: 0.6098 - val_loss: 0.2719 - val_f1: 0.0691\n",
      "Epoch 43/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3661 - f1: 0.6120 - val_loss: 0.2726 - val_f1: 0.0692\n",
      "Epoch 44/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3663 - f1: 0.6118 - val_loss: 0.2750 - val_f1: 0.0694\n",
      "Epoch 45/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3650 - f1: 0.6128 - val_loss: 0.2749 - val_f1: 0.0698\n",
      "Epoch 46/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3649 - f1: 0.6139 - val_loss: 0.2728 - val_f1: 0.0696\n",
      "Epoch 47/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3642 - f1: 0.6165 - val_loss: 0.2723 - val_f1: 0.0690\n",
      "Epoch 48/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3637 - f1: 0.6160 - val_loss: 0.2754 - val_f1: 0.0698\n",
      "Epoch 49/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3627 - f1: 0.6184 - val_loss: 0.2730 - val_f1: 0.0691\n",
      "Epoch 50/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3624 - f1: 0.6173 - val_loss: 0.2736 - val_f1: 0.0693\n",
      "Epoch 51/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3620 - f1: 0.6177 - val_loss: 0.2728 - val_f1: 0.0694\n",
      "Epoch 52/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3600 - f1: 0.6193 - val_loss: 0.2707 - val_f1: 0.0687\n",
      "Epoch 53/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3595 - f1: 0.6208 - val_loss: 0.2710 - val_f1: 0.0686\n",
      "Epoch 54/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3598 - f1: 0.6220 - val_loss: 0.2693 - val_f1: 0.0684\n",
      "Epoch 55/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3593 - f1: 0.6223 - val_loss: 0.2711 - val_f1: 0.0686\n",
      "Epoch 56/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3574 - f1: 0.6248 - val_loss: 0.2713 - val_f1: 0.0689\n",
      "Epoch 57/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3567 - f1: 0.6243 - val_loss: 0.2721 - val_f1: 0.0690\n",
      "Epoch 58/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3572 - f1: 0.6247 - val_loss: 0.2725 - val_f1: 0.0689\n",
      "Epoch 59/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3548 - f1: 0.6292 - val_loss: 0.2704 - val_f1: 0.0685\n",
      "Epoch 60/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3554 - f1: 0.6280 - val_loss: 0.2699 - val_f1: 0.0681\n",
      "Epoch 61/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3547 - f1: 0.6288 - val_loss: 0.2712 - val_f1: 0.0685\n",
      "Epoch 62/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3531 - f1: 0.6317 - val_loss: 0.2713 - val_f1: 0.0685\n",
      "Epoch 63/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3531 - f1: 0.6323 - val_loss: 0.2708 - val_f1: 0.0678\n",
      "Epoch 64/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3530 - f1: 0.6272 - val_loss: 0.2688 - val_f1: 0.0679\n",
      "Epoch 65/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3518 - f1: 0.6352 - val_loss: 0.2688 - val_f1: 0.0677\n",
      "Epoch 66/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3508 - f1: 0.6341 - val_loss: 0.2676 - val_f1: 0.0677\n",
      "Epoch 67/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3501 - f1: 0.6323 - val_loss: 0.2713 - val_f1: 0.0686\n",
      "Epoch 68/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3497 - f1: 0.6343 - val_loss: 0.2693 - val_f1: 0.0681\n",
      "Epoch 69/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3494 - f1: 0.6354 - val_loss: 0.2690 - val_f1: 0.0678\n",
      "Epoch 70/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3478 - f1: 0.6343 - val_loss: 0.2699 - val_f1: 0.0682\n",
      "Epoch 71/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3479 - f1: 0.6386 - val_loss: 0.2687 - val_f1: 0.0680\n",
      "Epoch 72/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3467 - f1: 0.6416 - val_loss: 0.2668 - val_f1: 0.0676\n",
      "Epoch 73/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3456 - f1: 0.6429 - val_loss: 0.2683 - val_f1: 0.0674\n",
      "Epoch 74/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3446 - f1: 0.6419 - val_loss: 0.2701 - val_f1: 0.0679\n",
      "Epoch 75/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3435 - f1: 0.6439 - val_loss: 0.2683 - val_f1: 0.0675\n",
      "Epoch 76/2000\n",
      "152640/168135 [==========================>...] - ETA: 0s - loss: 0.3440 - f1: 0.6448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3367 - f1: 0.6554 - val_loss: 0.2673 - val_f1: 0.0670\n",
      "Epoch 86/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3364 - f1: 0.6569 - val_loss: 0.2673 - val_f1: 0.0670\n",
      "Epoch 87/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3354 - f1: 0.6562 - val_loss: 0.2681 - val_f1: 0.0671\n",
      "Epoch 88/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3334 - f1: 0.6603 - val_loss: 0.2686 - val_f1: 0.0672\n",
      "Epoch 89/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3334 - f1: 0.6618 - val_loss: 0.2680 - val_f1: 0.0669\n",
      "Epoch 90/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3328 - f1: 0.6599 - val_loss: 0.2667 - val_f1: 0.0665\n",
      "Epoch 91/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3327 - f1: 0.6610 - val_loss: 0.2675 - val_f1: 0.0667\n",
      "Epoch 92/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3312 - f1: 0.6619 - val_loss: 0.2666 - val_f1: 0.0663\n",
      "Epoch 93/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3317 - f1: 0.6610 - val_loss: 0.2681 - val_f1: 0.0670\n",
      "Epoch 94/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3315 - f1: 0.6633 - val_loss: 0.2692 - val_f1: 0.0672\n",
      "Epoch 95/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3303 - f1: 0.6659 - val_loss: 0.2693 - val_f1: 0.0670\n",
      "Epoch 96/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3301 - f1: 0.6623 - val_loss: 0.2694 - val_f1: 0.0673\n",
      "Epoch 97/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3281 - f1: 0.6685 - val_loss: 0.2676 - val_f1: 0.0663\n",
      "Epoch 98/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3274 - f1: 0.6683 - val_loss: 0.2684 - val_f1: 0.0667\n",
      "Epoch 99/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3269 - f1: 0.6679 - val_loss: 0.2673 - val_f1: 0.0661\n",
      "Epoch 100/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3256 - f1: 0.6712 - val_loss: 0.2686 - val_f1: 0.0666\n",
      "Epoch 101/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3251 - f1: 0.6730 - val_loss: 0.2674 - val_f1: 0.0664\n",
      "Epoch 102/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3246 - f1: 0.6748 - val_loss: 0.2684 - val_f1: 0.0661\n",
      "Epoch 103/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3242 - f1: 0.6744 - val_loss: 0.2663 - val_f1: 0.0660\n",
      "Epoch 104/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3248 - f1: 0.6725 - val_loss: 0.2686 - val_f1: 0.0664\n",
      "Epoch 105/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3227 - f1: 0.6754 - val_loss: 0.2675 - val_f1: 0.0663\n",
      "Epoch 106/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3227 - f1: 0.6747 - val_loss: 0.2665 - val_f1: 0.0658\n",
      "Epoch 107/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3226 - f1: 0.6759 - val_loss: 0.2697 - val_f1: 0.0668\n",
      "Epoch 108/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3214 - f1: 0.6753 - val_loss: 0.2673 - val_f1: 0.0655\n",
      "Epoch 109/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3211 - f1: 0.6767 - val_loss: 0.2674 - val_f1: 0.0658\n",
      "Epoch 110/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3202 - f1: 0.6768 - val_loss: 0.2691 - val_f1: 0.0660\n",
      "Epoch 111/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3196 - f1: 0.6808 - val_loss: 0.2690 - val_f1: 0.0659\n",
      "Epoch 112/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3192 - f1: 0.6798 - val_loss: 0.2669 - val_f1: 0.0654\n",
      "Epoch 113/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3178 - f1: 0.6829 - val_loss: 0.2680 - val_f1: 0.0656\n",
      "Epoch 114/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3172 - f1: 0.6833 - val_loss: 0.2674 - val_f1: 0.0655\n",
      "Epoch 115/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3161 - f1: 0.6828 - val_loss: 0.2710 - val_f1: 0.0659\n",
      "Epoch 116/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3169 - f1: 0.6814 - val_loss: 0.2695 - val_f1: 0.0660\n",
      "Epoch 117/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3155 - f1: 0.6848 - val_loss: 0.2683 - val_f1: 0.0652\n",
      "Epoch 118/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3147 - f1: 0.6852 - val_loss: 0.2671 - val_f1: 0.0651\n",
      "Epoch 119/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3146 - f1: 0.6874 - val_loss: 0.2692 - val_f1: 0.0657\n",
      "Epoch 120/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3125 - f1: 0.6892 - val_loss: 0.2713 - val_f1: 0.0659\n",
      "Epoch 121/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3129 - f1: 0.6894 - val_loss: 0.2691 - val_f1: 0.0658\n",
      "Epoch 122/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3131 - f1: 0.6895 - val_loss: 0.2711 - val_f1: 0.0665\n",
      "Epoch 123/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3129 - f1: 0.6905 - val_loss: 0.2719 - val_f1: 0.0665\n",
      "Epoch 124/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3119 - f1: 0.6924 - val_loss: 0.2686 - val_f1: 0.0654\n",
      "Epoch 125/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3112 - f1: 0.6909 - val_loss: 0.2670 - val_f1: 0.0653\n",
      "Epoch 126/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3106 - f1: 0.6907 - val_loss: 0.2690 - val_f1: 0.0657\n",
      "Epoch 127/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3092 - f1: 0.6938 - val_loss: 0.2718 - val_f1: 0.0661\n",
      "Epoch 128/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3084 - f1: 0.6941 - val_loss: 0.2683 - val_f1: 0.0648\n",
      "Epoch 129/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3103 - f1: 0.6927 - val_loss: 0.2714 - val_f1: 0.0653\n",
      "Epoch 130/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3078 - f1: 0.6967 - val_loss: 0.2704 - val_f1: 0.0657\n",
      "Epoch 131/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3069 - f1: 0.6971 - val_loss: 0.2690 - val_f1: 0.0654\n",
      "Epoch 132/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.3078 - f1: 0.6938 - val_loss: 0.2703 - val_f1: 0.0655\n",
      "Epoch 133/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.3060 - f1: 0.6977 - val_loss: 0.2707 - val_f1: 0.0656\n",
      "Epoch 134/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3064 - f1: 0.6968 - val_loss: 0.2674 - val_f1: 0.0644\n",
      "Epoch 135/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3048 - f1: 0.6990 - val_loss: 0.2692 - val_f1: 0.0655\n",
      "Epoch 136/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3054 - f1: 0.6974 - val_loss: 0.2683 - val_f1: 0.0649\n",
      "Epoch 137/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3059 - f1: 0.6992 - val_loss: 0.2704 - val_f1: 0.0657\n",
      "Epoch 138/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3051 - f1: 0.7012 - val_loss: 0.2698 - val_f1: 0.0650\n",
      "Epoch 139/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3032 - f1: 0.7000 - val_loss: 0.2706 - val_f1: 0.0654\n",
      "Epoch 140/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3028 - f1: 0.7021 - val_loss: 0.2689 - val_f1: 0.0654\n",
      "Epoch 141/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3036 - f1: 0.7009 - val_loss: 0.2716 - val_f1: 0.0650\n",
      "Epoch 142/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3006 - f1: 0.7037 - val_loss: 0.2716 - val_f1: 0.0651\n",
      "Epoch 143/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3011 - f1: 0.7053 - val_loss: 0.2700 - val_f1: 0.0646\n",
      "Epoch 144/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.3014 - f1: 0.7030 - val_loss: 0.2701 - val_f1: 0.0648\n",
      "Epoch 145/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.3010 - f1: 0.7051 - val_loss: 0.2729 - val_f1: 0.0656\n",
      "Epoch 146/2000\n",
      "131840/168135 [======================>.......] - ETA: 1s - loss: 0.3006 - f1: 0.7051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2974 - f1: 0.7101 - val_loss: 0.2724 - val_f1: 0.0656\n",
      "Epoch 155/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2958 - f1: 0.7097 - val_loss: 0.2706 - val_f1: 0.0644\n",
      "Epoch 156/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2951 - f1: 0.7127 - val_loss: 0.2699 - val_f1: 0.0642\n",
      "Epoch 157/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2947 - f1: 0.7157 - val_loss: 0.2702 - val_f1: 0.0641\n",
      "Epoch 158/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2963 - f1: 0.7125 - val_loss: 0.2737 - val_f1: 0.0652\n",
      "Epoch 159/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2941 - f1: 0.7153 - val_loss: 0.2705 - val_f1: 0.0646\n",
      "Epoch 160/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2950 - f1: 0.7124 - val_loss: 0.2697 - val_f1: 0.0638\n",
      "Epoch 161/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2941 - f1: 0.7121 - val_loss: 0.2718 - val_f1: 0.0647\n",
      "Epoch 162/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2942 - f1: 0.7126 - val_loss: 0.2718 - val_f1: 0.0642\n",
      "Epoch 163/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2924 - f1: 0.7169 - val_loss: 0.2762 - val_f1: 0.0653\n",
      "Epoch 164/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2924 - f1: 0.7177 - val_loss: 0.2691 - val_f1: 0.0640\n",
      "Epoch 165/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2944 - f1: 0.7128 - val_loss: 0.2700 - val_f1: 0.0638\n",
      "Epoch 166/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2915 - f1: 0.7197 - val_loss: 0.2732 - val_f1: 0.0645\n",
      "Epoch 167/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2924 - f1: 0.7154 - val_loss: 0.2731 - val_f1: 0.0645\n",
      "Epoch 168/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2909 - f1: 0.7188 - val_loss: 0.2713 - val_f1: 0.0647\n",
      "Epoch 169/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2900 - f1: 0.7172 - val_loss: 0.2715 - val_f1: 0.0641\n",
      "Epoch 170/2000\n",
      " 58336/168135 [=========>....................] - ETA: 6s - loss: 0.2875 - f1: 0.7226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2859 - f1: 0.7250 - val_loss: 0.2725 - val_f1: 0.0645\n",
      "Epoch 177/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2886 - f1: 0.7217 - val_loss: 0.2732 - val_f1: 0.0644\n",
      "Epoch 178/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2850 - f1: 0.7253 - val_loss: 0.2751 - val_f1: 0.0647\n",
      "Epoch 179/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2875 - f1: 0.7211 - val_loss: 0.2736 - val_f1: 0.0641\n",
      "Epoch 180/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2862 - f1: 0.7228 - val_loss: 0.2726 - val_f1: 0.0641\n",
      "Epoch 181/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2859 - f1: 0.7234 - val_loss: 0.2751 - val_f1: 0.0643\n",
      "Epoch 182/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2873 - f1: 0.7213 - val_loss: 0.2740 - val_f1: 0.0646\n",
      "Epoch 183/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2846 - f1: 0.7262 - val_loss: 0.2782 - val_f1: 0.0649\n",
      "Epoch 184/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2856 - f1: 0.7249 - val_loss: 0.2731 - val_f1: 0.0636\n",
      "Epoch 185/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2852 - f1: 0.7262 - val_loss: 0.2728 - val_f1: 0.0639\n",
      "Epoch 186/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2837 - f1: 0.7252 - val_loss: 0.2736 - val_f1: 0.0641\n",
      "Epoch 187/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2833 - f1: 0.7296 - val_loss: 0.2756 - val_f1: 0.0646\n",
      "Epoch 188/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2811 - f1: 0.7308 - val_loss: 0.2751 - val_f1: 0.0639\n",
      "Epoch 189/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2849 - f1: 0.7271 - val_loss: 0.2753 - val_f1: 0.0643\n",
      "Epoch 190/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2830 - f1: 0.7289 - val_loss: 0.2769 - val_f1: 0.0645\n",
      "Epoch 191/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2822 - f1: 0.7304 - val_loss: 0.2744 - val_f1: 0.0644\n",
      "Epoch 192/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2809 - f1: 0.7292 - val_loss: 0.2737 - val_f1: 0.0637\n",
      "Epoch 193/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2805 - f1: 0.7298 - val_loss: 0.2752 - val_f1: 0.0646\n",
      "Epoch 194/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2821 - f1: 0.7290 - val_loss: 0.2742 - val_f1: 0.0640\n",
      "Epoch 195/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2808 - f1: 0.7304 - val_loss: 0.2771 - val_f1: 0.0644\n",
      "Epoch 196/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2806 - f1: 0.7297 - val_loss: 0.2755 - val_f1: 0.0639\n",
      "Epoch 197/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2805 - f1: 0.7331 - val_loss: 0.2791 - val_f1: 0.0648\n",
      "Epoch 198/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2815 - f1: 0.7335 - val_loss: 0.2776 - val_f1: 0.0647\n",
      "Epoch 199/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2796 - f1: 0.7324 - val_loss: 0.2748 - val_f1: 0.0643\n",
      "Epoch 200/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2776 - f1: 0.7338 - val_loss: 0.2756 - val_f1: 0.0650\n",
      "Epoch 201/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2783 - f1: 0.7335 - val_loss: 0.2768 - val_f1: 0.0642\n",
      "Epoch 202/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2785 - f1: 0.7345 - val_loss: 0.2758 - val_f1: 0.0642\n",
      "Epoch 203/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2785 - f1: 0.7336 - val_loss: 0.2752 - val_f1: 0.0644\n",
      "Epoch 204/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2783 - f1: 0.7362 - val_loss: 0.2740 - val_f1: 0.0634\n",
      "Epoch 205/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2783 - f1: 0.7341 - val_loss: 0.2743 - val_f1: 0.0639\n",
      "Epoch 206/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2784 - f1: 0.7320 - val_loss: 0.2770 - val_f1: 0.0644\n",
      "Epoch 207/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2762 - f1: 0.7354 - val_loss: 0.2767 - val_f1: 0.0641\n",
      "Epoch 208/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2775 - f1: 0.7342 - val_loss: 0.2780 - val_f1: 0.0641\n",
      "Epoch 209/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2774 - f1: 0.7339 - val_loss: 0.2758 - val_f1: 0.0643\n",
      "Epoch 210/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2767 - f1: 0.7352 - val_loss: 0.2758 - val_f1: 0.0645\n",
      "Epoch 211/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2760 - f1: 0.7349 - val_loss: 0.2803 - val_f1: 0.0641\n",
      "Epoch 212/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2749 - f1: 0.7386 - val_loss: 0.2777 - val_f1: 0.0640\n",
      "Epoch 213/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2758 - f1: 0.7356 - val_loss: 0.2783 - val_f1: 0.0642\n",
      "Epoch 214/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2741 - f1: 0.7385 - val_loss: 0.2775 - val_f1: 0.0635\n",
      "Epoch 215/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2744 - f1: 0.7363 - val_loss: 0.2794 - val_f1: 0.0629\n",
      "Epoch 216/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2740 - f1: 0.7386 - val_loss: 0.2763 - val_f1: 0.0639\n",
      "Epoch 217/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2755 - f1: 0.7386 - val_loss: 0.2787 - val_f1: 0.0639\n",
      "Epoch 218/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2733 - f1: 0.7401 - val_loss: 0.2781 - val_f1: 0.0629\n",
      "Epoch 219/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2741 - f1: 0.7398 - val_loss: 0.2816 - val_f1: 0.0643\n",
      "Epoch 220/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2739 - f1: 0.7382 - val_loss: 0.2762 - val_f1: 0.0638\n",
      "Epoch 221/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2722 - f1: 0.7415 - val_loss: 0.2756 - val_f1: 0.0636\n",
      "Epoch 222/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2739 - f1: 0.7394 - val_loss: 0.2787 - val_f1: 0.0635\n",
      "Epoch 223/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2724 - f1: 0.7409 - val_loss: 0.2783 - val_f1: 0.0626\n",
      "Epoch 224/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2744 - f1: 0.7375 - val_loss: 0.2769 - val_f1: 0.0638\n",
      "Epoch 225/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2730 - f1: 0.7398 - val_loss: 0.2749 - val_f1: 0.0626\n",
      "Epoch 226/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2710 - f1: 0.7439 - val_loss: 0.2772 - val_f1: 0.0626\n",
      "Epoch 227/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2714 - f1: 0.7443 - val_loss: 0.2790 - val_f1: 0.0638\n",
      "Epoch 228/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2710 - f1: 0.7425 - val_loss: 0.2753 - val_f1: 0.0635\n",
      "Epoch 229/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2716 - f1: 0.7422 - val_loss: 0.2793 - val_f1: 0.0639\n",
      "Epoch 230/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2704 - f1: 0.7421 - val_loss: 0.2776 - val_f1: 0.0632\n",
      "Epoch 231/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2704 - f1: 0.7429 - val_loss: 0.2785 - val_f1: 0.0635\n",
      "Epoch 232/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2711 - f1: 0.7439 - val_loss: 0.2770 - val_f1: 0.0633\n",
      "Epoch 233/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2712 - f1: 0.7438 - val_loss: 0.2775 - val_f1: 0.0638\n",
      "Epoch 234/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2697 - f1: 0.7461 - val_loss: 0.2807 - val_f1: 0.0636\n",
      "Epoch 235/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2699 - f1: 0.7452 - val_loss: 0.2806 - val_f1: 0.0635\n",
      "Epoch 236/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2706 - f1: 0.7431 - val_loss: 0.2798 - val_f1: 0.0635\n",
      "Epoch 237/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2705 - f1: 0.7427 - val_loss: 0.2804 - val_f1: 0.0643\n",
      "Epoch 238/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2694 - f1: 0.7462 - val_loss: 0.2802 - val_f1: 0.0635\n",
      "Epoch 239/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2699 - f1: 0.7443 - val_loss: 0.2821 - val_f1: 0.0636\n",
      "Epoch 240/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2683 - f1: 0.7469 - val_loss: 0.2809 - val_f1: 0.0634\n",
      "Epoch 241/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2690 - f1: 0.7436 - val_loss: 0.2822 - val_f1: 0.0637\n",
      "Epoch 242/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2682 - f1: 0.7466 - val_loss: 0.2796 - val_f1: 0.0625\n",
      "Epoch 243/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2693 - f1: 0.7442 - val_loss: 0.2807 - val_f1: 0.0627\n",
      "Epoch 244/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2684 - f1: 0.7455 - val_loss: 0.2788 - val_f1: 0.0629\n",
      "Epoch 245/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2671 - f1: 0.7478 - val_loss: 0.2836 - val_f1: 0.0635\n",
      "Epoch 246/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2668 - f1: 0.7480 - val_loss: 0.2792 - val_f1: 0.0636\n",
      "Epoch 247/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2676 - f1: 0.7482 - val_loss: 0.2778 - val_f1: 0.0641\n",
      "Epoch 248/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2675 - f1: 0.7456 - val_loss: 0.2841 - val_f1: 0.0647\n",
      "Epoch 249/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2663 - f1: 0.7509 - val_loss: 0.2821 - val_f1: 0.0635\n",
      "Epoch 250/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2651 - f1: 0.7487 - val_loss: 0.2807 - val_f1: 0.0622\n",
      "Epoch 251/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2654 - f1: 0.7502 - val_loss: 0.2816 - val_f1: 0.0629\n",
      "Epoch 252/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2650 - f1: 0.7496 - val_loss: 0.2818 - val_f1: 0.0631\n",
      "Epoch 253/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2660 - f1: 0.7525 - val_loss: 0.2818 - val_f1: 0.0634\n",
      "Epoch 254/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2660 - f1: 0.7493 - val_loss: 0.2839 - val_f1: 0.0631\n",
      "Epoch 255/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2653 - f1: 0.7505 - val_loss: 0.2832 - val_f1: 0.0628\n",
      "Epoch 256/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2655 - f1: 0.7497 - val_loss: 0.2808 - val_f1: 0.0633\n",
      "Epoch 257/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2656 - f1: 0.7495 - val_loss: 0.2775 - val_f1: 0.0629\n",
      "Epoch 258/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2644 - f1: 0.7513 - val_loss: 0.2807 - val_f1: 0.0629\n",
      "Epoch 259/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2644 - f1: 0.7510 - val_loss: 0.2806 - val_f1: 0.0627\n",
      "Epoch 260/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2650 - f1: 0.7485 - val_loss: 0.2779 - val_f1: 0.0625\n",
      "Epoch 261/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2650 - f1: 0.7486 - val_loss: 0.2812 - val_f1: 0.0628\n",
      "Epoch 262/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2639 - f1: 0.7502 - val_loss: 0.2805 - val_f1: 0.0637\n",
      "Epoch 263/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2632 - f1: 0.7510 - val_loss: 0.2836 - val_f1: 0.0627\n",
      "Epoch 264/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2633 - f1: 0.7513 - val_loss: 0.2812 - val_f1: 0.0638\n",
      "Epoch 265/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2639 - f1: 0.7516 - val_loss: 0.2799 - val_f1: 0.0634\n",
      "Epoch 266/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2630 - f1: 0.7523 - val_loss: 0.2799 - val_f1: 0.0620\n",
      "Epoch 267/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2621 - f1: 0.7546 - val_loss: 0.2812 - val_f1: 0.0628\n",
      "Epoch 268/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2624 - f1: 0.7545 - val_loss: 0.2849 - val_f1: 0.0638\n",
      "Epoch 269/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2622 - f1: 0.7544 - val_loss: 0.2802 - val_f1: 0.0635\n",
      "Epoch 270/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2625 - f1: 0.7534 - val_loss: 0.2844 - val_f1: 0.0639\n",
      "Epoch 271/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2604 - f1: 0.7553 - val_loss: 0.2806 - val_f1: 0.0627\n",
      "Epoch 272/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2614 - f1: 0.7547 - val_loss: 0.2838 - val_f1: 0.0636\n",
      "Epoch 273/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2621 - f1: 0.7546 - val_loss: 0.2811 - val_f1: 0.0630\n",
      "Epoch 274/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2602 - f1: 0.7557 - val_loss: 0.2805 - val_f1: 0.0626\n",
      "Epoch 275/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2609 - f1: 0.7548 - val_loss: 0.2831 - val_f1: 0.0632\n",
      "Epoch 276/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2605 - f1: 0.7545 - val_loss: 0.2823 - val_f1: 0.0631\n",
      "Epoch 277/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2607 - f1: 0.7561 - val_loss: 0.2845 - val_f1: 0.0637\n",
      "Epoch 278/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2617 - f1: 0.7542 - val_loss: 0.2826 - val_f1: 0.0629\n",
      "Epoch 279/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2605 - f1: 0.7550 - val_loss: 0.2840 - val_f1: 0.0631\n",
      "Epoch 280/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2608 - f1: 0.7541 - val_loss: 0.2869 - val_f1: 0.0634\n",
      "Epoch 281/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2601 - f1: 0.7570 - val_loss: 0.2837 - val_f1: 0.0625\n",
      "Epoch 282/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2599 - f1: 0.7572 - val_loss: 0.2844 - val_f1: 0.0626\n",
      "Epoch 283/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2595 - f1: 0.7581 - val_loss: 0.2778 - val_f1: 0.0625\n",
      "Epoch 284/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2600 - f1: 0.7568 - val_loss: 0.2829 - val_f1: 0.0635\n",
      "Epoch 285/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2602 - f1: 0.7573 - val_loss: 0.2844 - val_f1: 0.0629\n",
      "Epoch 286/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2600 - f1: 0.7556 - val_loss: 0.2854 - val_f1: 0.0628\n",
      "Epoch 287/2000\n",
      "  2976/168135 [..............................] - ETA: 8s - loss: 0.2415 - f1: 0.7989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2589 - f1: 0.7566 - val_loss: 0.2804 - val_f1: 0.0626\n",
      "Epoch 296/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2563 - f1: 0.7619 - val_loss: 0.2857 - val_f1: 0.0631\n",
      "Epoch 297/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2583 - f1: 0.7573 - val_loss: 0.2864 - val_f1: 0.0641\n",
      "Epoch 298/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2553 - f1: 0.7612 - val_loss: 0.2868 - val_f1: 0.0625\n",
      "Epoch 299/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2564 - f1: 0.7593 - val_loss: 0.2830 - val_f1: 0.0621\n",
      "Epoch 300/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2578 - f1: 0.7597 - val_loss: 0.2819 - val_f1: 0.0625\n",
      "Epoch 301/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2554 - f1: 0.7622 - val_loss: 0.2847 - val_f1: 0.0626\n",
      "Epoch 302/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2563 - f1: 0.7594 - val_loss: 0.2813 - val_f1: 0.0629\n",
      "Epoch 303/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2560 - f1: 0.7619 - val_loss: 0.2879 - val_f1: 0.0631\n",
      "Epoch 304/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2568 - f1: 0.7604 - val_loss: 0.2863 - val_f1: 0.0622\n",
      "Epoch 305/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2570 - f1: 0.7614 - val_loss: 0.2833 - val_f1: 0.0625\n",
      "Epoch 306/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2557 - f1: 0.7596 - val_loss: 0.2871 - val_f1: 0.0636\n",
      "Epoch 307/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2557 - f1: 0.7627 - val_loss: 0.2818 - val_f1: 0.0624\n",
      "Epoch 308/2000\n",
      "168135/168135 [==============================] - 12s 71us/step - loss: 0.2543 - f1: 0.7631 - val_loss: 0.2890 - val_f1: 0.0628\n",
      "Epoch 309/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2550 - f1: 0.7610 - val_loss: 0.2891 - val_f1: 0.0639\n",
      "Epoch 310/2000\n",
      "122912/168135 [====================>.........] - ETA: 2s - loss: 0.2569 - f1: 0.7569"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2546 - f1: 0.7634 - val_loss: 0.2861 - val_f1: 0.0625\n",
      "Epoch 318/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2540 - f1: 0.7628 - val_loss: 0.2887 - val_f1: 0.0621\n",
      "Epoch 319/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2551 - f1: 0.7618 - val_loss: 0.2847 - val_f1: 0.0621\n",
      "Epoch 320/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2533 - f1: 0.7656 - val_loss: 0.2863 - val_f1: 0.0629\n",
      "Epoch 321/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2536 - f1: 0.7626 - val_loss: 0.2872 - val_f1: 0.0630\n",
      "Epoch 322/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2532 - f1: 0.7645 - val_loss: 0.2887 - val_f1: 0.0626\n",
      "Epoch 323/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2528 - f1: 0.7626 - val_loss: 0.2836 - val_f1: 0.0624\n",
      "Epoch 324/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2524 - f1: 0.7645 - val_loss: 0.2842 - val_f1: 0.0619\n",
      "Epoch 325/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2537 - f1: 0.7645 - val_loss: 0.2879 - val_f1: 0.0627\n",
      "Epoch 326/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2539 - f1: 0.7636 - val_loss: 0.2850 - val_f1: 0.0630\n",
      "Epoch 327/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2532 - f1: 0.7643 - val_loss: 0.2872 - val_f1: 0.0633\n",
      "Epoch 328/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2519 - f1: 0.7646 - val_loss: 0.2882 - val_f1: 0.0626\n",
      "Epoch 329/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2531 - f1: 0.7634 - val_loss: 0.2896 - val_f1: 0.0622\n",
      "Epoch 330/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2522 - f1: 0.7642 - val_loss: 0.2882 - val_f1: 0.0628\n",
      "Epoch 331/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2522 - f1: 0.7674 - val_loss: 0.2895 - val_f1: 0.0630\n",
      "Epoch 332/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2528 - f1: 0.7649 - val_loss: 0.2894 - val_f1: 0.0630\n",
      "Epoch 333/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2523 - f1: 0.7659 - val_loss: 0.2870 - val_f1: 0.0624\n",
      "Epoch 334/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2496 - f1: 0.7696 - val_loss: 0.2877 - val_f1: 0.0622\n",
      "Epoch 335/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2520 - f1: 0.7646 - val_loss: 0.2879 - val_f1: 0.0625\n",
      "Epoch 336/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2505 - f1: 0.7666 - val_loss: 0.2894 - val_f1: 0.0633\n",
      "Epoch 337/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2502 - f1: 0.7671 - val_loss: 0.2917 - val_f1: 0.0628\n",
      "Epoch 338/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2528 - f1: 0.7660 - val_loss: 0.2879 - val_f1: 0.0620\n",
      "Epoch 339/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2514 - f1: 0.7676 - val_loss: 0.2829 - val_f1: 0.0622\n",
      "Epoch 340/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2512 - f1: 0.7663 - val_loss: 0.2875 - val_f1: 0.0623\n",
      "Epoch 341/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2506 - f1: 0.7668 - val_loss: 0.2849 - val_f1: 0.0622\n",
      "Epoch 342/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2520 - f1: 0.7649 - val_loss: 0.2894 - val_f1: 0.0633\n",
      "Epoch 343/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2501 - f1: 0.7667 - val_loss: 0.2902 - val_f1: 0.0625\n",
      "Epoch 344/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2510 - f1: 0.7670 - val_loss: 0.2887 - val_f1: 0.0620\n",
      "Epoch 345/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2504 - f1: 0.7669 - val_loss: 0.2895 - val_f1: 0.0617\n",
      "Epoch 346/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2502 - f1: 0.7679 - val_loss: 0.2869 - val_f1: 0.0622\n",
      "Epoch 347/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2482 - f1: 0.7688 - val_loss: 0.2890 - val_f1: 0.0618\n",
      "Epoch 348/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2519 - f1: 0.7651 - val_loss: 0.2887 - val_f1: 0.0621\n",
      "Epoch 349/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2482 - f1: 0.7702 - val_loss: 0.2941 - val_f1: 0.0626\n",
      "Epoch 350/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2490 - f1: 0.7705 - val_loss: 0.2855 - val_f1: 0.0620\n",
      "Epoch 351/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2490 - f1: 0.7680 - val_loss: 0.2925 - val_f1: 0.0622\n",
      "Epoch 352/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2494 - f1: 0.7689 - val_loss: 0.2827 - val_f1: 0.0622\n",
      "Epoch 353/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2480 - f1: 0.7718 - val_loss: 0.2891 - val_f1: 0.0623\n",
      "Epoch 354/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2484 - f1: 0.7710 - val_loss: 0.2878 - val_f1: 0.0621\n",
      "Epoch 355/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2495 - f1: 0.7696 - val_loss: 0.2903 - val_f1: 0.0622\n",
      "Epoch 356/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2475 - f1: 0.7716 - val_loss: 0.2894 - val_f1: 0.0626\n",
      "Epoch 357/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2491 - f1: 0.7694 - val_loss: 0.2852 - val_f1: 0.0617\n",
      "Epoch 358/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2471 - f1: 0.7715 - val_loss: 0.2856 - val_f1: 0.0621\n",
      "Epoch 359/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2487 - f1: 0.7711 - val_loss: 0.2909 - val_f1: 0.0625\n",
      "Epoch 360/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2498 - f1: 0.7667 - val_loss: 0.2849 - val_f1: 0.0616\n",
      "Epoch 361/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2473 - f1: 0.7713 - val_loss: 0.2876 - val_f1: 0.0628\n",
      "Epoch 362/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2466 - f1: 0.7739 - val_loss: 0.2882 - val_f1: 0.0627\n",
      "Epoch 363/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2468 - f1: 0.7711 - val_loss: 0.2890 - val_f1: 0.0624\n",
      "Epoch 364/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2471 - f1: 0.7705 - val_loss: 0.2904 - val_f1: 0.0614\n",
      "Epoch 365/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2488 - f1: 0.7698 - val_loss: 0.2873 - val_f1: 0.0622\n",
      "Epoch 366/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2467 - f1: 0.7702 - val_loss: 0.2906 - val_f1: 0.0624\n",
      "Epoch 367/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2480 - f1: 0.7718 - val_loss: 0.2880 - val_f1: 0.0616\n",
      "Epoch 368/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2475 - f1: 0.7697 - val_loss: 0.2862 - val_f1: 0.0618\n",
      "Epoch 369/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2463 - f1: 0.7723 - val_loss: 0.2920 - val_f1: 0.0627\n",
      "Epoch 370/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2458 - f1: 0.7727 - val_loss: 0.2920 - val_f1: 0.0630\n",
      "Epoch 371/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2477 - f1: 0.7726 - val_loss: 0.2863 - val_f1: 0.0613\n",
      "Epoch 372/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2474 - f1: 0.7726 - val_loss: 0.2894 - val_f1: 0.0621\n",
      "Epoch 373/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2477 - f1: 0.7723 - val_loss: 0.2857 - val_f1: 0.0616\n",
      "Epoch 374/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2475 - f1: 0.7699 - val_loss: 0.2897 - val_f1: 0.0620\n",
      "Epoch 375/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2461 - f1: 0.7726 - val_loss: 0.2926 - val_f1: 0.0626\n",
      "Epoch 376/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2467 - f1: 0.7707 - val_loss: 0.2930 - val_f1: 0.0618\n",
      "Epoch 377/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2458 - f1: 0.7723 - val_loss: 0.2898 - val_f1: 0.0620\n",
      "Epoch 378/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2451 - f1: 0.7735 - val_loss: 0.2890 - val_f1: 0.0618\n",
      "Epoch 379/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2461 - f1: 0.7753 - val_loss: 0.2901 - val_f1: 0.0624\n",
      "Epoch 380/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2454 - f1: 0.7742 - val_loss: 0.2919 - val_f1: 0.0617\n",
      "Epoch 381/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2455 - f1: 0.7744 - val_loss: 0.2858 - val_f1: 0.0612\n",
      "Epoch 382/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2449 - f1: 0.7734 - val_loss: 0.2884 - val_f1: 0.0618\n",
      "Epoch 383/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2450 - f1: 0.7745 - val_loss: 0.2897 - val_f1: 0.0623\n",
      "Epoch 384/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2451 - f1: 0.7740 - val_loss: 0.2933 - val_f1: 0.0625\n",
      "Epoch 385/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2462 - f1: 0.7713 - val_loss: 0.2929 - val_f1: 0.0624\n",
      "Epoch 386/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2454 - f1: 0.7749 - val_loss: 0.2914 - val_f1: 0.0629\n",
      "Epoch 387/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2452 - f1: 0.7728 - val_loss: 0.2902 - val_f1: 0.0621\n",
      "Epoch 388/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2437 - f1: 0.7758 - val_loss: 0.2934 - val_f1: 0.0626\n",
      "Epoch 389/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2445 - f1: 0.7751 - val_loss: 0.2917 - val_f1: 0.0626\n",
      "Epoch 390/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2455 - f1: 0.7729 - val_loss: 0.2901 - val_f1: 0.0611\n",
      "Epoch 391/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2444 - f1: 0.7751 - val_loss: 0.2918 - val_f1: 0.0621\n",
      "Epoch 392/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2441 - f1: 0.7752 - val_loss: 0.2909 - val_f1: 0.0620\n",
      "Epoch 393/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2428 - f1: 0.7774 - val_loss: 0.2961 - val_f1: 0.0624\n",
      "Epoch 394/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2447 - f1: 0.7745 - val_loss: 0.2889 - val_f1: 0.0620\n",
      "Epoch 395/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2432 - f1: 0.7761 - val_loss: 0.2937 - val_f1: 0.0615\n",
      "Epoch 396/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2456 - f1: 0.7733 - val_loss: 0.2901 - val_f1: 0.0630\n",
      "Epoch 397/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2438 - f1: 0.7753 - val_loss: 0.2919 - val_f1: 0.0615\n",
      "Epoch 398/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2422 - f1: 0.7759 - val_loss: 0.2932 - val_f1: 0.0621\n",
      "Epoch 399/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2441 - f1: 0.7763 - val_loss: 0.2927 - val_f1: 0.0623\n",
      "Epoch 400/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2438 - f1: 0.7752 - val_loss: 0.2928 - val_f1: 0.0623\n",
      "Epoch 401/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2440 - f1: 0.7761 - val_loss: 0.2861 - val_f1: 0.0615\n",
      "Epoch 402/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2426 - f1: 0.7754 - val_loss: 0.2940 - val_f1: 0.0623\n",
      "Epoch 403/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2436 - f1: 0.7759 - val_loss: 0.2897 - val_f1: 0.0619\n",
      "Epoch 404/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2423 - f1: 0.7778 - val_loss: 0.2929 - val_f1: 0.0624\n",
      "Epoch 405/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2432 - f1: 0.7769 - val_loss: 0.2887 - val_f1: 0.0614\n",
      "Epoch 406/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2423 - f1: 0.7776 - val_loss: 0.2882 - val_f1: 0.0617\n",
      "Epoch 407/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2426 - f1: 0.7779 - val_loss: 0.2904 - val_f1: 0.0621\n",
      "Epoch 408/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2410 - f1: 0.7770 - val_loss: 0.2920 - val_f1: 0.0624\n",
      "Epoch 409/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2404 - f1: 0.7768 - val_loss: 0.2936 - val_f1: 0.0624\n",
      "Epoch 410/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2420 - f1: 0.7783 - val_loss: 0.2911 - val_f1: 0.0618\n",
      "Epoch 411/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2437 - f1: 0.7751 - val_loss: 0.2935 - val_f1: 0.0627\n",
      "Epoch 412/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2423 - f1: 0.7761 - val_loss: 0.2904 - val_f1: 0.0625\n",
      "Epoch 413/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2420 - f1: 0.7761 - val_loss: 0.2903 - val_f1: 0.0613\n",
      "Epoch 414/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2417 - f1: 0.7763 - val_loss: 0.2961 - val_f1: 0.0630\n",
      "Epoch 415/2000\n",
      " 53408/168135 [========>.....................] - ETA: 6s - loss: 0.2422 - f1: 0.7746"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2406 - f1: 0.7800 - val_loss: 0.2930 - val_f1: 0.0626\n",
      "Epoch 424/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2417 - f1: 0.7756 - val_loss: 0.2924 - val_f1: 0.0625\n",
      "Epoch 425/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2406 - f1: 0.7789 - val_loss: 0.2941 - val_f1: 0.0623\n",
      "Epoch 426/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2403 - f1: 0.7792 - val_loss: 0.2935 - val_f1: 0.0624\n",
      "Epoch 427/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2395 - f1: 0.7793 - val_loss: 0.2894 - val_f1: 0.0612\n",
      "Epoch 428/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2401 - f1: 0.7788 - val_loss: 0.2882 - val_f1: 0.0620\n",
      "Epoch 429/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2402 - f1: 0.7816 - val_loss: 0.2967 - val_f1: 0.0619\n",
      "Epoch 430/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2397 - f1: 0.7797 - val_loss: 0.2926 - val_f1: 0.0624\n",
      "Epoch 431/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2402 - f1: 0.7786 - val_loss: 0.2950 - val_f1: 0.0618\n",
      "Epoch 432/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2405 - f1: 0.7789 - val_loss: 0.2882 - val_f1: 0.0611\n",
      "Epoch 433/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2396 - f1: 0.7787 - val_loss: 0.2978 - val_f1: 0.0631\n",
      "Epoch 434/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2411 - f1: 0.7780 - val_loss: 0.2890 - val_f1: 0.0612\n",
      "Epoch 435/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2404 - f1: 0.7797 - val_loss: 0.2906 - val_f1: 0.0614\n",
      "Epoch 436/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2390 - f1: 0.7801 - val_loss: 0.2918 - val_f1: 0.0619\n",
      "Epoch 437/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2395 - f1: 0.7803 - val_loss: 0.2890 - val_f1: 0.0612\n",
      "Epoch 438/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2395 - f1: 0.7804 - val_loss: 0.2957 - val_f1: 0.0621\n",
      "Epoch 439/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2407 - f1: 0.7795 - val_loss: 0.2910 - val_f1: 0.0611\n",
      "Epoch 440/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2398 - f1: 0.7800 - val_loss: 0.2905 - val_f1: 0.0615\n",
      "Epoch 441/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2379 - f1: 0.7826 - val_loss: 0.2939 - val_f1: 0.0625\n",
      "Epoch 442/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2403 - f1: 0.7790 - val_loss: 0.2930 - val_f1: 0.0620\n",
      "Epoch 443/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2384 - f1: 0.7804 - val_loss: 0.2911 - val_f1: 0.0618\n",
      "Epoch 444/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2387 - f1: 0.7801 - val_loss: 0.2936 - val_f1: 0.0619\n",
      "Epoch 445/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2393 - f1: 0.7798 - val_loss: 0.2938 - val_f1: 0.0621\n",
      "Epoch 446/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2387 - f1: 0.7811 - val_loss: 0.2930 - val_f1: 0.0618\n",
      "Epoch 447/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2393 - f1: 0.7806 - val_loss: 0.2958 - val_f1: 0.0623\n",
      "Epoch 448/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2387 - f1: 0.7827 - val_loss: 0.2932 - val_f1: 0.0610\n",
      "Epoch 449/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2381 - f1: 0.7814 - val_loss: 0.2952 - val_f1: 0.0617\n",
      "Epoch 450/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2398 - f1: 0.7803 - val_loss: 0.2934 - val_f1: 0.0619\n",
      "Epoch 451/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2378 - f1: 0.7831 - val_loss: 0.2915 - val_f1: 0.0615\n",
      "Epoch 452/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2380 - f1: 0.7811 - val_loss: 0.2933 - val_f1: 0.0616\n",
      "Epoch 453/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2394 - f1: 0.7807 - val_loss: 0.2973 - val_f1: 0.0613\n",
      "Epoch 454/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2388 - f1: 0.7813 - val_loss: 0.2928 - val_f1: 0.0619\n",
      "Epoch 455/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2392 - f1: 0.7802 - val_loss: 0.2893 - val_f1: 0.0613\n",
      "Epoch 456/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2382 - f1: 0.7807 - val_loss: 0.2972 - val_f1: 0.0629\n",
      "Epoch 457/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2367 - f1: 0.7842 - val_loss: 0.2961 - val_f1: 0.0620\n",
      "Epoch 458/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2372 - f1: 0.7805 - val_loss: 0.2968 - val_f1: 0.0626\n",
      "Epoch 459/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2374 - f1: 0.7821 - val_loss: 0.2975 - val_f1: 0.0613\n",
      "Epoch 460/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2376 - f1: 0.7807 - val_loss: 0.2931 - val_f1: 0.0625\n",
      "Epoch 461/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2381 - f1: 0.7807 - val_loss: 0.2943 - val_f1: 0.0618\n",
      "Epoch 462/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2364 - f1: 0.7849 - val_loss: 0.2944 - val_f1: 0.0614\n",
      "Epoch 463/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2368 - f1: 0.7820 - val_loss: 0.2928 - val_f1: 0.0620\n",
      "Epoch 464/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2358 - f1: 0.7847 - val_loss: 0.2944 - val_f1: 0.0618\n",
      "Epoch 465/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2386 - f1: 0.7826 - val_loss: 0.2950 - val_f1: 0.0626\n",
      "Epoch 466/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2390 - f1: 0.7798 - val_loss: 0.2929 - val_f1: 0.0617\n",
      "Epoch 467/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2364 - f1: 0.7821 - val_loss: 0.2919 - val_f1: 0.0622\n",
      "Epoch 468/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2361 - f1: 0.7834 - val_loss: 0.2982 - val_f1: 0.0614\n",
      "Epoch 469/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2376 - f1: 0.7813 - val_loss: 0.2992 - val_f1: 0.0622\n",
      "Epoch 470/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2380 - f1: 0.7825 - val_loss: 0.2948 - val_f1: 0.0608\n",
      "Epoch 471/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2371 - f1: 0.7824 - val_loss: 0.2932 - val_f1: 0.0625\n",
      "Epoch 472/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2371 - f1: 0.7830 - val_loss: 0.2964 - val_f1: 0.0616\n",
      "Epoch 473/2000\n",
      " 44768/168135 [======>.......................] - ETA: 6s - loss: 0.2327 - f1: 0.7845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2372 - f1: 0.7810 - val_loss: 0.2939 - val_f1: 0.0613\n",
      "Epoch 482/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2350 - f1: 0.7845 - val_loss: 0.2924 - val_f1: 0.0608\n",
      "Epoch 483/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2358 - f1: 0.7840 - val_loss: 0.2941 - val_f1: 0.0610\n",
      "Epoch 484/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2362 - f1: 0.7843 - val_loss: 0.2963 - val_f1: 0.0618\n",
      "Epoch 485/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2357 - f1: 0.7861 - val_loss: 0.2953 - val_f1: 0.0606\n",
      "Epoch 486/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2341 - f1: 0.7876 - val_loss: 0.2906 - val_f1: 0.0617\n",
      "Epoch 487/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2353 - f1: 0.7855 - val_loss: 0.2983 - val_f1: 0.0626\n",
      "Epoch 488/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2342 - f1: 0.7878 - val_loss: 0.2999 - val_f1: 0.0607\n",
      "Epoch 489/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2352 - f1: 0.7867 - val_loss: 0.2931 - val_f1: 0.0614\n",
      "Epoch 490/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2342 - f1: 0.7855 - val_loss: 0.2940 - val_f1: 0.0610\n",
      "Epoch 491/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2373 - f1: 0.7853 - val_loss: 0.2979 - val_f1: 0.0614\n",
      "Epoch 492/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2347 - f1: 0.7842 - val_loss: 0.2958 - val_f1: 0.0615\n",
      "Epoch 493/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2346 - f1: 0.7842 - val_loss: 0.3000 - val_f1: 0.0617\n",
      "Epoch 494/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2340 - f1: 0.7854 - val_loss: 0.2966 - val_f1: 0.0613\n",
      "Epoch 495/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2347 - f1: 0.7848 - val_loss: 0.2906 - val_f1: 0.0603\n",
      "Epoch 496/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2347 - f1: 0.7842 - val_loss: 0.2925 - val_f1: 0.0616\n",
      "Epoch 497/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2341 - f1: 0.7872 - val_loss: 0.2978 - val_f1: 0.0613\n",
      "Epoch 498/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2369 - f1: 0.7827 - val_loss: 0.2938 - val_f1: 0.0610\n",
      "Epoch 499/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2345 - f1: 0.7851 - val_loss: 0.2925 - val_f1: 0.0607\n",
      "Epoch 500/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2331 - f1: 0.7875 - val_loss: 0.2999 - val_f1: 0.0616\n",
      "Epoch 501/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2350 - f1: 0.7852 - val_loss: 0.3004 - val_f1: 0.0614\n",
      "Epoch 502/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2336 - f1: 0.7860 - val_loss: 0.3043 - val_f1: 0.0621\n",
      "Epoch 503/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2342 - f1: 0.7854 - val_loss: 0.2973 - val_f1: 0.0618\n",
      "Epoch 504/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2332 - f1: 0.7856 - val_loss: 0.2960 - val_f1: 0.0617\n",
      "Epoch 505/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2362 - f1: 0.7847 - val_loss: 0.2955 - val_f1: 0.0620\n",
      "Epoch 506/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2352 - f1: 0.7847 - val_loss: 0.2995 - val_f1: 0.0623\n",
      "Epoch 507/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2352 - f1: 0.7840 - val_loss: 0.2995 - val_f1: 0.0629\n",
      "Epoch 508/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2347 - f1: 0.7880 - val_loss: 0.2940 - val_f1: 0.0607\n",
      "Epoch 509/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2349 - f1: 0.7838 - val_loss: 0.2937 - val_f1: 0.0623\n",
      "Epoch 510/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2319 - f1: 0.7891 - val_loss: 0.2949 - val_f1: 0.0614\n",
      "Epoch 511/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2358 - f1: 0.7835 - val_loss: 0.2860 - val_f1: 0.0611\n",
      "Epoch 512/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2316 - f1: 0.7892 - val_loss: 0.2994 - val_f1: 0.0616\n",
      "Epoch 513/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2343 - f1: 0.7873 - val_loss: 0.2993 - val_f1: 0.0623\n",
      "Epoch 514/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2340 - f1: 0.7867 - val_loss: 0.2949 - val_f1: 0.0622\n",
      "Epoch 515/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2314 - f1: 0.7886 - val_loss: 0.2971 - val_f1: 0.0625\n",
      "Epoch 516/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2331 - f1: 0.7863 - val_loss: 0.2979 - val_f1: 0.0617\n",
      "Epoch 517/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2323 - f1: 0.7890 - val_loss: 0.2951 - val_f1: 0.0623\n",
      "Epoch 518/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2333 - f1: 0.7867 - val_loss: 0.2964 - val_f1: 0.0611\n",
      "Epoch 519/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2331 - f1: 0.7871 - val_loss: 0.2939 - val_f1: 0.0615\n",
      "Epoch 520/2000\n",
      " 97664/168135 [================>.............] - ETA: 3s - loss: 0.2308 - f1: 0.7894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2319 - f1: 0.7868 - val_loss: 0.2958 - val_f1: 0.0618\n",
      "Epoch 529/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2320 - f1: 0.7896 - val_loss: 0.2978 - val_f1: 0.0621\n",
      "Epoch 530/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2320 - f1: 0.7878 - val_loss: 0.3021 - val_f1: 0.0619\n",
      "Epoch 531/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2320 - f1: 0.7886 - val_loss: 0.2911 - val_f1: 0.0611\n",
      "Epoch 532/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2312 - f1: 0.7887 - val_loss: 0.2995 - val_f1: 0.0616\n",
      "Epoch 533/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2304 - f1: 0.7901 - val_loss: 0.2993 - val_f1: 0.0627\n",
      "Epoch 534/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2325 - f1: 0.7873 - val_loss: 0.3008 - val_f1: 0.0616\n",
      "Epoch 535/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2309 - f1: 0.7903 - val_loss: 0.2938 - val_f1: 0.0614\n",
      "Epoch 536/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2306 - f1: 0.7902 - val_loss: 0.3016 - val_f1: 0.0610\n",
      "Epoch 537/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2313 - f1: 0.7894 - val_loss: 0.3001 - val_f1: 0.0618\n",
      "Epoch 538/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2323 - f1: 0.7881 - val_loss: 0.2977 - val_f1: 0.0626\n",
      "Epoch 539/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2318 - f1: 0.7885 - val_loss: 0.3002 - val_f1: 0.0626\n",
      "Epoch 540/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2299 - f1: 0.7914 - val_loss: 0.2970 - val_f1: 0.0614\n",
      "Epoch 541/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2315 - f1: 0.7896 - val_loss: 0.2959 - val_f1: 0.0614\n",
      "Epoch 542/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2310 - f1: 0.7907 - val_loss: 0.2983 - val_f1: 0.0623\n",
      "Epoch 543/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2313 - f1: 0.7884 - val_loss: 0.2955 - val_f1: 0.0615\n",
      "Epoch 544/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2301 - f1: 0.7916 - val_loss: 0.2942 - val_f1: 0.0616\n",
      "Epoch 545/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2306 - f1: 0.7903 - val_loss: 0.2959 - val_f1: 0.0615\n",
      "Epoch 546/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2301 - f1: 0.7915 - val_loss: 0.2996 - val_f1: 0.0622\n",
      "Epoch 547/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2317 - f1: 0.7901 - val_loss: 0.2993 - val_f1: 0.0623\n",
      "Epoch 548/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2307 - f1: 0.7904 - val_loss: 0.3005 - val_f1: 0.0614\n",
      "Epoch 549/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2316 - f1: 0.7889 - val_loss: 0.2986 - val_f1: 0.0621\n",
      "Epoch 550/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2318 - f1: 0.7892 - val_loss: 0.2987 - val_f1: 0.0622\n",
      "Epoch 551/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2320 - f1: 0.7877 - val_loss: 0.2977 - val_f1: 0.0617\n",
      "Epoch 552/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2308 - f1: 0.7867 - val_loss: 0.2992 - val_f1: 0.0611\n",
      "Epoch 553/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2312 - f1: 0.7890 - val_loss: 0.3014 - val_f1: 0.0628\n",
      "Epoch 554/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2326 - f1: 0.7882 - val_loss: 0.2993 - val_f1: 0.0619\n",
      "Epoch 555/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2303 - f1: 0.7899 - val_loss: 0.2945 - val_f1: 0.0612\n",
      "Epoch 556/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2313 - f1: 0.7882 - val_loss: 0.2955 - val_f1: 0.0610\n",
      "Epoch 557/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2309 - f1: 0.7892 - val_loss: 0.2980 - val_f1: 0.0612\n",
      "Epoch 558/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2306 - f1: 0.7923 - val_loss: 0.3017 - val_f1: 0.0621\n",
      "Epoch 559/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2309 - f1: 0.7898 - val_loss: 0.3011 - val_f1: 0.0622\n",
      "Epoch 560/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2290 - f1: 0.7928 - val_loss: 0.2994 - val_f1: 0.0617\n",
      "Epoch 561/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2292 - f1: 0.7926 - val_loss: 0.2989 - val_f1: 0.0620\n",
      "Epoch 562/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2304 - f1: 0.7886 - val_loss: 0.2995 - val_f1: 0.0612\n",
      "Epoch 563/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2305 - f1: 0.7894 - val_loss: 0.2966 - val_f1: 0.0613\n",
      "Epoch 564/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2304 - f1: 0.7911 - val_loss: 0.3000 - val_f1: 0.0611\n",
      "Epoch 565/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2294 - f1: 0.7914 - val_loss: 0.2958 - val_f1: 0.0620\n",
      "Epoch 566/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2301 - f1: 0.7908 - val_loss: 0.2975 - val_f1: 0.0617\n",
      "Epoch 567/2000\n",
      "103008/168135 [=================>............] - ETA: 3s - loss: 0.2293 - f1: 0.79"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2283 - f1: 0.7939 - val_loss: 0.2928 - val_f1: 0.0604\n",
      "Epoch 576/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2285 - f1: 0.7925 - val_loss: 0.3020 - val_f1: 0.0625\n",
      "Epoch 577/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2284 - f1: 0.7941 - val_loss: 0.2944 - val_f1: 0.0621\n",
      "Epoch 578/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2279 - f1: 0.7948 - val_loss: 0.2999 - val_f1: 0.0619\n",
      "Epoch 579/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2281 - f1: 0.7918 - val_loss: 0.3011 - val_f1: 0.0617\n",
      "Epoch 580/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2288 - f1: 0.7931 - val_loss: 0.2996 - val_f1: 0.0616\n",
      "Epoch 581/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2290 - f1: 0.7908 - val_loss: 0.2999 - val_f1: 0.0623\n",
      "Epoch 582/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2282 - f1: 0.7947 - val_loss: 0.3021 - val_f1: 0.0622\n",
      "Epoch 583/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2297 - f1: 0.7920 - val_loss: 0.2945 - val_f1: 0.0614\n",
      "Epoch 584/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2290 - f1: 0.7908 - val_loss: 0.3003 - val_f1: 0.0617\n",
      "Epoch 585/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2286 - f1: 0.7925 - val_loss: 0.3007 - val_f1: 0.0627\n",
      "Epoch 586/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2282 - f1: 0.7906 - val_loss: 0.3029 - val_f1: 0.0621\n",
      "Epoch 587/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2295 - f1: 0.7940 - val_loss: 0.2982 - val_f1: 0.0613\n",
      "Epoch 588/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2282 - f1: 0.7926 - val_loss: 0.3012 - val_f1: 0.0627\n",
      "Epoch 589/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2292 - f1: 0.7911 - val_loss: 0.3032 - val_f1: 0.0621\n",
      "Epoch 590/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2293 - f1: 0.7927 - val_loss: 0.2996 - val_f1: 0.0617\n",
      "Epoch 591/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2284 - f1: 0.7929 - val_loss: 0.3011 - val_f1: 0.0623\n",
      "Epoch 592/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2286 - f1: 0.7918 - val_loss: 0.3040 - val_f1: 0.0625\n",
      "Epoch 593/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2275 - f1: 0.7915 - val_loss: 0.3071 - val_f1: 0.0622\n",
      "Epoch 594/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2277 - f1: 0.7938 - val_loss: 0.2960 - val_f1: 0.0615\n",
      "Epoch 595/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2285 - f1: 0.7930 - val_loss: 0.2994 - val_f1: 0.0612\n",
      "Epoch 596/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2296 - f1: 0.7902 - val_loss: 0.3009 - val_f1: 0.0620\n",
      "Epoch 597/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2269 - f1: 0.7951 - val_loss: 0.3026 - val_f1: 0.0624\n",
      "Epoch 598/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2282 - f1: 0.7947 - val_loss: 0.2999 - val_f1: 0.0619\n",
      "Epoch 599/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2269 - f1: 0.7932 - val_loss: 0.3047 - val_f1: 0.0624\n",
      "Epoch 600/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2283 - f1: 0.7910 - val_loss: 0.3023 - val_f1: 0.0612\n",
      "Epoch 601/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2285 - f1: 0.7917 - val_loss: 0.2967 - val_f1: 0.0615\n",
      "Epoch 602/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2284 - f1: 0.7916 - val_loss: 0.2970 - val_f1: 0.0605\n",
      "Epoch 603/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2282 - f1: 0.7931 - val_loss: 0.2976 - val_f1: 0.0621\n",
      "Epoch 604/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2274 - f1: 0.7940 - val_loss: 0.3019 - val_f1: 0.0608\n",
      "Epoch 605/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2269 - f1: 0.7937 - val_loss: 0.2946 - val_f1: 0.0613\n",
      "Epoch 606/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2282 - f1: 0.7921 - val_loss: 0.2987 - val_f1: 0.0627\n",
      "Epoch 607/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2268 - f1: 0.7946 - val_loss: 0.3051 - val_f1: 0.0624\n",
      "Epoch 608/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2268 - f1: 0.7952 - val_loss: 0.2980 - val_f1: 0.0612\n",
      "Epoch 609/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2262 - f1: 0.7947 - val_loss: 0.3046 - val_f1: 0.0611\n",
      "Epoch 610/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2250 - f1: 0.7952 - val_loss: 0.3002 - val_f1: 0.0611\n",
      "Epoch 611/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2274 - f1: 0.7918 - val_loss: 0.2994 - val_f1: 0.0620\n",
      "Epoch 612/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2270 - f1: 0.7945 - val_loss: 0.3048 - val_f1: 0.0619\n",
      "Epoch 613/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2262 - f1: 0.7925 - val_loss: 0.3048 - val_f1: 0.0627\n",
      "Epoch 614/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2274 - f1: 0.7924 - val_loss: 0.3014 - val_f1: 0.0619\n",
      "Epoch 615/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2254 - f1: 0.7963 - val_loss: 0.3052 - val_f1: 0.0629\n",
      "Epoch 616/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2256 - f1: 0.7947 - val_loss: 0.2983 - val_f1: 0.0623\n",
      "Epoch 617/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2277 - f1: 0.7929 - val_loss: 0.2958 - val_f1: 0.0613\n",
      "Epoch 618/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2286 - f1: 0.7908 - val_loss: 0.2945 - val_f1: 0.0615\n",
      "Epoch 619/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2272 - f1: 0.7938 - val_loss: 0.2984 - val_f1: 0.0614\n",
      "Epoch 620/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2265 - f1: 0.7936 - val_loss: 0.2990 - val_f1: 0.0613\n",
      "Epoch 621/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2265 - f1: 0.7949 - val_loss: 0.3018 - val_f1: 0.0617\n",
      "Epoch 622/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2252 - f1: 0.7969 - val_loss: 0.3028 - val_f1: 0.0613\n",
      "Epoch 623/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2279 - f1: 0.7931 - val_loss: 0.3016 - val_f1: 0.0621\n",
      "Epoch 624/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2271 - f1: 0.7943 - val_loss: 0.3013 - val_f1: 0.0618\n",
      "Epoch 625/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2264 - f1: 0.7924 - val_loss: 0.2982 - val_f1: 0.0615\n",
      "Epoch 626/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2273 - f1: 0.7952 - val_loss: 0.3023 - val_f1: 0.0621\n",
      "Epoch 627/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2269 - f1: 0.7924 - val_loss: 0.3019 - val_f1: 0.0618\n",
      "Epoch 628/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2265 - f1: 0.7935 - val_loss: 0.3050 - val_f1: 0.0616\n",
      "Epoch 629/2000\n",
      " 48096/168135 [=======>......................] - ETA: 6s - loss: 0.2268 - f1: 0.7988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2259 - f1: 0.7936 - val_loss: 0.3017 - val_f1: 0.0610\n",
      "Epoch 638/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2262 - f1: 0.7949 - val_loss: 0.3048 - val_f1: 0.0619\n",
      "Epoch 639/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2253 - f1: 0.7963 - val_loss: 0.3020 - val_f1: 0.0619\n",
      "Epoch 640/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2258 - f1: 0.7955 - val_loss: 0.3027 - val_f1: 0.0617\n",
      "Epoch 641/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2248 - f1: 0.7962 - val_loss: 0.3082 - val_f1: 0.0624\n",
      "Epoch 642/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2267 - f1: 0.7958 - val_loss: 0.2993 - val_f1: 0.0621\n",
      "Epoch 643/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2236 - f1: 0.7975 - val_loss: 0.3009 - val_f1: 0.0614\n",
      "Epoch 644/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2262 - f1: 0.7947 - val_loss: 0.3039 - val_f1: 0.0616\n",
      "Epoch 645/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2258 - f1: 0.7947 - val_loss: 0.2998 - val_f1: 0.0601\n",
      "Epoch 646/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2240 - f1: 0.7988 - val_loss: 0.2995 - val_f1: 0.0613\n",
      "Epoch 647/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2264 - f1: 0.7939 - val_loss: 0.2988 - val_f1: 0.0614\n",
      "Epoch 648/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2259 - f1: 0.7927 - val_loss: 0.3002 - val_f1: 0.0614\n",
      "Epoch 649/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2255 - f1: 0.7942 - val_loss: 0.3007 - val_f1: 0.0612\n",
      "Epoch 650/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2252 - f1: 0.7945 - val_loss: 0.3051 - val_f1: 0.0616\n",
      "Epoch 651/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2233 - f1: 0.7986 - val_loss: 0.3075 - val_f1: 0.0620\n",
      "Epoch 652/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2251 - f1: 0.7962 - val_loss: 0.3054 - val_f1: 0.0618\n",
      "Epoch 653/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2230 - f1: 0.7970 - val_loss: 0.3051 - val_f1: 0.0617\n",
      "Epoch 654/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2245 - f1: 0.7976 - val_loss: 0.3027 - val_f1: 0.0611\n",
      "Epoch 655/2000\n",
      "168135/168135 [==============================] - 9s 54us/step - loss: 0.2250 - f1: 0.7950 - val_loss: 0.3056 - val_f1: 0.0619\n",
      "Epoch 656/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2238 - f1: 0.7973 - val_loss: 0.2977 - val_f1: 0.0599\n",
      "Epoch 657/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2255 - f1: 0.7959 - val_loss: 0.3021 - val_f1: 0.0617\n",
      "Epoch 658/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2231 - f1: 0.7992 - val_loss: 0.3045 - val_f1: 0.0615\n",
      "Epoch 659/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2240 - f1: 0.7964 - val_loss: 0.3055 - val_f1: 0.0613\n",
      "Epoch 660/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2251 - f1: 0.7970 - val_loss: 0.3060 - val_f1: 0.0618\n",
      "Epoch 661/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2266 - f1: 0.7955 - val_loss: 0.2972 - val_f1: 0.0612\n",
      "Epoch 662/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2262 - f1: 0.7961 - val_loss: 0.3023 - val_f1: 0.0622\n",
      "Epoch 663/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2236 - f1: 0.7972 - val_loss: 0.3059 - val_f1: 0.0616\n",
      "Epoch 664/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2243 - f1: 0.7969 - val_loss: 0.2988 - val_f1: 0.0612\n",
      "Epoch 665/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2235 - f1: 0.7983 - val_loss: 0.2992 - val_f1: 0.0617\n",
      "Epoch 666/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2239 - f1: 0.7976 - val_loss: 0.3063 - val_f1: 0.0615\n",
      "Epoch 667/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2246 - f1: 0.7969 - val_loss: 0.3067 - val_f1: 0.0623\n",
      "Epoch 668/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2245 - f1: 0.7968 - val_loss: 0.3000 - val_f1: 0.0613\n",
      "Epoch 669/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2233 - f1: 0.7979 - val_loss: 0.3081 - val_f1: 0.0623\n",
      "Epoch 670/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2256 - f1: 0.7971 - val_loss: 0.3036 - val_f1: 0.0617\n",
      "Epoch 671/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2227 - f1: 0.7983 - val_loss: 0.2994 - val_f1: 0.0612\n",
      "Epoch 672/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2225 - f1: 0.7982 - val_loss: 0.3052 - val_f1: 0.0614\n",
      "Epoch 673/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2239 - f1: 0.7965 - val_loss: 0.3067 - val_f1: 0.0617\n",
      "Epoch 674/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2216 - f1: 0.7998 - val_loss: 0.3099 - val_f1: 0.0603\n",
      "Epoch 675/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2235 - f1: 0.7982 - val_loss: 0.3017 - val_f1: 0.0614\n",
      "Epoch 676/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2238 - f1: 0.7980 - val_loss: 0.3036 - val_f1: 0.0614\n",
      "Epoch 677/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2226 - f1: 0.7990 - val_loss: 0.3017 - val_f1: 0.0624\n",
      "Epoch 678/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2224 - f1: 0.8008 - val_loss: 0.3032 - val_f1: 0.0621\n",
      "Epoch 679/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2249 - f1: 0.7969 - val_loss: 0.3017 - val_f1: 0.0620\n",
      "Epoch 680/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2227 - f1: 0.7974 - val_loss: 0.3038 - val_f1: 0.0623\n",
      "Epoch 681/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2236 - f1: 0.7983 - val_loss: 0.3027 - val_f1: 0.0612\n",
      "Epoch 682/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2251 - f1: 0.7940 - val_loss: 0.3018 - val_f1: 0.0618\n",
      "Epoch 683/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2233 - f1: 0.7982 - val_loss: 0.3035 - val_f1: 0.0611\n",
      "Epoch 684/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2254 - f1: 0.7967 - val_loss: 0.3024 - val_f1: 0.0613\n",
      "Epoch 685/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2239 - f1: 0.7983 - val_loss: 0.2995 - val_f1: 0.0617\n",
      "Epoch 686/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2223 - f1: 0.7994 - val_loss: 0.3068 - val_f1: 0.0617\n",
      "Epoch 687/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2251 - f1: 0.7969 - val_loss: 0.3044 - val_f1: 0.0622\n",
      "Epoch 688/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2215 - f1: 0.8012 - val_loss: 0.3017 - val_f1: 0.0612\n",
      "Epoch 689/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2251 - f1: 0.7938 - val_loss: 0.3035 - val_f1: 0.0620\n",
      "Epoch 690/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2229 - f1: 0.7994 - val_loss: 0.3057 - val_f1: 0.0615\n",
      "Epoch 691/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2226 - f1: 0.8008 - val_loss: 0.3038 - val_f1: 0.0613\n",
      "Epoch 692/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2215 - f1: 0.8003 - val_loss: 0.3005 - val_f1: 0.0614\n",
      "Epoch 693/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2226 - f1: 0.7999 - val_loss: 0.3075 - val_f1: 0.0621\n",
      "Epoch 694/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2240 - f1: 0.7936 - val_loss: 0.3000 - val_f1: 0.0605\n",
      "Epoch 695/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2234 - f1: 0.7964 - val_loss: 0.3007 - val_f1: 0.0618\n",
      "Epoch 696/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2224 - f1: 0.7999 - val_loss: 0.3055 - val_f1: 0.0609\n",
      "Epoch 697/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2221 - f1: 0.7993 - val_loss: 0.3083 - val_f1: 0.0615\n",
      "Epoch 698/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2237 - f1: 0.8001 - val_loss: 0.3049 - val_f1: 0.0614\n",
      "Epoch 699/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2245 - f1: 0.7953 - val_loss: 0.3037 - val_f1: 0.0619\n",
      "Epoch 700/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2216 - f1: 0.7999 - val_loss: 0.3039 - val_f1: 0.0615\n",
      "Epoch 701/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2233 - f1: 0.7978 - val_loss: 0.3055 - val_f1: 0.0616\n",
      "Epoch 702/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2223 - f1: 0.7993 - val_loss: 0.3041 - val_f1: 0.0615\n",
      "Epoch 703/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2230 - f1: 0.7976 - val_loss: 0.2982 - val_f1: 0.0605\n",
      "Epoch 704/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2225 - f1: 0.7987 - val_loss: 0.3025 - val_f1: 0.0612\n",
      "Epoch 705/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2220 - f1: 0.8002 - val_loss: 0.3042 - val_f1: 0.0610\n",
      "Epoch 706/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2225 - f1: 0.7989 - val_loss: 0.3054 - val_f1: 0.0607\n",
      "Epoch 707/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2227 - f1: 0.7981 - val_loss: 0.2994 - val_f1: 0.0614\n",
      "Epoch 708/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2212 - f1: 0.8003 - val_loss: 0.3054 - val_f1: 0.0617\n",
      "Epoch 709/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2229 - f1: 0.7986 - val_loss: 0.3019 - val_f1: 0.0618\n",
      "Epoch 710/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2222 - f1: 0.7993 - val_loss: 0.3024 - val_f1: 0.0614\n",
      "Epoch 711/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2231 - f1: 0.7987 - val_loss: 0.3081 - val_f1: 0.0616\n",
      "Epoch 712/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2209 - f1: 0.7993 - val_loss: 0.3067 - val_f1: 0.0604\n",
      "Epoch 713/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2232 - f1: 0.7987 - val_loss: 0.2975 - val_f1: 0.0612\n",
      "Epoch 714/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2211 - f1: 0.7984 - val_loss: 0.3058 - val_f1: 0.0615\n",
      "Epoch 715/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2233 - f1: 0.7981 - val_loss: 0.3068 - val_f1: 0.0619\n",
      "Epoch 716/2000\n",
      " 98176/168135 [================>.............] - ETA: 3s - loss: 0.2223 - f1: 0.8017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2213 - f1: 0.8004 - val_loss: 0.3007 - val_f1: 0.0603\n",
      "Epoch 725/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2193 - f1: 0.8028 - val_loss: 0.3042 - val_f1: 0.0614\n",
      "Epoch 726/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2221 - f1: 0.7995 - val_loss: 0.3108 - val_f1: 0.0618\n",
      "Epoch 727/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2208 - f1: 0.8005 - val_loss: 0.3028 - val_f1: 0.0607\n",
      "Epoch 728/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2215 - f1: 0.7992 - val_loss: 0.3030 - val_f1: 0.0617\n",
      "Epoch 729/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2197 - f1: 0.8006 - val_loss: 0.3043 - val_f1: 0.0610\n",
      "Epoch 730/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2210 - f1: 0.8010 - val_loss: 0.2987 - val_f1: 0.0614\n",
      "Epoch 731/2000\n",
      " 59232/168135 [=========>....................] - ETA: 5s - loss: 0.2201 - f1: 0.8012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2204 - f1: 0.8010 - val_loss: 0.3056 - val_f1: 0.0609\n",
      "Epoch 740/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2207 - f1: 0.8001 - val_loss: 0.3051 - val_f1: 0.0620\n",
      "Epoch 741/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2193 - f1: 0.8017 - val_loss: 0.3122 - val_f1: 0.0619\n",
      "Epoch 742/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2202 - f1: 0.8011 - val_loss: 0.3054 - val_f1: 0.0611\n",
      "Epoch 743/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2204 - f1: 0.8010 - val_loss: 0.3039 - val_f1: 0.0616\n",
      "Epoch 744/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2199 - f1: 0.8026 - val_loss: 0.3075 - val_f1: 0.0619\n",
      "Epoch 745/2000\n",
      "125408/168135 [=====================>........] - ETA: 2s - loss: 0.2196 - f1: 0.8031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2211 - f1: 0.8010 - val_loss: 0.3056 - val_f1: 0.0617\n",
      "Epoch 760/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2203 - f1: 0.8014 - val_loss: 0.3042 - val_f1: 0.0609\n",
      "Epoch 761/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2218 - f1: 0.7998 - val_loss: 0.2969 - val_f1: 0.0606\n",
      "Epoch 762/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2183 - f1: 0.8026 - val_loss: 0.3059 - val_f1: 0.0617\n",
      "Epoch 763/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2206 - f1: 0.8020 - val_loss: 0.3023 - val_f1: 0.0612\n",
      "Epoch 764/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2203 - f1: 0.7998 - val_loss: 0.3034 - val_f1: 0.0611\n",
      "Epoch 765/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2195 - f1: 0.8037 - val_loss: 0.2994 - val_f1: 0.0617\n",
      "Epoch 766/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2191 - f1: 0.8033 - val_loss: 0.3055 - val_f1: 0.0617\n",
      "Epoch 767/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2206 - f1: 0.7985 - val_loss: 0.3085 - val_f1: 0.0613\n",
      "Epoch 768/2000\n",
      "117216/168135 [===================>..........] - ETA: 2s - loss: 0.2190 - f1: 0.8030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2192 - f1: 0.8014 - val_loss: 0.3062 - val_f1: 0.0609\n",
      "Epoch 778/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2193 - f1: 0.8040 - val_loss: 0.3077 - val_f1: 0.0618\n",
      "Epoch 779/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2188 - f1: 0.8037 - val_loss: 0.3072 - val_f1: 0.0619\n",
      "Epoch 780/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2194 - f1: 0.8017 - val_loss: 0.3077 - val_f1: 0.0617\n",
      "Epoch 781/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2191 - f1: 0.8040 - val_loss: 0.3044 - val_f1: 0.0615\n",
      "Epoch 782/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2185 - f1: 0.8056 - val_loss: 0.3058 - val_f1: 0.0615\n",
      "Epoch 783/2000\n",
      "168135/168135 [==============================] - 17s 104us/step - loss: 0.2185 - f1: 0.8050 - val_loss: 0.3020 - val_f1: 0.0619\n",
      "Epoch 784/2000\n",
      "168135/168135 [==============================] - 23s 135us/step - loss: 0.2182 - f1: 0.8040 - val_loss: 0.3019 - val_f1: 0.0610\n",
      "Epoch 785/2000\n",
      "168135/168135 [==============================] - 21s 124us/step - loss: 0.2195 - f1: 0.8000 - val_loss: 0.3080 - val_f1: 0.0614\n",
      "Epoch 786/2000\n",
      "168135/168135 [==============================] - 22s 130us/step - loss: 0.2196 - f1: 0.8025 - val_loss: 0.3044 - val_f1: 0.0614\n",
      "Epoch 787/2000\n",
      "168135/168135 [==============================] - 20s 117us/step - loss: 0.2192 - f1: 0.8028 - val_loss: 0.3038 - val_f1: 0.0614\n",
      "Epoch 788/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2150 - f1: 0.8066 - val_loss: 0.3077 - val_f1: 0.0608\n",
      "Epoch 824/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2169 - f1: 0.8039 - val_loss: 0.3064 - val_f1: 0.0614\n",
      "Epoch 825/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2180 - f1: 0.8037 - val_loss: 0.3054 - val_f1: 0.0611\n",
      "Epoch 826/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2172 - f1: 0.8025 - val_loss: 0.3080 - val_f1: 0.0613\n",
      "Epoch 827/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2174 - f1: 0.8055 - val_loss: 0.3055 - val_f1: 0.0616\n",
      "Epoch 828/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2171 - f1: 0.8072 - val_loss: 0.3056 - val_f1: 0.0611\n",
      "Epoch 829/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2175 - f1: 0.8043 - val_loss: 0.3119 - val_f1: 0.0616\n",
      "Epoch 830/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2175 - f1: 0.8028 - val_loss: 0.3070 - val_f1: 0.0617\n",
      "Epoch 831/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2174 - f1: 0.8046 - val_loss: 0.3089 - val_f1: 0.0611\n",
      "Epoch 832/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2174 - f1: 0.8025 - val_loss: 0.3027 - val_f1: 0.0605\n",
      "Epoch 833/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2160 - f1: 0.8047 - val_loss: 0.3075 - val_f1: 0.0612\n",
      "Epoch 834/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2163 - f1: 0.8067 - val_loss: 0.3048 - val_f1: 0.0614\n",
      "Epoch 835/2000\n",
      "168135/168135 [==============================] - 12s 69us/step - loss: 0.2167 - f1: 0.8057 - val_loss: 0.3102 - val_f1: 0.0618\n",
      "Epoch 836/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2168 - f1: 0.8038 - val_loss: 0.3089 - val_f1: 0.0606\n",
      "Epoch 837/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2172 - f1: 0.8029 - val_loss: 0.3046 - val_f1: 0.0610\n",
      "Epoch 838/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2181 - f1: 0.8025 - val_loss: 0.3002 - val_f1: 0.0613\n",
      "Epoch 839/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2163 - f1: 0.8050 - val_loss: 0.3048 - val_f1: 0.0617\n",
      "Epoch 840/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2179 - f1: 0.8028 - val_loss: 0.3086 - val_f1: 0.0606\n",
      "Epoch 841/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2166 - f1: 0.8045 - val_loss: 0.3112 - val_f1: 0.0618\n",
      "Epoch 842/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2167 - f1: 0.8084 - val_loss: 0.3053 - val_f1: 0.0610\n",
      "Epoch 843/2000\n",
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2168 - f1: 0.8058 - val_loss: 0.3031 - val_f1: 0.0609\n",
      "Epoch 844/2000\n",
      "168135/168135 [==============================] - 12s 70us/step - loss: 0.2163 - f1: 0.8044 - val_loss: 0.3075 - val_f1: 0.0605\n",
      "Epoch 845/2000\n",
      "168135/168135 [==============================] - 15s 87us/step - loss: 0.2170 - f1: 0.8057 - val_loss: 0.3092 - val_f1: 0.0618\n",
      "Epoch 846/2000\n",
      "168135/168135 [==============================] - 13s 77us/step - loss: 0.2170 - f1: 0.8045 - val_loss: 0.3080 - val_f1: 0.0607\n",
      "Epoch 847/2000\n",
      "168135/168135 [==============================] - 12s 70us/step - loss: 0.2184 - f1: 0.8040 - val_loss: 0.3119 - val_f1: 0.0611\n",
      "Epoch 848/2000\n",
      "168135/168135 [==============================] - 12s 73us/step - loss: 0.2163 - f1: 0.8032 - val_loss: 0.3089 - val_f1: 0.0609\n",
      "Epoch 849/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2173 - f1: 0.8054 - val_loss: 0.3087 - val_f1: 0.0609\n",
      "Epoch 850/2000\n",
      "168135/168135 [==============================] - 12s 69us/step - loss: 0.2175 - f1: 0.8034 - val_loss: 0.3015 - val_f1: 0.0607\n",
      "Epoch 851/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2154 - f1: 0.8071 - val_loss: 0.3107 - val_f1: 0.0613\n",
      "Epoch 852/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2166 - f1: 0.8066 - val_loss: 0.3085 - val_f1: 0.0615\n",
      "Epoch 853/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2179 - f1: 0.8065 - val_loss: 0.3097 - val_f1: 0.0615\n",
      "Epoch 854/2000\n",
      "168135/168135 [==============================] - 11s 66us/step - loss: 0.2164 - f1: 0.8061 - val_loss: 0.3059 - val_f1: 0.0607\n",
      "Epoch 855/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2165 - f1: 0.8054 - val_loss: 0.3138 - val_f1: 0.0610\n",
      "Epoch 856/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2157 - f1: 0.8049 - val_loss: 0.3086 - val_f1: 0.0611\n",
      "Epoch 857/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2160 - f1: 0.8047 - val_loss: 0.3088 - val_f1: 0.0608\n",
      "Epoch 858/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2157 - f1: 0.8070 - val_loss: 0.3097 - val_f1: 0.0613\n",
      "Epoch 859/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2150 - f1: 0.8064 - val_loss: 0.3026 - val_f1: 0.0601\n",
      "Epoch 860/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2157 - f1: 0.8078 - val_loss: 0.3073 - val_f1: 0.0609\n",
      "Epoch 861/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2148 - f1: 0.8070 - val_loss: 0.3090 - val_f1: 0.0611\n",
      "Epoch 862/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2174 - f1: 0.8054 - val_loss: 0.3006 - val_f1: 0.0604\n",
      "Epoch 863/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2162 - f1: 0.8061 - val_loss: 0.3086 - val_f1: 0.0615\n",
      "Epoch 864/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2184 - f1: 0.8041 - val_loss: 0.3024 - val_f1: 0.0613\n",
      "Epoch 865/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2166 - f1: 0.8059 - val_loss: 0.2982 - val_f1: 0.0604\n",
      "Epoch 866/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2152 - f1: 0.8066 - val_loss: 0.3013 - val_f1: 0.0600\n",
      "Epoch 867/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2169 - f1: 0.8033 - val_loss: 0.3097 - val_f1: 0.0613\n",
      "Epoch 868/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2167 - f1: 0.8056 - val_loss: 0.3042 - val_f1: 0.0613\n",
      "Epoch 869/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2165 - f1: 0.8067 - val_loss: 0.3105 - val_f1: 0.0614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2168 - f1: 0.8048 - val_loss: 0.3072 - val_f1: 0.0616\n",
      "Epoch 871/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2153 - f1: 0.8051 - val_loss: 0.3070 - val_f1: 0.0603\n",
      "Epoch 872/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2156 - f1: 0.8058 - val_loss: 0.3058 - val_f1: 0.0608\n",
      "Epoch 873/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2137 - f1: 0.8073 - val_loss: 0.3112 - val_f1: 0.0610\n",
      "Epoch 874/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2158 - f1: 0.8065 - val_loss: 0.3099 - val_f1: 0.0619\n",
      "Epoch 875/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2157 - f1: 0.8052 - val_loss: 0.3082 - val_f1: 0.0607\n",
      "Epoch 876/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2162 - f1: 0.8073 - val_loss: 0.3060 - val_f1: 0.0604\n",
      "Epoch 877/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2158 - f1: 0.8063 - val_loss: 0.3103 - val_f1: 0.0620\n",
      "Epoch 878/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2161 - f1: 0.8052 - val_loss: 0.3118 - val_f1: 0.0609\n",
      "Epoch 879/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2159 - f1: 0.8047 - val_loss: 0.3033 - val_f1: 0.0605\n",
      "Epoch 880/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2153 - f1: 0.8068 - val_loss: 0.3047 - val_f1: 0.0610\n",
      "Epoch 881/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2157 - f1: 0.8062 - val_loss: 0.3043 - val_f1: 0.0607\n",
      "Epoch 882/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2166 - f1: 0.8051 - val_loss: 0.3105 - val_f1: 0.0614\n",
      "Epoch 883/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2156 - f1: 0.8052 - val_loss: 0.3078 - val_f1: 0.0606\n",
      "Epoch 884/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2158 - f1: 0.8055 - val_loss: 0.3117 - val_f1: 0.0607\n",
      "Epoch 885/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2141 - f1: 0.8095 - val_loss: 0.3056 - val_f1: 0.0607\n",
      "Epoch 886/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2150 - f1: 0.8082 - val_loss: 0.3111 - val_f1: 0.0609\n",
      "Epoch 887/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2144 - f1: 0.8086 - val_loss: 0.3131 - val_f1: 0.0616\n",
      "Epoch 888/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2153 - f1: 0.8084 - val_loss: 0.3036 - val_f1: 0.0605\n",
      "Epoch 889/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2136 - f1: 0.8091 - val_loss: 0.3129 - val_f1: 0.0616\n",
      "Epoch 890/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2162 - f1: 0.8055 - val_loss: 0.3019 - val_f1: 0.0610\n",
      "Epoch 891/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2153 - f1: 0.8061 - val_loss: 0.3096 - val_f1: 0.0613\n",
      "Epoch 892/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2142 - f1: 0.8089 - val_loss: 0.3098 - val_f1: 0.0603\n",
      "Epoch 893/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2154 - f1: 0.8080 - val_loss: 0.3055 - val_f1: 0.0614\n",
      "Epoch 894/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2148 - f1: 0.8080 - val_loss: 0.3034 - val_f1: 0.0606\n",
      "Epoch 895/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2150 - f1: 0.8068 - val_loss: 0.3059 - val_f1: 0.0600\n",
      "Epoch 896/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2136 - f1: 0.8073 - val_loss: 0.3127 - val_f1: 0.0616\n",
      "Epoch 897/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2148 - f1: 0.8063 - val_loss: 0.3004 - val_f1: 0.0610\n",
      "Epoch 898/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2140 - f1: 0.8086 - val_loss: 0.3080 - val_f1: 0.0609\n",
      "Epoch 899/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2143 - f1: 0.8069 - val_loss: 0.3113 - val_f1: 0.0606\n",
      "Epoch 900/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2148 - f1: 0.8071 - val_loss: 0.3066 - val_f1: 0.0606\n",
      "Epoch 901/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2157 - f1: 0.8037 - val_loss: 0.3013 - val_f1: 0.0608\n",
      "Epoch 902/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2151 - f1: 0.8083 - val_loss: 0.3084 - val_f1: 0.0609\n",
      "Epoch 903/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2153 - f1: 0.8074 - val_loss: 0.3073 - val_f1: 0.0602\n",
      "Epoch 904/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2145 - f1: 0.8082 - val_loss: 0.3122 - val_f1: 0.0609\n",
      "Epoch 905/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2144 - f1: 0.8064 - val_loss: 0.3115 - val_f1: 0.0608\n",
      "Epoch 906/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2134 - f1: 0.8096 - val_loss: 0.3063 - val_f1: 0.0605\n",
      "Epoch 907/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2155 - f1: 0.8060 - val_loss: 0.3006 - val_f1: 0.0604\n",
      "Epoch 908/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2133 - f1: 0.8084 - val_loss: 0.3097 - val_f1: 0.0605\n",
      "Epoch 909/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2156 - f1: 0.8065 - val_loss: 0.3108 - val_f1: 0.0614\n",
      "Epoch 910/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2139 - f1: 0.8080 - val_loss: 0.3105 - val_f1: 0.0605\n",
      "Epoch 911/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2145 - f1: 0.8065 - val_loss: 0.3062 - val_f1: 0.0607\n",
      "Epoch 912/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2134 - f1: 0.8095 - val_loss: 0.3059 - val_f1: 0.0603\n",
      "Epoch 913/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2140 - f1: 0.8068 - val_loss: 0.3105 - val_f1: 0.0601\n",
      "Epoch 914/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2142 - f1: 0.8100 - val_loss: 0.3037 - val_f1: 0.0611\n",
      "Epoch 915/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2152 - f1: 0.8058 - val_loss: 0.3086 - val_f1: 0.0608\n",
      "Epoch 916/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2150 - f1: 0.8065 - val_loss: 0.3098 - val_f1: 0.0604\n",
      "Epoch 917/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2136 - f1: 0.8101 - val_loss: 0.3065 - val_f1: 0.0604\n",
      "Epoch 918/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2133 - f1: 0.8087 - val_loss: 0.3089 - val_f1: 0.0617\n",
      "Epoch 919/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2151 - f1: 0.8071 - val_loss: 0.3025 - val_f1: 0.0606\n",
      "Epoch 920/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2131 - f1: 0.8096 - val_loss: 0.3091 - val_f1: 0.0609\n",
      "Epoch 921/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2125 - f1: 0.8106 - val_loss: 0.3093 - val_f1: 0.0614\n",
      "Epoch 922/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2139 - f1: 0.8096 - val_loss: 0.3061 - val_f1: 0.0609\n",
      "Epoch 923/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2149 - f1: 0.8071 - val_loss: 0.3120 - val_f1: 0.0608\n",
      "Epoch 924/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2139 - f1: 0.8102 - val_loss: 0.3050 - val_f1: 0.0608\n",
      "Epoch 925/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2140 - f1: 0.8089 - val_loss: 0.3029 - val_f1: 0.0604\n",
      "Epoch 926/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2156 - f1: 0.8065 - val_loss: 0.3040 - val_f1: 0.0596\n",
      "Epoch 927/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2145 - f1: 0.8074 - val_loss: 0.3098 - val_f1: 0.0610\n",
      "Epoch 928/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2131 - f1: 0.8071 - val_loss: 0.3103 - val_f1: 0.0609\n",
      "Epoch 929/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2126 - f1: 0.8094 - val_loss: 0.3043 - val_f1: 0.0598\n",
      "Epoch 930/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2141 - f1: 0.8070 - val_loss: 0.3062 - val_f1: 0.0608\n",
      "Epoch 931/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2151 - f1: 0.8074 - val_loss: 0.3107 - val_f1: 0.0600\n",
      "Epoch 932/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2134 - f1: 0.8079 - val_loss: 0.3112 - val_f1: 0.0616\n",
      "Epoch 933/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2155 - f1: 0.8067 - val_loss: 0.3063 - val_f1: 0.0612\n",
      "Epoch 934/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2136 - f1: 0.8077 - val_loss: 0.3055 - val_f1: 0.0610\n",
      "Epoch 935/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2128 - f1: 0.8097 - val_loss: 0.3087 - val_f1: 0.0607\n",
      "Epoch 936/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2148 - f1: 0.8054 - val_loss: 0.3063 - val_f1: 0.0611\n",
      "Epoch 937/2000\n",
      "168135/168135 [==============================] - 11s 65us/step - loss: 0.2139 - f1: 0.8073 - val_loss: 0.3018 - val_f1: 0.0611\n",
      "Epoch 938/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2153 - f1: 0.8055 - val_loss: 0.3120 - val_f1: 0.0608\n",
      "Epoch 939/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2132 - f1: 0.8089 - val_loss: 0.3097 - val_f1: 0.0609\n",
      "Epoch 940/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2143 - f1: 0.8084 - val_loss: 0.3089 - val_f1: 0.0607\n",
      "Epoch 941/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2130 - f1: 0.8077 - val_loss: 0.3136 - val_f1: 0.0614\n",
      "Epoch 942/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2132 - f1: 0.8089 - val_loss: 0.3083 - val_f1: 0.0604\n",
      "Epoch 943/2000\n",
      "168135/168135 [==============================] - 12s 69us/step - loss: 0.2129 - f1: 0.8094 - val_loss: 0.3103 - val_f1: 0.0613\n",
      "Epoch 944/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2120 - f1: 0.8109 - val_loss: 0.3040 - val_f1: 0.0610\n",
      "Epoch 945/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2150 - f1: 0.8055 - val_loss: 0.3090 - val_f1: 0.0611\n",
      "Epoch 946/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2120 - f1: 0.8103 - val_loss: 0.3112 - val_f1: 0.0610\n",
      "Epoch 947/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2134 - f1: 0.8095 - val_loss: 0.3062 - val_f1: 0.0607\n",
      "Epoch 948/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2121 - f1: 0.8087 - val_loss: 0.3080 - val_f1: 0.0607\n",
      "Epoch 949/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2145 - f1: 0.8069 - val_loss: 0.3104 - val_f1: 0.0606\n",
      "Epoch 950/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2135 - f1: 0.8071 - val_loss: 0.3076 - val_f1: 0.0616\n",
      "Epoch 951/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2124 - f1: 0.8096 - val_loss: 0.3026 - val_f1: 0.0608\n",
      "Epoch 952/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2138 - f1: 0.8079 - val_loss: 0.3089 - val_f1: 0.0614\n",
      "Epoch 953/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2142 - f1: 0.8074 - val_loss: 0.3016 - val_f1: 0.0604\n",
      "Epoch 954/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2138 - f1: 0.8083 - val_loss: 0.3076 - val_f1: 0.0602\n",
      "Epoch 955/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2128 - f1: 0.8103 - val_loss: 0.3075 - val_f1: 0.0613\n",
      "Epoch 956/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2138 - f1: 0.8070 - val_loss: 0.3057 - val_f1: 0.0607\n",
      "Epoch 957/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2116 - f1: 0.8108 - val_loss: 0.3150 - val_f1: 0.0618\n",
      "Epoch 958/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2145 - f1: 0.8070 - val_loss: 0.3066 - val_f1: 0.0607\n",
      "Epoch 959/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2131 - f1: 0.8104 - val_loss: 0.3107 - val_f1: 0.0605\n",
      "Epoch 960/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2138 - f1: 0.8058 - val_loss: 0.3061 - val_f1: 0.0609\n",
      "Epoch 961/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2138 - f1: 0.8080 - val_loss: 0.3130 - val_f1: 0.0617\n",
      "Epoch 962/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2144 - f1: 0.8069 - val_loss: 0.3051 - val_f1: 0.0604\n",
      "Epoch 963/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2115 - f1: 0.8110 - val_loss: 0.3112 - val_f1: 0.0613\n",
      "Epoch 964/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2131 - f1: 0.8092 - val_loss: 0.3126 - val_f1: 0.0616\n",
      "Epoch 965/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2119 - f1: 0.8096 - val_loss: 0.3084 - val_f1: 0.0603\n",
      "Epoch 966/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2128 - f1: 0.8114 - val_loss: 0.3098 - val_f1: 0.0603\n",
      "Epoch 967/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2123 - f1: 0.8091 - val_loss: 0.3110 - val_f1: 0.0609\n",
      "Epoch 968/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2138 - f1: 0.8085 - val_loss: 0.3162 - val_f1: 0.0608\n",
      "Epoch 969/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2127 - f1: 0.8091 - val_loss: 0.3035 - val_f1: 0.0604\n",
      "Epoch 970/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2119 - f1: 0.8110 - val_loss: 0.3100 - val_f1: 0.0612\n",
      "Epoch 971/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2124 - f1: 0.8089 - val_loss: 0.3071 - val_f1: 0.0605\n",
      "Epoch 972/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2138 - f1: 0.8070 - val_loss: 0.3121 - val_f1: 0.0616\n",
      "Epoch 973/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2126 - f1: 0.8102 - val_loss: 0.3048 - val_f1: 0.0601\n",
      "Epoch 974/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2132 - f1: 0.8087 - val_loss: 0.3085 - val_f1: 0.0608\n",
      "Epoch 975/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2124 - f1: 0.8092 - val_loss: 0.3077 - val_f1: 0.0603\n",
      "Epoch 976/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2147 - f1: 0.8080 - val_loss: 0.3094 - val_f1: 0.0614\n",
      "Epoch 977/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2122 - f1: 0.8096 - val_loss: 0.3093 - val_f1: 0.0602\n",
      "Epoch 978/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2120 - f1: 0.8074 - val_loss: 0.3127 - val_f1: 0.0599\n",
      "Epoch 979/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2125 - f1: 0.8113 - val_loss: 0.3088 - val_f1: 0.0598\n",
      "Epoch 980/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2101 - f1: 0.8121 - val_loss: 0.3144 - val_f1: 0.0607\n",
      "Epoch 981/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2123 - f1: 0.8122 - val_loss: 0.3134 - val_f1: 0.0605\n",
      "Epoch 982/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2122 - f1: 0.8100 - val_loss: 0.3103 - val_f1: 0.0608\n",
      "Epoch 983/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2125 - f1: 0.8091 - val_loss: 0.3107 - val_f1: 0.0602\n",
      "Epoch 984/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2124 - f1: 0.8084 - val_loss: 0.3053 - val_f1: 0.0607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 985/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2122 - f1: 0.8104 - val_loss: 0.3187 - val_f1: 0.0614\n",
      "Epoch 986/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2129 - f1: 0.8123 - val_loss: 0.3136 - val_f1: 0.0607\n",
      "Epoch 987/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2130 - f1: 0.8080 - val_loss: 0.3043 - val_f1: 0.0601\n",
      "Epoch 988/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2129 - f1: 0.8093 - val_loss: 0.3090 - val_f1: 0.0613\n",
      "Epoch 989/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2109 - f1: 0.8096 - val_loss: 0.3047 - val_f1: 0.0603\n",
      "Epoch 990/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2127 - f1: 0.8101 - val_loss: 0.3092 - val_f1: 0.0608\n",
      "Epoch 991/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2119 - f1: 0.8090 - val_loss: 0.3152 - val_f1: 0.0614\n",
      "Epoch 992/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2130 - f1: 0.8086 - val_loss: 0.3081 - val_f1: 0.0603\n",
      "Epoch 993/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2136 - f1: 0.8104 - val_loss: 0.2991 - val_f1: 0.0596\n",
      "Epoch 994/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2125 - f1: 0.8090 - val_loss: 0.3079 - val_f1: 0.0601\n",
      "Epoch 995/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2112 - f1: 0.8121 - val_loss: 0.3063 - val_f1: 0.0608\n",
      "Epoch 996/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2135 - f1: 0.8083 - val_loss: 0.3080 - val_f1: 0.0610\n",
      "Epoch 997/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2116 - f1: 0.8099 - val_loss: 0.3111 - val_f1: 0.0615\n",
      "Epoch 998/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2130 - f1: 0.8090 - val_loss: 0.3041 - val_f1: 0.0603\n",
      "Epoch 999/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2116 - f1: 0.8127 - val_loss: 0.3064 - val_f1: 0.0603\n",
      "Epoch 1000/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2111 - f1: 0.8110 - val_loss: 0.3137 - val_f1: 0.0611\n",
      "Epoch 1001/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2121 - f1: 0.8097 - val_loss: 0.3066 - val_f1: 0.0611\n",
      "Epoch 1002/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2119 - f1: 0.8093 - val_loss: 0.3086 - val_f1: 0.0596\n",
      "Epoch 1003/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2129 - f1: 0.8074 - val_loss: 0.3126 - val_f1: 0.0606\n",
      "Epoch 1004/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2133 - f1: 0.8069 - val_loss: 0.3110 - val_f1: 0.0606\n",
      "Epoch 1005/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2114 - f1: 0.8100 - val_loss: 0.3073 - val_f1: 0.0608\n",
      "Epoch 1006/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2117 - f1: 0.8083 - val_loss: 0.3098 - val_f1: 0.0609\n",
      "Epoch 1007/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2131 - f1: 0.8087 - val_loss: 0.3052 - val_f1: 0.0597\n",
      "Epoch 1008/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2124 - f1: 0.8102 - val_loss: 0.3078 - val_f1: 0.0600\n",
      "Epoch 1009/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2113 - f1: 0.8117 - val_loss: 0.3072 - val_f1: 0.0608\n",
      "Epoch 1010/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2119 - f1: 0.8110 - val_loss: 0.3075 - val_f1: 0.0604\n",
      "Epoch 1011/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2129 - f1: 0.8102 - val_loss: 0.3139 - val_f1: 0.0609\n",
      "Epoch 1012/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2109 - f1: 0.8108 - val_loss: 0.3048 - val_f1: 0.0611\n",
      "Epoch 1013/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2111 - f1: 0.8116 - val_loss: 0.3126 - val_f1: 0.0612\n",
      "Epoch 1014/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2123 - f1: 0.8103 - val_loss: 0.3104 - val_f1: 0.0609\n",
      "Epoch 1015/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2109 - f1: 0.8099 - val_loss: 0.3094 - val_f1: 0.0612\n",
      "Epoch 1016/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2120 - f1: 0.8103 - val_loss: 0.3131 - val_f1: 0.0610\n",
      "Epoch 1017/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2125 - f1: 0.8107 - val_loss: 0.3100 - val_f1: 0.0608\n",
      "Epoch 1018/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2123 - f1: 0.8099 - val_loss: 0.3087 - val_f1: 0.0610\n",
      "Epoch 1019/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2114 - f1: 0.8107 - val_loss: 0.3144 - val_f1: 0.0605\n",
      "Epoch 1020/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2118 - f1: 0.8117 - val_loss: 0.3140 - val_f1: 0.0612\n",
      "Epoch 1021/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2114 - f1: 0.8116 - val_loss: 0.3125 - val_f1: 0.0613\n",
      "Epoch 1022/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2123 - f1: 0.8105 - val_loss: 0.3132 - val_f1: 0.0607\n",
      "Epoch 1023/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2127 - f1: 0.8110 - val_loss: 0.3031 - val_f1: 0.0599\n",
      "Epoch 1024/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2104 - f1: 0.8127 - val_loss: 0.3082 - val_f1: 0.0606\n",
      "Epoch 1025/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2126 - f1: 0.8087 - val_loss: 0.3017 - val_f1: 0.0599\n",
      "Epoch 1026/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2113 - f1: 0.8108 - val_loss: 0.3096 - val_f1: 0.0606\n",
      "Epoch 1027/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2103 - f1: 0.8107 - val_loss: 0.3083 - val_f1: 0.0601\n",
      "Epoch 1028/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2121 - f1: 0.8093 - val_loss: 0.3081 - val_f1: 0.0603\n",
      "Epoch 1029/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2096 - f1: 0.8113 - val_loss: 0.3141 - val_f1: 0.0603\n",
      "Epoch 1030/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2098 - f1: 0.8135 - val_loss: 0.3108 - val_f1: 0.0614\n",
      "Epoch 1031/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2113 - f1: 0.8100 - val_loss: 0.3148 - val_f1: 0.0609\n",
      "Epoch 1032/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2104 - f1: 0.8108 - val_loss: 0.3078 - val_f1: 0.0601\n",
      "Epoch 1033/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2122 - f1: 0.8079 - val_loss: 0.3013 - val_f1: 0.0599\n",
      "Epoch 1034/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2106 - f1: 0.8119 - val_loss: 0.3080 - val_f1: 0.0607\n",
      "Epoch 1035/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2107 - f1: 0.8101 - val_loss: 0.3185 - val_f1: 0.0609\n",
      "Epoch 1036/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2109 - f1: 0.8120 - val_loss: 0.3116 - val_f1: 0.0601\n",
      "Epoch 1037/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2115 - f1: 0.8104 - val_loss: 0.3167 - val_f1: 0.0605\n",
      "Epoch 1038/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2108 - f1: 0.8111 - val_loss: 0.3069 - val_f1: 0.0597\n",
      "Epoch 1039/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2103 - f1: 0.8123 - val_loss: 0.3103 - val_f1: 0.0604\n",
      "Epoch 1040/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2102 - f1: 0.8125 - val_loss: 0.3082 - val_f1: 0.0600\n",
      "Epoch 1041/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2096 - f1: 0.8119 - val_loss: 0.3150 - val_f1: 0.0610\n",
      "Epoch 1042/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2114 - f1: 0.8104 - val_loss: 0.3139 - val_f1: 0.0616\n",
      "Epoch 1043/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2132 - f1: 0.8081 - val_loss: 0.3048 - val_f1: 0.0613\n",
      "Epoch 1044/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2104 - f1: 0.8110 - val_loss: 0.3090 - val_f1: 0.0601\n",
      "Epoch 1045/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2100 - f1: 0.8131 - val_loss: 0.3105 - val_f1: 0.0607\n",
      "Epoch 1046/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2093 - f1: 0.8130 - val_loss: 0.3053 - val_f1: 0.0602\n",
      "Epoch 1047/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2111 - f1: 0.8107 - val_loss: 0.3028 - val_f1: 0.0597\n",
      "Epoch 1048/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2105 - f1: 0.8120 - val_loss: 0.3110 - val_f1: 0.0604\n",
      "Epoch 1049/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2099 - f1: 0.8109 - val_loss: 0.3099 - val_f1: 0.0600\n",
      "Epoch 1050/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2096 - f1: 0.8130 - val_loss: 0.3106 - val_f1: 0.0610\n",
      "Epoch 1051/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2094 - f1: 0.8145 - val_loss: 0.3116 - val_f1: 0.0605\n",
      "Epoch 1052/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2102 - f1: 0.8123 - val_loss: 0.3044 - val_f1: 0.0601\n",
      "Epoch 1053/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2105 - f1: 0.8128 - val_loss: 0.3162 - val_f1: 0.0611\n",
      "Epoch 1054/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2101 - f1: 0.8128 - val_loss: 0.3149 - val_f1: 0.0599\n",
      "Epoch 1055/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2099 - f1: 0.8139 - val_loss: 0.3137 - val_f1: 0.0599\n",
      "Epoch 1056/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2115 - f1: 0.8112 - val_loss: 0.3082 - val_f1: 0.0601\n",
      "Epoch 1057/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2099 - f1: 0.8121 - val_loss: 0.3091 - val_f1: 0.0600\n",
      "Epoch 1058/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2117 - f1: 0.8101 - val_loss: 0.3095 - val_f1: 0.0607\n",
      "Epoch 1059/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2122 - f1: 0.8097 - val_loss: 0.3099 - val_f1: 0.0612\n",
      "Epoch 1060/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2104 - f1: 0.8126 - val_loss: 0.3078 - val_f1: 0.0603\n",
      "Epoch 1061/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2110 - f1: 0.8133 - val_loss: 0.3190 - val_f1: 0.0609\n",
      "Epoch 1062/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2100 - f1: 0.8113 - val_loss: 0.3131 - val_f1: 0.0608\n",
      "Epoch 1063/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2102 - f1: 0.8121 - val_loss: 0.3130 - val_f1: 0.0605\n",
      "Epoch 1064/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2105 - f1: 0.8122 - val_loss: 0.3136 - val_f1: 0.0609\n",
      "Epoch 1065/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2086 - f1: 0.8135 - val_loss: 0.3068 - val_f1: 0.0601\n",
      "Epoch 1066/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2108 - f1: 0.8112 - val_loss: 0.3121 - val_f1: 0.0611\n",
      "Epoch 1067/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2103 - f1: 0.8124 - val_loss: 0.3107 - val_f1: 0.0604\n",
      "Epoch 1068/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2099 - f1: 0.8117 - val_loss: 0.3147 - val_f1: 0.0602\n",
      "Epoch 1069/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2106 - f1: 0.8112 - val_loss: 0.3074 - val_f1: 0.0609\n",
      "Epoch 1070/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2112 - f1: 0.8113 - val_loss: 0.3142 - val_f1: 0.0608\n",
      "Epoch 1071/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2097 - f1: 0.8111 - val_loss: 0.3125 - val_f1: 0.0605\n",
      "Epoch 1072/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2114 - f1: 0.8119 - val_loss: 0.3078 - val_f1: 0.0602\n",
      "Epoch 1073/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2103 - f1: 0.8129 - val_loss: 0.3110 - val_f1: 0.0600\n",
      "Epoch 1074/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2098 - f1: 0.8128 - val_loss: 0.3081 - val_f1: 0.0605\n",
      "Epoch 1075/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2087 - f1: 0.8128 - val_loss: 0.3156 - val_f1: 0.0614\n",
      "Epoch 1076/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2101 - f1: 0.8114 - val_loss: 0.3077 - val_f1: 0.0604\n",
      "Epoch 1077/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2106 - f1: 0.8122 - val_loss: 0.3033 - val_f1: 0.0602\n",
      "Epoch 1078/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2100 - f1: 0.8116 - val_loss: 0.3099 - val_f1: 0.0602\n",
      "Epoch 1079/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2102 - f1: 0.8119 - val_loss: 0.3090 - val_f1: 0.0600\n",
      "Epoch 1080/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2094 - f1: 0.8134 - val_loss: 0.3101 - val_f1: 0.0605\n",
      "Epoch 1081/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2092 - f1: 0.8138 - val_loss: 0.3093 - val_f1: 0.0607\n",
      "Epoch 1082/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2082 - f1: 0.8143 - val_loss: 0.3044 - val_f1: 0.0600\n",
      "Epoch 1083/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2110 - f1: 0.8111 - val_loss: 0.3163 - val_f1: 0.0610\n",
      "Epoch 1084/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2093 - f1: 0.8136 - val_loss: 0.3015 - val_f1: 0.0602\n",
      "Epoch 1085/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2103 - f1: 0.8123 - val_loss: 0.3107 - val_f1: 0.0604\n",
      "Epoch 1086/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2093 - f1: 0.8136 - val_loss: 0.3096 - val_f1: 0.0607\n",
      "Epoch 1087/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2112 - f1: 0.8114 - val_loss: 0.3113 - val_f1: 0.0608\n",
      "Epoch 1088/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2108 - f1: 0.8106 - val_loss: 0.3090 - val_f1: 0.0602\n",
      "Epoch 1089/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2096 - f1: 0.8121 - val_loss: 0.3121 - val_f1: 0.0596\n",
      "Epoch 1090/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2101 - f1: 0.8124 - val_loss: 0.3105 - val_f1: 0.0602\n",
      "Epoch 1091/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2099 - f1: 0.8133 - val_loss: 0.3067 - val_f1: 0.0603\n",
      "Epoch 1092/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2078 - f1: 0.8153 - val_loss: 0.3107 - val_f1: 0.0598\n",
      "Epoch 1093/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2114 - f1: 0.8108 - val_loss: 0.3170 - val_f1: 0.0609\n",
      "Epoch 1094/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2098 - f1: 0.8125 - val_loss: 0.3121 - val_f1: 0.0607\n",
      "Epoch 1095/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2092 - f1: 0.8123 - val_loss: 0.3111 - val_f1: 0.0607\n",
      "Epoch 1096/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2098 - f1: 0.8111 - val_loss: 0.3088 - val_f1: 0.0607\n",
      "Epoch 1097/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2092 - f1: 0.8138 - val_loss: 0.3066 - val_f1: 0.0602\n",
      "Epoch 1098/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2070 - f1: 0.8155 - val_loss: 0.3130 - val_f1: 0.0612\n",
      "Epoch 1099/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2077 - f1: 0.8144 - val_loss: 0.3107 - val_f1: 0.0600\n",
      "Epoch 1100/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2089 - f1: 0.8132 - val_loss: 0.3181 - val_f1: 0.0610\n",
      "Epoch 1101/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2090 - f1: 0.8120 - val_loss: 0.3119 - val_f1: 0.0606\n",
      "Epoch 1102/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2088 - f1: 0.8128 - val_loss: 0.3164 - val_f1: 0.0612\n",
      "Epoch 1103/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2091 - f1: 0.8135 - val_loss: 0.3078 - val_f1: 0.0605\n",
      "Epoch 1104/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2099 - f1: 0.8121 - val_loss: 0.3112 - val_f1: 0.0604\n",
      "Epoch 1105/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2099 - f1: 0.8118 - val_loss: 0.3112 - val_f1: 0.0600\n",
      "Epoch 1106/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2090 - f1: 0.8134 - val_loss: 0.3167 - val_f1: 0.0608\n",
      "Epoch 1107/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2084 - f1: 0.8145 - val_loss: 0.3154 - val_f1: 0.0604\n",
      "Epoch 1108/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2078 - f1: 0.8157 - val_loss: 0.3152 - val_f1: 0.0606\n",
      "Epoch 1109/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2101 - f1: 0.8124 - val_loss: 0.3120 - val_f1: 0.0608\n",
      "Epoch 1110/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2101 - f1: 0.8110 - val_loss: 0.3202 - val_f1: 0.0606\n",
      "Epoch 1111/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2098 - f1: 0.8128 - val_loss: 0.3077 - val_f1: 0.0601\n",
      "Epoch 1112/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2096 - f1: 0.8125 - val_loss: 0.3101 - val_f1: 0.0614\n",
      "Epoch 1113/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2089 - f1: 0.8135 - val_loss: 0.3108 - val_f1: 0.0606\n",
      "Epoch 1114/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2083 - f1: 0.8147 - val_loss: 0.3116 - val_f1: 0.0605\n",
      "Epoch 1115/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2092 - f1: 0.8136 - val_loss: 0.3140 - val_f1: 0.0606\n",
      "Epoch 1116/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2105 - f1: 0.8125 - val_loss: 0.3104 - val_f1: 0.0597\n",
      "Epoch 1117/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2085 - f1: 0.8143 - val_loss: 0.3144 - val_f1: 0.0614\n",
      "Epoch 1118/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2088 - f1: 0.8122 - val_loss: 0.3108 - val_f1: 0.0601\n",
      "Epoch 1119/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2098 - f1: 0.8107 - val_loss: 0.3152 - val_f1: 0.0608\n",
      "Epoch 1120/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2092 - f1: 0.8133 - val_loss: 0.3142 - val_f1: 0.0614\n",
      "Epoch 1121/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2091 - f1: 0.8137 - val_loss: 0.3108 - val_f1: 0.0595\n",
      "Epoch 1122/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2094 - f1: 0.8134 - val_loss: 0.3047 - val_f1: 0.0600\n",
      "Epoch 1123/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2081 - f1: 0.8130 - val_loss: 0.3097 - val_f1: 0.0609\n",
      "Epoch 1124/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2092 - f1: 0.8126 - val_loss: 0.3133 - val_f1: 0.0607\n",
      "Epoch 1125/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2072 - f1: 0.8152 - val_loss: 0.3142 - val_f1: 0.0605\n",
      "Epoch 1126/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2078 - f1: 0.8144 - val_loss: 0.3089 - val_f1: 0.0604\n",
      "Epoch 1127/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2102 - f1: 0.8108 - val_loss: 0.3081 - val_f1: 0.0601\n",
      "Epoch 1128/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2104 - f1: 0.8136 - val_loss: 0.3110 - val_f1: 0.0607\n",
      "Epoch 1129/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2071 - f1: 0.8147 - val_loss: 0.3113 - val_f1: 0.0606\n",
      "Epoch 1130/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2078 - f1: 0.8152 - val_loss: 0.3073 - val_f1: 0.0597\n",
      "Epoch 1131/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2079 - f1: 0.8133 - val_loss: 0.3202 - val_f1: 0.0616\n",
      "Epoch 1132/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2088 - f1: 0.8126 - val_loss: 0.3081 - val_f1: 0.0602\n",
      "Epoch 1133/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2099 - f1: 0.8135 - val_loss: 0.3132 - val_f1: 0.0609\n",
      "Epoch 1134/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2093 - f1: 0.8138 - val_loss: 0.3114 - val_f1: 0.0613\n",
      "Epoch 1135/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2101 - f1: 0.8111 - val_loss: 0.3056 - val_f1: 0.0595\n",
      "Epoch 1136/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2095 - f1: 0.8138 - val_loss: 0.3144 - val_f1: 0.0603\n",
      "Epoch 1137/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2089 - f1: 0.8135 - val_loss: 0.3156 - val_f1: 0.0608\n",
      "Epoch 1138/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2077 - f1: 0.8156 - val_loss: 0.3153 - val_f1: 0.0600\n",
      "Epoch 1139/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2079 - f1: 0.8138 - val_loss: 0.3129 - val_f1: 0.0610\n",
      "Epoch 1140/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2097 - f1: 0.8121 - val_loss: 0.3155 - val_f1: 0.0604\n",
      "Epoch 1141/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2089 - f1: 0.8147 - val_loss: 0.3070 - val_f1: 0.0603\n",
      "Epoch 1142/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2075 - f1: 0.8146 - val_loss: 0.3143 - val_f1: 0.0595\n",
      "Epoch 1143/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2094 - f1: 0.8137 - val_loss: 0.3095 - val_f1: 0.0603\n",
      "Epoch 1144/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2082 - f1: 0.8130 - val_loss: 0.3142 - val_f1: 0.0603\n",
      "Epoch 1145/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2088 - f1: 0.8136 - val_loss: 0.3175 - val_f1: 0.0604\n",
      "Epoch 1146/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2077 - f1: 0.8136 - val_loss: 0.3110 - val_f1: 0.0599\n",
      "Epoch 1147/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2078 - f1: 0.8151 - val_loss: 0.3126 - val_f1: 0.0592\n",
      "Epoch 1148/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2071 - f1: 0.8157 - val_loss: 0.3130 - val_f1: 0.0603\n",
      "Epoch 1149/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2085 - f1: 0.8137 - val_loss: 0.3163 - val_f1: 0.0603\n",
      "Epoch 1150/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2068 - f1: 0.8159 - val_loss: 0.3112 - val_f1: 0.0604\n",
      "Epoch 1151/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2081 - f1: 0.8143 - val_loss: 0.3123 - val_f1: 0.0603\n",
      "Epoch 1152/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2091 - f1: 0.8147 - val_loss: 0.3138 - val_f1: 0.0596\n",
      "Epoch 1153/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2094 - f1: 0.8130 - val_loss: 0.3149 - val_f1: 0.0611\n",
      "Epoch 1154/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2075 - f1: 0.8153 - val_loss: 0.3149 - val_f1: 0.0596\n",
      "Epoch 1155/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2069 - f1: 0.8143 - val_loss: 0.3129 - val_f1: 0.0605\n",
      "Epoch 1156/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2087 - f1: 0.8120 - val_loss: 0.3160 - val_f1: 0.0617\n",
      "Epoch 1157/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2091 - f1: 0.8150 - val_loss: 0.3097 - val_f1: 0.0604\n",
      "Epoch 1158/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2075 - f1: 0.8145 - val_loss: 0.3106 - val_f1: 0.0609\n",
      "Epoch 1159/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2092 - f1: 0.8144 - val_loss: 0.3134 - val_f1: 0.0602\n",
      "Epoch 1160/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2071 - f1: 0.8151 - val_loss: 0.3133 - val_f1: 0.0608\n",
      "Epoch 1161/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2065 - f1: 0.8164 - val_loss: 0.3200 - val_f1: 0.0610\n",
      "Epoch 1162/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2068 - f1: 0.8151 - val_loss: 0.3113 - val_f1: 0.0597\n",
      "Epoch 1163/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2084 - f1: 0.8140 - val_loss: 0.3181 - val_f1: 0.0600\n",
      "Epoch 1164/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2075 - f1: 0.8149 - val_loss: 0.3090 - val_f1: 0.0601\n",
      "Epoch 1165/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2073 - f1: 0.8147 - val_loss: 0.3104 - val_f1: 0.0600\n",
      "Epoch 1166/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2083 - f1: 0.8137 - val_loss: 0.3093 - val_f1: 0.0605\n",
      "Epoch 1167/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2081 - f1: 0.8142 - val_loss: 0.3069 - val_f1: 0.0600\n",
      "Epoch 1168/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2073 - f1: 0.8153 - val_loss: 0.3120 - val_f1: 0.0598\n",
      "Epoch 1169/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2056 - f1: 0.8165 - val_loss: 0.3086 - val_f1: 0.0604\n",
      "Epoch 1170/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2092 - f1: 0.8133 - val_loss: 0.3076 - val_f1: 0.0593\n",
      "Epoch 1171/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2081 - f1: 0.8135 - val_loss: 0.3115 - val_f1: 0.0606\n",
      "Epoch 1172/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2086 - f1: 0.8152 - val_loss: 0.3131 - val_f1: 0.0598\n",
      "Epoch 1173/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2073 - f1: 0.8138 - val_loss: 0.3168 - val_f1: 0.0608\n",
      "Epoch 1174/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2061 - f1: 0.8173 - val_loss: 0.3153 - val_f1: 0.0608\n",
      "Epoch 1175/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2060 - f1: 0.8165 - val_loss: 0.3154 - val_f1: 0.0605\n",
      "Epoch 1176/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2072 - f1: 0.8145 - val_loss: 0.3187 - val_f1: 0.0607\n",
      "Epoch 1177/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2075 - f1: 0.8171 - val_loss: 0.3140 - val_f1: 0.0609\n",
      "Epoch 1178/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2045 - f1: 0.8167 - val_loss: 0.3143 - val_f1: 0.0599\n",
      "Epoch 1179/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2061 - f1: 0.8163 - val_loss: 0.3108 - val_f1: 0.0608\n",
      "Epoch 1180/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2081 - f1: 0.8150 - val_loss: 0.3162 - val_f1: 0.0611\n",
      "Epoch 1181/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2082 - f1: 0.8134 - val_loss: 0.3112 - val_f1: 0.0603\n",
      "Epoch 1182/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2072 - f1: 0.8165 - val_loss: 0.3105 - val_f1: 0.0601\n",
      "Epoch 1183/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2089 - f1: 0.8144 - val_loss: 0.3191 - val_f1: 0.0617\n",
      "Epoch 1184/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2070 - f1: 0.8155 - val_loss: 0.3230 - val_f1: 0.0617\n",
      "Epoch 1185/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2076 - f1: 0.8168 - val_loss: 0.3183 - val_f1: 0.0607\n",
      "Epoch 1186/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2085 - f1: 0.8154 - val_loss: 0.3141 - val_f1: 0.0603\n",
      "Epoch 1187/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2070 - f1: 0.8154 - val_loss: 0.3117 - val_f1: 0.0602\n",
      "Epoch 1188/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2087 - f1: 0.8153 - val_loss: 0.3137 - val_f1: 0.0612\n",
      "Epoch 1189/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2094 - f1: 0.8131 - val_loss: 0.3175 - val_f1: 0.0605\n",
      "Epoch 1190/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2072 - f1: 0.8161 - val_loss: 0.3140 - val_f1: 0.0606\n",
      "Epoch 1191/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2070 - f1: 0.8166 - val_loss: 0.3097 - val_f1: 0.0597\n",
      "Epoch 1192/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2074 - f1: 0.8134 - val_loss: 0.3096 - val_f1: 0.0599\n",
      "Epoch 1193/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2056 - f1: 0.8174 - val_loss: 0.3118 - val_f1: 0.0600\n",
      "Epoch 1194/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2054 - f1: 0.8162 - val_loss: 0.3172 - val_f1: 0.0603\n",
      "Epoch 1195/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2075 - f1: 0.8145 - val_loss: 0.3114 - val_f1: 0.0590\n",
      "Epoch 1196/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2088 - f1: 0.8129 - val_loss: 0.3085 - val_f1: 0.0604\n",
      "Epoch 1197/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2074 - f1: 0.8143 - val_loss: 0.3070 - val_f1: 0.0592\n",
      "Epoch 1198/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2057 - f1: 0.8183 - val_loss: 0.3130 - val_f1: 0.0608\n",
      "Epoch 1199/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2066 - f1: 0.8168 - val_loss: 0.3122 - val_f1: 0.0599\n",
      "Epoch 1200/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2081 - f1: 0.8144 - val_loss: 0.3148 - val_f1: 0.0598\n",
      "Epoch 1201/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2074 - f1: 0.8153 - val_loss: 0.3109 - val_f1: 0.0607\n",
      "Epoch 1202/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2063 - f1: 0.8167 - val_loss: 0.3072 - val_f1: 0.0604\n",
      "Epoch 1203/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2083 - f1: 0.8151 - val_loss: 0.3091 - val_f1: 0.0603\n",
      "Epoch 1204/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2062 - f1: 0.8162 - val_loss: 0.3167 - val_f1: 0.0605\n",
      "Epoch 1205/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2077 - f1: 0.8151 - val_loss: 0.3111 - val_f1: 0.0599\n",
      "Epoch 1206/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2071 - f1: 0.8146 - val_loss: 0.3094 - val_f1: 0.0605\n",
      "Epoch 1207/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2079 - f1: 0.8137 - val_loss: 0.3160 - val_f1: 0.0612\n",
      "Epoch 1208/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2070 - f1: 0.8152 - val_loss: 0.3081 - val_f1: 0.0599\n",
      "Epoch 1209/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2081 - f1: 0.8140 - val_loss: 0.3110 - val_f1: 0.0602\n",
      "Epoch 1210/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2060 - f1: 0.8180 - val_loss: 0.3124 - val_f1: 0.0598\n",
      "Epoch 1211/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2061 - f1: 0.8160 - val_loss: 0.3167 - val_f1: 0.0605\n",
      "Epoch 1212/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2078 - f1: 0.8128 - val_loss: 0.3132 - val_f1: 0.0607\n",
      "Epoch 1213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2081 - f1: 0.8138 - val_loss: 0.3119 - val_f1: 0.0605\n",
      "Epoch 1214/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2052 - f1: 0.8150 - val_loss: 0.3147 - val_f1: 0.0595\n",
      "Epoch 1215/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2090 - f1: 0.8135 - val_loss: 0.3116 - val_f1: 0.0609\n",
      "Epoch 1216/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2084 - f1: 0.8136 - val_loss: 0.3171 - val_f1: 0.0607\n",
      "Epoch 1217/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2054 - f1: 0.8177 - val_loss: 0.3123 - val_f1: 0.0607\n",
      "Epoch 1218/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2076 - f1: 0.8145 - val_loss: 0.3148 - val_f1: 0.0613\n",
      "Epoch 1219/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2075 - f1: 0.8147 - val_loss: 0.3182 - val_f1: 0.0603\n",
      "Epoch 1220/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2053 - f1: 0.8173 - val_loss: 0.3180 - val_f1: 0.0604\n",
      "Epoch 1221/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2081 - f1: 0.8163 - val_loss: 0.3110 - val_f1: 0.0607\n",
      "Epoch 1222/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2076 - f1: 0.8155 - val_loss: 0.3078 - val_f1: 0.0599\n",
      "Epoch 1223/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2052 - f1: 0.8181 - val_loss: 0.3195 - val_f1: 0.0614\n",
      "Epoch 1224/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2076 - f1: 0.8152 - val_loss: 0.3079 - val_f1: 0.0599\n",
      "Epoch 1225/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2077 - f1: 0.8148 - val_loss: 0.3199 - val_f1: 0.0594\n",
      "Epoch 1226/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2079 - f1: 0.8151 - val_loss: 0.3091 - val_f1: 0.0608\n",
      "Epoch 1227/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2077 - f1: 0.8156 - val_loss: 0.3142 - val_f1: 0.0602\n",
      "Epoch 1228/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2069 - f1: 0.8149 - val_loss: 0.3175 - val_f1: 0.0608\n",
      "Epoch 1229/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2064 - f1: 0.8152 - val_loss: 0.3213 - val_f1: 0.0608\n",
      "Epoch 1230/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2055 - f1: 0.8174 - val_loss: 0.3130 - val_f1: 0.0604\n",
      "Epoch 1231/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2065 - f1: 0.8141 - val_loss: 0.3098 - val_f1: 0.0602\n",
      "Epoch 1232/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2074 - f1: 0.8143 - val_loss: 0.3125 - val_f1: 0.0594\n",
      "Epoch 1233/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2063 - f1: 0.8189 - val_loss: 0.3126 - val_f1: 0.0607\n",
      "Epoch 1234/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2070 - f1: 0.8137 - val_loss: 0.3092 - val_f1: 0.0601\n",
      "Epoch 1235/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2061 - f1: 0.8159 - val_loss: 0.3089 - val_f1: 0.0598\n",
      "Epoch 1236/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2069 - f1: 0.8150 - val_loss: 0.3137 - val_f1: 0.0606\n",
      "Epoch 1237/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2067 - f1: 0.8158 - val_loss: 0.3131 - val_f1: 0.0610\n",
      "Epoch 1238/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2062 - f1: 0.8160 - val_loss: 0.3129 - val_f1: 0.0605\n",
      "Epoch 1239/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2065 - f1: 0.8161 - val_loss: 0.3082 - val_f1: 0.0599\n",
      "Epoch 1240/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2056 - f1: 0.8192 - val_loss: 0.3124 - val_f1: 0.0594\n",
      "Epoch 1241/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2061 - f1: 0.8160 - val_loss: 0.3151 - val_f1: 0.0598\n",
      "Epoch 1242/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2078 - f1: 0.8147 - val_loss: 0.3123 - val_f1: 0.0596\n",
      "Epoch 1243/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2065 - f1: 0.8160 - val_loss: 0.3088 - val_f1: 0.0598\n",
      "Epoch 1244/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2060 - f1: 0.8177 - val_loss: 0.3183 - val_f1: 0.0596\n",
      "Epoch 1245/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2051 - f1: 0.8174 - val_loss: 0.3129 - val_f1: 0.0608\n",
      "Epoch 1246/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2068 - f1: 0.8163 - val_loss: 0.3159 - val_f1: 0.0601\n",
      "Epoch 1247/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2074 - f1: 0.8150 - val_loss: 0.3190 - val_f1: 0.0602\n",
      "Epoch 1248/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2062 - f1: 0.8171 - val_loss: 0.3209 - val_f1: 0.0606\n",
      "Epoch 1249/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2055 - f1: 0.8171 - val_loss: 0.3151 - val_f1: 0.0603\n",
      "Epoch 1250/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2066 - f1: 0.8160 - val_loss: 0.3147 - val_f1: 0.0605\n",
      "Epoch 1251/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2069 - f1: 0.8151 - val_loss: 0.3099 - val_f1: 0.0597\n",
      "Epoch 1252/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2046 - f1: 0.8158 - val_loss: 0.3141 - val_f1: 0.0597\n",
      "Epoch 1253/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2062 - f1: 0.8155 - val_loss: 0.3144 - val_f1: 0.0608\n",
      "Epoch 1254/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2066 - f1: 0.8142 - val_loss: 0.3149 - val_f1: 0.0602\n",
      "Epoch 1255/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2061 - f1: 0.8173 - val_loss: 0.3192 - val_f1: 0.0607\n",
      "Epoch 1256/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2059 - f1: 0.8163 - val_loss: 0.3170 - val_f1: 0.0597\n",
      "Epoch 1257/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2049 - f1: 0.8188 - val_loss: 0.3144 - val_f1: 0.0606\n",
      "Epoch 1258/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2071 - f1: 0.8146 - val_loss: 0.3120 - val_f1: 0.0599\n",
      "Epoch 1259/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2058 - f1: 0.8170 - val_loss: 0.3115 - val_f1: 0.0606\n",
      "Epoch 1260/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2071 - f1: 0.8162 - val_loss: 0.3129 - val_f1: 0.0598\n",
      "Epoch 1261/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2049 - f1: 0.8183 - val_loss: 0.3138 - val_f1: 0.0604\n",
      "Epoch 1262/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2068 - f1: 0.8161 - val_loss: 0.3116 - val_f1: 0.0597\n",
      "Epoch 1263/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2054 - f1: 0.8176 - val_loss: 0.3149 - val_f1: 0.0601\n",
      "Epoch 1264/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2073 - f1: 0.8153 - val_loss: 0.3197 - val_f1: 0.0599\n",
      "Epoch 1265/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2061 - f1: 0.8170 - val_loss: 0.3081 - val_f1: 0.0605\n",
      "Epoch 1266/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2045 - f1: 0.8178 - val_loss: 0.3104 - val_f1: 0.0591\n",
      "Epoch 1267/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2049 - f1: 0.8167 - val_loss: 0.3187 - val_f1: 0.0605\n",
      "Epoch 1268/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2054 - f1: 0.8188 - val_loss: 0.3170 - val_f1: 0.0603\n",
      "Epoch 1269/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2062 - f1: 0.8160 - val_loss: 0.3112 - val_f1: 0.0597\n",
      "Epoch 1270/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2051 - f1: 0.8190 - val_loss: 0.3069 - val_f1: 0.0597\n",
      "Epoch 1271/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2058 - f1: 0.8182 - val_loss: 0.3075 - val_f1: 0.0602\n",
      "Epoch 1272/2000\n",
      "168135/168135 [==============================] - 12s 70us/step - loss: 0.2052 - f1: 0.8178 - val_loss: 0.3196 - val_f1: 0.0607\n",
      "Epoch 1273/2000\n",
      "168135/168135 [==============================] - 11s 67us/step - loss: 0.2067 - f1: 0.8154 - val_loss: 0.3133 - val_f1: 0.0605\n",
      "Epoch 1274/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2061 - f1: 0.8166 - val_loss: 0.3122 - val_f1: 0.0609\n",
      "Epoch 1275/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2037 - f1: 0.8175 - val_loss: 0.3165 - val_f1: 0.0603\n",
      "Epoch 1276/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2052 - f1: 0.8176 - val_loss: 0.3111 - val_f1: 0.0602\n",
      "Epoch 1277/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2048 - f1: 0.8174 - val_loss: 0.3209 - val_f1: 0.0601\n",
      "Epoch 1278/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2062 - f1: 0.8180 - val_loss: 0.3127 - val_f1: 0.0606\n",
      "Epoch 1279/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2066 - f1: 0.8166 - val_loss: 0.3177 - val_f1: 0.0611\n",
      "Epoch 1280/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2047 - f1: 0.8196 - val_loss: 0.3084 - val_f1: 0.0601\n",
      "Epoch 1281/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2057 - f1: 0.8163 - val_loss: 0.3155 - val_f1: 0.0602\n",
      "Epoch 1282/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2068 - f1: 0.8149 - val_loss: 0.3079 - val_f1: 0.0597\n",
      "Epoch 1283/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2043 - f1: 0.8178 - val_loss: 0.3144 - val_f1: 0.0597\n",
      "Epoch 1284/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2054 - f1: 0.8180 - val_loss: 0.3144 - val_f1: 0.0595\n",
      "Epoch 1285/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2051 - f1: 0.8171 - val_loss: 0.3132 - val_f1: 0.0605\n",
      "Epoch 1286/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2059 - f1: 0.8177 - val_loss: 0.3165 - val_f1: 0.0599\n",
      "Epoch 1287/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2047 - f1: 0.8188 - val_loss: 0.3116 - val_f1: 0.0605\n",
      "Epoch 1288/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2052 - f1: 0.8170 - val_loss: 0.3257 - val_f1: 0.0603\n",
      "Epoch 1289/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2039 - f1: 0.8182 - val_loss: 0.3179 - val_f1: 0.0608\n",
      "Epoch 1290/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2074 - f1: 0.8137 - val_loss: 0.3180 - val_f1: 0.0600\n",
      "Epoch 1291/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2049 - f1: 0.8181 - val_loss: 0.3177 - val_f1: 0.0606\n",
      "Epoch 1292/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2058 - f1: 0.8162 - val_loss: 0.3197 - val_f1: 0.0604\n",
      "Epoch 1293/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2054 - f1: 0.8167 - val_loss: 0.3128 - val_f1: 0.0606\n",
      "Epoch 1294/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2054 - f1: 0.8181 - val_loss: 0.3127 - val_f1: 0.0606\n",
      "Epoch 1295/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2059 - f1: 0.8175 - val_loss: 0.3048 - val_f1: 0.0599\n",
      "Epoch 1296/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2054 - f1: 0.8150 - val_loss: 0.3192 - val_f1: 0.0605\n",
      "Epoch 1297/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2038 - f1: 0.8165 - val_loss: 0.3184 - val_f1: 0.0609\n",
      "Epoch 1298/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2052 - f1: 0.8180 - val_loss: 0.3145 - val_f1: 0.0602\n",
      "Epoch 1299/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2046 - f1: 0.8182 - val_loss: 0.3163 - val_f1: 0.0599\n",
      "Epoch 1300/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2053 - f1: 0.8185 - val_loss: 0.3140 - val_f1: 0.0594\n",
      "Epoch 1301/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2042 - f1: 0.8195 - val_loss: 0.3167 - val_f1: 0.0593\n",
      "Epoch 1302/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2043 - f1: 0.8196 - val_loss: 0.3141 - val_f1: 0.0610\n",
      "Epoch 1303/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2048 - f1: 0.8189 - val_loss: 0.3133 - val_f1: 0.0595\n",
      "Epoch 1304/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2056 - f1: 0.8179 - val_loss: 0.3114 - val_f1: 0.0606\n",
      "Epoch 1305/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2049 - f1: 0.8160 - val_loss: 0.3181 - val_f1: 0.0603\n",
      "Epoch 1306/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2049 - f1: 0.8184 - val_loss: 0.3190 - val_f1: 0.0603\n",
      "Epoch 1307/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2046 - f1: 0.8175 - val_loss: 0.3171 - val_f1: 0.0600\n",
      "Epoch 1308/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2052 - f1: 0.8162 - val_loss: 0.3096 - val_f1: 0.0598\n",
      "Epoch 1309/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2047 - f1: 0.8188 - val_loss: 0.3181 - val_f1: 0.0596\n",
      "Epoch 1310/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2045 - f1: 0.8183 - val_loss: 0.3149 - val_f1: 0.0600\n",
      "Epoch 1311/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2038 - f1: 0.8183 - val_loss: 0.3194 - val_f1: 0.0606\n",
      "Epoch 1312/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2059 - f1: 0.8157 - val_loss: 0.3198 - val_f1: 0.0614\n",
      "Epoch 1313/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2055 - f1: 0.8189 - val_loss: 0.3176 - val_f1: 0.0606\n",
      "Epoch 1314/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2057 - f1: 0.8187 - val_loss: 0.3195 - val_f1: 0.0602\n",
      "Epoch 1315/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2046 - f1: 0.8176 - val_loss: 0.3155 - val_f1: 0.0605\n",
      "Epoch 1316/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2055 - f1: 0.8182 - val_loss: 0.3117 - val_f1: 0.0607\n",
      "Epoch 1317/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2039 - f1: 0.8196 - val_loss: 0.3183 - val_f1: 0.0608\n",
      "Epoch 1318/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2037 - f1: 0.8182 - val_loss: 0.3152 - val_f1: 0.0604\n",
      "Epoch 1319/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2034 - f1: 0.8195 - val_loss: 0.3184 - val_f1: 0.0604\n",
      "Epoch 1320/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2064 - f1: 0.8163 - val_loss: 0.3155 - val_f1: 0.0603\n",
      "Epoch 1321/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2035 - f1: 0.8192 - val_loss: 0.3151 - val_f1: 0.0604\n",
      "Epoch 1322/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2046 - f1: 0.8199 - val_loss: 0.3202 - val_f1: 0.0610\n",
      "Epoch 1323/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2051 - f1: 0.8161 - val_loss: 0.3143 - val_f1: 0.0598\n",
      "Epoch 1324/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2052 - f1: 0.8173 - val_loss: 0.3111 - val_f1: 0.0600\n",
      "Epoch 1325/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2041 - f1: 0.8170 - val_loss: 0.3117 - val_f1: 0.0595\n",
      "Epoch 1326/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2034 - f1: 0.8208 - val_loss: 0.3134 - val_f1: 0.0600\n",
      "Epoch 1327/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2031 - f1: 0.8187 - val_loss: 0.3134 - val_f1: 0.0603\n",
      "Epoch 1328/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2034 - f1: 0.8194 - val_loss: 0.3180 - val_f1: 0.0598\n",
      "Epoch 1329/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2049 - f1: 0.8178 - val_loss: 0.3130 - val_f1: 0.0602\n",
      "Epoch 1330/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2034 - f1: 0.8191 - val_loss: 0.3191 - val_f1: 0.0603\n",
      "Epoch 1331/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2041 - f1: 0.8177 - val_loss: 0.3093 - val_f1: 0.0599\n",
      "Epoch 1332/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2055 - f1: 0.8187 - val_loss: 0.3106 - val_f1: 0.0600\n",
      "Epoch 1333/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2044 - f1: 0.8188 - val_loss: 0.3208 - val_f1: 0.0605\n",
      "Epoch 1334/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2021 - f1: 0.8217 - val_loss: 0.3139 - val_f1: 0.0589\n",
      "Epoch 1335/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2032 - f1: 0.8201 - val_loss: 0.3150 - val_f1: 0.0602\n",
      "Epoch 1336/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2033 - f1: 0.8201 - val_loss: 0.3123 - val_f1: 0.0600\n",
      "Epoch 1337/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2056 - f1: 0.8174 - val_loss: 0.3228 - val_f1: 0.0607\n",
      "Epoch 1338/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2063 - f1: 0.8186 - val_loss: 0.3175 - val_f1: 0.0607\n",
      "Epoch 1339/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2046 - f1: 0.8165 - val_loss: 0.3201 - val_f1: 0.0597\n",
      "Epoch 1340/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2039 - f1: 0.8195 - val_loss: 0.3158 - val_f1: 0.0608\n",
      "Epoch 1341/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2027 - f1: 0.8188 - val_loss: 0.3159 - val_f1: 0.0600\n",
      "Epoch 1342/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2047 - f1: 0.8189 - val_loss: 0.3145 - val_f1: 0.0587\n",
      "Epoch 1343/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2039 - f1: 0.8181 - val_loss: 0.3087 - val_f1: 0.0598\n",
      "Epoch 1344/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2036 - f1: 0.8197 - val_loss: 0.3131 - val_f1: 0.0609\n",
      "Epoch 1345/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2039 - f1: 0.8178 - val_loss: 0.3102 - val_f1: 0.0598\n",
      "Epoch 1346/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2044 - f1: 0.8176 - val_loss: 0.3197 - val_f1: 0.0602\n",
      "Epoch 1347/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2037 - f1: 0.8185 - val_loss: 0.3105 - val_f1: 0.0603\n",
      "Epoch 1348/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2051 - f1: 0.8190 - val_loss: 0.3157 - val_f1: 0.0603\n",
      "Epoch 1349/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2047 - f1: 0.8186 - val_loss: 0.3129 - val_f1: 0.0603\n",
      "Epoch 1350/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2047 - f1: 0.8166 - val_loss: 0.3172 - val_f1: 0.0604\n",
      "Epoch 1351/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2042 - f1: 0.8180 - val_loss: 0.3158 - val_f1: 0.0602\n",
      "Epoch 1352/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2049 - f1: 0.8156 - val_loss: 0.3148 - val_f1: 0.0595\n",
      "Epoch 1353/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2052 - f1: 0.8184 - val_loss: 0.3156 - val_f1: 0.0602\n",
      "Epoch 1354/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2056 - f1: 0.8158 - val_loss: 0.3199 - val_f1: 0.0598\n",
      "Epoch 1355/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2034 - f1: 0.8180 - val_loss: 0.3189 - val_f1: 0.0601\n",
      "Epoch 1356/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2039 - f1: 0.8178 - val_loss: 0.3094 - val_f1: 0.0601\n",
      "Epoch 1357/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2035 - f1: 0.8202 - val_loss: 0.3155 - val_f1: 0.0595\n",
      "Epoch 1358/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2043 - f1: 0.8192 - val_loss: 0.3159 - val_f1: 0.0602\n",
      "Epoch 1359/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2039 - f1: 0.8197 - val_loss: 0.3159 - val_f1: 0.0594\n",
      "Epoch 1360/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2039 - f1: 0.8175 - val_loss: 0.3118 - val_f1: 0.0591\n",
      "Epoch 1361/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2033 - f1: 0.8211 - val_loss: 0.3171 - val_f1: 0.0598\n",
      "Epoch 1362/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2041 - f1: 0.8196 - val_loss: 0.3160 - val_f1: 0.0600\n",
      "Epoch 1363/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2039 - f1: 0.8194 - val_loss: 0.3142 - val_f1: 0.0603\n",
      "Epoch 1364/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2048 - f1: 0.8183 - val_loss: 0.3103 - val_f1: 0.0599\n",
      "Epoch 1365/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2042 - f1: 0.8184 - val_loss: 0.3141 - val_f1: 0.0596\n",
      "Epoch 1366/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2037 - f1: 0.8192 - val_loss: 0.3222 - val_f1: 0.0600\n",
      "Epoch 1367/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2040 - f1: 0.8195 - val_loss: 0.3168 - val_f1: 0.0600\n",
      "Epoch 1368/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2058 - f1: 0.8177 - val_loss: 0.3136 - val_f1: 0.0601\n",
      "Epoch 1369/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2025 - f1: 0.8190 - val_loss: 0.3156 - val_f1: 0.0600\n",
      "Epoch 1370/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2031 - f1: 0.8182 - val_loss: 0.3190 - val_f1: 0.0594\n",
      "Epoch 1371/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2038 - f1: 0.8179 - val_loss: 0.3167 - val_f1: 0.0610\n",
      "Epoch 1372/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2030 - f1: 0.8207 - val_loss: 0.3149 - val_f1: 0.0590\n",
      "Epoch 1373/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2047 - f1: 0.8174 - val_loss: 0.3167 - val_f1: 0.0594\n",
      "Epoch 1374/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2048 - f1: 0.8177 - val_loss: 0.3111 - val_f1: 0.0604\n",
      "Epoch 1375/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2046 - f1: 0.8173 - val_loss: 0.3094 - val_f1: 0.0603\n",
      "Epoch 1376/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2040 - f1: 0.8196 - val_loss: 0.3147 - val_f1: 0.0603\n",
      "Epoch 1377/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2038 - f1: 0.8188 - val_loss: 0.3153 - val_f1: 0.0597\n",
      "Epoch 1378/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2036 - f1: 0.8201 - val_loss: 0.3174 - val_f1: 0.0590\n",
      "Epoch 1379/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2045 - f1: 0.8170 - val_loss: 0.3156 - val_f1: 0.0596\n",
      "Epoch 1380/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2040 - f1: 0.8183 - val_loss: 0.3145 - val_f1: 0.0599\n",
      "Epoch 1381/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2034 - f1: 0.8187 - val_loss: 0.3120 - val_f1: 0.0600\n",
      "Epoch 1382/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2022 - f1: 0.8211 - val_loss: 0.3146 - val_f1: 0.0604\n",
      "Epoch 1383/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2041 - f1: 0.8180 - val_loss: 0.3143 - val_f1: 0.0600\n",
      "Epoch 1384/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2039 - f1: 0.8190 - val_loss: 0.3169 - val_f1: 0.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1385/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2032 - f1: 0.8202 - val_loss: 0.3133 - val_f1: 0.0598\n",
      "Epoch 1386/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2046 - f1: 0.8174 - val_loss: 0.3141 - val_f1: 0.0592\n",
      "Epoch 1387/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2036 - f1: 0.8185 - val_loss: 0.3127 - val_f1: 0.0590\n",
      "Epoch 1388/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2019 - f1: 0.8217 - val_loss: 0.3130 - val_f1: 0.0595\n",
      "Epoch 1389/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2037 - f1: 0.8172 - val_loss: 0.3145 - val_f1: 0.0596\n",
      "Epoch 1390/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2029 - f1: 0.8190 - val_loss: 0.3090 - val_f1: 0.0598\n",
      "Epoch 1391/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2037 - f1: 0.8177 - val_loss: 0.3137 - val_f1: 0.0600\n",
      "Epoch 1392/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2034 - f1: 0.8206 - val_loss: 0.3159 - val_f1: 0.0597\n",
      "Epoch 1393/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2035 - f1: 0.8179 - val_loss: 0.3195 - val_f1: 0.0601\n",
      "Epoch 1394/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2030 - f1: 0.8205 - val_loss: 0.3171 - val_f1: 0.0600\n",
      "Epoch 1395/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2043 - f1: 0.8183 - val_loss: 0.3143 - val_f1: 0.0603\n",
      "Epoch 1396/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2035 - f1: 0.8191 - val_loss: 0.3157 - val_f1: 0.0598\n",
      "Epoch 1397/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2023 - f1: 0.8208 - val_loss: 0.3115 - val_f1: 0.0592\n",
      "Epoch 1398/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2036 - f1: 0.8183 - val_loss: 0.3147 - val_f1: 0.0600\n",
      "Epoch 1399/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2030 - f1: 0.8196 - val_loss: 0.3161 - val_f1: 0.0607\n",
      "Epoch 1400/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2033 - f1: 0.8193 - val_loss: 0.3154 - val_f1: 0.0595\n",
      "Epoch 1401/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2039 - f1: 0.8201 - val_loss: 0.3126 - val_f1: 0.0600\n",
      "Epoch 1402/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2041 - f1: 0.8198 - val_loss: 0.3105 - val_f1: 0.0585\n",
      "Epoch 1403/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2039 - f1: 0.8189 - val_loss: 0.3155 - val_f1: 0.0597\n",
      "Epoch 1404/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2038 - f1: 0.8180 - val_loss: 0.3134 - val_f1: 0.0596\n",
      "Epoch 1405/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2017 - f1: 0.8215 - val_loss: 0.3221 - val_f1: 0.0605\n",
      "Epoch 1406/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2042 - f1: 0.8195 - val_loss: 0.3114 - val_f1: 0.0601\n",
      "Epoch 1407/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2039 - f1: 0.8191 - val_loss: 0.3131 - val_f1: 0.0586\n",
      "Epoch 1408/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2034 - f1: 0.8204 - val_loss: 0.3176 - val_f1: 0.0598\n",
      "Epoch 1409/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2031 - f1: 0.8208 - val_loss: 0.3182 - val_f1: 0.0602\n",
      "Epoch 1410/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2015 - f1: 0.8214 - val_loss: 0.3193 - val_f1: 0.0601\n",
      "Epoch 1411/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2028 - f1: 0.8198 - val_loss: 0.3225 - val_f1: 0.0603\n",
      "Epoch 1412/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2029 - f1: 0.8211 - val_loss: 0.3175 - val_f1: 0.0598\n",
      "Epoch 1413/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2038 - f1: 0.8192 - val_loss: 0.3145 - val_f1: 0.0601\n",
      "Epoch 1414/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2029 - f1: 0.8198 - val_loss: 0.3216 - val_f1: 0.0605\n",
      "Epoch 1415/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2047 - f1: 0.8177 - val_loss: 0.3182 - val_f1: 0.0599\n",
      "Epoch 1416/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2029 - f1: 0.8196 - val_loss: 0.3162 - val_f1: 0.0597\n",
      "Epoch 1417/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2016 - f1: 0.8209 - val_loss: 0.3258 - val_f1: 0.0607\n",
      "Epoch 1418/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2022 - f1: 0.8208 - val_loss: 0.3141 - val_f1: 0.0597\n",
      "Epoch 1419/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2031 - f1: 0.8205 - val_loss: 0.3114 - val_f1: 0.0599\n",
      "Epoch 1420/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2035 - f1: 0.8190 - val_loss: 0.3165 - val_f1: 0.0599\n",
      "Epoch 1421/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2037 - f1: 0.8173 - val_loss: 0.3141 - val_f1: 0.0596\n",
      "Epoch 1422/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2025 - f1: 0.8217 - val_loss: 0.3122 - val_f1: 0.0591\n",
      "Epoch 1423/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2030 - f1: 0.8192 - val_loss: 0.3162 - val_f1: 0.0595\n",
      "Epoch 1424/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2006 - f1: 0.8213 - val_loss: 0.3162 - val_f1: 0.0612\n",
      "Epoch 1425/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2029 - f1: 0.8199 - val_loss: 0.3113 - val_f1: 0.0600\n",
      "Epoch 1426/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2034 - f1: 0.8200 - val_loss: 0.3133 - val_f1: 0.0599\n",
      "Epoch 1427/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2025 - f1: 0.8206 - val_loss: 0.3166 - val_f1: 0.0600\n",
      "Epoch 1428/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2034 - f1: 0.8212 - val_loss: 0.3140 - val_f1: 0.0599\n",
      "Epoch 1429/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2021 - f1: 0.8217 - val_loss: 0.3225 - val_f1: 0.0603\n",
      "Epoch 1430/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2022 - f1: 0.8224 - val_loss: 0.3196 - val_f1: 0.0599\n",
      "Epoch 1431/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2025 - f1: 0.8197 - val_loss: 0.3167 - val_f1: 0.0600\n",
      "Epoch 1432/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2020 - f1: 0.8211 - val_loss: 0.3194 - val_f1: 0.0605\n",
      "Epoch 1433/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2010 - f1: 0.8231 - val_loss: 0.3242 - val_f1: 0.0603\n",
      "Epoch 1434/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2016 - f1: 0.8202 - val_loss: 0.3135 - val_f1: 0.0594\n",
      "Epoch 1435/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2044 - f1: 0.8170 - val_loss: 0.3125 - val_f1: 0.0598\n",
      "Epoch 1436/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2017 - f1: 0.8204 - val_loss: 0.3130 - val_f1: 0.0596\n",
      "Epoch 1437/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2039 - f1: 0.8174 - val_loss: 0.3142 - val_f1: 0.0595\n",
      "Epoch 1438/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2015 - f1: 0.8226 - val_loss: 0.3227 - val_f1: 0.0604\n",
      "Epoch 1439/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2015 - f1: 0.8222 - val_loss: 0.3170 - val_f1: 0.0601\n",
      "Epoch 1440/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2013 - f1: 0.8224 - val_loss: 0.3167 - val_f1: 0.0590\n",
      "Epoch 1441/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2017 - f1: 0.8205 - val_loss: 0.3223 - val_f1: 0.0603\n",
      "Epoch 1442/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2028 - f1: 0.8210 - val_loss: 0.3214 - val_f1: 0.0601\n",
      "Epoch 1443/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2024 - f1: 0.8198 - val_loss: 0.3188 - val_f1: 0.0609\n",
      "Epoch 1444/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2010 - f1: 0.8230 - val_loss: 0.3210 - val_f1: 0.0599\n",
      "Epoch 1445/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2028 - f1: 0.8196 - val_loss: 0.3150 - val_f1: 0.0600\n",
      "Epoch 1446/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2033 - f1: 0.8209 - val_loss: 0.3152 - val_f1: 0.0603\n",
      "Epoch 1447/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2031 - f1: 0.8209 - val_loss: 0.3191 - val_f1: 0.0595\n",
      "Epoch 1448/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2015 - f1: 0.8189 - val_loss: 0.3203 - val_f1: 0.0605\n",
      "Epoch 1449/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2032 - f1: 0.8196 - val_loss: 0.3118 - val_f1: 0.0591\n",
      "Epoch 1450/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.2005 - f1: 0.8219 - val_loss: 0.3189 - val_f1: 0.0595\n",
      "Epoch 1451/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2024 - f1: 0.8214 - val_loss: 0.3133 - val_f1: 0.0591\n",
      "Epoch 1452/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2020 - f1: 0.8219 - val_loss: 0.3172 - val_f1: 0.0600\n",
      "Epoch 1453/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2026 - f1: 0.8194 - val_loss: 0.3205 - val_f1: 0.0595\n",
      "Epoch 1454/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2029 - f1: 0.8196 - val_loss: 0.3144 - val_f1: 0.0595\n",
      "Epoch 1455/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2031 - f1: 0.8191 - val_loss: 0.3120 - val_f1: 0.0592\n",
      "Epoch 1456/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2029 - f1: 0.8193 - val_loss: 0.3124 - val_f1: 0.0605\n",
      "Epoch 1457/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2015 - f1: 0.8220 - val_loss: 0.3185 - val_f1: 0.0601\n",
      "Epoch 1458/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2027 - f1: 0.8199 - val_loss: 0.3175 - val_f1: 0.0607\n",
      "Epoch 1459/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2017 - f1: 0.8215 - val_loss: 0.3173 - val_f1: 0.0603\n",
      "Epoch 1460/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2020 - f1: 0.8218 - val_loss: 0.3175 - val_f1: 0.0599\n",
      "Epoch 1461/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2028 - f1: 0.8217 - val_loss: 0.3174 - val_f1: 0.0591\n",
      "Epoch 1462/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2025 - f1: 0.8216 - val_loss: 0.3131 - val_f1: 0.0587\n",
      "Epoch 1463/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2020 - f1: 0.8209 - val_loss: 0.3179 - val_f1: 0.0605\n",
      "Epoch 1464/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2027 - f1: 0.8212 - val_loss: 0.3172 - val_f1: 0.0597\n",
      "Epoch 1465/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2031 - f1: 0.8202 - val_loss: 0.3160 - val_f1: 0.0598\n",
      "Epoch 1466/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2022 - f1: 0.8201 - val_loss: 0.3140 - val_f1: 0.0603\n",
      "Epoch 1467/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2030 - f1: 0.8190 - val_loss: 0.3172 - val_f1: 0.0606\n",
      "Epoch 1468/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2023 - f1: 0.8214 - val_loss: 0.3146 - val_f1: 0.0599\n",
      "Epoch 1469/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2025 - f1: 0.8197 - val_loss: 0.3218 - val_f1: 0.0609\n",
      "Epoch 1470/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2018 - f1: 0.8220 - val_loss: 0.3167 - val_f1: 0.0600\n",
      "Epoch 1471/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2023 - f1: 0.8210 - val_loss: 0.3185 - val_f1: 0.0594\n",
      "Epoch 1472/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2014 - f1: 0.8198 - val_loss: 0.3178 - val_f1: 0.0601\n",
      "Epoch 1473/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2029 - f1: 0.8202 - val_loss: 0.3175 - val_f1: 0.0606\n",
      "Epoch 1474/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2035 - f1: 0.8193 - val_loss: 0.3171 - val_f1: 0.0599\n",
      "Epoch 1475/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2014 - f1: 0.8211 - val_loss: 0.3153 - val_f1: 0.0596\n",
      "Epoch 1476/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2015 - f1: 0.8211 - val_loss: 0.3188 - val_f1: 0.0607\n",
      "Epoch 1477/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2001 - f1: 0.8230 - val_loss: 0.3097 - val_f1: 0.0594\n",
      "Epoch 1478/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2016 - f1: 0.8213 - val_loss: 0.3182 - val_f1: 0.0597\n",
      "Epoch 1479/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2028 - f1: 0.8192 - val_loss: 0.3162 - val_f1: 0.0599\n",
      "Epoch 1480/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2025 - f1: 0.8194 - val_loss: 0.3176 - val_f1: 0.0600\n",
      "Epoch 1481/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2001 - f1: 0.8215 - val_loss: 0.3231 - val_f1: 0.0603\n",
      "Epoch 1482/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2011 - f1: 0.8207 - val_loss: 0.3219 - val_f1: 0.0602\n",
      "Epoch 1483/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2022 - f1: 0.8209 - val_loss: 0.3194 - val_f1: 0.0597\n",
      "Epoch 1484/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2026 - f1: 0.8212 - val_loss: 0.3190 - val_f1: 0.0611\n",
      "Epoch 1485/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2003 - f1: 0.8203 - val_loss: 0.3185 - val_f1: 0.0604\n",
      "Epoch 1486/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2009 - f1: 0.8217 - val_loss: 0.3188 - val_f1: 0.0592\n",
      "Epoch 1487/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2022 - f1: 0.8216 - val_loss: 0.3141 - val_f1: 0.0598\n",
      "Epoch 1488/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2018 - f1: 0.8213 - val_loss: 0.3183 - val_f1: 0.0591\n",
      "Epoch 1489/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2029 - f1: 0.8190 - val_loss: 0.3116 - val_f1: 0.0591\n",
      "Epoch 1490/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2028 - f1: 0.8214 - val_loss: 0.3166 - val_f1: 0.0602\n",
      "Epoch 1491/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2005 - f1: 0.8228 - val_loss: 0.3152 - val_f1: 0.0597\n",
      "Epoch 1492/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2022 - f1: 0.8205 - val_loss: 0.3151 - val_f1: 0.0607\n",
      "Epoch 1493/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2024 - f1: 0.8221 - val_loss: 0.3126 - val_f1: 0.0593\n",
      "Epoch 1494/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2015 - f1: 0.8222 - val_loss: 0.3146 - val_f1: 0.0591\n",
      "Epoch 1495/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2036 - f1: 0.8198 - val_loss: 0.3193 - val_f1: 0.0599\n",
      "Epoch 1496/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2013 - f1: 0.8221 - val_loss: 0.3214 - val_f1: 0.0595\n",
      "Epoch 1497/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.2014 - f1: 0.8211 - val_loss: 0.3235 - val_f1: 0.0603\n",
      "Epoch 1498/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2023 - f1: 0.8216 - val_loss: 0.3134 - val_f1: 0.0587\n",
      "Epoch 1499/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 11s 68us/step - loss: 0.2012 - f1: 0.8220 - val_loss: 0.3161 - val_f1: 0.0597\n",
      "Epoch 1500/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2021 - f1: 0.8204 - val_loss: 0.3200 - val_f1: 0.0599\n",
      "Epoch 1501/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2004 - f1: 0.8219 - val_loss: 0.3187 - val_f1: 0.0599\n",
      "Epoch 1502/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2011 - f1: 0.8210 - val_loss: 0.3177 - val_f1: 0.0603\n",
      "Epoch 1503/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2012 - f1: 0.8201 - val_loss: 0.3194 - val_f1: 0.0597\n",
      "Epoch 1504/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2007 - f1: 0.8215 - val_loss: 0.3179 - val_f1: 0.0588\n",
      "Epoch 1505/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2013 - f1: 0.8195 - val_loss: 0.3166 - val_f1: 0.0595\n",
      "Epoch 1506/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2028 - f1: 0.8191 - val_loss: 0.3095 - val_f1: 0.0594\n",
      "Epoch 1507/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2006 - f1: 0.8221 - val_loss: 0.3188 - val_f1: 0.0596\n",
      "Epoch 1508/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2020 - f1: 0.8217 - val_loss: 0.3183 - val_f1: 0.0607\n",
      "Epoch 1509/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2015 - f1: 0.8212 - val_loss: 0.3169 - val_f1: 0.0597\n",
      "Epoch 1510/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2007 - f1: 0.8227 - val_loss: 0.3202 - val_f1: 0.0593\n",
      "Epoch 1511/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2000 - f1: 0.8254 - val_loss: 0.3241 - val_f1: 0.0593\n",
      "Epoch 1512/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2008 - f1: 0.8231 - val_loss: 0.3139 - val_f1: 0.0601\n",
      "Epoch 1513/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2013 - f1: 0.8208 - val_loss: 0.3200 - val_f1: 0.0602\n",
      "Epoch 1514/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2012 - f1: 0.8226 - val_loss: 0.3195 - val_f1: 0.0603\n",
      "Epoch 1515/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1999 - f1: 0.8212 - val_loss: 0.3169 - val_f1: 0.0589\n",
      "Epoch 1516/2000\n",
      "168135/168135 [==============================] - 11s 62us/step - loss: 0.2028 - f1: 0.8213 - val_loss: 0.3198 - val_f1: 0.0595\n",
      "Epoch 1517/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2018 - f1: 0.8191 - val_loss: 0.3127 - val_f1: 0.0597\n",
      "Epoch 1518/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2019 - f1: 0.8202 - val_loss: 0.3126 - val_f1: 0.0589\n",
      "Epoch 1519/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2026 - f1: 0.8208 - val_loss: 0.3179 - val_f1: 0.0598\n",
      "Epoch 1520/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2017 - f1: 0.8215 - val_loss: 0.3198 - val_f1: 0.0603\n",
      "Epoch 1521/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2009 - f1: 0.8212 - val_loss: 0.3206 - val_f1: 0.0604\n",
      "Epoch 1522/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2023 - f1: 0.8208 - val_loss: 0.3174 - val_f1: 0.0598\n",
      "Epoch 1523/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2014 - f1: 0.8210 - val_loss: 0.3160 - val_f1: 0.0598\n",
      "Epoch 1524/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2007 - f1: 0.8239 - val_loss: 0.3237 - val_f1: 0.0598\n",
      "Epoch 1525/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2002 - f1: 0.8216 - val_loss: 0.3165 - val_f1: 0.0592\n",
      "Epoch 1526/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2012 - f1: 0.8229 - val_loss: 0.3113 - val_f1: 0.0598\n",
      "Epoch 1527/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2007 - f1: 0.8212 - val_loss: 0.3200 - val_f1: 0.0597\n",
      "Epoch 1528/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2006 - f1: 0.8215 - val_loss: 0.3201 - val_f1: 0.0598\n",
      "Epoch 1529/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2023 - f1: 0.8196 - val_loss: 0.3164 - val_f1: 0.0592\n",
      "Epoch 1530/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2021 - f1: 0.8212 - val_loss: 0.3207 - val_f1: 0.0601\n",
      "Epoch 1531/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2007 - f1: 0.8232 - val_loss: 0.3189 - val_f1: 0.0598\n",
      "Epoch 1532/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2006 - f1: 0.8218 - val_loss: 0.3134 - val_f1: 0.0592\n",
      "Epoch 1533/2000\n",
      "168135/168135 [==============================] - 11s 62us/step - loss: 0.2013 - f1: 0.8221 - val_loss: 0.3187 - val_f1: 0.0601\n",
      "Epoch 1534/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2024 - f1: 0.8214 - val_loss: 0.3130 - val_f1: 0.0606\n",
      "Epoch 1535/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2016 - f1: 0.8223 - val_loss: 0.3206 - val_f1: 0.0597\n",
      "Epoch 1536/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2007 - f1: 0.8221 - val_loss: 0.3217 - val_f1: 0.0600\n",
      "Epoch 1537/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2010 - f1: 0.8223 - val_loss: 0.3168 - val_f1: 0.0601\n",
      "Epoch 1538/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2025 - f1: 0.8189 - val_loss: 0.3122 - val_f1: 0.0609\n",
      "Epoch 1539/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2017 - f1: 0.8209 - val_loss: 0.3125 - val_f1: 0.0592\n",
      "Epoch 1540/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.1996 - f1: 0.8243 - val_loss: 0.3182 - val_f1: 0.0596\n",
      "Epoch 1541/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2013 - f1: 0.8209 - val_loss: 0.3127 - val_f1: 0.0599\n",
      "Epoch 1542/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2002 - f1: 0.8225 - val_loss: 0.3154 - val_f1: 0.0592\n",
      "Epoch 1543/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2011 - f1: 0.8212 - val_loss: 0.3224 - val_f1: 0.0606\n",
      "Epoch 1544/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2016 - f1: 0.8218 - val_loss: 0.3169 - val_f1: 0.0599\n",
      "Epoch 1545/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2012 - f1: 0.8218 - val_loss: 0.3145 - val_f1: 0.0590\n",
      "Epoch 1546/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2016 - f1: 0.8205 - val_loss: 0.3148 - val_f1: 0.0602\n",
      "Epoch 1547/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1999 - f1: 0.8229 - val_loss: 0.3139 - val_f1: 0.0600\n",
      "Epoch 1548/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2030 - f1: 0.8191 - val_loss: 0.3159 - val_f1: 0.0600\n",
      "Epoch 1549/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2003 - f1: 0.8218 - val_loss: 0.3173 - val_f1: 0.0587\n",
      "Epoch 1550/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2007 - f1: 0.8228 - val_loss: 0.3173 - val_f1: 0.0602\n",
      "Epoch 1551/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2024 - f1: 0.8221 - val_loss: 0.3182 - val_f1: 0.0591\n",
      "Epoch 1552/2000\n",
      "168135/168135 [==============================] - 11s 64us/step - loss: 0.2023 - f1: 0.8194 - val_loss: 0.3153 - val_f1: 0.0598\n",
      "Epoch 1553/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2000 - f1: 0.8233 - val_loss: 0.3136 - val_f1: 0.0594\n",
      "Epoch 1554/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2009 - f1: 0.8230 - val_loss: 0.3166 - val_f1: 0.0607\n",
      "Epoch 1555/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.2013 - f1: 0.8220 - val_loss: 0.3121 - val_f1: 0.0584\n",
      "Epoch 1556/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1997 - f1: 0.8231 - val_loss: 0.3175 - val_f1: 0.0595\n",
      "Epoch 1557/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1993 - f1: 0.8241 - val_loss: 0.3172 - val_f1: 0.0600\n",
      "Epoch 1558/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2016 - f1: 0.8202 - val_loss: 0.3189 - val_f1: 0.0598\n",
      "Epoch 1559/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2017 - f1: 0.8200 - val_loss: 0.3189 - val_f1: 0.0602\n",
      "Epoch 1560/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2016 - f1: 0.8206 - val_loss: 0.3107 - val_f1: 0.0588\n",
      "Epoch 1561/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2019 - f1: 0.8201 - val_loss: 0.3178 - val_f1: 0.0597\n",
      "Epoch 1562/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1999 - f1: 0.8218 - val_loss: 0.3201 - val_f1: 0.0598\n",
      "Epoch 1563/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1987 - f1: 0.8240 - val_loss: 0.3225 - val_f1: 0.0599\n",
      "Epoch 1564/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2006 - f1: 0.8223 - val_loss: 0.3154 - val_f1: 0.0594\n",
      "Epoch 1565/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2006 - f1: 0.8233 - val_loss: 0.3251 - val_f1: 0.0600\n",
      "Epoch 1566/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2002 - f1: 0.8236 - val_loss: 0.3168 - val_f1: 0.0605\n",
      "Epoch 1567/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1995 - f1: 0.8231 - val_loss: 0.3199 - val_f1: 0.0589\n",
      "Epoch 1568/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2012 - f1: 0.8189 - val_loss: 0.3129 - val_f1: 0.0597\n",
      "Epoch 1569/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1994 - f1: 0.8231 - val_loss: 0.3211 - val_f1: 0.0594\n",
      "Epoch 1570/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1999 - f1: 0.8237 - val_loss: 0.3150 - val_f1: 0.0593\n",
      "Epoch 1571/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2004 - f1: 0.8235 - val_loss: 0.3196 - val_f1: 0.0604\n",
      "Epoch 1572/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1986 - f1: 0.8248 - val_loss: 0.3166 - val_f1: 0.0592\n",
      "Epoch 1573/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2030 - f1: 0.8203 - val_loss: 0.3191 - val_f1: 0.0606\n",
      "Epoch 1574/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2008 - f1: 0.8206 - val_loss: 0.3196 - val_f1: 0.0596\n",
      "Epoch 1575/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1997 - f1: 0.8232 - val_loss: 0.3206 - val_f1: 0.0595\n",
      "Epoch 1576/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1999 - f1: 0.8217 - val_loss: 0.3179 - val_f1: 0.0598\n",
      "Epoch 1577/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1988 - f1: 0.8232 - val_loss: 0.3206 - val_f1: 0.0592\n",
      "Epoch 1578/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2014 - f1: 0.8218 - val_loss: 0.3148 - val_f1: 0.0594\n",
      "Epoch 1579/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1999 - f1: 0.8248 - val_loss: 0.3190 - val_f1: 0.0602\n",
      "Epoch 1580/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2004 - f1: 0.8217 - val_loss: 0.3240 - val_f1: 0.0603\n",
      "Epoch 1581/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2013 - f1: 0.8219 - val_loss: 0.3168 - val_f1: 0.0599\n",
      "Epoch 1582/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2009 - f1: 0.8230 - val_loss: 0.3175 - val_f1: 0.0596\n",
      "Epoch 1583/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2000 - f1: 0.8210 - val_loss: 0.3237 - val_f1: 0.0612\n",
      "Epoch 1584/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2011 - f1: 0.8222 - val_loss: 0.3228 - val_f1: 0.0600\n",
      "Epoch 1585/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1992 - f1: 0.8234 - val_loss: 0.3197 - val_f1: 0.0602\n",
      "Epoch 1586/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2005 - f1: 0.8213 - val_loss: 0.3199 - val_f1: 0.0601\n",
      "Epoch 1587/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1982 - f1: 0.8250 - val_loss: 0.3174 - val_f1: 0.0584\n",
      "Epoch 1588/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1984 - f1: 0.8245 - val_loss: 0.3275 - val_f1: 0.0594\n",
      "Epoch 1589/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2000 - f1: 0.8237 - val_loss: 0.3254 - val_f1: 0.0603\n",
      "Epoch 1590/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2004 - f1: 0.8227 - val_loss: 0.3230 - val_f1: 0.0597\n",
      "Epoch 1591/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2001 - f1: 0.8227 - val_loss: 0.3108 - val_f1: 0.0595\n",
      "Epoch 1592/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1999 - f1: 0.8238 - val_loss: 0.3232 - val_f1: 0.0601\n",
      "Epoch 1593/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1993 - f1: 0.8236 - val_loss: 0.3190 - val_f1: 0.0592\n",
      "Epoch 1594/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2002 - f1: 0.8235 - val_loss: 0.3179 - val_f1: 0.0600\n",
      "Epoch 1595/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2008 - f1: 0.8218 - val_loss: 0.3240 - val_f1: 0.0596\n",
      "Epoch 1596/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1995 - f1: 0.8229 - val_loss: 0.3168 - val_f1: 0.0610\n",
      "Epoch 1597/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2012 - f1: 0.8213 - val_loss: 0.3100 - val_f1: 0.0590\n",
      "Epoch 1598/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2002 - f1: 0.8219 - val_loss: 0.3163 - val_f1: 0.0594\n",
      "Epoch 1599/2000\n",
      "168135/168135 [==============================] - 11s 62us/step - loss: 0.2016 - f1: 0.8222 - val_loss: 0.3130 - val_f1: 0.0588\n",
      "Epoch 1600/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1991 - f1: 0.8223 - val_loss: 0.3152 - val_f1: 0.0599\n",
      "Epoch 1601/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2022 - f1: 0.8192 - val_loss: 0.3177 - val_f1: 0.0599\n",
      "Epoch 1602/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1994 - f1: 0.8234 - val_loss: 0.3222 - val_f1: 0.0602\n",
      "Epoch 1603/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1996 - f1: 0.8228 - val_loss: 0.3182 - val_f1: 0.0603\n",
      "Epoch 1604/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1985 - f1: 0.8254 - val_loss: 0.3119 - val_f1: 0.0592\n",
      "Epoch 1605/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2005 - f1: 0.8250 - val_loss: 0.3208 - val_f1: 0.0599\n",
      "Epoch 1606/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2005 - f1: 0.8222 - val_loss: 0.3207 - val_f1: 0.0596\n",
      "Epoch 1607/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2002 - f1: 0.8203 - val_loss: 0.3208 - val_f1: 0.0594\n",
      "Epoch 1608/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1993 - f1: 0.8226 - val_loss: 0.3204 - val_f1: 0.0602\n",
      "Epoch 1609/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2000 - f1: 0.8231 - val_loss: 0.3183 - val_f1: 0.0603\n",
      "Epoch 1610/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1996 - f1: 0.8224 - val_loss: 0.3210 - val_f1: 0.0605\n",
      "Epoch 1611/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2021 - f1: 0.8198 - val_loss: 0.3179 - val_f1: 0.0595\n",
      "Epoch 1612/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1994 - f1: 0.8225 - val_loss: 0.3191 - val_f1: 0.0592\n",
      "Epoch 1613/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.2006 - f1: 0.8226 - val_loss: 0.3165 - val_f1: 0.0596\n",
      "Epoch 1614/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2007 - f1: 0.8222 - val_loss: 0.3252 - val_f1: 0.0604\n",
      "Epoch 1615/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1997 - f1: 0.8244 - val_loss: 0.3246 - val_f1: 0.0600\n",
      "Epoch 1616/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1997 - f1: 0.8250 - val_loss: 0.3170 - val_f1: 0.0591\n",
      "Epoch 1617/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1989 - f1: 0.8239 - val_loss: 0.3238 - val_f1: 0.0603\n",
      "Epoch 1618/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1991 - f1: 0.8241 - val_loss: 0.3195 - val_f1: 0.0607\n",
      "Epoch 1619/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1999 - f1: 0.8218 - val_loss: 0.3189 - val_f1: 0.0595\n",
      "Epoch 1620/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1996 - f1: 0.8243 - val_loss: 0.3170 - val_f1: 0.0592\n",
      "Epoch 1621/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1994 - f1: 0.8230 - val_loss: 0.3222 - val_f1: 0.0599\n",
      "Epoch 1622/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2001 - f1: 0.8220 - val_loss: 0.3189 - val_f1: 0.0589\n",
      "Epoch 1623/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2007 - f1: 0.8220 - val_loss: 0.3170 - val_f1: 0.0599\n",
      "Epoch 1624/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1994 - f1: 0.8239 - val_loss: 0.3225 - val_f1: 0.0603\n",
      "Epoch 1625/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1992 - f1: 0.8222 - val_loss: 0.3219 - val_f1: 0.0597\n",
      "Epoch 1626/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1993 - f1: 0.8236 - val_loss: 0.3141 - val_f1: 0.0593\n",
      "Epoch 1627/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2001 - f1: 0.8226 - val_loss: 0.3257 - val_f1: 0.0606\n",
      "Epoch 1628/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2001 - f1: 0.8239 - val_loss: 0.3113 - val_f1: 0.0594\n",
      "Epoch 1629/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1995 - f1: 0.8237 - val_loss: 0.3183 - val_f1: 0.0601\n",
      "Epoch 1630/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2008 - f1: 0.8221 - val_loss: 0.3183 - val_f1: 0.0594\n",
      "Epoch 1631/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1991 - f1: 0.8234 - val_loss: 0.3197 - val_f1: 0.0601\n",
      "Epoch 1632/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1996 - f1: 0.8229 - val_loss: 0.3174 - val_f1: 0.0592\n",
      "Epoch 1633/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1997 - f1: 0.8229 - val_loss: 0.3221 - val_f1: 0.0598\n",
      "Epoch 1634/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1988 - f1: 0.8239 - val_loss: 0.3210 - val_f1: 0.0598\n",
      "Epoch 1635/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1998 - f1: 0.8221 - val_loss: 0.3223 - val_f1: 0.0593\n",
      "Epoch 1636/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2006 - f1: 0.8222 - val_loss: 0.3118 - val_f1: 0.0596\n",
      "Epoch 1637/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1994 - f1: 0.8238 - val_loss: 0.3172 - val_f1: 0.0595\n",
      "Epoch 1638/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1997 - f1: 0.8220 - val_loss: 0.3233 - val_f1: 0.0603\n",
      "Epoch 1639/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1993 - f1: 0.8243 - val_loss: 0.3189 - val_f1: 0.0604\n",
      "Epoch 1640/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1986 - f1: 0.8236 - val_loss: 0.3217 - val_f1: 0.0596\n",
      "Epoch 1641/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1993 - f1: 0.8229 - val_loss: 0.3187 - val_f1: 0.0583\n",
      "Epoch 1642/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1987 - f1: 0.8241 - val_loss: 0.3171 - val_f1: 0.0595\n",
      "Epoch 1643/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1992 - f1: 0.8244 - val_loss: 0.3196 - val_f1: 0.0596\n",
      "Epoch 1644/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1981 - f1: 0.8269 - val_loss: 0.3159 - val_f1: 0.0604\n",
      "Epoch 1645/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2004 - f1: 0.8227 - val_loss: 0.3157 - val_f1: 0.0591\n",
      "Epoch 1646/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1983 - f1: 0.8234 - val_loss: 0.3175 - val_f1: 0.0598\n",
      "Epoch 1647/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1994 - f1: 0.8247 - val_loss: 0.3137 - val_f1: 0.0592\n",
      "Epoch 1648/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2004 - f1: 0.8235 - val_loss: 0.3143 - val_f1: 0.0599\n",
      "Epoch 1649/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1998 - f1: 0.8245 - val_loss: 0.3279 - val_f1: 0.0608\n",
      "Epoch 1650/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1998 - f1: 0.8229 - val_loss: 0.3136 - val_f1: 0.0588\n",
      "Epoch 1651/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1973 - f1: 0.8248 - val_loss: 0.3148 - val_f1: 0.0586\n",
      "Epoch 1652/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1987 - f1: 0.8234 - val_loss: 0.3222 - val_f1: 0.0609\n",
      "Epoch 1653/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.2008 - f1: 0.8219 - val_loss: 0.3139 - val_f1: 0.0588\n",
      "Epoch 1654/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1994 - f1: 0.8219 - val_loss: 0.3185 - val_f1: 0.0603\n",
      "Epoch 1655/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1991 - f1: 0.8241 - val_loss: 0.3211 - val_f1: 0.0593\n",
      "Epoch 1656/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.1997 - f1: 0.8223 - val_loss: 0.3173 - val_f1: 0.0600\n",
      "Epoch 1657/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1994 - f1: 0.8219 - val_loss: 0.3214 - val_f1: 0.0596\n",
      "Epoch 1658/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1988 - f1: 0.8251 - val_loss: 0.3144 - val_f1: 0.0582\n",
      "Epoch 1659/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1996 - f1: 0.8232 - val_loss: 0.3177 - val_f1: 0.0594\n",
      "Epoch 1660/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.2002 - f1: 0.8216 - val_loss: 0.3198 - val_f1: 0.0601\n",
      "Epoch 1661/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1991 - f1: 0.8233 - val_loss: 0.3248 - val_f1: 0.0596\n",
      "Epoch 1662/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1984 - f1: 0.8254 - val_loss: 0.3117 - val_f1: 0.0587\n",
      "Epoch 1663/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1998 - f1: 0.8233 - val_loss: 0.3132 - val_f1: 0.0592\n",
      "Epoch 1664/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1990 - f1: 0.8246 - val_loss: 0.3138 - val_f1: 0.0588\n",
      "Epoch 1665/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1993 - f1: 0.8233 - val_loss: 0.3220 - val_f1: 0.0604\n",
      "Epoch 1666/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1988 - f1: 0.8252 - val_loss: 0.3211 - val_f1: 0.0593\n",
      "Epoch 1667/2000\n",
      "168135/168135 [==============================] - 10s 62us/step - loss: 0.1993 - f1: 0.8232 - val_loss: 0.3121 - val_f1: 0.0591\n",
      "Epoch 1668/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2012 - f1: 0.8208 - val_loss: 0.3168 - val_f1: 0.0594\n",
      "Epoch 1669/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2012 - f1: 0.8215 - val_loss: 0.3180 - val_f1: 0.0597\n",
      "Epoch 1670/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1989 - f1: 0.8245 - val_loss: 0.3156 - val_f1: 0.0586\n",
      "Epoch 1671/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1974 - f1: 0.8267 - val_loss: 0.3192 - val_f1: 0.0597\n",
      "Epoch 1672/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2003 - f1: 0.8232 - val_loss: 0.3169 - val_f1: 0.0594\n",
      "Epoch 1673/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1991 - f1: 0.8246 - val_loss: 0.3136 - val_f1: 0.0590\n",
      "Epoch 1674/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1998 - f1: 0.8237 - val_loss: 0.3135 - val_f1: 0.0589\n",
      "Epoch 1675/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1983 - f1: 0.8229 - val_loss: 0.3224 - val_f1: 0.0599\n",
      "Epoch 1676/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.2014 - f1: 0.8211 - val_loss: 0.3223 - val_f1: 0.0601\n",
      "Epoch 1677/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1996 - f1: 0.8245 - val_loss: 0.3201 - val_f1: 0.0596\n",
      "Epoch 1678/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1994 - f1: 0.8233 - val_loss: 0.3174 - val_f1: 0.0600\n",
      "Epoch 1679/2000\n",
      "168135/168135 [==============================] - 10s 59us/step - loss: 0.1985 - f1: 0.8247 - val_loss: 0.3187 - val_f1: 0.0584\n",
      "Epoch 1680/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1982 - f1: 0.8249 - val_loss: 0.3232 - val_f1: 0.0587\n",
      "Epoch 1681/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1988 - f1: 0.8230 - val_loss: 0.3286 - val_f1: 0.0594\n",
      "Epoch 1682/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1999 - f1: 0.8219 - val_loss: 0.3193 - val_f1: 0.0599\n",
      "Epoch 1683/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1981 - f1: 0.8260 - val_loss: 0.3193 - val_f1: 0.0596\n",
      "Epoch 1684/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1990 - f1: 0.8229 - val_loss: 0.3135 - val_f1: 0.0591\n",
      "Epoch 1685/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1977 - f1: 0.8228 - val_loss: 0.3197 - val_f1: 0.0597\n",
      "Epoch 1686/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1992 - f1: 0.8244 - val_loss: 0.3265 - val_f1: 0.0594\n",
      "Epoch 1687/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1986 - f1: 0.8242 - val_loss: 0.3197 - val_f1: 0.0587\n",
      "Epoch 1688/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1993 - f1: 0.8236 - val_loss: 0.3171 - val_f1: 0.0596\n",
      "Epoch 1689/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1979 - f1: 0.8256 - val_loss: 0.3180 - val_f1: 0.0596\n",
      "Epoch 1690/2000\n",
      "168135/168135 [==============================] - 10s 58us/step - loss: 0.1978 - f1: 0.8264 - val_loss: 0.3151 - val_f1: 0.0589\n",
      "Epoch 1691/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1984 - f1: 0.8241 - val_loss: 0.3222 - val_f1: 0.0590\n",
      "Epoch 1692/2000\n",
      "168135/168135 [==============================] - 10s 61us/step - loss: 0.1995 - f1: 0.8220 - val_loss: 0.3232 - val_f1: 0.0594\n",
      "Epoch 1693/2000\n",
      "168135/168135 [==============================] - 10s 60us/step - loss: 0.1983 - f1: 0.8257 - val_loss: 0.3241 - val_f1: 0.0602\n",
      "Epoch 1694/2000\n",
      "168135/168135 [==============================] - 11s 63us/step - loss: 0.1992 - f1: 0.8249 - val_loss: 0.3139 - val_f1: 0.0588\n",
      "Epoch 1695/2000\n",
      "168135/168135 [==============================] - 12s 70us/step - loss: 0.1985 - f1: 0.8256 - val_loss: 0.3199 - val_f1: 0.0589\n",
      "Epoch 1696/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1998 - f1: 0.8226 - val_loss: 0.3157 - val_f1: 0.0596\n",
      "Epoch 1697/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1987 - f1: 0.8257 - val_loss: 0.3178 - val_f1: 0.0595\n",
      "Epoch 1698/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1969 - f1: 0.8256 - val_loss: 0.3235 - val_f1: 0.0602\n",
      "Epoch 1699/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1977 - f1: 0.8252 - val_loss: 0.3228 - val_f1: 0.0603\n",
      "Epoch 1700/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2001 - f1: 0.8215 - val_loss: 0.3180 - val_f1: 0.0601\n",
      "Epoch 1701/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1994 - f1: 0.8226 - val_loss: 0.3193 - val_f1: 0.0595\n",
      "Epoch 1702/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1983 - f1: 0.8245 - val_loss: 0.3198 - val_f1: 0.0596\n",
      "Epoch 1703/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1987 - f1: 0.8244 - val_loss: 0.3175 - val_f1: 0.0602\n",
      "Epoch 1704/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.2006 - f1: 0.8238 - val_loss: 0.3238 - val_f1: 0.0598\n",
      "Epoch 1705/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1992 - f1: 0.8229 - val_loss: 0.3222 - val_f1: 0.0599\n",
      "Epoch 1706/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1995 - f1: 0.8237 - val_loss: 0.3161 - val_f1: 0.0604\n",
      "Epoch 1707/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1986 - f1: 0.8245 - val_loss: 0.3176 - val_f1: 0.0597\n",
      "Epoch 1708/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1989 - f1: 0.8248 - val_loss: 0.3200 - val_f1: 0.0598\n",
      "Epoch 1709/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1978 - f1: 0.8254 - val_loss: 0.3167 - val_f1: 0.0594\n",
      "Epoch 1710/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1990 - f1: 0.8236 - val_loss: 0.3259 - val_f1: 0.0597\n",
      "Epoch 1711/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1982 - f1: 0.8246 - val_loss: 0.3187 - val_f1: 0.0598\n",
      "Epoch 1712/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1989 - f1: 0.8248 - val_loss: 0.3197 - val_f1: 0.0601\n",
      "Epoch 1713/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1998 - f1: 0.8234 - val_loss: 0.3190 - val_f1: 0.0594\n",
      "Epoch 1714/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1974 - f1: 0.8235 - val_loss: 0.3169 - val_f1: 0.0599\n",
      "Epoch 1715/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1985 - f1: 0.8230 - val_loss: 0.3244 - val_f1: 0.0600\n",
      "Epoch 1716/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1982 - f1: 0.8222 - val_loss: 0.3174 - val_f1: 0.0596\n",
      "Epoch 1717/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1973 - f1: 0.8266 - val_loss: 0.3179 - val_f1: 0.0597\n",
      "Epoch 1718/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1994 - f1: 0.8247 - val_loss: 0.3192 - val_f1: 0.0597\n",
      "Epoch 1719/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1984 - f1: 0.8242 - val_loss: 0.3202 - val_f1: 0.0603\n",
      "Epoch 1720/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1993 - f1: 0.8234 - val_loss: 0.3175 - val_f1: 0.0597\n",
      "Epoch 1721/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1972 - f1: 0.8260 - val_loss: 0.3146 - val_f1: 0.0580\n",
      "Epoch 1722/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1980 - f1: 0.8239 - val_loss: 0.3164 - val_f1: 0.0600\n",
      "Epoch 1723/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1989 - f1: 0.8235 - val_loss: 0.3174 - val_f1: 0.0593\n",
      "Epoch 1724/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1985 - f1: 0.8231 - val_loss: 0.3165 - val_f1: 0.0593\n",
      "Epoch 1725/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1985 - f1: 0.8228 - val_loss: 0.3236 - val_f1: 0.0601\n",
      "Epoch 1726/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1973 - f1: 0.8261 - val_loss: 0.3189 - val_f1: 0.0595\n",
      "Epoch 1727/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1961 - f1: 0.8267 - val_loss: 0.3282 - val_f1: 0.0604\n",
      "Epoch 1728/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1976 - f1: 0.8255 - val_loss: 0.3206 - val_f1: 0.0591\n",
      "Epoch 1729/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1988 - f1: 0.8246 - val_loss: 0.3182 - val_f1: 0.0593\n",
      "Epoch 1730/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1993 - f1: 0.8235 - val_loss: 0.3242 - val_f1: 0.0593\n",
      "Epoch 1731/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1977 - f1: 0.8239 - val_loss: 0.3180 - val_f1: 0.0597\n",
      "Epoch 1732/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2000 - f1: 0.8237 - val_loss: 0.3219 - val_f1: 0.0601\n",
      "Epoch 1733/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1991 - f1: 0.8243 - val_loss: 0.3179 - val_f1: 0.0591\n",
      "Epoch 1734/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1973 - f1: 0.8254 - val_loss: 0.3179 - val_f1: 0.0601\n",
      "Epoch 1735/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1976 - f1: 0.8253 - val_loss: 0.3215 - val_f1: 0.0593\n",
      "Epoch 1736/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1978 - f1: 0.8239 - val_loss: 0.3207 - val_f1: 0.0600\n",
      "Epoch 1737/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1976 - f1: 0.8244 - val_loss: 0.3198 - val_f1: 0.0600\n",
      "Epoch 1738/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1988 - f1: 0.8232 - val_loss: 0.3174 - val_f1: 0.0596\n",
      "Epoch 1739/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1976 - f1: 0.8239 - val_loss: 0.3187 - val_f1: 0.0593\n",
      "Epoch 1740/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2001 - f1: 0.8249 - val_loss: 0.3113 - val_f1: 0.0597\n",
      "Epoch 1741/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1991 - f1: 0.8246 - val_loss: 0.3179 - val_f1: 0.0594\n",
      "Epoch 1742/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1991 - f1: 0.8233 - val_loss: 0.3218 - val_f1: 0.0593\n",
      "Epoch 1743/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1989 - f1: 0.8241 - val_loss: 0.3181 - val_f1: 0.0594\n",
      "Epoch 1744/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1978 - f1: 0.8254 - val_loss: 0.3197 - val_f1: 0.0590\n",
      "Epoch 1745/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1974 - f1: 0.8245 - val_loss: 0.3224 - val_f1: 0.0595\n",
      "Epoch 1746/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1975 - f1: 0.8247 - val_loss: 0.3122 - val_f1: 0.0590\n",
      "Epoch 1747/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1993 - f1: 0.8229 - val_loss: 0.3132 - val_f1: 0.0598\n",
      "Epoch 1748/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1985 - f1: 0.8247 - val_loss: 0.3187 - val_f1: 0.0600\n",
      "Epoch 1749/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1973 - f1: 0.8255 - val_loss: 0.3195 - val_f1: 0.0587\n",
      "Epoch 1750/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1984 - f1: 0.8244 - val_loss: 0.3223 - val_f1: 0.0607\n",
      "Epoch 1751/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1980 - f1: 0.8234 - val_loss: 0.3192 - val_f1: 0.0600\n",
      "Epoch 1752/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1983 - f1: 0.8236 - val_loss: 0.3225 - val_f1: 0.0588\n",
      "Epoch 1753/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1967 - f1: 0.8263 - val_loss: 0.3220 - val_f1: 0.0590\n",
      "Epoch 1754/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1989 - f1: 0.8248 - val_loss: 0.3233 - val_f1: 0.0588\n",
      "Epoch 1755/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1985 - f1: 0.8253 - val_loss: 0.3190 - val_f1: 0.0593\n",
      "Epoch 1756/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1980 - f1: 0.8254 - val_loss: 0.3253 - val_f1: 0.0600\n",
      "Epoch 1757/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1969 - f1: 0.8264 - val_loss: 0.3222 - val_f1: 0.0601\n",
      "Epoch 1758/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1997 - f1: 0.8234 - val_loss: 0.3138 - val_f1: 0.0594\n",
      "Epoch 1759/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1961 - f1: 0.8258 - val_loss: 0.3210 - val_f1: 0.0599\n",
      "Epoch 1760/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1976 - f1: 0.8248 - val_loss: 0.3209 - val_f1: 0.0598\n",
      "Epoch 1761/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1965 - f1: 0.8266 - val_loss: 0.3257 - val_f1: 0.0593\n",
      "Epoch 1762/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1964 - f1: 0.8282 - val_loss: 0.3194 - val_f1: 0.0595\n",
      "Epoch 1763/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1990 - f1: 0.8234 - val_loss: 0.3216 - val_f1: 0.0593\n",
      "Epoch 1764/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1966 - f1: 0.8272 - val_loss: 0.3184 - val_f1: 0.0592\n",
      "Epoch 1765/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1964 - f1: 0.8265 - val_loss: 0.3218 - val_f1: 0.0596\n",
      "Epoch 1766/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1969 - f1: 0.8247 - val_loss: 0.3146 - val_f1: 0.0594\n",
      "Epoch 1767/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1968 - f1: 0.8271 - val_loss: 0.3245 - val_f1: 0.0593\n",
      "Epoch 1768/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1960 - f1: 0.8264 - val_loss: 0.3193 - val_f1: 0.0592\n",
      "Epoch 1769/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1969 - f1: 0.8262 - val_loss: 0.3259 - val_f1: 0.0599\n",
      "Epoch 1770/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1975 - f1: 0.8264 - val_loss: 0.3162 - val_f1: 0.0595\n",
      "Epoch 1771/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1992 - f1: 0.8239 - val_loss: 0.3196 - val_f1: 0.0596\n",
      "Epoch 1772/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1960 - f1: 0.8269 - val_loss: 0.3261 - val_f1: 0.0594\n",
      "Epoch 1773/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1976 - f1: 0.8265 - val_loss: 0.3219 - val_f1: 0.0591\n",
      "Epoch 1774/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1985 - f1: 0.8243 - val_loss: 0.3158 - val_f1: 0.0595\n",
      "Epoch 1775/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1986 - f1: 0.8241 - val_loss: 0.3140 - val_f1: 0.0593\n",
      "Epoch 1776/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1973 - f1: 0.8253 - val_loss: 0.3125 - val_f1: 0.0591\n",
      "Epoch 1777/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1973 - f1: 0.8255 - val_loss: 0.3271 - val_f1: 0.0604\n",
      "Epoch 1778/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1977 - f1: 0.8263 - val_loss: 0.3201 - val_f1: 0.0601\n",
      "Epoch 1779/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1995 - f1: 0.8230 - val_loss: 0.3213 - val_f1: 0.0593\n",
      "Epoch 1780/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1976 - f1: 0.8252 - val_loss: 0.3214 - val_f1: 0.0600\n",
      "Epoch 1781/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1971 - f1: 0.8263 - val_loss: 0.3277 - val_f1: 0.0594\n",
      "Epoch 1782/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1950 - f1: 0.8280 - val_loss: 0.3231 - val_f1: 0.0591\n",
      "Epoch 1783/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1961 - f1: 0.8264 - val_loss: 0.3199 - val_f1: 0.0594\n",
      "Epoch 1784/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1966 - f1: 0.8270 - val_loss: 0.3153 - val_f1: 0.0597\n",
      "Epoch 1785/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1985 - f1: 0.8244 - val_loss: 0.3237 - val_f1: 0.0593\n",
      "Epoch 1786/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1987 - f1: 0.8245 - val_loss: 0.3257 - val_f1: 0.0598\n",
      "Epoch 1787/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1984 - f1: 0.8242 - val_loss: 0.3148 - val_f1: 0.0584\n",
      "Epoch 1788/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1983 - f1: 0.8245 - val_loss: 0.3226 - val_f1: 0.0603\n",
      "Epoch 1789/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1969 - f1: 0.8256 - val_loss: 0.3187 - val_f1: 0.0586\n",
      "Epoch 1790/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1978 - f1: 0.8261 - val_loss: 0.3169 - val_f1: 0.0600\n",
      "Epoch 1791/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1978 - f1: 0.8248 - val_loss: 0.3227 - val_f1: 0.0599\n",
      "Epoch 1792/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1981 - f1: 0.8257 - val_loss: 0.3200 - val_f1: 0.0592\n",
      "Epoch 1793/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1992 - f1: 0.8233 - val_loss: 0.3191 - val_f1: 0.0599\n",
      "Epoch 1794/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1967 - f1: 0.8275 - val_loss: 0.3195 - val_f1: 0.0599\n",
      "Epoch 1795/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1968 - f1: 0.8254 - val_loss: 0.3195 - val_f1: 0.0600\n",
      "Epoch 1796/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1986 - f1: 0.8239 - val_loss: 0.3216 - val_f1: 0.0603\n",
      "Epoch 1797/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1976 - f1: 0.8254 - val_loss: 0.3235 - val_f1: 0.0594\n",
      "Epoch 1798/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1962 - f1: 0.8264 - val_loss: 0.3178 - val_f1: 0.0590\n",
      "Epoch 1799/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1976 - f1: 0.8254 - val_loss: 0.3165 - val_f1: 0.0602\n",
      "Epoch 1800/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1966 - f1: 0.8261 - val_loss: 0.3160 - val_f1: 0.0587\n",
      "Epoch 1801/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1966 - f1: 0.8269 - val_loss: 0.3194 - val_f1: 0.0586\n",
      "Epoch 1802/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1965 - f1: 0.8262 - val_loss: 0.3246 - val_f1: 0.0593\n",
      "Epoch 1803/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1967 - f1: 0.8258 - val_loss: 0.3191 - val_f1: 0.0594\n",
      "Epoch 1804/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1987 - f1: 0.8230 - val_loss: 0.3237 - val_f1: 0.0598\n",
      "Epoch 1805/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1970 - f1: 0.8273 - val_loss: 0.3209 - val_f1: 0.0600\n",
      "Epoch 1806/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1976 - f1: 0.8244 - val_loss: 0.3222 - val_f1: 0.0592\n",
      "Epoch 1807/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1993 - f1: 0.8236 - val_loss: 0.3081 - val_f1: 0.0590\n",
      "Epoch 1808/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1968 - f1: 0.8266 - val_loss: 0.3231 - val_f1: 0.0598\n",
      "Epoch 1809/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1990 - f1: 0.8241 - val_loss: 0.3199 - val_f1: 0.0586\n",
      "Epoch 1810/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1968 - f1: 0.8262 - val_loss: 0.3244 - val_f1: 0.0603\n",
      "Epoch 1811/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1974 - f1: 0.8249 - val_loss: 0.3190 - val_f1: 0.0591\n",
      "Epoch 1812/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1944 - f1: 0.8287 - val_loss: 0.3210 - val_f1: 0.0588\n",
      "Epoch 1813/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.2002 - f1: 0.8226 - val_loss: 0.3210 - val_f1: 0.0600\n",
      "Epoch 1814/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1974 - f1: 0.8266 - val_loss: 0.3191 - val_f1: 0.0595\n",
      "Epoch 1815/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1971 - f1: 0.8238 - val_loss: 0.3192 - val_f1: 0.0604\n",
      "Epoch 1816/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1985 - f1: 0.8246 - val_loss: 0.3186 - val_f1: 0.0593\n",
      "Epoch 1817/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1980 - f1: 0.8261 - val_loss: 0.3215 - val_f1: 0.0595\n",
      "Epoch 1818/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1963 - f1: 0.8269 - val_loss: 0.3233 - val_f1: 0.0601\n",
      "Epoch 1819/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1967 - f1: 0.8273 - val_loss: 0.3240 - val_f1: 0.0592\n",
      "Epoch 1820/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1982 - f1: 0.8247 - val_loss: 0.3188 - val_f1: 0.0593\n",
      "Epoch 1821/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1960 - f1: 0.8272 - val_loss: 0.3271 - val_f1: 0.0609\n",
      "Epoch 1822/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1948 - f1: 0.8264 - val_loss: 0.3237 - val_f1: 0.0585\n",
      "Epoch 1823/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1972 - f1: 0.8263 - val_loss: 0.3178 - val_f1: 0.0587\n",
      "Epoch 1824/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1962 - f1: 0.8258 - val_loss: 0.3232 - val_f1: 0.0589\n",
      "Epoch 1825/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1977 - f1: 0.8266 - val_loss: 0.3163 - val_f1: 0.0590\n",
      "Epoch 1826/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1955 - f1: 0.8283 - val_loss: 0.3169 - val_f1: 0.0594\n",
      "Epoch 1827/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1956 - f1: 0.8263 - val_loss: 0.3186 - val_f1: 0.0589\n",
      "Epoch 1828/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1970 - f1: 0.8261 - val_loss: 0.3237 - val_f1: 0.0592\n",
      "Epoch 1829/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1977 - f1: 0.8264 - val_loss: 0.3202 - val_f1: 0.0602\n",
      "Epoch 1830/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1982 - f1: 0.8264 - val_loss: 0.3193 - val_f1: 0.0589\n",
      "Epoch 1831/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1958 - f1: 0.8284 - val_loss: 0.3183 - val_f1: 0.0592\n",
      "Epoch 1832/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1982 - f1: 0.8258 - val_loss: 0.3194 - val_f1: 0.0593\n",
      "Epoch 1833/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1962 - f1: 0.8275 - val_loss: 0.3189 - val_f1: 0.0598\n",
      "Epoch 1834/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1975 - f1: 0.8262 - val_loss: 0.3189 - val_f1: 0.0593\n",
      "Epoch 1835/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1969 - f1: 0.8266 - val_loss: 0.3191 - val_f1: 0.0587\n",
      "Epoch 1836/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1971 - f1: 0.8240 - val_loss: 0.3206 - val_f1: 0.0595\n",
      "Epoch 1837/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1967 - f1: 0.8264 - val_loss: 0.3235 - val_f1: 0.0590\n",
      "Epoch 1838/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1981 - f1: 0.8255 - val_loss: 0.3175 - val_f1: 0.0597\n",
      "Epoch 1839/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1970 - f1: 0.8263 - val_loss: 0.3234 - val_f1: 0.0593\n",
      "Epoch 1840/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1973 - f1: 0.8256 - val_loss: 0.3220 - val_f1: 0.0596\n",
      "Epoch 1841/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1970 - f1: 0.8264 - val_loss: 0.3209 - val_f1: 0.0594\n",
      "Epoch 1842/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1962 - f1: 0.8259 - val_loss: 0.3142 - val_f1: 0.0589\n",
      "Epoch 1843/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1965 - f1: 0.8258 - val_loss: 0.3202 - val_f1: 0.0584\n",
      "Epoch 1844/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1974 - f1: 0.8244 - val_loss: 0.3198 - val_f1: 0.0600\n",
      "Epoch 1845/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1979 - f1: 0.8262 - val_loss: 0.3244 - val_f1: 0.0599\n",
      "Epoch 1846/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1959 - f1: 0.8269 - val_loss: 0.3255 - val_f1: 0.0591\n",
      "Epoch 1847/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1972 - f1: 0.8244 - val_loss: 0.3177 - val_f1: 0.0602\n",
      "Epoch 1848/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1949 - f1: 0.8286 - val_loss: 0.3233 - val_f1: 0.0595\n",
      "Epoch 1849/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1973 - f1: 0.8258 - val_loss: 0.3220 - val_f1: 0.0598\n",
      "Epoch 1850/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1972 - f1: 0.8280 - val_loss: 0.3180 - val_f1: 0.0593\n",
      "Epoch 1851/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1957 - f1: 0.8284 - val_loss: 0.3192 - val_f1: 0.0602\n",
      "Epoch 1852/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1977 - f1: 0.8252 - val_loss: 0.3198 - val_f1: 0.0599\n",
      "Epoch 1853/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1978 - f1: 0.8250 - val_loss: 0.3163 - val_f1: 0.0595\n",
      "Epoch 1854/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1970 - f1: 0.8250 - val_loss: 0.3173 - val_f1: 0.0598\n",
      "Epoch 1855/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1954 - f1: 0.8264 - val_loss: 0.3213 - val_f1: 0.0592\n",
      "Epoch 1856/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1979 - f1: 0.8255 - val_loss: 0.3151 - val_f1: 0.0597\n",
      "Epoch 1857/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1965 - f1: 0.8267 - val_loss: 0.3225 - val_f1: 0.0596\n",
      "Epoch 1858/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1968 - f1: 0.8271 - val_loss: 0.3153 - val_f1: 0.0589\n",
      "Epoch 1859/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1976 - f1: 0.8258 - val_loss: 0.3273 - val_f1: 0.0591\n",
      "Epoch 1860/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1966 - f1: 0.8258 - val_loss: 0.3227 - val_f1: 0.0599\n",
      "Epoch 1861/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1962 - f1: 0.8254 - val_loss: 0.3231 - val_f1: 0.0606\n",
      "Epoch 1862/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1956 - f1: 0.8285 - val_loss: 0.3273 - val_f1: 0.0589\n",
      "Epoch 1863/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1951 - f1: 0.8279 - val_loss: 0.3204 - val_f1: 0.0588\n",
      "Epoch 1864/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1955 - f1: 0.8272 - val_loss: 0.3166 - val_f1: 0.0593\n",
      "Epoch 1865/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1968 - f1: 0.8241 - val_loss: 0.3241 - val_f1: 0.0596\n",
      "Epoch 1866/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1953 - f1: 0.8264 - val_loss: 0.3277 - val_f1: 0.0597\n",
      "Epoch 1867/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1969 - f1: 0.8269 - val_loss: 0.3193 - val_f1: 0.0588\n",
      "Epoch 1868/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1967 - f1: 0.8263 - val_loss: 0.3162 - val_f1: 0.0594\n",
      "Epoch 1869/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1975 - f1: 0.8279 - val_loss: 0.3174 - val_f1: 0.0593\n",
      "Epoch 1870/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1965 - f1: 0.8266 - val_loss: 0.3204 - val_f1: 0.0603\n",
      "Epoch 1871/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1965 - f1: 0.8273 - val_loss: 0.3187 - val_f1: 0.0592\n",
      "Epoch 1872/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1970 - f1: 0.8252 - val_loss: 0.3268 - val_f1: 0.0592\n",
      "Epoch 1873/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1956 - f1: 0.8260 - val_loss: 0.3268 - val_f1: 0.0598\n",
      "Epoch 1874/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1974 - f1: 0.8260 - val_loss: 0.3233 - val_f1: 0.0603\n",
      "Epoch 1875/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1968 - f1: 0.8272 - val_loss: 0.3181 - val_f1: 0.0594\n",
      "Epoch 1876/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1955 - f1: 0.8284 - val_loss: 0.3233 - val_f1: 0.0599\n",
      "Epoch 1877/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1967 - f1: 0.8259 - val_loss: 0.3252 - val_f1: 0.0599\n",
      "Epoch 1878/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1957 - f1: 0.8279 - val_loss: 0.3223 - val_f1: 0.0590\n",
      "Epoch 1879/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1963 - f1: 0.8267 - val_loss: 0.3217 - val_f1: 0.0592\n",
      "Epoch 1880/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1963 - f1: 0.8242 - val_loss: 0.3271 - val_f1: 0.0593\n",
      "Epoch 1881/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1980 - f1: 0.8245 - val_loss: 0.3187 - val_f1: 0.0592\n",
      "Epoch 1882/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1974 - f1: 0.8256 - val_loss: 0.3246 - val_f1: 0.0598\n",
      "Epoch 1883/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1955 - f1: 0.8268 - val_loss: 0.3226 - val_f1: 0.0603\n",
      "Epoch 1884/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1974 - f1: 0.8242 - val_loss: 0.3201 - val_f1: 0.0593\n",
      "Epoch 1885/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1970 - f1: 0.8264 - val_loss: 0.3243 - val_f1: 0.0589\n",
      "Epoch 1886/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1969 - f1: 0.8245 - val_loss: 0.3230 - val_f1: 0.0603\n",
      "Epoch 1887/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1954 - f1: 0.8269 - val_loss: 0.3239 - val_f1: 0.0604\n",
      "Epoch 1888/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1964 - f1: 0.8268 - val_loss: 0.3226 - val_f1: 0.0594\n",
      "Epoch 1889/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1972 - f1: 0.8264 - val_loss: 0.3177 - val_f1: 0.0597\n",
      "Epoch 1890/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1961 - f1: 0.8268 - val_loss: 0.3212 - val_f1: 0.0597\n",
      "Epoch 1891/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1970 - f1: 0.8256 - val_loss: 0.3216 - val_f1: 0.0595\n",
      "Epoch 1892/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1971 - f1: 0.8263 - val_loss: 0.3238 - val_f1: 0.0597\n",
      "Epoch 1893/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1964 - f1: 0.8267 - val_loss: 0.3262 - val_f1: 0.0589\n",
      "Epoch 1894/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1958 - f1: 0.8274 - val_loss: 0.3230 - val_f1: 0.0589\n",
      "Epoch 1895/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1953 - f1: 0.8277 - val_loss: 0.3195 - val_f1: 0.0588\n",
      "Epoch 1896/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1955 - f1: 0.8270 - val_loss: 0.3251 - val_f1: 0.0596\n",
      "Epoch 1897/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1971 - f1: 0.8280 - val_loss: 0.3196 - val_f1: 0.0598\n",
      "Epoch 1898/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1965 - f1: 0.8268 - val_loss: 0.3282 - val_f1: 0.0603\n",
      "Epoch 1899/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1951 - f1: 0.8282 - val_loss: 0.3278 - val_f1: 0.0594\n",
      "Epoch 1900/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1967 - f1: 0.8264 - val_loss: 0.3246 - val_f1: 0.0592\n",
      "Epoch 1901/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1964 - f1: 0.8275 - val_loss: 0.3234 - val_f1: 0.0594\n",
      "Epoch 1902/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1958 - f1: 0.8291 - val_loss: 0.3183 - val_f1: 0.0599\n",
      "Epoch 1903/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1951 - f1: 0.8289 - val_loss: 0.3209 - val_f1: 0.0590\n",
      "Epoch 1904/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1964 - f1: 0.8273 - val_loss: 0.3205 - val_f1: 0.0596\n",
      "Epoch 1905/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1965 - f1: 0.8257 - val_loss: 0.3215 - val_f1: 0.0590\n",
      "Epoch 1906/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1955 - f1: 0.8275 - val_loss: 0.3223 - val_f1: 0.0590\n",
      "Epoch 1907/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1975 - f1: 0.8243 - val_loss: 0.3226 - val_f1: 0.0599\n",
      "Epoch 1908/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1960 - f1: 0.8261 - val_loss: 0.3233 - val_f1: 0.0597\n",
      "Epoch 1909/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1960 - f1: 0.8284 - val_loss: 0.3175 - val_f1: 0.0593\n",
      "Epoch 1910/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1958 - f1: 0.8271 - val_loss: 0.3272 - val_f1: 0.0594\n",
      "Epoch 1911/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1967 - f1: 0.8271 - val_loss: 0.3205 - val_f1: 0.0583\n",
      "Epoch 1912/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1960 - f1: 0.8247 - val_loss: 0.3217 - val_f1: 0.0604\n",
      "Epoch 1913/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1961 - f1: 0.8262 - val_loss: 0.3165 - val_f1: 0.0591\n",
      "Epoch 1914/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1970 - f1: 0.8249 - val_loss: 0.3258 - val_f1: 0.0591\n",
      "Epoch 1915/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1948 - f1: 0.8278 - val_loss: 0.3205 - val_f1: 0.0598\n",
      "Epoch 1916/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1967 - f1: 0.8268 - val_loss: 0.3231 - val_f1: 0.0590\n",
      "Epoch 1917/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1971 - f1: 0.8263 - val_loss: 0.3186 - val_f1: 0.0594\n",
      "Epoch 1918/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1969 - f1: 0.8251 - val_loss: 0.3194 - val_f1: 0.0598\n",
      "Epoch 1919/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1954 - f1: 0.8297 - val_loss: 0.3248 - val_f1: 0.0595\n",
      "Epoch 1920/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1972 - f1: 0.8268 - val_loss: 0.3191 - val_f1: 0.0596\n",
      "Epoch 1921/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1968 - f1: 0.8262 - val_loss: 0.3238 - val_f1: 0.0594\n",
      "Epoch 1922/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1973 - f1: 0.8256 - val_loss: 0.3223 - val_f1: 0.0589\n",
      "Epoch 1923/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1954 - f1: 0.8268 - val_loss: 0.3209 - val_f1: 0.0601\n",
      "Epoch 1924/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1966 - f1: 0.8278 - val_loss: 0.3214 - val_f1: 0.0596\n",
      "Epoch 1925/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1958 - f1: 0.8265 - val_loss: 0.3243 - val_f1: 0.0601\n",
      "Epoch 1926/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1959 - f1: 0.8270 - val_loss: 0.3195 - val_f1: 0.0591\n",
      "Epoch 1927/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1979 - f1: 0.8237 - val_loss: 0.3177 - val_f1: 0.0599\n",
      "Epoch 1928/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1951 - f1: 0.8302 - val_loss: 0.3198 - val_f1: 0.0599\n",
      "Epoch 1929/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1965 - f1: 0.8255 - val_loss: 0.3216 - val_f1: 0.0599\n",
      "Epoch 1930/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1958 - f1: 0.8273 - val_loss: 0.3170 - val_f1: 0.0593\n",
      "Epoch 1931/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1947 - f1: 0.8288 - val_loss: 0.3260 - val_f1: 0.0597\n",
      "Epoch 1932/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1981 - f1: 0.8232 - val_loss: 0.3323 - val_f1: 0.0606\n",
      "Epoch 1933/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1966 - f1: 0.8266 - val_loss: 0.3223 - val_f1: 0.0594\n",
      "Epoch 1934/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1971 - f1: 0.8268 - val_loss: 0.3198 - val_f1: 0.0598\n",
      "Epoch 1935/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1969 - f1: 0.8278 - val_loss: 0.3233 - val_f1: 0.0606\n",
      "Epoch 1936/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1968 - f1: 0.8267 - val_loss: 0.3176 - val_f1: 0.0587\n",
      "Epoch 1937/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1955 - f1: 0.8264 - val_loss: 0.3182 - val_f1: 0.0588\n",
      "Epoch 1938/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1969 - f1: 0.8250 - val_loss: 0.3214 - val_f1: 0.0593\n",
      "Epoch 1939/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1957 - f1: 0.8282 - val_loss: 0.3240 - val_f1: 0.0609\n",
      "Epoch 1940/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1966 - f1: 0.8266 - val_loss: 0.3218 - val_f1: 0.0587\n",
      "Epoch 1941/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1933 - f1: 0.8306 - val_loss: 0.3257 - val_f1: 0.0598\n",
      "Epoch 1942/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1947 - f1: 0.8286 - val_loss: 0.3196 - val_f1: 0.0601\n",
      "Epoch 1943/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1974 - f1: 0.8251 - val_loss: 0.3208 - val_f1: 0.0595\n",
      "Epoch 1944/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1967 - f1: 0.8271 - val_loss: 0.3241 - val_f1: 0.0590\n",
      "Epoch 1945/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1948 - f1: 0.8269 - val_loss: 0.3206 - val_f1: 0.0586\n",
      "Epoch 1946/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1956 - f1: 0.8266 - val_loss: 0.3304 - val_f1: 0.0597\n",
      "Epoch 1947/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1962 - f1: 0.8270 - val_loss: 0.3213 - val_f1: 0.0590\n",
      "Epoch 1948/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1952 - f1: 0.8275 - val_loss: 0.3281 - val_f1: 0.0597\n",
      "Epoch 1949/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1938 - f1: 0.8285 - val_loss: 0.3211 - val_f1: 0.0596\n",
      "Epoch 1950/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1972 - f1: 0.8272 - val_loss: 0.3177 - val_f1: 0.0582\n",
      "Epoch 1951/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1958 - f1: 0.8270 - val_loss: 0.3182 - val_f1: 0.0597\n",
      "Epoch 1952/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1947 - f1: 0.8317 - val_loss: 0.3265 - val_f1: 0.0594\n",
      "Epoch 1953/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1943 - f1: 0.8285 - val_loss: 0.3117 - val_f1: 0.0593\n",
      "Epoch 1954/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1965 - f1: 0.8246 - val_loss: 0.3223 - val_f1: 0.0597\n",
      "Epoch 1955/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1951 - f1: 0.8276 - val_loss: 0.3252 - val_f1: 0.0584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1956/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1950 - f1: 0.8290 - val_loss: 0.3248 - val_f1: 0.0596\n",
      "Epoch 1957/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1947 - f1: 0.8294 - val_loss: 0.3235 - val_f1: 0.0596\n",
      "Epoch 1958/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1952 - f1: 0.8274 - val_loss: 0.3205 - val_f1: 0.0601\n",
      "Epoch 1959/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1954 - f1: 0.8278 - val_loss: 0.3228 - val_f1: 0.0595\n",
      "Epoch 1960/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1955 - f1: 0.8274 - val_loss: 0.3195 - val_f1: 0.0601\n",
      "Epoch 1961/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1966 - f1: 0.8277 - val_loss: 0.3277 - val_f1: 0.0602\n",
      "Epoch 1962/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1963 - f1: 0.8271 - val_loss: 0.3210 - val_f1: 0.0599\n",
      "Epoch 1963/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1950 - f1: 0.8284 - val_loss: 0.3290 - val_f1: 0.0590\n",
      "Epoch 1964/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1968 - f1: 0.8261 - val_loss: 0.3238 - val_f1: 0.0599\n",
      "Epoch 1965/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1948 - f1: 0.8272 - val_loss: 0.3268 - val_f1: 0.0591\n",
      "Epoch 1966/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1951 - f1: 0.8280 - val_loss: 0.3192 - val_f1: 0.0597\n",
      "Epoch 1967/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1965 - f1: 0.8273 - val_loss: 0.3175 - val_f1: 0.0586\n",
      "Epoch 1968/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1950 - f1: 0.8280 - val_loss: 0.3231 - val_f1: 0.0595\n",
      "Epoch 1969/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1947 - f1: 0.8276 - val_loss: 0.3201 - val_f1: 0.0589\n",
      "Epoch 1970/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1934 - f1: 0.8302 - val_loss: 0.3242 - val_f1: 0.0594\n",
      "Epoch 1971/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1966 - f1: 0.8267 - val_loss: 0.3219 - val_f1: 0.0590\n",
      "Epoch 1972/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1958 - f1: 0.8279 - val_loss: 0.3196 - val_f1: 0.0588\n",
      "Epoch 1973/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1951 - f1: 0.8276 - val_loss: 0.3222 - val_f1: 0.0604\n",
      "Epoch 1974/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1954 - f1: 0.8286 - val_loss: 0.3249 - val_f1: 0.0600\n",
      "Epoch 1975/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1970 - f1: 0.8267 - val_loss: 0.3141 - val_f1: 0.0598\n",
      "Epoch 1976/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1954 - f1: 0.8273 - val_loss: 0.3158 - val_f1: 0.0599\n",
      "Epoch 1977/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1950 - f1: 0.8279 - val_loss: 0.3251 - val_f1: 0.0601\n",
      "Epoch 1978/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1966 - f1: 0.8265 - val_loss: 0.3180 - val_f1: 0.0590\n",
      "Epoch 1979/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1946 - f1: 0.8279 - val_loss: 0.3208 - val_f1: 0.0591\n",
      "Epoch 1980/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1948 - f1: 0.8278 - val_loss: 0.3186 - val_f1: 0.0590\n",
      "Epoch 1981/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1956 - f1: 0.8275 - val_loss: 0.3245 - val_f1: 0.0594\n",
      "Epoch 1982/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1956 - f1: 0.8276 - val_loss: 0.3206 - val_f1: 0.0594\n",
      "Epoch 1983/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1954 - f1: 0.8290 - val_loss: 0.3170 - val_f1: 0.0592\n",
      "Epoch 1984/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1971 - f1: 0.8255 - val_loss: 0.3176 - val_f1: 0.0591\n",
      "Epoch 1985/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1966 - f1: 0.8271 - val_loss: 0.3162 - val_f1: 0.0594\n",
      "Epoch 1986/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1954 - f1: 0.8272 - val_loss: 0.3165 - val_f1: 0.0595\n",
      "Epoch 1987/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1947 - f1: 0.8300 - val_loss: 0.3170 - val_f1: 0.0591\n",
      "Epoch 1988/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1963 - f1: 0.8277 - val_loss: 0.3189 - val_f1: 0.0591\n",
      "Epoch 1989/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1955 - f1: 0.8263 - val_loss: 0.3249 - val_f1: 0.0594\n",
      "Epoch 1990/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1956 - f1: 0.8288 - val_loss: 0.3184 - val_f1: 0.0587\n",
      "Epoch 1991/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1954 - f1: 0.8277 - val_loss: 0.3215 - val_f1: 0.0596\n",
      "Epoch 1992/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1945 - f1: 0.8273 - val_loss: 0.3234 - val_f1: 0.0594\n",
      "Epoch 1993/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1949 - f1: 0.8281 - val_loss: 0.3191 - val_f1: 0.0587\n",
      "Epoch 1994/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1937 - f1: 0.8306 - val_loss: 0.3170 - val_f1: 0.0587\n",
      "Epoch 1995/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1956 - f1: 0.8287 - val_loss: 0.3255 - val_f1: 0.0592\n",
      "Epoch 1996/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1947 - f1: 0.8284 - val_loss: 0.3186 - val_f1: 0.0591\n",
      "Epoch 1997/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1949 - f1: 0.8285 - val_loss: 0.3280 - val_f1: 0.0601\n",
      "Epoch 1998/2000\n",
      "168135/168135 [==============================] - 9s 56us/step - loss: 0.1939 - f1: 0.8302 - val_loss: 0.3213 - val_f1: 0.0589\n",
      "Epoch 1999/2000\n",
      "168135/168135 [==============================] - 10s 57us/step - loss: 0.1950 - f1: 0.8290 - val_loss: 0.3237 - val_f1: 0.0594\n",
      "Epoch 2000/2000\n",
      "168135/168135 [==============================] - 9s 55us/step - loss: 0.1962 - f1: 0.8272 - val_loss: 0.3158 - val_f1: 0.0589\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna5.train(x_train_norm,y_train,x_val_norm,y_val,batch_size,epochs,loss,metric)\n",
    "rna5.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[25550  1435]\n",
      " [ 1771  1244]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[25560  1426]\n",
      " [ 1756  1259]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[123932   1999]\n",
      " [  2079  40125]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rna5.predict(x_data,y_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
